{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ApplyingSODinAutoLabelling.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "187YBwDcuUDX"
      },
      "source": [
        "#import my model from my drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!git clone https://github.com/n00bmaster68/ApplyingSODinAutoLabelling\n",
        "\n",
        "#check whether device has GPU\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_lMrpL8y6Am"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBG0DTh8xtZo"
      },
      "source": [
        "import os\n",
        "import time\n",
        "from skimage import io, transform\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms#, utils\n",
        "# import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import glob\n",
        " \n",
        "from ApplyingSODinAutoLabelling.data_loader import RescaleT\n",
        "from ApplyingSODinAutoLabelling.data_loader import CenterCrop\n",
        "from ApplyingSODinAutoLabelling.data_loader import ToTensor\n",
        "from ApplyingSODinAutoLabelling.data_loader import ToTensorLab\n",
        "from ApplyingSODinAutoLabelling.data_loader import SalObjDataset\n",
        "\n",
        "from ApplyingSODinAutoLabelling.model import BASNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_jPbGrlxr3m"
      },
      "source": [
        "def normPRED(d):\n",
        "\tma = torch.max(d)\n",
        "\tmi = torch.min(d)\n",
        "\n",
        "\tdn = (d-mi)/(ma-mi)\n",
        "\treturn dn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odh17y-gBmoU"
      },
      "source": [
        "def save_output(image_name,pred,d_dir):\n",
        "\tpredict = pred\n",
        "\tpredict = predict.squeeze()\n",
        "\tpredict_np = predict.cpu().data.numpy()\n",
        "\n",
        "\tim = Image.fromarray(predict_np*255).convert('RGB')\n",
        "\timg_name = image_name.split(\"/\")[-1]\n",
        "\timage = io.imread(image_name)\n",
        "\timo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)\n",
        "\t# imo.show()\n",
        "\tgetCoordinate(imo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p83mP6agBnGg"
      },
      "source": [
        "def getCoordinate(imo):\n",
        "\topencvImage = cv2.cvtColor(np.array(imo), cv2.COLOR_RGB2BGR)\n",
        "\theight, width, _ = opencvImage.shape\n",
        "\tlower = [np.mean(opencvImage[:,:,i] - np.std(opencvImage[:,:,i])/3 ) for i in range(3)]\n",
        "\tupper = [250, 250, 250]\n",
        "\n",
        "\t# create NumPy arrays from the boundaries\n",
        "\tlower = np.array(lower, dtype=\"uint8\")\n",
        "\tupper = np.array(upper, dtype=\"uint8\")\n",
        "\n",
        "\t# find the colors within the specified boundaries and apply\n",
        "\tmask = cv2.inRange(opencvImage, lower, upper)\n",
        "\toutput = cv2.bitwise_and(opencvImage, opencvImage, mask=mask)\n",
        "\n",
        "\tret,thresh = cv2.threshold(mask, 40, 255, 0)\n",
        "\n",
        "\tcontours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "\tlargest_contour = max(contours, key = cv2.contourArea)\n",
        "\tx,y,w,h = cv2.boundingRect(largest_contour)\n",
        "\tprint(x/width, y/height, w/width, h/height)\n",
        "\tprint(f\"x:{x}, y:{y}, hW:{h}, wW:{w}\")\n",
        "\tprint(f\"Height:{height}, Weight:{width}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMVUG8H8BnyD"
      },
      "source": [
        "# --------- 1. get image path and name ---------\n",
        "image_dir = 'ApplyingSODinAutoLabelling/test_data/test_images/'\n",
        "prediction_dir = 'ApplyingSODinAutoLabelling/test_data/test_results/'\n",
        "model_dir = '/content/gdrive/MyDrive/basnet.pth'\n",
        "img_name_list = glob.glob(image_dir + '*.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rCm0X6QBoPn"
      },
      "source": [
        "# --------- 2. dataloader ---------\n",
        "#1. dataload\n",
        "test_salobj_dataset = SalObjDataset(img_name_list = img_name_list, lbl_name_list = [],transform=transforms.Compose([RescaleT(256),ToTensorLab(flag=0)]))\n",
        "test_salobj_dataloader = DataLoader(test_salobj_dataset, batch_size=1,shuffle=False,num_workers=1)\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjeR8fW3Bojy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH65xaEXBoaM"
      },
      "source": [
        "\t# --------- 3. model define ---------\n",
        "print(\"...load BASNet...\")\n",
        "net = BASNet(3,1)\n",
        "net.load_state_dict(torch.load(model_dir))\n",
        "if torch.cuda.is_available():\n",
        "  net.cuda()\t\n",
        "net.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE2bULPBBotN"
      },
      "source": [
        "# --------- 4. inference for each image ---------\n",
        "for i_test, data_test in enumerate(test_salobj_dataloader):\n",
        "  start = time.time()\t\n",
        "  print(\"\\n inferencing:\",img_name_list[i_test].split(\"/\")[-1])\n",
        "  \n",
        "  inputs_test = data_test['image']\n",
        "  inputs_test = inputs_test.type(torch.FloatTensor)\n",
        "  if torch.cuda.is_available():\n",
        "    inputs_test = Variable(inputs_test.cuda())\n",
        "  else:\n",
        "    inputs_test = Variable(inputs_test)\n",
        "    \n",
        "  d1,d2,d3,d4,d5,d6,d7,d8 = net(inputs_test)\n",
        "  \n",
        "  # normalization\n",
        "  pred = d1[:,0,:,:]\n",
        "  pred = normPRED(pred)\t\n",
        "  \n",
        "  save_output(img_name_list[i_test],pred,prediction_dir)\n",
        "  print(\"Time: \", time.time() - start, \"\\n\")\n",
        "  # break\n",
        "  del d1,d2,d3,d4,d5,d6,d7,d8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06FlQXOvzwue"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}