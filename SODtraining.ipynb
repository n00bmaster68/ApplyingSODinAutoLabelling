{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-06-14T11:09:37.406692Z",
     "iopub.status.busy": "2021-06-14T11:09:37.406455Z",
     "iopub.status.idle": "2021-06-14T11:09:40.511118Z",
     "shell.execute_reply": "2021-06-14T11:09:40.510497Z",
     "shell.execute_reply.started": "2021-06-14T11:09:37.406670Z"
    },
    "id": "MSL2ErH4SvOZ",
    "outputId": "7cc83edb-7160-452e-baaf-014f46c1731b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ApplyingSODinAutoLabelling'...\n",
      "remote: Enumerating objects: 2101, done.\u001b[K\n",
      "remote: Counting objects: 100% (2101/2101), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2080/2080), done.\u001b[K\n",
      "remote: Total 2101 (delta 21), reused 2084 (delta 8), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (2101/2101), 75.19 MiB | 60.96 MiB/s, done.\n",
      "Resolving deltas: 100% (21/21), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/n00bmaster68/ApplyingSODinAutoLabelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-06-14T23:21:07.019035Z",
     "iopub.status.busy": "2021-06-14T23:21:07.018809Z",
     "iopub.status.idle": "2021-06-14T23:21:43.179407Z",
     "shell.execute_reply": "2021-06-14T23:21:43.178696Z",
     "shell.execute_reply.started": "2021-06-14T23:21:07.019011Z"
    },
    "id": "CjqxfTA1XGU3",
    "outputId": "8812c0fe-55a0-46e3-f50d-add18ee630da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/saturn/lib/python3.7/site-packages (from torch) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/saturn/lib/python3.7/site-packages (from torch) (3.7.4.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.8.1\n",
      "Collecting scikit-image\n",
      "  Using cached scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2 MB)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from scikit-image) (1.20.1)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.6.14-py3-none-any.whl (169 kB)\n",
      "\u001b[K     |████████████████████████████████| 169 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from scikit-image) (2.5)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from scikit-image) (3.3.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from scikit-image) (8.1.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from scikit-image) (1.6.0)\n",
      "Collecting imageio>=2.3.0\n",
      "  Using cached imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Using cached PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2020.12.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/envs/saturn/lib/python3.7/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Installing collected packages: tifffile, PyWavelets, imageio, scikit-image\n",
      "Successfully installed PyWavelets-1.1.1 imageio-2.9.0 scikit-image-0.18.1 tifffile-2021.6.14\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\n",
      "Requirement already satisfied: torch==1.8.1 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from torchvision) (1.8.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/envs/saturn/lib/python3.7/site-packages (from torchvision) (8.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/saturn/lib/python3.7/site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/saturn/lib/python3.7/site-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.9.1\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "#check whether device has GPU\n",
    "# import tensorflow as tf\n",
    "# tf.test.gpu_device_name()\n",
    "# !nvidia-smi -L\n",
    "!pip install torch\n",
    "!pip install scikit-image\n",
    "!pip install torchvision\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T23:21:43.181055Z",
     "iopub.status.busy": "2021-06-14T23:21:43.180792Z",
     "iopub.status.idle": "2021-06-14T23:21:43.715791Z",
     "shell.execute_reply": "2021-06-14T23:21:43.715271Z",
     "shell.execute_reply.started": "2021-06-14T23:21:43.181018Z"
    },
    "id": "CKJksXRPSxvA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as standard_transforms\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from ApplyingSODinAutoLabelling.data_loader import Rescale\n",
    "from ApplyingSODinAutoLabelling.data_loader import RescaleT\n",
    "from ApplyingSODinAutoLabelling.data_loader import RandomCrop\n",
    "from ApplyingSODinAutoLabelling.data_loader import CenterCrop\n",
    "from ApplyingSODinAutoLabelling.data_loader import ToTensor\n",
    "from ApplyingSODinAutoLabelling.data_loader import ToTensorLab\n",
    "from ApplyingSODinAutoLabelling.data_loader import SalObjDataset\n",
    "\n",
    "from ApplyingSODinAutoLabelling.model import BASNet\n",
    "\n",
    "import ApplyingSODinAutoLabelling.deletable.pytorch_ssim as pytorch_ssim\n",
    "import ApplyingSODinAutoLabelling.deletable.pytorch_iou as pytorch_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-06-14T23:21:43.717531Z",
     "iopub.status.busy": "2021-06-14T23:21:43.717275Z",
     "iopub.status.idle": "2021-06-14T23:21:43.726441Z",
     "shell.execute_reply": "2021-06-14T23:21:43.725775Z",
     "shell.execute_reply.started": "2021-06-14T23:21:43.717498Z"
    },
    "id": "tN6sGAEGTvJr",
    "outputId": "72cfe343-0cac-4362-b636-27fd8bb7c79a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/saturn/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# ------- 1. define loss function --------\n",
    "\n",
    "bce_loss = nn.BCELoss(size_average=True)\n",
    "ssim_loss = pytorch_ssim.SSIM(window_size=11,size_average=True)\n",
    "iou_loss = pytorch_iou.IOU(size_average=True)\n",
    "\n",
    "def bce_ssim_loss(pred,target):\n",
    "\n",
    "\tbce_out = bce_loss(pred,target)\n",
    "\tssim_out = 1 - ssim_loss(pred,target)\n",
    "\tiou_out = iou_loss(pred,target)\n",
    "\n",
    "\tloss = bce_out + ssim_out + iou_out\n",
    "\treturn loss, ssim_out\n",
    "\n",
    "def muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, d7, labels_v):\n",
    "  loss0, ssim0 = bce_ssim_loss(d0,labels_v)\n",
    "  loss1, ssim1 = bce_ssim_loss(d1,labels_v)\n",
    "  loss2, ssim2 = bce_ssim_loss(d2,labels_v)\n",
    "  loss3, ssim3 = bce_ssim_loss(d3,labels_v)\n",
    "  loss4, ssim4 = bce_ssim_loss(d4,labels_v)\n",
    "  loss5, ssim5 = bce_ssim_loss(d5,labels_v)\n",
    "  loss6, ssim6 = bce_ssim_loss(d6,labels_v)\n",
    "  loss7, ssim7 = bce_ssim_loss(d7,labels_v)\n",
    "\n",
    "  acc = (ssim0 + ssim1 + ssim2 + ssim3 + ssim4 + ssim5 + ssim6 + ssim7) / 8\n",
    "  \n",
    "  loss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6 + loss7\n",
    "  print(\"l0: %3f, l1: %3f, l2: %3f, l3: %3f, l4: %3f, l5: %3f, l6: %3f\\n\"%(loss0.data,loss1.data,loss2.data,loss3.data,loss4.data,loss5.data,loss6.data))\n",
    "  \n",
    "  return loss0, loss, 1 - acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-06-14T23:22:03.950142Z",
     "iopub.status.busy": "2021-06-14T23:22:03.949906Z",
     "iopub.status.idle": "2021-06-14T23:22:03.964340Z",
     "shell.execute_reply": "2021-06-14T23:22:03.963725Z",
     "shell.execute_reply.started": "2021-06-14T23:22:03.950118Z"
    },
    "id": "2NH-ofMLTvSX",
    "outputId": "d2d523e7-2c6c-4de2-8d80-797f81a37a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "train images:  1000\n",
      "train labels:  1000\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# ------- 2. set the directory of training dataset --------\n",
    "\n",
    "data_dir = 'ApplyingSODinAutoLabelling/train_data/'\n",
    "tra_image_dir = 'DUTS/DUTS-TR/DUTS-TR/im_aug/'\n",
    "tra_label_dir = 'DUTS/DUTS-TR/DUTS-TR/gt_aug/'\n",
    "\n",
    "image_ext = '.jpg'\n",
    "label_ext = '.png'\n",
    "\n",
    "model_dir = \"ApplyingSODinAutoLabelling/saved_models/basnet_bsi/\"\n",
    "\n",
    "\n",
    "epoch_num = 400\n",
    "batch_size_train = 8 \n",
    "batch_size_val = 1\n",
    "train_num = 0\n",
    "val_num = 0\n",
    "\n",
    "tra_img_name_list = glob.glob(data_dir + tra_image_dir + '*' + image_ext)\n",
    "\n",
    "tra_lbl_name_list = []\n",
    "for img_path in tra_img_name_list:\n",
    "\timg_name = img_path.split(\"/\")[-1]\n",
    "\n",
    "\taaa = img_name.split(\".\")\n",
    "\tbbb = aaa[0:-1]\n",
    "\timidx = bbb[0]\n",
    "\tfor i in range(1,len(bbb)):\n",
    "\t\timidx = imidx + \".\" + bbb[i]\n",
    "\n",
    "\ttra_lbl_name_list.append(data_dir + tra_label_dir + imidx + label_ext)\n",
    "\n",
    "print(\"---\")\n",
    "print(\"train images: \", len(tra_img_name_list))\n",
    "print(\"train labels: \", len(tra_lbl_name_list))\n",
    "print(\"---\")\n",
    "\n",
    "train_num = len(tra_img_name_list)\n",
    "\n",
    "salobj_dataset = SalObjDataset(\n",
    "    img_name_list=tra_img_name_list,\n",
    "    lbl_name_list=tra_lbl_name_list,\n",
    "    transform=transforms.Compose([\n",
    "        RescaleT(256),\n",
    "        RandomCrop(224),\n",
    "        ToTensorLab(flag=0)]))\n",
    "salobj_dataloader = DataLoader(salobj_dataset, batch_size=batch_size_train, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "1d796ffde8ac43dd93a991be4a710df9",
      "cc56d20ea8d8484892ec15b0c703f43c",
      "fb6bd39c44054d859ba3a199c63d94d5",
      "0695f33655af490e9c7a41df37b36431",
      "c998593c747e4840bd352f2d7ccdf7a3",
      "6b0fb610fdb64262be5900045a8e51c9",
      "e49af9a0bf4343d887c9a1fa7c568b06",
      "e54cc196908a4cb49aa49dc5aac7778f"
     ]
    },
    "execution": {
     "iopub.execute_input": "2021-06-14T23:22:08.380789Z",
     "iopub.status.busy": "2021-06-14T23:22:08.380525Z",
     "iopub.status.idle": "2021-06-14T23:22:15.399362Z",
     "shell.execute_reply": "2021-06-14T23:22:15.398819Z",
     "shell.execute_reply.started": "2021-06-14T23:22:08.380761Z"
    },
    "id": "LNL4AVnSTvYv",
    "outputId": "866a6755-1d4c-4f15-b4e8-2c4b2ed51824"
   },
   "outputs": [],
   "source": [
    "# ------- 3. define model --------\n",
    "# define the net\n",
    "net = BASNet(3, 1)\n",
    "# net.load_state_dict(torch.load(\"ApplyingSODinAutoLabelling/saved_models/basnet_bsi/basnet_bsi_itr_42000_train_1.170107_tar_0.025873.pth\"))\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-06-14T23:22:16.438651Z",
     "iopub.status.busy": "2021-06-14T23:22:16.438372Z",
     "iopub.status.idle": "2021-06-14T23:22:16.444260Z",
     "shell.execute_reply": "2021-06-14T23:22:16.443417Z",
     "shell.execute_reply.started": "2021-06-14T23:22:16.438618Z"
    },
    "id": "yHfoce-xTveR",
    "outputId": "3c3bb38a-fc40-4383-fd95-094ef1593c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---define optimizer...\n"
     ]
    }
   ],
   "source": [
    "# ------- 4. define optimizer --------\n",
    "print(\"---define optimizer...\")\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-06-14T23:25:50.641689Z",
     "iopub.status.busy": "2021-06-14T23:25:50.641457Z",
     "iopub.status.idle": "2021-06-15T02:15:32.124459Z",
     "shell.execute_reply": "2021-06-15T02:15:32.123416Z",
     "shell.execute_reply.started": "2021-06-14T23:25:50.641665Z"
    },
    "id": "CMrCr4J9TvjK",
    "outputId": "91227037-fc14-4c02-8135-0557fb9a7c36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/saturn/lib/python3.7/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/srv/conda/envs/saturn/lib/python3.7/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l0: 0.020569, l1: 0.021451, l2: 0.027077, l3: 0.040666, l4: 0.091220, l5: 0.197166, l6: 0.429669\n",
      "\n",
      "[epoch: 327/400, batch: 8/1000, ite: 43627] train loss: 1.2589, accuracy: 94.4221%, tar: 0.0206 \n",
      "l0: 0.024627, l1: 0.026028, l2: 0.033344, l3: 0.049147, l4: 0.097491, l5: 0.181382, l6: 0.427431\n",
      "\n",
      "[epoch: 327/400, batch: 16/1000, ite: 43628] train loss: 1.2676, accuracy: 94.6877%, tar: 0.0226 \n",
      "l0: 0.021815, l1: 0.023188, l2: 0.030266, l3: 0.042640, l4: 0.072216, l5: 0.149280, l6: 0.316113\n",
      "\n",
      "[epoch: 327/400, batch: 24/1000, ite: 43629] train loss: 1.1692, accuracy: 95.8737%, tar: 0.0223 \n",
      "l0: 0.019923, l1: 0.021978, l2: 0.029356, l3: 0.044496, l4: 0.073477, l5: 0.130958, l6: 0.272593\n",
      "\n",
      "[epoch: 327/400, batch: 32/1000, ite: 43630] train loss: 1.0930, accuracy: 96.2943%, tar: 0.0217 \n",
      "l0: 0.020918, l1: 0.022505, l2: 0.030285, l3: 0.043802, l4: 0.084441, l5: 0.187063, l6: 0.311302\n",
      "\n",
      "[epoch: 327/400, batch: 40/1000, ite: 43631] train loss: 1.0771, accuracy: 96.2786%, tar: 0.0216 \n",
      "l0: 0.023127, l1: 0.024653, l2: 0.031423, l3: 0.046395, l4: 0.072294, l5: 0.125791, l6: 0.249742\n",
      "\n",
      "[epoch: 327/400, batch: 48/1000, ite: 43632] train loss: 1.0339, accuracy: 96.5050%, tar: 0.0218 \n",
      "l0: 0.032986, l1: 0.036586, l2: 0.048250, l3: 0.073024, l4: 0.124534, l5: 0.196167, l6: 0.391158\n",
      "\n",
      "[epoch: 327/400, batch: 56/1000, ite: 43633] train loss: 1.0715, accuracy: 95.3516%, tar: 0.0234 \n",
      "l0: 0.026743, l1: 0.027532, l2: 0.034655, l3: 0.049476, l4: 0.087242, l5: 0.182329, l6: 0.420918\n",
      "\n",
      "[epoch: 327/400, batch: 64/1000, ite: 43634] train loss: 1.0956, accuracy: 93.6628%, tar: 0.0238 \n",
      "l0: 0.023236, l1: 0.024042, l2: 0.031105, l3: 0.046792, l4: 0.078701, l5: 0.149983, l6: 0.345872\n",
      "\n",
      "[epoch: 327/400, batch: 72/1000, ite: 43635] train loss: 1.0904, accuracy: 94.9839%, tar: 0.0238 \n",
      "l0: 0.036961, l1: 0.038989, l2: 0.049321, l3: 0.069837, l4: 0.121837, l5: 0.231743, l6: 0.451691\n",
      "\n",
      "[epoch: 327/400, batch: 80/1000, ite: 43636] train loss: 1.1273, accuracy: 93.8895%, tar: 0.0251 \n",
      "l0: 0.030253, l1: 0.031727, l2: 0.043036, l3: 0.058731, l4: 0.105728, l5: 0.225570, l6: 0.514189\n",
      "\n",
      "[epoch: 327/400, batch: 88/1000, ite: 43637] train loss: 1.1640, accuracy: 92.9653%, tar: 0.0256 \n",
      "l0: 0.024054, l1: 0.024278, l2: 0.029710, l3: 0.038991, l4: 0.062660, l5: 0.109618, l6: 0.250335\n",
      "\n",
      "[epoch: 327/400, batch: 96/1000, ite: 43638] train loss: 1.1335, accuracy: 95.9004%, tar: 0.0254 \n",
      "l0: 0.026827, l1: 0.027773, l2: 0.034372, l3: 0.050793, l4: 0.085696, l5: 0.164265, l6: 0.353812\n",
      "\n",
      "[epoch: 327/400, batch: 104/1000, ite: 43639] train loss: 1.1312, accuracy: 95.1876%, tar: 0.0255 \n",
      "l0: 0.027061, l1: 0.028147, l2: 0.035771, l3: 0.050924, l4: 0.087470, l5: 0.182917, l6: 0.333245\n",
      "\n",
      "[epoch: 327/400, batch: 112/1000, ite: 43640] train loss: 1.1279, accuracy: 94.7607%, tar: 0.0257 \n",
      "l0: 0.028012, l1: 0.029322, l2: 0.037550, l3: 0.059760, l4: 0.097390, l5: 0.217369, l6: 0.395917\n",
      "\n",
      "[epoch: 327/400, batch: 120/1000, ite: 43641] train loss: 1.1371, accuracy: 94.6434%, tar: 0.0258 \n",
      "l0: 0.030900, l1: 0.031677, l2: 0.039268, l3: 0.056055, l4: 0.106874, l5: 0.188778, l6: 0.315772\n",
      "\n",
      "[epoch: 327/400, batch: 128/1000, ite: 43642] train loss: 1.1341, accuracy: 95.1233%, tar: 0.0261 \n",
      "l0: 0.024259, l1: 0.025557, l2: 0.035899, l3: 0.054484, l4: 0.097791, l5: 0.173694, l6: 0.395735\n",
      "\n",
      "[epoch: 327/400, batch: 136/1000, ite: 43643] train loss: 1.1384, accuracy: 95.1672%, tar: 0.0260 \n",
      "l0: 0.029081, l1: 0.030093, l2: 0.039131, l3: 0.055935, l4: 0.103556, l5: 0.201272, l6: 0.408469\n",
      "\n",
      "[epoch: 327/400, batch: 144/1000, ite: 43644] train loss: 1.1464, accuracy: 94.7325%, tar: 0.0262 \n",
      "l0: 0.031827, l1: 0.032981, l2: 0.040613, l3: 0.052983, l4: 0.089043, l5: 0.180979, l6: 0.384987\n",
      "\n",
      "[epoch: 327/400, batch: 152/1000, ite: 43645] train loss: 1.1490, accuracy: 94.8094%, tar: 0.0265 \n",
      "l0: 0.023403, l1: 0.025517, l2: 0.034310, l3: 0.052842, l4: 0.095973, l5: 0.200782, l6: 0.405099\n",
      "\n",
      "[epoch: 327/400, batch: 160/1000, ite: 43646] train loss: 1.1539, accuracy: 95.1826%, tar: 0.0263 \n",
      "l0: 0.019277, l1: 0.020002, l2: 0.026930, l3: 0.046940, l4: 0.093475, l5: 0.175938, l6: 0.312274\n",
      "\n",
      "[epoch: 327/400, batch: 168/1000, ite: 43647] train loss: 1.1471, accuracy: 95.4680%, tar: 0.0260 \n",
      "l0: 0.036064, l1: 0.037633, l2: 0.046210, l3: 0.072614, l4: 0.133096, l5: 0.281194, l6: 0.546778\n",
      "\n",
      "[epoch: 327/400, batch: 176/1000, ite: 43648] train loss: 1.1728, accuracy: 92.4410%, tar: 0.0265 \n",
      "l0: 0.026333, l1: 0.027525, l2: 0.036615, l3: 0.054168, l4: 0.101924, l5: 0.215203, l6: 0.458618\n",
      "\n",
      "[epoch: 327/400, batch: 184/1000, ite: 43649] train loss: 1.1820, accuracy: 94.1959%, tar: 0.0264 \n",
      "l0: 0.024553, l1: 0.025210, l2: 0.033034, l3: 0.046124, l4: 0.080393, l5: 0.157926, l6: 0.367982\n",
      "\n",
      "[epoch: 327/400, batch: 192/1000, ite: 43650] train loss: 1.1790, accuracy: 94.8650%, tar: 0.0264 \n",
      "l0: 0.030079, l1: 0.031277, l2: 0.042027, l3: 0.063472, l4: 0.109532, l5: 0.213003, l6: 0.409980\n",
      "\n",
      "[epoch: 327/400, batch: 200/1000, ite: 43651] train loss: 1.1843, accuracy: 94.4102%, tar: 0.0265 \n",
      "l0: 0.018919, l1: 0.020371, l2: 0.028368, l3: 0.042206, l4: 0.075267, l5: 0.153075, l6: 0.293556\n",
      "\n",
      "[epoch: 327/400, batch: 208/1000, ite: 43652] train loss: 1.1746, accuracy: 96.5360%, tar: 0.0262 \n",
      "l0: 0.024212, l1: 0.024745, l2: 0.029333, l3: 0.043608, l4: 0.076887, l5: 0.131117, l6: 0.272360\n",
      "\n",
      "[epoch: 327/400, batch: 216/1000, ite: 43653] train loss: 1.1635, accuracy: 95.4290%, tar: 0.0261 \n",
      "l0: 0.022809, l1: 0.024003, l2: 0.030242, l3: 0.043301, l4: 0.078587, l5: 0.141539, l6: 0.313760\n",
      "\n",
      "[epoch: 327/400, batch: 224/1000, ite: 43654] train loss: 1.1566, accuracy: 95.5585%, tar: 0.0260 \n",
      "l0: 0.025504, l1: 0.026948, l2: 0.034394, l3: 0.054728, l4: 0.102852, l5: 0.197563, l6: 0.397427\n",
      "\n",
      "[epoch: 327/400, batch: 232/1000, ite: 43655] train loss: 1.1594, accuracy: 94.7655%, tar: 0.0260 \n",
      "l0: 0.025737, l1: 0.026497, l2: 0.035211, l3: 0.049609, l4: 0.086257, l5: 0.180335, l6: 0.345169\n",
      "\n",
      "[epoch: 327/400, batch: 240/1000, ite: 43656] train loss: 1.1574, accuracy: 95.3965%, tar: 0.0260 \n",
      "l0: 0.025820, l1: 0.027134, l2: 0.035813, l3: 0.054779, l4: 0.097722, l5: 0.208743, l6: 0.416229\n",
      "\n",
      "[epoch: 327/400, batch: 248/1000, ite: 43657] train loss: 1.1616, accuracy: 94.5069%, tar: 0.0260 \n",
      "l0: 0.029541, l1: 0.031207, l2: 0.043982, l3: 0.065977, l4: 0.126165, l5: 0.246226, l6: 0.447105\n",
      "\n",
      "[epoch: 327/400, batch: 256/1000, ite: 43658] train loss: 1.1702, accuracy: 93.5426%, tar: 0.0261 \n",
      "l0: 0.028142, l1: 0.029513, l2: 0.038435, l3: 0.054374, l4: 0.094702, l5: 0.185677, l6: 0.441562\n",
      "\n",
      "[epoch: 327/400, batch: 264/1000, ite: 43659] train loss: 1.1747, accuracy: 94.1057%, tar: 0.0262 \n",
      "l0: 0.023803, l1: 0.025689, l2: 0.035356, l3: 0.055071, l4: 0.104854, l5: 0.188554, l6: 0.359158\n",
      "\n",
      "[epoch: 327/400, batch: 272/1000, ite: 43660] train loss: 1.1741, accuracy: 95.4065%, tar: 0.0261 \n",
      "l0: 0.025803, l1: 0.027206, l2: 0.033515, l3: 0.048846, l4: 0.092330, l5: 0.212345, l6: 0.434998\n",
      "\n",
      "[epoch: 327/400, batch: 280/1000, ite: 43661] train loss: 1.1780, accuracy: 93.7424%, tar: 0.0261 \n",
      "l0: 0.024894, l1: 0.026697, l2: 0.034387, l3: 0.048099, l4: 0.084278, l5: 0.160260, l6: 0.335058\n",
      "\n",
      "[epoch: 327/400, batch: 288/1000, ite: 43662] train loss: 1.1743, accuracy: 95.2811%, tar: 0.0261 \n",
      "l0: 0.019752, l1: 0.021182, l2: 0.028365, l3: 0.046116, l4: 0.094596, l5: 0.171891, l6: 0.365565\n",
      "\n",
      "[epoch: 327/400, batch: 296/1000, ite: 43663] train loss: 1.1727, accuracy: 95.2005%, tar: 0.0259 \n",
      "l0: 0.027419, l1: 0.029289, l2: 0.037947, l3: 0.055342, l4: 0.101281, l5: 0.268917, l6: 0.526564\n",
      "\n",
      "[epoch: 327/400, batch: 304/1000, ite: 43664] train loss: 1.1833, accuracy: 93.4277%, tar: 0.0259 \n",
      "l0: 0.027242, l1: 0.028131, l2: 0.036158, l3: 0.050699, l4: 0.079571, l5: 0.185223, l6: 0.335264\n",
      "\n",
      "[epoch: 327/400, batch: 312/1000, ite: 43665] train loss: 1.1808, accuracy: 94.9782%, tar: 0.0260 \n",
      "l0: 0.023255, l1: 0.023974, l2: 0.033205, l3: 0.045257, l4: 0.084993, l5: 0.162019, l6: 0.348544\n",
      "\n",
      "[epoch: 327/400, batch: 320/1000, ite: 43666] train loss: 1.1781, accuracy: 96.2146%, tar: 0.0259 \n",
      "l0: 0.026914, l1: 0.027891, l2: 0.034458, l3: 0.052313, l4: 0.100644, l5: 0.194514, l6: 0.465208\n",
      "\n",
      "[epoch: 327/400, batch: 328/1000, ite: 43667] train loss: 1.1826, accuracy: 93.7414%, tar: 0.0259 \n",
      "l0: 0.028445, l1: 0.030501, l2: 0.038407, l3: 0.056281, l4: 0.097855, l5: 0.175593, l6: 0.400042\n",
      "\n",
      "[epoch: 327/400, batch: 336/1000, ite: 43668] train loss: 1.1837, accuracy: 95.0849%, tar: 0.0260 \n",
      "l0: 0.022886, l1: 0.024221, l2: 0.030493, l3: 0.043512, l4: 0.080186, l5: 0.165716, l6: 0.325144\n",
      "\n",
      "[epoch: 327/400, batch: 344/1000, ite: 43669] train loss: 1.1800, accuracy: 94.9416%, tar: 0.0259 \n",
      "l0: 0.031888, l1: 0.032800, l2: 0.040381, l3: 0.056745, l4: 0.103054, l5: 0.197750, l6: 0.368349\n",
      "\n",
      "[epoch: 327/400, batch: 352/1000, ite: 43670] train loss: 1.1805, accuracy: 94.3959%, tar: 0.0260 \n",
      "l0: 0.018007, l1: 0.019076, l2: 0.023971, l3: 0.036327, l4: 0.064023, l5: 0.126431, l6: 0.260836\n",
      "\n",
      "[epoch: 327/400, batch: 360/1000, ite: 43671] train loss: 1.1723, accuracy: 96.2820%, tar: 0.0259 \n",
      "l0: 0.022480, l1: 0.023634, l2: 0.030427, l3: 0.045239, l4: 0.081691, l5: 0.171768, l6: 0.319091\n",
      "\n",
      "[epoch: 327/400, batch: 368/1000, ite: 43672] train loss: 1.1690, accuracy: 95.7486%, tar: 0.0258 \n",
      "l0: 0.025622, l1: 0.026373, l2: 0.032681, l3: 0.048554, l4: 0.090426, l5: 0.173177, l6: 0.335229\n",
      "\n",
      "[epoch: 327/400, batch: 376/1000, ite: 43673] train loss: 1.1669, accuracy: 95.0013%, tar: 0.0258 \n",
      "l0: 0.018692, l1: 0.019438, l2: 0.025181, l3: 0.035844, l4: 0.058709, l5: 0.110703, l6: 0.241206\n",
      "\n",
      "[epoch: 327/400, batch: 384/1000, ite: 43674] train loss: 1.1584, accuracy: 96.5343%, tar: 0.0256 \n",
      "l0: 0.025740, l1: 0.026696, l2: 0.033694, l3: 0.051254, l4: 0.094520, l5: 0.177301, l6: 0.337236\n",
      "\n",
      "[epoch: 327/400, batch: 392/1000, ite: 43675] train loss: 1.1570, accuracy: 95.3521%, tar: 0.0256 \n",
      "l0: 0.036291, l1: 0.037901, l2: 0.048142, l3: 0.066117, l4: 0.123328, l5: 0.271926, l6: 0.545748\n",
      "\n",
      "[epoch: 327/400, batch: 400/1000, ite: 43676] train loss: 1.1675, accuracy: 93.2688%, tar: 0.0259 \n",
      "l0: 0.035817, l1: 0.036980, l2: 0.048020, l3: 0.068705, l4: 0.108861, l5: 0.231921, l6: 0.482013\n",
      "\n",
      "[epoch: 327/400, batch: 408/1000, ite: 43677] train loss: 1.1741, accuracy: 92.9522%, tar: 0.0260 \n",
      "l0: 0.021854, l1: 0.022782, l2: 0.030560, l3: 0.046141, l4: 0.082914, l5: 0.172917, l6: 0.399717\n",
      "\n",
      "[epoch: 327/400, batch: 416/1000, ite: 43678] train loss: 1.1742, accuracy: 95.1846%, tar: 0.0260 \n",
      "l0: 0.028901, l1: 0.029879, l2: 0.036274, l3: 0.049040, l4: 0.091049, l5: 0.190431, l6: 0.384432\n",
      "\n",
      "[epoch: 327/400, batch: 424/1000, ite: 43679] train loss: 1.1748, accuracy: 94.1342%, tar: 0.0260 \n",
      "l0: 0.036104, l1: 0.037369, l2: 0.046948, l3: 0.065291, l4: 0.103447, l5: 0.195226, l6: 0.408787\n",
      "\n",
      "[epoch: 327/400, batch: 432/1000, ite: 43680] train loss: 1.1772, accuracy: 94.0608%, tar: 0.0262 \n",
      "l0: 0.029557, l1: 0.031577, l2: 0.039313, l3: 0.057923, l4: 0.100712, l5: 0.178533, l6: 0.340486\n",
      "\n",
      "[epoch: 327/400, batch: 440/1000, ite: 43681] train loss: 1.1762, accuracy: 95.0129%, tar: 0.0263 \n",
      "l0: 0.019468, l1: 0.020502, l2: 0.027169, l3: 0.039392, l4: 0.065622, l5: 0.122790, l6: 0.275755\n",
      "\n",
      "[epoch: 327/400, batch: 448/1000, ite: 43682] train loss: 1.1704, accuracy: 96.3786%, tar: 0.0262 \n",
      "l0: 0.021039, l1: 0.022206, l2: 0.030849, l3: 0.046003, l4: 0.079147, l5: 0.153253, l6: 0.311509\n",
      "\n",
      "[epoch: 327/400, batch: 456/1000, ite: 43683] train loss: 1.1670, accuracy: 96.0890%, tar: 0.0261 \n",
      "l0: 0.021015, l1: 0.021652, l2: 0.027332, l3: 0.038336, l4: 0.069063, l5: 0.118778, l6: 0.269037\n",
      "\n",
      "[epoch: 327/400, batch: 464/1000, ite: 43684] train loss: 1.1614, accuracy: 95.7313%, tar: 0.0260 \n",
      "l0: 0.027510, l1: 0.028656, l2: 0.035510, l3: 0.053692, l4: 0.092245, l5: 0.169862, l6: 0.296600\n",
      "\n",
      "[epoch: 327/400, batch: 472/1000, ite: 43685] train loss: 1.1588, accuracy: 95.1586%, tar: 0.0260 \n",
      "l0: 0.025063, l1: 0.026492, l2: 0.033470, l3: 0.044660, l4: 0.093221, l5: 0.185099, l6: 0.402820\n",
      "\n",
      "[epoch: 327/400, batch: 480/1000, ite: 43686] train loss: 1.1599, accuracy: 94.5051%, tar: 0.0260 \n",
      "l0: 0.033322, l1: 0.035075, l2: 0.044473, l3: 0.065783, l4: 0.121309, l5: 0.234693, l6: 0.463318\n",
      "\n",
      "[epoch: 327/400, batch: 488/1000, ite: 43687] train loss: 1.1650, accuracy: 93.7046%, tar: 0.0261 \n",
      "l0: 0.023737, l1: 0.024646, l2: 0.031783, l3: 0.048705, l4: 0.089342, l5: 0.169288, l6: 0.371823\n",
      "\n",
      "[epoch: 327/400, batch: 496/1000, ite: 43688] train loss: 1.1645, accuracy: 95.1197%, tar: 0.0261 \n",
      "l0: 0.021150, l1: 0.022563, l2: 0.029720, l3: 0.044121, l4: 0.085213, l5: 0.158802, l6: 0.407641\n",
      "\n",
      "[epoch: 327/400, batch: 504/1000, ite: 43689] train loss: 1.1648, accuracy: 94.6592%, tar: 0.0260 \n",
      "l0: 0.019045, l1: 0.019832, l2: 0.026239, l3: 0.040209, l4: 0.066369, l5: 0.130466, l6: 0.262533\n",
      "\n",
      "[epoch: 327/400, batch: 512/1000, ite: 43690] train loss: 1.1597, accuracy: 95.8765%, tar: 0.0259 \n",
      "l0: 0.025876, l1: 0.027209, l2: 0.033409, l3: 0.052671, l4: 0.098711, l5: 0.167850, l6: 0.343130\n",
      "\n",
      "[epoch: 327/400, batch: 520/1000, ite: 43691] train loss: 1.1587, accuracy: 95.3078%, tar: 0.0259 \n",
      "l0: 0.020307, l1: 0.021928, l2: 0.029794, l3: 0.044064, l4: 0.079512, l5: 0.154080, l6: 0.308714\n",
      "\n",
      "[epoch: 327/400, batch: 528/1000, ite: 43692] train loss: 1.1558, accuracy: 95.5391%, tar: 0.0258 \n",
      "l0: 0.030350, l1: 0.031473, l2: 0.039980, l3: 0.056478, l4: 0.104228, l5: 0.224751, l6: 0.544044\n",
      "\n",
      "[epoch: 327/400, batch: 536/1000, ite: 43693] train loss: 1.1621, accuracy: 92.2964%, tar: 0.0259 \n",
      "l0: 0.025429, l1: 0.026731, l2: 0.036352, l3: 0.051098, l4: 0.085738, l5: 0.205130, l6: 0.455479\n",
      "\n",
      "[epoch: 327/400, batch: 544/1000, ite: 43694] train loss: 1.1647, accuracy: 94.6610%, tar: 0.0259 \n",
      "l0: 0.022366, l1: 0.023312, l2: 0.030292, l3: 0.043379, l4: 0.074778, l5: 0.152337, l6: 0.277635\n",
      "\n",
      "[epoch: 327/400, batch: 552/1000, ite: 43695] train loss: 1.1610, accuracy: 95.8770%, tar: 0.0258 \n",
      "l0: 0.022854, l1: 0.023947, l2: 0.032644, l3: 0.045019, l4: 0.073450, l5: 0.136833, l6: 0.304222\n",
      "\n",
      "[epoch: 327/400, batch: 560/1000, ite: 43696] train loss: 1.1579, accuracy: 95.5171%, tar: 0.0258 \n",
      "l0: 0.028220, l1: 0.029561, l2: 0.035343, l3: 0.050416, l4: 0.089110, l5: 0.161995, l6: 0.386719\n",
      "\n",
      "[epoch: 327/400, batch: 568/1000, ite: 43697] train loss: 1.1580, accuracy: 94.5578%, tar: 0.0258 \n",
      "l0: 0.030230, l1: 0.031487, l2: 0.039185, l3: 0.057851, l4: 0.101927, l5: 0.207377, l6: 0.442827\n",
      "\n",
      "[epoch: 327/400, batch: 576/1000, ite: 43698] train loss: 1.1608, accuracy: 93.2884%, tar: 0.0259 \n",
      "l0: 0.037594, l1: 0.038669, l2: 0.047602, l3: 0.063787, l4: 0.107252, l5: 0.207156, l6: 0.437902\n",
      "\n",
      "[epoch: 327/400, batch: 584/1000, ite: 43699] train loss: 1.1638, accuracy: 93.3672%, tar: 0.0260 \n",
      "l0: 0.025754, l1: 0.027654, l2: 0.037875, l3: 0.063212, l4: 0.137073, l5: 0.303219, l6: 0.512180\n",
      "\n",
      "[epoch: 327/400, batch: 592/1000, ite: 43700] train loss: 1.1700, accuracy: 93.5257%, tar: 0.0260 \n",
      "l0: 0.022884, l1: 0.024015, l2: 0.032634, l3: 0.050150, l4: 0.087132, l5: 0.167397, l6: 0.321851\n",
      "\n",
      "[epoch: 327/400, batch: 600/1000, ite: 43701] train loss: 1.1682, accuracy: 95.1116%, tar: 0.0260 \n",
      "l0: 0.024872, l1: 0.025830, l2: 0.032854, l3: 0.050352, l4: 0.088507, l5: 0.196397, l6: 0.445636\n",
      "\n",
      "[epoch: 327/400, batch: 608/1000, ite: 43702] train loss: 1.1702, accuracy: 94.1537%, tar: 0.0260 \n",
      "l0: 0.020662, l1: 0.021620, l2: 0.027408, l3: 0.040473, l4: 0.073094, l5: 0.164794, l6: 0.375940\n",
      "\n",
      "[epoch: 327/400, batch: 616/1000, ite: 43703] train loss: 1.1694, accuracy: 94.8447%, tar: 0.0259 \n",
      "l0: 0.023947, l1: 0.025648, l2: 0.035300, l3: 0.054155, l4: 0.094332, l5: 0.166296, l6: 0.375122\n",
      "\n",
      "[epoch: 327/400, batch: 624/1000, ite: 43704] train loss: 1.1691, accuracy: 95.3187%, tar: 0.0259 \n",
      "l0: 0.020180, l1: 0.021323, l2: 0.027693, l3: 0.038231, l4: 0.066388, l5: 0.125211, l6: 0.319983\n",
      "\n",
      "[epoch: 327/400, batch: 632/1000, ite: 43705] train loss: 1.1662, accuracy: 95.8939%, tar: 0.0258 \n",
      "l0: 0.019900, l1: 0.020821, l2: 0.027670, l3: 0.045212, l4: 0.087176, l5: 0.179992, l6: 0.317575\n",
      "\n",
      "[epoch: 327/400, batch: 640/1000, ite: 43706] train loss: 1.1643, accuracy: 95.5048%, tar: 0.0257 \n",
      "l0: 0.026518, l1: 0.028000, l2: 0.037487, l3: 0.057288, l4: 0.104004, l5: 0.184525, l6: 0.371938\n",
      "\n",
      "[epoch: 327/400, batch: 648/1000, ite: 43707] train loss: 1.1645, accuracy: 94.7071%, tar: 0.0257 \n",
      "l0: 0.025689, l1: 0.026512, l2: 0.033158, l3: 0.047342, l4: 0.080634, l5: 0.154479, l6: 0.318339\n",
      "\n",
      "[epoch: 327/400, batch: 656/1000, ite: 43708] train loss: 1.1626, accuracy: 95.4815%, tar: 0.0257 \n",
      "l0: 0.024001, l1: 0.025577, l2: 0.031772, l3: 0.047431, l4: 0.098486, l5: 0.173908, l6: 0.340105\n",
      "\n",
      "[epoch: 327/400, batch: 664/1000, ite: 43709] train loss: 1.1617, accuracy: 95.5088%, tar: 0.0257 \n",
      "l0: 0.025526, l1: 0.027144, l2: 0.036052, l3: 0.053751, l4: 0.094009, l5: 0.188484, l6: 0.379975\n",
      "\n",
      "[epoch: 327/400, batch: 672/1000, ite: 43710] train loss: 1.1620, accuracy: 94.2353%, tar: 0.0257 \n",
      "l0: 0.025524, l1: 0.026770, l2: 0.034775, l3: 0.054825, l4: 0.107176, l5: 0.223955, l6: 0.434887\n",
      "\n",
      "[epoch: 327/400, batch: 680/1000, ite: 43711] train loss: 1.1641, accuracy: 94.3711%, tar: 0.0257 \n",
      "l0: 0.026958, l1: 0.027967, l2: 0.035447, l3: 0.048320, l4: 0.086593, l5: 0.229207, l6: 0.480931\n",
      "\n",
      "[epoch: 327/400, batch: 688/1000, ite: 43712] train loss: 1.1671, accuracy: 93.0280%, tar: 0.0257 \n",
      "l0: 0.031638, l1: 0.032890, l2: 0.042110, l3: 0.065767, l4: 0.131928, l5: 0.270847, l6: 0.539474\n",
      "\n",
      "[epoch: 327/400, batch: 696/1000, ite: 43713] train loss: 1.1727, accuracy: 93.3204%, tar: 0.0258 \n",
      "l0: 0.020939, l1: 0.021755, l2: 0.027713, l3: 0.038421, l4: 0.066979, l5: 0.120488, l6: 0.241189\n",
      "\n",
      "[epoch: 327/400, batch: 704/1000, ite: 43714] train loss: 1.1684, accuracy: 96.3230%, tar: 0.0257 \n",
      "l0: 0.028759, l1: 0.030367, l2: 0.038999, l3: 0.058347, l4: 0.111060, l5: 0.191567, l6: 0.376499\n",
      "\n",
      "[epoch: 327/400, batch: 712/1000, ite: 43715] train loss: 1.1690, accuracy: 94.6126%, tar: 0.0258 \n",
      "l0: 0.019524, l1: 0.020922, l2: 0.028186, l3: 0.043551, l4: 0.083618, l5: 0.137919, l6: 0.291449\n",
      "\n",
      "[epoch: 327/400, batch: 720/1000, ite: 43716] train loss: 1.1663, accuracy: 96.0731%, tar: 0.0257 \n",
      "l0: 0.028227, l1: 0.029366, l2: 0.037000, l3: 0.051214, l4: 0.087028, l5: 0.207183, l6: 0.421420\n",
      "\n",
      "[epoch: 327/400, batch: 728/1000, ite: 43717] train loss: 1.1676, accuracy: 94.3612%, tar: 0.0257 \n",
      "l0: 0.034098, l1: 0.035493, l2: 0.044338, l3: 0.061440, l4: 0.097738, l5: 0.179901, l6: 0.391410\n",
      "\n",
      "[epoch: 327/400, batch: 736/1000, ite: 43718] train loss: 1.1683, accuracy: 93.7999%, tar: 0.0258 \n",
      "l0: 0.020059, l1: 0.022139, l2: 0.028733, l3: 0.042323, l4: 0.088884, l5: 0.172404, l6: 0.412241\n",
      "\n",
      "[epoch: 327/400, batch: 744/1000, ite: 43719] train loss: 1.1686, accuracy: 95.4272%, tar: 0.0258 \n",
      "l0: 0.027962, l1: 0.029094, l2: 0.036701, l3: 0.053249, l4: 0.092903, l5: 0.206911, l6: 0.427903\n",
      "\n",
      "[epoch: 327/400, batch: 752/1000, ite: 43720] train loss: 1.1701, accuracy: 94.1227%, tar: 0.0258 \n",
      "l0: 0.028731, l1: 0.030982, l2: 0.041561, l3: 0.064712, l4: 0.137300, l5: 0.299299, l6: 0.519442\n",
      "\n",
      "[epoch: 327/400, batch: 760/1000, ite: 43721] train loss: 1.1751, accuracy: 93.2775%, tar: 0.0258 \n",
      "l0: 0.024726, l1: 0.025377, l2: 0.033865, l3: 0.051444, l4: 0.138609, l5: 0.266167, l6: 0.436437\n",
      "\n",
      "[epoch: 327/400, batch: 768/1000, ite: 43722] train loss: 1.1776, accuracy: 94.1501%, tar: 0.0258 \n",
      "l0: 0.022314, l1: 0.022783, l2: 0.028940, l3: 0.039747, l4: 0.068310, l5: 0.120412, l6: 0.256204\n",
      "\n",
      "[epoch: 327/400, batch: 776/1000, ite: 43723] train loss: 1.1739, accuracy: 95.7421%, tar: 0.0258 \n",
      "l0: 0.035741, l1: 0.036888, l2: 0.048155, l3: 0.069539, l4: 0.113286, l5: 0.216329, l6: 0.371576\n",
      "\n",
      "[epoch: 327/400, batch: 784/1000, ite: 43724] train loss: 1.1749, accuracy: 94.6182%, tar: 0.0259 \n",
      "l0: 0.029294, l1: 0.030552, l2: 0.039741, l3: 0.055532, l4: 0.095986, l5: 0.190266, l6: 0.399588\n",
      "\n",
      "[epoch: 327/400, batch: 792/1000, ite: 43725] train loss: 1.1756, accuracy: 94.5261%, tar: 0.0259 \n",
      "l0: 0.027462, l1: 0.028505, l2: 0.034576, l3: 0.047520, l4: 0.078792, l5: 0.132109, l6: 0.247174\n",
      "\n",
      "[epoch: 327/400, batch: 800/1000, ite: 43726] train loss: 1.1723, accuracy: 95.1739%, tar: 0.0259 \n",
      "l0: 0.024824, l1: 0.025798, l2: 0.031808, l3: 0.044588, l4: 0.071698, l5: 0.146989, l6: 0.339444\n",
      "\n",
      "[epoch: 327/400, batch: 808/1000, ite: 43727] train loss: 1.1709, accuracy: 95.5030%, tar: 0.0259 \n",
      "l0: 0.023520, l1: 0.024538, l2: 0.031487, l3: 0.048712, l4: 0.092516, l5: 0.172387, l6: 0.350276\n",
      "\n",
      "[epoch: 327/400, batch: 816/1000, ite: 43728] train loss: 1.1701, accuracy: 95.5776%, tar: 0.0259 \n",
      "l0: 0.035169, l1: 0.036363, l2: 0.045156, l3: 0.064852, l4: 0.106908, l5: 0.200256, l6: 0.426977\n",
      "\n",
      "[epoch: 327/400, batch: 824/1000, ite: 43729] train loss: 1.1719, accuracy: 93.7376%, tar: 0.0260 \n",
      "l0: 0.029254, l1: 0.030863, l2: 0.041322, l3: 0.065258, l4: 0.140738, l5: 0.281772, l6: 0.456965\n",
      "\n",
      "[epoch: 327/400, batch: 832/1000, ite: 43730] train loss: 1.1751, accuracy: 93.4734%, tar: 0.0260 \n",
      "l0: 0.022676, l1: 0.023930, l2: 0.031979, l3: 0.050032, l4: 0.096315, l5: 0.184503, l6: 0.365331\n",
      "\n",
      "[epoch: 327/400, batch: 840/1000, ite: 43731] train loss: 1.1748, accuracy: 94.6332%, tar: 0.0260 \n",
      "l0: 0.027560, l1: 0.028168, l2: 0.036482, l3: 0.051949, l4: 0.097850, l5: 0.196238, l6: 0.389999\n",
      "\n",
      "[epoch: 327/400, batch: 848/1000, ite: 43732] train loss: 1.1752, accuracy: 95.0520%, tar: 0.0260 \n",
      "l0: 0.026360, l1: 0.027180, l2: 0.035001, l3: 0.051954, l4: 0.115585, l5: 0.210699, l6: 0.365643\n",
      "\n",
      "[epoch: 327/400, batch: 856/1000, ite: 43733] train loss: 1.1755, accuracy: 94.1855%, tar: 0.0260 \n",
      "l0: 0.027889, l1: 0.029043, l2: 0.036982, l3: 0.052710, l4: 0.093744, l5: 0.216867, l6: 0.405920\n",
      "\n",
      "[epoch: 327/400, batch: 864/1000, ite: 43734] train loss: 1.1764, accuracy: 93.8256%, tar: 0.0260 \n",
      "l0: 0.024139, l1: 0.025223, l2: 0.033909, l3: 0.055215, l4: 0.118149, l5: 0.258828, l6: 0.465886\n",
      "\n",
      "[epoch: 327/400, batch: 872/1000, ite: 43735] train loss: 1.1789, accuracy: 94.4200%, tar: 0.0260 \n",
      "l0: 0.026182, l1: 0.027300, l2: 0.036616, l3: 0.056490, l4: 0.115122, l5: 0.243330, l6: 0.498732\n",
      "\n",
      "[epoch: 327/400, batch: 880/1000, ite: 43736] train loss: 1.1818, accuracy: 93.7585%, tar: 0.0260 \n",
      "l0: 0.023471, l1: 0.024363, l2: 0.030976, l3: 0.045714, l4: 0.078018, l5: 0.158309, l6: 0.305745\n",
      "\n",
      "[epoch: 327/400, batch: 888/1000, ite: 43737] train loss: 1.1800, accuracy: 95.3583%, tar: 0.0260 \n",
      "l0: 0.028874, l1: 0.030575, l2: 0.038571, l3: 0.059249, l4: 0.111760, l5: 0.214207, l6: 0.409155\n",
      "\n",
      "[epoch: 327/400, batch: 896/1000, ite: 43738] train loss: 1.1811, accuracy: 93.8404%, tar: 0.0260 \n",
      "l0: 0.035403, l1: 0.037028, l2: 0.045792, l3: 0.064769, l4: 0.115698, l5: 0.230576, l6: 0.504799\n",
      "\n",
      "[epoch: 327/400, batch: 904/1000, ite: 43739] train loss: 1.1843, accuracy: 93.5608%, tar: 0.0261 \n",
      "l0: 0.025573, l1: 0.026358, l2: 0.032119, l3: 0.045506, l4: 0.078744, l5: 0.151613, l6: 0.302403\n",
      "\n",
      "[epoch: 327/400, batch: 912/1000, ite: 43740] train loss: 1.1825, accuracy: 95.0490%, tar: 0.0261 \n",
      "l0: 0.026293, l1: 0.028150, l2: 0.038100, l3: 0.059385, l4: 0.118240, l5: 0.211813, l6: 0.382973\n",
      "\n",
      "[epoch: 327/400, batch: 920/1000, ite: 43741] train loss: 1.1831, accuracy: 94.7992%, tar: 0.0261 \n",
      "l0: 0.030481, l1: 0.031498, l2: 0.042104, l3: 0.056135, l4: 0.089738, l5: 0.179247, l6: 0.346200\n",
      "\n",
      "[epoch: 327/400, batch: 928/1000, ite: 43742] train loss: 1.1826, accuracy: 94.8957%, tar: 0.0261 \n",
      "l0: 0.025090, l1: 0.026084, l2: 0.032743, l3: 0.045511, l4: 0.082423, l5: 0.171922, l6: 0.322380\n",
      "\n",
      "[epoch: 327/400, batch: 936/1000, ite: 43743] train loss: 1.1813, accuracy: 94.8583%, tar: 0.0261 \n",
      "l0: 0.021478, l1: 0.021949, l2: 0.028568, l3: 0.040415, l4: 0.075301, l5: 0.135220, l6: 0.277929\n",
      "\n",
      "[epoch: 327/400, batch: 944/1000, ite: 43744] train loss: 1.1788, accuracy: 96.0128%, tar: 0.0261 \n",
      "l0: 0.020712, l1: 0.021718, l2: 0.028780, l3: 0.042435, l4: 0.075143, l5: 0.137820, l6: 0.266191\n",
      "\n",
      "[epoch: 327/400, batch: 952/1000, ite: 43745] train loss: 1.1762, accuracy: 95.2124%, tar: 0.0260 \n",
      "l0: 0.023870, l1: 0.025663, l2: 0.032956, l3: 0.044723, l4: 0.081191, l5: 0.175782, l6: 0.407572\n",
      "\n",
      "[epoch: 327/400, batch: 960/1000, ite: 43746] train loss: 1.1764, accuracy: 95.1959%, tar: 0.0260 \n",
      "l0: 0.023913, l1: 0.024833, l2: 0.030900, l3: 0.044118, l4: 0.076799, l5: 0.155709, l6: 0.334935\n",
      "\n",
      "[epoch: 327/400, batch: 968/1000, ite: 43747] train loss: 1.1752, accuracy: 94.6539%, tar: 0.0260 \n",
      "l0: 0.022464, l1: 0.023662, l2: 0.030922, l3: 0.042751, l4: 0.074275, l5: 0.138922, l6: 0.263715\n",
      "\n",
      "[epoch: 327/400, batch: 976/1000, ite: 43748] train loss: 1.1726, accuracy: 95.6966%, tar: 0.0260 \n",
      "l0: 0.024794, l1: 0.026151, l2: 0.035749, l3: 0.053660, l4: 0.101124, l5: 0.206656, l6: 0.482920\n",
      "\n",
      "[epoch: 327/400, batch: 984/1000, ite: 43749] train loss: 1.1745, accuracy: 94.2479%, tar: 0.0259 \n",
      "l0: 0.019625, l1: 0.020429, l2: 0.026620, l3: 0.037604, l4: 0.063005, l5: 0.116996, l6: 0.303122\n",
      "\n",
      "[epoch: 327/400, batch: 992/1000, ite: 43750] train loss: 1.1723, accuracy: 95.5450%, tar: 0.0259 \n",
      "l0: 0.026321, l1: 0.027746, l2: 0.035540, l3: 0.054043, l4: 0.095702, l5: 0.196897, l6: 0.416240\n",
      "\n",
      "[epoch: 327/400, batch: 1000/1000, ite: 43751] train loss: 1.1731, accuracy: 94.2082%, tar: 0.0259 \n",
      "l0: 0.022893, l1: 0.024251, l2: 0.030014, l3: 0.044693, l4: 0.080943, l5: 0.190787, l6: 0.396272\n",
      "\n",
      "[epoch: 328/400, batch: 8/1000, ite: 43752] train loss: 1.1732, accuracy: 94.5989%, tar: 0.0259 \n",
      "l0: 0.026034, l1: 0.027730, l2: 0.036157, l3: 0.052791, l4: 0.102226, l5: 0.211755, l6: 0.399838\n",
      "\n",
      "[epoch: 328/400, batch: 16/1000, ite: 43753] train loss: 1.1739, accuracy: 94.4477%, tar: 0.0259 \n",
      "l0: 0.025236, l1: 0.026751, l2: 0.034544, l3: 0.051105, l4: 0.101242, l5: 0.217541, l6: 0.481598\n",
      "\n",
      "[epoch: 328/400, batch: 24/1000, ite: 43754] train loss: 1.1759, accuracy: 94.5773%, tar: 0.0259 \n",
      "l0: 0.020012, l1: 0.021066, l2: 0.026192, l3: 0.040934, l4: 0.079532, l5: 0.197009, l6: 0.405654\n",
      "\n",
      "[epoch: 328/400, batch: 32/1000, ite: 43755] train loss: 1.1760, accuracy: 95.0269%, tar: 0.0258 \n",
      "l0: 0.029384, l1: 0.030915, l2: 0.040531, l3: 0.063112, l4: 0.122995, l5: 0.225621, l6: 0.426685\n",
      "\n",
      "[epoch: 328/400, batch: 40/1000, ite: 43756] train loss: 1.1774, accuracy: 94.2221%, tar: 0.0259 \n",
      "l0: 0.030485, l1: 0.031563, l2: 0.037940, l3: 0.053158, l4: 0.093575, l5: 0.186410, l6: 0.455282\n",
      "\n",
      "[epoch: 328/400, batch: 48/1000, ite: 43757] train loss: 1.1789, accuracy: 93.7978%, tar: 0.0259 \n",
      "l0: 0.029522, l1: 0.031166, l2: 0.040767, l3: 0.064399, l4: 0.120034, l5: 0.212717, l6: 0.344195\n",
      "\n",
      "[epoch: 328/400, batch: 56/1000, ite: 43758] train loss: 1.1789, accuracy: 94.9202%, tar: 0.0259 \n",
      "l0: 0.020903, l1: 0.022123, l2: 0.028768, l3: 0.040961, l4: 0.068906, l5: 0.132189, l6: 0.258137\n",
      "\n",
      "[epoch: 328/400, batch: 64/1000, ite: 43759] train loss: 1.1764, accuracy: 95.6472%, tar: 0.0259 \n",
      "l0: 0.024708, l1: 0.026003, l2: 0.033179, l3: 0.049554, l4: 0.093432, l5: 0.171386, l6: 0.386391\n",
      "\n",
      "[epoch: 328/400, batch: 72/1000, ite: 43760] train loss: 1.1764, accuracy: 94.8538%, tar: 0.0259 \n",
      "l0: 0.029810, l1: 0.030891, l2: 0.040528, l3: 0.059900, l4: 0.124841, l5: 0.185713, l6: 0.410474\n",
      "\n",
      "[epoch: 328/400, batch: 80/1000, ite: 43761] train loss: 1.1772, accuracy: 94.6476%, tar: 0.0259 \n",
      "l0: 0.028639, l1: 0.029609, l2: 0.037885, l3: 0.057965, l4: 0.111403, l5: 0.202491, l6: 0.429988\n",
      "\n",
      "[epoch: 328/400, batch: 88/1000, ite: 43762] train loss: 1.1784, accuracy: 94.0212%, tar: 0.0259 \n",
      "l0: 0.021400, l1: 0.022775, l2: 0.029890, l3: 0.043473, l4: 0.078739, l5: 0.156832, l6: 0.337204\n",
      "\n",
      "[epoch: 328/400, batch: 96/1000, ite: 43763] train loss: 1.1773, accuracy: 95.3920%, tar: 0.0259 \n",
      "l0: 0.027899, l1: 0.029293, l2: 0.038080, l3: 0.063473, l4: 0.128082, l5: 0.232693, l6: 0.479926\n",
      "\n",
      "[epoch: 328/400, batch: 104/1000, ite: 43764] train loss: 1.1795, accuracy: 93.0778%, tar: 0.0259 \n",
      "l0: 0.027396, l1: 0.028244, l2: 0.035445, l3: 0.048557, l4: 0.091614, l5: 0.189849, l6: 0.390480\n",
      "\n",
      "[epoch: 328/400, batch: 112/1000, ite: 43765] train loss: 1.1797, accuracy: 95.1253%, tar: 0.0259 \n",
      "l0: 0.020154, l1: 0.021486, l2: 0.029715, l3: 0.041562, l4: 0.077162, l5: 0.139571, l6: 0.282058\n",
      "\n",
      "[epoch: 328/400, batch: 120/1000, ite: 43766] train loss: 1.1777, accuracy: 95.7188%, tar: 0.0259 \n",
      "l0: 0.028381, l1: 0.029501, l2: 0.037267, l3: 0.053318, l4: 0.089717, l5: 0.184015, l6: 0.334362\n",
      "\n",
      "[epoch: 328/400, batch: 128/1000, ite: 43767] train loss: 1.1771, accuracy: 94.9406%, tar: 0.0259 \n",
      "l0: 0.018044, l1: 0.019317, l2: 0.025899, l3: 0.038571, l4: 0.069709, l5: 0.153678, l6: 0.286245\n",
      "\n",
      "[epoch: 328/400, batch: 136/1000, ite: 43768] train loss: 1.1751, accuracy: 95.9145%, tar: 0.0258 \n",
      "l0: 0.029265, l1: 0.030364, l2: 0.037765, l3: 0.057141, l4: 0.104652, l5: 0.190427, l6: 0.347474\n",
      "\n",
      "[epoch: 328/400, batch: 144/1000, ite: 43769] train loss: 1.1749, accuracy: 94.1320%, tar: 0.0259 \n",
      "l0: 0.033940, l1: 0.035281, l2: 0.045271, l3: 0.067991, l4: 0.121959, l5: 0.272743, l6: 0.552858\n",
      "\n",
      "[epoch: 328/400, batch: 152/1000, ite: 43770] train loss: 1.1784, accuracy: 92.0966%, tar: 0.0259 \n",
      "l0: 0.028718, l1: 0.030692, l2: 0.038995, l3: 0.059407, l4: 0.115387, l5: 0.217089, l6: 0.448918\n",
      "\n",
      "[epoch: 328/400, batch: 160/1000, ite: 43771] train loss: 1.1799, accuracy: 94.3002%, tar: 0.0259 \n",
      "l0: 0.034506, l1: 0.035766, l2: 0.043370, l3: 0.056288, l4: 0.087732, l5: 0.141747, l6: 0.305058\n",
      "\n",
      "[epoch: 328/400, batch: 168/1000, ite: 43772] train loss: 1.1787, accuracy: 95.0269%, tar: 0.0260 \n",
      "l0: 0.021677, l1: 0.023853, l2: 0.033479, l3: 0.051228, l4: 0.108898, l5: 0.218447, l6: 0.358672\n",
      "\n",
      "[epoch: 328/400, batch: 176/1000, ite: 43773] train loss: 1.1787, accuracy: 95.6998%, tar: 0.0260 \n",
      "l0: 0.027375, l1: 0.028776, l2: 0.037444, l3: 0.053707, l4: 0.085940, l5: 0.164506, l6: 0.397677\n",
      "\n",
      "[epoch: 328/400, batch: 184/1000, ite: 43774] train loss: 1.1788, accuracy: 94.6417%, tar: 0.0260 \n",
      "l0: 0.026230, l1: 0.027593, l2: 0.036854, l3: 0.053284, l4: 0.095779, l5: 0.232280, l6: 0.472094\n",
      "\n",
      "[epoch: 328/400, batch: 192/1000, ite: 43775] train loss: 1.1804, accuracy: 93.7275%, tar: 0.0260 \n",
      "l0: 0.025888, l1: 0.027706, l2: 0.036003, l3: 0.052419, l4: 0.099855, l5: 0.177137, l6: 0.307606\n",
      "\n",
      "[epoch: 328/400, batch: 200/1000, ite: 43776] train loss: 1.1794, accuracy: 95.6102%, tar: 0.0260 \n",
      "l0: 0.025470, l1: 0.026887, l2: 0.036651, l3: 0.050852, l4: 0.086148, l5: 0.162353, l6: 0.309554\n",
      "\n",
      "[epoch: 328/400, batch: 208/1000, ite: 43777] train loss: 1.1783, accuracy: 95.3490%, tar: 0.0260 \n",
      "l0: 0.020773, l1: 0.021785, l2: 0.028363, l3: 0.040213, l4: 0.061903, l5: 0.114473, l6: 0.252667\n",
      "\n",
      "[epoch: 328/400, batch: 216/1000, ite: 43778] train loss: 1.1757, accuracy: 96.0827%, tar: 0.0259 \n",
      "l0: 0.027468, l1: 0.029262, l2: 0.037437, l3: 0.053991, l4: 0.096064, l5: 0.198254, l6: 0.400551\n",
      "\n",
      "[epoch: 328/400, batch: 224/1000, ite: 43779] train loss: 1.1761, accuracy: 94.3329%, tar: 0.0259 \n",
      "l0: 0.033128, l1: 0.034421, l2: 0.042272, l3: 0.058129, l4: 0.099095, l5: 0.224451, l6: 0.475982\n",
      "\n",
      "[epoch: 328/400, batch: 232/1000, ite: 43780] train loss: 1.1777, accuracy: 94.4437%, tar: 0.0260 \n",
      "l0: 0.022819, l1: 0.023794, l2: 0.030858, l3: 0.044685, l4: 0.078357, l5: 0.166031, l6: 0.330044\n",
      "\n",
      "[epoch: 328/400, batch: 240/1000, ite: 43781] train loss: 1.1768, accuracy: 95.2735%, tar: 0.0260 \n",
      "l0: 0.024310, l1: 0.024729, l2: 0.030577, l3: 0.045259, l4: 0.074657, l5: 0.138259, l6: 0.239528\n",
      "\n",
      "[epoch: 328/400, batch: 248/1000, ite: 43782] train loss: 1.1745, accuracy: 96.0309%, tar: 0.0260 \n",
      "l0: 0.028828, l1: 0.029636, l2: 0.038582, l3: 0.053095, l4: 0.089219, l5: 0.168280, l6: 0.367200\n",
      "\n",
      "[epoch: 328/400, batch: 256/1000, ite: 43783] train loss: 1.1744, accuracy: 94.2900%, tar: 0.0260 \n",
      "l0: 0.027408, l1: 0.028934, l2: 0.037312, l3: 0.055483, l4: 0.095349, l5: 0.184558, l6: 0.317933\n",
      "\n",
      "[epoch: 328/400, batch: 264/1000, ite: 43784] train loss: 1.1737, accuracy: 95.0635%, tar: 0.0260 \n",
      "l0: 0.030325, l1: 0.031406, l2: 0.040286, l3: 0.055508, l4: 0.083313, l5: 0.155133, l6: 0.359069\n",
      "\n",
      "[epoch: 328/400, batch: 272/1000, ite: 43785] train loss: 1.1734, accuracy: 94.6695%, tar: 0.0260 \n",
      "l0: 0.025440, l1: 0.026766, l2: 0.032600, l3: 0.048183, l4: 0.101602, l5: 0.215203, l6: 0.404335\n",
      "\n",
      "[epoch: 328/400, batch: 280/1000, ite: 43786] train loss: 1.1739, accuracy: 94.1983%, tar: 0.0260 \n",
      "l0: 0.019363, l1: 0.021870, l2: 0.029438, l3: 0.044823, l4: 0.085664, l5: 0.187733, l6: 0.364700\n",
      "\n",
      "[epoch: 328/400, batch: 288/1000, ite: 43787] train loss: 1.1736, accuracy: 96.2866%, tar: 0.0260 \n",
      "l0: 0.023227, l1: 0.024240, l2: 0.031127, l3: 0.046820, l4: 0.095357, l5: 0.182287, l6: 0.381483\n",
      "\n",
      "[epoch: 328/400, batch: 296/1000, ite: 43788] train loss: 1.1735, accuracy: 94.7086%, tar: 0.0260 \n",
      "l0: 0.022359, l1: 0.023620, l2: 0.031998, l3: 0.050510, l4: 0.088299, l5: 0.186338, l6: 0.375206\n",
      "\n",
      "[epoch: 328/400, batch: 304/1000, ite: 43789] train loss: 1.1734, accuracy: 94.7512%, tar: 0.0259 \n",
      "l0: 0.026203, l1: 0.027735, l2: 0.035782, l3: 0.054570, l4: 0.103887, l5: 0.205779, l6: 0.408293\n",
      "\n",
      "[epoch: 328/400, batch: 312/1000, ite: 43790] train loss: 1.1740, accuracy: 94.3184%, tar: 0.0259 \n",
      "l0: 0.029181, l1: 0.030530, l2: 0.039242, l3: 0.056180, l4: 0.117756, l5: 0.226221, l6: 0.441234\n",
      "\n",
      "[epoch: 328/400, batch: 320/1000, ite: 43791] train loss: 1.1753, accuracy: 94.1423%, tar: 0.0260 \n",
      "l0: 0.022623, l1: 0.025643, l2: 0.035275, l3: 0.060816, l4: 0.121253, l5: 0.195230, l6: 0.481992\n",
      "\n",
      "[epoch: 328/400, batch: 328/1000, ite: 43792] train loss: 1.1768, accuracy: 94.1816%, tar: 0.0259 \n",
      "l0: 0.019255, l1: 0.019923, l2: 0.026187, l3: 0.037191, l4: 0.067726, l5: 0.156146, l6: 0.368527\n",
      "\n",
      "[epoch: 328/400, batch: 336/1000, ite: 43793] train loss: 1.1762, accuracy: 95.4969%, tar: 0.0259 \n",
      "l0: 0.021256, l1: 0.022678, l2: 0.029665, l3: 0.043503, l4: 0.069847, l5: 0.126354, l6: 0.275482\n",
      "\n",
      "[epoch: 328/400, batch: 344/1000, ite: 43794] train loss: 1.1744, accuracy: 96.2876%, tar: 0.0259 \n",
      "l0: 0.034314, l1: 0.035543, l2: 0.045271, l3: 0.067168, l4: 0.113103, l5: 0.218131, l6: 0.490570\n",
      "\n",
      "[epoch: 328/400, batch: 352/1000, ite: 43795] train loss: 1.1762, accuracy: 92.9984%, tar: 0.0259 \n",
      "l0: 0.030864, l1: 0.032316, l2: 0.039012, l3: 0.060193, l4: 0.118334, l5: 0.248798, l6: 0.503720\n",
      "\n",
      "[epoch: 328/400, batch: 360/1000, ite: 43796] train loss: 1.1784, accuracy: 93.2595%, tar: 0.0259 \n",
      "l0: 0.036036, l1: 0.037579, l2: 0.048048, l3: 0.074208, l4: 0.149153, l5: 0.283986, l6: 0.561299\n",
      "\n",
      "[epoch: 328/400, batch: 368/1000, ite: 43797] train loss: 1.1818, accuracy: 92.5411%, tar: 0.0260 \n",
      "l0: 0.025879, l1: 0.027108, l2: 0.036598, l3: 0.051792, l4: 0.088319, l5: 0.191051, l6: 0.448255\n",
      "\n",
      "[epoch: 328/400, batch: 376/1000, ite: 43798] train loss: 1.1825, accuracy: 94.6248%, tar: 0.0260 \n",
      "l0: 0.026089, l1: 0.027308, l2: 0.036923, l3: 0.050623, l4: 0.100047, l5: 0.194177, l6: 0.451440\n",
      "\n",
      "[epoch: 328/400, batch: 384/1000, ite: 43799] train loss: 1.1834, accuracy: 94.7866%, tar: 0.0260 \n",
      "l0: 0.033252, l1: 0.035501, l2: 0.045656, l3: 0.067674, l4: 0.112044, l5: 0.210591, l6: 0.343893\n",
      "\n",
      "[epoch: 328/400, batch: 392/1000, ite: 43800] train loss: 1.1835, accuracy: 94.8182%, tar: 0.0260 \n",
      "l0: 0.031645, l1: 0.032502, l2: 0.040676, l3: 0.053349, l4: 0.095992, l5: 0.186266, l6: 0.338632\n",
      "\n",
      "[epoch: 328/400, batch: 400/1000, ite: 43801] train loss: 1.1832, accuracy: 94.4835%, tar: 0.0261 \n",
      "l0: 0.026106, l1: 0.027653, l2: 0.036514, l3: 0.055156, l4: 0.099138, l5: 0.171310, l6: 0.339780\n",
      "\n",
      "[epoch: 328/400, batch: 408/1000, ite: 43802] train loss: 1.1827, accuracy: 95.5034%, tar: 0.0261 \n",
      "l0: 0.019335, l1: 0.019740, l2: 0.024138, l3: 0.034774, l4: 0.062427, l5: 0.123176, l6: 0.235688\n",
      "\n",
      "[epoch: 328/400, batch: 416/1000, ite: 43803] train loss: 1.1803, accuracy: 96.1980%, tar: 0.0260 \n",
      "l0: 0.023700, l1: 0.024605, l2: 0.031092, l3: 0.044949, l4: 0.084779, l5: 0.164946, l6: 0.305600\n",
      "\n",
      "[epoch: 328/400, batch: 424/1000, ite: 43804] train loss: 1.1793, accuracy: 95.4600%, tar: 0.0260 \n",
      "l0: 0.025920, l1: 0.026580, l2: 0.033361, l3: 0.045668, l4: 0.072031, l5: 0.141678, l6: 0.282767\n",
      "\n",
      "[epoch: 328/400, batch: 432/1000, ite: 43805] train loss: 1.1778, accuracy: 95.4325%, tar: 0.0260 \n",
      "l0: 0.020649, l1: 0.021713, l2: 0.028592, l3: 0.044273, l4: 0.083343, l5: 0.164750, l6: 0.313901\n",
      "\n",
      "[epoch: 328/400, batch: 440/1000, ite: 43806] train loss: 1.1768, accuracy: 95.2421%, tar: 0.0260 \n",
      "l0: 0.029900, l1: 0.030894, l2: 0.038977, l3: 0.054382, l4: 0.096380, l5: 0.187560, l6: 0.412102\n",
      "\n",
      "[epoch: 328/400, batch: 448/1000, ite: 43807] train loss: 1.1773, accuracy: 93.9368%, tar: 0.0260 \n",
      "l0: 0.026256, l1: 0.027338, l2: 0.034518, l3: 0.049711, l4: 0.096452, l5: 0.184850, l6: 0.349350\n",
      "\n",
      "[epoch: 328/400, batch: 456/1000, ite: 43808] train loss: 1.1770, accuracy: 94.6255%, tar: 0.0260 \n",
      "l0: 0.026141, l1: 0.028018, l2: 0.035906, l3: 0.048357, l4: 0.090452, l5: 0.169670, l6: 0.318089\n",
      "\n",
      "[epoch: 328/400, batch: 464/1000, ite: 43809] train loss: 1.1762, accuracy: 95.6720%, tar: 0.0260 \n",
      "l0: 0.033416, l1: 0.036063, l2: 0.047746, l3: 0.070902, l4: 0.128999, l5: 0.241826, l6: 0.477222\n",
      "\n",
      "[epoch: 328/400, batch: 472/1000, ite: 43810] train loss: 1.1781, accuracy: 93.6984%, tar: 0.0261 \n",
      "l0: 0.029287, l1: 0.030917, l2: 0.039486, l3: 0.059678, l4: 0.103007, l5: 0.223952, l6: 0.404400\n",
      "\n",
      "[epoch: 328/400, batch: 480/1000, ite: 43811] train loss: 1.1788, accuracy: 94.4473%, tar: 0.0261 \n",
      "l0: 0.025884, l1: 0.026587, l2: 0.034305, l3: 0.046931, l4: 0.092149, l5: 0.185515, l6: 0.368973\n",
      "\n",
      "[epoch: 328/400, batch: 488/1000, ite: 43812] train loss: 1.1786, accuracy: 94.7515%, tar: 0.0261 \n",
      "l0: 0.021938, l1: 0.023646, l2: 0.033263, l3: 0.052115, l4: 0.096499, l5: 0.188398, l6: 0.442364\n",
      "\n",
      "[epoch: 328/400, batch: 496/1000, ite: 43813] train loss: 1.1793, accuracy: 94.7592%, tar: 0.0261 \n",
      "l0: 0.024173, l1: 0.025278, l2: 0.033989, l3: 0.047025, l4: 0.075367, l5: 0.117787, l6: 0.264986\n",
      "\n",
      "[epoch: 328/400, batch: 504/1000, ite: 43814] train loss: 1.1776, accuracy: 95.7717%, tar: 0.0260 \n",
      "l0: 0.021106, l1: 0.021676, l2: 0.026708, l3: 0.034845, l4: 0.052443, l5: 0.083844, l6: 0.179908\n",
      "\n",
      "[epoch: 328/400, batch: 512/1000, ite: 43815] train loss: 1.1746, accuracy: 96.8378%, tar: 0.0260 \n",
      "l0: 0.023080, l1: 0.024571, l2: 0.031613, l3: 0.045469, l4: 0.090879, l5: 0.181677, l6: 0.423318\n",
      "\n",
      "[epoch: 328/400, batch: 520/1000, ite: 43816] train loss: 1.1749, accuracy: 93.7534%, tar: 0.0260 \n",
      "l0: 0.029004, l1: 0.029743, l2: 0.034827, l3: 0.046100, l4: 0.071250, l5: 0.132674, l6: 0.278904\n",
      "\n",
      "[epoch: 328/400, batch: 528/1000, ite: 43817] train loss: 1.1736, accuracy: 96.3906%, tar: 0.0260 \n",
      "l0: 0.025998, l1: 0.027139, l2: 0.034805, l3: 0.051971, l4: 0.105358, l5: 0.219651, l6: 0.425895\n",
      "\n",
      "[epoch: 328/400, batch: 536/1000, ite: 43818] train loss: 1.1743, accuracy: 94.1045%, tar: 0.0260 \n",
      "l0: 0.036113, l1: 0.038074, l2: 0.049033, l3: 0.072456, l4: 0.134687, l5: 0.251405, l6: 0.495869\n",
      "\n",
      "[epoch: 328/400, batch: 544/1000, ite: 43819] train loss: 1.1764, accuracy: 93.8058%, tar: 0.0261 \n",
      "l0: 0.023357, l1: 0.025570, l2: 0.035521, l3: 0.050083, l4: 0.085222, l5: 0.169780, l6: 0.358073\n",
      "\n",
      "[epoch: 328/400, batch: 552/1000, ite: 43820] train loss: 1.1760, accuracy: 95.7649%, tar: 0.0261 \n",
      "l0: 0.030299, l1: 0.031468, l2: 0.039658, l3: 0.056030, l4: 0.089461, l5: 0.160690, l6: 0.380775\n",
      "\n",
      "[epoch: 328/400, batch: 560/1000, ite: 43821] train loss: 1.1760, accuracy: 94.6425%, tar: 0.0261 \n",
      "l0: 0.030754, l1: 0.031706, l2: 0.040589, l3: 0.057547, l4: 0.096617, l5: 0.187954, l6: 0.382576\n",
      "\n",
      "[epoch: 328/400, batch: 568/1000, ite: 43822] train loss: 1.1763, accuracy: 94.0919%, tar: 0.0261 \n",
      "l0: 0.036589, l1: 0.037515, l2: 0.047274, l3: 0.071855, l4: 0.163744, l5: 0.348463, l6: 0.564434\n",
      "\n",
      "[epoch: 328/400, batch: 576/1000, ite: 43823] train loss: 1.1796, accuracy: 91.7502%, tar: 0.0262 \n",
      "l0: 0.024262, l1: 0.025620, l2: 0.034532, l3: 0.049783, l4: 0.092323, l5: 0.180604, l6: 0.390243\n",
      "\n",
      "[epoch: 328/400, batch: 584/1000, ite: 43824] train loss: 1.1797, accuracy: 94.3790%, tar: 0.0261 \n",
      "l0: 0.025308, l1: 0.026596, l2: 0.033632, l3: 0.052438, l4: 0.106766, l5: 0.226171, l6: 0.421295\n",
      "\n",
      "[epoch: 328/400, batch: 592/1000, ite: 43825] train loss: 1.1804, accuracy: 94.5876%, tar: 0.0261 \n",
      "l0: 0.028367, l1: 0.030003, l2: 0.037923, l3: 0.051104, l4: 0.086586, l5: 0.166854, l6: 0.353761\n",
      "\n",
      "[epoch: 328/400, batch: 600/1000, ite: 43826] train loss: 1.1800, accuracy: 94.8220%, tar: 0.0262 \n",
      "l0: 0.030915, l1: 0.031838, l2: 0.039238, l3: 0.054592, l4: 0.096489, l5: 0.180772, l6: 0.394078\n",
      "\n",
      "[epoch: 328/400, batch: 608/1000, ite: 43827] train loss: 1.1803, accuracy: 93.8602%, tar: 0.0262 \n",
      "l0: 0.025785, l1: 0.026747, l2: 0.034185, l3: 0.048215, l4: 0.087274, l5: 0.193867, l6: 0.338723\n",
      "\n",
      "[epoch: 328/400, batch: 616/1000, ite: 43828] train loss: 1.1798, accuracy: 94.8409%, tar: 0.0262 \n",
      "l0: 0.020336, l1: 0.020687, l2: 0.026311, l3: 0.038392, l4: 0.067781, l5: 0.145102, l6: 0.337881\n",
      "\n",
      "[epoch: 328/400, batch: 624/1000, ite: 43829] train loss: 1.1790, accuracy: 95.8164%, tar: 0.0261 \n",
      "l0: 0.021465, l1: 0.022594, l2: 0.029403, l3: 0.046259, l4: 0.084053, l5: 0.158092, l6: 0.290581\n",
      "\n",
      "[epoch: 328/400, batch: 632/1000, ite: 43830] train loss: 1.1778, accuracy: 95.6789%, tar: 0.0261 \n",
      "l0: 0.030419, l1: 0.032316, l2: 0.039792, l3: 0.054770, l4: 0.096464, l5: 0.206785, l6: 0.410505\n",
      "\n",
      "[epoch: 328/400, batch: 640/1000, ite: 43831] train loss: 1.1784, accuracy: 93.4066%, tar: 0.0261 \n",
      "l0: 0.027937, l1: 0.029780, l2: 0.040048, l3: 0.063008, l4: 0.119950, l5: 0.222528, l6: 0.485733\n",
      "\n",
      "[epoch: 328/400, batch: 648/1000, ite: 43832] train loss: 1.1798, accuracy: 95.0641%, tar: 0.0262 \n",
      "l0: 0.024652, l1: 0.026185, l2: 0.034935, l3: 0.051993, l4: 0.107229, l5: 0.222275, l6: 0.392645\n",
      "\n",
      "[epoch: 328/400, batch: 656/1000, ite: 43833] train loss: 1.1802, accuracy: 94.9288%, tar: 0.0261 \n",
      "l0: 0.022848, l1: 0.024378, l2: 0.030856, l3: 0.047807, l4: 0.090349, l5: 0.183491, l6: 0.370257\n",
      "\n",
      "[epoch: 328/400, batch: 664/1000, ite: 43834] train loss: 1.1800, accuracy: 95.2456%, tar: 0.0261 \n",
      "l0: 0.019999, l1: 0.021388, l2: 0.029619, l3: 0.045080, l4: 0.077611, l5: 0.155591, l6: 0.339591\n",
      "\n",
      "[epoch: 328/400, batch: 672/1000, ite: 43835] train loss: 1.1792, accuracy: 95.9592%, tar: 0.0261 \n",
      "l0: 0.024432, l1: 0.026449, l2: 0.035216, l3: 0.052084, l4: 0.088191, l5: 0.169008, l6: 0.358769\n",
      "\n",
      "[epoch: 328/400, batch: 680/1000, ite: 43836] train loss: 1.1790, accuracy: 95.3903%, tar: 0.0261 \n",
      "l0: 0.029092, l1: 0.031079, l2: 0.039929, l3: 0.058633, l4: 0.110423, l5: 0.220737, l6: 0.431624\n",
      "\n",
      "[epoch: 328/400, batch: 688/1000, ite: 43837] train loss: 1.1798, accuracy: 93.6910%, tar: 0.0261 \n",
      "l0: 0.022616, l1: 0.023783, l2: 0.030675, l3: 0.045294, l4: 0.082174, l5: 0.157917, l6: 0.399806\n",
      "\n",
      "[epoch: 328/400, batch: 696/1000, ite: 43838] train loss: 1.1798, accuracy: 95.1233%, tar: 0.0261 \n",
      "l0: 0.025641, l1: 0.026312, l2: 0.033115, l3: 0.044401, l4: 0.070024, l5: 0.123248, l6: 0.296222\n",
      "\n",
      "[epoch: 328/400, batch: 704/1000, ite: 43839] train loss: 1.1785, accuracy: 95.4844%, tar: 0.0261 \n",
      "l0: 0.023257, l1: 0.023565, l2: 0.030684, l3: 0.046367, l4: 0.077193, l5: 0.163686, l6: 0.309162\n",
      "\n",
      "[epoch: 328/400, batch: 712/1000, ite: 43840] train loss: 1.1777, accuracy: 95.1102%, tar: 0.0261 \n",
      "l0: 0.029395, l1: 0.030423, l2: 0.039089, l3: 0.057263, l4: 0.107874, l5: 0.227359, l6: 0.418803\n",
      "\n",
      "[epoch: 328/400, batch: 720/1000, ite: 43841] train loss: 1.1784, accuracy: 94.3362%, tar: 0.0261 \n",
      "l0: 0.027166, l1: 0.029342, l2: 0.039003, l3: 0.062571, l4: 0.121832, l5: 0.238150, l6: 0.423619\n",
      "\n",
      "[epoch: 328/400, batch: 728/1000, ite: 43842] train loss: 1.1793, accuracy: 94.4672%, tar: 0.0261 \n",
      "l0: 0.025850, l1: 0.026459, l2: 0.033971, l3: 0.048689, l4: 0.088974, l5: 0.177409, l6: 0.430048\n",
      "\n",
      "[epoch: 328/400, batch: 736/1000, ite: 43843] train loss: 1.1798, accuracy: 93.9466%, tar: 0.0261 \n",
      "l0: 0.030598, l1: 0.032649, l2: 0.043693, l3: 0.062569, l4: 0.107932, l5: 0.203565, l6: 0.366697\n",
      "\n",
      "[epoch: 328/400, batch: 744/1000, ite: 43844] train loss: 1.1800, accuracy: 94.7458%, tar: 0.0261 \n",
      "l0: 0.021464, l1: 0.022615, l2: 0.030544, l3: 0.043471, l4: 0.072509, l5: 0.174391, l6: 0.426986\n",
      "\n",
      "[epoch: 328/400, batch: 752/1000, ite: 43845] train loss: 1.1802, accuracy: 95.1896%, tar: 0.0261 \n",
      "l0: 0.027680, l1: 0.028990, l2: 0.038906, l3: 0.055961, l4: 0.100830, l5: 0.209834, l6: 0.389976\n",
      "\n",
      "[epoch: 328/400, batch: 760/1000, ite: 43846] train loss: 1.1805, accuracy: 94.6406%, tar: 0.0261 \n",
      "l0: 0.023879, l1: 0.025262, l2: 0.031133, l3: 0.043222, l4: 0.066632, l5: 0.127123, l6: 0.267244\n",
      "\n",
      "[epoch: 328/400, batch: 768/1000, ite: 43847] train loss: 1.1790, accuracy: 96.1214%, tar: 0.0261 \n",
      "l0: 0.025759, l1: 0.027173, l2: 0.037517, l3: 0.060523, l4: 0.125313, l5: 0.254439, l6: 0.496007\n",
      "\n",
      "[epoch: 328/400, batch: 776/1000, ite: 43848] train loss: 1.1805, accuracy: 93.2867%, tar: 0.0261 \n",
      "l0: 0.028372, l1: 0.029654, l2: 0.037329, l3: 0.050717, l4: 0.097634, l5: 0.172706, l6: 0.360990\n",
      "\n",
      "[epoch: 328/400, batch: 784/1000, ite: 43849] train loss: 1.1804, accuracy: 95.3503%, tar: 0.0261 \n",
      "l0: 0.022058, l1: 0.022928, l2: 0.030060, l3: 0.043369, l4: 0.078399, l5: 0.145835, l6: 0.278447\n",
      "\n",
      "[epoch: 328/400, batch: 792/1000, ite: 43850] train loss: 1.1791, accuracy: 95.6016%, tar: 0.0261 \n",
      "l0: 0.023374, l1: 0.024153, l2: 0.029867, l3: 0.043392, l4: 0.083568, l5: 0.171972, l6: 0.316953\n",
      "\n",
      "[epoch: 328/400, batch: 800/1000, ite: 43851] train loss: 1.1784, accuracy: 95.3218%, tar: 0.0261 \n",
      "l0: 0.032421, l1: 0.033632, l2: 0.044292, l3: 0.063565, l4: 0.105496, l5: 0.237471, l6: 0.456848\n",
      "\n",
      "[epoch: 328/400, batch: 808/1000, ite: 43852] train loss: 1.1795, accuracy: 94.0227%, tar: 0.0261 \n",
      "l0: 0.036980, l1: 0.038092, l2: 0.045367, l3: 0.064869, l4: 0.124618, l5: 0.233186, l6: 0.476849\n",
      "\n",
      "[epoch: 328/400, batch: 816/1000, ite: 43853] train loss: 1.1810, accuracy: 92.8354%, tar: 0.0261 \n",
      "l0: 0.028213, l1: 0.029171, l2: 0.035772, l3: 0.050895, l4: 0.088295, l5: 0.200786, l6: 0.433436\n",
      "\n",
      "[epoch: 328/400, batch: 824/1000, ite: 43854] train loss: 1.1814, accuracy: 93.7375%, tar: 0.0262 \n",
      "l0: 0.027497, l1: 0.029341, l2: 0.039444, l3: 0.062269, l4: 0.109104, l5: 0.205248, l6: 0.411722\n",
      "\n",
      "[epoch: 328/400, batch: 832/1000, ite: 43855] train loss: 1.1819, accuracy: 94.4782%, tar: 0.0262 \n",
      "l0: 0.026853, l1: 0.027345, l2: 0.033010, l3: 0.044426, l4: 0.074442, l5: 0.132826, l6: 0.295404\n",
      "\n",
      "[epoch: 328/400, batch: 840/1000, ite: 43856] train loss: 1.1809, accuracy: 94.9655%, tar: 0.0262 \n",
      "l0: 0.025619, l1: 0.026881, l2: 0.035424, l3: 0.053276, l4: 0.109427, l5: 0.226727, l6: 0.407803\n",
      "\n",
      "[epoch: 328/400, batch: 848/1000, ite: 43857] train loss: 1.1814, accuracy: 94.4146%, tar: 0.0262 \n",
      "l0: 0.034573, l1: 0.037205, l2: 0.047316, l3: 0.070244, l4: 0.132968, l5: 0.279097, l6: 0.628700\n",
      "\n",
      "[epoch: 328/400, batch: 856/1000, ite: 43858] train loss: 1.1843, accuracy: 92.8998%, tar: 0.0262 \n",
      "l0: 0.024888, l1: 0.026249, l2: 0.034893, l3: 0.058749, l4: 0.109760, l5: 0.191061, l6: 0.369470\n",
      "\n",
      "[epoch: 328/400, batch: 864/1000, ite: 43859] train loss: 1.1843, accuracy: 94.7168%, tar: 0.0262 \n",
      "l0: 0.024961, l1: 0.025965, l2: 0.032032, l3: 0.041820, l4: 0.065129, l5: 0.123285, l6: 0.316058\n",
      "\n",
      "[epoch: 328/400, batch: 872/1000, ite: 43860] train loss: 1.1833, accuracy: 94.7952%, tar: 0.0262 \n",
      "l0: 0.039323, l1: 0.040209, l2: 0.048867, l3: 0.066394, l4: 0.115644, l5: 0.207718, l6: 0.382245\n",
      "\n",
      "[epoch: 328/400, batch: 880/1000, ite: 43861] train loss: 1.1837, accuracy: 94.1572%, tar: 0.0262 \n",
      "l0: 0.027511, l1: 0.029199, l2: 0.038720, l3: 0.059000, l4: 0.112269, l5: 0.199320, l6: 0.385463\n",
      "\n",
      "[epoch: 328/400, batch: 888/1000, ite: 43862] train loss: 1.1840, accuracy: 94.7882%, tar: 0.0262 \n",
      "l0: 0.026773, l1: 0.027871, l2: 0.036170, l3: 0.052161, l4: 0.086536, l5: 0.150745, l6: 0.339056\n",
      "\n",
      "[epoch: 328/400, batch: 896/1000, ite: 43863] train loss: 1.1835, accuracy: 94.9907%, tar: 0.0262 \n",
      "l0: 0.028870, l1: 0.029879, l2: 0.037279, l3: 0.049478, l4: 0.083576, l5: 0.202529, l6: 0.412777\n",
      "\n",
      "[epoch: 328/400, batch: 904/1000, ite: 43864] train loss: 1.1838, accuracy: 93.6370%, tar: 0.0263 \n",
      "l0: 0.031384, l1: 0.032771, l2: 0.041690, l3: 0.065258, l4: 0.119498, l5: 0.216346, l6: 0.413648\n",
      "\n",
      "[epoch: 328/400, batch: 912/1000, ite: 43865] train loss: 1.1845, accuracy: 94.3456%, tar: 0.0263 \n",
      "l0: 0.019939, l1: 0.020564, l2: 0.025005, l3: 0.034883, l4: 0.061260, l5: 0.109085, l6: 0.255130\n",
      "\n",
      "[epoch: 328/400, batch: 920/1000, ite: 43866] train loss: 1.1828, accuracy: 96.2728%, tar: 0.0263 \n",
      "l0: 0.033621, l1: 0.034482, l2: 0.043730, l3: 0.058776, l4: 0.101762, l5: 0.189596, l6: 0.398590\n",
      "\n",
      "[epoch: 328/400, batch: 928/1000, ite: 43867] train loss: 1.1832, accuracy: 93.4506%, tar: 0.0263 \n",
      "l0: 0.018492, l1: 0.020530, l2: 0.029021, l3: 0.046078, l4: 0.083247, l5: 0.162787, l6: 0.321890\n",
      "\n",
      "[epoch: 328/400, batch: 936/1000, ite: 43868] train loss: 1.1824, accuracy: 96.5648%, tar: 0.0263 \n",
      "l0: 0.023431, l1: 0.024027, l2: 0.030768, l3: 0.043375, l4: 0.075683, l5: 0.141966, l6: 0.345401\n",
      "\n",
      "[epoch: 328/400, batch: 944/1000, ite: 43869] train loss: 1.1818, accuracy: 94.7384%, tar: 0.0262 \n",
      "l0: 0.025794, l1: 0.027473, l2: 0.035702, l3: 0.055476, l4: 0.104154, l5: 0.190360, l6: 0.344564\n",
      "\n",
      "[epoch: 328/400, batch: 952/1000, ite: 43870] train loss: 1.1816, accuracy: 95.7005%, tar: 0.0262 \n",
      "l0: 0.030436, l1: 0.031762, l2: 0.039452, l3: 0.058965, l4: 0.105419, l5: 0.181463, l6: 0.329552\n",
      "\n",
      "[epoch: 328/400, batch: 960/1000, ite: 43871] train loss: 1.1813, accuracy: 94.8314%, tar: 0.0263 \n",
      "l0: 0.024081, l1: 0.025939, l2: 0.034359, l3: 0.049959, l4: 0.092354, l5: 0.202768, l6: 0.366463\n",
      "\n",
      "[epoch: 328/400, batch: 968/1000, ite: 43872] train loss: 1.1813, accuracy: 95.2446%, tar: 0.0262 \n",
      "l0: 0.022770, l1: 0.023868, l2: 0.029821, l3: 0.040687, l4: 0.061881, l5: 0.111546, l6: 0.240159\n",
      "\n",
      "[epoch: 328/400, batch: 976/1000, ite: 43873] train loss: 1.1796, accuracy: 96.0978%, tar: 0.0262 \n",
      "l0: 0.037649, l1: 0.039874, l2: 0.047178, l3: 0.068551, l4: 0.140130, l5: 0.298088, l6: 0.522962\n",
      "\n",
      "[epoch: 328/400, batch: 984/1000, ite: 43874] train loss: 1.1817, accuracy: 92.5809%, tar: 0.0263 \n",
      "l0: 0.027869, l1: 0.029006, l2: 0.035018, l3: 0.050226, l4: 0.085993, l5: 0.166530, l6: 0.330612\n",
      "\n",
      "[epoch: 328/400, batch: 992/1000, ite: 43875] train loss: 1.1812, accuracy: 94.8282%, tar: 0.0263 \n",
      "l0: 0.032738, l1: 0.033285, l2: 0.039982, l3: 0.053221, l4: 0.093942, l5: 0.181889, l6: 0.398855\n",
      "\n",
      "[epoch: 328/400, batch: 1000/1000, ite: 43876] train loss: 1.1814, accuracy: 94.0273%, tar: 0.0263 \n",
      "l0: 0.030073, l1: 0.031898, l2: 0.040716, l3: 0.058573, l4: 0.107600, l5: 0.186161, l6: 0.337451\n",
      "\n",
      "[epoch: 329/400, batch: 8/1000, ite: 43877] train loss: 1.1812, accuracy: 95.0036%, tar: 0.0263 \n",
      "l0: 0.021691, l1: 0.022469, l2: 0.029629, l3: 0.042413, l4: 0.070656, l5: 0.127622, l6: 0.246873\n",
      "\n",
      "[epoch: 329/400, batch: 16/1000, ite: 43878] train loss: 1.1798, accuracy: 96.0970%, tar: 0.0263 \n",
      "l0: 0.028978, l1: 0.030326, l2: 0.039881, l3: 0.059310, l4: 0.111889, l5: 0.230096, l6: 0.467682\n",
      "\n",
      "[epoch: 329/400, batch: 24/1000, ite: 43879] train loss: 1.1808, accuracy: 93.6933%, tar: 0.0263 \n",
      "l0: 0.028037, l1: 0.030511, l2: 0.037318, l3: 0.056718, l4: 0.113830, l5: 0.255104, l6: 0.529170\n",
      "\n",
      "[epoch: 329/400, batch: 32/1000, ite: 43880] train loss: 1.1824, accuracy: 94.9774%, tar: 0.0263 \n",
      "l0: 0.022485, l1: 0.024073, l2: 0.031668, l3: 0.049249, l4: 0.093858, l5: 0.184507, l6: 0.383434\n",
      "\n",
      "[epoch: 329/400, batch: 40/1000, ite: 43881] train loss: 1.1823, accuracy: 95.7892%, tar: 0.0263 \n",
      "l0: 0.022614, l1: 0.023844, l2: 0.031012, l3: 0.045577, l4: 0.076172, l5: 0.151350, l6: 0.295595\n",
      "\n",
      "[epoch: 329/400, batch: 48/1000, ite: 43882] train loss: 1.1814, accuracy: 95.7516%, tar: 0.0263 \n",
      "l0: 0.024989, l1: 0.025893, l2: 0.032495, l3: 0.050571, l4: 0.102667, l5: 0.185122, l6: 0.361851\n",
      "\n",
      "[epoch: 329/400, batch: 56/1000, ite: 43883] train loss: 1.1813, accuracy: 94.6435%, tar: 0.0263 \n",
      "l0: 0.024804, l1: 0.025701, l2: 0.034100, l3: 0.047629, l4: 0.090752, l5: 0.189208, l6: 0.370196\n",
      "\n",
      "[epoch: 329/400, batch: 64/1000, ite: 43884] train loss: 1.1812, accuracy: 95.0982%, tar: 0.0263 \n",
      "l0: 0.029246, l1: 0.030386, l2: 0.040920, l3: 0.055844, l4: 0.089383, l5: 0.180493, l6: 0.326181\n",
      "\n",
      "[epoch: 329/400, batch: 72/1000, ite: 43885] train loss: 1.1808, accuracy: 95.2964%, tar: 0.0263 \n",
      "l0: 0.035110, l1: 0.038091, l2: 0.051307, l3: 0.076482, l4: 0.138054, l5: 0.231538, l6: 0.441694\n",
      "\n",
      "[epoch: 329/400, batch: 80/1000, ite: 43886] train loss: 1.1819, accuracy: 94.0505%, tar: 0.0263 \n",
      "l0: 0.026755, l1: 0.027251, l2: 0.035399, l3: 0.051876, l4: 0.095245, l5: 0.190084, l6: 0.365539\n",
      "\n",
      "[epoch: 329/400, batch: 88/1000, ite: 43887] train loss: 1.1818, accuracy: 94.3203%, tar: 0.0263 \n",
      "l0: 0.026796, l1: 0.027322, l2: 0.035188, l3: 0.049018, l4: 0.081111, l5: 0.164120, l6: 0.338602\n",
      "\n",
      "[epoch: 329/400, batch: 96/1000, ite: 43888] train loss: 1.1813, accuracy: 95.2974%, tar: 0.0263 \n",
      "l0: 0.030609, l1: 0.032951, l2: 0.043338, l3: 0.067487, l4: 0.136233, l5: 0.239831, l6: 0.450941\n",
      "\n",
      "[epoch: 329/400, batch: 104/1000, ite: 43889] train loss: 1.1823, accuracy: 94.0242%, tar: 0.0264 \n",
      "l0: 0.024542, l1: 0.025397, l2: 0.032581, l3: 0.047141, l4: 0.082560, l5: 0.170521, l6: 0.317963\n",
      "\n",
      "[epoch: 329/400, batch: 112/1000, ite: 43890] train loss: 1.1817, accuracy: 95.6131%, tar: 0.0263 \n",
      "l0: 0.024952, l1: 0.026329, l2: 0.032785, l3: 0.050107, l4: 0.095201, l5: 0.185666, l6: 0.376062\n",
      "\n",
      "[epoch: 329/400, batch: 120/1000, ite: 43891] train loss: 1.1817, accuracy: 94.5309%, tar: 0.0263 \n",
      "l0: 0.027077, l1: 0.030054, l2: 0.042475, l3: 0.068358, l4: 0.136744, l5: 0.282116, l6: 0.543596\n",
      "\n",
      "[epoch: 329/400, batch: 128/1000, ite: 43892] train loss: 1.1835, accuracy: 93.8508%, tar: 0.0263 \n",
      "l0: 0.023085, l1: 0.024134, l2: 0.029259, l3: 0.041315, l4: 0.067704, l5: 0.120083, l6: 0.255062\n",
      "\n",
      "[epoch: 329/400, batch: 136/1000, ite: 43893] train loss: 1.1821, accuracy: 95.8740%, tar: 0.0263 \n",
      "l0: 0.032958, l1: 0.034886, l2: 0.046476, l3: 0.072465, l4: 0.125245, l5: 0.254775, l6: 0.457709\n",
      "\n",
      "[epoch: 329/400, batch: 144/1000, ite: 43894] train loss: 1.1833, accuracy: 93.8764%, tar: 0.0264 \n",
      "l0: 0.023786, l1: 0.024655, l2: 0.031637, l3: 0.050701, l4: 0.102215, l5: 0.206919, l6: 0.417157\n",
      "\n",
      "[epoch: 329/400, batch: 152/1000, ite: 43895] train loss: 1.1836, accuracy: 94.6606%, tar: 0.0263 \n",
      "l0: 0.027873, l1: 0.029019, l2: 0.038336, l3: 0.056162, l4: 0.112966, l5: 0.275842, l6: 0.545259\n",
      "\n",
      "[epoch: 329/400, batch: 160/1000, ite: 43896] train loss: 1.1853, accuracy: 92.6393%, tar: 0.0263 \n",
      "l0: 0.029090, l1: 0.030516, l2: 0.038758, l3: 0.055221, l4: 0.101890, l5: 0.190266, l6: 0.380062\n",
      "\n",
      "[epoch: 329/400, batch: 168/1000, ite: 43897] train loss: 1.1854, accuracy: 93.8122%, tar: 0.0264 \n",
      "l0: 0.027219, l1: 0.028603, l2: 0.036004, l3: 0.050256, l4: 0.085939, l5: 0.200450, l6: 0.368571\n",
      "\n",
      "[epoch: 329/400, batch: 176/1000, ite: 43898] train loss: 1.1854, accuracy: 94.8625%, tar: 0.0264 \n",
      "l0: 0.022718, l1: 0.024368, l2: 0.033149, l3: 0.049502, l4: 0.098893, l5: 0.203153, l6: 0.395738\n",
      "\n",
      "[epoch: 329/400, batch: 184/1000, ite: 43899] train loss: 1.1855, accuracy: 95.4470%, tar: 0.0263 \n",
      "l0: 0.026376, l1: 0.027522, l2: 0.033487, l3: 0.047696, l4: 0.083043, l5: 0.154825, l6: 0.270654\n",
      "\n",
      "[epoch: 329/400, batch: 192/1000, ite: 43900] train loss: 1.1845, accuracy: 95.5368%, tar: 0.0263 \n",
      "l0: 0.019474, l1: 0.020367, l2: 0.026223, l3: 0.039795, l4: 0.063930, l5: 0.113499, l6: 0.253752\n",
      "\n",
      "[epoch: 329/400, batch: 200/1000, ite: 43901] train loss: 1.1831, accuracy: 96.3786%, tar: 0.0263 \n",
      "l0: 0.020589, l1: 0.022207, l2: 0.027656, l3: 0.037508, l4: 0.067667, l5: 0.138104, l6: 0.298407\n",
      "\n",
      "[epoch: 329/400, batch: 208/1000, ite: 43902] train loss: 1.1822, accuracy: 96.4041%, tar: 0.0263 \n",
      "l0: 0.025501, l1: 0.027024, l2: 0.034962, l3: 0.052960, l4: 0.104279, l5: 0.253376, l6: 0.494525\n",
      "\n",
      "[epoch: 329/400, batch: 216/1000, ite: 43903] train loss: 1.1833, accuracy: 93.3888%, tar: 0.0263 \n",
      "l0: 0.027118, l1: 0.028168, l2: 0.034365, l3: 0.049493, l4: 0.088060, l5: 0.168995, l6: 0.317505\n",
      "\n",
      "[epoch: 329/400, batch: 224/1000, ite: 43904] train loss: 1.1828, accuracy: 94.8741%, tar: 0.0263 \n",
      "l0: 0.030227, l1: 0.031567, l2: 0.039093, l3: 0.052825, l4: 0.110016, l5: 0.203128, l6: 0.393703\n",
      "\n",
      "[epoch: 329/400, batch: 232/1000, ite: 43905] train loss: 1.1831, accuracy: 94.4088%, tar: 0.0263 \n",
      "l0: 0.034198, l1: 0.036499, l2: 0.046647, l3: 0.069473, l4: 0.127168, l5: 0.210388, l6: 0.471254\n",
      "\n",
      "[epoch: 329/400, batch: 240/1000, ite: 43906] train loss: 1.1841, accuracy: 93.2808%, tar: 0.0263 \n",
      "l0: 0.024162, l1: 0.025307, l2: 0.034761, l3: 0.054828, l4: 0.103109, l5: 0.182047, l6: 0.343786\n",
      "\n",
      "[epoch: 329/400, batch: 248/1000, ite: 43907] train loss: 1.1839, accuracy: 95.4072%, tar: 0.0263 \n",
      "l0: 0.026100, l1: 0.027454, l2: 0.035023, l3: 0.049381, l4: 0.084136, l5: 0.157010, l6: 0.449264\n",
      "\n",
      "[epoch: 329/400, batch: 256/1000, ite: 43908] train loss: 1.1842, accuracy: 93.8460%, tar: 0.0263 \n",
      "l0: 0.024974, l1: 0.026525, l2: 0.033313, l3: 0.046866, l4: 0.074761, l5: 0.123535, l6: 0.263273\n",
      "\n",
      "[epoch: 329/400, batch: 264/1000, ite: 43909] train loss: 1.1831, accuracy: 95.7790%, tar: 0.0263 \n",
      "l0: 0.027875, l1: 0.028925, l2: 0.037410, l3: 0.054701, l4: 0.112242, l5: 0.214663, l6: 0.401052\n",
      "\n",
      "[epoch: 329/400, batch: 272/1000, ite: 43910] train loss: 1.1834, accuracy: 94.4337%, tar: 0.0263 \n",
      "l0: 0.026704, l1: 0.027797, l2: 0.034647, l3: 0.046468, l4: 0.070908, l5: 0.114297, l6: 0.235210\n",
      "\n",
      "[epoch: 329/400, batch: 280/1000, ite: 43911] train loss: 1.1821, accuracy: 95.7806%, tar: 0.0263 \n",
      "l0: 0.024825, l1: 0.025647, l2: 0.031565, l3: 0.045462, l4: 0.077232, l5: 0.141251, l6: 0.283740\n",
      "\n",
      "[epoch: 329/400, batch: 288/1000, ite: 43912] train loss: 1.1811, accuracy: 95.2053%, tar: 0.0263 \n",
      "l0: 0.023774, l1: 0.024808, l2: 0.030340, l3: 0.042331, l4: 0.071327, l5: 0.132590, l6: 0.259496\n",
      "\n",
      "[epoch: 329/400, batch: 296/1000, ite: 43913] train loss: 1.1800, accuracy: 96.5147%, tar: 0.0263 \n",
      "l0: 0.034314, l1: 0.035128, l2: 0.041929, l3: 0.056063, l4: 0.095892, l5: 0.177992, l6: 0.354792\n",
      "\n",
      "[epoch: 329/400, batch: 304/1000, ite: 43914] train loss: 1.1799, accuracy: 93.9331%, tar: 0.0264 \n",
      "l0: 0.023678, l1: 0.024548, l2: 0.032068, l3: 0.049643, l4: 0.097674, l5: 0.182839, l6: 0.349685\n",
      "\n",
      "[epoch: 329/400, batch: 312/1000, ite: 43915] train loss: 1.1797, accuracy: 94.8208%, tar: 0.0263 \n",
      "l0: 0.030296, l1: 0.030954, l2: 0.037408, l3: 0.050751, l4: 0.084955, l5: 0.169551, l6: 0.305392\n",
      "\n",
      "[epoch: 329/400, batch: 320/1000, ite: 43916] train loss: 1.1791, accuracy: 94.5755%, tar: 0.0264 \n",
      "l0: 0.021656, l1: 0.022907, l2: 0.028925, l3: 0.041787, l4: 0.076858, l5: 0.151807, l6: 0.319213\n",
      "\n",
      "[epoch: 329/400, batch: 328/1000, ite: 43917] train loss: 1.1785, accuracy: 95.7562%, tar: 0.0263 \n",
      "l0: 0.031631, l1: 0.032588, l2: 0.042572, l3: 0.061848, l4: 0.113282, l5: 0.211164, l6: 0.430720\n",
      "\n",
      "[epoch: 329/400, batch: 336/1000, ite: 43918] train loss: 1.1791, accuracy: 94.0418%, tar: 0.0264 \n",
      "l0: 0.025273, l1: 0.026426, l2: 0.034567, l3: 0.046252, l4: 0.079550, l5: 0.146977, l6: 0.284027\n",
      "\n",
      "[epoch: 329/400, batch: 344/1000, ite: 43919] train loss: 1.1782, accuracy: 95.4717%, tar: 0.0264 \n",
      "l0: 0.023214, l1: 0.024120, l2: 0.030830, l3: 0.043658, l4: 0.077069, l5: 0.150212, l6: 0.341664\n",
      "\n",
      "[epoch: 329/400, batch: 352/1000, ite: 43920] train loss: 1.1778, accuracy: 95.1358%, tar: 0.0263 \n",
      "l0: 0.030868, l1: 0.031820, l2: 0.041359, l3: 0.055656, l4: 0.103139, l5: 0.186631, l6: 0.372048\n",
      "\n",
      "[epoch: 329/400, batch: 360/1000, ite: 43921] train loss: 1.1778, accuracy: 95.0150%, tar: 0.0264 \n",
      "l0: 0.020956, l1: 0.022083, l2: 0.028094, l3: 0.039797, l4: 0.069957, l5: 0.124745, l6: 0.245137\n",
      "\n",
      "[epoch: 329/400, batch: 368/1000, ite: 43922] train loss: 1.1765, accuracy: 96.1432%, tar: 0.0263 \n",
      "l0: 0.022561, l1: 0.023688, l2: 0.030053, l3: 0.045895, l4: 0.079729, l5: 0.162754, l6: 0.358373\n",
      "\n",
      "[epoch: 329/400, batch: 376/1000, ite: 43923] train loss: 1.1762, accuracy: 95.1316%, tar: 0.0263 \n",
      "l0: 0.028944, l1: 0.030367, l2: 0.038222, l3: 0.054010, l4: 0.095581, l5: 0.195483, l6: 0.421352\n",
      "\n",
      "[epoch: 329/400, batch: 384/1000, ite: 43924] train loss: 1.1766, accuracy: 94.3508%, tar: 0.0263 \n",
      "l0: 0.029871, l1: 0.030545, l2: 0.034695, l3: 0.047694, l4: 0.075448, l5: 0.138263, l6: 0.280504\n",
      "\n",
      "[epoch: 329/400, batch: 392/1000, ite: 43925] train loss: 1.1758, accuracy: 95.1440%, tar: 0.0263 \n",
      "l0: 0.027233, l1: 0.028920, l2: 0.037566, l3: 0.057505, l4: 0.115769, l5: 0.270420, l6: 0.459045\n",
      "\n",
      "[epoch: 329/400, batch: 400/1000, ite: 43926] train loss: 1.1767, accuracy: 93.2632%, tar: 0.0264 \n",
      "l0: 0.023856, l1: 0.024934, l2: 0.033884, l3: 0.051648, l4: 0.101380, l5: 0.215317, l6: 0.379719\n",
      "\n",
      "[epoch: 329/400, batch: 408/1000, ite: 43927] train loss: 1.1769, accuracy: 94.2528%, tar: 0.0263 \n",
      "l0: 0.032302, l1: 0.034342, l2: 0.046133, l3: 0.077312, l4: 0.180901, l5: 0.325190, l6: 0.546219\n",
      "\n",
      "[epoch: 329/400, batch: 416/1000, ite: 43928] train loss: 1.1789, accuracy: 92.5866%, tar: 0.0264 \n",
      "l0: 0.025734, l1: 0.027376, l2: 0.035855, l3: 0.053297, l4: 0.103552, l5: 0.226677, l6: 0.511308\n",
      "\n",
      "[epoch: 329/400, batch: 424/1000, ite: 43929] train loss: 1.1799, accuracy: 94.9194%, tar: 0.0264 \n",
      "l0: 0.023346, l1: 0.024928, l2: 0.033811, l3: 0.052052, l4: 0.107833, l5: 0.209042, l6: 0.394049\n",
      "\n",
      "[epoch: 329/400, batch: 432/1000, ite: 43930] train loss: 1.1801, accuracy: 94.5124%, tar: 0.0264 \n",
      "l0: 0.021449, l1: 0.022485, l2: 0.028761, l3: 0.045636, l4: 0.081807, l5: 0.143910, l6: 0.362309\n",
      "\n",
      "[epoch: 329/400, batch: 440/1000, ite: 43931] train loss: 1.1798, accuracy: 94.4230%, tar: 0.0263 \n",
      "l0: 0.021803, l1: 0.023614, l2: 0.033363, l3: 0.056634, l4: 0.103065, l5: 0.190745, l6: 0.325198\n",
      "\n",
      "[epoch: 329/400, batch: 448/1000, ite: 43932] train loss: 1.1795, accuracy: 95.7739%, tar: 0.0263 \n",
      "l0: 0.022433, l1: 0.023831, l2: 0.032789, l3: 0.046518, l4: 0.083155, l5: 0.151140, l6: 0.277464\n",
      "\n",
      "[epoch: 329/400, batch: 456/1000, ite: 43933] train loss: 1.1786, accuracy: 95.6945%, tar: 0.0263 \n",
      "l0: 0.020289, l1: 0.021502, l2: 0.029685, l3: 0.047895, l4: 0.084021, l5: 0.191907, l6: 0.393047\n",
      "\n",
      "[epoch: 329/400, batch: 464/1000, ite: 43934] train loss: 1.1786, accuracy: 94.8614%, tar: 0.0263 \n",
      "l0: 0.030499, l1: 0.031620, l2: 0.039633, l3: 0.058928, l4: 0.101235, l5: 0.208848, l6: 0.444065\n",
      "\n",
      "[epoch: 329/400, batch: 472/1000, ite: 43935] train loss: 1.1792, accuracy: 92.8682%, tar: 0.0263 \n",
      "l0: 0.032567, l1: 0.033781, l2: 0.043019, l3: 0.065526, l4: 0.118064, l5: 0.248334, l6: 0.510213\n",
      "\n",
      "[epoch: 329/400, batch: 480/1000, ite: 43936] train loss: 1.1804, accuracy: 93.1699%, tar: 0.0263 \n",
      "l0: 0.021904, l1: 0.022895, l2: 0.028471, l3: 0.039669, l4: 0.073304, l5: 0.130495, l6: 0.256639\n",
      "\n",
      "[epoch: 329/400, batch: 488/1000, ite: 43937] train loss: 1.1793, accuracy: 96.1172%, tar: 0.0263 \n",
      "l0: 0.020918, l1: 0.021989, l2: 0.028249, l3: 0.044193, l4: 0.080500, l5: 0.147923, l6: 0.286352\n",
      "\n",
      "[epoch: 329/400, batch: 496/1000, ite: 43938] train loss: 1.1785, accuracy: 95.5583%, tar: 0.0263 \n",
      "l0: 0.029010, l1: 0.030477, l2: 0.038320, l3: 0.056420, l4: 0.114361, l5: 0.240021, l6: 0.425724\n",
      "\n",
      "[epoch: 329/400, batch: 504/1000, ite: 43939] train loss: 1.1791, accuracy: 93.6958%, tar: 0.0263 \n",
      "l0: 0.032881, l1: 0.034621, l2: 0.042634, l3: 0.060362, l4: 0.114792, l5: 0.228480, l6: 0.395624\n",
      "\n",
      "[epoch: 329/400, batch: 512/1000, ite: 43940] train loss: 1.1795, accuracy: 94.5504%, tar: 0.0263 \n",
      "l0: 0.022339, l1: 0.023739, l2: 0.031593, l3: 0.045971, l4: 0.074957, l5: 0.144801, l6: 0.310996\n",
      "\n",
      "[epoch: 329/400, batch: 520/1000, ite: 43941] train loss: 1.1788, accuracy: 95.5294%, tar: 0.0263 \n",
      "l0: 0.024552, l1: 0.026111, l2: 0.032692, l3: 0.048490, l4: 0.089138, l5: 0.150584, l6: 0.309580\n",
      "\n",
      "[epoch: 329/400, batch: 528/1000, ite: 43942] train loss: 1.1783, accuracy: 94.8380%, tar: 0.0263 \n",
      "l0: 0.024706, l1: 0.025781, l2: 0.034418, l3: 0.052470, l4: 0.099373, l5: 0.205665, l6: 0.420455\n",
      "\n",
      "[epoch: 329/400, batch: 536/1000, ite: 43943] train loss: 1.1786, accuracy: 94.5711%, tar: 0.0263 \n",
      "l0: 0.022648, l1: 0.023506, l2: 0.028964, l3: 0.043403, l4: 0.072950, l5: 0.127384, l6: 0.273988\n",
      "\n",
      "[epoch: 329/400, batch: 544/1000, ite: 43944] train loss: 1.1776, accuracy: 95.4722%, tar: 0.0263 \n",
      "l0: 0.025510, l1: 0.026885, l2: 0.035066, l3: 0.047562, l4: 0.081438, l5: 0.141458, l6: 0.276220\n",
      "\n",
      "[epoch: 329/400, batch: 552/1000, ite: 43945] train loss: 1.1768, accuracy: 95.7557%, tar: 0.0263 \n",
      "l0: 0.025062, l1: 0.026138, l2: 0.032523, l3: 0.044783, l4: 0.070219, l5: 0.136567, l6: 0.301276\n",
      "\n",
      "[epoch: 329/400, batch: 560/1000, ite: 43946] train loss: 1.1761, accuracy: 95.5016%, tar: 0.0263 \n",
      "l0: 0.024616, l1: 0.025935, l2: 0.034543, l3: 0.051141, l4: 0.090244, l5: 0.164906, l6: 0.321853\n",
      "\n",
      "[epoch: 329/400, batch: 568/1000, ite: 43947] train loss: 1.1757, accuracy: 95.4112%, tar: 0.0263 \n",
      "l0: 0.027739, l1: 0.029378, l2: 0.036841, l3: 0.053357, l4: 0.099433, l5: 0.193082, l6: 0.360949\n",
      "\n",
      "[epoch: 329/400, batch: 576/1000, ite: 43948] train loss: 1.1756, accuracy: 94.6057%, tar: 0.0263 \n",
      "l0: 0.027450, l1: 0.028252, l2: 0.036831, l3: 0.054972, l4: 0.099061, l5: 0.183941, l6: 0.329251\n",
      "\n",
      "[epoch: 329/400, batch: 584/1000, ite: 43949] train loss: 1.1754, accuracy: 95.2118%, tar: 0.0263 \n",
      "l0: 0.022742, l1: 0.024000, l2: 0.031245, l3: 0.046984, l4: 0.082007, l5: 0.156516, l6: 0.323276\n",
      "\n",
      "[epoch: 329/400, batch: 592/1000, ite: 43950] train loss: 1.1749, accuracy: 95.5593%, tar: 0.0263 \n",
      "l0: 0.032139, l1: 0.033457, l2: 0.040433, l3: 0.063766, l4: 0.113417, l5: 0.240011, l6: 0.459034\n",
      "\n",
      "[epoch: 329/400, batch: 600/1000, ite: 43951] train loss: 1.1757, accuracy: 93.3077%, tar: 0.0263 \n",
      "l0: 0.025892, l1: 0.027825, l2: 0.036540, l3: 0.053948, l4: 0.096263, l5: 0.172341, l6: 0.432486\n",
      "\n",
      "[epoch: 329/400, batch: 608/1000, ite: 43952] train loss: 1.1760, accuracy: 94.9952%, tar: 0.0263 \n",
      "l0: 0.021103, l1: 0.021664, l2: 0.028649, l3: 0.039698, l4: 0.066768, l5: 0.110562, l6: 0.205214\n",
      "\n",
      "[epoch: 329/400, batch: 616/1000, ite: 43953] train loss: 1.1746, accuracy: 96.3585%, tar: 0.0263 \n",
      "l0: 0.030822, l1: 0.033407, l2: 0.042365, l3: 0.067914, l4: 0.128662, l5: 0.232424, l6: 0.467906\n",
      "\n",
      "[epoch: 329/400, batch: 624/1000, ite: 43954] train loss: 1.1755, accuracy: 94.4920%, tar: 0.0263 \n",
      "l0: 0.026825, l1: 0.027737, l2: 0.035412, l3: 0.051458, l4: 0.091225, l5: 0.170518, l6: 0.361075\n",
      "\n",
      "[epoch: 329/400, batch: 632/1000, ite: 43955] train loss: 1.1753, accuracy: 94.2301%, tar: 0.0263 \n",
      "l0: 0.024645, l1: 0.025431, l2: 0.031901, l3: 0.044874, l4: 0.083714, l5: 0.180851, l6: 0.357340\n",
      "\n",
      "[epoch: 329/400, batch: 640/1000, ite: 43956] train loss: 1.1751, accuracy: 94.8972%, tar: 0.0263 \n",
      "l0: 0.022466, l1: 0.024051, l2: 0.030873, l3: 0.045589, l4: 0.079523, l5: 0.143486, l6: 0.332653\n",
      "\n",
      "[epoch: 329/400, batch: 648/1000, ite: 43957] train loss: 1.1746, accuracy: 95.3417%, tar: 0.0263 \n",
      "l0: 0.033233, l1: 0.034510, l2: 0.043253, l3: 0.059575, l4: 0.099250, l5: 0.212692, l6: 0.377013\n",
      "\n",
      "[epoch: 329/400, batch: 656/1000, ite: 43958] train loss: 1.1748, accuracy: 94.0191%, tar: 0.0263 \n",
      "l0: 0.027738, l1: 0.028914, l2: 0.037106, l3: 0.051990, l4: 0.090718, l5: 0.186563, l6: 0.389778\n",
      "\n",
      "[epoch: 329/400, batch: 664/1000, ite: 43959] train loss: 1.1749, accuracy: 94.6431%, tar: 0.0263 \n",
      "l0: 0.024141, l1: 0.025199, l2: 0.031973, l3: 0.044482, l4: 0.081844, l5: 0.196136, l6: 0.417610\n",
      "\n",
      "[epoch: 329/400, batch: 672/1000, ite: 43960] train loss: 1.1751, accuracy: 94.0929%, tar: 0.0263 \n",
      "l0: 0.030479, l1: 0.032053, l2: 0.040027, l3: 0.056756, l4: 0.099808, l5: 0.190447, l6: 0.443305\n",
      "\n",
      "[epoch: 329/400, batch: 680/1000, ite: 43961] train loss: 1.1756, accuracy: 93.9944%, tar: 0.0263 \n",
      "l0: 0.025876, l1: 0.027246, l2: 0.034414, l3: 0.048504, l4: 0.090426, l5: 0.189444, l6: 0.457717\n",
      "\n",
      "[epoch: 329/400, batch: 688/1000, ite: 43962] train loss: 1.1761, accuracy: 94.1138%, tar: 0.0263 \n",
      "l0: 0.024927, l1: 0.026393, l2: 0.036186, l3: 0.053618, l4: 0.091299, l5: 0.165698, l6: 0.342133\n",
      "\n",
      "[epoch: 329/400, batch: 696/1000, ite: 43963] train loss: 1.1758, accuracy: 95.6053%, tar: 0.0263 \n",
      "l0: 0.024396, l1: 0.025444, l2: 0.032660, l3: 0.045557, l4: 0.073517, l5: 0.146557, l6: 0.328247\n",
      "\n",
      "[epoch: 329/400, batch: 704/1000, ite: 43964] train loss: 1.1753, accuracy: 94.7034%, tar: 0.0263 \n",
      "l0: 0.024379, l1: 0.025735, l2: 0.035447, l3: 0.053061, l4: 0.097858, l5: 0.180179, l6: 0.392263\n",
      "\n",
      "[epoch: 329/400, batch: 712/1000, ite: 43965] train loss: 1.1754, accuracy: 95.3910%, tar: 0.0263 \n",
      "l0: 0.028652, l1: 0.030391, l2: 0.041599, l3: 0.061796, l4: 0.111580, l5: 0.207343, l6: 0.396520\n",
      "\n",
      "[epoch: 329/400, batch: 720/1000, ite: 43966] train loss: 1.1757, accuracy: 95.1560%, tar: 0.0263 \n",
      "l0: 0.036628, l1: 0.038081, l2: 0.049088, l3: 0.069680, l4: 0.133437, l5: 0.285432, l6: 0.529887\n",
      "\n",
      "[epoch: 329/400, batch: 728/1000, ite: 43967] train loss: 1.1772, accuracy: 91.9004%, tar: 0.0263 \n",
      "l0: 0.027229, l1: 0.028746, l2: 0.036690, l3: 0.052404, l4: 0.095693, l5: 0.175948, l6: 0.381748\n",
      "\n",
      "[epoch: 329/400, batch: 736/1000, ite: 43968] train loss: 1.1772, accuracy: 94.8838%, tar: 0.0263 \n",
      "l0: 0.029858, l1: 0.031476, l2: 0.041439, l3: 0.059276, l4: 0.109338, l5: 0.226796, l6: 0.518381\n",
      "\n",
      "[epoch: 329/400, batch: 744/1000, ite: 43969] train loss: 1.1783, accuracy: 93.3505%, tar: 0.0263 \n",
      "l0: 0.028062, l1: 0.028997, l2: 0.034844, l3: 0.046452, l4: 0.084739, l5: 0.176262, l6: 0.347284\n",
      "\n",
      "[epoch: 329/400, batch: 752/1000, ite: 43970] train loss: 1.1780, accuracy: 94.7756%, tar: 0.0263 \n",
      "l0: 0.021859, l1: 0.022859, l2: 0.029842, l3: 0.041565, l4: 0.073520, l5: 0.125446, l6: 0.262106\n",
      "\n",
      "[epoch: 329/400, batch: 760/1000, ite: 43971] train loss: 1.1771, accuracy: 96.1920%, tar: 0.0263 \n",
      "l0: 0.022836, l1: 0.023808, l2: 0.031828, l3: 0.048387, l4: 0.080311, l5: 0.157283, l6: 0.339884\n",
      "\n",
      "[epoch: 329/400, batch: 768/1000, ite: 43972] train loss: 1.1767, accuracy: 94.8836%, tar: 0.0263 \n",
      "l0: 0.024543, l1: 0.026402, l2: 0.033933, l3: 0.050887, l4: 0.078428, l5: 0.149742, l6: 0.349625\n",
      "\n",
      "[epoch: 329/400, batch: 776/1000, ite: 43973] train loss: 1.1764, accuracy: 95.9541%, tar: 0.0263 \n",
      "l0: 0.028225, l1: 0.029684, l2: 0.037362, l3: 0.061249, l4: 0.104242, l5: 0.191997, l6: 0.378427\n",
      "\n",
      "[epoch: 329/400, batch: 784/1000, ite: 43974] train loss: 1.1765, accuracy: 95.3858%, tar: 0.0263 \n",
      "l0: 0.032603, l1: 0.033795, l2: 0.041196, l3: 0.053488, l4: 0.087289, l5: 0.158535, l6: 0.365481\n",
      "\n",
      "[epoch: 329/400, batch: 792/1000, ite: 43975] train loss: 1.1764, accuracy: 93.9797%, tar: 0.0263 \n",
      "l0: 0.035177, l1: 0.037007, l2: 0.046232, l3: 0.072637, l4: 0.136963, l5: 0.284839, l6: 0.565857\n",
      "\n",
      "[epoch: 329/400, batch: 800/1000, ite: 43976] train loss: 1.1781, accuracy: 92.0856%, tar: 0.0264 \n",
      "l0: 0.024185, l1: 0.025397, l2: 0.032864, l3: 0.046854, l4: 0.081200, l5: 0.173953, l6: 0.369245\n",
      "\n",
      "[epoch: 329/400, batch: 808/1000, ite: 43977] train loss: 1.1779, accuracy: 94.7977%, tar: 0.0264 \n",
      "l0: 0.017889, l1: 0.018711, l2: 0.025749, l3: 0.036023, l4: 0.061434, l5: 0.113251, l6: 0.240762\n",
      "\n",
      "[epoch: 329/400, batch: 816/1000, ite: 43978] train loss: 1.1767, accuracy: 96.2791%, tar: 0.0263 \n",
      "l0: 0.025223, l1: 0.026994, l2: 0.034113, l3: 0.049968, l4: 0.087854, l5: 0.161164, l6: 0.365023\n",
      "\n",
      "[epoch: 329/400, batch: 824/1000, ite: 43979] train loss: 1.1766, accuracy: 95.3688%, tar: 0.0263 \n",
      "l0: 0.041186, l1: 0.043614, l2: 0.053024, l3: 0.072737, l4: 0.133393, l5: 0.300709, l6: 0.539071\n",
      "\n",
      "[epoch: 329/400, batch: 832/1000, ite: 43980] train loss: 1.1782, accuracy: 92.9029%, tar: 0.0264 \n",
      "l0: 0.041421, l1: 0.043486, l2: 0.053934, l3: 0.074602, l4: 0.125182, l5: 0.242708, l6: 0.505283\n",
      "\n",
      "[epoch: 329/400, batch: 840/1000, ite: 43981] train loss: 1.1793, accuracy: 93.6732%, tar: 0.0264 \n",
      "l0: 0.027827, l1: 0.029322, l2: 0.037661, l3: 0.054109, l4: 0.100615, l5: 0.187245, l6: 0.354941\n",
      "\n",
      "[epoch: 329/400, batch: 848/1000, ite: 43982] train loss: 1.1792, accuracy: 95.4254%, tar: 0.0264 \n",
      "l0: 0.032483, l1: 0.033060, l2: 0.040173, l3: 0.055366, l4: 0.096956, l5: 0.191247, l6: 0.429008\n",
      "\n",
      "[epoch: 329/400, batch: 856/1000, ite: 43983] train loss: 1.1796, accuracy: 94.1528%, tar: 0.0264 \n",
      "l0: 0.025029, l1: 0.025976, l2: 0.031779, l3: 0.048808, l4: 0.086856, l5: 0.179653, l6: 0.394223\n",
      "\n",
      "[epoch: 329/400, batch: 864/1000, ite: 43984] train loss: 1.1796, accuracy: 94.3294%, tar: 0.0264 \n",
      "l0: 0.025475, l1: 0.026193, l2: 0.031863, l3: 0.043442, l4: 0.080246, l5: 0.136320, l6: 0.269124\n",
      "\n",
      "[epoch: 329/400, batch: 872/1000, ite: 43985] train loss: 1.1788, accuracy: 95.5935%, tar: 0.0264 \n",
      "l0: 0.034746, l1: 0.036843, l2: 0.044009, l3: 0.061077, l4: 0.110327, l5: 0.193017, l6: 0.428529\n",
      "\n",
      "[epoch: 329/400, batch: 880/1000, ite: 43986] train loss: 1.1792, accuracy: 93.8809%, tar: 0.0265 \n",
      "l0: 0.027264, l1: 0.027955, l2: 0.035062, l3: 0.044462, l4: 0.072755, l5: 0.164878, l6: 0.341397\n",
      "\n",
      "[epoch: 329/400, batch: 888/1000, ite: 43987] train loss: 1.1789, accuracy: 94.7538%, tar: 0.0265 \n",
      "l0: 0.024562, l1: 0.026397, l2: 0.036119, l3: 0.057434, l4: 0.108567, l5: 0.197560, l6: 0.362331\n",
      "\n",
      "[epoch: 329/400, batch: 896/1000, ite: 43988] train loss: 1.1789, accuracy: 95.6402%, tar: 0.0264 \n",
      "l0: 0.029634, l1: 0.031215, l2: 0.038252, l3: 0.056297, l4: 0.105254, l5: 0.233037, l6: 0.434262\n",
      "\n",
      "[epoch: 329/400, batch: 904/1000, ite: 43989] train loss: 1.1794, accuracy: 94.0277%, tar: 0.0265 \n",
      "l0: 0.028968, l1: 0.030354, l2: 0.039299, l3: 0.054107, l4: 0.090134, l5: 0.180827, l6: 0.323999\n",
      "\n",
      "[epoch: 329/400, batch: 912/1000, ite: 43990] train loss: 1.1791, accuracy: 95.3441%, tar: 0.0265 \n",
      "l0: 0.024821, l1: 0.026271, l2: 0.033743, l3: 0.050976, l4: 0.094609, l5: 0.172265, l6: 0.376512\n",
      "\n",
      "[epoch: 329/400, batch: 920/1000, ite: 43991] train loss: 1.1791, accuracy: 95.1689%, tar: 0.0265 \n",
      "l0: 0.020627, l1: 0.021922, l2: 0.029775, l3: 0.043919, l4: 0.086311, l5: 0.167314, l6: 0.333547\n",
      "\n",
      "[epoch: 329/400, batch: 928/1000, ite: 43992] train loss: 1.1787, accuracy: 95.3237%, tar: 0.0264 \n",
      "l0: 0.031222, l1: 0.033340, l2: 0.041827, l3: 0.062653, l4: 0.113504, l5: 0.216863, l6: 0.383769\n",
      "\n",
      "[epoch: 329/400, batch: 936/1000, ite: 43993] train loss: 1.1790, accuracy: 94.5472%, tar: 0.0265 \n",
      "l0: 0.027865, l1: 0.029041, l2: 0.037705, l3: 0.054815, l4: 0.104607, l5: 0.211928, l6: 0.366128\n",
      "\n",
      "[epoch: 329/400, batch: 944/1000, ite: 43994] train loss: 1.1790, accuracy: 94.3352%, tar: 0.0265 \n",
      "l0: 0.028164, l1: 0.029268, l2: 0.037753, l3: 0.054027, l4: 0.096894, l5: 0.186343, l6: 0.446168\n",
      "\n",
      "[epoch: 329/400, batch: 952/1000, ite: 43995] train loss: 1.1794, accuracy: 94.2591%, tar: 0.0265 \n",
      "l0: 0.027685, l1: 0.028861, l2: 0.035498, l3: 0.050080, l4: 0.095175, l5: 0.201304, l6: 0.369032\n",
      "\n",
      "[epoch: 329/400, batch: 960/1000, ite: 43996] train loss: 1.1794, accuracy: 94.2636%, tar: 0.0265 \n",
      "l0: 0.028366, l1: 0.030097, l2: 0.038655, l3: 0.063409, l4: 0.123195, l5: 0.257752, l6: 0.443348\n",
      "\n",
      "[epoch: 329/400, batch: 968/1000, ite: 43997] train loss: 1.1801, accuracy: 94.2388%, tar: 0.0265 \n",
      "l0: 0.030483, l1: 0.033114, l2: 0.044113, l3: 0.069261, l4: 0.140718, l5: 0.262159, l6: 0.491962\n",
      "\n",
      "[epoch: 329/400, batch: 976/1000, ite: 43998] train loss: 1.1811, accuracy: 94.3063%, tar: 0.0265 \n",
      "l0: 0.031284, l1: 0.032491, l2: 0.040734, l3: 0.056646, l4: 0.096740, l5: 0.200527, l6: 0.467115\n",
      "\n",
      "[epoch: 329/400, batch: 984/1000, ite: 43999] train loss: 1.1817, accuracy: 93.3991%, tar: 0.0265 \n",
      "l0: 0.024959, l1: 0.026465, l2: 0.034608, l3: 0.050857, l4: 0.087581, l5: 0.154541, l6: 0.276534\n",
      "\n",
      "[epoch: 329/400, batch: 992/1000, ite: 44000] train loss: 1.1811, accuracy: 96.2205%, tar: 0.0265 \n",
      "l0: 0.026457, l1: 0.027808, l2: 0.035813, l3: 0.052979, l4: 0.097025, l5: 0.189467, l6: 0.367954\n",
      "\n",
      "[epoch: 329/400, batch: 1000/1000, ite: 44001] train loss: 1.1703, accuracy: 95.1563%, tar: 0.0265 \n",
      "l0: 0.022264, l1: 0.023973, l2: 0.031895, l3: 0.045476, l4: 0.086454, l5: 0.172548, l6: 0.384313\n",
      "\n",
      "[epoch: 330/400, batch: 8/1000, ite: 44002] train loss: 1.1622, accuracy: 95.0423%, tar: 0.0244 \n",
      "l0: 0.025545, l1: 0.027143, l2: 0.034920, l3: 0.051337, l4: 0.095723, l5: 0.197459, l6: 0.371762\n",
      "\n",
      "[epoch: 330/400, batch: 16/1000, ite: 44003] train loss: 1.1674, accuracy: 95.1248%, tar: 0.0248 \n",
      "l0: 0.024602, l1: 0.026111, l2: 0.034753, l3: 0.050560, l4: 0.092843, l5: 0.167202, l6: 0.310815\n",
      "\n",
      "[epoch: 330/400, batch: 24/1000, ite: 44004] train loss: 1.1318, accuracy: 95.0457%, tar: 0.0247 \n",
      "l0: 0.027218, l1: 0.028842, l2: 0.037412, l3: 0.052251, l4: 0.096032, l5: 0.200460, l6: 0.382274\n",
      "\n",
      "[epoch: 330/400, batch: 32/1000, ite: 44005] train loss: 1.1496, accuracy: 94.5927%, tar: 0.0252 \n",
      "l0: 0.024426, l1: 0.025423, l2: 0.032289, l3: 0.048730, l4: 0.089831, l5: 0.174805, l6: 0.358319\n",
      "\n",
      "[epoch: 330/400, batch: 40/1000, ite: 44006] train loss: 1.1449, accuracy: 94.8658%, tar: 0.0251 \n",
      "l0: 0.024589, l1: 0.025391, l2: 0.032035, l3: 0.043282, l4: 0.080363, l5: 0.134106, l6: 0.252107\n",
      "\n",
      "[epoch: 330/400, batch: 48/1000, ite: 44007] train loss: 1.1025, accuracy: 95.9398%, tar: 0.0250 \n",
      "l0: 0.022740, l1: 0.023742, l2: 0.029824, l3: 0.042481, l4: 0.075291, l5: 0.140216, l6: 0.288037\n",
      "\n",
      "[epoch: 330/400, batch: 56/1000, ite: 44008] train loss: 1.0792, accuracy: 95.2249%, tar: 0.0247 \n",
      "l0: 0.027534, l1: 0.029384, l2: 0.039449, l3: 0.062160, l4: 0.121083, l5: 0.244795, l6: 0.473219\n",
      "\n",
      "[epoch: 330/400, batch: 64/1000, ite: 44009] train loss: 1.1234, accuracy: 93.7764%, tar: 0.0250 \n",
      "l0: 0.030277, l1: 0.032438, l2: 0.041892, l3: 0.060372, l4: 0.112917, l5: 0.237014, l6: 0.445586\n",
      "\n",
      "[epoch: 330/400, batch: 72/1000, ite: 44010] train loss: 1.1520, accuracy: 93.7752%, tar: 0.0256 \n",
      "l0: 0.042776, l1: 0.044862, l2: 0.054632, l3: 0.074155, l4: 0.133501, l5: 0.290492, l6: 0.689579\n",
      "\n",
      "[epoch: 330/400, batch: 80/1000, ite: 44011] train loss: 1.2300, accuracy: 90.5739%, tar: 0.0271 \n",
      "l0: 0.022295, l1: 0.022921, l2: 0.028007, l3: 0.038893, l4: 0.062855, l5: 0.106932, l6: 0.241530\n",
      "\n",
      "[epoch: 330/400, batch: 88/1000, ite: 44012] train loss: 1.1914, accuracy: 95.6986%, tar: 0.0267 \n",
      "l0: 0.032013, l1: 0.033773, l2: 0.042518, l3: 0.061237, l4: 0.111647, l5: 0.221235, l6: 0.461727\n",
      "\n",
      "[epoch: 330/400, batch: 96/1000, ite: 44013] train loss: 1.2101, accuracy: 93.1616%, tar: 0.0271 \n",
      "l0: 0.024629, l1: 0.026160, l2: 0.035956, l3: 0.054509, l4: 0.096965, l5: 0.195199, l6: 0.467443\n",
      "\n",
      "[epoch: 330/400, batch: 104/1000, ite: 44014] train loss: 1.2218, accuracy: 93.2811%, tar: 0.0270 \n",
      "l0: 0.030539, l1: 0.031928, l2: 0.039956, l3: 0.056993, l4: 0.100656, l5: 0.181266, l6: 0.319962\n",
      "\n",
      "[epoch: 330/400, batch: 112/1000, ite: 44015] train loss: 1.2130, accuracy: 95.0319%, tar: 0.0272 \n",
      "l0: 0.034998, l1: 0.036481, l2: 0.043787, l3: 0.058866, l4: 0.096186, l5: 0.177958, l6: 0.341866\n",
      "\n",
      "[epoch: 330/400, batch: 120/1000, ite: 44016] train loss: 1.2086, accuracy: 94.7769%, tar: 0.0277 \n",
      "l0: 0.018759, l1: 0.019608, l2: 0.027124, l3: 0.043187, l4: 0.071136, l5: 0.135832, l6: 0.371067\n",
      "\n",
      "[epoch: 330/400, batch: 128/1000, ite: 44017] train loss: 1.1999, accuracy: 95.5127%, tar: 0.0272 \n",
      "l0: 0.019980, l1: 0.020474, l2: 0.026260, l3: 0.037234, l4: 0.063902, l5: 0.123912, l6: 0.231654\n",
      "\n",
      "[epoch: 330/400, batch: 136/1000, ite: 44018] train loss: 1.1751, accuracy: 95.9775%, tar: 0.0268 \n",
      "l0: 0.028522, l1: 0.029697, l2: 0.038911, l3: 0.059652, l4: 0.107988, l5: 0.227821, l6: 0.499900\n",
      "\n",
      "[epoch: 330/400, batch: 144/1000, ite: 44019] train loss: 1.1920, accuracy: 93.6198%, tar: 0.0269 \n",
      "l0: 0.024500, l1: 0.026137, l2: 0.034254, l3: 0.050014, l4: 0.088632, l5: 0.196539, l6: 0.402011\n",
      "\n",
      "[epoch: 330/400, batch: 152/1000, ite: 44020] train loss: 1.1938, accuracy: 95.1741%, tar: 0.0267 \n",
      "l0: 0.027683, l1: 0.029288, l2: 0.038317, l3: 0.055061, l4: 0.090636, l5: 0.164863, l6: 0.331802\n",
      "\n",
      "[epoch: 330/400, batch: 160/1000, ite: 44021] train loss: 1.1884, accuracy: 94.7480%, tar: 0.0268 \n",
      "l0: 0.022965, l1: 0.024118, l2: 0.031407, l3: 0.042682, l4: 0.080287, l5: 0.168623, l6: 0.374397\n",
      "\n",
      "[epoch: 330/400, batch: 168/1000, ite: 44022] train loss: 1.1854, accuracy: 95.2986%, tar: 0.0266 \n",
      "l0: 0.028159, l1: 0.029485, l2: 0.037212, l3: 0.051234, l4: 0.086709, l5: 0.153136, l6: 0.316164\n",
      "\n",
      "[epoch: 330/400, batch: 176/1000, ite: 44023] train loss: 1.1783, accuracy: 95.6565%, tar: 0.0267 \n",
      "l0: 0.020340, l1: 0.021731, l2: 0.029520, l3: 0.047032, l4: 0.085679, l5: 0.160512, l6: 0.322303\n",
      "\n",
      "[epoch: 330/400, batch: 184/1000, ite: 44024] train loss: 1.1715, accuracy: 95.3064%, tar: 0.0264 \n",
      "l0: 0.029926, l1: 0.033089, l2: 0.047258, l3: 0.073962, l4: 0.142576, l5: 0.274669, l6: 0.497450\n",
      "\n",
      "[epoch: 330/400, batch: 192/1000, ite: 44025] train loss: 1.1889, accuracy: 94.2070%, tar: 0.0265 \n",
      "l0: 0.025027, l1: 0.026679, l2: 0.034671, l3: 0.050538, l4: 0.095858, l5: 0.194673, l6: 0.406940\n",
      "\n",
      "[epoch: 330/400, batch: 200/1000, ite: 44026] train loss: 1.1910, accuracy: 94.2206%, tar: 0.0265 \n",
      "l0: 0.036431, l1: 0.038002, l2: 0.044479, l3: 0.061905, l4: 0.113761, l5: 0.226230, l6: 0.510458\n",
      "\n",
      "[epoch: 330/400, batch: 208/1000, ite: 44027] train loss: 1.2043, accuracy: 92.4759%, tar: 0.0269 \n",
      "l0: 0.027871, l1: 0.028699, l2: 0.038103, l3: 0.060548, l4: 0.110154, l5: 0.194958, l6: 0.412361\n",
      "\n",
      "[epoch: 330/400, batch: 216/1000, ite: 44028] train loss: 1.2074, accuracy: 94.4134%, tar: 0.0269 \n",
      "l0: 0.027769, l1: 0.028938, l2: 0.034747, l3: 0.044062, l4: 0.069089, l5: 0.133349, l6: 0.332820\n",
      "\n",
      "[epoch: 330/400, batch: 224/1000, ite: 44029] train loss: 1.2009, accuracy: 94.8667%, tar: 0.0269 \n",
      "l0: 0.026237, l1: 0.027950, l2: 0.034303, l3: 0.050327, l4: 0.092495, l5: 0.173934, l6: 0.339976\n",
      "\n",
      "[epoch: 330/400, batch: 232/1000, ite: 44030] train loss: 1.1972, accuracy: 94.9014%, tar: 0.0269 \n",
      "l0: 0.026969, l1: 0.028000, l2: 0.037020, l3: 0.048354, l4: 0.080263, l5: 0.164368, l6: 0.293048\n",
      "\n",
      "[epoch: 330/400, batch: 240/1000, ite: 44031] train loss: 1.1900, accuracy: 95.7205%, tar: 0.0269 \n",
      "l0: 0.022335, l1: 0.022979, l2: 0.030662, l3: 0.045052, l4: 0.079136, l5: 0.147449, l6: 0.317990\n",
      "\n",
      "[epoch: 330/400, batch: 248/1000, ite: 44032] train loss: 1.1838, accuracy: 95.0335%, tar: 0.0268 \n",
      "l0: 0.028154, l1: 0.029183, l2: 0.035887, l3: 0.050603, l4: 0.088390, l5: 0.174200, l6: 0.433502\n",
      "\n",
      "[epoch: 330/400, batch: 256/1000, ite: 44033] train loss: 1.1867, accuracy: 93.8700%, tar: 0.0268 \n",
      "l0: 0.025952, l1: 0.027688, l2: 0.035831, l3: 0.054125, l4: 0.103069, l5: 0.244722, l6: 0.460010\n",
      "\n",
      "[epoch: 330/400, batch: 264/1000, ite: 44034] train loss: 1.1935, accuracy: 93.6253%, tar: 0.0268 \n",
      "l0: 0.026098, l1: 0.027636, l2: 0.034632, l3: 0.056441, l4: 0.093057, l5: 0.194777, l6: 0.446100\n",
      "\n",
      "[epoch: 330/400, batch: 272/1000, ite: 44035] train loss: 1.1973, accuracy: 94.2091%, tar: 0.0268 \n",
      "l0: 0.025947, l1: 0.027988, l2: 0.037259, l3: 0.058254, l4: 0.111935, l5: 0.224258, l6: 0.418417\n",
      "\n",
      "[epoch: 330/400, batch: 280/1000, ite: 44036] train loss: 1.2009, accuracy: 94.8856%, tar: 0.0267 \n",
      "l0: 0.026974, l1: 0.028373, l2: 0.036881, l3: 0.055061, l4: 0.095324, l5: 0.169093, l6: 0.311889\n",
      "\n",
      "[epoch: 330/400, batch: 288/1000, ite: 44037] train loss: 1.1967, accuracy: 95.0555%, tar: 0.0267 \n",
      "l0: 0.031147, l1: 0.033291, l2: 0.041189, l3: 0.063757, l4: 0.118613, l5: 0.229412, l6: 0.408124\n",
      "\n",
      "[epoch: 330/400, batch: 296/1000, ite: 44038] train loss: 1.2004, accuracy: 94.2179%, tar: 0.0269 \n",
      "l0: 0.027160, l1: 0.027920, l2: 0.035291, l3: 0.050069, l4: 0.087836, l5: 0.162809, l6: 0.394995\n",
      "\n",
      "[epoch: 330/400, batch: 304/1000, ite: 44039] train loss: 1.2000, accuracy: 94.2425%, tar: 0.0269 \n",
      "l0: 0.029793, l1: 0.030724, l2: 0.040703, l3: 0.056215, l4: 0.104130, l5: 0.189129, l6: 0.352201\n",
      "\n",
      "[epoch: 330/400, batch: 312/1000, ite: 44040] train loss: 1.1991, accuracy: 94.6851%, tar: 0.0269 \n",
      "l0: 0.027586, l1: 0.028605, l2: 0.036517, l3: 0.048851, l4: 0.091496, l5: 0.203990, l6: 0.535654\n",
      "\n",
      "[epoch: 330/400, batch: 320/1000, ite: 44041] train loss: 1.2066, accuracy: 93.2211%, tar: 0.0270 \n",
      "l0: 0.023837, l1: 0.025341, l2: 0.036551, l3: 0.053306, l4: 0.097490, l5: 0.178362, l6: 0.313854\n",
      "\n",
      "[epoch: 330/400, batch: 328/1000, ite: 44042] train loss: 1.2029, accuracy: 95.4342%, tar: 0.0269 \n",
      "l0: 0.018766, l1: 0.020057, l2: 0.027342, l3: 0.043999, l4: 0.112006, l5: 0.163881, l6: 0.385509\n",
      "\n",
      "[epoch: 330/400, batch: 336/1000, ite: 44043] train loss: 1.2019, accuracy: 96.0226%, tar: 0.0267 \n",
      "l0: 0.021256, l1: 0.022123, l2: 0.030046, l3: 0.041214, l4: 0.061728, l5: 0.100538, l6: 0.251154\n",
      "\n",
      "[epoch: 330/400, batch: 344/1000, ite: 44044] train loss: 1.1924, accuracy: 96.4459%, tar: 0.0266 \n",
      "l0: 0.029155, l1: 0.030728, l2: 0.039103, l3: 0.055787, l4: 0.094905, l5: 0.185395, l6: 0.407499\n",
      "\n",
      "[epoch: 330/400, batch: 352/1000, ite: 44045] train loss: 1.1938, accuracy: 93.9008%, tar: 0.0266 \n",
      "l0: 0.028080, l1: 0.029495, l2: 0.036516, l3: 0.050760, l4: 0.084534, l5: 0.160994, l6: 0.312243\n",
      "\n",
      "[epoch: 330/400, batch: 360/1000, ite: 44046] train loss: 1.1902, accuracy: 95.1112%, tar: 0.0267 \n",
      "l0: 0.027713, l1: 0.029527, l2: 0.039705, l3: 0.061946, l4: 0.125289, l5: 0.240042, l6: 0.461444\n",
      "\n",
      "[epoch: 330/400, batch: 368/1000, ite: 44047] train loss: 1.1956, accuracy: 94.1957%, tar: 0.0267 \n",
      "l0: 0.024141, l1: 0.026113, l2: 0.035534, l3: 0.058881, l4: 0.140324, l5: 0.278774, l6: 0.524932\n",
      "\n",
      "[epoch: 330/400, batch: 376/1000, ite: 44048] train loss: 1.2045, accuracy: 93.7204%, tar: 0.0266 \n",
      "l0: 0.029394, l1: 0.031815, l2: 0.039538, l3: 0.058940, l4: 0.102211, l5: 0.192514, l6: 0.391123\n",
      "\n",
      "[epoch: 330/400, batch: 384/1000, ite: 44049] train loss: 1.2052, accuracy: 94.3460%, tar: 0.0267 \n",
      "l0: 0.026734, l1: 0.027753, l2: 0.038527, l3: 0.052681, l4: 0.091507, l5: 0.191961, l6: 0.391811\n",
      "\n",
      "[epoch: 330/400, batch: 392/1000, ite: 44050] train loss: 1.2054, accuracy: 94.2738%, tar: 0.0267 \n",
      "l0: 0.029205, l1: 0.030524, l2: 0.037296, l3: 0.053775, l4: 0.109040, l5: 0.238321, l6: 0.519818\n",
      "\n",
      "[epoch: 330/400, batch: 400/1000, ite: 44051] train loss: 1.2118, accuracy: 94.0706%, tar: 0.0267 \n",
      "l0: 0.028410, l1: 0.029024, l2: 0.036388, l3: 0.050543, l4: 0.088252, l5: 0.158804, l6: 0.325490\n",
      "\n",
      "[epoch: 330/400, batch: 408/1000, ite: 44052] train loss: 1.2086, accuracy: 95.1163%, tar: 0.0268 \n",
      "l0: 0.031212, l1: 0.032988, l2: 0.042977, l3: 0.063488, l4: 0.126103, l5: 0.303341, l6: 0.533789\n",
      "\n",
      "[epoch: 330/400, batch: 416/1000, ite: 44053] train loss: 1.2171, accuracy: 93.0878%, tar: 0.0269 \n",
      "l0: 0.029645, l1: 0.030382, l2: 0.037734, l3: 0.054577, l4: 0.100420, l5: 0.203821, l6: 0.453083\n",
      "\n",
      "[epoch: 330/400, batch: 424/1000, ite: 44054] train loss: 1.2200, accuracy: 93.6254%, tar: 0.0269 \n",
      "l0: 0.026191, l1: 0.027342, l2: 0.036869, l3: 0.057648, l4: 0.103516, l5: 0.212931, l6: 0.381692\n",
      "\n",
      "[epoch: 330/400, batch: 432/1000, ite: 44055] train loss: 1.2203, accuracy: 94.8816%, tar: 0.0269 \n",
      "l0: 0.024784, l1: 0.025472, l2: 0.030568, l3: 0.041618, l4: 0.068683, l5: 0.128328, l6: 0.301070\n",
      "\n",
      "[epoch: 330/400, batch: 440/1000, ite: 44056] train loss: 1.2150, accuracy: 95.5620%, tar: 0.0269 \n",
      "l0: 0.027073, l1: 0.028339, l2: 0.036406, l3: 0.052042, l4: 0.085982, l5: 0.161351, l6: 0.314322\n",
      "\n",
      "[epoch: 330/400, batch: 448/1000, ite: 44057] train loss: 1.2116, accuracy: 95.0527%, tar: 0.0269 \n",
      "l0: 0.021258, l1: 0.022444, l2: 0.030532, l3: 0.043677, l4: 0.087098, l5: 0.172765, l6: 0.336663\n",
      "\n",
      "[epoch: 330/400, batch: 456/1000, ite: 44058] train loss: 1.2089, accuracy: 95.4420%, tar: 0.0268 \n",
      "l0: 0.027539, l1: 0.029064, l2: 0.036784, l3: 0.049669, l4: 0.085802, l5: 0.179546, l6: 0.358985\n",
      "\n",
      "[epoch: 330/400, batch: 464/1000, ite: 44059] train loss: 1.2074, accuracy: 95.1570%, tar: 0.0268 \n",
      "l0: 0.027124, l1: 0.028262, l2: 0.036658, l3: 0.053375, l4: 0.098561, l5: 0.173269, l6: 0.382777\n",
      "\n",
      "[epoch: 330/400, batch: 472/1000, ite: 44060] train loss: 1.2071, accuracy: 95.1828%, tar: 0.0268 \n",
      "l0: 0.028329, l1: 0.029855, l2: 0.037823, l3: 0.055158, l4: 0.100177, l5: 0.192829, l6: 0.406713\n",
      "\n",
      "[epoch: 330/400, batch: 480/1000, ite: 44061] train loss: 1.2081, accuracy: 94.3691%, tar: 0.0268 \n",
      "l0: 0.024319, l1: 0.025674, l2: 0.031447, l3: 0.043726, l4: 0.079507, l5: 0.172734, l6: 0.292730\n",
      "\n",
      "[epoch: 330/400, batch: 488/1000, ite: 44062] train loss: 1.2042, accuracy: 95.5335%, tar: 0.0268 \n",
      "l0: 0.024767, l1: 0.025990, l2: 0.032937, l3: 0.048977, l4: 0.085974, l5: 0.177019, l6: 0.438575\n",
      "\n",
      "[epoch: 330/400, batch: 496/1000, ite: 44063] train loss: 1.2052, accuracy: 94.0793%, tar: 0.0267 \n",
      "l0: 0.026472, l1: 0.028272, l2: 0.036033, l3: 0.056308, l4: 0.099666, l5: 0.210393, l6: 0.455687\n",
      "\n",
      "[epoch: 330/400, batch: 504/1000, ite: 44064] train loss: 1.2078, accuracy: 95.0022%, tar: 0.0267 \n",
      "l0: 0.026460, l1: 0.027298, l2: 0.034563, l3: 0.045952, l4: 0.075110, l5: 0.144244, l6: 0.325327\n",
      "\n",
      "[epoch: 330/400, batch: 512/1000, ite: 44065] train loss: 1.2046, accuracy: 95.2829%, tar: 0.0267 \n",
      "l0: 0.027506, l1: 0.029039, l2: 0.037221, l3: 0.059274, l4: 0.115167, l5: 0.251419, l6: 0.495479\n",
      "\n",
      "[epoch: 330/400, batch: 520/1000, ite: 44066] train loss: 1.2091, accuracy: 93.3305%, tar: 0.0267 \n",
      "l0: 0.024362, l1: 0.024916, l2: 0.031850, l3: 0.046908, l4: 0.103248, l5: 0.190761, l6: 0.339711\n",
      "\n",
      "[epoch: 330/400, batch: 528/1000, ite: 44067] train loss: 1.2076, accuracy: 94.7048%, tar: 0.0267 \n",
      "l0: 0.025171, l1: 0.027261, l2: 0.036224, l3: 0.051278, l4: 0.098316, l5: 0.222212, l6: 0.377832\n",
      "\n",
      "[epoch: 330/400, batch: 536/1000, ite: 44068] train loss: 1.2078, accuracy: 95.1108%, tar: 0.0267 \n",
      "l0: 0.024359, l1: 0.025536, l2: 0.030499, l3: 0.042479, l4: 0.074295, l5: 0.132546, l6: 0.271336\n",
      "\n",
      "[epoch: 330/400, batch: 544/1000, ite: 44069] train loss: 1.2032, accuracy: 95.3398%, tar: 0.0266 \n",
      "l0: 0.029916, l1: 0.032105, l2: 0.040936, l3: 0.057877, l4: 0.108947, l5: 0.219433, l6: 0.395271\n",
      "\n",
      "[epoch: 330/400, batch: 552/1000, ite: 44070] train loss: 1.2044, accuracy: 94.8984%, tar: 0.0267 \n",
      "l0: 0.030875, l1: 0.031808, l2: 0.039383, l3: 0.053001, l4: 0.089986, l5: 0.168084, l6: 0.361965\n",
      "\n",
      "[epoch: 330/400, batch: 560/1000, ite: 44071] train loss: 1.2035, accuracy: 95.0167%, tar: 0.0267 \n",
      "l0: 0.032624, l1: 0.032795, l2: 0.038193, l3: 0.051591, l4: 0.087266, l5: 0.180324, l6: 0.381463\n",
      "\n",
      "[epoch: 330/400, batch: 568/1000, ite: 44072] train loss: 1.2033, accuracy: 93.8208%, tar: 0.0268 \n",
      "l0: 0.024201, l1: 0.024693, l2: 0.030735, l3: 0.041248, l4: 0.066168, l5: 0.119646, l6: 0.269984\n",
      "\n",
      "[epoch: 330/400, batch: 576/1000, ite: 44073] train loss: 1.1985, accuracy: 95.8149%, tar: 0.0268 \n",
      "l0: 0.021813, l1: 0.023444, l2: 0.031617, l3: 0.050289, l4: 0.097196, l5: 0.183046, l6: 0.375479\n",
      "\n",
      "[epoch: 330/400, batch: 584/1000, ite: 44074] train loss: 1.1980, accuracy: 95.2239%, tar: 0.0267 \n",
      "l0: 0.019910, l1: 0.021162, l2: 0.028163, l3: 0.038368, l4: 0.062566, l5: 0.119804, l6: 0.237543\n",
      "\n",
      "[epoch: 330/400, batch: 592/1000, ite: 44075] train loss: 1.1923, accuracy: 96.3161%, tar: 0.0266 \n",
      "l0: 0.023879, l1: 0.025434, l2: 0.033161, l3: 0.050299, l4: 0.095499, l5: 0.181765, l6: 0.390006\n",
      "\n",
      "[epoch: 330/400, batch: 600/1000, ite: 44076] train loss: 1.1924, accuracy: 94.6580%, tar: 0.0266 \n",
      "l0: 0.025390, l1: 0.026195, l2: 0.035845, l3: 0.053249, l4: 0.091688, l5: 0.171573, l6: 0.377942\n",
      "\n",
      "[epoch: 330/400, batch: 608/1000, ite: 44077] train loss: 1.1921, accuracy: 94.7025%, tar: 0.0266 \n",
      "l0: 0.024930, l1: 0.025997, l2: 0.032975, l3: 0.047610, l4: 0.080024, l5: 0.165199, l6: 0.315043\n",
      "\n",
      "[epoch: 330/400, batch: 616/1000, ite: 44078] train loss: 1.1897, accuracy: 95.2919%, tar: 0.0266 \n",
      "l0: 0.025928, l1: 0.026932, l2: 0.035048, l3: 0.053409, l4: 0.098721, l5: 0.212763, l6: 0.383430\n",
      "\n",
      "[epoch: 330/400, batch: 624/1000, ite: 44079] train loss: 1.1901, accuracy: 94.7533%, tar: 0.0266 \n",
      "l0: 0.025038, l1: 0.026480, l2: 0.034744, l3: 0.050862, l4: 0.081874, l5: 0.143547, l6: 0.361063\n",
      "\n",
      "[epoch: 330/400, batch: 632/1000, ite: 44080] train loss: 1.1888, accuracy: 95.8121%, tar: 0.0265 \n",
      "l0: 0.023741, l1: 0.025001, l2: 0.032380, l3: 0.046683, l4: 0.085188, l5: 0.161858, l6: 0.383224\n",
      "\n",
      "[epoch: 330/400, batch: 640/1000, ite: 44081] train loss: 1.1882, accuracy: 95.3521%, tar: 0.0265 \n",
      "l0: 0.023715, l1: 0.024344, l2: 0.031340, l3: 0.044967, l4: 0.083897, l5: 0.154914, l6: 0.315767\n",
      "\n",
      "[epoch: 330/400, batch: 648/1000, ite: 44082] train loss: 1.1860, accuracy: 95.1140%, tar: 0.0265 \n",
      "l0: 0.027382, l1: 0.028754, l2: 0.036598, l3: 0.054710, l4: 0.094403, l5: 0.174856, l6: 0.351404\n",
      "\n",
      "[epoch: 330/400, batch: 656/1000, ite: 44083] train loss: 1.1853, accuracy: 95.3110%, tar: 0.0265 \n",
      "l0: 0.019581, l1: 0.020144, l2: 0.026310, l3: 0.039973, l4: 0.073050, l5: 0.134450, l6: 0.269845\n",
      "\n",
      "[epoch: 330/400, batch: 664/1000, ite: 44084] train loss: 1.1814, accuracy: 95.9829%, tar: 0.0264 \n",
      "l0: 0.021121, l1: 0.023042, l2: 0.030315, l3: 0.041988, l4: 0.083968, l5: 0.149420, l6: 0.320204\n",
      "\n",
      "[epoch: 330/400, batch: 672/1000, ite: 44085] train loss: 1.1792, accuracy: 96.5977%, tar: 0.0263 \n",
      "l0: 0.028205, l1: 0.028947, l2: 0.036399, l3: 0.048631, l4: 0.084803, l5: 0.146330, l6: 0.334743\n",
      "\n",
      "[epoch: 330/400, batch: 680/1000, ite: 44086] train loss: 1.1776, accuracy: 95.3727%, tar: 0.0264 \n",
      "l0: 0.023790, l1: 0.025518, l2: 0.033378, l3: 0.052753, l4: 0.096337, l5: 0.208550, l6: 0.387789\n",
      "\n",
      "[epoch: 330/400, batch: 688/1000, ite: 44087] train loss: 1.1781, accuracy: 95.0322%, tar: 0.0263 \n",
      "l0: 0.024206, l1: 0.025444, l2: 0.033149, l3: 0.050272, l4: 0.087294, l5: 0.157094, l6: 0.345492\n",
      "\n",
      "[epoch: 330/400, batch: 696/1000, ite: 44088] train loss: 1.1770, accuracy: 95.1405%, tar: 0.0263 \n",
      "l0: 0.031197, l1: 0.032314, l2: 0.040163, l3: 0.059429, l4: 0.104568, l5: 0.216388, l6: 0.455118\n",
      "\n",
      "[epoch: 330/400, batch: 704/1000, ite: 44089] train loss: 1.1796, accuracy: 93.7877%, tar: 0.0264 \n",
      "l0: 0.026003, l1: 0.027008, l2: 0.034988, l3: 0.053435, l4: 0.092372, l5: 0.189721, l6: 0.359872\n",
      "\n",
      "[epoch: 330/400, batch: 712/1000, ite: 44090] train loss: 1.1792, accuracy: 94.6777%, tar: 0.0264 \n",
      "l0: 0.026914, l1: 0.028089, l2: 0.037195, l3: 0.055814, l4: 0.097365, l5: 0.222352, l6: 0.399469\n",
      "\n",
      "[epoch: 330/400, batch: 720/1000, ite: 44091] train loss: 1.1802, accuracy: 94.6503%, tar: 0.0264 \n",
      "l0: 0.022944, l1: 0.023730, l2: 0.031678, l3: 0.044203, l4: 0.073631, l5: 0.130942, l6: 0.269121\n",
      "\n",
      "[epoch: 330/400, batch: 728/1000, ite: 44092] train loss: 1.1768, accuracy: 96.0871%, tar: 0.0263 \n",
      "l0: 0.021326, l1: 0.023401, l2: 0.031359, l3: 0.048494, l4: 0.088670, l5: 0.186148, l6: 0.315906\n",
      "\n",
      "[epoch: 330/400, batch: 736/1000, ite: 44093] train loss: 1.1753, accuracy: 96.0799%, tar: 0.0263 \n",
      "l0: 0.035504, l1: 0.037218, l2: 0.047072, l3: 0.071514, l4: 0.137424, l5: 0.260931, l6: 0.493796\n",
      "\n",
      "[epoch: 330/400, batch: 744/1000, ite: 44094] train loss: 1.1796, accuracy: 92.4402%, tar: 0.0264 \n",
      "l0: 0.025322, l1: 0.026256, l2: 0.033864, l3: 0.049526, l4: 0.086843, l5: 0.162813, l6: 0.295055\n",
      "\n",
      "[epoch: 330/400, batch: 752/1000, ite: 44095] train loss: 1.1775, accuracy: 95.0332%, tar: 0.0264 \n",
      "l0: 0.027322, l1: 0.029874, l2: 0.040494, l3: 0.067996, l4: 0.121663, l5: 0.194571, l6: 0.326021\n",
      "\n",
      "[epoch: 330/400, batch: 760/1000, ite: 44096] train loss: 1.1771, accuracy: 95.6977%, tar: 0.0264 \n",
      "l0: 0.026282, l1: 0.027968, l2: 0.037355, l3: 0.063462, l4: 0.147573, l5: 0.299159, l6: 0.538674\n",
      "\n",
      "[epoch: 330/400, batch: 768/1000, ite: 44097] train loss: 1.1823, accuracy: 94.1646%, tar: 0.0264 \n",
      "l0: 0.026932, l1: 0.027974, l2: 0.034283, l3: 0.047297, l4: 0.083534, l5: 0.167768, l6: 0.329836\n",
      "\n",
      "[epoch: 330/400, batch: 776/1000, ite: 44098] train loss: 1.1810, accuracy: 94.9133%, tar: 0.0264 \n",
      "l0: 0.033743, l1: 0.035690, l2: 0.045530, l3: 0.065423, l4: 0.131985, l5: 0.231907, l6: 0.427589\n",
      "\n",
      "[epoch: 330/400, batch: 784/1000, ite: 44099] train loss: 1.1832, accuracy: 94.5493%, tar: 0.0264 \n",
      "l0: 0.032914, l1: 0.034172, l2: 0.042239, l3: 0.059244, l4: 0.110273, l5: 0.232046, l6: 0.500587\n",
      "\n",
      "[epoch: 330/400, batch: 792/1000, ite: 44100] train loss: 1.1866, accuracy: 92.5832%, tar: 0.0265 \n",
      "l0: 0.033067, l1: 0.034088, l2: 0.044012, l3: 0.064642, l4: 0.125988, l5: 0.261869, l6: 0.451890\n",
      "\n",
      "[epoch: 330/400, batch: 800/1000, ite: 44101] train loss: 1.1894, accuracy: 94.1702%, tar: 0.0266 \n",
      "l0: 0.025729, l1: 0.027165, l2: 0.034294, l3: 0.052269, l4: 0.097279, l5: 0.199376, l6: 0.361503\n",
      "\n",
      "[epoch: 330/400, batch: 808/1000, ite: 44102] train loss: 1.1892, accuracy: 95.2729%, tar: 0.0266 \n",
      "l0: 0.029800, l1: 0.030978, l2: 0.039769, l3: 0.054754, l4: 0.096646, l5: 0.209751, l6: 0.529569\n",
      "\n",
      "[epoch: 330/400, batch: 816/1000, ite: 44103] train loss: 1.1924, accuracy: 93.8786%, tar: 0.0266 \n",
      "l0: 0.028242, l1: 0.029571, l2: 0.038183, l3: 0.052831, l4: 0.085672, l5: 0.178271, l6: 0.418553\n",
      "\n",
      "[epoch: 330/400, batch: 824/1000, ite: 44104] train loss: 1.1930, accuracy: 94.0115%, tar: 0.0266 \n",
      "l0: 0.025178, l1: 0.025800, l2: 0.032978, l3: 0.048628, l4: 0.078404, l5: 0.178275, l6: 0.343003\n",
      "\n",
      "[epoch: 330/400, batch: 832/1000, ite: 44105] train loss: 1.1919, accuracy: 94.4364%, tar: 0.0266 \n",
      "l0: 0.028760, l1: 0.030215, l2: 0.037426, l3: 0.052759, l4: 0.101780, l5: 0.225396, l6: 0.404991\n",
      "\n",
      "[epoch: 330/400, batch: 840/1000, ite: 44106] train loss: 1.1928, accuracy: 94.5722%, tar: 0.0266 \n",
      "l0: 0.022765, l1: 0.023604, l2: 0.029925, l3: 0.044615, l4: 0.087347, l5: 0.177150, l6: 0.350892\n",
      "\n",
      "[epoch: 330/400, batch: 848/1000, ite: 44107] train loss: 1.1919, accuracy: 94.9556%, tar: 0.0266 \n",
      "l0: 0.024397, l1: 0.025545, l2: 0.031919, l3: 0.046349, l4: 0.084696, l5: 0.154775, l6: 0.287935\n",
      "\n",
      "[epoch: 330/400, batch: 856/1000, ite: 44108] train loss: 1.1896, accuracy: 95.3382%, tar: 0.0266 \n",
      "l0: 0.023489, l1: 0.023856, l2: 0.030524, l3: 0.040214, l4: 0.068074, l5: 0.108920, l6: 0.217747\n",
      "\n",
      "[epoch: 330/400, batch: 864/1000, ite: 44109] train loss: 1.1854, accuracy: 96.1946%, tar: 0.0265 \n",
      "l0: 0.021591, l1: 0.022517, l2: 0.027495, l3: 0.038689, l4: 0.072011, l5: 0.143566, l6: 0.364068\n",
      "\n",
      "[epoch: 330/400, batch: 872/1000, ite: 44110] train loss: 1.1843, accuracy: 95.2465%, tar: 0.0265 \n",
      "l0: 0.023716, l1: 0.024348, l2: 0.031550, l3: 0.045465, l4: 0.081796, l5: 0.155136, l6: 0.289437\n",
      "\n",
      "[epoch: 330/400, batch: 880/1000, ite: 44111] train loss: 1.1821, accuracy: 95.3947%, tar: 0.0265 \n",
      "l0: 0.028080, l1: 0.028981, l2: 0.037949, l3: 0.055075, l4: 0.102158, l5: 0.193413, l6: 0.393829\n",
      "\n",
      "[epoch: 330/400, batch: 888/1000, ite: 44112] train loss: 1.1826, accuracy: 94.6872%, tar: 0.0265 \n",
      "l0: 0.025296, l1: 0.026312, l2: 0.033823, l3: 0.049422, l4: 0.079593, l5: 0.136875, l6: 0.254546\n",
      "\n",
      "[epoch: 330/400, batch: 896/1000, ite: 44113] train loss: 1.1798, accuracy: 95.8413%, tar: 0.0265 \n",
      "l0: 0.022993, l1: 0.023914, l2: 0.030932, l3: 0.044311, l4: 0.079488, l5: 0.173263, l6: 0.331216\n",
      "\n",
      "[epoch: 330/400, batch: 904/1000, ite: 44114] train loss: 1.1786, accuracy: 96.2529%, tar: 0.0264 \n",
      "l0: 0.026316, l1: 0.027276, l2: 0.032047, l3: 0.045611, l4: 0.069929, l5: 0.116761, l6: 0.253197\n",
      "\n",
      "[epoch: 330/400, batch: 912/1000, ite: 44115] train loss: 1.1756, accuracy: 95.5867%, tar: 0.0264 \n",
      "l0: 0.023546, l1: 0.024409, l2: 0.032543, l3: 0.045943, l4: 0.088891, l5: 0.189125, l6: 0.384536\n",
      "\n",
      "[epoch: 330/400, batch: 920/1000, ite: 44116] train loss: 1.1756, accuracy: 94.0583%, tar: 0.0264 \n",
      "l0: 0.026172, l1: 0.027139, l2: 0.034184, l3: 0.048654, l4: 0.087741, l5: 0.169264, l6: 0.315198\n",
      "\n",
      "[epoch: 330/400, batch: 928/1000, ite: 44117] train loss: 1.1744, accuracy: 94.9227%, tar: 0.0264 \n",
      "l0: 0.020583, l1: 0.021612, l2: 0.028023, l3: 0.045292, l4: 0.080071, l5: 0.162436, l6: 0.368093\n",
      "\n",
      "[epoch: 330/400, batch: 936/1000, ite: 44118] train loss: 1.1737, accuracy: 95.5028%, tar: 0.0264 \n",
      "l0: 0.029336, l1: 0.030386, l2: 0.038268, l3: 0.056675, l4: 0.106306, l5: 0.223240, l6: 0.391233\n",
      "\n",
      "[epoch: 330/400, batch: 944/1000, ite: 44119] train loss: 1.1745, accuracy: 94.3433%, tar: 0.0264 \n",
      "l0: 0.031219, l1: 0.032896, l2: 0.043866, l3: 0.062027, l4: 0.112354, l5: 0.271480, l6: 0.489859\n",
      "\n",
      "[epoch: 330/400, batch: 952/1000, ite: 44120] train loss: 1.1776, accuracy: 93.7894%, tar: 0.0264 \n",
      "l0: 0.028460, l1: 0.029549, l2: 0.038891, l3: 0.064262, l4: 0.121823, l5: 0.226837, l6: 0.387574\n",
      "\n",
      "[epoch: 330/400, batch: 960/1000, ite: 44121] train loss: 1.1785, accuracy: 94.5458%, tar: 0.0264 \n",
      "l0: 0.019221, l1: 0.020250, l2: 0.027810, l3: 0.043550, l4: 0.085366, l5: 0.167792, l6: 0.314397\n",
      "\n",
      "[epoch: 330/400, batch: 968/1000, ite: 44122] train loss: 1.1770, accuracy: 95.3876%, tar: 0.0264 \n",
      "l0: 0.028106, l1: 0.029811, l2: 0.037497, l3: 0.055260, l4: 0.103193, l5: 0.207208, l6: 0.470277\n",
      "\n",
      "[epoch: 330/400, batch: 976/1000, ite: 44123] train loss: 1.1789, accuracy: 93.9463%, tar: 0.0264 \n",
      "l0: 0.024552, l1: 0.026208, l2: 0.032991, l3: 0.047857, l4: 0.087506, l5: 0.170520, l6: 0.338022\n",
      "\n",
      "[epoch: 330/400, batch: 984/1000, ite: 44124] train loss: 1.1780, accuracy: 94.6003%, tar: 0.0264 \n",
      "l0: 0.024399, l1: 0.025821, l2: 0.034051, l3: 0.054458, l4: 0.105948, l5: 0.199088, l6: 0.389480\n",
      "\n",
      "[epoch: 330/400, batch: 992/1000, ite: 44125] train loss: 1.1784, accuracy: 94.6793%, tar: 0.0264 \n",
      "l0: 0.027328, l1: 0.028873, l2: 0.037809, l3: 0.056809, l4: 0.108559, l5: 0.194910, l6: 0.399692\n",
      "\n",
      "[epoch: 330/400, batch: 1000/1000, ite: 44126] train loss: 1.1790, accuracy: 94.6946%, tar: 0.0264 \n",
      "l0: 0.024857, l1: 0.026014, l2: 0.035182, l3: 0.053210, l4: 0.090836, l5: 0.142414, l6: 0.261394\n",
      "\n",
      "[epoch: 331/400, batch: 8/1000, ite: 44127] train loss: 1.1768, accuracy: 96.3031%, tar: 0.0264 \n",
      "l0: 0.025067, l1: 0.026567, l2: 0.035418, l3: 0.057550, l4: 0.139381, l5: 0.288103, l6: 0.528542\n",
      "\n",
      "[epoch: 331/400, batch: 16/1000, ite: 44128] train loss: 1.1803, accuracy: 93.1744%, tar: 0.0264 \n",
      "l0: 0.022460, l1: 0.024018, l2: 0.031046, l3: 0.044168, l4: 0.082897, l5: 0.160482, l6: 0.330539\n",
      "\n",
      "[epoch: 331/400, batch: 24/1000, ite: 44129] train loss: 1.1792, accuracy: 95.4785%, tar: 0.0263 \n",
      "l0: 0.021085, l1: 0.022001, l2: 0.031036, l3: 0.043057, l4: 0.079283, l5: 0.182433, l6: 0.347554\n",
      "\n",
      "[epoch: 331/400, batch: 32/1000, ite: 44130] train loss: 1.1784, accuracy: 94.7710%, tar: 0.0263 \n",
      "l0: 0.026163, l1: 0.027466, l2: 0.034910, l3: 0.047697, l4: 0.085826, l5: 0.171562, l6: 0.361063\n",
      "\n",
      "[epoch: 331/400, batch: 40/1000, ite: 44131] train loss: 1.1780, accuracy: 94.3621%, tar: 0.0263 \n",
      "l0: 0.023963, l1: 0.025410, l2: 0.031268, l3: 0.044594, l4: 0.080979, l5: 0.190650, l6: 0.361012\n",
      "\n",
      "[epoch: 331/400, batch: 48/1000, ite: 44132] train loss: 1.1775, accuracy: 95.4407%, tar: 0.0263 \n",
      "l0: 0.022798, l1: 0.023910, l2: 0.030365, l3: 0.044138, l4: 0.076529, l5: 0.145709, l6: 0.299918\n",
      "\n",
      "[epoch: 331/400, batch: 56/1000, ite: 44133] train loss: 1.1758, accuracy: 95.4859%, tar: 0.0262 \n",
      "l0: 0.025866, l1: 0.027377, l2: 0.036191, l3: 0.053867, l4: 0.099663, l5: 0.229970, l6: 0.412060\n",
      "\n",
      "[epoch: 331/400, batch: 64/1000, ite: 44134] train loss: 1.1768, accuracy: 93.9275%, tar: 0.0262 \n",
      "l0: 0.032198, l1: 0.034767, l2: 0.045742, l3: 0.068322, l4: 0.127591, l5: 0.247040, l6: 0.470567\n",
      "\n",
      "[epoch: 331/400, batch: 72/1000, ite: 44135] train loss: 1.1791, accuracy: 93.9144%, tar: 0.0263 \n",
      "l0: 0.019194, l1: 0.019948, l2: 0.026086, l3: 0.035315, l4: 0.058564, l5: 0.109695, l6: 0.249721\n",
      "\n",
      "[epoch: 331/400, batch: 80/1000, ite: 44136] train loss: 1.1761, accuracy: 96.3923%, tar: 0.0262 \n",
      "l0: 0.026977, l1: 0.028590, l2: 0.036548, l3: 0.050935, l4: 0.091429, l5: 0.189499, l6: 0.419062\n",
      "\n",
      "[epoch: 331/400, batch: 88/1000, ite: 44137] train loss: 1.1768, accuracy: 94.0869%, tar: 0.0262 \n",
      "l0: 0.021041, l1: 0.022268, l2: 0.027760, l3: 0.041455, l4: 0.070552, l5: 0.163538, l6: 0.426821\n",
      "\n",
      "[epoch: 331/400, batch: 96/1000, ite: 44138] train loss: 1.1770, accuracy: 94.1902%, tar: 0.0262 \n",
      "l0: 0.031816, l1: 0.033804, l2: 0.040385, l3: 0.057369, l4: 0.100710, l5: 0.224633, l6: 0.499655\n",
      "\n",
      "[epoch: 331/400, batch: 104/1000, ite: 44139] train loss: 1.1792, accuracy: 93.5750%, tar: 0.0262 \n",
      "l0: 0.024858, l1: 0.026263, l2: 0.034405, l3: 0.053309, l4: 0.098379, l5: 0.206979, l6: 0.370882\n",
      "\n",
      "[epoch: 331/400, batch: 112/1000, ite: 44140] train loss: 1.1793, accuracy: 95.7100%, tar: 0.0262 \n",
      "l0: 0.020495, l1: 0.021692, l2: 0.028098, l3: 0.040273, l4: 0.068347, l5: 0.136671, l6: 0.257949\n",
      "\n",
      "[epoch: 331/400, batch: 120/1000, ite: 44141] train loss: 1.1769, accuracy: 96.3011%, tar: 0.0262 \n",
      "l0: 0.021121, l1: 0.022033, l2: 0.029212, l3: 0.045711, l4: 0.090136, l5: 0.149935, l6: 0.301940\n",
      "\n",
      "[epoch: 331/400, batch: 128/1000, ite: 44142] train loss: 1.1754, accuracy: 96.1851%, tar: 0.0262 \n",
      "l0: 0.026161, l1: 0.027059, l2: 0.034410, l3: 0.047061, l4: 0.077380, l5: 0.161544, l6: 0.341452\n",
      "\n",
      "[epoch: 331/400, batch: 136/1000, ite: 44143] train loss: 1.1746, accuracy: 94.6527%, tar: 0.0262 \n",
      "l0: 0.031490, l1: 0.032955, l2: 0.042018, l3: 0.057267, l4: 0.106713, l5: 0.276996, l6: 0.580095\n",
      "\n",
      "[epoch: 331/400, batch: 144/1000, ite: 44144] train loss: 1.1783, accuracy: 92.1680%, tar: 0.0262 \n",
      "l0: 0.023811, l1: 0.025789, l2: 0.036725, l3: 0.060535, l4: 0.120213, l5: 0.233753, l6: 0.495962\n",
      "\n",
      "[epoch: 331/400, batch: 152/1000, ite: 44145] train loss: 1.1805, accuracy: 94.1248%, tar: 0.0262 \n",
      "l0: 0.025655, l1: 0.027278, l2: 0.036315, l3: 0.057648, l4: 0.129581, l5: 0.271423, l6: 0.524333\n",
      "\n",
      "[epoch: 331/400, batch: 160/1000, ite: 44146] train loss: 1.1833, accuracy: 93.9103%, tar: 0.0262 \n",
      "l0: 0.022818, l1: 0.024296, l2: 0.031875, l3: 0.048035, l4: 0.086567, l5: 0.172049, l6: 0.334109\n",
      "\n",
      "[epoch: 331/400, batch: 168/1000, ite: 44147] train loss: 1.1825, accuracy: 94.9089%, tar: 0.0261 \n",
      "l0: 0.018959, l1: 0.020010, l2: 0.026213, l3: 0.038806, l4: 0.070329, l5: 0.145299, l6: 0.275436\n",
      "\n",
      "[epoch: 331/400, batch: 176/1000, ite: 44148] train loss: 1.1803, accuracy: 95.9444%, tar: 0.0261 \n",
      "l0: 0.028281, l1: 0.030455, l2: 0.042125, l3: 0.067793, l4: 0.132376, l5: 0.241039, l6: 0.425759\n",
      "\n",
      "[epoch: 331/400, batch: 184/1000, ite: 44149] train loss: 1.1818, accuracy: 95.0939%, tar: 0.0261 \n",
      "l0: 0.028823, l1: 0.030120, l2: 0.039096, l3: 0.054298, l4: 0.097507, l5: 0.209588, l6: 0.467932\n",
      "\n",
      "[epoch: 331/400, batch: 192/1000, ite: 44150] train loss: 1.1832, accuracy: 93.5741%, tar: 0.0261 \n",
      "l0: 0.021796, l1: 0.023022, l2: 0.030343, l3: 0.045944, l4: 0.082800, l5: 0.197372, l6: 0.418367\n",
      "\n",
      "[epoch: 331/400, batch: 200/1000, ite: 44151] train loss: 1.1836, accuracy: 94.3082%, tar: 0.0261 \n",
      "l0: 0.023962, l1: 0.025540, l2: 0.032813, l3: 0.046707, l4: 0.080816, l5: 0.152916, l6: 0.305158\n",
      "\n",
      "[epoch: 331/400, batch: 208/1000, ite: 44152] train loss: 1.1823, accuracy: 95.7841%, tar: 0.0261 \n",
      "l0: 0.027494, l1: 0.028656, l2: 0.036370, l3: 0.052185, l4: 0.094474, l5: 0.175314, l6: 0.399063\n",
      "\n",
      "[epoch: 331/400, batch: 216/1000, ite: 44153] train loss: 1.1825, accuracy: 95.0101%, tar: 0.0261 \n",
      "l0: 0.026382, l1: 0.027429, l2: 0.035579, l3: 0.051520, l4: 0.097632, l5: 0.188004, l6: 0.382280\n",
      "\n",
      "[epoch: 331/400, batch: 224/1000, ite: 44154] train loss: 1.1826, accuracy: 94.4079%, tar: 0.0261 \n",
      "l0: 0.022626, l1: 0.024393, l2: 0.030958, l3: 0.044764, l4: 0.081351, l5: 0.156599, l6: 0.356773\n",
      "\n",
      "[epoch: 331/400, batch: 232/1000, ite: 44155] train loss: 1.1819, accuracy: 95.4813%, tar: 0.0261 \n",
      "l0: 0.031572, l1: 0.033455, l2: 0.043051, l3: 0.070624, l4: 0.137277, l5: 0.285291, l6: 0.494978\n",
      "\n",
      "[epoch: 331/400, batch: 240/1000, ite: 44156] train loss: 1.1845, accuracy: 93.0559%, tar: 0.0261 \n",
      "l0: 0.023955, l1: 0.024156, l2: 0.030483, l3: 0.045260, l4: 0.087084, l5: 0.193493, l6: 0.434752\n",
      "\n",
      "[epoch: 331/400, batch: 248/1000, ite: 44157] train loss: 1.1852, accuracy: 94.4359%, tar: 0.0261 \n",
      "l0: 0.020985, l1: 0.022353, l2: 0.028595, l3: 0.043348, l4: 0.087342, l5: 0.183153, l6: 0.336941\n",
      "\n",
      "[epoch: 331/400, batch: 256/1000, ite: 44158] train loss: 1.1844, accuracy: 95.3510%, tar: 0.0261 \n",
      "l0: 0.020698, l1: 0.021885, l2: 0.029052, l3: 0.042682, l4: 0.071805, l5: 0.133822, l6: 0.261019\n",
      "\n",
      "[epoch: 331/400, batch: 264/1000, ite: 44159] train loss: 1.1823, accuracy: 96.3526%, tar: 0.0260 \n",
      "l0: 0.020752, l1: 0.021713, l2: 0.029044, l3: 0.044449, l4: 0.083099, l5: 0.154857, l6: 0.386389\n",
      "\n",
      "[epoch: 331/400, batch: 272/1000, ite: 44160] train loss: 1.1820, accuracy: 95.0359%, tar: 0.0260 \n",
      "l0: 0.025586, l1: 0.027130, l2: 0.034945, l3: 0.049387, l4: 0.092845, l5: 0.222574, l6: 0.440770\n",
      "\n",
      "[epoch: 331/400, batch: 280/1000, ite: 44161] train loss: 1.1830, accuracy: 93.9872%, tar: 0.0260 \n",
      "l0: 0.020944, l1: 0.022126, l2: 0.031839, l3: 0.049287, l4: 0.085260, l5: 0.172381, l6: 0.347744\n",
      "\n",
      "[epoch: 331/400, batch: 288/1000, ite: 44162] train loss: 1.1824, accuracy: 94.9385%, tar: 0.0260 \n",
      "l0: 0.022422, l1: 0.023156, l2: 0.030305, l3: 0.043193, l4: 0.068566, l5: 0.117420, l6: 0.234700\n",
      "\n",
      "[epoch: 331/400, batch: 296/1000, ite: 44163] train loss: 1.1799, accuracy: 95.8557%, tar: 0.0259 \n",
      "l0: 0.030053, l1: 0.031272, l2: 0.039532, l3: 0.059543, l4: 0.119641, l5: 0.215600, l6: 0.420822\n",
      "\n",
      "[epoch: 331/400, batch: 304/1000, ite: 44164] train loss: 1.1809, accuracy: 94.1684%, tar: 0.0260 \n",
      "l0: 0.029078, l1: 0.030687, l2: 0.039860, l3: 0.060711, l4: 0.110006, l5: 0.234869, l6: 0.459422\n",
      "\n",
      "[epoch: 331/400, batch: 312/1000, ite: 44165] train loss: 1.1824, accuracy: 93.9148%, tar: 0.0260 \n",
      "l0: 0.030402, l1: 0.032759, l2: 0.042806, l3: 0.064383, l4: 0.109021, l5: 0.210280, l6: 0.442656\n",
      "\n",
      "[epoch: 331/400, batch: 320/1000, ite: 44166] train loss: 1.1836, accuracy: 93.6856%, tar: 0.0260 \n",
      "l0: 0.030740, l1: 0.031966, l2: 0.040475, l3: 0.054976, l4: 0.102671, l5: 0.210389, l6: 0.381129\n",
      "\n",
      "[epoch: 331/400, batch: 328/1000, ite: 44167] train loss: 1.1840, accuracy: 94.2710%, tar: 0.0260 \n",
      "l0: 0.028358, l1: 0.029657, l2: 0.038392, l3: 0.050502, l4: 0.088272, l5: 0.173973, l6: 0.358218\n",
      "\n",
      "[epoch: 331/400, batch: 336/1000, ite: 44168] train loss: 1.1837, accuracy: 94.6252%, tar: 0.0261 \n",
      "l0: 0.030084, l1: 0.031122, l2: 0.039326, l3: 0.053720, l4: 0.095559, l5: 0.201290, l6: 0.472050\n",
      "\n",
      "[epoch: 331/400, batch: 344/1000, ite: 44169] train loss: 1.1849, accuracy: 94.4012%, tar: 0.0261 \n",
      "l0: 0.018912, l1: 0.019581, l2: 0.025547, l3: 0.037218, l4: 0.065686, l5: 0.142619, l6: 0.271658\n",
      "\n",
      "[epoch: 331/400, batch: 352/1000, ite: 44170] train loss: 1.1830, accuracy: 95.9015%, tar: 0.0260 \n",
      "l0: 0.026494, l1: 0.027377, l2: 0.035483, l3: 0.055860, l4: 0.106216, l5: 0.215117, l6: 0.445553\n",
      "\n",
      "[epoch: 331/400, batch: 360/1000, ite: 44171] train loss: 1.1841, accuracy: 93.2646%, tar: 0.0260 \n",
      "l0: 0.024277, l1: 0.025357, l2: 0.032770, l3: 0.045290, l4: 0.085362, l5: 0.173647, l6: 0.346900\n",
      "\n",
      "[epoch: 331/400, batch: 368/1000, ite: 44172] train loss: 1.1835, accuracy: 94.9969%, tar: 0.0260 \n",
      "l0: 0.024421, l1: 0.025318, l2: 0.031585, l3: 0.043648, l4: 0.072320, l5: 0.127712, l6: 0.325289\n",
      "\n",
      "[epoch: 331/400, batch: 376/1000, ite: 44173] train loss: 1.1824, accuracy: 94.4841%, tar: 0.0260 \n",
      "l0: 0.025334, l1: 0.026610, l2: 0.032464, l3: 0.051045, l4: 0.088406, l5: 0.180158, l6: 0.363706\n",
      "\n",
      "[epoch: 331/400, batch: 384/1000, ite: 44174] train loss: 1.1821, accuracy: 95.5231%, tar: 0.0260 \n",
      "l0: 0.026077, l1: 0.027921, l2: 0.037147, l3: 0.057649, l4: 0.119863, l5: 0.248160, l6: 0.436049\n",
      "\n",
      "[epoch: 331/400, batch: 392/1000, ite: 44175] train loss: 1.1833, accuracy: 95.0325%, tar: 0.0260 \n",
      "l0: 0.026900, l1: 0.028057, l2: 0.036332, l3: 0.054993, l4: 0.098925, l5: 0.192354, l6: 0.369680\n",
      "\n",
      "[epoch: 331/400, batch: 400/1000, ite: 44176] train loss: 1.1833, accuracy: 94.4042%, tar: 0.0260 \n",
      "l0: 0.025109, l1: 0.026250, l2: 0.031163, l3: 0.043331, l4: 0.084636, l5: 0.155130, l6: 0.321759\n",
      "\n",
      "[epoch: 331/400, batch: 408/1000, ite: 44177] train loss: 1.1823, accuracy: 94.7880%, tar: 0.0260 \n",
      "l0: 0.023111, l1: 0.024181, l2: 0.030306, l3: 0.044527, l4: 0.077691, l5: 0.163873, l6: 0.329865\n",
      "\n",
      "[epoch: 331/400, batch: 416/1000, ite: 44178] train loss: 1.1815, accuracy: 94.6370%, tar: 0.0260 \n",
      "l0: 0.025410, l1: 0.026758, l2: 0.035022, l3: 0.049609, l4: 0.087816, l5: 0.170961, l6: 0.342871\n",
      "\n",
      "[epoch: 331/400, batch: 424/1000, ite: 44179] train loss: 1.1809, accuracy: 95.2687%, tar: 0.0260 \n",
      "l0: 0.021368, l1: 0.022706, l2: 0.030227, l3: 0.046781, l4: 0.082023, l5: 0.165243, l6: 0.307898\n",
      "\n",
      "[epoch: 331/400, batch: 432/1000, ite: 44180] train loss: 1.1799, accuracy: 96.0877%, tar: 0.0260 \n",
      "l0: 0.027729, l1: 0.029375, l2: 0.037785, l3: 0.051192, l4: 0.087333, l5: 0.180446, l6: 0.406273\n",
      "\n",
      "[epoch: 331/400, batch: 440/1000, ite: 44181] train loss: 1.1801, accuracy: 94.4344%, tar: 0.0260 \n",
      "l0: 0.030409, l1: 0.032021, l2: 0.040883, l3: 0.063140, l4: 0.120600, l5: 0.227501, l6: 0.466643\n",
      "\n",
      "[epoch: 331/400, batch: 448/1000, ite: 44182] train loss: 1.1816, accuracy: 93.0966%, tar: 0.0260 \n",
      "l0: 0.027491, l1: 0.028285, l2: 0.036663, l3: 0.054072, l4: 0.093253, l5: 0.172393, l6: 0.370935\n",
      "\n",
      "[epoch: 331/400, batch: 456/1000, ite: 44183] train loss: 1.1815, accuracy: 94.4193%, tar: 0.0260 \n",
      "l0: 0.027546, l1: 0.028760, l2: 0.036695, l3: 0.053778, l4: 0.089398, l5: 0.199841, l6: 0.370087\n",
      "\n",
      "[epoch: 331/400, batch: 464/1000, ite: 44184] train loss: 1.1815, accuracy: 94.4621%, tar: 0.0260 \n",
      "l0: 0.022164, l1: 0.022456, l2: 0.028396, l3: 0.040087, l4: 0.068528, l5: 0.116988, l6: 0.253273\n",
      "\n",
      "[epoch: 331/400, batch: 472/1000, ite: 44185] train loss: 1.1795, accuracy: 96.0673%, tar: 0.0260 \n",
      "l0: 0.025920, l1: 0.027245, l2: 0.035846, l3: 0.048822, l4: 0.084319, l5: 0.151516, l6: 0.325227\n",
      "\n",
      "[epoch: 331/400, batch: 480/1000, ite: 44186] train loss: 1.1786, accuracy: 95.7146%, tar: 0.0260 \n",
      "l0: 0.026916, l1: 0.028702, l2: 0.038154, l3: 0.060055, l4: 0.119841, l5: 0.207046, l6: 0.422045\n",
      "\n",
      "[epoch: 331/400, batch: 488/1000, ite: 44187] train loss: 1.1794, accuracy: 94.5147%, tar: 0.0260 \n",
      "l0: 0.032609, l1: 0.033175, l2: 0.041264, l3: 0.059074, l4: 0.110171, l5: 0.215412, l6: 0.436242\n",
      "\n",
      "[epoch: 331/400, batch: 496/1000, ite: 44188] train loss: 1.1805, accuracy: 93.9577%, tar: 0.0260 \n",
      "l0: 0.024239, l1: 0.025648, l2: 0.034368, l3: 0.052573, l4: 0.092565, l5: 0.206155, l6: 0.379972\n",
      "\n",
      "[epoch: 331/400, batch: 504/1000, ite: 44189] train loss: 1.1805, accuracy: 94.6540%, tar: 0.0260 \n",
      "l0: 0.024504, l1: 0.026393, l2: 0.036436, l3: 0.061233, l4: 0.123337, l5: 0.218718, l6: 0.435901\n",
      "\n",
      "[epoch: 331/400, batch: 512/1000, ite: 44190] train loss: 1.1815, accuracy: 94.6054%, tar: 0.0260 \n",
      "l0: 0.023005, l1: 0.024575, l2: 0.032038, l3: 0.046444, l4: 0.081577, l5: 0.161269, l6: 0.316224\n",
      "\n",
      "[epoch: 331/400, batch: 520/1000, ite: 44191] train loss: 1.1806, accuracy: 95.3269%, tar: 0.0260 \n",
      "l0: 0.035254, l1: 0.036986, l2: 0.045063, l3: 0.062730, l4: 0.106230, l5: 0.228331, l6: 0.435493\n",
      "\n",
      "[epoch: 331/400, batch: 528/1000, ite: 44192] train loss: 1.1817, accuracy: 94.3508%, tar: 0.0261 \n",
      "l0: 0.026894, l1: 0.028435, l2: 0.036875, l3: 0.053664, l4: 0.097377, l5: 0.242028, l6: 0.460607\n",
      "\n",
      "[epoch: 331/400, batch: 536/1000, ite: 44193] train loss: 1.1827, accuracy: 93.5594%, tar: 0.0261 \n",
      "l0: 0.030903, l1: 0.031612, l2: 0.040390, l3: 0.055360, l4: 0.095571, l5: 0.194209, l6: 0.464137\n",
      "\n",
      "[epoch: 331/400, batch: 544/1000, ite: 44194] train loss: 1.1838, accuracy: 93.4874%, tar: 0.0261 \n",
      "l0: 0.031534, l1: 0.033153, l2: 0.042698, l3: 0.064915, l4: 0.107304, l5: 0.195016, l6: 0.350182\n",
      "\n",
      "[epoch: 331/400, batch: 552/1000, ite: 44195] train loss: 1.1837, accuracy: 93.9069%, tar: 0.0261 \n",
      "l0: 0.021048, l1: 0.021777, l2: 0.026415, l3: 0.036821, l4: 0.062911, l5: 0.118180, l6: 0.265810\n",
      "\n",
      "[epoch: 331/400, batch: 560/1000, ite: 44196] train loss: 1.1819, accuracy: 95.7774%, tar: 0.0261 \n",
      "l0: 0.021028, l1: 0.022066, l2: 0.029009, l3: 0.045776, l4: 0.076847, l5: 0.140286, l6: 0.290782\n",
      "\n",
      "[epoch: 331/400, batch: 568/1000, ite: 44197] train loss: 1.1806, accuracy: 95.4324%, tar: 0.0261 \n",
      "l0: 0.026634, l1: 0.027004, l2: 0.035669, l3: 0.053526, l4: 0.098212, l5: 0.199354, l6: 0.363325\n",
      "\n",
      "[epoch: 331/400, batch: 576/1000, ite: 44198] train loss: 1.1806, accuracy: 94.4901%, tar: 0.0261 \n",
      "l0: 0.024371, l1: 0.025235, l2: 0.034091, l3: 0.050426, l4: 0.089873, l5: 0.170235, l6: 0.316212\n",
      "\n",
      "[epoch: 331/400, batch: 584/1000, ite: 44199] train loss: 1.1798, accuracy: 95.0508%, tar: 0.0261 \n",
      "l0: 0.028535, l1: 0.030493, l2: 0.041355, l3: 0.065806, l4: 0.127362, l5: 0.234754, l6: 0.430092\n",
      "\n",
      "[epoch: 331/400, batch: 592/1000, ite: 44200] train loss: 1.1808, accuracy: 93.5618%, tar: 0.0261 \n",
      "l0: 0.029475, l1: 0.030812, l2: 0.038591, l3: 0.061072, l4: 0.112076, l5: 0.200572, l6: 0.413309\n",
      "\n",
      "[epoch: 331/400, batch: 600/1000, ite: 44201] train loss: 1.1815, accuracy: 94.6508%, tar: 0.0261 \n",
      "l0: 0.029938, l1: 0.032115, l2: 0.042482, l3: 0.058879, l4: 0.108149, l5: 0.225499, l6: 0.417488\n",
      "\n",
      "[epoch: 331/400, batch: 608/1000, ite: 44202] train loss: 1.1822, accuracy: 94.8511%, tar: 0.0261 \n",
      "l0: 0.023994, l1: 0.024607, l2: 0.031287, l3: 0.046355, l4: 0.084683, l5: 0.165648, l6: 0.426848\n",
      "\n",
      "[epoch: 331/400, batch: 616/1000, ite: 44203] train loss: 1.1825, accuracy: 94.0447%, tar: 0.0261 \n",
      "l0: 0.021166, l1: 0.023455, l2: 0.031796, l3: 0.047234, l4: 0.087550, l5: 0.186947, l6: 0.368998\n",
      "\n",
      "[epoch: 331/400, batch: 624/1000, ite: 44204] train loss: 1.1823, accuracy: 95.9318%, tar: 0.0261 \n",
      "l0: 0.028430, l1: 0.030048, l2: 0.039610, l3: 0.056501, l4: 0.103810, l5: 0.201943, l6: 0.402084\n",
      "\n",
      "[epoch: 331/400, batch: 632/1000, ite: 44205] train loss: 1.1826, accuracy: 94.3043%, tar: 0.0261 \n",
      "l0: 0.022975, l1: 0.025030, l2: 0.033618, l3: 0.051255, l4: 0.092782, l5: 0.175797, l6: 0.326663\n",
      "\n",
      "[epoch: 331/400, batch: 640/1000, ite: 44206] train loss: 1.1820, accuracy: 95.5839%, tar: 0.0261 \n",
      "l0: 0.028477, l1: 0.030420, l2: 0.040950, l3: 0.061119, l4: 0.118214, l5: 0.236396, l6: 0.443154\n",
      "\n",
      "[epoch: 331/400, batch: 648/1000, ite: 44207] train loss: 1.1831, accuracy: 94.0784%, tar: 0.0261 \n",
      "l0: 0.021475, l1: 0.022901, l2: 0.029576, l3: 0.044977, l4: 0.076175, l5: 0.155466, l6: 0.305716\n",
      "\n",
      "[epoch: 331/400, batch: 656/1000, ite: 44208] train loss: 1.1821, accuracy: 95.4890%, tar: 0.0261 \n",
      "l0: 0.028968, l1: 0.029765, l2: 0.039186, l3: 0.054935, l4: 0.093791, l5: 0.206948, l6: 0.400913\n",
      "\n",
      "[epoch: 331/400, batch: 664/1000, ite: 44209] train loss: 1.1824, accuracy: 94.0195%, tar: 0.0261 \n",
      "l0: 0.019930, l1: 0.021204, l2: 0.029785, l3: 0.046098, l4: 0.099762, l5: 0.177536, l6: 0.345132\n",
      "\n",
      "[epoch: 331/400, batch: 672/1000, ite: 44210] train loss: 1.1819, accuracy: 96.4028%, tar: 0.0260 \n",
      "l0: 0.024103, l1: 0.026392, l2: 0.037183, l3: 0.053754, l4: 0.095691, l5: 0.198494, l6: 0.433764\n",
      "\n",
      "[epoch: 331/400, batch: 680/1000, ite: 44211] train loss: 1.1825, accuracy: 95.4077%, tar: 0.0260 \n",
      "l0: 0.024172, l1: 0.025216, l2: 0.032424, l3: 0.047076, l4: 0.080814, l5: 0.154784, l6: 0.291742\n",
      "\n",
      "[epoch: 331/400, batch: 688/1000, ite: 44212] train loss: 1.1814, accuracy: 95.1577%, tar: 0.0260 \n",
      "l0: 0.021577, l1: 0.022900, l2: 0.030295, l3: 0.042640, l4: 0.078796, l5: 0.186186, l6: 0.340348\n",
      "\n",
      "[epoch: 331/400, batch: 696/1000, ite: 44213] train loss: 1.1809, accuracy: 95.3413%, tar: 0.0260 \n",
      "l0: 0.027797, l1: 0.028965, l2: 0.035378, l3: 0.050080, l4: 0.084549, l5: 0.164135, l6: 0.372274\n",
      "\n",
      "[epoch: 331/400, batch: 704/1000, ite: 44214] train loss: 1.1807, accuracy: 94.6048%, tar: 0.0260 \n",
      "l0: 0.020860, l1: 0.022322, l2: 0.031251, l3: 0.051126, l4: 0.090113, l5: 0.161903, l6: 0.338146\n",
      "\n",
      "[epoch: 331/400, batch: 712/1000, ite: 44215] train loss: 1.1801, accuracy: 95.4562%, tar: 0.0260 \n",
      "l0: 0.022454, l1: 0.023494, l2: 0.031013, l3: 0.046694, l4: 0.080698, l5: 0.162729, l6: 0.267754\n",
      "\n",
      "[epoch: 331/400, batch: 720/1000, ite: 44216] train loss: 1.1789, accuracy: 95.6486%, tar: 0.0260 \n",
      "l0: 0.025453, l1: 0.026528, l2: 0.032199, l3: 0.044369, l4: 0.077374, l5: 0.147759, l6: 0.361415\n",
      "\n",
      "[epoch: 331/400, batch: 728/1000, ite: 44217] train loss: 1.1784, accuracy: 94.4786%, tar: 0.0260 \n",
      "l0: 0.026929, l1: 0.028353, l2: 0.033583, l3: 0.044188, l4: 0.080554, l5: 0.160164, l6: 0.334744\n",
      "\n",
      "[epoch: 331/400, batch: 736/1000, ite: 44218] train loss: 1.1778, accuracy: 95.0848%, tar: 0.0260 \n",
      "l0: 0.022626, l1: 0.023871, l2: 0.031031, l3: 0.045868, l4: 0.085447, l5: 0.189596, l6: 0.392722\n",
      "\n",
      "[epoch: 331/400, batch: 744/1000, ite: 44219] train loss: 1.1779, accuracy: 94.4956%, tar: 0.0260 \n",
      "l0: 0.027658, l1: 0.029791, l2: 0.039916, l3: 0.064985, l4: 0.110453, l5: 0.218088, l6: 0.412008\n",
      "\n",
      "[epoch: 331/400, batch: 752/1000, ite: 44220] train loss: 1.1785, accuracy: 94.8991%, tar: 0.0260 \n",
      "l0: 0.026519, l1: 0.028205, l2: 0.035099, l3: 0.050615, l4: 0.090490, l5: 0.185156, l6: 0.379984\n",
      "\n",
      "[epoch: 331/400, batch: 760/1000, ite: 44221] train loss: 1.1785, accuracy: 95.2338%, tar: 0.0260 \n",
      "l0: 0.028307, l1: 0.030747, l2: 0.043458, l3: 0.069940, l4: 0.161093, l5: 0.293354, l6: 0.508790\n",
      "\n",
      "[epoch: 331/400, batch: 768/1000, ite: 44222] train loss: 1.1806, accuracy: 93.8250%, tar: 0.0260 \n",
      "l0: 0.024793, l1: 0.026048, l2: 0.033274, l3: 0.051230, l4: 0.083514, l5: 0.149088, l6: 0.319672\n",
      "\n",
      "[epoch: 331/400, batch: 776/1000, ite: 44223] train loss: 1.1798, accuracy: 95.6337%, tar: 0.0260 \n",
      "l0: 0.027993, l1: 0.029487, l2: 0.037782, l3: 0.053613, l4: 0.097899, l5: 0.204779, l6: 0.371692\n",
      "\n",
      "[epoch: 331/400, batch: 784/1000, ite: 44224] train loss: 1.1799, accuracy: 94.5800%, tar: 0.0260 \n",
      "l0: 0.030301, l1: 0.031756, l2: 0.039611, l3: 0.056537, l4: 0.096218, l5: 0.185864, l6: 0.400145\n",
      "\n",
      "[epoch: 331/400, batch: 792/1000, ite: 44225] train loss: 1.1802, accuracy: 94.2714%, tar: 0.0260 \n",
      "l0: 0.021152, l1: 0.022201, l2: 0.029812, l3: 0.042717, l4: 0.076830, l5: 0.142409, l6: 0.294548\n",
      "\n",
      "[epoch: 331/400, batch: 800/1000, ite: 44226] train loss: 1.1791, accuracy: 95.8318%, tar: 0.0260 \n",
      "l0: 0.025521, l1: 0.026641, l2: 0.034342, l3: 0.051121, l4: 0.104743, l5: 0.194368, l6: 0.400524\n",
      "\n",
      "[epoch: 331/400, batch: 808/1000, ite: 44227] train loss: 1.1794, accuracy: 94.2108%, tar: 0.0260 \n",
      "l0: 0.024362, l1: 0.025594, l2: 0.032672, l3: 0.044982, l4: 0.076100, l5: 0.179984, l6: 0.376230\n",
      "\n",
      "[epoch: 331/400, batch: 816/1000, ite: 44228] train loss: 1.1792, accuracy: 94.5265%, tar: 0.0260 \n",
      "l0: 0.023059, l1: 0.023975, l2: 0.029920, l3: 0.043187, l4: 0.071071, l5: 0.138036, l6: 0.409061\n",
      "\n",
      "[epoch: 331/400, batch: 824/1000, ite: 44229] train loss: 1.1791, accuracy: 94.8074%, tar: 0.0260 \n",
      "l0: 0.021335, l1: 0.022545, l2: 0.031145, l3: 0.045792, l4: 0.081648, l5: 0.143555, l6: 0.312387\n",
      "\n",
      "[epoch: 331/400, batch: 832/1000, ite: 44230] train loss: 1.1782, accuracy: 95.7272%, tar: 0.0259 \n",
      "l0: 0.022193, l1: 0.023518, l2: 0.029825, l3: 0.045857, l4: 0.091927, l5: 0.160748, l6: 0.315077\n",
      "\n",
      "[epoch: 331/400, batch: 840/1000, ite: 44231] train loss: 1.1775, accuracy: 95.3414%, tar: 0.0259 \n",
      "l0: 0.023751, l1: 0.025222, l2: 0.030939, l3: 0.042728, l4: 0.071954, l5: 0.145732, l6: 0.278456\n",
      "\n",
      "[epoch: 331/400, batch: 848/1000, ite: 44232] train loss: 1.1763, accuracy: 96.0109%, tar: 0.0259 \n",
      "l0: 0.027175, l1: 0.028565, l2: 0.040071, l3: 0.073789, l4: 0.131774, l5: 0.191052, l6: 0.353814\n",
      "\n",
      "[epoch: 331/400, batch: 856/1000, ite: 44233] train loss: 1.1764, accuracy: 95.5836%, tar: 0.0259 \n",
      "l0: 0.023026, l1: 0.024292, l2: 0.031436, l3: 0.043969, l4: 0.074929, l5: 0.140573, l6: 0.362412\n",
      "\n",
      "[epoch: 331/400, batch: 864/1000, ite: 44234] train loss: 1.1759, accuracy: 95.0512%, tar: 0.0259 \n",
      "l0: 0.026122, l1: 0.026545, l2: 0.031230, l3: 0.042255, l4: 0.065621, l5: 0.124683, l6: 0.268163\n",
      "\n",
      "[epoch: 331/400, batch: 872/1000, ite: 44235] train loss: 1.1746, accuracy: 95.0645%, tar: 0.0259 \n",
      "l0: 0.024109, l1: 0.025076, l2: 0.032413, l3: 0.046549, l4: 0.090102, l5: 0.177841, l6: 0.356981\n",
      "\n",
      "[epoch: 331/400, batch: 880/1000, ite: 44236] train loss: 1.1743, accuracy: 95.4429%, tar: 0.0259 \n",
      "l0: 0.026926, l1: 0.028251, l2: 0.037002, l3: 0.055630, l4: 0.100499, l5: 0.192314, l6: 0.453850\n",
      "\n",
      "[epoch: 331/400, batch: 888/1000, ite: 44237] train loss: 1.1751, accuracy: 93.9376%, tar: 0.0259 \n",
      "l0: 0.033529, l1: 0.035147, l2: 0.042853, l3: 0.063947, l4: 0.110238, l5: 0.251130, l6: 0.593306\n",
      "\n",
      "[epoch: 331/400, batch: 896/1000, ite: 44238] train loss: 1.1774, accuracy: 91.4982%, tar: 0.0259 \n",
      "l0: 0.025415, l1: 0.026269, l2: 0.034328, l3: 0.053240, l4: 0.086263, l5: 0.154598, l6: 0.302700\n",
      "\n",
      "[epoch: 331/400, batch: 904/1000, ite: 44239] train loss: 1.1766, accuracy: 95.1148%, tar: 0.0259 \n",
      "l0: 0.022969, l1: 0.024217, l2: 0.030877, l3: 0.049518, l4: 0.089834, l5: 0.182622, l6: 0.350604\n",
      "\n",
      "[epoch: 331/400, batch: 912/1000, ite: 44240] train loss: 1.1763, accuracy: 95.4248%, tar: 0.0259 \n",
      "l0: 0.025661, l1: 0.027004, l2: 0.036043, l3: 0.056546, l4: 0.114029, l5: 0.210293, l6: 0.475840\n",
      "\n",
      "[epoch: 331/400, batch: 920/1000, ite: 44241] train loss: 1.1773, accuracy: 93.8787%, tar: 0.0259 \n",
      "l0: 0.029272, l1: 0.030758, l2: 0.039868, l3: 0.056628, l4: 0.106572, l5: 0.206096, l6: 0.485132\n",
      "\n",
      "[epoch: 331/400, batch: 928/1000, ite: 44242] train loss: 1.1784, accuracy: 94.0189%, tar: 0.0259 \n",
      "l0: 0.018414, l1: 0.019253, l2: 0.025472, l3: 0.037495, l4: 0.062695, l5: 0.123318, l6: 0.239064\n",
      "\n",
      "[epoch: 331/400, batch: 936/1000, ite: 44243] train loss: 1.1768, accuracy: 96.5293%, tar: 0.0259 \n",
      "l0: 0.021370, l1: 0.022727, l2: 0.028353, l3: 0.041978, l4: 0.067252, l5: 0.146874, l6: 0.325777\n",
      "\n",
      "[epoch: 331/400, batch: 944/1000, ite: 44244] train loss: 1.1760, accuracy: 95.7046%, tar: 0.0259 \n",
      "l0: 0.028334, l1: 0.029135, l2: 0.038313, l3: 0.052619, l4: 0.085883, l5: 0.193456, l6: 0.377290\n",
      "\n",
      "[epoch: 331/400, batch: 952/1000, ite: 44245] train loss: 1.1760, accuracy: 94.9520%, tar: 0.0259 \n",
      "l0: 0.024693, l1: 0.025832, l2: 0.034352, l3: 0.050689, l4: 0.097187, l5: 0.217931, l6: 0.445543\n",
      "\n",
      "[epoch: 331/400, batch: 960/1000, ite: 44246] train loss: 1.1767, accuracy: 94.4323%, tar: 0.0259 \n",
      "l0: 0.024338, l1: 0.026516, l2: 0.037642, l3: 0.053495, l4: 0.086572, l5: 0.159797, l6: 0.347596\n",
      "\n",
      "[epoch: 331/400, batch: 968/1000, ite: 44247] train loss: 1.1763, accuracy: 95.7726%, tar: 0.0259 \n",
      "l0: 0.024019, l1: 0.025002, l2: 0.032834, l3: 0.046283, l4: 0.078910, l5: 0.142952, l6: 0.290281\n",
      "\n",
      "[epoch: 331/400, batch: 976/1000, ite: 44248] train loss: 1.1754, accuracy: 95.0930%, tar: 0.0259 \n",
      "l0: 0.026816, l1: 0.028205, l2: 0.037658, l3: 0.053414, l4: 0.094945, l5: 0.199184, l6: 0.362305\n",
      "\n",
      "[epoch: 331/400, batch: 984/1000, ite: 44249] train loss: 1.1754, accuracy: 94.4719%, tar: 0.0259 \n",
      "l0: 0.025877, l1: 0.027155, l2: 0.034631, l3: 0.051502, l4: 0.102585, l5: 0.226408, l6: 0.417482\n",
      "\n",
      "[epoch: 331/400, batch: 992/1000, ite: 44250] train loss: 1.1759, accuracy: 94.5608%, tar: 0.0259 \n",
      "l0: 0.027976, l1: 0.029168, l2: 0.038086, l3: 0.051430, l4: 0.085454, l5: 0.183410, l6: 0.301777\n",
      "\n",
      "[epoch: 331/400, batch: 1000/1000, ite: 44251] train loss: 1.1753, accuracy: 95.3165%, tar: 0.0259 \n",
      "l0: 0.030261, l1: 0.031442, l2: 0.038986, l3: 0.056159, l4: 0.100485, l5: 0.244719, l6: 0.443309\n",
      "\n",
      "[epoch: 332/400, batch: 8/1000, ite: 44252] train loss: 1.1762, accuracy: 92.8692%, tar: 0.0259 \n",
      "l0: 0.026351, l1: 0.028085, l2: 0.038589, l3: 0.059630, l4: 0.110916, l5: 0.232091, l6: 0.389501\n",
      "\n",
      "[epoch: 332/400, batch: 16/1000, ite: 44253] train loss: 1.1765, accuracy: 94.7943%, tar: 0.0259 \n",
      "l0: 0.027415, l1: 0.028575, l2: 0.038574, l3: 0.055975, l4: 0.100587, l5: 0.211212, l6: 0.464754\n",
      "\n",
      "[epoch: 332/400, batch: 24/1000, ite: 44254] train loss: 1.1774, accuracy: 93.9973%, tar: 0.0259 \n",
      "l0: 0.025377, l1: 0.026616, l2: 0.033090, l3: 0.047912, l4: 0.087177, l5: 0.175377, l6: 0.382019\n",
      "\n",
      "[epoch: 332/400, batch: 32/1000, ite: 44255] train loss: 1.1774, accuracy: 94.4716%, tar: 0.0259 \n",
      "l0: 0.025287, l1: 0.026871, l2: 0.038363, l3: 0.059997, l4: 0.113724, l5: 0.229063, l6: 0.422012\n",
      "\n",
      "[epoch: 332/400, batch: 40/1000, ite: 44256] train loss: 1.1780, accuracy: 94.4506%, tar: 0.0259 \n",
      "l0: 0.020269, l1: 0.021159, l2: 0.026457, l3: 0.040240, l4: 0.080386, l5: 0.168183, l6: 0.316440\n",
      "\n",
      "[epoch: 332/400, batch: 48/1000, ite: 44257] train loss: 1.1773, accuracy: 95.5325%, tar: 0.0259 \n",
      "l0: 0.025184, l1: 0.026378, l2: 0.033284, l3: 0.051408, l4: 0.090056, l5: 0.170276, l6: 0.362369\n",
      "\n",
      "[epoch: 332/400, batch: 56/1000, ite: 44258] train loss: 1.1771, accuracy: 95.1169%, tar: 0.0259 \n",
      "l0: 0.025850, l1: 0.027169, l2: 0.034045, l3: 0.049532, l4: 0.094576, l5: 0.191427, l6: 0.404137\n",
      "\n",
      "[epoch: 332/400, batch: 64/1000, ite: 44259] train loss: 1.1773, accuracy: 94.4820%, tar: 0.0259 \n",
      "l0: 0.022577, l1: 0.023841, l2: 0.032951, l3: 0.046705, l4: 0.079407, l5: 0.166210, l6: 0.334304\n",
      "\n",
      "[epoch: 332/400, batch: 72/1000, ite: 44260] train loss: 1.1768, accuracy: 94.9112%, tar: 0.0259 \n",
      "l0: 0.030531, l1: 0.033296, l2: 0.048575, l3: 0.078405, l4: 0.136926, l5: 0.261497, l6: 0.484956\n",
      "\n",
      "[epoch: 332/400, batch: 80/1000, ite: 44261] train loss: 1.1783, accuracy: 94.2445%, tar: 0.0259 \n",
      "l0: 0.031369, l1: 0.033045, l2: 0.042719, l3: 0.061569, l4: 0.116358, l5: 0.246640, l6: 0.460259\n",
      "\n",
      "[epoch: 332/400, batch: 88/1000, ite: 44262] train loss: 1.1794, accuracy: 93.5327%, tar: 0.0259 \n",
      "l0: 0.029321, l1: 0.030280, l2: 0.038123, l3: 0.055473, l4: 0.103163, l5: 0.202585, l6: 0.426606\n",
      "\n",
      "[epoch: 332/400, batch: 96/1000, ite: 44263] train loss: 1.1799, accuracy: 93.5632%, tar: 0.0259 \n",
      "l0: 0.026631, l1: 0.028768, l2: 0.038738, l3: 0.055978, l4: 0.099250, l5: 0.208283, l6: 0.392037\n",
      "\n",
      "[epoch: 332/400, batch: 104/1000, ite: 44264] train loss: 1.1802, accuracy: 94.5582%, tar: 0.0259 \n",
      "l0: 0.029392, l1: 0.031127, l2: 0.040148, l3: 0.057958, l4: 0.097989, l5: 0.190500, l6: 0.376558\n",
      "\n",
      "[epoch: 332/400, batch: 112/1000, ite: 44265] train loss: 1.1803, accuracy: 94.5675%, tar: 0.0259 \n",
      "l0: 0.025096, l1: 0.025856, l2: 0.031132, l3: 0.044549, l4: 0.077457, l5: 0.153443, l6: 0.322573\n",
      "\n",
      "[epoch: 332/400, batch: 120/1000, ite: 44266] train loss: 1.1796, accuracy: 94.6986%, tar: 0.0259 \n",
      "l0: 0.026171, l1: 0.027556, l2: 0.036033, l3: 0.056139, l4: 0.106772, l5: 0.201469, l6: 0.421760\n",
      "\n",
      "[epoch: 332/400, batch: 128/1000, ite: 44267] train loss: 1.1801, accuracy: 94.5668%, tar: 0.0259 \n",
      "l0: 0.019647, l1: 0.021410, l2: 0.027117, l3: 0.041374, l4: 0.080233, l5: 0.168003, l6: 0.311644\n",
      "\n",
      "[epoch: 332/400, batch: 136/1000, ite: 44268] train loss: 1.1794, accuracy: 95.9398%, tar: 0.0259 \n",
      "l0: 0.032338, l1: 0.034537, l2: 0.043549, l3: 0.065403, l4: 0.104655, l5: 0.208266, l6: 0.467586\n",
      "\n",
      "[epoch: 332/400, batch: 144/1000, ite: 44269] train loss: 1.1803, accuracy: 92.9286%, tar: 0.0259 \n",
      "l0: 0.029204, l1: 0.030623, l2: 0.039857, l3: 0.058061, l4: 0.101503, l5: 0.226033, l6: 0.425489\n",
      "\n",
      "[epoch: 332/400, batch: 152/1000, ite: 44270] train loss: 1.1808, accuracy: 94.8186%, tar: 0.0259 \n",
      "l0: 0.027559, l1: 0.029026, l2: 0.037996, l3: 0.060002, l4: 0.126825, l5: 0.229154, l6: 0.492921\n",
      "\n",
      "[epoch: 332/400, batch: 160/1000, ite: 44271] train loss: 1.1820, accuracy: 93.3595%, tar: 0.0260 \n",
      "l0: 0.027070, l1: 0.027986, l2: 0.037511, l3: 0.058059, l4: 0.122375, l5: 0.224497, l6: 0.387382\n",
      "\n",
      "[epoch: 332/400, batch: 168/1000, ite: 44272] train loss: 1.1823, accuracy: 94.1316%, tar: 0.0260 \n",
      "l0: 0.030304, l1: 0.032015, l2: 0.041009, l3: 0.057958, l4: 0.102546, l5: 0.217090, l6: 0.478458\n",
      "\n",
      "[epoch: 332/400, batch: 176/1000, ite: 44273] train loss: 1.1833, accuracy: 93.1932%, tar: 0.0260 \n",
      "l0: 0.020355, l1: 0.020981, l2: 0.026603, l3: 0.038640, l4: 0.066534, l5: 0.134410, l6: 0.265453\n",
      "\n",
      "[epoch: 332/400, batch: 184/1000, ite: 44274] train loss: 1.1820, accuracy: 95.7309%, tar: 0.0260 \n",
      "l0: 0.032631, l1: 0.033825, l2: 0.041797, l3: 0.058125, l4: 0.095110, l5: 0.163835, l6: 0.387342\n",
      "\n",
      "[epoch: 332/400, batch: 192/1000, ite: 44275] train loss: 1.1821, accuracy: 94.2652%, tar: 0.0260 \n",
      "l0: 0.026583, l1: 0.027953, l2: 0.035134, l3: 0.047588, l4: 0.080797, l5: 0.157892, l6: 0.296876\n",
      "\n",
      "[epoch: 332/400, batch: 200/1000, ite: 44276] train loss: 1.1814, accuracy: 95.2845%, tar: 0.0260 \n",
      "l0: 0.021442, l1: 0.022511, l2: 0.028068, l3: 0.044599, l4: 0.090699, l5: 0.162520, l6: 0.349315\n",
      "\n",
      "[epoch: 332/400, batch: 208/1000, ite: 44277] train loss: 1.1810, accuracy: 95.1451%, tar: 0.0260 \n",
      "l0: 0.021379, l1: 0.022226, l2: 0.028950, l3: 0.041311, l4: 0.080105, l5: 0.190789, l6: 0.357606\n",
      "\n",
      "[epoch: 332/400, batch: 216/1000, ite: 44278] train loss: 1.1807, accuracy: 94.9357%, tar: 0.0259 \n",
      "l0: 0.018641, l1: 0.019759, l2: 0.027148, l3: 0.040426, l4: 0.069000, l5: 0.132867, l6: 0.291021\n",
      "\n",
      "[epoch: 332/400, batch: 224/1000, ite: 44279] train loss: 1.1797, accuracy: 95.7845%, tar: 0.0259 \n",
      "l0: 0.032483, l1: 0.034819, l2: 0.046818, l3: 0.070697, l4: 0.134804, l5: 0.279021, l6: 0.492760\n",
      "\n",
      "[epoch: 332/400, batch: 232/1000, ite: 44280] train loss: 1.1812, accuracy: 93.2959%, tar: 0.0259 \n",
      "l0: 0.023686, l1: 0.024722, l2: 0.031573, l3: 0.042386, l4: 0.066644, l5: 0.123468, l6: 0.257060\n",
      "\n",
      "[epoch: 332/400, batch: 240/1000, ite: 44281] train loss: 1.1799, accuracy: 95.9275%, tar: 0.0259 \n",
      "l0: 0.021510, l1: 0.022321, l2: 0.030442, l3: 0.046351, l4: 0.083995, l5: 0.183336, l6: 0.385510\n",
      "\n",
      "[epoch: 332/400, batch: 248/1000, ite: 44282] train loss: 1.1799, accuracy: 94.8972%, tar: 0.0259 \n",
      "l0: 0.025878, l1: 0.026761, l2: 0.033093, l3: 0.045041, l4: 0.082574, l5: 0.187523, l6: 0.380257\n",
      "\n",
      "[epoch: 332/400, batch: 256/1000, ite: 44283] train loss: 1.1798, accuracy: 95.3569%, tar: 0.0259 \n",
      "l0: 0.023555, l1: 0.025154, l2: 0.031350, l3: 0.044444, l4: 0.078079, l5: 0.160699, l6: 0.358416\n",
      "\n",
      "[epoch: 332/400, batch: 264/1000, ite: 44284] train loss: 1.1795, accuracy: 96.0218%, tar: 0.0259 \n",
      "l0: 0.032221, l1: 0.033563, l2: 0.043608, l3: 0.061523, l4: 0.106965, l5: 0.216908, l6: 0.426961\n",
      "\n",
      "[epoch: 332/400, batch: 272/1000, ite: 44285] train loss: 1.1801, accuracy: 93.6228%, tar: 0.0259 \n",
      "l0: 0.018659, l1: 0.019854, l2: 0.027346, l3: 0.037589, l4: 0.066914, l5: 0.117711, l6: 0.225460\n",
      "\n",
      "[epoch: 332/400, batch: 280/1000, ite: 44286] train loss: 1.1786, accuracy: 96.3776%, tar: 0.0259 \n",
      "l0: 0.027602, l1: 0.028903, l2: 0.037547, l3: 0.054763, l4: 0.094499, l5: 0.191063, l6: 0.382239\n",
      "\n",
      "[epoch: 332/400, batch: 288/1000, ite: 44287] train loss: 1.1786, accuracy: 93.7970%, tar: 0.0259 \n",
      "l0: 0.031511, l1: 0.032791, l2: 0.041098, l3: 0.058994, l4: 0.096984, l5: 0.184880, l6: 0.416000\n",
      "\n",
      "[epoch: 332/400, batch: 296/1000, ite: 44288] train loss: 1.1789, accuracy: 93.7314%, tar: 0.0259 \n",
      "l0: 0.024872, l1: 0.026833, l2: 0.032633, l3: 0.049133, l4: 0.103337, l5: 0.171872, l6: 0.397302\n",
      "\n",
      "[epoch: 332/400, batch: 304/1000, ite: 44289] train loss: 1.1790, accuracy: 95.1791%, tar: 0.0259 \n",
      "l0: 0.023122, l1: 0.024575, l2: 0.031676, l3: 0.049896, l4: 0.105603, l5: 0.194186, l6: 0.372203\n",
      "\n",
      "[epoch: 332/400, batch: 312/1000, ite: 44290] train loss: 1.1790, accuracy: 95.0897%, tar: 0.0259 \n",
      "l0: 0.023569, l1: 0.024873, l2: 0.033461, l3: 0.051698, l4: 0.090652, l5: 0.150402, l6: 0.308119\n",
      "\n",
      "[epoch: 332/400, batch: 320/1000, ite: 44291] train loss: 1.1784, accuracy: 95.4661%, tar: 0.0259 \n",
      "l0: 0.022426, l1: 0.024180, l2: 0.031534, l3: 0.047730, l4: 0.087774, l5: 0.156691, l6: 0.284050\n",
      "\n",
      "[epoch: 332/400, batch: 328/1000, ite: 44292] train loss: 1.1775, accuracy: 95.9623%, tar: 0.0259 \n",
      "l0: 0.038426, l1: 0.039501, l2: 0.047833, l3: 0.067017, l4: 0.114537, l5: 0.261637, l6: 0.486743\n",
      "\n",
      "[epoch: 332/400, batch: 336/1000, ite: 44293] train loss: 1.1788, accuracy: 92.5772%, tar: 0.0259 \n",
      "l0: 0.036411, l1: 0.037987, l2: 0.046514, l3: 0.063359, l4: 0.107665, l5: 0.239363, l6: 0.459313\n",
      "\n",
      "[epoch: 332/400, batch: 344/1000, ite: 44294] train loss: 1.1797, accuracy: 93.5748%, tar: 0.0260 \n",
      "l0: 0.026000, l1: 0.027104, l2: 0.035337, l3: 0.051983, l4: 0.103211, l5: 0.227245, l6: 0.412176\n",
      "\n",
      "[epoch: 332/400, batch: 352/1000, ite: 44295] train loss: 1.1801, accuracy: 94.1195%, tar: 0.0260 \n",
      "l0: 0.018918, l1: 0.020033, l2: 0.026599, l3: 0.038080, l4: 0.076873, l5: 0.175145, l6: 0.347724\n",
      "\n",
      "[epoch: 332/400, batch: 360/1000, ite: 44296] train loss: 1.1797, accuracy: 95.7294%, tar: 0.0260 \n",
      "l0: 0.027240, l1: 0.028274, l2: 0.037368, l3: 0.054779, l4: 0.098903, l5: 0.178776, l6: 0.335507\n",
      "\n",
      "[epoch: 332/400, batch: 368/1000, ite: 44297] train loss: 1.1795, accuracy: 95.3449%, tar: 0.0260 \n",
      "l0: 0.027305, l1: 0.028680, l2: 0.036137, l3: 0.053246, l4: 0.095909, l5: 0.195423, l6: 0.339983\n",
      "\n",
      "[epoch: 332/400, batch: 376/1000, ite: 44298] train loss: 1.1793, accuracy: 95.3593%, tar: 0.0260 \n",
      "l0: 0.025087, l1: 0.026704, l2: 0.036520, l3: 0.052242, l4: 0.096525, l5: 0.211831, l6: 0.441952\n",
      "\n",
      "[epoch: 332/400, batch: 384/1000, ite: 44299] train loss: 1.1798, accuracy: 94.8735%, tar: 0.0260 \n",
      "l0: 0.022945, l1: 0.023789, l2: 0.030802, l3: 0.047696, l4: 0.091540, l5: 0.172103, l6: 0.359481\n",
      "\n",
      "[epoch: 332/400, batch: 392/1000, ite: 44300] train loss: 1.1796, accuracy: 95.2378%, tar: 0.0259 \n",
      "l0: 0.027952, l1: 0.029137, l2: 0.037223, l3: 0.053658, l4: 0.092924, l5: 0.167486, l6: 0.357320\n",
      "\n",
      "[epoch: 332/400, batch: 400/1000, ite: 44301] train loss: 1.1793, accuracy: 95.0998%, tar: 0.0260 \n",
      "l0: 0.021715, l1: 0.023409, l2: 0.032273, l3: 0.044572, l4: 0.078344, l5: 0.158635, l6: 0.298289\n",
      "\n",
      "[epoch: 332/400, batch: 408/1000, ite: 44302] train loss: 1.1786, accuracy: 95.3874%, tar: 0.0259 \n",
      "l0: 0.025170, l1: 0.026409, l2: 0.036623, l3: 0.058924, l4: 0.124200, l5: 0.239360, l6: 0.457416\n",
      "\n",
      "[epoch: 332/400, batch: 416/1000, ite: 44303] train loss: 1.1794, accuracy: 94.2631%, tar: 0.0259 \n",
      "l0: 0.019716, l1: 0.021626, l2: 0.028437, l3: 0.046558, l4: 0.087741, l5: 0.167094, l6: 0.335690\n",
      "\n",
      "[epoch: 332/400, batch: 424/1000, ite: 44304] train loss: 1.1790, accuracy: 96.1792%, tar: 0.0259 \n",
      "l0: 0.026938, l1: 0.028283, l2: 0.035290, l3: 0.048097, l4: 0.085368, l5: 0.183264, l6: 0.369827\n",
      "\n",
      "[epoch: 332/400, batch: 432/1000, ite: 44305] train loss: 1.1789, accuracy: 94.5258%, tar: 0.0259 \n",
      "l0: 0.029791, l1: 0.030851, l2: 0.037667, l3: 0.050985, l4: 0.096381, l5: 0.199544, l6: 0.387051\n",
      "\n",
      "[epoch: 332/400, batch: 440/1000, ite: 44306] train loss: 1.1790, accuracy: 94.5753%, tar: 0.0259 \n",
      "l0: 0.023339, l1: 0.024989, l2: 0.033277, l3: 0.056908, l4: 0.113769, l5: 0.233196, l6: 0.445172\n",
      "\n",
      "[epoch: 332/400, batch: 448/1000, ite: 44307] train loss: 1.1796, accuracy: 94.4692%, tar: 0.0259 \n",
      "l0: 0.022458, l1: 0.023334, l2: 0.030378, l3: 0.044497, l4: 0.080343, l5: 0.163199, l6: 0.323419\n",
      "\n",
      "[epoch: 332/400, batch: 456/1000, ite: 44308] train loss: 1.1791, accuracy: 95.7148%, tar: 0.0259 \n",
      "l0: 0.021684, l1: 0.022778, l2: 0.028999, l3: 0.043081, l4: 0.084989, l5: 0.170430, l6: 0.352376\n",
      "\n",
      "[epoch: 332/400, batch: 464/1000, ite: 44309] train loss: 1.1788, accuracy: 95.0662%, tar: 0.0259 \n",
      "l0: 0.021945, l1: 0.023814, l2: 0.032913, l3: 0.052326, l4: 0.092932, l5: 0.169671, l6: 0.341547\n",
      "\n",
      "[epoch: 332/400, batch: 472/1000, ite: 44310] train loss: 1.1785, accuracy: 95.3603%, tar: 0.0259 \n",
      "l0: 0.023046, l1: 0.023704, l2: 0.030430, l3: 0.042725, l4: 0.070039, l5: 0.151471, l6: 0.326151\n",
      "\n",
      "[epoch: 332/400, batch: 480/1000, ite: 44311] train loss: 1.1779, accuracy: 95.0138%, tar: 0.0259 \n",
      "l0: 0.021089, l1: 0.022320, l2: 0.030255, l3: 0.046510, l4: 0.083595, l5: 0.172003, l6: 0.326903\n",
      "\n",
      "[epoch: 332/400, batch: 488/1000, ite: 44312] train loss: 1.1774, accuracy: 95.4202%, tar: 0.0259 \n",
      "l0: 0.024281, l1: 0.026051, l2: 0.033706, l3: 0.052522, l4: 0.128461, l5: 0.237023, l6: 0.400678\n",
      "\n",
      "[epoch: 332/400, batch: 496/1000, ite: 44313] train loss: 1.1778, accuracy: 95.3860%, tar: 0.0259 \n",
      "l0: 0.030052, l1: 0.030913, l2: 0.038863, l3: 0.053028, l4: 0.086946, l5: 0.179853, l6: 0.456748\n",
      "\n",
      "[epoch: 332/400, batch: 504/1000, ite: 44314] train loss: 1.1784, accuracy: 92.8955%, tar: 0.0259 \n",
      "l0: 0.022260, l1: 0.023706, l2: 0.031490, l3: 0.047191, l4: 0.097835, l5: 0.181748, l6: 0.416642\n",
      "\n",
      "[epoch: 332/400, batch: 512/1000, ite: 44315] train loss: 1.1786, accuracy: 94.5356%, tar: 0.0259 \n",
      "l0: 0.033965, l1: 0.035540, l2: 0.046980, l3: 0.063549, l4: 0.113379, l5: 0.229364, l6: 0.436755\n",
      "\n",
      "[epoch: 332/400, batch: 520/1000, ite: 44316] train loss: 1.1793, accuracy: 93.6226%, tar: 0.0259 \n",
      "l0: 0.025540, l1: 0.026209, l2: 0.031495, l3: 0.041828, l4: 0.060424, l5: 0.119113, l6: 0.285531\n",
      "\n",
      "[epoch: 332/400, batch: 528/1000, ite: 44317] train loss: 1.1784, accuracy: 95.0665%, tar: 0.0259 \n",
      "l0: 0.032004, l1: 0.032808, l2: 0.042791, l3: 0.064172, l4: 0.113466, l5: 0.228839, l6: 0.425825\n",
      "\n",
      "[epoch: 332/400, batch: 536/1000, ite: 44318] train loss: 1.1790, accuracy: 93.8497%, tar: 0.0259 \n",
      "l0: 0.026034, l1: 0.027237, l2: 0.034990, l3: 0.051394, l4: 0.093045, l5: 0.157814, l6: 0.299730\n",
      "\n",
      "[epoch: 332/400, batch: 544/1000, ite: 44319] train loss: 1.1784, accuracy: 95.2388%, tar: 0.0259 \n",
      "l0: 0.029078, l1: 0.030969, l2: 0.040005, l3: 0.059656, l4: 0.119099, l5: 0.193328, l6: 0.382513\n",
      "\n",
      "[epoch: 332/400, batch: 552/1000, ite: 44320] train loss: 1.1786, accuracy: 94.6328%, tar: 0.0259 \n",
      "l0: 0.026368, l1: 0.027658, l2: 0.036409, l3: 0.052105, l4: 0.091967, l5: 0.181110, l6: 0.375653\n",
      "\n",
      "[epoch: 332/400, batch: 560/1000, ite: 44321] train loss: 1.1786, accuracy: 94.5757%, tar: 0.0259 \n",
      "l0: 0.028948, l1: 0.030779, l2: 0.039488, l3: 0.058421, l4: 0.109495, l5: 0.210924, l6: 0.455468\n",
      "\n",
      "[epoch: 332/400, batch: 568/1000, ite: 44322] train loss: 1.1792, accuracy: 93.8324%, tar: 0.0259 \n",
      "l0: 0.023043, l1: 0.024206, l2: 0.031768, l3: 0.046429, l4: 0.083075, l5: 0.153107, l6: 0.294982\n",
      "\n",
      "[epoch: 332/400, batch: 576/1000, ite: 44323] train loss: 1.1785, accuracy: 95.2981%, tar: 0.0259 \n",
      "l0: 0.019315, l1: 0.020526, l2: 0.025954, l3: 0.043434, l4: 0.080916, l5: 0.130555, l6: 0.258777\n",
      "\n",
      "[epoch: 332/400, batch: 584/1000, ite: 44324] train loss: 1.1775, accuracy: 96.0506%, tar: 0.0259 \n",
      "l0: 0.027007, l1: 0.028050, l2: 0.035804, l3: 0.056161, l4: 0.104688, l5: 0.200987, l6: 0.385642\n",
      "\n",
      "[epoch: 332/400, batch: 592/1000, ite: 44325] train loss: 1.1777, accuracy: 94.4248%, tar: 0.0259 \n",
      "l0: 0.025737, l1: 0.027337, l2: 0.035341, l3: 0.054784, l4: 0.110783, l5: 0.202879, l6: 0.422131\n",
      "\n",
      "[epoch: 332/400, batch: 600/1000, ite: 44326] train loss: 1.1780, accuracy: 94.5519%, tar: 0.0259 \n",
      "l0: 0.020485, l1: 0.023011, l2: 0.032682, l3: 0.053196, l4: 0.095608, l5: 0.155595, l6: 0.330802\n",
      "\n",
      "[epoch: 332/400, batch: 608/1000, ite: 44327] train loss: 1.1777, accuracy: 96.0257%, tar: 0.0259 \n",
      "l0: 0.026680, l1: 0.028327, l2: 0.036075, l3: 0.054345, l4: 0.112654, l5: 0.240202, l6: 0.444455\n",
      "\n",
      "[epoch: 332/400, batch: 616/1000, ite: 44328] train loss: 1.1783, accuracy: 93.5843%, tar: 0.0259 \n",
      "l0: 0.022994, l1: 0.024206, l2: 0.031727, l3: 0.046195, l4: 0.087610, l5: 0.155131, l6: 0.352945\n",
      "\n",
      "[epoch: 332/400, batch: 624/1000, ite: 44329] train loss: 1.1780, accuracy: 94.7948%, tar: 0.0259 \n",
      "l0: 0.029172, l1: 0.031039, l2: 0.039032, l3: 0.055156, l4: 0.102697, l5: 0.200005, l6: 0.409944\n",
      "\n",
      "[epoch: 332/400, batch: 632/1000, ite: 44330] train loss: 1.1783, accuracy: 94.6979%, tar: 0.0259 \n",
      "l0: 0.020095, l1: 0.020799, l2: 0.027023, l3: 0.041553, l4: 0.067241, l5: 0.114232, l6: 0.253531\n",
      "\n",
      "[epoch: 332/400, batch: 640/1000, ite: 44331] train loss: 1.1772, accuracy: 95.6963%, tar: 0.0259 \n",
      "l0: 0.030414, l1: 0.032003, l2: 0.041797, l3: 0.057025, l4: 0.101186, l5: 0.177776, l6: 0.374144\n",
      "\n",
      "[epoch: 332/400, batch: 648/1000, ite: 44332] train loss: 1.1772, accuracy: 95.1772%, tar: 0.0259 \n",
      "l0: 0.022079, l1: 0.023956, l2: 0.030776, l3: 0.044897, l4: 0.079544, l5: 0.139627, l6: 0.247061\n",
      "\n",
      "[epoch: 332/400, batch: 656/1000, ite: 44333] train loss: 1.1762, accuracy: 96.0788%, tar: 0.0259 \n",
      "l0: 0.026138, l1: 0.028051, l2: 0.039561, l3: 0.060961, l4: 0.107446, l5: 0.198799, l6: 0.362777\n",
      "\n",
      "[epoch: 332/400, batch: 664/1000, ite: 44334] train loss: 1.1763, accuracy: 94.7379%, tar: 0.0259 \n",
      "l0: 0.023813, l1: 0.024537, l2: 0.032632, l3: 0.045292, l4: 0.077744, l5: 0.156809, l6: 0.335859\n",
      "\n",
      "[epoch: 332/400, batch: 672/1000, ite: 44335] train loss: 1.1759, accuracy: 95.7007%, tar: 0.0259 \n",
      "l0: 0.021259, l1: 0.022697, l2: 0.032212, l3: 0.047102, l4: 0.082908, l5: 0.153081, l6: 0.355350\n",
      "\n",
      "[epoch: 332/400, batch: 680/1000, ite: 44336] train loss: 1.1756, accuracy: 95.4671%, tar: 0.0259 \n",
      "l0: 0.019584, l1: 0.021181, l2: 0.028692, l3: 0.041585, l4: 0.074476, l5: 0.160320, l6: 0.418849\n",
      "\n",
      "[epoch: 332/400, batch: 688/1000, ite: 44337] train loss: 1.1756, accuracy: 94.3417%, tar: 0.0258 \n",
      "l0: 0.019920, l1: 0.020556, l2: 0.025871, l3: 0.037689, l4: 0.063808, l5: 0.130267, l6: 0.270466\n",
      "\n",
      "[epoch: 332/400, batch: 696/1000, ite: 44338] train loss: 1.1746, accuracy: 95.9162%, tar: 0.0258 \n",
      "l0: 0.024111, l1: 0.025201, l2: 0.032463, l3: 0.049501, l4: 0.087408, l5: 0.155528, l6: 0.337260\n",
      "\n",
      "[epoch: 332/400, batch: 704/1000, ite: 44339] train loss: 1.1743, accuracy: 95.0258%, tar: 0.0258 \n",
      "l0: 0.023804, l1: 0.024941, l2: 0.030728, l3: 0.042682, l4: 0.074037, l5: 0.165229, l6: 0.369287\n",
      "\n",
      "[epoch: 332/400, batch: 712/1000, ite: 44340] train loss: 1.1741, accuracy: 95.0317%, tar: 0.0258 \n",
      "l0: 0.021518, l1: 0.022576, l2: 0.030613, l3: 0.052308, l4: 0.102634, l5: 0.172118, l6: 0.346341\n",
      "\n",
      "[epoch: 332/400, batch: 720/1000, ite: 44341] train loss: 1.1738, accuracy: 95.3985%, tar: 0.0258 \n",
      "l0: 0.022538, l1: 0.023585, l2: 0.032531, l3: 0.047522, l4: 0.081177, l5: 0.171743, l6: 0.358695\n",
      "\n",
      "[epoch: 332/400, batch: 728/1000, ite: 44342] train loss: 1.1736, accuracy: 94.9378%, tar: 0.0258 \n",
      "l0: 0.023291, l1: 0.024293, l2: 0.031141, l3: 0.042595, l4: 0.067453, l5: 0.131225, l6: 0.318014\n",
      "\n",
      "[epoch: 332/400, batch: 736/1000, ite: 44343] train loss: 1.1730, accuracy: 95.4906%, tar: 0.0258 \n",
      "l0: 0.027096, l1: 0.028277, l2: 0.037855, l3: 0.057272, l4: 0.103196, l5: 0.236069, l6: 0.514357\n",
      "\n",
      "[epoch: 332/400, batch: 744/1000, ite: 44344] train loss: 1.1740, accuracy: 92.8867%, tar: 0.0258 \n",
      "l0: 0.020025, l1: 0.020904, l2: 0.026555, l3: 0.039731, l4: 0.074768, l5: 0.168204, l6: 0.356382\n",
      "\n",
      "[epoch: 332/400, batch: 752/1000, ite: 44345] train loss: 1.1737, accuracy: 94.7624%, tar: 0.0258 \n",
      "l0: 0.025005, l1: 0.026594, l2: 0.034770, l3: 0.049563, l4: 0.096677, l5: 0.163322, l6: 0.298803\n",
      "\n",
      "[epoch: 332/400, batch: 760/1000, ite: 44346] train loss: 1.1732, accuracy: 96.1991%, tar: 0.0258 \n",
      "l0: 0.022626, l1: 0.023695, l2: 0.030672, l3: 0.043165, l4: 0.071062, l5: 0.140511, l6: 0.299302\n",
      "\n",
      "[epoch: 332/400, batch: 768/1000, ite: 44347] train loss: 1.1725, accuracy: 95.6437%, tar: 0.0258 \n",
      "l0: 0.023985, l1: 0.026671, l2: 0.032983, l3: 0.045529, l4: 0.079519, l5: 0.149547, l6: 0.323293\n",
      "\n",
      "[epoch: 332/400, batch: 776/1000, ite: 44348] train loss: 1.1720, accuracy: 95.8498%, tar: 0.0257 \n",
      "l0: 0.021118, l1: 0.023689, l2: 0.033357, l3: 0.057154, l4: 0.111987, l5: 0.203427, l6: 0.402073\n",
      "\n",
      "[epoch: 332/400, batch: 784/1000, ite: 44349] train loss: 1.1723, accuracy: 95.5868%, tar: 0.0257 \n",
      "l0: 0.029044, l1: 0.031091, l2: 0.040854, l3: 0.064721, l4: 0.135152, l5: 0.281316, l6: 0.512392\n",
      "\n",
      "[epoch: 332/400, batch: 792/1000, ite: 44350] train loss: 1.1736, accuracy: 93.9782%, tar: 0.0257 \n",
      "l0: 0.027404, l1: 0.028378, l2: 0.037119, l3: 0.063422, l4: 0.106076, l5: 0.180843, l6: 0.348066\n",
      "\n",
      "[epoch: 332/400, batch: 800/1000, ite: 44351] train loss: 1.1735, accuracy: 94.9530%, tar: 0.0257 \n",
      "l0: 0.025975, l1: 0.027502, l2: 0.035175, l3: 0.050641, l4: 0.092890, l5: 0.219385, l6: 0.412681\n",
      "\n",
      "[epoch: 332/400, batch: 808/1000, ite: 44352] train loss: 1.1738, accuracy: 94.3291%, tar: 0.0257 \n",
      "l0: 0.022964, l1: 0.023700, l2: 0.030783, l3: 0.046513, l4: 0.080410, l5: 0.150837, l6: 0.339691\n",
      "\n",
      "[epoch: 332/400, batch: 816/1000, ite: 44353] train loss: 1.1734, accuracy: 95.2469%, tar: 0.0257 \n",
      "l0: 0.028871, l1: 0.029662, l2: 0.040041, l3: 0.058115, l4: 0.099452, l5: 0.176662, l6: 0.380553\n",
      "\n",
      "[epoch: 332/400, batch: 824/1000, ite: 44354] train loss: 1.1735, accuracy: 94.2299%, tar: 0.0257 \n",
      "l0: 0.025683, l1: 0.026930, l2: 0.034389, l3: 0.046813, l4: 0.084282, l5: 0.177167, l6: 0.343687\n",
      "\n",
      "[epoch: 332/400, batch: 832/1000, ite: 44355] train loss: 1.1733, accuracy: 95.0574%, tar: 0.0257 \n",
      "l0: 0.027864, l1: 0.029178, l2: 0.036292, l3: 0.049410, l4: 0.092373, l5: 0.167386, l6: 0.342277\n",
      "\n",
      "[epoch: 332/400, batch: 840/1000, ite: 44356] train loss: 1.1731, accuracy: 94.7564%, tar: 0.0258 \n",
      "l0: 0.021248, l1: 0.022470, l2: 0.029153, l3: 0.042144, l4: 0.079482, l5: 0.169888, l6: 0.361039\n",
      "\n",
      "[epoch: 332/400, batch: 848/1000, ite: 44357] train loss: 1.1728, accuracy: 94.9573%, tar: 0.0257 \n",
      "l0: 0.025286, l1: 0.026568, l2: 0.035753, l3: 0.046171, l4: 0.083943, l5: 0.152895, l6: 0.313672\n",
      "\n",
      "[epoch: 332/400, batch: 856/1000, ite: 44358] train loss: 1.1724, accuracy: 95.6900%, tar: 0.0257 \n",
      "l0: 0.026905, l1: 0.028377, l2: 0.036901, l3: 0.055904, l4: 0.121720, l5: 0.242965, l6: 0.387861\n",
      "\n",
      "[epoch: 332/400, batch: 864/1000, ite: 44359] train loss: 1.1727, accuracy: 94.5810%, tar: 0.0257 \n",
      "l0: 0.020823, l1: 0.021950, l2: 0.028572, l3: 0.041208, l4: 0.067120, l5: 0.131430, l6: 0.307225\n",
      "\n",
      "[epoch: 332/400, batch: 872/1000, ite: 44360] train loss: 1.1720, accuracy: 95.4058%, tar: 0.0257 \n",
      "l0: 0.021197, l1: 0.022053, l2: 0.029735, l3: 0.044649, l4: 0.102756, l5: 0.192318, l6: 0.335924\n",
      "\n",
      "[epoch: 332/400, batch: 880/1000, ite: 44361] train loss: 1.1718, accuracy: 94.9354%, tar: 0.0257 \n",
      "l0: 0.020518, l1: 0.021862, l2: 0.027915, l3: 0.042765, l4: 0.084748, l5: 0.159649, l6: 0.328948\n",
      "\n",
      "[epoch: 332/400, batch: 888/1000, ite: 44362] train loss: 1.1714, accuracy: 95.1610%, tar: 0.0257 \n",
      "l0: 0.030184, l1: 0.031579, l2: 0.040396, l3: 0.059872, l4: 0.103981, l5: 0.207099, l6: 0.433952\n",
      "\n",
      "[epoch: 332/400, batch: 896/1000, ite: 44363] train loss: 1.1719, accuracy: 93.6332%, tar: 0.0257 \n",
      "l0: 0.024523, l1: 0.025685, l2: 0.034015, l3: 0.048229, l4: 0.087421, l5: 0.177924, l6: 0.313650\n",
      "\n",
      "[epoch: 332/400, batch: 904/1000, ite: 44364] train loss: 1.1715, accuracy: 95.8974%, tar: 0.0257 \n",
      "l0: 0.021674, l1: 0.022375, l2: 0.026956, l3: 0.034089, l4: 0.058419, l5: 0.108371, l6: 0.251367\n",
      "\n",
      "[epoch: 332/400, batch: 912/1000, ite: 44365] train loss: 1.1704, accuracy: 96.4433%, tar: 0.0257 \n",
      "l0: 0.025197, l1: 0.026645, l2: 0.035465, l3: 0.052774, l4: 0.097827, l5: 0.184524, l6: 0.382176\n",
      "\n",
      "[epoch: 332/400, batch: 920/1000, ite: 44366] train loss: 1.1704, accuracy: 94.6647%, tar: 0.0257 \n",
      "l0: 0.019313, l1: 0.021254, l2: 0.028488, l3: 0.041301, l4: 0.078502, l5: 0.170238, l6: 0.391488\n",
      "\n",
      "[epoch: 332/400, batch: 928/1000, ite: 44367] train loss: 1.1704, accuracy: 95.8204%, tar: 0.0257 \n",
      "l0: 0.023886, l1: 0.025681, l2: 0.032368, l3: 0.047827, l4: 0.091982, l5: 0.170817, l6: 0.350210\n",
      "\n",
      "[epoch: 332/400, batch: 936/1000, ite: 44368] train loss: 1.1702, accuracy: 94.9844%, tar: 0.0257 \n",
      "l0: 0.026138, l1: 0.026853, l2: 0.034065, l3: 0.048133, l4: 0.086046, l5: 0.181559, l6: 0.441654\n",
      "\n",
      "[epoch: 332/400, batch: 944/1000, ite: 44369] train loss: 1.1705, accuracy: 93.6607%, tar: 0.0257 \n",
      "l0: 0.023024, l1: 0.025250, l2: 0.035612, l3: 0.056235, l4: 0.103803, l5: 0.237301, l6: 0.475809\n",
      "\n",
      "[epoch: 332/400, batch: 952/1000, ite: 44370] train loss: 1.1712, accuracy: 94.7284%, tar: 0.0257 \n",
      "l0: 0.028372, l1: 0.029491, l2: 0.037811, l3: 0.053611, l4: 0.097181, l5: 0.195231, l6: 0.438806\n",
      "\n",
      "[epoch: 332/400, batch: 960/1000, ite: 44371] train loss: 1.1717, accuracy: 93.7910%, tar: 0.0257 \n",
      "l0: 0.034109, l1: 0.035188, l2: 0.044539, l3: 0.060867, l4: 0.102176, l5: 0.211936, l6: 0.446995\n",
      "\n",
      "[epoch: 332/400, batch: 968/1000, ite: 44372] train loss: 1.1722, accuracy: 94.2148%, tar: 0.0257 \n",
      "l0: 0.026777, l1: 0.027720, l2: 0.033111, l3: 0.042400, l4: 0.072502, l5: 0.162018, l6: 0.340622\n",
      "\n",
      "[epoch: 332/400, batch: 976/1000, ite: 44373] train loss: 1.1719, accuracy: 94.6646%, tar: 0.0257 \n",
      "l0: 0.022330, l1: 0.023296, l2: 0.030442, l3: 0.041890, l4: 0.067270, l5: 0.125522, l6: 0.282761\n",
      "\n",
      "[epoch: 332/400, batch: 984/1000, ite: 44374] train loss: 1.1711, accuracy: 95.7558%, tar: 0.0257 \n",
      "l0: 0.034273, l1: 0.037335, l2: 0.048332, l3: 0.072662, l4: 0.144930, l5: 0.290502, l6: 0.507344\n",
      "\n",
      "[epoch: 332/400, batch: 992/1000, ite: 44375] train loss: 1.1724, accuracy: 93.6983%, tar: 0.0257 \n",
      "l0: 0.022177, l1: 0.022963, l2: 0.030249, l3: 0.042278, l4: 0.088932, l5: 0.169485, l6: 0.338972\n",
      "\n",
      "[epoch: 332/400, batch: 1000/1000, ite: 44376] train loss: 1.1721, accuracy: 95.0979%, tar: 0.0257 \n",
      "l0: 0.019240, l1: 0.019768, l2: 0.025909, l3: 0.037824, l4: 0.064285, l5: 0.122737, l6: 0.290050\n",
      "\n",
      "[epoch: 333/400, batch: 8/1000, ite: 44377] train loss: 1.1713, accuracy: 95.9494%, tar: 0.0257 \n",
      "l0: 0.023998, l1: 0.025259, l2: 0.030778, l3: 0.042897, l4: 0.097711, l5: 0.169702, l6: 0.328007\n",
      "\n",
      "[epoch: 333/400, batch: 16/1000, ite: 44378] train loss: 1.1710, accuracy: 95.1397%, tar: 0.0257 \n",
      "l0: 0.026874, l1: 0.028413, l2: 0.037515, l3: 0.052829, l4: 0.087087, l5: 0.200176, l6: 0.435907\n",
      "\n",
      "[epoch: 333/400, batch: 24/1000, ite: 44379] train loss: 1.1714, accuracy: 94.8248%, tar: 0.0257 \n",
      "l0: 0.023440, l1: 0.024934, l2: 0.034273, l3: 0.052474, l4: 0.087499, l5: 0.166831, l6: 0.365220\n",
      "\n",
      "[epoch: 333/400, batch: 32/1000, ite: 44380] train loss: 1.1713, accuracy: 94.5867%, tar: 0.0257 \n",
      "l0: 0.017969, l1: 0.019380, l2: 0.026536, l3: 0.038677, l4: 0.071468, l5: 0.148695, l6: 0.318502\n",
      "\n",
      "[epoch: 333/400, batch: 40/1000, ite: 44381] train loss: 1.1707, accuracy: 95.4837%, tar: 0.0257 \n",
      "l0: 0.019761, l1: 0.020435, l2: 0.027344, l3: 0.039275, l4: 0.066401, l5: 0.113866, l6: 0.277047\n",
      "\n",
      "[epoch: 333/400, batch: 48/1000, ite: 44382] train loss: 1.1698, accuracy: 96.3299%, tar: 0.0256 \n",
      "l0: 0.025847, l1: 0.027383, l2: 0.036932, l3: 0.061244, l4: 0.109838, l5: 0.213459, l6: 0.451947\n",
      "\n",
      "[epoch: 333/400, batch: 56/1000, ite: 44383] train loss: 1.1704, accuracy: 94.5303%, tar: 0.0257 \n",
      "l0: 0.021194, l1: 0.022927, l2: 0.032799, l3: 0.053840, l4: 0.115678, l5: 0.211784, l6: 0.363821\n",
      "\n",
      "[epoch: 333/400, batch: 64/1000, ite: 44384] train loss: 1.1705, accuracy: 95.5352%, tar: 0.0256 \n",
      "l0: 0.026524, l1: 0.027677, l2: 0.035273, l3: 0.050164, l4: 0.090918, l5: 0.198667, l6: 0.389182\n",
      "\n",
      "[epoch: 333/400, batch: 72/1000, ite: 44385] train loss: 1.1706, accuracy: 94.0732%, tar: 0.0256 \n",
      "l0: 0.020768, l1: 0.022014, l2: 0.029928, l3: 0.042480, l4: 0.081611, l5: 0.139279, l6: 0.339786\n",
      "\n",
      "[epoch: 333/400, batch: 80/1000, ite: 44386] train loss: 1.1702, accuracy: 94.8866%, tar: 0.0256 \n",
      "l0: 0.024069, l1: 0.025216, l2: 0.031292, l3: 0.046698, l4: 0.079953, l5: 0.144508, l6: 0.300857\n",
      "\n",
      "[epoch: 333/400, batch: 88/1000, ite: 44387] train loss: 1.1696, accuracy: 96.0097%, tar: 0.0256 \n",
      "l0: 0.023064, l1: 0.024334, l2: 0.030857, l3: 0.043639, l4: 0.070593, l5: 0.140792, l6: 0.358788\n",
      "\n",
      "[epoch: 333/400, batch: 96/1000, ite: 44388] train loss: 1.1693, accuracy: 95.9289%, tar: 0.0256 \n",
      "l0: 0.029300, l1: 0.030370, l2: 0.037971, l3: 0.054484, l4: 0.111787, l5: 0.232245, l6: 0.494397\n",
      "\n",
      "[epoch: 333/400, batch: 104/1000, ite: 44389] train loss: 1.1702, accuracy: 93.5755%, tar: 0.0256 \n",
      "l0: 0.037681, l1: 0.039293, l2: 0.049088, l3: 0.067486, l4: 0.119928, l5: 0.259664, l6: 0.555586\n",
      "\n",
      "[epoch: 333/400, batch: 112/1000, ite: 44390] train loss: 1.1715, accuracy: 91.7102%, tar: 0.0257 \n",
      "l0: 0.021553, l1: 0.022454, l2: 0.028925, l3: 0.043296, l4: 0.077126, l5: 0.181750, l6: 0.339538\n",
      "\n",
      "[epoch: 333/400, batch: 120/1000, ite: 44391] train loss: 1.1712, accuracy: 95.2579%, tar: 0.0256 \n",
      "l0: 0.023350, l1: 0.025867, l2: 0.035003, l3: 0.052369, l4: 0.097207, l5: 0.194029, l6: 0.415188\n",
      "\n",
      "[epoch: 333/400, batch: 128/1000, ite: 44392] train loss: 1.1715, accuracy: 95.1149%, tar: 0.0256 \n",
      "l0: 0.019488, l1: 0.020305, l2: 0.026698, l3: 0.038581, l4: 0.066684, l5: 0.119816, l6: 0.250466\n",
      "\n",
      "[epoch: 333/400, batch: 136/1000, ite: 44393] train loss: 1.1705, accuracy: 96.0718%, tar: 0.0256 \n",
      "l0: 0.020386, l1: 0.020894, l2: 0.026871, l3: 0.042527, l4: 0.086247, l5: 0.159835, l6: 0.340986\n",
      "\n",
      "[epoch: 333/400, batch: 144/1000, ite: 44394] train loss: 1.1702, accuracy: 94.8127%, tar: 0.0256 \n",
      "l0: 0.022774, l1: 0.024666, l2: 0.034715, l3: 0.056701, l4: 0.103193, l5: 0.208730, l6: 0.372071\n",
      "\n",
      "[epoch: 333/400, batch: 152/1000, ite: 44395] train loss: 1.1703, accuracy: 95.4713%, tar: 0.0256 \n",
      "l0: 0.027353, l1: 0.028992, l2: 0.039253, l3: 0.062818, l4: 0.105480, l5: 0.188248, l6: 0.398481\n",
      "\n",
      "[epoch: 333/400, batch: 160/1000, ite: 44396] train loss: 1.1705, accuracy: 94.1921%, tar: 0.0256 \n",
      "l0: 0.026347, l1: 0.027642, l2: 0.037159, l3: 0.056017, l4: 0.105270, l5: 0.216458, l6: 0.413164\n",
      "\n",
      "[epoch: 333/400, batch: 168/1000, ite: 44397] train loss: 1.1708, accuracy: 94.3499%, tar: 0.0256 \n",
      "l0: 0.021127, l1: 0.022213, l2: 0.028657, l3: 0.048278, l4: 0.107547, l5: 0.205249, l6: 0.348054\n",
      "\n",
      "[epoch: 333/400, batch: 176/1000, ite: 44398] train loss: 1.1707, accuracy: 95.0424%, tar: 0.0256 \n",
      "l0: 0.025939, l1: 0.026810, l2: 0.034588, l3: 0.051662, l4: 0.094829, l5: 0.212002, l6: 0.370606\n",
      "\n",
      "[epoch: 333/400, batch: 184/1000, ite: 44399] train loss: 1.1708, accuracy: 94.1539%, tar: 0.0256 \n",
      "l0: 0.023808, l1: 0.025301, l2: 0.034676, l3: 0.054402, l4: 0.092345, l5: 0.161131, l6: 0.378730\n",
      "\n",
      "[epoch: 333/400, batch: 192/1000, ite: 44400] train loss: 1.1707, accuracy: 95.3102%, tar: 0.0256 \n",
      "l0: 0.025795, l1: 0.027159, l2: 0.033341, l3: 0.047099, l4: 0.092761, l5: 0.189544, l6: 0.383611\n",
      "\n",
      "[epoch: 333/400, batch: 200/1000, ite: 44401] train loss: 1.1707, accuracy: 94.1817%, tar: 0.0256 \n",
      "l0: 0.021633, l1: 0.022545, l2: 0.029952, l3: 0.048464, l4: 0.100498, l5: 0.148381, l6: 0.319974\n",
      "\n",
      "[epoch: 333/400, batch: 208/1000, ite: 44402] train loss: 1.1704, accuracy: 95.4805%, tar: 0.0256 \n",
      "l0: 0.021543, l1: 0.023670, l2: 0.033156, l3: 0.048668, l4: 0.085674, l5: 0.181246, l6: 0.338234\n",
      "\n",
      "[epoch: 333/400, batch: 216/1000, ite: 44403] train loss: 1.1701, accuracy: 96.0190%, tar: 0.0256 \n",
      "l0: 0.025021, l1: 0.026238, l2: 0.035069, l3: 0.051975, l4: 0.086215, l5: 0.157173, l6: 0.309207\n",
      "\n",
      "[epoch: 333/400, batch: 224/1000, ite: 44404] train loss: 1.1697, accuracy: 95.5589%, tar: 0.0256 \n",
      "l0: 0.019648, l1: 0.020594, l2: 0.026745, l3: 0.038470, l4: 0.073854, l5: 0.147593, l6: 0.281838\n",
      "\n",
      "[epoch: 333/400, batch: 232/1000, ite: 44405] train loss: 1.1690, accuracy: 95.5473%, tar: 0.0256 \n",
      "l0: 0.027987, l1: 0.028888, l2: 0.037293, l3: 0.052568, l4: 0.088083, l5: 0.176335, l6: 0.420225\n",
      "\n",
      "[epoch: 333/400, batch: 240/1000, ite: 44406] train loss: 1.1692, accuracy: 94.1642%, tar: 0.0256 \n",
      "l0: 0.021338, l1: 0.022715, l2: 0.029221, l3: 0.041827, l4: 0.081265, l5: 0.160288, l6: 0.318749\n",
      "\n",
      "[epoch: 333/400, batch: 248/1000, ite: 44407] train loss: 1.1688, accuracy: 95.4920%, tar: 0.0256 \n",
      "l0: 0.022212, l1: 0.023654, l2: 0.030937, l3: 0.046610, l4: 0.082473, l5: 0.151723, l6: 0.330959\n",
      "\n",
      "[epoch: 333/400, batch: 256/1000, ite: 44408] train loss: 1.1685, accuracy: 94.9619%, tar: 0.0255 \n",
      "l0: 0.019087, l1: 0.020257, l2: 0.024986, l3: 0.033250, l4: 0.062106, l5: 0.114179, l6: 0.245321\n",
      "\n",
      "[epoch: 333/400, batch: 264/1000, ite: 44409] train loss: 1.1675, accuracy: 96.1021%, tar: 0.0255 \n",
      "l0: 0.025661, l1: 0.026214, l2: 0.034657, l3: 0.052363, l4: 0.106133, l5: 0.199623, l6: 0.382062\n",
      "\n",
      "[epoch: 333/400, batch: 272/1000, ite: 44410] train loss: 1.1676, accuracy: 94.7129%, tar: 0.0255 \n",
      "l0: 0.025519, l1: 0.027343, l2: 0.034545, l3: 0.046309, l4: 0.080934, l5: 0.209240, l6: 0.366274\n",
      "\n",
      "[epoch: 333/400, batch: 280/1000, ite: 44411] train loss: 1.1676, accuracy: 94.9293%, tar: 0.0255 \n",
      "l0: 0.031727, l1: 0.033437, l2: 0.044258, l3: 0.060284, l4: 0.116052, l5: 0.270967, l6: 0.532050\n",
      "\n",
      "[epoch: 333/400, batch: 288/1000, ite: 44412] train loss: 1.1687, accuracy: 93.0755%, tar: 0.0255 \n",
      "l0: 0.029789, l1: 0.031677, l2: 0.040336, l3: 0.058892, l4: 0.135157, l5: 0.269664, l6: 0.477667\n",
      "\n",
      "[epoch: 333/400, batch: 296/1000, ite: 44413] train loss: 1.1696, accuracy: 93.7908%, tar: 0.0256 \n",
      "l0: 0.027711, l1: 0.029218, l2: 0.036515, l3: 0.051416, l4: 0.107391, l5: 0.184296, l6: 0.359751\n",
      "\n",
      "[epoch: 333/400, batch: 304/1000, ite: 44414] train loss: 1.1696, accuracy: 94.5974%, tar: 0.0256 \n",
      "l0: 0.025704, l1: 0.027431, l2: 0.035780, l3: 0.050703, l4: 0.096192, l5: 0.201114, l6: 0.369567\n",
      "\n",
      "[epoch: 333/400, batch: 312/1000, ite: 44415] train loss: 1.1696, accuracy: 95.1971%, tar: 0.0256 \n",
      "l0: 0.032456, l1: 0.033525, l2: 0.044162, l3: 0.065355, l4: 0.121847, l5: 0.256220, l6: 0.518466\n",
      "\n",
      "[epoch: 333/400, batch: 320/1000, ite: 44416] train loss: 1.1706, accuracy: 93.1601%, tar: 0.0256 \n",
      "l0: 0.025066, l1: 0.026266, l2: 0.032454, l3: 0.048318, l4: 0.086241, l5: 0.179192, l6: 0.381181\n",
      "\n",
      "[epoch: 333/400, batch: 328/1000, ite: 44417] train loss: 1.1706, accuracy: 95.3082%, tar: 0.0256 \n",
      "l0: 0.041383, l1: 0.042178, l2: 0.052090, l3: 0.071215, l4: 0.112129, l5: 0.210232, l6: 0.460018\n",
      "\n",
      "[epoch: 333/400, batch: 336/1000, ite: 44418] train loss: 1.1713, accuracy: 92.7957%, tar: 0.0256 \n",
      "l0: 0.023625, l1: 0.024564, l2: 0.032019, l3: 0.045831, l4: 0.085259, l5: 0.148048, l6: 0.264736\n",
      "\n",
      "[epoch: 333/400, batch: 344/1000, ite: 44419] train loss: 1.1707, accuracy: 95.7397%, tar: 0.0256 \n",
      "l0: 0.021342, l1: 0.022304, l2: 0.028870, l3: 0.042718, l4: 0.082434, l5: 0.150552, l6: 0.328669\n",
      "\n",
      "[epoch: 333/400, batch: 352/1000, ite: 44420] train loss: 1.1703, accuracy: 95.2580%, tar: 0.0256 \n",
      "l0: 0.030862, l1: 0.031727, l2: 0.038668, l3: 0.051163, l4: 0.089294, l5: 0.148673, l6: 0.338338\n",
      "\n",
      "[epoch: 333/400, batch: 360/1000, ite: 44421] train loss: 1.1700, accuracy: 95.3384%, tar: 0.0256 \n",
      "l0: 0.025267, l1: 0.027175, l2: 0.036115, l3: 0.063171, l4: 0.130408, l5: 0.256523, l6: 0.550661\n",
      "\n",
      "[epoch: 333/400, batch: 368/1000, ite: 44422] train loss: 1.1711, accuracy: 94.0694%, tar: 0.0256 \n",
      "l0: 0.024269, l1: 0.025728, l2: 0.034720, l3: 0.055722, l4: 0.097163, l5: 0.179816, l6: 0.393723\n",
      "\n",
      "[epoch: 333/400, batch: 376/1000, ite: 44423] train loss: 1.1712, accuracy: 94.8878%, tar: 0.0256 \n",
      "l0: 0.030441, l1: 0.031299, l2: 0.041334, l3: 0.059197, l4: 0.117578, l5: 0.227115, l6: 0.437641\n",
      "\n",
      "[epoch: 333/400, batch: 384/1000, ite: 44424] train loss: 1.1717, accuracy: 93.8562%, tar: 0.0256 \n",
      "l0: 0.028226, l1: 0.029734, l2: 0.039097, l3: 0.057889, l4: 0.103133, l5: 0.182081, l6: 0.340583\n",
      "\n",
      "[epoch: 333/400, batch: 392/1000, ite: 44425] train loss: 1.1716, accuracy: 95.5436%, tar: 0.0256 \n",
      "l0: 0.029906, l1: 0.032106, l2: 0.041943, l3: 0.065180, l4: 0.118778, l5: 0.232932, l6: 0.476495\n",
      "\n",
      "[epoch: 333/400, batch: 400/1000, ite: 44426] train loss: 1.1723, accuracy: 94.1158%, tar: 0.0256 \n",
      "l0: 0.019360, l1: 0.020650, l2: 0.029848, l3: 0.048504, l4: 0.100222, l5: 0.203688, l6: 0.386583\n",
      "\n",
      "[epoch: 333/400, batch: 408/1000, ite: 44427] train loss: 1.1724, accuracy: 94.9212%, tar: 0.0256 \n",
      "l0: 0.021965, l1: 0.023098, l2: 0.031546, l3: 0.049723, l4: 0.111934, l5: 0.229290, l6: 0.489915\n",
      "\n",
      "[epoch: 333/400, batch: 416/1000, ite: 44428] train loss: 1.1730, accuracy: 94.1518%, tar: 0.0256 \n",
      "l0: 0.022449, l1: 0.023370, l2: 0.028844, l3: 0.040849, l4: 0.072981, l5: 0.142007, l6: 0.318274\n",
      "\n",
      "[epoch: 333/400, batch: 424/1000, ite: 44429] train loss: 1.1725, accuracy: 94.9230%, tar: 0.0256 \n",
      "l0: 0.024014, l1: 0.025055, l2: 0.033285, l3: 0.048856, l4: 0.082540, l5: 0.154852, l6: 0.304923\n",
      "\n",
      "[epoch: 333/400, batch: 432/1000, ite: 44430] train loss: 1.1721, accuracy: 95.1920%, tar: 0.0256 \n",
      "l0: 0.027914, l1: 0.029283, l2: 0.037267, l3: 0.053319, l4: 0.097946, l5: 0.213312, l6: 0.399025\n",
      "\n",
      "[epoch: 333/400, batch: 440/1000, ite: 44431] train loss: 1.1723, accuracy: 94.4869%, tar: 0.0256 \n",
      "l0: 0.031243, l1: 0.033402, l2: 0.044797, l3: 0.062873, l4: 0.125895, l5: 0.288015, l6: 0.571395\n",
      "\n",
      "[epoch: 333/400, batch: 448/1000, ite: 44432] train loss: 1.1736, accuracy: 92.8666%, tar: 0.0256 \n",
      "l0: 0.019933, l1: 0.020837, l2: 0.027573, l3: 0.038913, l4: 0.072780, l5: 0.126382, l6: 0.311001\n",
      "\n",
      "[epoch: 333/400, batch: 456/1000, ite: 44433] train loss: 1.1731, accuracy: 95.7580%, tar: 0.0256 \n",
      "l0: 0.022372, l1: 0.023487, l2: 0.031171, l3: 0.046521, l4: 0.081228, l5: 0.144825, l6: 0.313394\n",
      "\n",
      "[epoch: 333/400, batch: 464/1000, ite: 44434] train loss: 1.1726, accuracy: 95.2726%, tar: 0.0256 \n",
      "l0: 0.026549, l1: 0.028284, l2: 0.038360, l3: 0.056382, l4: 0.102416, l5: 0.174821, l6: 0.342815\n",
      "\n",
      "[epoch: 333/400, batch: 472/1000, ite: 44435] train loss: 1.1725, accuracy: 95.2854%, tar: 0.0256 \n",
      "l0: 0.023869, l1: 0.025109, l2: 0.031835, l3: 0.045342, l4: 0.085875, l5: 0.168427, l6: 0.341601\n",
      "\n",
      "[epoch: 333/400, batch: 480/1000, ite: 44436] train loss: 1.1723, accuracy: 94.4599%, tar: 0.0256 \n",
      "l0: 0.021458, l1: 0.022729, l2: 0.028541, l3: 0.039601, l4: 0.066868, l5: 0.140977, l6: 0.318735\n",
      "\n",
      "[epoch: 333/400, batch: 488/1000, ite: 44437] train loss: 1.1718, accuracy: 95.5419%, tar: 0.0256 \n",
      "l0: 0.026072, l1: 0.027394, l2: 0.035131, l3: 0.054382, l4: 0.117075, l5: 0.270261, l6: 0.468277\n",
      "\n",
      "[epoch: 333/400, batch: 496/1000, ite: 44438] train loss: 1.1725, accuracy: 93.4597%, tar: 0.0256 \n",
      "l0: 0.017655, l1: 0.019031, l2: 0.024949, l3: 0.039316, l4: 0.070276, l5: 0.130570, l6: 0.301565\n",
      "\n",
      "[epoch: 333/400, batch: 504/1000, ite: 44439] train loss: 1.1719, accuracy: 96.2038%, tar: 0.0256 \n",
      "l0: 0.028588, l1: 0.030250, l2: 0.039514, l3: 0.055137, l4: 0.091963, l5: 0.193630, l6: 0.408804\n",
      "\n",
      "[epoch: 333/400, batch: 512/1000, ite: 44440] train loss: 1.1721, accuracy: 94.0500%, tar: 0.0256 \n",
      "l0: 0.029342, l1: 0.029992, l2: 0.037564, l3: 0.052459, l4: 0.095514, l5: 0.182481, l6: 0.403745\n",
      "\n",
      "[epoch: 333/400, batch: 520/1000, ite: 44441] train loss: 1.1722, accuracy: 93.5361%, tar: 0.0256 \n",
      "l0: 0.020655, l1: 0.021882, l2: 0.029210, l3: 0.044665, l4: 0.081684, l5: 0.170017, l6: 0.450983\n",
      "\n",
      "[epoch: 333/400, batch: 528/1000, ite: 44442] train loss: 1.1725, accuracy: 94.9032%, tar: 0.0256 \n",
      "l0: 0.026332, l1: 0.026974, l2: 0.034859, l3: 0.051717, l4: 0.095791, l5: 0.178104, l6: 0.347723\n",
      "\n",
      "[epoch: 333/400, batch: 536/1000, ite: 44443] train loss: 1.1724, accuracy: 95.3168%, tar: 0.0256 \n",
      "l0: 0.030390, l1: 0.031274, l2: 0.037916, l3: 0.051670, l4: 0.085267, l5: 0.171081, l6: 0.352088\n",
      "\n",
      "[epoch: 333/400, batch: 544/1000, ite: 44444] train loss: 1.1722, accuracy: 93.9940%, tar: 0.0256 \n",
      "l0: 0.027225, l1: 0.028343, l2: 0.035700, l3: 0.050161, l4: 0.084576, l5: 0.169761, l6: 0.306229\n",
      "\n",
      "[epoch: 333/400, batch: 552/1000, ite: 44445] train loss: 1.1719, accuracy: 95.1325%, tar: 0.0256 \n",
      "l0: 0.034879, l1: 0.035666, l2: 0.045907, l3: 0.060926, l4: 0.108897, l5: 0.254444, l6: 0.490329\n",
      "\n",
      "[epoch: 333/400, batch: 560/1000, ite: 44446] train loss: 1.1727, accuracy: 92.9160%, tar: 0.0256 \n",
      "l0: 0.022760, l1: 0.025134, l2: 0.034722, l3: 0.052822, l4: 0.094584, l5: 0.176262, l6: 0.373621\n",
      "\n",
      "[epoch: 333/400, batch: 568/1000, ite: 44447] train loss: 1.1727, accuracy: 95.5782%, tar: 0.0256 \n",
      "l0: 0.021336, l1: 0.021949, l2: 0.027642, l3: 0.038410, l4: 0.069402, l5: 0.124205, l6: 0.242651\n",
      "\n",
      "[epoch: 333/400, batch: 576/1000, ite: 44448] train loss: 1.1718, accuracy: 96.0701%, tar: 0.0256 \n",
      "l0: 0.023373, l1: 0.025381, l2: 0.033257, l3: 0.055683, l4: 0.129854, l5: 0.256460, l6: 0.465789\n",
      "\n",
      "[epoch: 333/400, batch: 584/1000, ite: 44449] train loss: 1.1724, accuracy: 94.0867%, tar: 0.0256 \n",
      "l0: 0.024986, l1: 0.025498, l2: 0.032521, l3: 0.042749, l4: 0.072257, l5: 0.136350, l6: 0.272470\n",
      "\n",
      "[epoch: 333/400, batch: 592/1000, ite: 44450] train loss: 1.1718, accuracy: 95.2050%, tar: 0.0256 \n",
      "l0: 0.025234, l1: 0.026745, l2: 0.034382, l3: 0.047628, l4: 0.087158, l5: 0.233869, l6: 0.407758\n",
      "\n",
      "[epoch: 333/400, batch: 600/1000, ite: 44451] train loss: 1.1720, accuracy: 94.8468%, tar: 0.0256 \n",
      "l0: 0.028511, l1: 0.031007, l2: 0.041580, l3: 0.061109, l4: 0.102805, l5: 0.202972, l6: 0.390156\n",
      "\n",
      "[epoch: 333/400, batch: 608/1000, ite: 44452] train loss: 1.1722, accuracy: 94.9682%, tar: 0.0256 \n",
      "l0: 0.016250, l1: 0.017002, l2: 0.022009, l3: 0.035905, l4: 0.061678, l5: 0.107881, l6: 0.222736\n",
      "\n",
      "[epoch: 333/400, batch: 616/1000, ite: 44453] train loss: 1.1712, accuracy: 96.3234%, tar: 0.0256 \n",
      "l0: 0.020453, l1: 0.021790, l2: 0.030251, l3: 0.047074, l4: 0.087304, l5: 0.188638, l6: 0.381538\n",
      "\n",
      "[epoch: 333/400, batch: 624/1000, ite: 44454] train loss: 1.1712, accuracy: 95.9989%, tar: 0.0256 \n",
      "l0: 0.018557, l1: 0.021452, l2: 0.032818, l3: 0.061662, l4: 0.102733, l5: 0.189330, l6: 0.424232\n",
      "\n",
      "[epoch: 333/400, batch: 632/1000, ite: 44455] train loss: 1.1714, accuracy: 94.9544%, tar: 0.0256 \n",
      "l0: 0.016990, l1: 0.018070, l2: 0.024432, l3: 0.036049, l4: 0.060254, l5: 0.124682, l6: 0.259118\n",
      "\n",
      "[epoch: 333/400, batch: 640/1000, ite: 44456] train loss: 1.1706, accuracy: 96.0123%, tar: 0.0255 \n",
      "l0: 0.020254, l1: 0.021544, l2: 0.028424, l3: 0.043174, l4: 0.096261, l5: 0.190385, l6: 0.367779\n",
      "\n",
      "[epoch: 333/400, batch: 648/1000, ite: 44457] train loss: 1.1705, accuracy: 94.9888%, tar: 0.0255 \n",
      "l0: 0.029299, l1: 0.030442, l2: 0.038012, l3: 0.055400, l4: 0.109916, l5: 0.239338, l6: 0.464942\n",
      "\n",
      "[epoch: 333/400, batch: 656/1000, ite: 44458] train loss: 1.1711, accuracy: 93.8730%, tar: 0.0255 \n",
      "l0: 0.035492, l1: 0.037184, l2: 0.047458, l3: 0.070926, l4: 0.138278, l5: 0.255530, l6: 0.484633\n",
      "\n",
      "[epoch: 333/400, batch: 664/1000, ite: 44459] train loss: 1.1720, accuracy: 93.5013%, tar: 0.0256 \n",
      "l0: 0.024775, l1: 0.026129, l2: 0.033860, l3: 0.048812, l4: 0.083170, l5: 0.172617, l6: 0.376708\n",
      "\n",
      "[epoch: 333/400, batch: 672/1000, ite: 44460] train loss: 1.1719, accuracy: 95.2232%, tar: 0.0255 \n",
      "l0: 0.021009, l1: 0.021987, l2: 0.029780, l3: 0.043965, l4: 0.088364, l5: 0.209628, l6: 0.423149\n",
      "\n",
      "[epoch: 333/400, batch: 680/1000, ite: 44461] train loss: 1.1721, accuracy: 95.0701%, tar: 0.0255 \n",
      "l0: 0.022150, l1: 0.023689, l2: 0.030099, l3: 0.043120, l4: 0.078551, l5: 0.172745, l6: 0.395429\n",
      "\n",
      "[epoch: 333/400, batch: 688/1000, ite: 44462] train loss: 1.1721, accuracy: 95.4222%, tar: 0.0255 \n",
      "l0: 0.027731, l1: 0.029508, l2: 0.038848, l3: 0.060968, l4: 0.127178, l5: 0.254290, l6: 0.529840\n",
      "\n",
      "[epoch: 333/400, batch: 696/1000, ite: 44463] train loss: 1.1730, accuracy: 93.3104%, tar: 0.0255 \n",
      "l0: 0.020489, l1: 0.021493, l2: 0.027731, l3: 0.040086, l4: 0.071762, l5: 0.138640, l6: 0.262606\n",
      "\n",
      "[epoch: 333/400, batch: 704/1000, ite: 44464] train loss: 1.1723, accuracy: 95.6736%, tar: 0.0255 \n",
      "l0: 0.023239, l1: 0.024296, l2: 0.032357, l3: 0.050529, l4: 0.091985, l5: 0.167221, l6: 0.328508\n",
      "\n",
      "[epoch: 333/400, batch: 712/1000, ite: 44465] train loss: 1.1721, accuracy: 94.7679%, tar: 0.0255 \n",
      "l0: 0.025743, l1: 0.026897, l2: 0.037724, l3: 0.053981, l4: 0.089302, l5: 0.177562, l6: 0.383232\n",
      "\n",
      "[epoch: 333/400, batch: 720/1000, ite: 44466] train loss: 1.1721, accuracy: 95.2206%, tar: 0.0255 \n",
      "l0: 0.021696, l1: 0.023405, l2: 0.030190, l3: 0.047475, l4: 0.097505, l5: 0.245484, l6: 0.429353\n",
      "\n",
      "[epoch: 333/400, batch: 728/1000, ite: 44467] train loss: 1.1724, accuracy: 94.2534%, tar: 0.0255 \n",
      "l0: 0.020021, l1: 0.020961, l2: 0.026492, l3: 0.036982, l4: 0.060797, l5: 0.100251, l6: 0.213548\n",
      "\n",
      "[epoch: 333/400, batch: 736/1000, ite: 44468] train loss: 1.1714, accuracy: 95.9743%, tar: 0.0255 \n",
      "l0: 0.029755, l1: 0.031472, l2: 0.040203, l3: 0.060602, l4: 0.119963, l5: 0.228577, l6: 0.416065\n",
      "\n",
      "[epoch: 333/400, batch: 744/1000, ite: 44469] train loss: 1.1718, accuracy: 94.6524%, tar: 0.0255 \n",
      "l0: 0.024959, l1: 0.026233, l2: 0.033371, l3: 0.049747, l4: 0.090553, l5: 0.183924, l6: 0.407752\n",
      "\n",
      "[epoch: 333/400, batch: 752/1000, ite: 44470] train loss: 1.1719, accuracy: 93.9888%, tar: 0.0255 \n",
      "l0: 0.028464, l1: 0.029551, l2: 0.036322, l3: 0.050408, l4: 0.088900, l5: 0.176289, l6: 0.407381\n",
      "\n",
      "[epoch: 333/400, batch: 760/1000, ite: 44471] train loss: 1.1720, accuracy: 94.2619%, tar: 0.0255 \n",
      "l0: 0.026683, l1: 0.028146, l2: 0.036832, l3: 0.061457, l4: 0.112912, l5: 0.206053, l6: 0.348725\n",
      "\n",
      "[epoch: 333/400, batch: 768/1000, ite: 44472] train loss: 1.1720, accuracy: 94.8447%, tar: 0.0255 \n",
      "l0: 0.028602, l1: 0.029514, l2: 0.038698, l3: 0.053185, l4: 0.087842, l5: 0.178350, l6: 0.337288\n",
      "\n",
      "[epoch: 333/400, batch: 776/1000, ite: 44473] train loss: 1.1719, accuracy: 94.8452%, tar: 0.0255 \n",
      "l0: 0.026372, l1: 0.027242, l2: 0.034903, l3: 0.048105, l4: 0.082982, l5: 0.183769, l6: 0.409937\n",
      "\n",
      "[epoch: 333/400, batch: 784/1000, ite: 44474] train loss: 1.1720, accuracy: 94.7197%, tar: 0.0255 \n",
      "l0: 0.018626, l1: 0.019375, l2: 0.024570, l3: 0.034316, l4: 0.064607, l5: 0.116533, l6: 0.253466\n",
      "\n",
      "[epoch: 333/400, batch: 792/1000, ite: 44475] train loss: 1.1712, accuracy: 96.4320%, tar: 0.0255 \n",
      "l0: 0.020781, l1: 0.021660, l2: 0.029140, l3: 0.043769, l4: 0.076441, l5: 0.150683, l6: 0.337855\n",
      "\n",
      "[epoch: 333/400, batch: 800/1000, ite: 44476] train loss: 1.1709, accuracy: 95.0257%, tar: 0.0255 \n",
      "l0: 0.023949, l1: 0.025860, l2: 0.035084, l3: 0.051882, l4: 0.103011, l5: 0.210493, l6: 0.408795\n",
      "\n",
      "[epoch: 333/400, batch: 808/1000, ite: 44477] train loss: 1.1711, accuracy: 95.2622%, tar: 0.0255 \n",
      "l0: 0.020585, l1: 0.021877, l2: 0.028109, l3: 0.039014, l4: 0.066201, l5: 0.129547, l6: 0.267448\n",
      "\n",
      "[epoch: 333/400, batch: 816/1000, ite: 44478] train loss: 1.1704, accuracy: 96.0615%, tar: 0.0255 \n",
      "l0: 0.021139, l1: 0.022459, l2: 0.030313, l3: 0.044346, l4: 0.082661, l5: 0.158373, l6: 0.311871\n",
      "\n",
      "[epoch: 333/400, batch: 824/1000, ite: 44479] train loss: 1.1701, accuracy: 95.6500%, tar: 0.0255 \n",
      "l0: 0.021122, l1: 0.022822, l2: 0.031779, l3: 0.048345, l4: 0.074428, l5: 0.130520, l6: 0.263952\n",
      "\n",
      "[epoch: 333/400, batch: 832/1000, ite: 44480] train loss: 1.1694, accuracy: 95.8630%, tar: 0.0255 \n",
      "l0: 0.024656, l1: 0.025349, l2: 0.032358, l3: 0.044357, l4: 0.079288, l5: 0.152014, l6: 0.332449\n",
      "\n",
      "[epoch: 333/400, batch: 840/1000, ite: 44481] train loss: 1.1691, accuracy: 95.1093%, tar: 0.0255 \n",
      "l0: 0.035085, l1: 0.036737, l2: 0.047033, l3: 0.073703, l4: 0.144583, l5: 0.278032, l6: 0.527262\n",
      "\n",
      "[epoch: 333/400, batch: 848/1000, ite: 44482] train loss: 1.1702, accuracy: 92.7463%, tar: 0.0255 \n",
      "l0: 0.027527, l1: 0.028986, l2: 0.035699, l3: 0.050113, l4: 0.085395, l5: 0.165990, l6: 0.376437\n",
      "\n",
      "[epoch: 333/400, batch: 856/1000, ite: 44483] train loss: 1.1701, accuracy: 94.2184%, tar: 0.0255 \n",
      "l0: 0.021541, l1: 0.022168, l2: 0.029311, l3: 0.043676, l4: 0.073028, l5: 0.131210, l6: 0.263979\n",
      "\n",
      "[epoch: 333/400, batch: 864/1000, ite: 44484] train loss: 1.1695, accuracy: 96.4230%, tar: 0.0255 \n",
      "l0: 0.018535, l1: 0.018945, l2: 0.021947, l3: 0.026910, l4: 0.053852, l5: 0.094154, l6: 0.254043\n",
      "\n",
      "[epoch: 333/400, batch: 872/1000, ite: 44485] train loss: 1.1686, accuracy: 96.0785%, tar: 0.0255 \n",
      "l0: 0.030898, l1: 0.032175, l2: 0.041922, l3: 0.059015, l4: 0.108417, l5: 0.253326, l6: 0.474077\n",
      "\n",
      "[epoch: 333/400, batch: 880/1000, ite: 44486] train loss: 1.1693, accuracy: 92.8055%, tar: 0.0255 \n",
      "l0: 0.027230, l1: 0.029301, l2: 0.038549, l3: 0.058150, l4: 0.108466, l5: 0.199409, l6: 0.359740\n",
      "\n",
      "[epoch: 333/400, batch: 888/1000, ite: 44487] train loss: 1.1693, accuracy: 94.6844%, tar: 0.0255 \n",
      "l0: 0.022842, l1: 0.023735, l2: 0.030607, l3: 0.045350, l4: 0.078482, l5: 0.176177, l6: 0.310155\n",
      "\n",
      "[epoch: 333/400, batch: 896/1000, ite: 44488] train loss: 1.1690, accuracy: 95.7960%, tar: 0.0255 \n",
      "l0: 0.025387, l1: 0.026483, l2: 0.035020, l3: 0.049401, l4: 0.084253, l5: 0.202811, l6: 0.390234\n",
      "\n",
      "[epoch: 333/400, batch: 904/1000, ite: 44489] train loss: 1.1691, accuracy: 94.7610%, tar: 0.0255 \n",
      "l0: 0.020326, l1: 0.021790, l2: 0.028781, l3: 0.043078, l4: 0.074563, l5: 0.151042, l6: 0.322521\n",
      "\n",
      "[epoch: 333/400, batch: 912/1000, ite: 44490] train loss: 1.1687, accuracy: 95.8390%, tar: 0.0255 \n",
      "l0: 0.021576, l1: 0.021903, l2: 0.029045, l3: 0.043025, l4: 0.078182, l5: 0.192155, l6: 0.335201\n",
      "\n",
      "[epoch: 333/400, batch: 920/1000, ite: 44491] train loss: 1.1685, accuracy: 94.8541%, tar: 0.0255 \n",
      "l0: 0.026639, l1: 0.028682, l2: 0.038433, l3: 0.054745, l4: 0.100837, l5: 0.225109, l6: 0.420874\n",
      "\n",
      "[epoch: 333/400, batch: 928/1000, ite: 44492] train loss: 1.1688, accuracy: 94.6731%, tar: 0.0255 \n",
      "l0: 0.033208, l1: 0.034716, l2: 0.043134, l3: 0.061277, l4: 0.097247, l5: 0.170348, l6: 0.314616\n",
      "\n",
      "[epoch: 333/400, batch: 936/1000, ite: 44493] train loss: 1.1686, accuracy: 94.8849%, tar: 0.0255 \n",
      "l0: 0.033667, l1: 0.034560, l2: 0.041964, l3: 0.056327, l4: 0.096964, l5: 0.180370, l6: 0.363042\n",
      "\n",
      "[epoch: 333/400, batch: 944/1000, ite: 44494] train loss: 1.1686, accuracy: 93.8034%, tar: 0.0255 \n",
      "l0: 0.021631, l1: 0.022527, l2: 0.027208, l3: 0.044268, l4: 0.080225, l5: 0.174801, l6: 0.330983\n",
      "\n",
      "[epoch: 333/400, batch: 952/1000, ite: 44495] train loss: 1.1683, accuracy: 95.0529%, tar: 0.0255 \n",
      "l0: 0.022924, l1: 0.024478, l2: 0.029746, l3: 0.044593, l4: 0.086567, l5: 0.170907, l6: 0.388463\n",
      "\n",
      "[epoch: 333/400, batch: 960/1000, ite: 44496] train loss: 1.1683, accuracy: 94.9068%, tar: 0.0255 \n",
      "l0: 0.025619, l1: 0.027054, l2: 0.035514, l3: 0.052823, l4: 0.099156, l5: 0.203547, l6: 0.411045\n",
      "\n",
      "[epoch: 333/400, batch: 968/1000, ite: 44497] train loss: 1.1685, accuracy: 94.6078%, tar: 0.0255 \n",
      "l0: 0.025847, l1: 0.027914, l2: 0.037489, l3: 0.059905, l4: 0.110702, l5: 0.195385, l6: 0.417463\n",
      "\n",
      "[epoch: 333/400, batch: 976/1000, ite: 44498] train loss: 1.1687, accuracy: 94.7102%, tar: 0.0255 \n",
      "l0: 0.027298, l1: 0.028517, l2: 0.038252, l3: 0.060027, l4: 0.115207, l5: 0.244598, l6: 0.545761\n",
      "\n",
      "[epoch: 333/400, batch: 984/1000, ite: 44499] train loss: 1.1696, accuracy: 92.4563%, tar: 0.0255 \n",
      "l0: 0.024678, l1: 0.026312, l2: 0.035067, l3: 0.057150, l4: 0.100659, l5: 0.194073, l6: 0.381715\n",
      "\n",
      "[epoch: 333/400, batch: 992/1000, ite: 44500] train loss: 1.1697, accuracy: 95.1515%, tar: 0.0255 \n",
      "l0: 0.033099, l1: 0.034368, l2: 0.041964, l3: 0.056965, l4: 0.100078, l5: 0.219067, l6: 0.474523\n",
      "\n",
      "[epoch: 333/400, batch: 1000/1000, ite: 44501] train loss: 1.1702, accuracy: 93.1217%, tar: 0.0255 \n",
      "l0: 0.027658, l1: 0.029661, l2: 0.040009, l3: 0.062907, l4: 0.135058, l5: 0.249280, l6: 0.460309\n",
      "\n",
      "[epoch: 334/400, batch: 8/1000, ite: 44502] train loss: 1.1708, accuracy: 94.1861%, tar: 0.0255 \n",
      "l0: 0.024397, l1: 0.025897, l2: 0.034147, l3: 0.050510, l4: 0.085712, l5: 0.199836, l6: 0.431174\n",
      "\n",
      "[epoch: 334/400, batch: 16/1000, ite: 44503] train loss: 1.1711, accuracy: 94.8938%, tar: 0.0255 \n",
      "l0: 0.026381, l1: 0.027407, l2: 0.034841, l3: 0.048659, l4: 0.079562, l5: 0.136704, l6: 0.305186\n",
      "\n",
      "[epoch: 334/400, batch: 24/1000, ite: 44504] train loss: 1.1706, accuracy: 95.2385%, tar: 0.0255 \n",
      "l0: 0.024872, l1: 0.025542, l2: 0.032426, l3: 0.043315, l4: 0.070000, l5: 0.136407, l6: 0.376076\n",
      "\n",
      "[epoch: 334/400, batch: 32/1000, ite: 44505] train loss: 1.1705, accuracy: 94.8365%, tar: 0.0255 \n",
      "l0: 0.021542, l1: 0.022823, l2: 0.027486, l3: 0.038505, l4: 0.062973, l5: 0.125471, l6: 0.316362\n",
      "\n",
      "[epoch: 334/400, batch: 40/1000, ite: 44506] train loss: 1.1700, accuracy: 95.6671%, tar: 0.0255 \n",
      "l0: 0.031259, l1: 0.032579, l2: 0.043205, l3: 0.061278, l4: 0.110347, l5: 0.210393, l6: 0.469901\n",
      "\n",
      "[epoch: 334/400, batch: 48/1000, ite: 44507] train loss: 1.1705, accuracy: 94.3173%, tar: 0.0255 \n",
      "l0: 0.022387, l1: 0.023271, l2: 0.032050, l3: 0.046934, l4: 0.088181, l5: 0.183386, l6: 0.385574\n",
      "\n",
      "[epoch: 334/400, batch: 56/1000, ite: 44508] train loss: 1.1705, accuracy: 94.8415%, tar: 0.0255 \n",
      "l0: 0.026290, l1: 0.027961, l2: 0.036601, l3: 0.055515, l4: 0.114027, l5: 0.226256, l6: 0.432725\n",
      "\n",
      "[epoch: 334/400, batch: 64/1000, ite: 44509] train loss: 1.1709, accuracy: 93.8007%, tar: 0.0255 \n",
      "l0: 0.025536, l1: 0.026040, l2: 0.033522, l3: 0.046006, l4: 0.076554, l5: 0.176292, l6: 0.334723\n",
      "\n",
      "[epoch: 334/400, batch: 72/1000, ite: 44510] train loss: 1.1707, accuracy: 94.7606%, tar: 0.0255 \n",
      "l0: 0.020524, l1: 0.021828, l2: 0.030772, l3: 0.051233, l4: 0.107056, l5: 0.225049, l6: 0.440173\n",
      "\n",
      "[epoch: 334/400, batch: 80/1000, ite: 44511] train loss: 1.1710, accuracy: 94.1240%, tar: 0.0255 \n",
      "l0: 0.022779, l1: 0.024218, l2: 0.032903, l3: 0.050176, l4: 0.100673, l5: 0.221400, l6: 0.464983\n",
      "\n",
      "[epoch: 334/400, batch: 88/1000, ite: 44512] train loss: 1.1714, accuracy: 94.7961%, tar: 0.0255 \n",
      "l0: 0.029710, l1: 0.030753, l2: 0.039166, l3: 0.056013, l4: 0.106488, l5: 0.245459, l6: 0.615600\n",
      "\n",
      "[epoch: 334/400, batch: 96/1000, ite: 44513] train loss: 1.1726, accuracy: 92.3575%, tar: 0.0255 \n",
      "l0: 0.021900, l1: 0.022981, l2: 0.030666, l3: 0.045791, l4: 0.096283, l5: 0.213055, l6: 0.431457\n",
      "\n",
      "[epoch: 334/400, batch: 104/1000, ite: 44514] train loss: 1.1728, accuracy: 93.9572%, tar: 0.0255 \n",
      "l0: 0.018554, l1: 0.019739, l2: 0.026844, l3: 0.044551, l4: 0.083254, l5: 0.185096, l6: 0.363101\n",
      "\n",
      "[epoch: 334/400, batch: 112/1000, ite: 44515] train loss: 1.1727, accuracy: 95.0750%, tar: 0.0255 \n",
      "l0: 0.021145, l1: 0.022002, l2: 0.028324, l3: 0.042870, l4: 0.077812, l5: 0.137766, l6: 0.299463\n",
      "\n",
      "[epoch: 334/400, batch: 120/1000, ite: 44516] train loss: 1.1723, accuracy: 96.1765%, tar: 0.0255 \n",
      "l0: 0.020619, l1: 0.021874, l2: 0.029586, l3: 0.047936, l4: 0.094531, l5: 0.176331, l6: 0.442847\n",
      "\n",
      "[epoch: 334/400, batch: 128/1000, ite: 44517] train loss: 1.1725, accuracy: 94.6611%, tar: 0.0255 \n",
      "l0: 0.034915, l1: 0.036042, l2: 0.045746, l3: 0.065895, l4: 0.114598, l5: 0.212019, l6: 0.494390\n",
      "\n",
      "[epoch: 334/400, batch: 136/1000, ite: 44518] train loss: 1.1731, accuracy: 92.5216%, tar: 0.0255 \n",
      "l0: 0.021581, l1: 0.023245, l2: 0.031906, l3: 0.054030, l4: 0.106193, l5: 0.227179, l6: 0.427363\n",
      "\n",
      "[epoch: 334/400, batch: 144/1000, ite: 44519] train loss: 1.1734, accuracy: 95.2873%, tar: 0.0255 \n",
      "l0: 0.021533, l1: 0.023204, l2: 0.030648, l3: 0.045038, l4: 0.083729, l5: 0.204740, l6: 0.365537\n",
      "\n",
      "[epoch: 334/400, batch: 152/1000, ite: 44520] train loss: 1.1734, accuracy: 95.7037%, tar: 0.0255 \n",
      "l0: 0.025226, l1: 0.026417, l2: 0.033274, l3: 0.045361, l4: 0.075750, l5: 0.154678, l6: 0.322796\n",
      "\n",
      "[epoch: 334/400, batch: 160/1000, ite: 44521] train loss: 1.1731, accuracy: 95.1180%, tar: 0.0255 \n",
      "l0: 0.026331, l1: 0.027806, l2: 0.036025, l3: 0.048528, l4: 0.081553, l5: 0.197586, l6: 0.431393\n",
      "\n",
      "[epoch: 334/400, batch: 168/1000, ite: 44522] train loss: 1.1733, accuracy: 93.8234%, tar: 0.0255 \n",
      "l0: 0.022874, l1: 0.023900, l2: 0.031536, l3: 0.044605, l4: 0.078768, l5: 0.156227, l6: 0.332072\n",
      "\n",
      "[epoch: 334/400, batch: 176/1000, ite: 44523] train loss: 1.1730, accuracy: 95.6351%, tar: 0.0255 \n",
      "l0: 0.032289, l1: 0.033556, l2: 0.040842, l3: 0.053192, l4: 0.087526, l5: 0.150783, l6: 0.292747\n",
      "\n",
      "[epoch: 334/400, batch: 184/1000, ite: 44524] train loss: 1.1726, accuracy: 95.5353%, tar: 0.0255 \n",
      "l0: 0.029899, l1: 0.031474, l2: 0.040416, l3: 0.053778, l4: 0.088257, l5: 0.175045, l6: 0.362159\n",
      "\n",
      "[epoch: 334/400, batch: 192/1000, ite: 44525] train loss: 1.1726, accuracy: 95.5109%, tar: 0.0255 \n",
      "l0: 0.020939, l1: 0.022689, l2: 0.029227, l3: 0.040373, l4: 0.075840, l5: 0.134214, l6: 0.320273\n",
      "\n",
      "[epoch: 334/400, batch: 200/1000, ite: 44526] train loss: 1.1722, accuracy: 96.2393%, tar: 0.0255 \n",
      "l0: 0.026025, l1: 0.027906, l2: 0.038677, l3: 0.054110, l4: 0.093695, l5: 0.213181, l6: 0.452031\n",
      "\n",
      "[epoch: 334/400, batch: 208/1000, ite: 44527] train loss: 1.1725, accuracy: 94.4322%, tar: 0.0255 \n",
      "l0: 0.020455, l1: 0.021876, l2: 0.028896, l3: 0.046806, l4: 0.086965, l5: 0.188441, l6: 0.376783\n",
      "\n",
      "[epoch: 334/400, batch: 216/1000, ite: 44528] train loss: 1.1725, accuracy: 95.0157%, tar: 0.0255 \n",
      "l0: 0.026863, l1: 0.028122, l2: 0.036056, l3: 0.049402, l4: 0.082180, l5: 0.140044, l6: 0.309075\n",
      "\n",
      "[epoch: 334/400, batch: 224/1000, ite: 44529] train loss: 1.1721, accuracy: 95.1467%, tar: 0.0255 \n",
      "l0: 0.028455, l1: 0.029662, l2: 0.038381, l3: 0.056636, l4: 0.100649, l5: 0.227485, l6: 0.542355\n",
      "\n",
      "[epoch: 334/400, batch: 232/1000, ite: 44530] train loss: 1.1729, accuracy: 93.2329%, tar: 0.0255 \n",
      "l0: 0.019882, l1: 0.020983, l2: 0.027777, l3: 0.040789, l4: 0.070029, l5: 0.126195, l6: 0.250398\n",
      "\n",
      "[epoch: 334/400, batch: 240/1000, ite: 44531] train loss: 1.1722, accuracy: 95.8087%, tar: 0.0255 \n",
      "l0: 0.020118, l1: 0.021177, l2: 0.028718, l3: 0.043803, l4: 0.076956, l5: 0.151416, l6: 0.296666\n",
      "\n",
      "[epoch: 334/400, batch: 248/1000, ite: 44532] train loss: 1.1718, accuracy: 95.7741%, tar: 0.0254 \n",
      "l0: 0.021110, l1: 0.022264, l2: 0.027137, l3: 0.035455, l4: 0.061654, l5: 0.127187, l6: 0.249965\n",
      "\n",
      "[epoch: 334/400, batch: 256/1000, ite: 44533] train loss: 1.1711, accuracy: 96.1427%, tar: 0.0254 \n",
      "l0: 0.027029, l1: 0.028554, l2: 0.036877, l3: 0.056188, l4: 0.100863, l5: 0.184797, l6: 0.348891\n",
      "\n",
      "[epoch: 334/400, batch: 264/1000, ite: 44534] train loss: 1.1710, accuracy: 95.3907%, tar: 0.0254 \n",
      "l0: 0.029873, l1: 0.031091, l2: 0.038617, l3: 0.056186, l4: 0.102476, l5: 0.194886, l6: 0.362973\n",
      "\n",
      "[epoch: 334/400, batch: 272/1000, ite: 44535] train loss: 1.1710, accuracy: 94.0724%, tar: 0.0255 \n",
      "l0: 0.029753, l1: 0.031169, l2: 0.041578, l3: 0.060102, l4: 0.107226, l5: 0.236237, l6: 0.407518\n",
      "\n",
      "[epoch: 334/400, batch: 280/1000, ite: 44536] train loss: 1.1713, accuracy: 93.8602%, tar: 0.0255 \n",
      "l0: 0.025014, l1: 0.026276, l2: 0.033053, l3: 0.047454, l4: 0.093726, l5: 0.191196, l6: 0.417625\n",
      "\n",
      "[epoch: 334/400, batch: 288/1000, ite: 44537] train loss: 1.1715, accuracy: 94.7045%, tar: 0.0255 \n",
      "l0: 0.016258, l1: 0.017179, l2: 0.022469, l3: 0.032881, l4: 0.078472, l5: 0.176938, l6: 0.353456\n",
      "\n",
      "[epoch: 334/400, batch: 296/1000, ite: 44538] train loss: 1.1713, accuracy: 95.9987%, tar: 0.0254 \n",
      "l0: 0.024155, l1: 0.025314, l2: 0.031770, l3: 0.048140, l4: 0.085088, l5: 0.176022, l6: 0.387184\n",
      "\n",
      "[epoch: 334/400, batch: 304/1000, ite: 44539] train loss: 1.1713, accuracy: 94.7942%, tar: 0.0254 \n",
      "l0: 0.017908, l1: 0.018780, l2: 0.024176, l3: 0.039807, l4: 0.074094, l5: 0.131951, l6: 0.262146\n",
      "\n",
      "[epoch: 334/400, batch: 312/1000, ite: 44540] train loss: 1.1706, accuracy: 96.2461%, tar: 0.0254 \n",
      "l0: 0.025437, l1: 0.026518, l2: 0.033612, l3: 0.048138, l4: 0.077580, l5: 0.132913, l6: 0.259034\n",
      "\n",
      "[epoch: 334/400, batch: 320/1000, ite: 44541] train loss: 1.1701, accuracy: 95.7268%, tar: 0.0254 \n",
      "l0: 0.028755, l1: 0.030681, l2: 0.038026, l3: 0.052298, l4: 0.099490, l5: 0.208230, l6: 0.391251\n",
      "\n",
      "[epoch: 334/400, batch: 328/1000, ite: 44542] train loss: 1.1702, accuracy: 93.6671%, tar: 0.0254 \n",
      "l0: 0.023677, l1: 0.024528, l2: 0.033063, l3: 0.043447, l4: 0.071729, l5: 0.143285, l6: 0.333039\n",
      "\n",
      "[epoch: 334/400, batch: 336/1000, ite: 44543] train loss: 1.1699, accuracy: 95.0700%, tar: 0.0254 \n",
      "l0: 0.029873, l1: 0.031691, l2: 0.042377, l3: 0.062053, l4: 0.101368, l5: 0.211877, l6: 0.386925\n",
      "\n",
      "[epoch: 334/400, batch: 344/1000, ite: 44544] train loss: 1.1701, accuracy: 94.6466%, tar: 0.0254 \n",
      "l0: 0.027609, l1: 0.028450, l2: 0.035119, l3: 0.047950, l4: 0.092242, l5: 0.197778, l6: 0.355403\n",
      "\n",
      "[epoch: 334/400, batch: 352/1000, ite: 44545] train loss: 1.1700, accuracy: 94.7579%, tar: 0.0254 \n",
      "l0: 0.019629, l1: 0.020861, l2: 0.029206, l3: 0.051739, l4: 0.097453, l5: 0.172921, l6: 0.328926\n",
      "\n",
      "[epoch: 334/400, batch: 360/1000, ite: 44546] train loss: 1.1698, accuracy: 95.4937%, tar: 0.0254 \n",
      "l0: 0.026804, l1: 0.028354, l2: 0.034614, l3: 0.052967, l4: 0.093243, l5: 0.179044, l6: 0.339543\n",
      "\n",
      "[epoch: 334/400, batch: 368/1000, ite: 44547] train loss: 1.1697, accuracy: 95.1502%, tar: 0.0254 \n",
      "l0: 0.027217, l1: 0.028431, l2: 0.038429, l3: 0.056425, l4: 0.106008, l5: 0.255825, l6: 0.489530\n",
      "\n",
      "[epoch: 334/400, batch: 376/1000, ite: 44548] train loss: 1.1703, accuracy: 93.9240%, tar: 0.0254 \n",
      "l0: 0.025554, l1: 0.027052, l2: 0.035383, l3: 0.049560, l4: 0.080365, l5: 0.168955, l6: 0.408729\n",
      "\n",
      "[epoch: 334/400, batch: 384/1000, ite: 44549] train loss: 1.1703, accuracy: 94.0422%, tar: 0.0254 \n",
      "l0: 0.020400, l1: 0.021693, l2: 0.028162, l3: 0.045121, l4: 0.093550, l5: 0.170297, l6: 0.376826\n",
      "\n",
      "[epoch: 334/400, batch: 392/1000, ite: 44550] train loss: 1.1703, accuracy: 95.0168%, tar: 0.0254 \n",
      "l0: 0.023798, l1: 0.024378, l2: 0.030402, l3: 0.040566, l4: 0.070208, l5: 0.136979, l6: 0.293585\n",
      "\n",
      "[epoch: 334/400, batch: 400/1000, ite: 44551] train loss: 1.1698, accuracy: 95.7022%, tar: 0.0254 \n",
      "l0: 0.022662, l1: 0.023495, l2: 0.029996, l3: 0.045338, l4: 0.083785, l5: 0.156702, l6: 0.333334\n",
      "\n",
      "[epoch: 334/400, batch: 408/1000, ite: 44552] train loss: 1.1696, accuracy: 94.9724%, tar: 0.0254 \n",
      "l0: 0.028554, l1: 0.031403, l2: 0.039528, l3: 0.061525, l4: 0.116393, l5: 0.233367, l6: 0.373348\n",
      "\n",
      "[epoch: 334/400, batch: 416/1000, ite: 44553] train loss: 1.1697, accuracy: 95.3537%, tar: 0.0254 \n",
      "l0: 0.023736, l1: 0.024883, l2: 0.033469, l3: 0.048110, l4: 0.083047, l5: 0.172919, l6: 0.428432\n",
      "\n",
      "[epoch: 334/400, batch: 424/1000, ite: 44554] train loss: 1.1699, accuracy: 94.6776%, tar: 0.0254 \n",
      "l0: 0.027013, l1: 0.028645, l2: 0.036985, l3: 0.059077, l4: 0.109822, l5: 0.230734, l6: 0.511951\n",
      "\n",
      "[epoch: 334/400, batch: 432/1000, ite: 44555] train loss: 1.1705, accuracy: 93.9305%, tar: 0.0254 \n",
      "l0: 0.024563, l1: 0.025793, l2: 0.032552, l3: 0.044288, l4: 0.077586, l5: 0.142178, l6: 0.395941\n",
      "\n",
      "[epoch: 334/400, batch: 440/1000, ite: 44556] train loss: 1.1705, accuracy: 95.2146%, tar: 0.0254 \n",
      "l0: 0.023353, l1: 0.024718, l2: 0.032559, l3: 0.047408, l4: 0.092916, l5: 0.174793, l6: 0.333412\n",
      "\n",
      "[epoch: 334/400, batch: 448/1000, ite: 44557] train loss: 1.1703, accuracy: 95.0752%, tar: 0.0254 \n",
      "l0: 0.023640, l1: 0.025357, l2: 0.034619, l3: 0.053694, l4: 0.099792, l5: 0.199736, l6: 0.342656\n",
      "\n",
      "[epoch: 334/400, batch: 456/1000, ite: 44558] train loss: 1.1702, accuracy: 95.2962%, tar: 0.0254 \n",
      "l0: 0.024735, l1: 0.026250, l2: 0.032770, l3: 0.050024, l4: 0.084213, l5: 0.164164, l6: 0.322007\n",
      "\n",
      "[epoch: 334/400, batch: 464/1000, ite: 44559] train loss: 1.1699, accuracy: 95.2480%, tar: 0.0254 \n",
      "l0: 0.017698, l1: 0.018383, l2: 0.024246, l3: 0.037837, l4: 0.096304, l5: 0.153470, l6: 0.288149\n",
      "\n",
      "[epoch: 334/400, batch: 472/1000, ite: 44560] train loss: 1.1695, accuracy: 96.4355%, tar: 0.0254 \n",
      "l0: 0.028467, l1: 0.029428, l2: 0.034142, l3: 0.046014, l4: 0.074592, l5: 0.159560, l6: 0.327233\n",
      "\n",
      "[epoch: 334/400, batch: 480/1000, ite: 44561] train loss: 1.1693, accuracy: 94.5382%, tar: 0.0254 \n",
      "l0: 0.026919, l1: 0.027971, l2: 0.035284, l3: 0.051310, l4: 0.094568, l5: 0.174198, l6: 0.361167\n",
      "\n",
      "[epoch: 334/400, batch: 488/1000, ite: 44562] train loss: 1.1692, accuracy: 94.6378%, tar: 0.0254 \n",
      "l0: 0.023859, l1: 0.024582, l2: 0.031741, l3: 0.048905, l4: 0.102756, l5: 0.191593, l6: 0.420254\n",
      "\n",
      "[epoch: 334/400, batch: 496/1000, ite: 44563] train loss: 1.1694, accuracy: 93.7386%, tar: 0.0254 \n",
      "l0: 0.027440, l1: 0.028530, l2: 0.036900, l3: 0.056577, l4: 0.110466, l5: 0.208845, l6: 0.480179\n",
      "\n",
      "[epoch: 334/400, batch: 504/1000, ite: 44564] train loss: 1.1699, accuracy: 92.5027%, tar: 0.0254 \n",
      "l0: 0.021787, l1: 0.022617, l2: 0.028150, l3: 0.038046, l4: 0.066635, l5: 0.120007, l6: 0.295851\n",
      "\n",
      "[epoch: 334/400, batch: 512/1000, ite: 44565] train loss: 1.1694, accuracy: 95.6702%, tar: 0.0254 \n",
      "l0: 0.026293, l1: 0.027769, l2: 0.035723, l3: 0.052184, l4: 0.092194, l5: 0.246494, l6: 0.450350\n",
      "\n",
      "[epoch: 334/400, batch: 520/1000, ite: 44566] train loss: 1.1698, accuracy: 93.4365%, tar: 0.0254 \n",
      "l0: 0.021063, l1: 0.022678, l2: 0.030256, l3: 0.046828, l4: 0.083840, l5: 0.151134, l6: 0.269844\n",
      "\n",
      "[epoch: 334/400, batch: 528/1000, ite: 44567] train loss: 1.1693, accuracy: 96.3109%, tar: 0.0254 \n",
      "l0: 0.022798, l1: 0.023772, l2: 0.030768, l3: 0.043218, l4: 0.072812, l5: 0.129739, l6: 0.286431\n",
      "\n",
      "[epoch: 334/400, batch: 536/1000, ite: 44568] train loss: 1.1688, accuracy: 95.5332%, tar: 0.0254 \n",
      "l0: 0.032270, l1: 0.033264, l2: 0.041957, l3: 0.059016, l4: 0.097098, l5: 0.178804, l6: 0.355845\n",
      "\n",
      "[epoch: 334/400, batch: 544/1000, ite: 44569] train loss: 1.1688, accuracy: 94.0853%, tar: 0.0254 \n",
      "l0: 0.025483, l1: 0.026318, l2: 0.032622, l3: 0.045288, l4: 0.079064, l5: 0.161734, l6: 0.317591\n",
      "\n",
      "[epoch: 334/400, batch: 552/1000, ite: 44570] train loss: 1.1686, accuracy: 95.4068%, tar: 0.0254 \n",
      "l0: 0.019922, l1: 0.021122, l2: 0.027672, l3: 0.042476, l4: 0.076412, l5: 0.126646, l6: 0.248841\n",
      "\n",
      "[epoch: 334/400, batch: 560/1000, ite: 44571] train loss: 1.1679, accuracy: 96.6546%, tar: 0.0254 \n",
      "l0: 0.025022, l1: 0.026364, l2: 0.032147, l3: 0.046397, l4: 0.087672, l5: 0.144214, l6: 0.295354\n",
      "\n",
      "[epoch: 334/400, batch: 568/1000, ite: 44572] train loss: 1.1676, accuracy: 95.0068%, tar: 0.0254 \n",
      "l0: 0.024058, l1: 0.024846, l2: 0.031125, l3: 0.044220, l4: 0.079982, l5: 0.184977, l6: 0.401398\n",
      "\n",
      "[epoch: 334/400, batch: 576/1000, ite: 44573] train loss: 1.1676, accuracy: 94.3105%, tar: 0.0254 \n",
      "l0: 0.014978, l1: 0.016258, l2: 0.021671, l3: 0.031714, l4: 0.060405, l5: 0.110369, l6: 0.221183\n",
      "\n",
      "[epoch: 334/400, batch: 584/1000, ite: 44574] train loss: 1.1668, accuracy: 97.1606%, tar: 0.0254 \n",
      "l0: 0.025826, l1: 0.026680, l2: 0.034480, l3: 0.052420, l4: 0.089201, l5: 0.164455, l6: 0.341206\n",
      "\n",
      "[epoch: 334/400, batch: 592/1000, ite: 44575] train loss: 1.1667, accuracy: 95.5325%, tar: 0.0254 \n",
      "l0: 0.029180, l1: 0.029726, l2: 0.035653, l3: 0.048365, l4: 0.081460, l5: 0.154559, l6: 0.348230\n",
      "\n",
      "[epoch: 334/400, batch: 600/1000, ite: 44576] train loss: 1.1665, accuracy: 94.3887%, tar: 0.0254 \n",
      "l0: 0.022838, l1: 0.024486, l2: 0.032282, l3: 0.048036, l4: 0.084519, l5: 0.170344, l6: 0.347433\n",
      "\n",
      "[epoch: 334/400, batch: 608/1000, ite: 44577] train loss: 1.1664, accuracy: 95.3560%, tar: 0.0254 \n",
      "l0: 0.028868, l1: 0.029898, l2: 0.037372, l3: 0.055498, l4: 0.093984, l5: 0.165455, l6: 0.379989\n",
      "\n",
      "[epoch: 334/400, batch: 616/1000, ite: 44578] train loss: 1.1664, accuracy: 94.3243%, tar: 0.0254 \n",
      "l0: 0.034555, l1: 0.036338, l2: 0.045206, l3: 0.066349, l4: 0.128992, l5: 0.322815, l6: 0.512126\n",
      "\n",
      "[epoch: 334/400, batch: 624/1000, ite: 44579] train loss: 1.1672, accuracy: 93.1654%, tar: 0.0254 \n",
      "l0: 0.026278, l1: 0.028057, l2: 0.038283, l3: 0.057689, l4: 0.106840, l5: 0.207857, l6: 0.366190\n",
      "\n",
      "[epoch: 334/400, batch: 632/1000, ite: 44580] train loss: 1.1673, accuracy: 95.3724%, tar: 0.0254 \n",
      "l0: 0.028757, l1: 0.031504, l2: 0.036889, l3: 0.048300, l4: 0.085854, l5: 0.157480, l6: 0.354060\n",
      "\n",
      "[epoch: 334/400, batch: 640/1000, ite: 44581] train loss: 1.1672, accuracy: 95.2783%, tar: 0.0254 \n",
      "l0: 0.027996, l1: 0.028864, l2: 0.036995, l3: 0.054214, l4: 0.098726, l5: 0.169127, l6: 0.318289\n",
      "\n",
      "[epoch: 334/400, batch: 648/1000, ite: 44582] train loss: 1.1670, accuracy: 94.7909%, tar: 0.0254 \n",
      "l0: 0.032029, l1: 0.033536, l2: 0.044822, l3: 0.062574, l4: 0.096651, l5: 0.181869, l6: 0.382957\n",
      "\n",
      "[epoch: 334/400, batch: 656/1000, ite: 44583] train loss: 1.1671, accuracy: 94.5358%, tar: 0.0254 \n",
      "l0: 0.026142, l1: 0.027176, l2: 0.035010, l3: 0.055900, l4: 0.096348, l5: 0.178400, l6: 0.347860\n",
      "\n",
      "[epoch: 334/400, batch: 664/1000, ite: 44584] train loss: 1.1670, accuracy: 94.7773%, tar: 0.0254 \n",
      "l0: 0.028540, l1: 0.029799, l2: 0.038100, l3: 0.059574, l4: 0.135970, l5: 0.230088, l6: 0.389054\n",
      "\n",
      "[epoch: 334/400, batch: 672/1000, ite: 44585] train loss: 1.1672, accuracy: 94.0190%, tar: 0.0254 \n",
      "l0: 0.020968, l1: 0.022443, l2: 0.029929, l3: 0.049708, l4: 0.094587, l5: 0.187877, l6: 0.449239\n",
      "\n",
      "[epoch: 334/400, batch: 680/1000, ite: 44586] train loss: 1.1675, accuracy: 95.4480%, tar: 0.0254 \n",
      "l0: 0.033021, l1: 0.034078, l2: 0.043963, l3: 0.063141, l4: 0.110873, l5: 0.205264, l6: 0.389038\n",
      "\n",
      "[epoch: 334/400, batch: 688/1000, ite: 44587] train loss: 1.1677, accuracy: 94.7262%, tar: 0.0254 \n",
      "l0: 0.026626, l1: 0.028616, l2: 0.038047, l3: 0.061127, l4: 0.103861, l5: 0.211771, l6: 0.411751\n",
      "\n",
      "[epoch: 334/400, batch: 696/1000, ite: 44588] train loss: 1.1679, accuracy: 94.5243%, tar: 0.0254 \n",
      "l0: 0.029761, l1: 0.032018, l2: 0.042509, l3: 0.065062, l4: 0.122000, l5: 0.231747, l6: 0.475859\n",
      "\n",
      "[epoch: 334/400, batch: 704/1000, ite: 44589] train loss: 1.1684, accuracy: 93.7246%, tar: 0.0254 \n",
      "l0: 0.033460, l1: 0.036377, l2: 0.047744, l3: 0.076896, l4: 0.145401, l5: 0.252176, l6: 0.436618\n",
      "\n",
      "[epoch: 334/400, batch: 712/1000, ite: 44590] train loss: 1.1689, accuracy: 93.9565%, tar: 0.0255 \n",
      "l0: 0.015931, l1: 0.017357, l2: 0.026560, l3: 0.043914, l4: 0.086453, l5: 0.147825, l6: 0.310157\n",
      "\n",
      "[epoch: 334/400, batch: 720/1000, ite: 44591] train loss: 1.1686, accuracy: 96.3834%, tar: 0.0254 \n",
      "l0: 0.068066, l1: 0.068245, l2: 0.079341, l3: 0.104084, l4: 0.169497, l5: 0.262066, l6: 0.536057\n",
      "\n",
      "[epoch: 334/400, batch: 728/1000, ite: 44592] train loss: 1.1697, accuracy: 92.0768%, tar: 0.0255 \n",
      "l0: 0.026929, l1: 0.028132, l2: 0.036013, l3: 0.053957, l4: 0.103268, l5: 0.170413, l6: 0.401334\n",
      "\n",
      "[epoch: 334/400, batch: 736/1000, ite: 44593] train loss: 1.1698, accuracy: 94.4336%, tar: 0.0255 \n",
      "l0: 0.024962, l1: 0.027712, l2: 0.038345, l3: 0.061440, l4: 0.115818, l5: 0.190165, l6: 0.365103\n",
      "\n",
      "[epoch: 334/400, batch: 744/1000, ite: 44594] train loss: 1.1698, accuracy: 95.6975%, tar: 0.0255 \n",
      "l0: 0.026393, l1: 0.027427, l2: 0.037105, l3: 0.055806, l4: 0.105615, l5: 0.229252, l6: 0.453935\n",
      "\n",
      "[epoch: 334/400, batch: 752/1000, ite: 44595] train loss: 1.1702, accuracy: 94.3997%, tar: 0.0255 \n",
      "l0: 0.041343, l1: 0.042242, l2: 0.049526, l3: 0.061343, l4: 0.112358, l5: 0.130967, l6: 0.277454\n",
      "\n",
      "[epoch: 334/400, batch: 760/1000, ite: 44596] train loss: 1.1699, accuracy: 94.7634%, tar: 0.0255 \n",
      "l0: 0.035083, l1: 0.037034, l2: 0.043542, l3: 0.065044, l4: 0.120003, l5: 0.251064, l6: 0.521992\n",
      "\n",
      "[epoch: 334/400, batch: 768/1000, ite: 44597] train loss: 1.1706, accuracy: 93.2849%, tar: 0.0256 \n",
      "l0: 0.027316, l1: 0.029017, l2: 0.038485, l3: 0.059434, l4: 0.113092, l5: 0.216504, l6: 0.411964\n",
      "\n",
      "[epoch: 334/400, batch: 776/1000, ite: 44598] train loss: 1.1708, accuracy: 94.3077%, tar: 0.0256 \n",
      "l0: 0.031026, l1: 0.032555, l2: 0.041438, l3: 0.067108, l4: 0.134350, l5: 0.213481, l6: 0.402084\n",
      "\n",
      "[epoch: 334/400, batch: 784/1000, ite: 44599] train loss: 1.1711, accuracy: 94.3839%, tar: 0.0256 \n",
      "l0: 0.027275, l1: 0.028676, l2: 0.037697, l3: 0.060425, l4: 0.124798, l5: 0.216236, l6: 0.408009\n",
      "\n",
      "[epoch: 334/400, batch: 792/1000, ite: 44600] train loss: 1.1714, accuracy: 94.5918%, tar: 0.0256 \n",
      "l0: 0.030322, l1: 0.031476, l2: 0.037588, l3: 0.051064, l4: 0.075756, l5: 0.136356, l6: 0.255294\n",
      "\n",
      "[epoch: 334/400, batch: 800/1000, ite: 44601] train loss: 1.1709, accuracy: 95.4754%, tar: 0.0256 \n",
      "l0: 0.024182, l1: 0.028671, l2: 0.035027, l3: 0.046623, l4: 0.076329, l5: 0.146958, l6: 0.277624\n",
      "\n",
      "[epoch: 334/400, batch: 808/1000, ite: 44602] train loss: 1.1704, accuracy: 95.4371%, tar: 0.0256 \n",
      "l0: 0.030885, l1: 0.032648, l2: 0.038749, l3: 0.058227, l4: 0.118633, l5: 0.248628, l6: 0.482242\n",
      "\n",
      "[epoch: 334/400, batch: 816/1000, ite: 44603] train loss: 1.1710, accuracy: 93.6248%, tar: 0.0256 \n",
      "l0: 0.033035, l1: 0.034111, l2: 0.040718, l3: 0.055507, l4: 0.098908, l5: 0.175326, l6: 0.321035\n",
      "\n",
      "[epoch: 334/400, batch: 824/1000, ite: 44604] train loss: 1.1708, accuracy: 94.8242%, tar: 0.0256 \n",
      "l0: 0.025582, l1: 0.026457, l2: 0.033701, l3: 0.047445, l4: 0.079933, l5: 0.163649, l6: 0.357229\n",
      "\n",
      "[epoch: 334/400, batch: 832/1000, ite: 44605] train loss: 1.1707, accuracy: 95.5248%, tar: 0.0256 \n",
      "l0: 0.021717, l1: 0.021964, l2: 0.026099, l3: 0.038174, l4: 0.062870, l5: 0.110313, l6: 0.263615\n",
      "\n",
      "[epoch: 334/400, batch: 840/1000, ite: 44606] train loss: 1.1701, accuracy: 95.5631%, tar: 0.0256 \n",
      "l0: 0.029170, l1: 0.029790, l2: 0.037873, l3: 0.053960, l4: 0.089190, l5: 0.150229, l6: 0.343022\n",
      "\n",
      "[epoch: 334/400, batch: 848/1000, ite: 44607] train loss: 1.1699, accuracy: 94.3130%, tar: 0.0256 \n",
      "l0: 0.026635, l1: 0.027447, l2: 0.033348, l3: 0.050302, l4: 0.089566, l5: 0.180063, l6: 0.345483\n",
      "\n",
      "[epoch: 334/400, batch: 856/1000, ite: 44608] train loss: 1.1698, accuracy: 94.4140%, tar: 0.0256 \n",
      "l0: 0.039178, l1: 0.041739, l2: 0.053432, l3: 0.077904, l4: 0.141530, l5: 0.256187, l6: 0.476767\n",
      "\n",
      "[epoch: 334/400, batch: 864/1000, ite: 44609] train loss: 1.1705, accuracy: 93.3979%, tar: 0.0256 \n",
      "l0: 0.077078, l1: 0.078545, l2: 0.092902, l3: 0.119062, l4: 0.158568, l5: 0.252620, l6: 0.436419\n",
      "\n",
      "[epoch: 334/400, batch: 872/1000, ite: 44610] train loss: 1.1713, accuracy: 93.4888%, tar: 0.0257 \n",
      "l0: 0.036902, l1: 0.038813, l2: 0.047830, l3: 0.067833, l4: 0.128171, l5: 0.247581, l6: 0.440591\n",
      "\n",
      "[epoch: 334/400, batch: 880/1000, ite: 44611] train loss: 1.1717, accuracy: 94.0602%, tar: 0.0257 \n",
      "l0: 0.028615, l1: 0.030592, l2: 0.038203, l3: 0.057478, l4: 0.107275, l5: 0.216048, l6: 0.467597\n",
      "\n",
      "[epoch: 334/400, batch: 888/1000, ite: 44612] train loss: 1.1721, accuracy: 94.2286%, tar: 0.0257 \n",
      "l0: 0.034368, l1: 0.035442, l2: 0.045437, l3: 0.061364, l4: 0.111609, l5: 0.206840, l6: 0.410279\n",
      "\n",
      "[epoch: 334/400, batch: 896/1000, ite: 44613] train loss: 1.1724, accuracy: 93.5922%, tar: 0.0257 \n",
      "l0: 0.025311, l1: 0.025908, l2: 0.035864, l3: 0.050831, l4: 0.094167, l5: 0.194421, l6: 0.410917\n",
      "\n",
      "[epoch: 334/400, batch: 904/1000, ite: 44614] train loss: 1.1725, accuracy: 95.3350%, tar: 0.0257 \n",
      "l0: 0.031602, l1: 0.032756, l2: 0.042378, l3: 0.061338, l4: 0.113070, l5: 0.207923, l6: 0.417428\n",
      "\n",
      "[epoch: 334/400, batch: 912/1000, ite: 44615] train loss: 1.1727, accuracy: 93.6659%, tar: 0.0258 \n",
      "l0: 0.029401, l1: 0.030626, l2: 0.038926, l3: 0.061818, l4: 0.117070, l5: 0.208166, l6: 0.403810\n",
      "\n",
      "[epoch: 334/400, batch: 920/1000, ite: 44616] train loss: 1.1729, accuracy: 94.5820%, tar: 0.0258 \n",
      "l0: 0.034723, l1: 0.036686, l2: 0.045646, l3: 0.064640, l4: 0.114833, l5: 0.217256, l6: 0.392001\n",
      "\n",
      "[epoch: 334/400, batch: 928/1000, ite: 44617] train loss: 1.1731, accuracy: 94.1674%, tar: 0.0258 \n",
      "l0: 0.035376, l1: 0.036773, l2: 0.045703, l3: 0.065517, l4: 0.116633, l5: 0.220808, l6: 0.424035\n",
      "\n",
      "[epoch: 334/400, batch: 936/1000, ite: 44618] train loss: 1.1735, accuracy: 94.0552%, tar: 0.0258 \n",
      "l0: 0.028938, l1: 0.030167, l2: 0.040042, l3: 0.062518, l4: 0.108334, l5: 0.176107, l6: 0.328918\n",
      "\n",
      "[epoch: 334/400, batch: 944/1000, ite: 44619] train loss: 1.1734, accuracy: 95.4614%, tar: 0.0258 \n",
      "l0: 0.034154, l1: 0.035568, l2: 0.043613, l3: 0.059355, l4: 0.111730, l5: 0.211636, l6: 0.371673\n",
      "\n",
      "[epoch: 334/400, batch: 952/1000, ite: 44620] train loss: 1.1735, accuracy: 94.4173%, tar: 0.0258 \n",
      "l0: 0.029084, l1: 0.029377, l2: 0.034787, l3: 0.044308, l4: 0.064984, l5: 0.107519, l6: 0.231528\n",
      "\n",
      "[epoch: 334/400, batch: 960/1000, ite: 44621] train loss: 1.1728, accuracy: 95.6231%, tar: 0.0258 \n",
      "l0: 0.029091, l1: 0.030673, l2: 0.038430, l3: 0.057146, l4: 0.103595, l5: 0.198500, l6: 0.418270\n",
      "\n",
      "[epoch: 334/400, batch: 968/1000, ite: 44622] train loss: 1.1731, accuracy: 94.4639%, tar: 0.0258 \n",
      "l0: 0.027970, l1: 0.029120, l2: 0.035725, l3: 0.051465, l4: 0.094089, l5: 0.186319, l6: 0.370639\n",
      "\n",
      "[epoch: 334/400, batch: 976/1000, ite: 44623] train loss: 1.1730, accuracy: 94.5691%, tar: 0.0258 \n",
      "l0: 0.032918, l1: 0.034642, l2: 0.045516, l3: 0.062346, l4: 0.098254, l5: 0.191637, l6: 0.408685\n",
      "\n",
      "[epoch: 334/400, batch: 984/1000, ite: 44624] train loss: 1.1732, accuracy: 93.9689%, tar: 0.0258 \n",
      "l0: 0.032203, l1: 0.033441, l2: 0.040261, l3: 0.056348, l4: 0.094013, l5: 0.185223, l6: 0.411111\n",
      "\n",
      "[epoch: 334/400, batch: 992/1000, ite: 44625] train loss: 1.1734, accuracy: 93.9790%, tar: 0.0258 \n",
      "l0: 0.039524, l1: 0.041621, l2: 0.050711, l3: 0.065384, l4: 0.113879, l5: 0.207205, l6: 0.447643\n",
      "\n",
      "[epoch: 334/400, batch: 1000/1000, ite: 44626] train loss: 1.1738, accuracy: 93.1457%, tar: 0.0259 \n",
      "l0: 0.029487, l1: 0.030948, l2: 0.039588, l3: 0.054626, l4: 0.092583, l5: 0.182345, l6: 0.329742\n",
      "\n",
      "[epoch: 335/400, batch: 8/1000, ite: 44627] train loss: 1.1737, accuracy: 94.7447%, tar: 0.0259 \n",
      "l0: 0.040622, l1: 0.042592, l2: 0.052342, l3: 0.080617, l4: 0.131693, l5: 0.238276, l6: 0.449155\n",
      "\n",
      "[epoch: 335/400, batch: 16/1000, ite: 44628] train loss: 1.1742, accuracy: 93.2643%, tar: 0.0259 \n",
      "l0: 0.024670, l1: 0.025984, l2: 0.032511, l3: 0.048291, l4: 0.078965, l5: 0.141317, l6: 0.268223\n",
      "\n",
      "[epoch: 335/400, batch: 24/1000, ite: 44629] train loss: 1.1737, accuracy: 95.8448%, tar: 0.0259 \n",
      "l0: 0.025364, l1: 0.027154, l2: 0.036506, l3: 0.054429, l4: 0.098157, l5: 0.184663, l6: 0.394417\n",
      "\n",
      "[epoch: 335/400, batch: 32/1000, ite: 44630] train loss: 1.1738, accuracy: 94.7877%, tar: 0.0259 \n",
      "l0: 0.032104, l1: 0.033054, l2: 0.040873, l3: 0.059150, l4: 0.106039, l5: 0.231466, l6: 0.475744\n",
      "\n",
      "[epoch: 335/400, batch: 40/1000, ite: 44631] train loss: 1.1742, accuracy: 92.7179%, tar: 0.0259 \n",
      "l0: 0.035704, l1: 0.037702, l2: 0.049712, l3: 0.070373, l4: 0.118992, l5: 0.219745, l6: 0.386972\n",
      "\n",
      "[epoch: 335/400, batch: 48/1000, ite: 44632] train loss: 1.1745, accuracy: 94.3282%, tar: 0.0259 \n",
      "l0: 0.034309, l1: 0.035739, l2: 0.043616, l3: 0.060934, l4: 0.117555, l5: 0.221436, l6: 0.396828\n",
      "\n",
      "[epoch: 335/400, batch: 56/1000, ite: 44633] train loss: 1.1747, accuracy: 95.3466%, tar: 0.0259 \n",
      "l0: 0.034407, l1: 0.035807, l2: 0.046331, l3: 0.064428, l4: 0.109040, l5: 0.215139, l6: 0.442808\n",
      "\n",
      "[epoch: 335/400, batch: 64/1000, ite: 44634] train loss: 1.1750, accuracy: 93.6739%, tar: 0.0259 \n",
      "l0: 0.027001, l1: 0.027548, l2: 0.037446, l3: 0.057950, l4: 0.100334, l5: 0.194314, l6: 0.440324\n",
      "\n",
      "[epoch: 335/400, batch: 72/1000, ite: 44635] train loss: 1.1753, accuracy: 95.1359%, tar: 0.0259 \n",
      "l0: 0.029617, l1: 0.030356, l2: 0.037160, l3: 0.049572, l4: 0.086338, l5: 0.172857, l6: 0.353798\n",
      "\n",
      "[epoch: 335/400, batch: 80/1000, ite: 44636] train loss: 1.1752, accuracy: 94.9352%, tar: 0.0260 \n",
      "l0: 0.029448, l1: 0.030467, l2: 0.038894, l3: 0.056091, l4: 0.104520, l5: 0.213075, l6: 0.500941\n",
      "\n",
      "[epoch: 335/400, batch: 88/1000, ite: 44637] train loss: 1.1757, accuracy: 94.8472%, tar: 0.0260 \n",
      "l0: 0.037736, l1: 0.041646, l2: 0.046584, l3: 0.062510, l4: 0.098261, l5: 0.155027, l6: 0.280630\n",
      "\n",
      "[epoch: 335/400, batch: 96/1000, ite: 44638] train loss: 1.1754, accuracy: 94.6072%, tar: 0.0260 \n",
      "l0: 0.028734, l1: 0.030009, l2: 0.037162, l3: 0.050767, l4: 0.092134, l5: 0.206417, l6: 0.388582\n",
      "\n",
      "[epoch: 335/400, batch: 104/1000, ite: 44639] train loss: 1.1755, accuracy: 94.7124%, tar: 0.0260 \n",
      "l0: 0.043166, l1: 0.046098, l2: 0.057456, l3: 0.084076, l4: 0.155863, l5: 0.293790, l6: 0.572945\n",
      "\n",
      "[epoch: 335/400, batch: 112/1000, ite: 44640] train loss: 1.1765, accuracy: 92.6095%, tar: 0.0260 \n",
      "l0: 0.030248, l1: 0.031602, l2: 0.038507, l3: 0.051843, l4: 0.085957, l5: 0.168339, l6: 0.389040\n",
      "\n",
      "[epoch: 335/400, batch: 120/1000, ite: 44641] train loss: 1.1765, accuracy: 94.1689%, tar: 0.0260 \n",
      "l0: 0.033776, l1: 0.035374, l2: 0.041330, l3: 0.054914, l4: 0.092223, l5: 0.166885, l6: 0.321994\n",
      "\n",
      "[epoch: 335/400, batch: 128/1000, ite: 44642] train loss: 1.1764, accuracy: 95.1069%, tar: 0.0260 \n",
      "l0: 0.035900, l1: 0.036969, l2: 0.044231, l3: 0.068619, l4: 0.156884, l5: 0.284643, l6: 0.478451\n",
      "\n",
      "[epoch: 335/400, batch: 136/1000, ite: 44643] train loss: 1.1770, accuracy: 93.3509%, tar: 0.0260 \n",
      "l0: 0.032214, l1: 0.034410, l2: 0.043139, l3: 0.061717, l4: 0.101714, l5: 0.177352, l6: 0.367569\n",
      "\n",
      "[epoch: 335/400, batch: 144/1000, ite: 44644] train loss: 1.1770, accuracy: 94.5098%, tar: 0.0261 \n",
      "l0: 0.046873, l1: 0.049143, l2: 0.057328, l3: 0.075322, l4: 0.126230, l5: 0.231290, l6: 0.500067\n",
      "\n",
      "[epoch: 335/400, batch: 152/1000, ite: 44645] train loss: 1.1776, accuracy: 92.8459%, tar: 0.0261 \n",
      "l0: 0.025812, l1: 0.031896, l2: 0.037617, l3: 0.048155, l4: 0.074798, l5: 0.129414, l6: 0.268258\n",
      "\n",
      "[epoch: 335/400, batch: 160/1000, ite: 44646] train loss: 1.1772, accuracy: 95.6758%, tar: 0.0261 \n",
      "l0: 0.027776, l1: 0.029801, l2: 0.034739, l3: 0.044465, l4: 0.086228, l5: 0.153641, l6: 0.310078\n",
      "\n",
      "[epoch: 335/400, batch: 168/1000, ite: 44647] train loss: 1.1769, accuracy: 95.2774%, tar: 0.0261 \n",
      "l0: 0.034324, l1: 0.035522, l2: 0.043053, l3: 0.062840, l4: 0.117088, l5: 0.210237, l6: 0.442343\n",
      "\n",
      "[epoch: 335/400, batch: 176/1000, ite: 44648] train loss: 1.1773, accuracy: 92.8959%, tar: 0.0261 \n",
      "l0: 0.028578, l1: 0.028865, l2: 0.035803, l3: 0.050199, l4: 0.081551, l5: 0.140000, l6: 0.297301\n",
      "\n",
      "[epoch: 335/400, batch: 184/1000, ite: 44649] train loss: 1.1769, accuracy: 95.4683%, tar: 0.0261 \n",
      "l0: 0.036137, l1: 0.037421, l2: 0.047157, l3: 0.064180, l4: 0.102887, l5: 0.171379, l6: 0.354500\n",
      "\n",
      "[epoch: 335/400, batch: 192/1000, ite: 44650] train loss: 1.1769, accuracy: 94.6514%, tar: 0.0261 \n",
      "l0: 0.036590, l1: 0.038003, l2: 0.047224, l3: 0.065132, l4: 0.110553, l5: 0.208673, l6: 0.410730\n",
      "\n",
      "[epoch: 335/400, batch: 200/1000, ite: 44651] train loss: 1.1771, accuracy: 93.7429%, tar: 0.0261 \n",
      "l0: 0.047605, l1: 0.050063, l2: 0.061856, l3: 0.096896, l4: 0.180379, l5: 0.320221, l6: 0.640467\n",
      "\n",
      "[epoch: 335/400, batch: 208/1000, ite: 44652] train loss: 1.1784, accuracy: 92.0717%, tar: 0.0262 \n",
      "l0: 0.034294, l1: 0.035412, l2: 0.045097, l3: 0.061366, l4: 0.103833, l5: 0.214810, l6: 0.430709\n",
      "\n",
      "[epoch: 335/400, batch: 216/1000, ite: 44653] train loss: 1.1787, accuracy: 94.5861%, tar: 0.0262 \n",
      "l0: 0.029841, l1: 0.030956, l2: 0.037270, l3: 0.052808, l4: 0.089840, l5: 0.174862, l6: 0.312733\n",
      "\n",
      "[epoch: 335/400, batch: 224/1000, ite: 44654] train loss: 1.1785, accuracy: 95.2834%, tar: 0.0262 \n",
      "l0: 0.036758, l1: 0.037831, l2: 0.044900, l3: 0.062962, l4: 0.109821, l5: 0.212175, l6: 0.433965\n",
      "\n",
      "[epoch: 335/400, batch: 232/1000, ite: 44655] train loss: 1.1788, accuracy: 93.2467%, tar: 0.0262 \n",
      "l0: 0.052810, l1: 0.048625, l2: 0.054888, l3: 0.074607, l4: 0.128023, l5: 0.229029, l6: 0.419898\n",
      "\n",
      "[epoch: 335/400, batch: 240/1000, ite: 44656] train loss: 1.1792, accuracy: 93.2770%, tar: 0.0262 \n",
      "l0: 0.039474, l1: 0.041787, l2: 0.051922, l3: 0.072337, l4: 0.120365, l5: 0.208623, l6: 0.449788\n",
      "\n",
      "[epoch: 335/400, batch: 248/1000, ite: 44657] train loss: 1.1796, accuracy: 94.1951%, tar: 0.0263 \n",
      "l0: 0.029662, l1: 0.031107, l2: 0.036590, l3: 0.052065, l4: 0.092405, l5: 0.174582, l6: 0.357385\n",
      "\n",
      "[epoch: 335/400, batch: 256/1000, ite: 44658] train loss: 1.1795, accuracy: 94.3558%, tar: 0.0263 \n",
      "l0: 0.029948, l1: 0.031387, l2: 0.039538, l3: 0.053342, l4: 0.086319, l5: 0.178022, l6: 0.317092\n",
      "\n",
      "[epoch: 335/400, batch: 264/1000, ite: 44659] train loss: 1.1793, accuracy: 95.3535%, tar: 0.0263 \n",
      "l0: 0.035324, l1: 0.036787, l2: 0.043871, l3: 0.063979, l4: 0.101153, l5: 0.169089, l6: 0.329130\n",
      "\n",
      "[epoch: 335/400, batch: 272/1000, ite: 44660] train loss: 1.1792, accuracy: 94.4617%, tar: 0.0263 \n",
      "l0: 0.034528, l1: 0.036072, l2: 0.045526, l3: 0.062904, l4: 0.109626, l5: 0.253853, l6: 0.437471\n",
      "\n",
      "[epoch: 335/400, batch: 280/1000, ite: 44661] train loss: 1.1796, accuracy: 94.1616%, tar: 0.0263 \n",
      "l0: 0.091493, l1: 0.087912, l2: 0.133808, l3: 0.195063, l4: 0.201283, l5: 0.246265, l6: 0.405920\n",
      "\n",
      "[epoch: 335/400, batch: 288/1000, ite: 44662] train loss: 1.1804, accuracy: 93.7868%, tar: 0.0264 \n",
      "l0: 0.028388, l1: 0.029830, l2: 0.037837, l3: 0.053841, l4: 0.101962, l5: 0.204437, l6: 0.417239\n",
      "\n",
      "[epoch: 335/400, batch: 296/1000, ite: 44663] train loss: 1.1806, accuracy: 94.1648%, tar: 0.0264 \n",
      "l0: 0.028254, l1: 0.030900, l2: 0.038189, l3: 0.055334, l4: 0.092306, l5: 0.159185, l6: 0.305022\n",
      "\n",
      "[epoch: 335/400, batch: 304/1000, ite: 44664] train loss: 1.1804, accuracy: 95.2073%, tar: 0.0264 \n",
      "l0: 0.036755, l1: 0.038585, l2: 0.051476, l3: 0.079001, l4: 0.138577, l5: 0.256716, l6: 0.536557\n",
      "\n",
      "[epoch: 335/400, batch: 312/1000, ite: 44665] train loss: 1.1811, accuracy: 94.1799%, tar: 0.0264 \n",
      "l0: 0.044000, l1: 0.044216, l2: 0.051146, l3: 0.065146, l4: 0.103217, l5: 0.165480, l6: 0.323633\n",
      "\n",
      "[epoch: 335/400, batch: 320/1000, ite: 44666] train loss: 1.1810, accuracy: 94.6977%, tar: 0.0264 \n",
      "l0: 0.028779, l1: 0.030585, l2: 0.041331, l3: 0.064923, l4: 0.127550, l5: 0.228861, l6: 0.462755\n",
      "\n",
      "[epoch: 335/400, batch: 328/1000, ite: 44667] train loss: 1.1814, accuracy: 93.9692%, tar: 0.0264 \n",
      "l0: 0.030048, l1: 0.031866, l2: 0.039748, l3: 0.060332, l4: 0.106758, l5: 0.193017, l6: 0.447336\n",
      "\n",
      "[epoch: 335/400, batch: 336/1000, ite: 44668] train loss: 1.1817, accuracy: 93.7020%, tar: 0.0265 \n",
      "l0: 0.026145, l1: 0.027081, l2: 0.034691, l3: 0.046808, l4: 0.087111, l5: 0.152402, l6: 0.307325\n",
      "\n",
      "[epoch: 335/400, batch: 344/1000, ite: 44669] train loss: 1.1814, accuracy: 95.5837%, tar: 0.0265 \n",
      "l0: 0.034305, l1: 0.036132, l2: 0.045174, l3: 0.062092, l4: 0.101419, l5: 0.183036, l6: 0.354031\n",
      "\n",
      "[epoch: 335/400, batch: 352/1000, ite: 44670] train loss: 1.1814, accuracy: 94.9103%, tar: 0.0265 \n",
      "l0: 0.026198, l1: 0.027750, l2: 0.032986, l3: 0.045971, l4: 0.077509, l5: 0.150591, l6: 0.303868\n",
      "\n",
      "[epoch: 335/400, batch: 360/1000, ite: 44671] train loss: 1.1811, accuracy: 95.8733%, tar: 0.0265 \n",
      "l0: 0.026929, l1: 0.027910, l2: 0.037823, l3: 0.060782, l4: 0.113126, l5: 0.215782, l6: 0.368755\n",
      "\n",
      "[epoch: 335/400, batch: 368/1000, ite: 44672] train loss: 1.1812, accuracy: 95.5839%, tar: 0.0265 \n",
      "l0: 0.029076, l1: 0.030669, l2: 0.036778, l3: 0.054966, l4: 0.100228, l5: 0.184039, l6: 0.341755\n",
      "\n",
      "[epoch: 335/400, batch: 376/1000, ite: 44673] train loss: 1.1811, accuracy: 95.6651%, tar: 0.0265 \n",
      "l0: 0.027864, l1: 0.028604, l2: 0.035009, l3: 0.049250, l4: 0.079440, l5: 0.157337, l6: 0.306642\n",
      "\n",
      "[epoch: 335/400, batch: 384/1000, ite: 44674] train loss: 1.1808, accuracy: 94.8384%, tar: 0.0265 \n",
      "l0: 0.037546, l1: 0.038384, l2: 0.047361, l3: 0.066670, l4: 0.114078, l5: 0.264019, l6: 0.525514\n",
      "\n",
      "[epoch: 335/400, batch: 392/1000, ite: 44675] train loss: 1.1814, accuracy: 93.0285%, tar: 0.0265 \n",
      "l0: 0.032351, l1: 0.033037, l2: 0.039053, l3: 0.052854, l4: 0.088145, l5: 0.156736, l6: 0.306184\n",
      "\n",
      "[epoch: 335/400, batch: 400/1000, ite: 44676] train loss: 1.1812, accuracy: 94.8369%, tar: 0.0265 \n",
      "l0: 0.032583, l1: 0.034283, l2: 0.040918, l3: 0.054338, l4: 0.076132, l5: 0.122237, l6: 0.221319\n",
      "\n",
      "[epoch: 335/400, batch: 408/1000, ite: 44677] train loss: 1.1807, accuracy: 96.2097%, tar: 0.0265 \n",
      "l0: 0.029213, l1: 0.030053, l2: 0.038101, l3: 0.052845, l4: 0.083933, l5: 0.159533, l6: 0.380209\n",
      "\n",
      "[epoch: 335/400, batch: 416/1000, ite: 44678] train loss: 1.1806, accuracy: 94.3039%, tar: 0.0265 \n",
      "l0: 0.046199, l1: 0.049281, l2: 0.056962, l3: 0.076627, l4: 0.121250, l5: 0.213878, l6: 0.382175\n",
      "\n",
      "[epoch: 335/400, batch: 424/1000, ite: 44679] train loss: 1.1809, accuracy: 94.0724%, tar: 0.0265 \n",
      "l0: 0.030948, l1: 0.031424, l2: 0.037517, l3: 0.052553, l4: 0.089429, l5: 0.173630, l6: 0.405149\n",
      "\n",
      "[epoch: 335/400, batch: 432/1000, ite: 44680] train loss: 1.1809, accuracy: 94.0135%, tar: 0.0265 \n",
      "l0: 0.031068, l1: 0.031745, l2: 0.038463, l3: 0.057503, l4: 0.100279, l5: 0.171304, l6: 0.318968\n",
      "\n",
      "[epoch: 335/400, batch: 440/1000, ite: 44681] train loss: 1.1808, accuracy: 94.4564%, tar: 0.0266 \n",
      "l0: 0.026398, l1: 0.027134, l2: 0.034653, l3: 0.048596, l4: 0.074492, l5: 0.130355, l6: 0.294271\n",
      "\n",
      "[epoch: 335/400, batch: 448/1000, ite: 44682] train loss: 1.1804, accuracy: 95.2024%, tar: 0.0266 \n",
      "l0: 0.034663, l1: 0.036327, l2: 0.043021, l3: 0.057691, l4: 0.101680, l5: 0.215798, l6: 0.379720\n",
      "\n",
      "[epoch: 335/400, batch: 456/1000, ite: 44683] train loss: 1.1805, accuracy: 95.4793%, tar: 0.0266 \n",
      "l0: 0.043644, l1: 0.044982, l2: 0.052229, l3: 0.072753, l4: 0.129552, l5: 0.260766, l6: 0.469375\n",
      "\n",
      "[epoch: 335/400, batch: 464/1000, ite: 44684] train loss: 1.1811, accuracy: 92.8474%, tar: 0.0266 \n",
      "l0: 0.029473, l1: 0.030047, l2: 0.038769, l3: 0.057140, l4: 0.099718, l5: 0.199181, l6: 0.374081\n",
      "\n",
      "[epoch: 335/400, batch: 472/1000, ite: 44685] train loss: 1.1811, accuracy: 94.6028%, tar: 0.0266 \n",
      "l0: 0.036519, l1: 0.037526, l2: 0.046786, l3: 0.067473, l4: 0.110705, l5: 0.263983, l6: 0.509988\n",
      "\n",
      "[epoch: 335/400, batch: 480/1000, ite: 44686] train loss: 1.1817, accuracy: 93.0565%, tar: 0.0266 \n",
      "l0: 0.037468, l1: 0.038367, l2: 0.046110, l3: 0.064685, l4: 0.120128, l5: 0.233018, l6: 0.453258\n",
      "\n",
      "[epoch: 335/400, batch: 488/1000, ite: 44687] train loss: 1.1820, accuracy: 93.5279%, tar: 0.0266 \n",
      "l0: 0.041612, l1: 0.043271, l2: 0.052684, l3: 0.074823, l4: 0.128703, l5: 0.251596, l6: 0.568167\n",
      "\n",
      "[epoch: 335/400, batch: 496/1000, ite: 44688] train loss: 1.1828, accuracy: 92.1408%, tar: 0.0266 \n",
      "l0: 0.028834, l1: 0.030344, l2: 0.039515, l3: 0.055525, l4: 0.095044, l5: 0.180545, l6: 0.341731\n",
      "\n",
      "[epoch: 335/400, batch: 504/1000, ite: 44689] train loss: 1.1827, accuracy: 94.7634%, tar: 0.0266 \n",
      "l0: 0.031995, l1: 0.033344, l2: 0.040223, l3: 0.055605, l4: 0.106283, l5: 0.205227, l6: 0.349018\n",
      "\n",
      "[epoch: 335/400, batch: 512/1000, ite: 44690] train loss: 1.1827, accuracy: 94.0809%, tar: 0.0267 \n",
      "l0: 0.035086, l1: 0.036226, l2: 0.045962, l3: 0.067255, l4: 0.117784, l5: 0.227177, l6: 0.511908\n",
      "\n",
      "[epoch: 335/400, batch: 520/1000, ite: 44691] train loss: 1.1833, accuracy: 92.3824%, tar: 0.0267 \n",
      "l0: 0.027160, l1: 0.028200, l2: 0.036397, l3: 0.054307, l4: 0.096433, l5: 0.173377, l6: 0.361760\n",
      "\n",
      "[epoch: 335/400, batch: 528/1000, ite: 44692] train loss: 1.1832, accuracy: 94.4537%, tar: 0.0267 \n",
      "l0: 0.029866, l1: 0.031776, l2: 0.038718, l3: 0.052289, l4: 0.079761, l5: 0.153977, l6: 0.348574\n",
      "\n",
      "[epoch: 335/400, batch: 536/1000, ite: 44693] train loss: 1.1831, accuracy: 95.2892%, tar: 0.0267 \n",
      "l0: 0.035287, l1: 0.035874, l2: 0.043899, l3: 0.058455, l4: 0.099569, l5: 0.178181, l6: 0.390612\n",
      "\n",
      "[epoch: 335/400, batch: 544/1000, ite: 44694] train loss: 1.1831, accuracy: 93.7752%, tar: 0.0267 \n",
      "l0: 0.035266, l1: 0.036811, l2: 0.046377, l3: 0.068432, l4: 0.118191, l5: 0.227635, l6: 0.459203\n",
      "\n",
      "[epoch: 335/400, batch: 552/1000, ite: 44695] train loss: 1.1835, accuracy: 93.9610%, tar: 0.0267 \n",
      "l0: 0.024382, l1: 0.025701, l2: 0.033766, l3: 0.052708, l4: 0.099547, l5: 0.188359, l6: 0.436164\n",
      "\n",
      "[epoch: 335/400, batch: 560/1000, ite: 44696] train loss: 1.1837, accuracy: 94.2787%, tar: 0.0267 \n",
      "l0: 0.024211, l1: 0.025523, l2: 0.033695, l3: 0.052573, l4: 0.099620, l5: 0.198737, l6: 0.367861\n",
      "\n",
      "[epoch: 335/400, batch: 568/1000, ite: 44697] train loss: 1.1837, accuracy: 94.8223%, tar: 0.0267 \n",
      "l0: 0.029235, l1: 0.031285, l2: 0.041211, l3: 0.058994, l4: 0.095269, l5: 0.161251, l6: 0.294844\n",
      "\n",
      "[epoch: 335/400, batch: 576/1000, ite: 44698] train loss: 1.1834, accuracy: 95.4755%, tar: 0.0267 \n",
      "l0: 0.021884, l1: 0.023880, l2: 0.029806, l3: 0.040780, l4: 0.063856, l5: 0.107092, l6: 0.209029\n",
      "\n",
      "[epoch: 335/400, batch: 584/1000, ite: 44699] train loss: 1.1827, accuracy: 96.5365%, tar: 0.0267 \n",
      "l0: 0.028562, l1: 0.029394, l2: 0.035309, l3: 0.049068, l4: 0.083006, l5: 0.140512, l6: 0.306689\n",
      "\n",
      "[epoch: 335/400, batch: 592/1000, ite: 44700] train loss: 1.1824, accuracy: 95.3200%, tar: 0.0267 \n",
      "l0: 0.025513, l1: 0.026371, l2: 0.032354, l3: 0.043183, l4: 0.073775, l5: 0.138906, l6: 0.306221\n",
      "\n",
      "[epoch: 335/400, batch: 600/1000, ite: 44701] train loss: 1.1821, accuracy: 95.0976%, tar: 0.0267 \n",
      "l0: 0.034066, l1: 0.035512, l2: 0.044237, l3: 0.063220, l4: 0.108430, l5: 0.226298, l6: 0.435429\n",
      "\n",
      "[epoch: 335/400, batch: 608/1000, ite: 44702] train loss: 1.1824, accuracy: 93.5175%, tar: 0.0267 \n",
      "l0: 0.029333, l1: 0.031251, l2: 0.039557, l3: 0.057031, l4: 0.104285, l5: 0.186884, l6: 0.376649\n",
      "\n",
      "[epoch: 335/400, batch: 616/1000, ite: 44703] train loss: 1.1824, accuracy: 94.2325%, tar: 0.0267 \n",
      "l0: 0.022831, l1: 0.023858, l2: 0.031305, l3: 0.047861, l4: 0.079102, l5: 0.141196, l6: 0.378531\n",
      "\n",
      "[epoch: 335/400, batch: 624/1000, ite: 44704] train loss: 1.1823, accuracy: 94.4666%, tar: 0.0267 \n",
      "l0: 0.026176, l1: 0.027428, l2: 0.034591, l3: 0.049670, l4: 0.084887, l5: 0.161366, l6: 0.301328\n",
      "\n",
      "[epoch: 335/400, batch: 632/1000, ite: 44705] train loss: 1.1821, accuracy: 96.0240%, tar: 0.0267 \n",
      "l0: 0.027231, l1: 0.029183, l2: 0.037850, l3: 0.052397, l4: 0.095030, l5: 0.184000, l6: 0.344526\n",
      "\n",
      "[epoch: 335/400, batch: 640/1000, ite: 44706] train loss: 1.1820, accuracy: 95.2692%, tar: 0.0267 \n",
      "l0: 0.027793, l1: 0.029326, l2: 0.038498, l3: 0.055686, l4: 0.095806, l5: 0.191077, l6: 0.406443\n",
      "\n",
      "[epoch: 335/400, batch: 648/1000, ite: 44707] train loss: 1.1821, accuracy: 94.3028%, tar: 0.0267 \n",
      "l0: 0.028775, l1: 0.029717, l2: 0.037325, l3: 0.056422, l4: 0.091303, l5: 0.160909, l6: 0.299071\n",
      "\n",
      "[epoch: 335/400, batch: 656/1000, ite: 44708] train loss: 1.1818, accuracy: 95.0293%, tar: 0.0267 \n",
      "l0: 0.026444, l1: 0.027492, l2: 0.035255, l3: 0.052557, l4: 0.099745, l5: 0.191401, l6: 0.327117\n",
      "\n",
      "[epoch: 335/400, batch: 664/1000, ite: 44709] train loss: 1.1817, accuracy: 95.3233%, tar: 0.0267 \n",
      "l0: 0.033037, l1: 0.034586, l2: 0.045136, l3: 0.059559, l4: 0.104054, l5: 0.204485, l6: 0.443351\n",
      "\n",
      "[epoch: 335/400, batch: 672/1000, ite: 44710] train loss: 1.1819, accuracy: 94.5834%, tar: 0.0267 \n",
      "l0: 0.036947, l1: 0.037621, l2: 0.048176, l3: 0.071202, l4: 0.134182, l5: 0.277513, l6: 0.524777\n",
      "\n",
      "[epoch: 335/400, batch: 680/1000, ite: 44711] train loss: 1.1826, accuracy: 92.3541%, tar: 0.0267 \n",
      "l0: 0.021751, l1: 0.022926, l2: 0.030029, l3: 0.041657, l4: 0.074417, l5: 0.160050, l6: 0.331320\n",
      "\n",
      "[epoch: 335/400, batch: 688/1000, ite: 44712] train loss: 1.1824, accuracy: 95.7228%, tar: 0.0267 \n",
      "l0: 0.034020, l1: 0.035451, l2: 0.042684, l3: 0.059855, l4: 0.113439, l5: 0.206069, l6: 0.414806\n",
      "\n",
      "[epoch: 335/400, batch: 696/1000, ite: 44713] train loss: 1.1826, accuracy: 93.7987%, tar: 0.0267 \n",
      "l0: 0.029081, l1: 0.029929, l2: 0.039788, l3: 0.056208, l4: 0.092021, l5: 0.177750, l6: 0.359797\n",
      "\n",
      "[epoch: 335/400, batch: 704/1000, ite: 44714] train loss: 1.1825, accuracy: 95.0982%, tar: 0.0267 \n",
      "l0: 0.028219, l1: 0.029531, l2: 0.036864, l3: 0.054291, l4: 0.100781, l5: 0.223151, l6: 0.427812\n",
      "\n",
      "[epoch: 335/400, batch: 712/1000, ite: 44715] train loss: 1.1827, accuracy: 94.2927%, tar: 0.0267 \n",
      "l0: 0.023952, l1: 0.025182, l2: 0.031460, l3: 0.048251, l4: 0.082939, l5: 0.152145, l6: 0.328217\n",
      "\n",
      "[epoch: 335/400, batch: 720/1000, ite: 44716] train loss: 1.1825, accuracy: 95.8345%, tar: 0.0267 \n",
      "l0: 0.037648, l1: 0.039020, l2: 0.048850, l3: 0.071969, l4: 0.128464, l5: 0.257695, l6: 0.482765\n",
      "\n",
      "[epoch: 335/400, batch: 728/1000, ite: 44717] train loss: 1.1830, accuracy: 92.9531%, tar: 0.0267 \n",
      "l0: 0.033595, l1: 0.034988, l2: 0.044384, l3: 0.064445, l4: 0.109899, l5: 0.215391, l6: 0.437914\n",
      "\n",
      "[epoch: 335/400, batch: 736/1000, ite: 44718] train loss: 1.1833, accuracy: 94.2656%, tar: 0.0268 \n",
      "l0: 0.024961, l1: 0.026800, l2: 0.036345, l3: 0.057488, l4: 0.102660, l5: 0.203939, l6: 0.459167\n",
      "\n",
      "[epoch: 335/400, batch: 744/1000, ite: 44719] train loss: 1.1836, accuracy: 94.1072%, tar: 0.0268 \n",
      "l0: 0.027135, l1: 0.027452, l2: 0.035073, l3: 0.046400, l4: 0.076158, l5: 0.143965, l6: 0.301665\n",
      "\n",
      "[epoch: 335/400, batch: 752/1000, ite: 44720] train loss: 1.1833, accuracy: 95.3596%, tar: 0.0268 \n",
      "l0: 0.029074, l1: 0.030588, l2: 0.038757, l3: 0.054246, l4: 0.091235, l5: 0.191279, l6: 0.351162\n",
      "\n",
      "[epoch: 335/400, batch: 760/1000, ite: 44721] train loss: 1.1832, accuracy: 95.0970%, tar: 0.0268 \n",
      "l0: 0.026033, l1: 0.027326, l2: 0.034132, l3: 0.051891, l4: 0.086373, l5: 0.140055, l6: 0.276328\n",
      "\n",
      "[epoch: 335/400, batch: 768/1000, ite: 44722] train loss: 1.1829, accuracy: 95.0121%, tar: 0.0268 \n",
      "l0: 0.029218, l1: 0.030717, l2: 0.037871, l3: 0.055922, l4: 0.114140, l5: 0.198915, l6: 0.442797\n",
      "\n",
      "[epoch: 335/400, batch: 776/1000, ite: 44723] train loss: 1.1831, accuracy: 94.7494%, tar: 0.0268 \n",
      "l0: 0.022563, l1: 0.023947, l2: 0.030803, l3: 0.047288, l4: 0.089059, l5: 0.189720, l6: 0.327928\n",
      "\n",
      "[epoch: 335/400, batch: 784/1000, ite: 44724] train loss: 1.1829, accuracy: 95.3398%, tar: 0.0268 \n",
      "l0: 0.026234, l1: 0.027872, l2: 0.035223, l3: 0.047677, l4: 0.079763, l5: 0.154073, l6: 0.270073\n",
      "\n",
      "[epoch: 335/400, batch: 792/1000, ite: 44725] train loss: 1.1826, accuracy: 96.2536%, tar: 0.0268 \n",
      "l0: 0.025934, l1: 0.027386, l2: 0.036247, l3: 0.053630, l4: 0.125264, l5: 0.160936, l6: 0.397078\n",
      "\n",
      "[epoch: 335/400, batch: 800/1000, ite: 44726] train loss: 1.1826, accuracy: 95.4578%, tar: 0.0267 \n",
      "l0: 0.018125, l1: 0.020021, l2: 0.027923, l3: 0.041561, l4: 0.080372, l5: 0.150807, l6: 0.304570\n",
      "\n",
      "[epoch: 335/400, batch: 808/1000, ite: 44727] train loss: 1.1823, accuracy: 96.4979%, tar: 0.0267 \n",
      "l0: 0.030822, l1: 0.032234, l2: 0.043632, l3: 0.066825, l4: 0.123970, l5: 0.241468, l6: 0.406244\n",
      "\n",
      "[epoch: 335/400, batch: 816/1000, ite: 44728] train loss: 1.1826, accuracy: 93.9339%, tar: 0.0267 \n",
      "l0: 0.030126, l1: 0.031102, l2: 0.038071, l3: 0.054990, l4: 0.093458, l5: 0.177268, l6: 0.390431\n",
      "\n",
      "[epoch: 335/400, batch: 824/1000, ite: 44729] train loss: 1.1826, accuracy: 94.1183%, tar: 0.0267 \n",
      "l0: 0.018848, l1: 0.020216, l2: 0.025452, l3: 0.035059, l4: 0.068553, l5: 0.152712, l6: 0.270506\n",
      "\n",
      "[epoch: 335/400, batch: 832/1000, ite: 44730] train loss: 1.1822, accuracy: 97.0145%, tar: 0.0267 \n",
      "l0: 0.030690, l1: 0.032059, l2: 0.043101, l3: 0.061186, l4: 0.111585, l5: 0.218392, l6: 0.421648\n",
      "\n",
      "[epoch: 335/400, batch: 840/1000, ite: 44731] train loss: 1.1824, accuracy: 94.2854%, tar: 0.0267 \n",
      "l0: 0.032602, l1: 0.034679, l2: 0.044330, l3: 0.066638, l4: 0.128687, l5: 0.260954, l6: 0.532193\n",
      "\n",
      "[epoch: 335/400, batch: 848/1000, ite: 44732] train loss: 1.1830, accuracy: 93.2537%, tar: 0.0268 \n",
      "l0: 0.033909, l1: 0.035564, l2: 0.046242, l3: 0.068700, l4: 0.128311, l5: 0.261949, l6: 0.548918\n",
      "\n",
      "[epoch: 335/400, batch: 856/1000, ite: 44733] train loss: 1.1837, accuracy: 92.8249%, tar: 0.0268 \n",
      "l0: 0.034325, l1: 0.036519, l2: 0.046851, l3: 0.073295, l4: 0.131965, l5: 0.263755, l6: 0.492363\n",
      "\n",
      "[epoch: 335/400, batch: 864/1000, ite: 44734] train loss: 1.1842, accuracy: 94.2543%, tar: 0.0268 \n",
      "l0: 0.033438, l1: 0.034263, l2: 0.043950, l3: 0.066303, l4: 0.113755, l5: 0.229657, l6: 0.458514\n",
      "\n",
      "[epoch: 335/400, batch: 872/1000, ite: 44735] train loss: 1.1846, accuracy: 94.0692%, tar: 0.0268 \n",
      "l0: 0.026833, l1: 0.028905, l2: 0.037775, l3: 0.057016, l4: 0.116285, l5: 0.273514, l6: 0.513630\n",
      "\n",
      "[epoch: 335/400, batch: 880/1000, ite: 44736] train loss: 1.1851, accuracy: 93.6423%, tar: 0.0268 \n",
      "l0: 0.026397, l1: 0.027451, l2: 0.034395, l3: 0.051208, l4: 0.096505, l5: 0.157482, l6: 0.330557\n",
      "\n",
      "[epoch: 335/400, batch: 888/1000, ite: 44737] train loss: 1.1849, accuracy: 94.8559%, tar: 0.0268 \n",
      "l0: 0.025341, l1: 0.027242, l2: 0.035515, l3: 0.059547, l4: 0.133640, l5: 0.233638, l6: 0.409961\n",
      "\n",
      "[epoch: 335/400, batch: 896/1000, ite: 44738] train loss: 1.1851, accuracy: 94.8347%, tar: 0.0268 \n",
      "l0: 0.032690, l1: 0.033653, l2: 0.040268, l3: 0.055414, l4: 0.084739, l5: 0.152859, l6: 0.313385\n",
      "\n",
      "[epoch: 335/400, batch: 904/1000, ite: 44739] train loss: 1.1849, accuracy: 94.5694%, tar: 0.0268 \n",
      "l0: 0.026612, l1: 0.027610, l2: 0.037635, l3: 0.063225, l4: 0.118456, l5: 0.237217, l6: 0.476146\n",
      "\n",
      "[epoch: 335/400, batch: 912/1000, ite: 44740] train loss: 1.1853, accuracy: 94.7985%, tar: 0.0268 \n",
      "l0: 0.028786, l1: 0.029769, l2: 0.037763, l3: 0.051510, l4: 0.081734, l5: 0.165752, l6: 0.336424\n",
      "\n",
      "[epoch: 335/400, batch: 920/1000, ite: 44741] train loss: 1.1851, accuracy: 95.1032%, tar: 0.0268 \n",
      "l0: 0.027117, l1: 0.028373, l2: 0.035951, l3: 0.049449, l4: 0.082571, l5: 0.140863, l6: 0.315206\n",
      "\n",
      "[epoch: 335/400, batch: 928/1000, ite: 44742] train loss: 1.1849, accuracy: 94.8321%, tar: 0.0268 \n",
      "l0: 0.024605, l1: 0.026061, l2: 0.035601, l3: 0.053105, l4: 0.087448, l5: 0.153579, l6: 0.285604\n",
      "\n",
      "[epoch: 335/400, batch: 936/1000, ite: 44743] train loss: 1.1846, accuracy: 95.8473%, tar: 0.0268 \n",
      "l0: 0.020941, l1: 0.021903, l2: 0.028679, l3: 0.040729, l4: 0.072699, l5: 0.148885, l6: 0.357915\n",
      "\n",
      "[epoch: 335/400, batch: 944/1000, ite: 44744] train loss: 1.1844, accuracy: 95.6256%, tar: 0.0268 \n",
      "l0: 0.036074, l1: 0.039041, l2: 0.045066, l3: 0.059967, l4: 0.100353, l5: 0.213549, l6: 0.485437\n",
      "\n",
      "[epoch: 335/400, batch: 952/1000, ite: 44745] train loss: 1.1848, accuracy: 92.5196%, tar: 0.0268 \n",
      "l0: 0.034402, l1: 0.036003, l2: 0.044543, l3: 0.060665, l4: 0.108312, l5: 0.201469, l6: 0.410620\n",
      "\n",
      "[epoch: 335/400, batch: 960/1000, ite: 44746] train loss: 1.1850, accuracy: 94.6236%, tar: 0.0268 \n",
      "l0: 0.025120, l1: 0.027526, l2: 0.037529, l3: 0.065098, l4: 0.107846, l5: 0.193239, l6: 0.382691\n",
      "\n",
      "[epoch: 335/400, batch: 968/1000, ite: 44747] train loss: 1.1850, accuracy: 95.0674%, tar: 0.0268 \n",
      "l0: 0.035796, l1: 0.037680, l2: 0.047258, l3: 0.068368, l4: 0.110064, l5: 0.189512, l6: 0.360904\n",
      "\n",
      "[epoch: 335/400, batch: 976/1000, ite: 44748] train loss: 1.1851, accuracy: 94.8268%, tar: 0.0268 \n",
      "l0: 0.026237, l1: 0.028398, l2: 0.037079, l3: 0.059997, l4: 0.117036, l5: 0.228571, l6: 0.446656\n",
      "\n",
      "[epoch: 335/400, batch: 984/1000, ite: 44749] train loss: 1.1853, accuracy: 94.9976%, tar: 0.0268 \n",
      "l0: 0.022619, l1: 0.023530, l2: 0.029515, l3: 0.047591, l4: 0.089625, l5: 0.166163, l6: 0.306262\n",
      "\n",
      "[epoch: 335/400, batch: 992/1000, ite: 44750] train loss: 1.1851, accuracy: 95.4456%, tar: 0.0268 \n",
      "l0: 0.024700, l1: 0.025933, l2: 0.033661, l3: 0.045742, l4: 0.072033, l5: 0.155939, l6: 0.287098\n",
      "\n",
      "[epoch: 335/400, batch: 1000/1000, ite: 44751] train loss: 1.1848, accuracy: 95.6520%, tar: 0.0268 \n",
      "l0: 0.023416, l1: 0.024233, l2: 0.030727, l3: 0.046799, l4: 0.100978, l5: 0.197939, l6: 0.369993\n",
      "\n",
      "[epoch: 336/400, batch: 8/1000, ite: 44752] train loss: 1.1847, accuracy: 94.5656%, tar: 0.0268 \n",
      "l0: 0.024359, l1: 0.025930, l2: 0.035404, l3: 0.053091, l4: 0.095340, l5: 0.173192, l6: 0.315573\n",
      "\n",
      "[epoch: 336/400, batch: 16/1000, ite: 44753] train loss: 1.1845, accuracy: 95.3790%, tar: 0.0268 \n",
      "l0: 0.028637, l1: 0.030466, l2: 0.038897, l3: 0.056536, l4: 0.095010, l5: 0.181518, l6: 0.443595\n",
      "\n",
      "[epoch: 336/400, batch: 24/1000, ite: 44754] train loss: 1.1847, accuracy: 94.6848%, tar: 0.0268 \n",
      "l0: 0.027427, l1: 0.028620, l2: 0.035521, l3: 0.049620, l4: 0.080941, l5: 0.156295, l6: 0.293509\n",
      "\n",
      "[epoch: 336/400, batch: 32/1000, ite: 44755] train loss: 1.1844, accuracy: 95.1156%, tar: 0.0268 \n",
      "l0: 0.026113, l1: 0.027823, l2: 0.035218, l3: 0.053946, l4: 0.103255, l5: 0.202610, l6: 0.408289\n",
      "\n",
      "[epoch: 336/400, batch: 40/1000, ite: 44756] train loss: 1.1845, accuracy: 93.9221%, tar: 0.0268 \n",
      "l0: 0.023306, l1: 0.025566, l2: 0.034078, l3: 0.052561, l4: 0.096177, l5: 0.189315, l6: 0.376058\n",
      "\n",
      "[epoch: 336/400, batch: 48/1000, ite: 44757] train loss: 1.1845, accuracy: 95.4725%, tar: 0.0268 \n",
      "l0: 0.028362, l1: 0.029663, l2: 0.038629, l3: 0.057176, l4: 0.104502, l5: 0.185600, l6: 0.344757\n",
      "\n",
      "[epoch: 336/400, batch: 56/1000, ite: 44758] train loss: 1.1845, accuracy: 94.9735%, tar: 0.0268 \n",
      "l0: 0.023179, l1: 0.024532, l2: 0.032493, l3: 0.050095, l4: 0.105787, l5: 0.223822, l6: 0.412466\n",
      "\n",
      "[epoch: 336/400, batch: 64/1000, ite: 44759] train loss: 1.1846, accuracy: 94.4574%, tar: 0.0268 \n",
      "l0: 0.031720, l1: 0.032564, l2: 0.040814, l3: 0.053531, l4: 0.082582, l5: 0.154300, l6: 0.407516\n",
      "\n",
      "[epoch: 336/400, batch: 72/1000, ite: 44760] train loss: 1.1847, accuracy: 93.7939%, tar: 0.0268 \n",
      "l0: 0.023851, l1: 0.024548, l2: 0.032923, l3: 0.048139, l4: 0.087299, l5: 0.176162, l6: 0.410126\n",
      "\n",
      "[epoch: 336/400, batch: 80/1000, ite: 44761] train loss: 1.1847, accuracy: 94.3897%, tar: 0.0268 \n",
      "l0: 0.025198, l1: 0.025952, l2: 0.032543, l3: 0.047092, l4: 0.090808, l5: 0.185754, l6: 0.373058\n",
      "\n",
      "[epoch: 336/400, batch: 88/1000, ite: 44762] train loss: 1.1847, accuracy: 94.3743%, tar: 0.0268 \n",
      "l0: 0.025032, l1: 0.026158, l2: 0.032117, l3: 0.048753, l4: 0.085003, l5: 0.171973, l6: 0.342752\n",
      "\n",
      "[epoch: 336/400, batch: 96/1000, ite: 44763] train loss: 1.1845, accuracy: 94.9211%, tar: 0.0268 \n",
      "l0: 0.029150, l1: 0.030223, l2: 0.037206, l3: 0.049637, l4: 0.088573, l5: 0.165723, l6: 0.400482\n",
      "\n",
      "[epoch: 336/400, batch: 104/1000, ite: 44764] train loss: 1.1845, accuracy: 94.7372%, tar: 0.0268 \n",
      "l0: 0.025980, l1: 0.027557, l2: 0.036342, l3: 0.052012, l4: 0.095574, l5: 0.176701, l6: 0.345452\n",
      "\n",
      "[epoch: 336/400, batch: 112/1000, ite: 44765] train loss: 1.1844, accuracy: 95.0839%, tar: 0.0268 \n",
      "l0: 0.024258, l1: 0.025295, l2: 0.032423, l3: 0.046123, l4: 0.076826, l5: 0.126970, l6: 0.232781\n",
      "\n",
      "[epoch: 336/400, batch: 120/1000, ite: 44766] train loss: 1.1839, accuracy: 96.2476%, tar: 0.0268 \n",
      "l0: 0.027589, l1: 0.029707, l2: 0.038361, l3: 0.059155, l4: 0.118394, l5: 0.220513, l6: 0.429760\n",
      "\n",
      "[epoch: 336/400, batch: 128/1000, ite: 44767] train loss: 1.1842, accuracy: 93.6351%, tar: 0.0268 \n",
      "l0: 0.024404, l1: 0.025464, l2: 0.031144, l3: 0.042512, l4: 0.068218, l5: 0.128416, l6: 0.283395\n",
      "\n",
      "[epoch: 336/400, batch: 136/1000, ite: 44768] train loss: 1.1838, accuracy: 95.6100%, tar: 0.0268 \n",
      "l0: 0.029865, l1: 0.031505, l2: 0.039380, l3: 0.055892, l4: 0.094673, l5: 0.186919, l6: 0.403435\n",
      "\n",
      "[epoch: 336/400, batch: 144/1000, ite: 44769] train loss: 1.1839, accuracy: 93.9623%, tar: 0.0268 \n",
      "l0: 0.029335, l1: 0.030342, l2: 0.038365, l3: 0.051941, l4: 0.087312, l5: 0.180712, l6: 0.368870\n",
      "\n",
      "[epoch: 336/400, batch: 152/1000, ite: 44770] train loss: 1.1838, accuracy: 94.7528%, tar: 0.0268 \n",
      "l0: 0.021753, l1: 0.023262, l2: 0.030420, l3: 0.046816, l4: 0.102875, l5: 0.223598, l6: 0.453362\n",
      "\n",
      "[epoch: 336/400, batch: 160/1000, ite: 44771] train loss: 1.1841, accuracy: 94.5608%, tar: 0.0268 \n",
      "l0: 0.028145, l1: 0.029429, l2: 0.039765, l3: 0.058665, l4: 0.095215, l5: 0.194627, l6: 0.418814\n",
      "\n",
      "[epoch: 336/400, batch: 168/1000, ite: 44772] train loss: 1.1842, accuracy: 94.2346%, tar: 0.0268 \n",
      "l0: 0.025707, l1: 0.027711, l2: 0.037091, l3: 0.056837, l4: 0.107554, l5: 0.233431, l6: 0.418715\n",
      "\n",
      "[epoch: 336/400, batch: 176/1000, ite: 44773] train loss: 1.1844, accuracy: 94.6262%, tar: 0.0268 \n",
      "l0: 0.026286, l1: 0.027446, l2: 0.037457, l3: 0.055272, l4: 0.092985, l5: 0.168850, l6: 0.388084\n",
      "\n",
      "[epoch: 336/400, batch: 184/1000, ite: 44774] train loss: 1.1844, accuracy: 94.5367%, tar: 0.0268 \n",
      "l0: 0.030362, l1: 0.031669, l2: 0.039209, l3: 0.057073, l4: 0.106878, l5: 0.213411, l6: 0.431565\n",
      "\n",
      "[epoch: 336/400, batch: 192/1000, ite: 44775] train loss: 1.1846, accuracy: 94.0875%, tar: 0.0268 \n",
      "l0: 0.026806, l1: 0.028090, l2: 0.036411, l3: 0.050652, l4: 0.093633, l5: 0.176810, l6: 0.330794\n",
      "\n",
      "[epoch: 336/400, batch: 200/1000, ite: 44776] train loss: 1.1845, accuracy: 95.4607%, tar: 0.0268 \n",
      "l0: 0.029525, l1: 0.030892, l2: 0.036045, l3: 0.050525, l4: 0.084708, l5: 0.162884, l6: 0.334780\n",
      "\n",
      "[epoch: 336/400, batch: 208/1000, ite: 44777] train loss: 1.1843, accuracy: 95.4202%, tar: 0.0268 \n",
      "l0: 0.029647, l1: 0.031320, l2: 0.040226, l3: 0.055590, l4: 0.095687, l5: 0.186497, l6: 0.419958\n",
      "\n",
      "[epoch: 336/400, batch: 216/1000, ite: 44778] train loss: 1.1845, accuracy: 94.2391%, tar: 0.0268 \n",
      "l0: 0.025192, l1: 0.026206, l2: 0.033045, l3: 0.047376, l4: 0.086874, l5: 0.209488, l6: 0.414055\n",
      "\n",
      "[epoch: 336/400, batch: 224/1000, ite: 44779] train loss: 1.1846, accuracy: 94.4557%, tar: 0.0268 \n",
      "l0: 0.028820, l1: 0.029732, l2: 0.037724, l3: 0.052877, l4: 0.088443, l5: 0.172637, l6: 0.363359\n",
      "\n",
      "[epoch: 336/400, batch: 232/1000, ite: 44780] train loss: 1.1845, accuracy: 94.7452%, tar: 0.0268 \n",
      "l0: 0.026108, l1: 0.026676, l2: 0.032290, l3: 0.045733, l4: 0.077945, l5: 0.157417, l6: 0.330336\n",
      "\n",
      "[epoch: 336/400, batch: 240/1000, ite: 44781] train loss: 1.1843, accuracy: 94.9224%, tar: 0.0268 \n",
      "l0: 0.024370, l1: 0.026806, l2: 0.035227, l3: 0.053093, l4: 0.103618, l5: 0.209439, l6: 0.393777\n",
      "\n",
      "[epoch: 336/400, batch: 248/1000, ite: 44782] train loss: 1.1844, accuracy: 94.7439%, tar: 0.0268 \n",
      "l0: 0.026746, l1: 0.028391, l2: 0.036366, l3: 0.055414, l4: 0.106230, l5: 0.243086, l6: 0.426289\n",
      "\n",
      "[epoch: 336/400, batch: 256/1000, ite: 44783] train loss: 1.1846, accuracy: 94.8413%, tar: 0.0268 \n",
      "l0: 0.019881, l1: 0.021464, l2: 0.026858, l3: 0.042418, l4: 0.097501, l5: 0.181943, l6: 0.347033\n",
      "\n",
      "[epoch: 336/400, batch: 264/1000, ite: 44784] train loss: 1.1844, accuracy: 95.8183%, tar: 0.0268 \n",
      "l0: 0.021843, l1: 0.022798, l2: 0.029608, l3: 0.043201, l4: 0.071441, l5: 0.133761, l6: 0.316362\n",
      "\n",
      "[epoch: 336/400, batch: 272/1000, ite: 44785] train loss: 1.1842, accuracy: 95.6023%, tar: 0.0268 \n",
      "l0: 0.030224, l1: 0.031696, l2: 0.042196, l3: 0.063178, l4: 0.108590, l5: 0.223293, l6: 0.484938\n",
      "\n",
      "[epoch: 336/400, batch: 280/1000, ite: 44786] train loss: 1.1845, accuracy: 94.0530%, tar: 0.0268 \n",
      "l0: 0.020921, l1: 0.022276, l2: 0.030429, l3: 0.051843, l4: 0.138634, l5: 0.201190, l6: 0.435354\n",
      "\n",
      "[epoch: 336/400, batch: 288/1000, ite: 44787] train loss: 1.1847, accuracy: 95.1057%, tar: 0.0268 \n",
      "l0: 0.026163, l1: 0.029277, l2: 0.042319, l3: 0.069350, l4: 0.146883, l5: 0.288922, l6: 0.509220\n",
      "\n",
      "[epoch: 336/400, batch: 296/1000, ite: 44788] train loss: 1.1853, accuracy: 94.3489%, tar: 0.0268 \n",
      "l0: 0.023449, l1: 0.024878, l2: 0.034590, l3: 0.049301, l4: 0.090254, l5: 0.187350, l6: 0.408453\n",
      "\n",
      "[epoch: 336/400, batch: 304/1000, ite: 44789] train loss: 1.1853, accuracy: 95.1104%, tar: 0.0268 \n",
      "l0: 0.019010, l1: 0.019756, l2: 0.025923, l3: 0.038274, l4: 0.063804, l5: 0.106708, l6: 0.256368\n",
      "\n",
      "[epoch: 336/400, batch: 312/1000, ite: 44790] train loss: 1.1848, accuracy: 95.9844%, tar: 0.0268 \n",
      "l0: 0.025502, l1: 0.027617, l2: 0.034413, l3: 0.049724, l4: 0.081119, l5: 0.158392, l6: 0.399664\n",
      "\n",
      "[epoch: 336/400, batch: 320/1000, ite: 44791] train loss: 1.1848, accuracy: 94.3727%, tar: 0.0268 \n",
      "l0: 0.028576, l1: 0.030258, l2: 0.039801, l3: 0.061232, l4: 0.120462, l5: 0.243646, l6: 0.444799\n",
      "\n",
      "[epoch: 336/400, batch: 328/1000, ite: 44792] train loss: 1.1851, accuracy: 93.7640%, tar: 0.0268 \n",
      "l0: 0.020281, l1: 0.022247, l2: 0.028921, l3: 0.043060, l4: 0.076867, l5: 0.160582, l6: 0.331782\n",
      "\n",
      "[epoch: 336/400, batch: 336/1000, ite: 44793] train loss: 1.1849, accuracy: 95.5890%, tar: 0.0268 \n",
      "l0: 0.028301, l1: 0.029889, l2: 0.038371, l3: 0.061077, l4: 0.102405, l5: 0.175519, l6: 0.371620\n",
      "\n",
      "[epoch: 336/400, batch: 344/1000, ite: 44794] train loss: 1.1849, accuracy: 94.3823%, tar: 0.0268 \n",
      "l0: 0.019742, l1: 0.020742, l2: 0.025996, l3: 0.036992, l4: 0.068475, l5: 0.114351, l6: 0.245478\n",
      "\n",
      "[epoch: 336/400, batch: 352/1000, ite: 44795] train loss: 1.1844, accuracy: 96.0474%, tar: 0.0267 \n",
      "l0: 0.028586, l1: 0.028863, l2: 0.037981, l3: 0.053162, l4: 0.087634, l5: 0.185849, l6: 0.425494\n",
      "\n",
      "[epoch: 336/400, batch: 360/1000, ite: 44796] train loss: 1.1845, accuracy: 94.2671%, tar: 0.0267 \n",
      "l0: 0.024154, l1: 0.026408, l2: 0.035190, l3: 0.052284, l4: 0.097788, l5: 0.170331, l6: 0.329756\n",
      "\n",
      "[epoch: 336/400, batch: 368/1000, ite: 44797] train loss: 1.1844, accuracy: 95.2235%, tar: 0.0267 \n",
      "l0: 0.032077, l1: 0.035354, l2: 0.046078, l3: 0.066356, l4: 0.103037, l5: 0.205234, l6: 0.462087\n",
      "\n",
      "[epoch: 336/400, batch: 376/1000, ite: 44798] train loss: 1.1847, accuracy: 93.3509%, tar: 0.0268 \n",
      "l0: 0.025853, l1: 0.027365, l2: 0.033891, l3: 0.048325, l4: 0.088640, l5: 0.222404, l6: 0.436748\n",
      "\n",
      "[epoch: 336/400, batch: 384/1000, ite: 44799] train loss: 1.1848, accuracy: 94.2586%, tar: 0.0267 \n",
      "l0: 0.032822, l1: 0.034851, l2: 0.044176, l3: 0.064900, l4: 0.116730, l5: 0.208265, l6: 0.382444\n",
      "\n",
      "[epoch: 336/400, batch: 392/1000, ite: 44800] train loss: 1.1850, accuracy: 94.3591%, tar: 0.0268 \n",
      "l0: 0.030847, l1: 0.032500, l2: 0.042888, l3: 0.064190, l4: 0.119298, l5: 0.241865, l6: 0.482790\n",
      "\n",
      "[epoch: 336/400, batch: 400/1000, ite: 44801] train loss: 1.1853, accuracy: 93.3070%, tar: 0.0268 \n",
      "l0: 0.029391, l1: 0.030613, l2: 0.039607, l3: 0.056585, l4: 0.095983, l5: 0.208307, l6: 0.457829\n",
      "\n",
      "[epoch: 336/400, batch: 408/1000, ite: 44802] train loss: 1.1856, accuracy: 93.5215%, tar: 0.0268 \n",
      "l0: 0.020415, l1: 0.021446, l2: 0.026567, l3: 0.037912, l4: 0.064412, l5: 0.120034, l6: 0.347322\n",
      "\n",
      "[epoch: 336/400, batch: 416/1000, ite: 44803] train loss: 1.1853, accuracy: 95.1622%, tar: 0.0268 \n",
      "l0: 0.030190, l1: 0.032113, l2: 0.042272, l3: 0.062072, l4: 0.110387, l5: 0.186342, l6: 0.341552\n",
      "\n",
      "[epoch: 336/400, batch: 424/1000, ite: 44804] train loss: 1.1853, accuracy: 94.3834%, tar: 0.0268 \n",
      "l0: 0.029391, l1: 0.030744, l2: 0.036573, l3: 0.049317, l4: 0.087892, l5: 0.165861, l6: 0.335946\n",
      "\n",
      "[epoch: 336/400, batch: 432/1000, ite: 44805] train loss: 1.1852, accuracy: 94.6480%, tar: 0.0268 \n",
      "l0: 0.021128, l1: 0.022774, l2: 0.029790, l3: 0.044425, l4: 0.081786, l5: 0.155663, l6: 0.309957\n",
      "\n",
      "[epoch: 336/400, batch: 440/1000, ite: 44806] train loss: 1.1849, accuracy: 95.8957%, tar: 0.0268 \n",
      "l0: 0.033632, l1: 0.034889, l2: 0.041978, l3: 0.056840, l4: 0.086477, l5: 0.154975, l6: 0.325130\n",
      "\n",
      "[epoch: 336/400, batch: 448/1000, ite: 44807] train loss: 1.1847, accuracy: 94.7173%, tar: 0.0268 \n",
      "l0: 0.024614, l1: 0.025478, l2: 0.032482, l3: 0.046319, l4: 0.078916, l5: 0.148650, l6: 0.294727\n",
      "\n",
      "[epoch: 336/400, batch: 456/1000, ite: 44808] train loss: 1.1845, accuracy: 95.4276%, tar: 0.0268 \n",
      "l0: 0.028657, l1: 0.030527, l2: 0.037189, l3: 0.061552, l4: 0.110081, l5: 0.221223, l6: 0.418394\n",
      "\n",
      "[epoch: 336/400, batch: 464/1000, ite: 44809] train loss: 1.1846, accuracy: 94.3243%, tar: 0.0268 \n",
      "l0: 0.027124, l1: 0.028568, l2: 0.038273, l3: 0.052476, l4: 0.098872, l5: 0.204542, l6: 0.429473\n",
      "\n",
      "[epoch: 336/400, batch: 472/1000, ite: 44810] train loss: 1.1848, accuracy: 94.1523%, tar: 0.0268 \n",
      "l0: 0.031453, l1: 0.033385, l2: 0.044922, l3: 0.062858, l4: 0.117169, l5: 0.214466, l6: 0.411954\n",
      "\n",
      "[epoch: 336/400, batch: 480/1000, ite: 44811] train loss: 1.1850, accuracy: 94.3259%, tar: 0.0268 \n",
      "l0: 0.039873, l1: 0.040862, l2: 0.051804, l3: 0.077970, l4: 0.141679, l5: 0.254332, l6: 0.475100\n",
      "\n",
      "[epoch: 336/400, batch: 488/1000, ite: 44812] train loss: 1.1854, accuracy: 94.1554%, tar: 0.0268 \n",
      "l0: 0.016983, l1: 0.018232, l2: 0.024200, l3: 0.034951, l4: 0.057630, l5: 0.104671, l6: 0.240697\n",
      "\n",
      "[epoch: 336/400, batch: 496/1000, ite: 44813] train loss: 1.1849, accuracy: 96.9587%, tar: 0.0268 \n",
      "l0: 0.026496, l1: 0.029187, l2: 0.039221, l3: 0.060542, l4: 0.109606, l5: 0.238103, l6: 0.446185\n",
      "\n",
      "[epoch: 336/400, batch: 504/1000, ite: 44814] train loss: 1.1852, accuracy: 95.2993%, tar: 0.0268 \n",
      "l0: 0.033022, l1: 0.034386, l2: 0.042024, l3: 0.059305, l4: 0.105870, l5: 0.219009, l6: 0.456474\n",
      "\n",
      "[epoch: 336/400, batch: 512/1000, ite: 44815] train loss: 1.1854, accuracy: 93.2401%, tar: 0.0268 \n",
      "l0: 0.020297, l1: 0.021880, l2: 0.029418, l3: 0.046748, l4: 0.082767, l5: 0.170788, l6: 0.401151\n",
      "\n",
      "[epoch: 336/400, batch: 520/1000, ite: 44816] train loss: 1.1854, accuracy: 96.2175%, tar: 0.0268 \n",
      "l0: 0.028808, l1: 0.030672, l2: 0.040470, l3: 0.061946, l4: 0.119120, l5: 0.247210, l6: 0.465403\n",
      "\n",
      "[epoch: 336/400, batch: 528/1000, ite: 44817] train loss: 1.1858, accuracy: 93.7950%, tar: 0.0268 \n",
      "l0: 0.032148, l1: 0.034559, l2: 0.042630, l3: 0.058966, l4: 0.097232, l5: 0.167593, l6: 0.318962\n",
      "\n",
      "[epoch: 336/400, batch: 536/1000, ite: 44818] train loss: 1.1856, accuracy: 94.7327%, tar: 0.0268 \n",
      "l0: 0.024628, l1: 0.026298, l2: 0.033202, l3: 0.050528, l4: 0.089722, l5: 0.159773, l6: 0.325671\n",
      "\n",
      "[epoch: 336/400, batch: 544/1000, ite: 44819] train loss: 1.1854, accuracy: 95.2105%, tar: 0.0268 \n",
      "l0: 0.032458, l1: 0.035386, l2: 0.045395, l3: 0.071500, l4: 0.131875, l5: 0.254150, l6: 0.470732\n",
      "\n",
      "[epoch: 336/400, batch: 552/1000, ite: 44820] train loss: 1.1858, accuracy: 94.2861%, tar: 0.0268 \n",
      "l0: 0.025451, l1: 0.026517, l2: 0.034259, l3: 0.047550, l4: 0.084833, l5: 0.171264, l6: 0.366548\n",
      "\n",
      "[epoch: 336/400, batch: 560/1000, ite: 44821] train loss: 1.1858, accuracy: 95.0517%, tar: 0.0268 \n",
      "l0: 0.022766, l1: 0.024037, l2: 0.030551, l3: 0.042896, l4: 0.068245, l5: 0.130596, l6: 0.300893\n",
      "\n",
      "[epoch: 336/400, batch: 568/1000, ite: 44822] train loss: 1.1854, accuracy: 96.0821%, tar: 0.0268 \n",
      "l0: 0.061582, l1: 0.068195, l2: 0.079143, l3: 0.101307, l4: 0.160283, l5: 0.250005, l6: 0.459089\n",
      "\n",
      "l0: 0.028652, l1: 0.030377, l2: 0.037521, l3: 0.055177, l4: 0.087618, l5: 0.142253, l6: 0.315094\n",
      "\n",
      "[epoch: 336/400, batch: 592/1000, ite: 44825] train loss: 1.1859, accuracy: 95.4153%, tar: 0.0268 \n",
      "l0: 0.026187, l1: 0.027706, l2: 0.039331, l3: 0.062555, l4: 0.121321, l5: 0.239915, l6: 0.459691\n",
      "\n",
      "[epoch: 336/400, batch: 600/1000, ite: 44826] train loss: 1.1862, accuracy: 94.0772%, tar: 0.0268 \n",
      "l0: 0.024696, l1: 0.025600, l2: 0.033298, l3: 0.046327, l4: 0.073076, l5: 0.134031, l6: 0.297330\n",
      "\n",
      "[epoch: 336/400, batch: 608/1000, ite: 44827] train loss: 1.1859, accuracy: 95.4823%, tar: 0.0268 \n",
      "l0: 0.020492, l1: 0.021529, l2: 0.026640, l3: 0.035912, l4: 0.060335, l5: 0.119575, l6: 0.247178\n",
      "\n",
      "[epoch: 336/400, batch: 616/1000, ite: 44828] train loss: 1.1854, accuracy: 96.4877%, tar: 0.0268 \n",
      "l0: 0.026584, l1: 0.027516, l2: 0.034714, l3: 0.047654, l4: 0.076041, l5: 0.161698, l6: 0.339295\n",
      "\n",
      "[epoch: 336/400, batch: 624/1000, ite: 44829] train loss: 1.1853, accuracy: 94.9906%, tar: 0.0268 \n",
      "l0: 0.037488, l1: 0.039877, l2: 0.047244, l3: 0.065492, l4: 0.110028, l5: 0.235605, l6: 0.484698\n",
      "\n",
      "[epoch: 336/400, batch: 632/1000, ite: 44830] train loss: 1.1857, accuracy: 92.2517%, tar: 0.0268 \n",
      "l0: 0.032707, l1: 0.033726, l2: 0.042704, l3: 0.058765, l4: 0.101023, l5: 0.206168, l6: 0.404544\n",
      "\n",
      "[epoch: 336/400, batch: 640/1000, ite: 44831] train loss: 1.1858, accuracy: 94.4018%, tar: 0.0268 \n",
      "l0: 0.039056, l1: 0.040343, l2: 0.048464, l3: 0.063778, l4: 0.122531, l5: 0.255183, l6: 0.516585\n",
      "\n",
      "[epoch: 336/400, batch: 648/1000, ite: 44832] train loss: 1.1863, accuracy: 93.1978%, tar: 0.0269 \n",
      "l0: 0.026800, l1: 0.027819, l2: 0.034435, l3: 0.047827, l4: 0.077262, l5: 0.159718, l6: 0.357257\n",
      "\n",
      "[epoch: 336/400, batch: 656/1000, ite: 44833] train loss: 1.1862, accuracy: 95.4738%, tar: 0.0269 \n",
      "l0: 0.026444, l1: 0.027481, l2: 0.033951, l3: 0.046782, l4: 0.083430, l5: 0.148552, l6: 0.297205\n",
      "\n",
      "[epoch: 336/400, batch: 664/1000, ite: 44834] train loss: 1.1859, accuracy: 95.1635%, tar: 0.0269 \n",
      "l0: 0.029065, l1: 0.030302, l2: 0.037106, l3: 0.050787, l4: 0.086552, l5: 0.148114, l6: 0.287113\n",
      "\n",
      "[epoch: 336/400, batch: 672/1000, ite: 44835] train loss: 1.1856, accuracy: 94.9888%, tar: 0.0269 \n",
      "l0: 0.028425, l1: 0.030233, l2: 0.039020, l3: 0.054989, l4: 0.100461, l5: 0.188230, l6: 0.423305\n",
      "\n",
      "[epoch: 336/400, batch: 680/1000, ite: 44836] train loss: 1.1858, accuracy: 94.8807%, tar: 0.0269 \n",
      "l0: 0.031725, l1: 0.033397, l2: 0.047149, l3: 0.066198, l4: 0.118107, l5: 0.250534, l6: 0.516731\n",
      "\n",
      "[epoch: 336/400, batch: 688/1000, ite: 44837] train loss: 1.1862, accuracy: 93.4761%, tar: 0.0269 \n",
      "l0: 0.022638, l1: 0.023391, l2: 0.030031, l3: 0.042805, l4: 0.069738, l5: 0.126325, l6: 0.272484\n",
      "\n",
      "[epoch: 336/400, batch: 696/1000, ite: 44838] train loss: 1.1859, accuracy: 95.8697%, tar: 0.0269 \n",
      "l0: 0.031730, l1: 0.033212, l2: 0.040558, l3: 0.058728, l4: 0.118425, l5: 0.211118, l6: 0.372644\n",
      "\n",
      "[epoch: 336/400, batch: 704/1000, ite: 44839] train loss: 1.1859, accuracy: 93.9642%, tar: 0.0269 \n",
      "l0: 0.027640, l1: 0.028394, l2: 0.036036, l3: 0.051297, l4: 0.109015, l5: 0.196290, l6: 0.406235\n",
      "\n",
      "[epoch: 336/400, batch: 712/1000, ite: 44840] train loss: 1.1860, accuracy: 95.1302%, tar: 0.0269 \n",
      "l0: 0.022859, l1: 0.024625, l2: 0.033279, l3: 0.047652, l4: 0.091234, l5: 0.172660, l6: 0.311599\n",
      "\n",
      "[epoch: 336/400, batch: 720/1000, ite: 44841] train loss: 1.1858, accuracy: 95.2387%, tar: 0.0269 \n",
      "l0: 0.034413, l1: 0.036070, l2: 0.047306, l3: 0.068620, l4: 0.112385, l5: 0.237056, l6: 0.506544\n",
      "\n",
      "[epoch: 336/400, batch: 728/1000, ite: 44842] train loss: 1.1863, accuracy: 92.8717%, tar: 0.0269 \n",
      "l0: 0.022504, l1: 0.023661, l2: 0.027842, l3: 0.039053, l4: 0.059706, l5: 0.106011, l6: 0.245186\n",
      "\n",
      "[epoch: 336/400, batch: 736/1000, ite: 44843] train loss: 1.1858, accuracy: 96.4658%, tar: 0.0269 \n",
      "l0: 0.034958, l1: 0.036029, l2: 0.044852, l3: 0.068242, l4: 0.135724, l5: 0.251177, l6: 0.508304\n",
      "\n",
      "[epoch: 336/400, batch: 744/1000, ite: 44844] train loss: 1.1862, accuracy: 92.7442%, tar: 0.0269 \n",
      "l0: 0.024611, l1: 0.025867, l2: 0.033860, l3: 0.053487, l4: 0.100019, l5: 0.219129, l6: 0.355576\n",
      "\n",
      "[epoch: 336/400, batch: 752/1000, ite: 44845] train loss: 1.1862, accuracy: 94.9628%, tar: 0.0269 \n",
      "l0: 0.028560, l1: 0.030244, l2: 0.039500, l3: 0.058956, l4: 0.106966, l5: 0.216219, l6: 0.438002\n",
      "\n",
      "[epoch: 336/400, batch: 760/1000, ite: 44846] train loss: 1.1864, accuracy: 94.2637%, tar: 0.0269 \n",
      "l0: 0.025913, l1: 0.026885, l2: 0.036009, l3: 0.054074, l4: 0.094052, l5: 0.195477, l6: 0.369158\n",
      "\n",
      "[epoch: 336/400, batch: 768/1000, ite: 44847] train loss: 1.1864, accuracy: 94.4264%, tar: 0.0269 \n",
      "l0: 0.028678, l1: 0.029408, l2: 0.037663, l3: 0.054555, l4: 0.095339, l5: 0.202530, l6: 0.385668\n",
      "\n",
      "[epoch: 336/400, batch: 776/1000, ite: 44848] train loss: 1.1865, accuracy: 93.9346%, tar: 0.0269 \n",
      "l0: 0.029156, l1: 0.030843, l2: 0.038744, l3: 0.060355, l4: 0.127364, l5: 0.280069, l6: 0.564823\n",
      "\n",
      "[epoch: 336/400, batch: 784/1000, ite: 44849] train loss: 1.1871, accuracy: 92.9541%, tar: 0.0269 \n",
      "l0: 0.025224, l1: 0.026010, l2: 0.034208, l3: 0.053374, l4: 0.112079, l5: 0.208468, l6: 0.360329\n",
      "\n",
      "[epoch: 336/400, batch: 792/1000, ite: 44850] train loss: 1.1871, accuracy: 94.8528%, tar: 0.0269 \n",
      "l0: 0.026093, l1: 0.028500, l2: 0.039456, l3: 0.068327, l4: 0.154961, l5: 0.234345, l6: 0.404362\n",
      "\n",
      "[epoch: 336/400, batch: 800/1000, ite: 44851] train loss: 1.1873, accuracy: 95.2130%, tar: 0.0269 \n",
      "l0: 0.025288, l1: 0.026012, l2: 0.032460, l3: 0.045197, l4: 0.069196, l5: 0.135748, l6: 0.295624\n",
      "\n",
      "[epoch: 336/400, batch: 808/1000, ite: 44852] train loss: 1.1870, accuracy: 95.0624%, tar: 0.0269 \n",
      "l0: 0.029785, l1: 0.030976, l2: 0.041754, l3: 0.062365, l4: 0.119312, l5: 0.219801, l6: 0.421591\n",
      "\n",
      "[epoch: 336/400, batch: 816/1000, ite: 44853] train loss: 1.1872, accuracy: 93.9249%, tar: 0.0269 \n",
      "l0: 0.024054, l1: 0.025450, l2: 0.031886, l3: 0.043352, l4: 0.074784, l5: 0.133408, l6: 0.260815\n",
      "\n",
      "[epoch: 336/400, batch: 824/1000, ite: 44854] train loss: 1.1868, accuracy: 95.8675%, tar: 0.0269 \n",
      "l0: 0.025867, l1: 0.026972, l2: 0.034434, l3: 0.051486, l4: 0.089913, l5: 0.182628, l6: 0.343485\n",
      "\n",
      "[epoch: 336/400, batch: 832/1000, ite: 44855] train loss: 1.1867, accuracy: 94.8691%, tar: 0.0269 \n",
      "l0: 0.026137, l1: 0.028791, l2: 0.037044, l3: 0.055175, l4: 0.107322, l5: 0.224438, l6: 0.420494\n",
      "\n",
      "[epoch: 336/400, batch: 840/1000, ite: 44856] train loss: 1.1868, accuracy: 93.9698%, tar: 0.0269 \n",
      "l0: 0.026802, l1: 0.028520, l2: 0.036199, l3: 0.051174, l4: 0.094346, l5: 0.193323, l6: 0.423658\n",
      "\n",
      "[epoch: 336/400, batch: 848/1000, ite: 44857] train loss: 1.1869, accuracy: 94.7270%, tar: 0.0269 \n",
      "l0: 0.029872, l1: 0.031535, l2: 0.039785, l3: 0.053507, l4: 0.083184, l5: 0.138531, l6: 0.251301\n",
      "\n",
      "[epoch: 336/400, batch: 856/1000, ite: 44858] train loss: 1.1866, accuracy: 95.6200%, tar: 0.0269 \n",
      "l0: 0.023580, l1: 0.024611, l2: 0.034736, l3: 0.055627, l4: 0.108973, l5: 0.180762, l6: 0.361124\n",
      "\n",
      "[epoch: 336/400, batch: 864/1000, ite: 44859] train loss: 1.1866, accuracy: 95.3543%, tar: 0.0269 \n",
      "l0: 0.029033, l1: 0.030417, l2: 0.040028, l3: 0.057043, l4: 0.110830, l5: 0.197487, l6: 0.375418\n",
      "\n",
      "[epoch: 336/400, batch: 872/1000, ite: 44860] train loss: 1.1866, accuracy: 94.5719%, tar: 0.0269 \n",
      "l0: 0.031167, l1: 0.032566, l2: 0.041721, l3: 0.061004, l4: 0.101505, l5: 0.180299, l6: 0.350971\n",
      "\n",
      "[epoch: 336/400, batch: 880/1000, ite: 44861] train loss: 1.1865, accuracy: 95.2740%, tar: 0.0269 \n",
      "l0: 0.032118, l1: 0.034070, l2: 0.043025, l3: 0.060797, l4: 0.119255, l5: 0.253385, l6: 0.470482\n",
      "\n",
      "[epoch: 336/400, batch: 888/1000, ite: 44862] train loss: 1.1869, accuracy: 92.7749%, tar: 0.0269 \n",
      "l0: 0.021572, l1: 0.022520, l2: 0.028853, l3: 0.043858, l4: 0.081637, l5: 0.180003, l6: 0.342862\n",
      "\n",
      "[epoch: 336/400, batch: 896/1000, ite: 44863] train loss: 1.1868, accuracy: 94.8455%, tar: 0.0269 \n",
      "l0: 0.036222, l1: 0.036074, l2: 0.046444, l3: 0.067684, l4: 0.120632, l5: 0.258850, l6: 0.544085\n",
      "\n",
      "[epoch: 336/400, batch: 904/1000, ite: 44864] train loss: 1.1873, accuracy: 93.0146%, tar: 0.0269 \n",
      "l0: 0.022123, l1: 0.022846, l2: 0.030038, l3: 0.048462, l4: 0.092728, l5: 0.198350, l6: 0.439909\n",
      "\n",
      "[epoch: 336/400, batch: 912/1000, ite: 44865] train loss: 1.1874, accuracy: 94.7231%, tar: 0.0269 \n",
      "l0: 0.024881, l1: 0.026372, l2: 0.034733, l3: 0.050258, l4: 0.081671, l5: 0.147968, l6: 0.375246\n",
      "\n",
      "[epoch: 336/400, batch: 920/1000, ite: 44866] train loss: 1.1873, accuracy: 95.0579%, tar: 0.0269 \n",
      "l0: 0.028745, l1: 0.030537, l2: 0.038806, l3: 0.056293, l4: 0.111984, l5: 0.245710, l6: 0.495217\n",
      "\n",
      "[epoch: 336/400, batch: 928/1000, ite: 44867] train loss: 1.1877, accuracy: 93.6799%, tar: 0.0269 \n",
      "l0: 0.026055, l1: 0.026955, l2: 0.033787, l3: 0.046042, l4: 0.080265, l5: 0.151181, l6: 0.355307\n",
      "\n",
      "[epoch: 336/400, batch: 936/1000, ite: 44868] train loss: 1.1876, accuracy: 94.4757%, tar: 0.0269 \n",
      "l0: 0.021526, l1: 0.023219, l2: 0.031216, l3: 0.051470, l4: 0.111187, l5: 0.179711, l6: 0.317198\n",
      "\n",
      "[epoch: 336/400, batch: 944/1000, ite: 44869] train loss: 1.1874, accuracy: 95.5210%, tar: 0.0269 \n",
      "l0: 0.023553, l1: 0.024640, l2: 0.030371, l3: 0.041155, l4: 0.072232, l5: 0.142718, l6: 0.263109\n",
      "\n",
      "[epoch: 336/400, batch: 952/1000, ite: 44870] train loss: 1.1871, accuracy: 95.5015%, tar: 0.0269 \n",
      "l0: 0.023483, l1: 0.024926, l2: 0.033725, l3: 0.050427, l4: 0.108670, l5: 0.196409, l6: 0.361428\n",
      "\n",
      "[epoch: 336/400, batch: 960/1000, ite: 44871] train loss: 1.1870, accuracy: 94.8036%, tar: 0.0269 \n",
      "l0: 0.027645, l1: 0.029529, l2: 0.038382, l3: 0.062337, l4: 0.118994, l5: 0.242171, l6: 0.407851\n",
      "\n",
      "[epoch: 336/400, batch: 968/1000, ite: 44872] train loss: 1.1872, accuracy: 94.5585%, tar: 0.0269 \n",
      "l0: 0.027758, l1: 0.029232, l2: 0.037879, l3: 0.053266, l4: 0.092503, l5: 0.199362, l6: 0.379100\n",
      "\n",
      "[epoch: 336/400, batch: 976/1000, ite: 44873] train loss: 1.1872, accuracy: 94.8164%, tar: 0.0269 \n",
      "l0: 0.028067, l1: 0.029138, l2: 0.039327, l3: 0.055272, l4: 0.090711, l5: 0.147018, l6: 0.374993\n",
      "\n",
      "[epoch: 336/400, batch: 984/1000, ite: 44874] train loss: 1.1872, accuracy: 95.1469%, tar: 0.0269 \n",
      "l0: 0.024361, l1: 0.025468, l2: 0.031536, l3: 0.044496, l4: 0.073148, l5: 0.149420, l6: 0.264286\n",
      "\n",
      "[epoch: 336/400, batch: 992/1000, ite: 44875] train loss: 1.1868, accuracy: 95.4884%, tar: 0.0269 \n",
      "l0: 0.034003, l1: 0.035058, l2: 0.045030, l3: 0.066623, l4: 0.124173, l5: 0.252622, l6: 0.536487\n",
      "\n",
      "[epoch: 336/400, batch: 1000/1000, ite: 44876] train loss: 1.1873, accuracy: 92.5010%, tar: 0.0269 \n",
      "l0: 0.020682, l1: 0.021366, l2: 0.027946, l3: 0.042231, l4: 0.067683, l5: 0.120943, l6: 0.276600\n",
      "\n",
      "[epoch: 337/400, batch: 8/1000, ite: 44877] train loss: 1.1870, accuracy: 95.6447%, tar: 0.0269 \n",
      "l0: 0.027930, l1: 0.029337, l2: 0.039182, l3: 0.062151, l4: 0.113046, l5: 0.214466, l6: 0.456506\n",
      "\n",
      "[epoch: 337/400, batch: 16/1000, ite: 44878] train loss: 1.1872, accuracy: 94.3657%, tar: 0.0269 \n",
      "l0: 0.022809, l1: 0.023967, l2: 0.032371, l3: 0.049453, l4: 0.090343, l5: 0.187574, l6: 0.363402\n",
      "\n",
      "[epoch: 337/400, batch: 24/1000, ite: 44879] train loss: 1.1872, accuracy: 95.3501%, tar: 0.0269 \n",
      "l0: 0.030467, l1: 0.032132, l2: 0.041226, l3: 0.057798, l4: 0.093958, l5: 0.212577, l6: 0.442383\n",
      "\n",
      "[epoch: 337/400, batch: 32/1000, ite: 44880] train loss: 1.1873, accuracy: 93.6468%, tar: 0.0269 \n",
      "l0: 0.027884, l1: 0.028912, l2: 0.037482, l3: 0.052337, l4: 0.091168, l5: 0.174153, l6: 0.350874\n",
      "\n",
      "[epoch: 337/400, batch: 40/1000, ite: 44881] train loss: 1.1873, accuracy: 95.4528%, tar: 0.0269 \n",
      "l0: 0.016784, l1: 0.018080, l2: 0.026329, l3: 0.039338, l4: 0.068462, l5: 0.133067, l6: 0.282031\n",
      "\n",
      "[epoch: 337/400, batch: 48/1000, ite: 44882] train loss: 1.1869, accuracy: 96.4779%, tar: 0.0269 \n",
      "l0: 0.032379, l1: 0.034114, l2: 0.044427, l3: 0.075599, l4: 0.146320, l5: 0.317393, l6: 0.621974\n",
      "\n",
      "[epoch: 337/400, batch: 56/1000, ite: 44883] train loss: 1.1877, accuracy: 91.8649%, tar: 0.0269 \n",
      "l0: 0.023763, l1: 0.023994, l2: 0.029062, l3: 0.038548, l4: 0.063291, l5: 0.111458, l6: 0.253874\n",
      "\n",
      "[epoch: 337/400, batch: 64/1000, ite: 44884] train loss: 1.1873, accuracy: 95.8979%, tar: 0.0269 \n",
      "l0: 0.023050, l1: 0.023916, l2: 0.030391, l3: 0.042760, l4: 0.069693, l5: 0.133236, l6: 0.291579\n",
      "\n",
      "[epoch: 337/400, batch: 72/1000, ite: 44885] train loss: 1.1870, accuracy: 95.6456%, tar: 0.0269 \n",
      "l0: 0.027904, l1: 0.029762, l2: 0.041193, l3: 0.061753, l4: 0.130955, l5: 0.316858, l6: 0.562157\n",
      "\n",
      "[epoch: 337/400, batch: 80/1000, ite: 44886] train loss: 1.1876, accuracy: 92.9354%, tar: 0.0269 \n",
      "l0: 0.024971, l1: 0.026039, l2: 0.033271, l3: 0.047864, l4: 0.078160, l5: 0.170338, l6: 0.406753\n",
      "\n",
      "[epoch: 337/400, batch: 88/1000, ite: 44887] train loss: 1.1876, accuracy: 94.9700%, tar: 0.0269 \n",
      "l0: 0.020783, l1: 0.021281, l2: 0.027681, l3: 0.039348, l4: 0.070802, l5: 0.133340, l6: 0.337137\n",
      "\n",
      "[epoch: 337/400, batch: 96/1000, ite: 44888] train loss: 1.1874, accuracy: 95.2593%, tar: 0.0268 \n",
      "l0: 0.027623, l1: 0.029831, l2: 0.039470, l3: 0.063734, l4: 0.129278, l5: 0.268464, l6: 0.529184\n",
      "\n",
      "[epoch: 337/400, batch: 104/1000, ite: 44889] train loss: 1.1879, accuracy: 94.5402%, tar: 0.0268 \n",
      "l0: 0.026116, l1: 0.028050, l2: 0.036516, l3: 0.054208, l4: 0.103069, l5: 0.200773, l6: 0.346122\n",
      "\n",
      "[epoch: 337/400, batch: 112/1000, ite: 44890] train loss: 1.1878, accuracy: 95.0065%, tar: 0.0268 \n",
      "l0: 0.030427, l1: 0.032446, l2: 0.043520, l3: 0.073025, l4: 0.138529, l5: 0.245867, l6: 0.487455\n",
      "\n",
      "[epoch: 337/400, batch: 120/1000, ite: 44891] train loss: 1.1882, accuracy: 94.0795%, tar: 0.0269 \n",
      "l0: 0.026442, l1: 0.028040, l2: 0.037028, l3: 0.056182, l4: 0.104099, l5: 0.199964, l6: 0.419758\n",
      "\n",
      "[epoch: 337/400, batch: 128/1000, ite: 44892] train loss: 1.1883, accuracy: 93.5962%, tar: 0.0269 \n",
      "l0: 0.022507, l1: 0.023863, l2: 0.031412, l3: 0.046512, l4: 0.079806, l5: 0.157558, l6: 0.323289\n",
      "\n",
      "[epoch: 337/400, batch: 136/1000, ite: 44893] train loss: 1.1881, accuracy: 95.5909%, tar: 0.0268 \n",
      "l0: 0.028317, l1: 0.030462, l2: 0.040759, l3: 0.061852, l4: 0.122507, l5: 0.271168, l6: 0.515455\n",
      "\n",
      "[epoch: 337/400, batch: 144/1000, ite: 44894] train loss: 1.1886, accuracy: 94.4489%, tar: 0.0268 \n",
      "l0: 0.026976, l1: 0.028008, l2: 0.035704, l3: 0.053093, l4: 0.099225, l5: 0.197115, l6: 0.407124\n",
      "\n",
      "[epoch: 337/400, batch: 152/1000, ite: 44895] train loss: 1.1887, accuracy: 94.3583%, tar: 0.0268 \n",
      "l0: 0.025093, l1: 0.027231, l2: 0.035891, l3: 0.053054, l4: 0.101515, l5: 0.184382, l6: 0.396433\n",
      "\n",
      "[epoch: 337/400, batch: 160/1000, ite: 44896] train loss: 1.1887, accuracy: 94.9467%, tar: 0.0268 \n",
      "l0: 0.022149, l1: 0.023277, l2: 0.030724, l3: 0.041939, l4: 0.073343, l5: 0.138021, l6: 0.248372\n",
      "\n",
      "[epoch: 337/400, batch: 168/1000, ite: 44897] train loss: 1.1883, accuracy: 95.5490%, tar: 0.0268 \n",
      "l0: 0.024035, l1: 0.025491, l2: 0.033468, l3: 0.045103, l4: 0.077880, l5: 0.189868, l6: 0.376989\n",
      "\n",
      "[epoch: 337/400, batch: 176/1000, ite: 44898] train loss: 1.1883, accuracy: 94.2662%, tar: 0.0268 \n",
      "l0: 0.023254, l1: 0.024273, l2: 0.030765, l3: 0.042387, l4: 0.068357, l5: 0.127604, l6: 0.290329\n",
      "\n",
      "[epoch: 337/400, batch: 184/1000, ite: 44899] train loss: 1.1879, accuracy: 95.6569%, tar: 0.0268 \n",
      "l0: 0.019990, l1: 0.020767, l2: 0.026137, l3: 0.035156, l4: 0.057393, l5: 0.109548, l6: 0.226245\n",
      "\n",
      "[epoch: 337/400, batch: 192/1000, ite: 44900] train loss: 1.1874, accuracy: 96.4152%, tar: 0.0268 \n",
      "l0: 0.023485, l1: 0.024525, l2: 0.033752, l3: 0.052748, l4: 0.105491, l5: 0.239293, l6: 0.386063\n",
      "\n",
      "[epoch: 337/400, batch: 200/1000, ite: 44901] train loss: 1.1875, accuracy: 93.5831%, tar: 0.0268 \n",
      "l0: 0.024282, l1: 0.025557, l2: 0.031761, l3: 0.043856, l4: 0.083048, l5: 0.175714, l6: 0.323297\n",
      "\n",
      "[epoch: 337/400, batch: 208/1000, ite: 44902] train loss: 1.1873, accuracy: 95.5005%, tar: 0.0268 \n",
      "l0: 0.022115, l1: 0.022861, l2: 0.029501, l3: 0.043261, l4: 0.084733, l5: 0.155016, l6: 0.316308\n",
      "\n",
      "[epoch: 337/400, batch: 216/1000, ite: 44903] train loss: 1.1871, accuracy: 95.0317%, tar: 0.0268 \n",
      "l0: 0.020631, l1: 0.022380, l2: 0.028852, l3: 0.040433, l4: 0.074434, l5: 0.177534, l6: 0.324706\n",
      "\n",
      "[epoch: 337/400, batch: 224/1000, ite: 44904] train loss: 1.1870, accuracy: 95.6473%, tar: 0.0268 \n",
      "l0: 0.022990, l1: 0.024297, l2: 0.031362, l3: 0.048883, l4: 0.083502, l5: 0.159998, l6: 0.348664\n",
      "\n",
      "[epoch: 337/400, batch: 232/1000, ite: 44905] train loss: 1.1868, accuracy: 95.0951%, tar: 0.0268 \n",
      "l0: 0.034056, l1: 0.035443, l2: 0.044633, l3: 0.065660, l4: 0.120837, l5: 0.229203, l6: 0.478303\n",
      "\n",
      "[epoch: 337/400, batch: 240/1000, ite: 44906] train loss: 1.1872, accuracy: 93.3949%, tar: 0.0268 \n",
      "l0: 0.020256, l1: 0.021286, l2: 0.027641, l3: 0.039276, l4: 0.071603, l5: 0.147837, l6: 0.314951\n",
      "\n",
      "[epoch: 337/400, batch: 248/1000, ite: 44907] train loss: 1.1869, accuracy: 96.0545%, tar: 0.0268 \n",
      "l0: 0.023756, l1: 0.024594, l2: 0.033894, l3: 0.050051, l4: 0.085142, l5: 0.176389, l6: 0.431265\n",
      "\n",
      "[epoch: 337/400, batch: 256/1000, ite: 44908] train loss: 1.1870, accuracy: 94.3831%, tar: 0.0268 \n",
      "l0: 0.024073, l1: 0.025061, l2: 0.031667, l3: 0.044674, l4: 0.076067, l5: 0.162545, l6: 0.388140\n",
      "\n",
      "[epoch: 337/400, batch: 264/1000, ite: 44909] train loss: 1.1869, accuracy: 94.1980%, tar: 0.0268 \n",
      "l0: 0.028098, l1: 0.029595, l2: 0.039470, l3: 0.054957, l4: 0.092570, l5: 0.177768, l6: 0.357914\n",
      "\n",
      "[epoch: 337/400, batch: 272/1000, ite: 44910] train loss: 1.1869, accuracy: 94.5775%, tar: 0.0268 \n",
      "l0: 0.024484, l1: 0.025668, l2: 0.033797, l3: 0.051429, l4: 0.091695, l5: 0.211786, l6: 0.369287\n",
      "\n",
      "[epoch: 337/400, batch: 280/1000, ite: 44911] train loss: 1.1869, accuracy: 95.0797%, tar: 0.0268 \n",
      "l0: 0.027948, l1: 0.029395, l2: 0.037791, l3: 0.057191, l4: 0.114390, l5: 0.233917, l6: 0.440629\n",
      "\n",
      "[epoch: 337/400, batch: 288/1000, ite: 44912] train loss: 1.1871, accuracy: 94.1115%, tar: 0.0268 \n",
      "l0: 0.020428, l1: 0.021471, l2: 0.028677, l3: 0.041224, l4: 0.073985, l5: 0.165929, l6: 0.353769\n",
      "\n",
      "[epoch: 337/400, batch: 296/1000, ite: 44913] train loss: 1.1870, accuracy: 94.9115%, tar: 0.0268 \n",
      "l0: 0.019789, l1: 0.022103, l2: 0.031444, l3: 0.049389, l4: 0.085816, l5: 0.166152, l6: 0.353320\n",
      "\n",
      "[epoch: 337/400, batch: 304/1000, ite: 44914] train loss: 1.1869, accuracy: 95.9771%, tar: 0.0268 \n",
      "l0: 0.032376, l1: 0.033822, l2: 0.042363, l3: 0.057451, l4: 0.095777, l5: 0.199462, l6: 0.424526\n",
      "\n",
      "[epoch: 337/400, batch: 312/1000, ite: 44915] train loss: 1.1870, accuracy: 93.1971%, tar: 0.0268 \n",
      "l0: 0.030770, l1: 0.032156, l2: 0.039476, l3: 0.058314, l4: 0.113663, l5: 0.229745, l6: 0.440641\n",
      "\n",
      "[epoch: 337/400, batch: 320/1000, ite: 44916] train loss: 1.1872, accuracy: 93.9782%, tar: 0.0268 \n",
      "l0: 0.030880, l1: 0.033156, l2: 0.043549, l3: 0.068437, l4: 0.139771, l5: 0.323680, l6: 0.519549\n",
      "\n",
      "[epoch: 337/400, batch: 328/1000, ite: 44917] train loss: 1.1878, accuracy: 92.8890%, tar: 0.0268 \n",
      "l0: 0.022808, l1: 0.024671, l2: 0.032715, l3: 0.049066, l4: 0.100623, l5: 0.170472, l6: 0.321368\n",
      "\n",
      "[epoch: 337/400, batch: 336/1000, ite: 44918] train loss: 1.1876, accuracy: 95.9337%, tar: 0.0268 \n",
      "l0: 0.023149, l1: 0.023959, l2: 0.031116, l3: 0.041815, l4: 0.066359, l5: 0.122378, l6: 0.255304\n",
      "\n",
      "[epoch: 337/400, batch: 344/1000, ite: 44919] train loss: 1.1872, accuracy: 95.7363%, tar: 0.0268 \n",
      "l0: 0.031055, l1: 0.032717, l2: 0.041574, l3: 0.061056, l4: 0.110748, l5: 0.225927, l6: 0.516197\n",
      "\n",
      "[epoch: 337/400, batch: 352/1000, ite: 44920] train loss: 1.1876, accuracy: 93.4595%, tar: 0.0268 \n",
      "l0: 0.021388, l1: 0.022457, l2: 0.027699, l3: 0.038565, l4: 0.078296, l5: 0.173938, l6: 0.358646\n",
      "\n",
      "[epoch: 337/400, batch: 360/1000, ite: 44921] train loss: 1.1875, accuracy: 95.3886%, tar: 0.0268 \n",
      "l0: 0.021692, l1: 0.022526, l2: 0.030972, l3: 0.044617, l4: 0.084799, l5: 0.185779, l6: 0.324795\n",
      "\n",
      "[epoch: 337/400, batch: 368/1000, ite: 44922] train loss: 1.1873, accuracy: 95.3111%, tar: 0.0268 \n",
      "l0: 0.033069, l1: 0.033699, l2: 0.042025, l3: 0.055396, l4: 0.090942, l5: 0.170992, l6: 0.439151\n",
      "\n",
      "[epoch: 337/400, batch: 376/1000, ite: 44923] train loss: 1.1875, accuracy: 93.8447%, tar: 0.0268 \n",
      "l0: 0.025078, l1: 0.026736, l2: 0.033131, l3: 0.047854, l4: 0.091452, l5: 0.194996, l6: 0.415842\n",
      "\n",
      "[epoch: 337/400, batch: 384/1000, ite: 44924] train loss: 1.1875, accuracy: 94.7267%, tar: 0.0268 \n",
      "l0: 0.028371, l1: 0.029622, l2: 0.037087, l3: 0.048803, l4: 0.080703, l5: 0.180416, l6: 0.376650\n",
      "\n",
      "[epoch: 337/400, batch: 392/1000, ite: 44925] train loss: 1.1875, accuracy: 94.7041%, tar: 0.0268 \n",
      "l0: 0.021076, l1: 0.022496, l2: 0.027793, l3: 0.044415, l4: 0.085485, l5: 0.177785, l6: 0.319286\n",
      "\n",
      "[epoch: 337/400, batch: 400/1000, ite: 44926] train loss: 1.1873, accuracy: 95.4744%, tar: 0.0268 \n",
      "l0: 0.025963, l1: 0.027026, l2: 0.034363, l3: 0.046376, l4: 0.083848, l5: 0.175420, l6: 0.359715\n",
      "\n",
      "[epoch: 337/400, batch: 408/1000, ite: 44927] train loss: 1.1872, accuracy: 94.8533%, tar: 0.0268 \n",
      "l0: 0.022695, l1: 0.023623, l2: 0.029681, l3: 0.043464, l4: 0.071196, l5: 0.128657, l6: 0.299218\n",
      "\n",
      "[epoch: 337/400, batch: 416/1000, ite: 44928] train loss: 1.1870, accuracy: 95.6817%, tar: 0.0268 \n",
      "l0: 0.020403, l1: 0.021224, l2: 0.028599, l3: 0.038879, l4: 0.066876, l5: 0.127113, l6: 0.298685\n",
      "\n",
      "[epoch: 337/400, batch: 424/1000, ite: 44929] train loss: 1.1867, accuracy: 96.3431%, tar: 0.0268 \n",
      "l0: 0.022580, l1: 0.023602, l2: 0.031701, l3: 0.046230, l4: 0.084405, l5: 0.156828, l6: 0.312512\n",
      "\n",
      "[epoch: 337/400, batch: 432/1000, ite: 44930] train loss: 1.1865, accuracy: 95.3920%, tar: 0.0268 \n",
      "l0: 0.023955, l1: 0.025440, l2: 0.032532, l3: 0.046868, l4: 0.086348, l5: 0.162618, l6: 0.310487\n",
      "\n",
      "[epoch: 337/400, batch: 440/1000, ite: 44931] train loss: 1.1863, accuracy: 95.6613%, tar: 0.0268 \n",
      "l0: 0.030484, l1: 0.031737, l2: 0.040663, l3: 0.064383, l4: 0.111623, l5: 0.224161, l6: 0.495996\n",
      "\n",
      "[epoch: 337/400, batch: 448/1000, ite: 44932] train loss: 1.1866, accuracy: 92.3815%, tar: 0.0268 \n",
      "l0: 0.020834, l1: 0.022019, l2: 0.028006, l3: 0.039633, l4: 0.068269, l5: 0.134420, l6: 0.281454\n",
      "\n",
      "[epoch: 337/400, batch: 456/1000, ite: 44933] train loss: 1.1862, accuracy: 95.8429%, tar: 0.0268 \n",
      "l0: 0.024979, l1: 0.025908, l2: 0.033819, l3: 0.047583, l4: 0.074624, l5: 0.134287, l6: 0.264438\n",
      "\n",
      "[epoch: 337/400, batch: 464/1000, ite: 44934] train loss: 1.1859, accuracy: 95.6852%, tar: 0.0268 \n",
      "l0: 0.024636, l1: 0.025800, l2: 0.034643, l3: 0.050412, l4: 0.095527, l5: 0.173725, l6: 0.397460\n",
      "\n",
      "[epoch: 337/400, batch: 472/1000, ite: 44935] train loss: 1.1859, accuracy: 94.5161%, tar: 0.0268 \n",
      "l0: 0.029711, l1: 0.031376, l2: 0.039135, l3: 0.055894, l4: 0.099614, l5: 0.215425, l6: 0.393519\n",
      "\n",
      "[epoch: 337/400, batch: 480/1000, ite: 44936] train loss: 1.1860, accuracy: 94.5131%, tar: 0.0268 \n",
      "l0: 0.017654, l1: 0.019056, l2: 0.025289, l3: 0.037958, l4: 0.072231, l5: 0.128630, l6: 0.256077\n",
      "\n",
      "[epoch: 337/400, batch: 488/1000, ite: 44937] train loss: 1.1856, accuracy: 96.4955%, tar: 0.0268 \n",
      "l0: 0.020979, l1: 0.022103, l2: 0.029898, l3: 0.047859, l4: 0.089277, l5: 0.188718, l6: 0.370844\n",
      "\n",
      "[epoch: 337/400, batch: 496/1000, ite: 44938] train loss: 1.1856, accuracy: 95.1948%, tar: 0.0267 \n",
      "l0: 0.023855, l1: 0.025781, l2: 0.035132, l3: 0.051725, l4: 0.100498, l5: 0.200324, l6: 0.391482\n",
      "\n",
      "[epoch: 337/400, batch: 504/1000, ite: 44939] train loss: 1.1856, accuracy: 95.2655%, tar: 0.0267 \n",
      "l0: 0.021594, l1: 0.023362, l2: 0.031209, l3: 0.048749, l4: 0.079380, l5: 0.137689, l6: 0.288615\n",
      "\n",
      "[epoch: 337/400, batch: 512/1000, ite: 44940] train loss: 1.1853, accuracy: 96.3199%, tar: 0.0267 \n",
      "l0: 0.023795, l1: 0.024763, l2: 0.032079, l3: 0.044689, l4: 0.075968, l5: 0.139812, l6: 0.301964\n",
      "\n",
      "[epoch: 337/400, batch: 520/1000, ite: 44941] train loss: 1.1851, accuracy: 95.3147%, tar: 0.0267 \n",
      "l0: 0.033360, l1: 0.034694, l2: 0.044100, l3: 0.062489, l4: 0.110183, l5: 0.212562, l6: 0.466653\n",
      "\n",
      "[epoch: 337/400, batch: 528/1000, ite: 44942] train loss: 1.1854, accuracy: 93.3735%, tar: 0.0267 \n",
      "l0: 0.024325, l1: 0.024907, l2: 0.031334, l3: 0.045712, l4: 0.069838, l5: 0.129452, l6: 0.315260\n",
      "\n",
      "[epoch: 337/400, batch: 536/1000, ite: 44943] train loss: 1.1851, accuracy: 95.4111%, tar: 0.0267 \n",
      "l0: 0.025856, l1: 0.027579, l2: 0.040131, l3: 0.069760, l4: 0.138913, l5: 0.279370, l6: 0.562475\n",
      "\n",
      "[epoch: 337/400, batch: 544/1000, ite: 44944] train loss: 1.1857, accuracy: 94.0166%, tar: 0.0267 \n",
      "l0: 0.025299, l1: 0.026307, l2: 0.034872, l3: 0.051464, l4: 0.087895, l5: 0.161965, l6: 0.301923\n",
      "\n",
      "[epoch: 337/400, batch: 552/1000, ite: 44945] train loss: 1.1855, accuracy: 95.0276%, tar: 0.0267 \n",
      "l0: 0.023015, l1: 0.025231, l2: 0.035065, l3: 0.063395, l4: 0.133524, l5: 0.270585, l6: 0.436790\n",
      "\n",
      "[epoch: 337/400, batch: 560/1000, ite: 44946] train loss: 1.1857, accuracy: 94.9445%, tar: 0.0267 \n",
      "l0: 0.029102, l1: 0.030443, l2: 0.039267, l3: 0.059025, l4: 0.129502, l5: 0.236279, l6: 0.454682\n",
      "\n",
      "[epoch: 337/400, batch: 568/1000, ite: 44947] train loss: 1.1860, accuracy: 93.9712%, tar: 0.0267 \n",
      "l0: 0.023802, l1: 0.025696, l2: 0.034539, l3: 0.048932, l4: 0.080850, l5: 0.144311, l6: 0.275986\n",
      "\n",
      "[epoch: 337/400, batch: 576/1000, ite: 44948] train loss: 1.1857, accuracy: 96.1128%, tar: 0.0267 \n",
      "l0: 0.023905, l1: 0.024896, l2: 0.030910, l3: 0.042678, l4: 0.073984, l5: 0.139020, l6: 0.280028\n",
      "\n",
      "[epoch: 337/400, batch: 584/1000, ite: 44949] train loss: 1.1854, accuracy: 95.5962%, tar: 0.0267 \n",
      "l0: 0.020414, l1: 0.021382, l2: 0.027874, l3: 0.041850, l4: 0.075424, l5: 0.136663, l6: 0.258494\n",
      "\n",
      "[epoch: 337/400, batch: 592/1000, ite: 44950] train loss: 1.1851, accuracy: 96.1079%, tar: 0.0267 \n",
      "l0: 0.022820, l1: 0.023389, l2: 0.029662, l3: 0.041939, l4: 0.074280, l5: 0.137157, l6: 0.282595\n",
      "\n",
      "[epoch: 337/400, batch: 600/1000, ite: 44951] train loss: 1.1848, accuracy: 95.6287%, tar: 0.0267 \n",
      "l0: 0.020494, l1: 0.022016, l2: 0.027935, l3: 0.043969, l4: 0.085227, l5: 0.145781, l6: 0.301133\n",
      "\n",
      "[epoch: 337/400, batch: 608/1000, ite: 44952] train loss: 1.1845, accuracy: 95.4701%, tar: 0.0267 \n",
      "l0: 0.031060, l1: 0.031414, l2: 0.038511, l3: 0.052936, l4: 0.085534, l5: 0.159141, l6: 0.400713\n",
      "\n",
      "[epoch: 337/400, batch: 616/1000, ite: 44953] train loss: 1.1845, accuracy: 93.6860%, tar: 0.0267 \n",
      "l0: 0.028901, l1: 0.030770, l2: 0.038532, l3: 0.055358, l4: 0.106442, l5: 0.237742, l6: 0.447878\n",
      "\n",
      "[epoch: 337/400, batch: 624/1000, ite: 44954] train loss: 1.1847, accuracy: 94.5748%, tar: 0.0267 \n",
      "l0: 0.022884, l1: 0.024042, l2: 0.032461, l3: 0.047006, l4: 0.080294, l5: 0.150009, l6: 0.287834\n",
      "\n",
      "[epoch: 337/400, batch: 632/1000, ite: 44955] train loss: 1.1845, accuracy: 95.5177%, tar: 0.0267 \n",
      "l0: 0.017905, l1: 0.019421, l2: 0.025897, l3: 0.038072, l4: 0.072853, l5: 0.148356, l6: 0.310775\n",
      "\n",
      "[epoch: 337/400, batch: 640/1000, ite: 44956] train loss: 1.1842, accuracy: 96.0388%, tar: 0.0267 \n",
      "l0: 0.019003, l1: 0.019869, l2: 0.024663, l3: 0.036023, l4: 0.064735, l5: 0.136193, l6: 0.281733\n",
      "\n",
      "[epoch: 337/400, batch: 648/1000, ite: 44957] train loss: 1.1839, accuracy: 95.9667%, tar: 0.0267 \n",
      "l0: 0.031322, l1: 0.032532, l2: 0.043501, l3: 0.058506, l4: 0.106948, l5: 0.209066, l6: 0.429728\n",
      "\n",
      "[epoch: 337/400, batch: 656/1000, ite: 44958] train loss: 1.1841, accuracy: 93.9922%, tar: 0.0267 \n",
      "l0: 0.027599, l1: 0.029179, l2: 0.038985, l3: 0.056807, l4: 0.104029, l5: 0.216590, l6: 0.399183\n",
      "\n",
      "[epoch: 337/400, batch: 664/1000, ite: 44959] train loss: 1.1842, accuracy: 94.6448%, tar: 0.0267 \n",
      "l0: 0.032305, l1: 0.034471, l2: 0.044653, l3: 0.066815, l4: 0.121219, l5: 0.225828, l6: 0.443141\n",
      "\n",
      "[epoch: 337/400, batch: 672/1000, ite: 44960] train loss: 1.1844, accuracy: 93.9939%, tar: 0.0267 \n",
      "l0: 0.021573, l1: 0.023077, l2: 0.028962, l3: 0.042404, l4: 0.083108, l5: 0.179413, l6: 0.409445\n",
      "\n",
      "[epoch: 337/400, batch: 680/1000, ite: 44961] train loss: 1.1844, accuracy: 94.9392%, tar: 0.0267 \n",
      "l0: 0.025158, l1: 0.026738, l2: 0.035368, l3: 0.052414, l4: 0.096589, l5: 0.172217, l6: 0.315569\n",
      "\n",
      "[epoch: 337/400, batch: 688/1000, ite: 44962] train loss: 1.1843, accuracy: 95.7999%, tar: 0.0267 \n",
      "l0: 0.024021, l1: 0.024746, l2: 0.032464, l3: 0.047627, l4: 0.084709, l5: 0.153838, l6: 0.296078\n",
      "\n",
      "[epoch: 337/400, batch: 696/1000, ite: 44963] train loss: 1.1840, accuracy: 95.2726%, tar: 0.0267 \n",
      "l0: 0.022948, l1: 0.024170, l2: 0.031454, l3: 0.045034, l4: 0.081149, l5: 0.159622, l6: 0.379577\n",
      "\n",
      "[epoch: 337/400, batch: 704/1000, ite: 44964] train loss: 1.1840, accuracy: 95.2468%, tar: 0.0267 \n",
      "l0: 0.031650, l1: 0.032737, l2: 0.039893, l3: 0.055462, l4: 0.092565, l5: 0.216086, l6: 0.376914\n",
      "\n",
      "[epoch: 337/400, batch: 712/1000, ite: 44965] train loss: 1.1840, accuracy: 93.7369%, tar: 0.0267 \n",
      "l0: 0.029159, l1: 0.030552, l2: 0.037380, l3: 0.058298, l4: 0.121818, l5: 0.265117, l6: 0.484921\n",
      "\n",
      "[epoch: 337/400, batch: 720/1000, ite: 44966] train loss: 1.1844, accuracy: 93.7516%, tar: 0.0267 \n",
      "l0: 0.025415, l1: 0.026426, l2: 0.035219, l3: 0.052433, l4: 0.091787, l5: 0.178738, l6: 0.338337\n",
      "\n",
      "[epoch: 337/400, batch: 728/1000, ite: 44967] train loss: 1.1843, accuracy: 95.1030%, tar: 0.0267 \n",
      "l0: 0.028615, l1: 0.029959, l2: 0.039822, l3: 0.061385, l4: 0.123229, l5: 0.205923, l6: 0.420534\n",
      "\n",
      "[epoch: 337/400, batch: 736/1000, ite: 44968] train loss: 1.1844, accuracy: 94.1033%, tar: 0.0267 \n",
      "l0: 0.026213, l1: 0.027284, l2: 0.034358, l3: 0.050739, l4: 0.093463, l5: 0.185834, l6: 0.424472\n",
      "\n",
      "[epoch: 337/400, batch: 744/1000, ite: 44969] train loss: 1.1845, accuracy: 93.3399%, tar: 0.0267 \n",
      "l0: 0.022086, l1: 0.023215, l2: 0.031307, l3: 0.047020, l4: 0.085206, l5: 0.156125, l6: 0.307914\n",
      "\n",
      "[epoch: 337/400, batch: 752/1000, ite: 44970] train loss: 1.1843, accuracy: 95.2855%, tar: 0.0267 \n",
      "l0: 0.023189, l1: 0.023841, l2: 0.030143, l3: 0.042575, l4: 0.071815, l5: 0.128840, l6: 0.303887\n",
      "\n",
      "[epoch: 337/400, batch: 760/1000, ite: 44971] train loss: 1.1840, accuracy: 95.2809%, tar: 0.0267 \n",
      "l0: 0.030034, l1: 0.030921, l2: 0.040470, l3: 0.060138, l4: 0.104819, l5: 0.186009, l6: 0.368675\n",
      "\n",
      "[epoch: 337/400, batch: 768/1000, ite: 44972] train loss: 1.1841, accuracy: 94.3215%, tar: 0.0267 \n",
      "l0: 0.025512, l1: 0.026690, l2: 0.035107, l3: 0.051122, l4: 0.096228, l5: 0.196963, l6: 0.343687\n",
      "\n",
      "[epoch: 337/400, batch: 776/1000, ite: 44973] train loss: 1.1840, accuracy: 94.5487%, tar: 0.0267 \n",
      "l0: 0.025274, l1: 0.026413, l2: 0.033200, l3: 0.053239, l4: 0.136216, l5: 0.244486, l6: 0.617748\n",
      "\n",
      "[epoch: 337/400, batch: 784/1000, ite: 44974] train loss: 1.1846, accuracy: 92.9312%, tar: 0.0267 \n",
      "l0: 0.032519, l1: 0.033987, l2: 0.045066, l3: 0.065368, l4: 0.123352, l5: 0.256969, l6: 0.505108\n",
      "\n",
      "[epoch: 337/400, batch: 792/1000, ite: 44975] train loss: 1.1850, accuracy: 93.1714%, tar: 0.0267 \n",
      "l0: 0.026035, l1: 0.026960, l2: 0.033376, l3: 0.043719, l4: 0.076005, l5: 0.145044, l6: 0.404152\n",
      "\n",
      "[epoch: 337/400, batch: 800/1000, ite: 44976] train loss: 1.1850, accuracy: 94.1994%, tar: 0.0267 \n",
      "l0: 0.025429, l1: 0.026688, l2: 0.037818, l3: 0.061786, l4: 0.117822, l5: 0.216985, l6: 0.461592\n",
      "\n",
      "[epoch: 337/400, batch: 808/1000, ite: 44977] train loss: 1.1852, accuracy: 94.0401%, tar: 0.0267 \n",
      "l0: 0.026672, l1: 0.027956, l2: 0.036007, l3: 0.049187, l4: 0.088489, l5: 0.173936, l6: 0.317396\n",
      "\n",
      "[epoch: 337/400, batch: 816/1000, ite: 44978] train loss: 1.1851, accuracy: 94.9894%, tar: 0.0267 \n",
      "l0: 0.034555, l1: 0.036086, l2: 0.045724, l3: 0.065149, l4: 0.144410, l5: 0.286334, l6: 0.585578\n",
      "\n",
      "[epoch: 337/400, batch: 824/1000, ite: 44979] train loss: 1.1857, accuracy: 92.1553%, tar: 0.0267 \n",
      "l0: 0.018158, l1: 0.019340, l2: 0.025333, l3: 0.036112, l4: 0.062218, l5: 0.136318, l6: 0.281596\n",
      "\n",
      "[epoch: 337/400, batch: 832/1000, ite: 44980] train loss: 1.1853, accuracy: 96.4793%, tar: 0.0267 \n",
      "l0: 0.023907, l1: 0.025070, l2: 0.030953, l3: 0.044673, l4: 0.077037, l5: 0.154657, l6: 0.377581\n",
      "\n",
      "[epoch: 337/400, batch: 840/1000, ite: 44981] train loss: 1.1853, accuracy: 94.3861%, tar: 0.0267 \n",
      "l0: 0.017813, l1: 0.018966, l2: 0.025577, l3: 0.039772, l4: 0.088644, l5: 0.181521, l6: 0.329819\n",
      "\n",
      "[epoch: 337/400, batch: 848/1000, ite: 44982] train loss: 1.1851, accuracy: 95.5231%, tar: 0.0267 \n",
      "l0: 0.017989, l1: 0.019250, l2: 0.026737, l3: 0.041201, l4: 0.087132, l5: 0.178891, l6: 0.286813\n",
      "\n",
      "[epoch: 337/400, batch: 856/1000, ite: 44983] train loss: 1.1849, accuracy: 96.3669%, tar: 0.0267 \n",
      "l0: 0.025008, l1: 0.025808, l2: 0.032827, l3: 0.046594, l4: 0.078391, l5: 0.142302, l6: 0.278386\n",
      "\n",
      "[epoch: 337/400, batch: 864/1000, ite: 44984] train loss: 1.1846, accuracy: 95.2556%, tar: 0.0267 \n",
      "l0: 0.027503, l1: 0.028263, l2: 0.035417, l3: 0.052555, l4: 0.090766, l5: 0.165936, l6: 0.323311\n",
      "\n",
      "[epoch: 337/400, batch: 872/1000, ite: 44985] train loss: 1.1845, accuracy: 94.9853%, tar: 0.0267 \n",
      "l0: 0.027275, l1: 0.028140, l2: 0.035745, l3: 0.049471, l4: 0.083382, l5: 0.209013, l6: 0.422375\n",
      "\n",
      "[epoch: 337/400, batch: 880/1000, ite: 44986] train loss: 1.1846, accuracy: 93.9925%, tar: 0.0267 \n",
      "l0: 0.023330, l1: 0.024501, l2: 0.032321, l3: 0.047102, l4: 0.082138, l5: 0.164544, l6: 0.312763\n",
      "\n",
      "[epoch: 337/400, batch: 888/1000, ite: 44987] train loss: 1.1844, accuracy: 95.0377%, tar: 0.0267 \n",
      "l0: 0.025251, l1: 0.026629, l2: 0.034770, l3: 0.054582, l4: 0.096768, l5: 0.194345, l6: 0.414316\n",
      "\n",
      "[epoch: 337/400, batch: 896/1000, ite: 44988] train loss: 1.1845, accuracy: 94.8020%, tar: 0.0267 \n",
      "l0: 0.024591, l1: 0.026089, l2: 0.035262, l3: 0.060289, l4: 0.114003, l5: 0.208771, l6: 0.383071\n",
      "\n",
      "[epoch: 337/400, batch: 904/1000, ite: 44989] train loss: 1.1845, accuracy: 94.7115%, tar: 0.0267 \n",
      "l0: 0.026459, l1: 0.027426, l2: 0.038250, l3: 0.055260, l4: 0.088852, l5: 0.157173, l6: 0.331188\n",
      "\n",
      "[epoch: 337/400, batch: 912/1000, ite: 44990] train loss: 1.1844, accuracy: 94.7578%, tar: 0.0267 \n",
      "l0: 0.031871, l1: 0.033682, l2: 0.041847, l3: 0.061059, l4: 0.113024, l5: 0.207583, l6: 0.395507\n",
      "\n",
      "[epoch: 337/400, batch: 920/1000, ite: 44991] train loss: 1.1845, accuracy: 94.2244%, tar: 0.0267 \n",
      "l0: 0.027507, l1: 0.029251, l2: 0.037355, l3: 0.053715, l4: 0.105575, l5: 0.225583, l6: 0.497315\n",
      "\n",
      "[epoch: 337/400, batch: 928/1000, ite: 44992] train loss: 1.1848, accuracy: 94.2287%, tar: 0.0267 \n",
      "l0: 0.022715, l1: 0.023792, l2: 0.030987, l3: 0.046013, l4: 0.087220, l5: 0.194122, l6: 0.448421\n",
      "\n",
      "[epoch: 337/400, batch: 936/1000, ite: 44993] train loss: 1.1849, accuracy: 94.1648%, tar: 0.0267 \n",
      "l0: 0.021676, l1: 0.022687, l2: 0.030468, l3: 0.042972, l4: 0.075824, l5: 0.136625, l6: 0.277299\n",
      "\n",
      "[epoch: 337/400, batch: 944/1000, ite: 44994] train loss: 1.1846, accuracy: 96.0856%, tar: 0.0267 \n",
      "l0: 0.024526, l1: 0.025903, l2: 0.032681, l3: 0.049218, l4: 0.090864, l5: 0.170759, l6: 0.335390\n",
      "\n",
      "[epoch: 337/400, batch: 952/1000, ite: 44995] train loss: 1.1845, accuracy: 95.0537%, tar: 0.0267 \n",
      "l0: 0.024311, l1: 0.025839, l2: 0.035301, l3: 0.057114, l4: 0.105790, l5: 0.247558, l6: 0.432389\n",
      "\n",
      "[epoch: 337/400, batch: 960/1000, ite: 44996] train loss: 1.1847, accuracy: 94.6567%, tar: 0.0267 \n",
      "l0: 0.027969, l1: 0.029083, l2: 0.037352, l3: 0.054749, l4: 0.101590, l5: 0.191593, l6: 0.440659\n",
      "\n",
      "[epoch: 337/400, batch: 968/1000, ite: 44997] train loss: 1.1848, accuracy: 93.8301%, tar: 0.0267 \n",
      "l0: 0.020979, l1: 0.021772, l2: 0.027783, l3: 0.040049, l4: 0.072607, l5: 0.168319, l6: 0.342278\n",
      "\n",
      "[epoch: 337/400, batch: 976/1000, ite: 44998] train loss: 1.1847, accuracy: 94.6707%, tar: 0.0267 \n",
      "l0: 0.021920, l1: 0.023413, l2: 0.031977, l3: 0.046088, l4: 0.082132, l5: 0.185197, l6: 0.387598\n",
      "\n",
      "[epoch: 337/400, batch: 984/1000, ite: 44999] train loss: 1.1847, accuracy: 95.6155%, tar: 0.0267 \n",
      "l0: 0.028518, l1: 0.030139, l2: 0.038675, l3: 0.058172, l4: 0.098751, l5: 0.176037, l6: 0.305759\n",
      "\n",
      "[epoch: 337/400, batch: 992/1000, ite: 45000] train loss: 1.1845, accuracy: 95.4637%, tar: 0.0267 \n",
      "l0: 0.025326, l1: 0.028595, l2: 0.041775, l3: 0.067752, l4: 0.129297, l5: 0.221894, l6: 0.400356\n",
      "\n",
      "[epoch: 337/400, batch: 1000/1000, ite: 45001] train loss: 1.1847, accuracy: 95.1877%, tar: 0.0267 \n",
      "l0: 0.031351, l1: 0.033067, l2: 0.045057, l3: 0.065224, l4: 0.110834, l5: 0.232657, l6: 0.409440\n",
      "\n",
      "[epoch: 338/400, batch: 8/1000, ite: 45002] train loss: 1.1848, accuracy: 93.3519%, tar: 0.0267 \n",
      "l0: 0.021617, l1: 0.023485, l2: 0.031692, l3: 0.048669, l4: 0.082308, l5: 0.167514, l6: 0.428131\n",
      "\n",
      "[epoch: 338/400, batch: 16/1000, ite: 45003] train loss: 1.1849, accuracy: 95.2950%, tar: 0.0267 \n",
      "l0: 0.024968, l1: 0.025918, l2: 0.032338, l3: 0.045541, l4: 0.083536, l5: 0.179573, l6: 0.356418\n",
      "\n",
      "[epoch: 338/400, batch: 24/1000, ite: 45004] train loss: 1.1848, accuracy: 94.4632%, tar: 0.0267 \n",
      "l0: 0.019711, l1: 0.020516, l2: 0.027432, l3: 0.038780, l4: 0.064855, l5: 0.121366, l6: 0.272090\n",
      "\n",
      "[epoch: 338/400, batch: 32/1000, ite: 45005] train loss: 1.1845, accuracy: 96.0502%, tar: 0.0266 \n",
      "l0: 0.026339, l1: 0.027674, l2: 0.034556, l3: 0.044868, l4: 0.067051, l5: 0.146279, l6: 0.303834\n",
      "\n",
      "[epoch: 338/400, batch: 40/1000, ite: 45006] train loss: 1.1843, accuracy: 95.2954%, tar: 0.0266 \n",
      "l0: 0.023292, l1: 0.024117, l2: 0.031331, l3: 0.046226, l4: 0.085204, l5: 0.193672, l6: 0.415067\n",
      "\n",
      "[epoch: 338/400, batch: 48/1000, ite: 45007] train loss: 1.1843, accuracy: 94.3537%, tar: 0.0266 \n",
      "l0: 0.015810, l1: 0.016495, l2: 0.021366, l3: 0.032694, l4: 0.059643, l5: 0.114430, l6: 0.230525\n",
      "\n",
      "[epoch: 338/400, batch: 56/1000, ite: 45008] train loss: 1.1839, accuracy: 96.3363%, tar: 0.0266 \n",
      "l0: 0.031892, l1: 0.033367, l2: 0.042005, l3: 0.060395, l4: 0.111821, l5: 0.203481, l6: 0.373651\n",
      "\n",
      "[epoch: 338/400, batch: 64/1000, ite: 45009] train loss: 1.1839, accuracy: 94.7430%, tar: 0.0266 \n",
      "l0: 0.027566, l1: 0.029520, l2: 0.041405, l3: 0.066511, l4: 0.118553, l5: 0.247353, l6: 0.458893\n",
      "\n",
      "[epoch: 338/400, batch: 72/1000, ite: 45010] train loss: 1.1842, accuracy: 94.4832%, tar: 0.0266 \n",
      "l0: 0.017947, l1: 0.018959, l2: 0.025461, l3: 0.039883, l4: 0.071103, l5: 0.137486, l6: 0.306133\n",
      "\n",
      "[epoch: 338/400, batch: 80/1000, ite: 45011] train loss: 1.1839, accuracy: 95.4628%, tar: 0.0266 \n",
      "l0: 0.018412, l1: 0.019799, l2: 0.025887, l3: 0.037114, l4: 0.067328, l5: 0.141152, l6: 0.435710\n",
      "\n",
      "[epoch: 338/400, batch: 88/1000, ite: 45012] train loss: 1.1839, accuracy: 95.2839%, tar: 0.0266 \n",
      "l0: 0.020803, l1: 0.022681, l2: 0.030568, l3: 0.047854, l4: 0.093709, l5: 0.236508, l6: 0.495693\n",
      "\n",
      "[epoch: 338/400, batch: 96/1000, ite: 45013] train loss: 1.1842, accuracy: 94.4569%, tar: 0.0266 \n",
      "l0: 0.020545, l1: 0.022108, l2: 0.029655, l3: 0.046590, l4: 0.088358, l5: 0.176890, l6: 0.340659\n",
      "\n",
      "[epoch: 338/400, batch: 104/1000, ite: 45014] train loss: 1.1841, accuracy: 96.1386%, tar: 0.0266 \n",
      "l0: 0.028671, l1: 0.030320, l2: 0.041081, l3: 0.066005, l4: 0.138857, l5: 0.288389, l6: 0.589994\n",
      "\n",
      "[epoch: 338/400, batch: 112/1000, ite: 45015] train loss: 1.1846, accuracy: 92.5688%, tar: 0.0266 \n",
      "l0: 0.026249, l1: 0.027240, l2: 0.035179, l3: 0.048687, l4: 0.082400, l5: 0.146412, l6: 0.316984\n",
      "\n",
      "[epoch: 338/400, batch: 120/1000, ite: 45016] train loss: 1.1845, accuracy: 95.1909%, tar: 0.0266 \n",
      "l0: 0.022625, l1: 0.024094, l2: 0.033842, l3: 0.053824, l4: 0.097503, l5: 0.189761, l6: 0.371923\n",
      "\n",
      "[epoch: 338/400, batch: 128/1000, ite: 45017] train loss: 1.1845, accuracy: 94.9476%, tar: 0.0266 \n",
      "l0: 0.022939, l1: 0.023561, l2: 0.030691, l3: 0.045315, l4: 0.083404, l5: 0.182419, l6: 0.387500\n",
      "\n",
      "[epoch: 338/400, batch: 136/1000, ite: 45018] train loss: 1.1844, accuracy: 94.1783%, tar: 0.0266 \n",
      "l0: 0.023821, l1: 0.024880, l2: 0.030847, l3: 0.046335, l4: 0.093320, l5: 0.156396, l6: 0.297327\n",
      "\n",
      "[epoch: 338/400, batch: 144/1000, ite: 45019] train loss: 1.1842, accuracy: 95.8171%, tar: 0.0266 \n",
      "l0: 0.022182, l1: 0.023052, l2: 0.029879, l3: 0.044140, l4: 0.082983, l5: 0.182281, l6: 0.375317\n",
      "\n",
      "[epoch: 338/400, batch: 152/1000, ite: 45020] train loss: 1.1842, accuracy: 95.4412%, tar: 0.0266 \n",
      "l0: 0.020329, l1: 0.022295, l2: 0.031425, l3: 0.049295, l4: 0.084183, l5: 0.142586, l6: 0.273804\n",
      "\n",
      "[epoch: 338/400, batch: 160/1000, ite: 45021] train loss: 1.1839, accuracy: 96.4692%, tar: 0.0266 \n",
      "l0: 0.028104, l1: 0.029492, l2: 0.038114, l3: 0.053000, l4: 0.092447, l5: 0.188643, l6: 0.363229\n",
      "\n",
      "[epoch: 338/400, batch: 168/1000, ite: 45022] train loss: 1.1839, accuracy: 94.7677%, tar: 0.0266 \n",
      "l0: 0.022969, l1: 0.024494, l2: 0.032327, l3: 0.046536, l4: 0.089347, l5: 0.201065, l6: 0.376053\n",
      "\n",
      "[epoch: 338/400, batch: 176/1000, ite: 45023] train loss: 1.1839, accuracy: 95.2417%, tar: 0.0266 \n",
      "l0: 0.019436, l1: 0.020331, l2: 0.027293, l3: 0.040440, l4: 0.082775, l5: 0.207164, l6: 0.360176\n",
      "\n",
      "[epoch: 338/400, batch: 184/1000, ite: 45024] train loss: 1.1838, accuracy: 95.2326%, tar: 0.0266 \n",
      "l0: 0.025315, l1: 0.026666, l2: 0.035437, l3: 0.053671, l4: 0.100901, l5: 0.205766, l6: 0.411546\n",
      "\n",
      "[epoch: 338/400, batch: 192/1000, ite: 45025] train loss: 1.1839, accuracy: 94.2618%, tar: 0.0266 \n",
      "l0: 0.030403, l1: 0.032560, l2: 0.041288, l3: 0.065024, l4: 0.122384, l5: 0.267473, l6: 0.530726\n",
      "\n",
      "[epoch: 338/400, batch: 200/1000, ite: 45026] train loss: 1.1843, accuracy: 92.5566%, tar: 0.0266 \n",
      "l0: 0.024953, l1: 0.026515, l2: 0.034706, l3: 0.052600, l4: 0.103574, l5: 0.223279, l6: 0.566163\n",
      "\n",
      "[epoch: 338/400, batch: 208/1000, ite: 45027] train loss: 1.1847, accuracy: 93.6914%, tar: 0.0266 \n",
      "l0: 0.022196, l1: 0.023789, l2: 0.031538, l3: 0.050132, l4: 0.098716, l5: 0.221190, l6: 0.409418\n",
      "\n",
      "[epoch: 338/400, batch: 216/1000, ite: 45028] train loss: 1.1848, accuracy: 94.7937%, tar: 0.0266 \n",
      "l0: 0.021378, l1: 0.022501, l2: 0.029598, l3: 0.046961, l4: 0.089951, l5: 0.159952, l6: 0.331671\n",
      "\n",
      "[epoch: 338/400, batch: 224/1000, ite: 45029] train loss: 1.1847, accuracy: 95.3609%, tar: 0.0266 \n",
      "l0: 0.019147, l1: 0.020217, l2: 0.027036, l3: 0.045155, l4: 0.089978, l5: 0.148268, l6: 0.288944\n",
      "\n",
      "[epoch: 338/400, batch: 232/1000, ite: 45030] train loss: 1.1844, accuracy: 95.8465%, tar: 0.0266 \n",
      "l0: 0.029785, l1: 0.031567, l2: 0.042275, l3: 0.061061, l4: 0.115947, l5: 0.249294, l6: 0.470447\n",
      "\n",
      "[epoch: 338/400, batch: 240/1000, ite: 45031] train loss: 1.1847, accuracy: 93.5453%, tar: 0.0266 \n",
      "l0: 0.020715, l1: 0.022323, l2: 0.028617, l3: 0.041926, l4: 0.079565, l5: 0.162599, l6: 0.393380\n",
      "\n",
      "[epoch: 338/400, batch: 248/1000, ite: 45032] train loss: 1.1847, accuracy: 95.1406%, tar: 0.0266 \n",
      "l0: 0.028795, l1: 0.030118, l2: 0.039180, l3: 0.059070, l4: 0.118271, l5: 0.241288, l6: 0.462827\n",
      "\n",
      "[epoch: 338/400, batch: 256/1000, ite: 45033] train loss: 1.1849, accuracy: 92.9497%, tar: 0.0266 \n",
      "l0: 0.023045, l1: 0.023763, l2: 0.030627, l3: 0.044683, l4: 0.082530, l5: 0.153776, l6: 0.326148\n",
      "\n",
      "[epoch: 338/400, batch: 264/1000, ite: 45034] train loss: 1.1848, accuracy: 95.0698%, tar: 0.0266 \n",
      "l0: 0.022416, l1: 0.023433, l2: 0.030307, l3: 0.042287, l4: 0.069127, l5: 0.141596, l6: 0.304077\n",
      "\n",
      "[epoch: 338/400, batch: 272/1000, ite: 45035] train loss: 1.1845, accuracy: 95.3560%, tar: 0.0266 \n",
      "l0: 0.028403, l1: 0.029776, l2: 0.037977, l3: 0.056029, l4: 0.104733, l5: 0.221455, l6: 0.482310\n",
      "\n",
      "[epoch: 338/400, batch: 280/1000, ite: 45036] train loss: 1.1848, accuracy: 93.3717%, tar: 0.0266 \n",
      "l0: 0.032157, l1: 0.032830, l2: 0.040760, l3: 0.053499, l4: 0.087263, l5: 0.166214, l6: 0.355640\n",
      "\n",
      "[epoch: 338/400, batch: 288/1000, ite: 45037] train loss: 1.1847, accuracy: 94.6532%, tar: 0.0266 \n",
      "l0: 0.024342, l1: 0.025836, l2: 0.033595, l3: 0.050129, l4: 0.102715, l5: 0.192196, l6: 0.374637\n",
      "\n",
      "[epoch: 338/400, batch: 296/1000, ite: 45038] train loss: 1.1847, accuracy: 95.2858%, tar: 0.0266 \n",
      "l0: 0.026463, l1: 0.027608, l2: 0.036006, l3: 0.053959, l4: 0.094028, l5: 0.199206, l6: 0.368543\n",
      "\n",
      "[epoch: 338/400, batch: 304/1000, ite: 45039] train loss: 1.1847, accuracy: 94.1796%, tar: 0.0266 \n",
      "l0: 0.026371, l1: 0.027976, l2: 0.036071, l3: 0.055361, l4: 0.110549, l5: 0.234038, l6: 0.438189\n",
      "\n",
      "[epoch: 338/400, batch: 312/1000, ite: 45040] train loss: 1.1849, accuracy: 94.4391%, tar: 0.0266 \n",
      "l0: 0.024754, l1: 0.025486, l2: 0.032451, l3: 0.048534, l4: 0.087023, l5: 0.152167, l6: 0.338816\n",
      "\n",
      "[epoch: 338/400, batch: 320/1000, ite: 45041] train loss: 1.1847, accuracy: 95.2137%, tar: 0.0266 \n",
      "l0: 0.028897, l1: 0.030743, l2: 0.039254, l3: 0.060424, l4: 0.128367, l5: 0.246318, l6: 0.510045\n",
      "\n",
      "[epoch: 338/400, batch: 328/1000, ite: 45042] train loss: 1.1851, accuracy: 94.2161%, tar: 0.0266 \n",
      "l0: 0.031572, l1: 0.034645, l2: 0.046171, l3: 0.071310, l4: 0.128990, l5: 0.266949, l6: 0.433952\n",
      "\n",
      "[epoch: 338/400, batch: 336/1000, ite: 45043] train loss: 1.1854, accuracy: 94.2538%, tar: 0.0266 \n",
      "l0: 0.030641, l1: 0.031816, l2: 0.040355, l3: 0.055368, l4: 0.092395, l5: 0.182084, l6: 0.389836\n",
      "\n",
      "[epoch: 338/400, batch: 344/1000, ite: 45044] train loss: 1.1854, accuracy: 93.8769%, tar: 0.0266 \n",
      "l0: 0.024813, l1: 0.026278, l2: 0.033335, l3: 0.043819, l4: 0.071084, l5: 0.166227, l6: 0.361486\n",
      "\n",
      "[epoch: 338/400, batch: 352/1000, ite: 45045] train loss: 1.1853, accuracy: 94.7807%, tar: 0.0266 \n",
      "l0: 0.018251, l1: 0.020583, l2: 0.029662, l3: 0.045006, l4: 0.082674, l5: 0.178947, l6: 0.332550\n",
      "\n",
      "[epoch: 338/400, batch: 360/1000, ite: 45046] train loss: 1.1852, accuracy: 96.3455%, tar: 0.0266 \n",
      "l0: 0.015305, l1: 0.016131, l2: 0.021548, l3: 0.032789, l4: 0.059452, l5: 0.119465, l6: 0.242231\n",
      "\n",
      "[epoch: 338/400, batch: 368/1000, ite: 45047] train loss: 1.1847, accuracy: 96.5094%, tar: 0.0266 \n",
      "l0: 0.019422, l1: 0.020247, l2: 0.027690, l3: 0.040975, l4: 0.072947, l5: 0.131053, l6: 0.268677\n",
      "\n",
      "[epoch: 338/400, batch: 376/1000, ite: 45048] train loss: 1.1844, accuracy: 96.0928%, tar: 0.0265 \n",
      "l0: 0.024496, l1: 0.026013, l2: 0.034221, l3: 0.054551, l4: 0.104371, l5: 0.217439, l6: 0.410978\n",
      "\n",
      "[epoch: 338/400, batch: 384/1000, ite: 45049] train loss: 1.1845, accuracy: 94.2467%, tar: 0.0265 \n",
      "l0: 0.020669, l1: 0.021582, l2: 0.029584, l3: 0.041284, l4: 0.071899, l5: 0.161943, l6: 0.328179\n",
      "\n",
      "[epoch: 338/400, batch: 392/1000, ite: 45050] train loss: 1.1844, accuracy: 94.8886%, tar: 0.0265 \n",
      "l0: 0.018025, l1: 0.018782, l2: 0.024041, l3: 0.036850, l4: 0.067054, l5: 0.150835, l6: 0.353564\n",
      "\n",
      "[epoch: 338/400, batch: 400/1000, ite: 45051] train loss: 1.1842, accuracy: 95.2211%, tar: 0.0265 \n",
      "l0: 0.023089, l1: 0.024505, l2: 0.032131, l3: 0.044453, l4: 0.076167, l5: 0.134850, l6: 0.291754\n",
      "\n",
      "[epoch: 338/400, batch: 408/1000, ite: 45052] train loss: 1.1840, accuracy: 96.0892%, tar: 0.0265 \n",
      "l0: 0.018039, l1: 0.019197, l2: 0.025861, l3: 0.038682, l4: 0.064590, l5: 0.127897, l6: 0.283797\n",
      "\n",
      "[epoch: 338/400, batch: 416/1000, ite: 45053] train loss: 1.1837, accuracy: 96.0226%, tar: 0.0265 \n",
      "l0: 0.021555, l1: 0.022582, l2: 0.029003, l3: 0.040811, l4: 0.071360, l5: 0.153127, l6: 0.367053\n",
      "\n",
      "[epoch: 338/400, batch: 424/1000, ite: 45054] train loss: 1.1836, accuracy: 94.9996%, tar: 0.0265 \n",
      "l0: 0.020131, l1: 0.020986, l2: 0.028141, l3: 0.040198, l4: 0.071491, l5: 0.135067, l6: 0.315646\n",
      "\n",
      "[epoch: 338/400, batch: 432/1000, ite: 45055] train loss: 1.1833, accuracy: 95.1643%, tar: 0.0265 \n",
      "l0: 0.030412, l1: 0.032265, l2: 0.038898, l3: 0.060327, l4: 0.114292, l5: 0.225070, l6: 0.405004\n",
      "\n",
      "[epoch: 338/400, batch: 440/1000, ite: 45056] train loss: 1.1835, accuracy: 93.3701%, tar: 0.0265 \n",
      "l0: 0.025217, l1: 0.026280, l2: 0.035116, l3: 0.051478, l4: 0.091197, l5: 0.167861, l6: 0.311143\n",
      "\n",
      "[epoch: 338/400, batch: 448/1000, ite: 45057] train loss: 1.1833, accuracy: 95.0516%, tar: 0.0265 \n",
      "l0: 0.020531, l1: 0.021934, l2: 0.029192, l3: 0.041973, l4: 0.069651, l5: 0.137372, l6: 0.318585\n",
      "\n",
      "[epoch: 338/400, batch: 456/1000, ite: 45058] train loss: 1.1831, accuracy: 96.0174%, tar: 0.0265 \n",
      "l0: 0.018735, l1: 0.019898, l2: 0.026886, l3: 0.041677, l4: 0.078316, l5: 0.127533, l6: 0.248511\n",
      "\n",
      "[epoch: 338/400, batch: 464/1000, ite: 45059] train loss: 1.1828, accuracy: 96.2305%, tar: 0.0265 \n",
      "l0: 0.026217, l1: 0.027650, l2: 0.037053, l3: 0.055699, l4: 0.092538, l5: 0.157653, l6: 0.331231\n",
      "\n",
      "[epoch: 338/400, batch: 472/1000, ite: 45060] train loss: 1.1827, accuracy: 94.7984%, tar: 0.0265 \n",
      "l0: 0.025996, l1: 0.026734, l2: 0.038368, l3: 0.056833, l4: 0.090019, l5: 0.160843, l6: 0.385772\n",
      "\n",
      "[epoch: 338/400, batch: 480/1000, ite: 45061] train loss: 1.1826, accuracy: 94.6251%, tar: 0.0265 \n",
      "l0: 0.024708, l1: 0.025824, l2: 0.034880, l3: 0.053625, l4: 0.094749, l5: 0.178856, l6: 0.346051\n",
      "\n",
      "[epoch: 338/400, batch: 488/1000, ite: 45062] train loss: 1.1826, accuracy: 94.7103%, tar: 0.0265 \n",
      "l0: 0.026389, l1: 0.027813, l2: 0.036012, l3: 0.052923, l4: 0.097557, l5: 0.212211, l6: 0.476061\n",
      "\n",
      "[epoch: 338/400, batch: 496/1000, ite: 45063] train loss: 1.1828, accuracy: 93.6759%, tar: 0.0265 \n",
      "l0: 0.019043, l1: 0.020452, l2: 0.027773, l3: 0.042414, l4: 0.079659, l5: 0.154676, l6: 0.294982\n",
      "\n",
      "[epoch: 338/400, batch: 504/1000, ite: 45064] train loss: 1.1826, accuracy: 95.7185%, tar: 0.0265 \n",
      "l0: 0.012411, l1: 0.013838, l2: 0.018794, l3: 0.028657, l4: 0.056588, l5: 0.124700, l6: 0.254997\n",
      "\n",
      "[epoch: 338/400, batch: 512/1000, ite: 45065] train loss: 1.1822, accuracy: 96.8970%, tar: 0.0265 \n",
      "l0: 0.030623, l1: 0.031445, l2: 0.038534, l3: 0.053312, l4: 0.091063, l5: 0.200864, l6: 0.401567\n",
      "\n",
      "[epoch: 338/400, batch: 520/1000, ite: 45066] train loss: 1.1822, accuracy: 94.4634%, tar: 0.0265 \n",
      "l0: 0.021241, l1: 0.022083, l2: 0.028668, l3: 0.042379, l4: 0.072308, l5: 0.130992, l6: 0.330723\n",
      "\n",
      "[epoch: 338/400, batch: 528/1000, ite: 45067] train loss: 1.1821, accuracy: 95.3910%, tar: 0.0265 \n",
      "l0: 0.019647, l1: 0.020387, l2: 0.027037, l3: 0.037896, l4: 0.064368, l5: 0.111179, l6: 0.219089\n",
      "\n",
      "[epoch: 338/400, batch: 536/1000, ite: 45068] train loss: 1.1816, accuracy: 95.9715%, tar: 0.0265 \n",
      "l0: 0.018630, l1: 0.020101, l2: 0.029726, l3: 0.047684, l4: 0.091922, l5: 0.184202, l6: 0.334532\n",
      "\n",
      "[epoch: 338/400, batch: 544/1000, ite: 45069] train loss: 1.1815, accuracy: 95.7573%, tar: 0.0265 \n",
      "l0: 0.021935, l1: 0.022957, l2: 0.028937, l3: 0.040237, l4: 0.068246, l5: 0.147247, l6: 0.294638\n",
      "\n",
      "[epoch: 338/400, batch: 552/1000, ite: 45070] train loss: 1.1813, accuracy: 96.0882%, tar: 0.0265 \n",
      "l0: 0.024048, l1: 0.025343, l2: 0.033081, l3: 0.050444, l4: 0.086779, l5: 0.183719, l6: 0.405813\n",
      "\n",
      "[epoch: 338/400, batch: 560/1000, ite: 45071] train loss: 1.1813, accuracy: 94.2297%, tar: 0.0265 \n",
      "l0: 0.024620, l1: 0.026125, l2: 0.034225, l3: 0.052621, l4: 0.102607, l5: 0.211201, l6: 0.452255\n",
      "\n",
      "[epoch: 338/400, batch: 568/1000, ite: 45072] train loss: 1.1815, accuracy: 94.4998%, tar: 0.0264 \n",
      "l0: 0.022957, l1: 0.025039, l2: 0.034763, l3: 0.054900, l4: 0.115088, l5: 0.212237, l6: 0.457978\n",
      "\n",
      "[epoch: 338/400, batch: 576/1000, ite: 45073] train loss: 1.1817, accuracy: 94.5812%, tar: 0.0264 \n",
      "l0: 0.022774, l1: 0.023633, l2: 0.031122, l3: 0.045518, l4: 0.085132, l5: 0.164786, l6: 0.362983\n",
      "\n",
      "[epoch: 338/400, batch: 584/1000, ite: 45074] train loss: 1.1816, accuracy: 95.1201%, tar: 0.0264 \n",
      "l0: 0.018197, l1: 0.019099, l2: 0.025586, l3: 0.037629, l4: 0.072556, l5: 0.157570, l6: 0.324392\n",
      "\n",
      "[epoch: 338/400, batch: 592/1000, ite: 45075] train loss: 1.1814, accuracy: 95.3767%, tar: 0.0264 \n",
      "l0: 0.029381, l1: 0.030882, l2: 0.039960, l3: 0.054192, l4: 0.086254, l5: 0.167718, l6: 0.331085\n",
      "\n",
      "[epoch: 338/400, batch: 600/1000, ite: 45076] train loss: 1.1813, accuracy: 94.4971%, tar: 0.0264 \n",
      "l0: 0.041116, l1: 0.043165, l2: 0.055966, l3: 0.077309, l4: 0.149747, l5: 0.341065, l6: 0.718208\n",
      "\n",
      "[epoch: 338/400, batch: 608/1000, ite: 45077] train loss: 1.1822, accuracy: 90.3711%, tar: 0.0265 \n",
      "l0: 0.018567, l1: 0.019247, l2: 0.024241, l3: 0.033622, l4: 0.056419, l5: 0.103888, l6: 0.237002\n",
      "\n",
      "[epoch: 338/400, batch: 616/1000, ite: 45078] train loss: 1.1818, accuracy: 95.8726%, tar: 0.0264 \n",
      "l0: 0.024982, l1: 0.026668, l2: 0.035083, l3: 0.049552, l4: 0.084138, l5: 0.148249, l6: 0.329371\n",
      "\n",
      "[epoch: 338/400, batch: 624/1000, ite: 45079] train loss: 1.1817, accuracy: 95.0112%, tar: 0.0264 \n",
      "l0: 0.023453, l1: 0.024798, l2: 0.034853, l3: 0.054506, l4: 0.096079, l5: 0.169788, l6: 0.353036\n",
      "\n",
      "[epoch: 338/400, batch: 632/1000, ite: 45080] train loss: 1.1816, accuracy: 94.9411%, tar: 0.0264 \n",
      "l0: 0.031493, l1: 0.033297, l2: 0.041785, l3: 0.063344, l4: 0.131561, l5: 0.279533, l6: 0.550703\n",
      "\n",
      "[epoch: 338/400, batch: 640/1000, ite: 45081] train loss: 1.1821, accuracy: 92.9082%, tar: 0.0264 \n",
      "l0: 0.023602, l1: 0.024931, l2: 0.031670, l3: 0.044966, l4: 0.090448, l5: 0.176244, l6: 0.333997\n",
      "\n",
      "[epoch: 338/400, batch: 648/1000, ite: 45082] train loss: 1.1820, accuracy: 95.5393%, tar: 0.0264 \n",
      "l0: 0.029207, l1: 0.031476, l2: 0.043644, l3: 0.069570, l4: 0.124482, l5: 0.219280, l6: 0.427521\n",
      "\n",
      "[epoch: 338/400, batch: 656/1000, ite: 45083] train loss: 1.1821, accuracy: 94.3083%, tar: 0.0264 \n",
      "l0: 0.023704, l1: 0.024813, l2: 0.032208, l3: 0.044896, l4: 0.076813, l5: 0.145826, l6: 0.315954\n",
      "\n",
      "[epoch: 338/400, batch: 664/1000, ite: 45084] train loss: 1.1820, accuracy: 95.2601%, tar: 0.0264 \n",
      "l0: 0.022368, l1: 0.023514, l2: 0.032225, l3: 0.049243, l4: 0.084541, l5: 0.175551, l6: 0.331984\n",
      "\n",
      "[epoch: 338/400, batch: 672/1000, ite: 45085] train loss: 1.1818, accuracy: 95.3182%, tar: 0.0264 \n",
      "l0: 0.022739, l1: 0.023958, l2: 0.032218, l3: 0.051256, l4: 0.118332, l5: 0.217802, l6: 0.408127\n",
      "\n",
      "[epoch: 338/400, batch: 680/1000, ite: 45086] train loss: 1.1819, accuracy: 94.1082%, tar: 0.0264 \n",
      "l0: 0.019772, l1: 0.021303, l2: 0.028851, l3: 0.042995, l4: 0.086504, l5: 0.139909, l6: 0.295221\n",
      "\n",
      "[epoch: 338/400, batch: 688/1000, ite: 45087] train loss: 1.1817, accuracy: 96.2964%, tar: 0.0264 \n",
      "l0: 0.020664, l1: 0.021636, l2: 0.029096, l3: 0.042413, l4: 0.069855, l5: 0.118275, l6: 0.242911\n",
      "\n",
      "[epoch: 338/400, batch: 696/1000, ite: 45088] train loss: 1.1814, accuracy: 96.6982%, tar: 0.0264 \n",
      "l0: 0.023558, l1: 0.024772, l2: 0.032468, l3: 0.049158, l4: 0.092193, l5: 0.207100, l6: 0.390747\n",
      "\n",
      "[epoch: 338/400, batch: 704/1000, ite: 45089] train loss: 1.1814, accuracy: 94.8157%, tar: 0.0264 \n",
      "l0: 0.016108, l1: 0.017157, l2: 0.023705, l3: 0.034890, l4: 0.060935, l5: 0.133292, l6: 0.303785\n",
      "\n",
      "[epoch: 338/400, batch: 712/1000, ite: 45090] train loss: 1.1811, accuracy: 95.7989%, tar: 0.0264 \n",
      "l0: 0.026540, l1: 0.027898, l2: 0.036309, l3: 0.055908, l4: 0.107625, l5: 0.222113, l6: 0.507853\n",
      "\n",
      "[epoch: 338/400, batch: 720/1000, ite: 45091] train loss: 1.1814, accuracy: 93.4480%, tar: 0.0264 \n",
      "l0: 0.026317, l1: 0.027107, l2: 0.035275, l3: 0.051175, l4: 0.088682, l5: 0.138371, l6: 0.317875\n",
      "\n",
      "[epoch: 338/400, batch: 728/1000, ite: 45092] train loss: 1.1813, accuracy: 95.7457%, tar: 0.0264 \n",
      "l0: 0.023823, l1: 0.025012, l2: 0.033381, l3: 0.049444, l4: 0.083901, l5: 0.180448, l6: 0.376066\n",
      "\n",
      "[epoch: 338/400, batch: 736/1000, ite: 45093] train loss: 1.1812, accuracy: 94.6689%, tar: 0.0264 \n",
      "l0: 0.018731, l1: 0.019652, l2: 0.024710, l3: 0.037612, l4: 0.065429, l5: 0.143100, l6: 0.281989\n",
      "\n",
      "[epoch: 338/400, batch: 744/1000, ite: 45094] train loss: 1.1810, accuracy: 95.7661%, tar: 0.0264 \n",
      "l0: 0.030738, l1: 0.031903, l2: 0.039417, l3: 0.060343, l4: 0.123638, l5: 0.212299, l6: 0.431609\n",
      "\n",
      "[epoch: 338/400, batch: 752/1000, ite: 45095] train loss: 1.1811, accuracy: 92.9918%, tar: 0.0264 \n",
      "l0: 0.022812, l1: 0.023537, l2: 0.031690, l3: 0.048977, l4: 0.084131, l5: 0.189174, l6: 0.411119\n",
      "\n",
      "[epoch: 338/400, batch: 760/1000, ite: 45096] train loss: 1.1812, accuracy: 94.6419%, tar: 0.0264 \n",
      "l0: 0.018871, l1: 0.020766, l2: 0.026821, l3: 0.037930, l4: 0.101658, l5: 0.198709, l6: 0.272073\n",
      "\n",
      "[epoch: 338/400, batch: 768/1000, ite: 45097] train loss: 1.1810, accuracy: 96.7079%, tar: 0.0264 \n",
      "l0: 0.021427, l1: 0.022414, l2: 0.030199, l3: 0.043899, l4: 0.073467, l5: 0.157179, l6: 0.282831\n",
      "\n",
      "[epoch: 338/400, batch: 776/1000, ite: 45098] train loss: 1.1807, accuracy: 96.2804%, tar: 0.0264 \n",
      "l0: 0.043768, l1: 0.045257, l2: 0.054990, l3: 0.078756, l4: 0.156050, l5: 0.366797, l6: 0.673012\n",
      "\n",
      "[epoch: 338/400, batch: 784/1000, ite: 45099] train loss: 1.1816, accuracy: 90.3183%, tar: 0.0264 \n",
      "l0: 0.028969, l1: 0.029914, l2: 0.038540, l3: 0.057766, l4: 0.089512, l5: 0.144077, l6: 0.337164\n",
      "\n",
      "[epoch: 338/400, batch: 792/1000, ite: 45100] train loss: 1.1815, accuracy: 94.5592%, tar: 0.0264 \n",
      "l0: 0.018202, l1: 0.019580, l2: 0.026715, l3: 0.038393, l4: 0.067042, l5: 0.117843, l6: 0.236798\n",
      "\n",
      "[epoch: 338/400, batch: 800/1000, ite: 45101] train loss: 1.1811, accuracy: 96.6669%, tar: 0.0264 \n",
      "l0: 0.022263, l1: 0.023059, l2: 0.029863, l3: 0.041251, l4: 0.068027, l5: 0.138275, l6: 0.284701\n",
      "\n",
      "[epoch: 338/400, batch: 808/1000, ite: 45102] train loss: 1.1808, accuracy: 95.4152%, tar: 0.0264 \n",
      "l0: 0.025488, l1: 0.026582, l2: 0.034722, l3: 0.051574, l4: 0.101199, l5: 0.196927, l6: 0.392185\n",
      "\n",
      "[epoch: 338/400, batch: 816/1000, ite: 45103] train loss: 1.1809, accuracy: 94.1732%, tar: 0.0264 \n",
      "l0: 0.023426, l1: 0.024295, l2: 0.031316, l3: 0.046903, l4: 0.099233, l5: 0.160467, l6: 0.331157\n",
      "\n",
      "[epoch: 338/400, batch: 824/1000, ite: 45104] train loss: 1.1807, accuracy: 95.2636%, tar: 0.0264 \n",
      "l0: 0.030099, l1: 0.031565, l2: 0.040729, l3: 0.064124, l4: 0.117945, l5: 0.218615, l6: 0.416101\n",
      "\n",
      "[epoch: 338/400, batch: 832/1000, ite: 45105] train loss: 1.1809, accuracy: 94.2348%, tar: 0.0264 \n",
      "l0: 0.023507, l1: 0.024839, l2: 0.032722, l3: 0.049800, l4: 0.086530, l5: 0.173394, l6: 0.307022\n",
      "\n",
      "[epoch: 338/400, batch: 840/1000, ite: 45106] train loss: 1.1807, accuracy: 95.6871%, tar: 0.0264 \n",
      "l0: 0.022312, l1: 0.023904, l2: 0.032888, l3: 0.048519, l4: 0.086764, l5: 0.178609, l6: 0.392772\n",
      "\n",
      "[epoch: 338/400, batch: 848/1000, ite: 45107] train loss: 1.1807, accuracy: 95.0891%, tar: 0.0264 \n",
      "l0: 0.022779, l1: 0.025227, l2: 0.034392, l3: 0.057343, l4: 0.107340, l5: 0.252845, l6: 0.425944\n",
      "\n",
      "[epoch: 338/400, batch: 856/1000, ite: 45108] train loss: 1.1809, accuracy: 95.0468%, tar: 0.0264 \n",
      "l0: 0.019353, l1: 0.020499, l2: 0.026885, l3: 0.038993, l4: 0.064921, l5: 0.126460, l6: 0.243817\n",
      "\n",
      "[epoch: 338/400, batch: 864/1000, ite: 45109] train loss: 1.1805, accuracy: 96.7965%, tar: 0.0264 \n",
      "l0: 0.032380, l1: 0.046360, l2: 0.054601, l3: 0.073445, l4: 0.124791, l5: 0.265763, l6: 0.369888\n",
      "\n",
      "[epoch: 338/400, batch: 872/1000, ite: 45110] train loss: 1.1807, accuracy: 94.0465%, tar: 0.0264 \n",
      "l0: 0.020795, l1: 0.021796, l2: 0.029546, l3: 0.046882, l4: 0.090509, l5: 0.174722, l6: 0.297543\n",
      "\n",
      "[epoch: 338/400, batch: 880/1000, ite: 45111] train loss: 1.1805, accuracy: 95.9946%, tar: 0.0264 \n",
      "l0: 0.028100, l1: 0.028644, l2: 0.037068, l3: 0.053223, l4: 0.089049, l5: 0.195922, l6: 0.395387\n",
      "\n",
      "[epoch: 338/400, batch: 888/1000, ite: 45112] train loss: 1.1805, accuracy: 94.1396%, tar: 0.0264 \n",
      "l0: 0.050736, l1: 0.050714, l2: 0.060196, l3: 0.080890, l4: 0.143617, l5: 0.273279, l6: 0.488480\n",
      "\n",
      "[epoch: 338/400, batch: 896/1000, ite: 45113] train loss: 1.1810, accuracy: 93.1214%, tar: 0.0264 \n",
      "l0: 0.022853, l1: 0.023448, l2: 0.029217, l3: 0.039704, l4: 0.065355, l5: 0.131939, l6: 0.295779\n",
      "\n",
      "[epoch: 338/400, batch: 904/1000, ite: 45114] train loss: 1.1807, accuracy: 94.8202%, tar: 0.0264 \n",
      "l0: 0.027396, l1: 0.029147, l2: 0.034801, l3: 0.046900, l4: 0.084199, l5: 0.177971, l6: 0.366337\n",
      "\n",
      "[epoch: 338/400, batch: 912/1000, ite: 45115] train loss: 1.1807, accuracy: 95.2584%, tar: 0.0264 \n",
      "l0: 0.134214, l1: 0.145528, l2: 0.152940, l3: 0.165328, l4: 0.199616, l5: 0.256144, l6: 0.383704\n",
      "\n",
      "[epoch: 338/400, batch: 920/1000, ite: 45116] train loss: 1.1812, accuracy: 92.8535%, tar: 0.0265 \n",
      "l0: 0.067983, l1: 0.072717, l2: 0.081087, l3: 0.107101, l4: 0.159823, l5: 0.275176, l6: 0.528235\n",
      "\n",
      "[epoch: 338/400, batch: 928/1000, ite: 45117] train loss: 1.1818, accuracy: 92.3910%, tar: 0.0265 \n",
      "l0: 0.046592, l1: 0.048718, l2: 0.058064, l3: 0.083454, l4: 0.134383, l5: 0.234564, l6: 0.449288\n",
      "\n",
      "[epoch: 338/400, batch: 936/1000, ite: 45118] train loss: 1.1821, accuracy: 93.8226%, tar: 0.0266 \n",
      "l0: 0.045315, l1: 0.047500, l2: 0.056419, l3: 0.081280, l4: 0.124250, l5: 0.238405, l6: 0.425013\n",
      "\n",
      "[epoch: 338/400, batch: 944/1000, ite: 45119] train loss: 1.1823, accuracy: 94.3754%, tar: 0.0266 \n",
      "l0: 0.037534, l1: 0.039279, l2: 0.045924, l3: 0.060549, l4: 0.112453, l5: 0.201828, l6: 0.387091\n",
      "\n",
      "[epoch: 338/400, batch: 952/1000, ite: 45120] train loss: 1.1824, accuracy: 94.1841%, tar: 0.0266 \n",
      "l0: 0.070573, l1: 0.069787, l2: 0.077584, l3: 0.110560, l4: 0.183005, l5: 0.358196, l6: 0.574176\n",
      "\n",
      "[epoch: 338/400, batch: 960/1000, ite: 45121] train loss: 1.1832, accuracy: 92.8410%, tar: 0.0266 \n",
      "l0: 0.091537, l1: 0.091922, l2: 0.098348, l3: 0.120734, l4: 0.169788, l5: 0.272914, l6: 0.463505\n",
      "\n",
      "[epoch: 338/400, batch: 968/1000, ite: 45122] train loss: 1.1837, accuracy: 93.3889%, tar: 0.0267 \n",
      "l0: 0.311841, l1: 0.218016, l2: 0.223650, l3: 0.236181, l4: 0.248881, l5: 0.333026, l6: 0.570040\n",
      "\n",
      "[epoch: 338/400, batch: 976/1000, ite: 45123] train loss: 1.1850, accuracy: 90.4417%, tar: 0.0269 \n",
      "l0: 0.142407, l1: 0.151483, l2: 0.168430, l3: 0.198222, l4: 0.263420, l5: 0.362218, l6: 0.589024\n",
      "\n",
      "[epoch: 338/400, batch: 984/1000, ite: 45124] train loss: 1.1862, accuracy: 90.6749%, tar: 0.0270 \n",
      "l0: 0.100134, l1: 0.103389, l2: 0.116965, l3: 0.143124, l4: 0.191974, l5: 0.317384, l6: 0.569483\n",
      "\n",
      "[epoch: 338/400, batch: 992/1000, ite: 45125] train loss: 1.1870, accuracy: 90.7656%, tar: 0.0271 \n",
      "l0: 0.932060, l1: 0.949728, l2: 1.241940, l3: 2.156558, l4: 2.496792, l5: 2.482389, l6: 1.457996\n",
      "\n",
      "[epoch: 338/400, batch: 1000/1000, ite: 45126] train loss: 1.1974, accuracy: 85.8615%, tar: 0.0279 \n",
      "l0: 0.073585, l1: 0.080099, l2: 0.076049, l3: 0.086988, l4: 0.126375, l5: 0.187901, l6: 0.370912\n",
      "\n",
      "[epoch: 339/400, batch: 8/1000, ite: 45127] train loss: 1.1976, accuracy: 94.4223%, tar: 0.0279 \n",
      "l0: 0.176772, l1: 0.197538, l2: 0.177792, l3: 0.175914, l4: 0.193561, l5: 0.302391, l6: 0.563256\n",
      "\n",
      "[epoch: 339/400, batch: 16/1000, ite: 45128] train loss: 1.1986, accuracy: 90.8313%, tar: 0.0281 \n",
      "l0: 0.168881, l1: 0.172900, l2: 0.189880, l3: 0.251163, l4: 0.299751, l5: 0.309314, l6: 0.498675\n",
      "\n",
      "[epoch: 339/400, batch: 24/1000, ite: 45129] train loss: 1.1996, accuracy: 89.7688%, tar: 0.0282 \n",
      "l0: 0.462351, l1: 0.505882, l2: 0.615783, l3: 1.161425, l4: 1.420942, l5: 1.023907, l6: 0.913118\n",
      "\n",
      "[epoch: 339/400, batch: 32/1000, ite: 45130] train loss: 1.2046, accuracy: 87.9036%, tar: 0.0286 \n",
      "l0: 0.187068, l1: 0.157294, l2: 0.167512, l3: 0.188434, l4: 0.235417, l5: 0.325116, l6: 0.509269\n",
      "\n",
      "[epoch: 339/400, batch: 40/1000, ite: 45131] train loss: 1.2055, accuracy: 90.8780%, tar: 0.0287 \n",
      "l0: 0.492222, l1: 0.439232, l2: 0.483721, l3: 0.555585, l4: 0.613906, l5: 0.727324, l6: 0.842406\n",
      "\n",
      "[epoch: 339/400, batch: 48/1000, ite: 45132] train loss: 1.2088, accuracy: 85.6147%, tar: 0.0291 \n",
      "l0: 0.290645, l1: 0.283655, l2: 0.319445, l3: 0.536491, l4: 0.694417, l5: 0.762790, l6: 1.170981\n",
      "\n",
      "[epoch: 339/400, batch: 56/1000, ite: 45133] train loss: 1.2123, accuracy: 86.7133%, tar: 0.0294 \n",
      "l0: 0.378925, l1: 0.388896, l2: 0.388617, l3: 0.441597, l4: 0.511400, l5: 0.611243, l6: 0.796628\n",
      "\n",
      "[epoch: 339/400, batch: 64/1000, ite: 45134] train loss: 1.2149, accuracy: 86.5721%, tar: 0.0297 \n",
      "l0: 0.260473, l1: 0.273354, l2: 0.259594, l3: 0.300691, l4: 0.328358, l5: 0.372752, l6: 0.541432\n",
      "\n",
      "[epoch: 339/400, batch: 72/1000, ite: 45135] train loss: 1.2164, accuracy: 90.8480%, tar: 0.0299 \n",
      "l0: 0.279462, l1: 0.300406, l2: 0.290840, l3: 0.301056, l4: 0.386693, l5: 0.486582, l6: 0.541139\n",
      "\n",
      "[epoch: 339/400, batch: 80/1000, ite: 45136] train loss: 1.2180, accuracy: 90.5281%, tar: 0.0301 \n",
      "l0: 0.418221, l1: 0.426335, l2: 0.435017, l3: 0.488128, l4: 0.703719, l5: 0.970553, l6: 1.013512\n",
      "\n",
      "[epoch: 339/400, batch: 88/1000, ite: 45137] train loss: 1.2217, accuracy: 84.8169%, tar: 0.0304 \n",
      "l0: 0.256212, l1: 0.255232, l2: 0.278092, l3: 0.314390, l4: 0.379021, l5: 0.496577, l6: 0.735791\n",
      "\n",
      "[epoch: 339/400, batch: 96/1000, ite: 45138] train loss: 1.2237, accuracy: 86.8271%, tar: 0.0306 \n",
      "l0: 0.275522, l1: 0.272101, l2: 0.291367, l3: 0.311349, l4: 0.368197, l5: 0.479283, l6: 0.673819\n",
      "\n",
      "[epoch: 339/400, batch: 104/1000, ite: 45139] train loss: 1.2257, accuracy: 88.0654%, tar: 0.0309 \n",
      "l0: 0.425466, l1: 0.416046, l2: 0.433289, l3: 0.488934, l4: 0.561516, l5: 0.935568, l6: 1.161013\n",
      "\n",
      "[epoch: 339/400, batch: 112/1000, ite: 45140] train loss: 1.2294, accuracy: 89.0004%, tar: 0.0312 \n",
      "l0: 0.315445, l1: 0.320838, l2: 0.337242, l3: 0.539998, l4: 0.792247, l5: 0.836425, l6: 0.984307\n",
      "\n",
      "[epoch: 339/400, batch: 120/1000, ite: 45141] train loss: 1.2328, accuracy: 86.7600%, tar: 0.0314 \n",
      "l0: 0.518934, l1: 0.523350, l2: 0.521371, l3: 0.613585, l4: 0.693444, l5: 0.946283, l6: 1.238793\n",
      "\n",
      "[epoch: 339/400, batch: 128/1000, ite: 45142] train loss: 1.2370, accuracy: 88.6187%, tar: 0.0319 \n",
      "l0: 0.513707, l1: 0.518457, l2: 0.519781, l3: 0.580910, l4: 0.713080, l5: 0.789679, l6: 1.036071\n",
      "\n",
      "l0: 0.505021, l1: 0.499603, l2: 0.512660, l3: 0.558560, l4: 0.557983, l5: 0.617793, l6: 0.646028\n",
      "\n",
      "[epoch: 339/400, batch: 152/1000, ite: 45145] train loss: 1.2492, accuracy: 83.8783%, tar: 0.0332 \n",
      "l0: 0.487726, l1: 0.488452, l2: 0.470684, l3: 0.503986, l4: 0.556839, l5: 0.649208, l6: 0.806177\n",
      "\n",
      "[epoch: 339/400, batch: 160/1000, ite: 45146] train loss: 1.2522, accuracy: 84.9027%, tar: 0.0336 \n",
      "l0: 0.442539, l1: 0.453756, l2: 0.460429, l3: 0.529612, l4: 0.662951, l5: 0.886826, l6: 1.243370\n",
      "\n",
      "[epoch: 339/400, batch: 168/1000, ite: 45147] train loss: 1.2560, accuracy: 82.6287%, tar: 0.0340 \n",
      "l0: 0.619688, l1: 0.638572, l2: 0.628920, l3: 0.676636, l4: 0.724279, l5: 0.815325, l6: 1.710366\n",
      "\n",
      "[epoch: 339/400, batch: 176/1000, ite: 45148] train loss: 1.2614, accuracy: 83.8434%, tar: 0.0345 \n",
      "l0: 0.380912, l1: 0.394941, l2: 0.403825, l3: 0.438457, l4: 0.496671, l5: 0.728690, l6: 1.184269\n",
      "\n",
      "[epoch: 339/400, batch: 184/1000, ite: 45149] train loss: 1.2648, accuracy: 85.0120%, tar: 0.0348 \n",
      "l0: 0.496051, l1: 0.509640, l2: 0.508907, l3: 0.560792, l4: 0.620280, l5: 0.683584, l6: 0.749836\n",
      "\n",
      "[epoch: 339/400, batch: 192/1000, ite: 45150] train loss: 1.2679, accuracy: 85.5968%, tar: 0.0352 \n",
      "l0: 0.220823, l1: 0.227512, l2: 0.216803, l3: 0.243922, l4: 0.310026, l5: 0.371138, l6: 0.488069\n",
      "\n",
      "[epoch: 339/400, batch: 200/1000, ite: 45151] train loss: 1.2690, accuracy: 90.9437%, tar: 0.0353 \n",
      "l0: 0.320601, l1: 0.330583, l2: 0.342282, l3: 0.397347, l4: 0.472516, l5: 0.589350, l6: 0.665772\n",
      "\n",
      "[epoch: 339/400, batch: 208/1000, ite: 45152] train loss: 1.2711, accuracy: 87.2756%, tar: 0.0356 \n",
      "l0: 0.442145, l1: 0.459883, l2: 0.482955, l3: 0.516563, l4: 0.498808, l5: 0.573642, l6: 0.886723\n",
      "\n",
      "[epoch: 339/400, batch: 216/1000, ite: 45153] train loss: 1.2740, accuracy: 84.6060%, tar: 0.0359 \n",
      "l0: 0.400304, l1: 0.403127, l2: 0.400694, l3: 0.440370, l4: 0.536959, l5: 0.733641, l6: 1.205422\n",
      "\n",
      "[epoch: 339/400, batch: 224/1000, ite: 45154] train loss: 1.2774, accuracy: 85.5124%, tar: 0.0362 \n",
      "l0: 0.332756, l1: 0.322975, l2: 0.320409, l3: 0.358811, l4: 0.419534, l5: 0.458721, l6: 1.446279\n",
      "\n",
      "[epoch: 339/400, batch: 232/1000, ite: 45155] train loss: 1.2806, accuracy: 88.3600%, tar: 0.0365 \n",
      "l0: 0.153948, l1: 0.163993, l2: 0.168659, l3: 0.173428, l4: 0.209764, l5: 0.274428, l6: 0.432862\n",
      "\n",
      "[epoch: 339/400, batch: 240/1000, ite: 45156] train loss: 1.2812, accuracy: 92.4758%, tar: 0.0366 \n",
      "l0: 0.333613, l1: 0.352292, l2: 0.354102, l3: 0.353572, l4: 0.351102, l5: 0.365434, l6: 0.626321\n",
      "\n",
      "[epoch: 339/400, batch: 248/1000, ite: 45157] train loss: 1.2830, accuracy: 88.5571%, tar: 0.0369 \n",
      "l0: 0.361754, l1: 0.372361, l2: 0.376812, l3: 0.406757, l4: 0.506454, l5: 0.690779, l6: 0.923036\n",
      "\n",
      "[epoch: 339/400, batch: 256/1000, ite: 45158] train loss: 1.2858, accuracy: 85.4684%, tar: 0.0371 \n",
      "l0: 0.130153, l1: 0.133621, l2: 0.152370, l3: 0.163188, l4: 0.209736, l5: 0.298737, l6: 0.472691\n",
      "\n",
      "[epoch: 339/400, batch: 264/1000, ite: 45159] train loss: 1.2865, accuracy: 91.6475%, tar: 0.0372 \n",
      "l0: 0.226206, l1: 0.233468, l2: 0.234333, l3: 0.241368, l4: 0.275330, l5: 0.384876, l6: 0.596209\n",
      "\n",
      "[epoch: 339/400, batch: 272/1000, ite: 45160] train loss: 1.2878, accuracy: 89.3344%, tar: 0.0374 \n",
      "l0: 0.493683, l1: 0.521809, l2: 0.505689, l3: 0.464807, l4: 0.434672, l5: 0.480086, l6: 0.726947\n",
      "\n",
      "[epoch: 339/400, batch: 280/1000, ite: 45161] train loss: 1.2904, accuracy: 86.4455%, tar: 0.0378 \n",
      "l0: 0.168302, l1: 0.189912, l2: 0.197185, l3: 0.204602, l4: 0.242864, l5: 0.284613, l6: 0.437926\n",
      "\n",
      "[epoch: 339/400, batch: 288/1000, ite: 45162] train loss: 1.2912, accuracy: 90.4501%, tar: 0.0379 \n",
      "l0: 0.198472, l1: 0.200116, l2: 0.208924, l3: 0.239956, l4: 0.281955, l5: 0.362162, l6: 0.541287\n",
      "\n",
      "[epoch: 339/400, batch: 296/1000, ite: 45163] train loss: 1.2923, accuracy: 90.4165%, tar: 0.0380 \n",
      "l0: 0.247712, l1: 0.242245, l2: 0.238383, l3: 0.262020, l4: 0.311394, l5: 0.387745, l6: 0.578000\n",
      "\n",
      "[epoch: 339/400, batch: 304/1000, ite: 45164] train loss: 1.2936, accuracy: 91.3387%, tar: 0.0382 \n",
      "l0: 0.298816, l1: 0.300196, l2: 0.275181, l3: 0.370884, l4: 0.465494, l5: 0.542273, l6: 0.881719\n",
      "\n",
      "[epoch: 339/400, batch: 312/1000, ite: 45165] train loss: 1.2959, accuracy: 88.5644%, tar: 0.0384 \n",
      "l0: 0.306441, l1: 0.304445, l2: 0.308143, l3: 0.332977, l4: 0.411349, l5: 0.546857, l6: 0.800277\n",
      "\n",
      "[epoch: 339/400, batch: 320/1000, ite: 45166] train loss: 1.2980, accuracy: 88.6163%, tar: 0.0387 \n",
      "l0: 0.180215, l1: 0.166131, l2: 0.167530, l3: 0.184013, l4: 0.231052, l5: 0.325487, l6: 0.548840\n",
      "\n",
      "[epoch: 339/400, batch: 328/1000, ite: 45167] train loss: 1.2989, accuracy: 91.1992%, tar: 0.0388 \n",
      "l0: 0.274046, l1: 0.269241, l2: 0.265271, l3: 0.292719, l4: 0.301647, l5: 0.406424, l6: 0.605242\n",
      "\n",
      "[epoch: 339/400, batch: 336/1000, ite: 45168] train loss: 1.3005, accuracy: 89.2767%, tar: 0.0390 \n",
      "l0: 0.176312, l1: 0.173174, l2: 0.175257, l3: 0.193921, l4: 0.240743, l5: 0.324925, l6: 0.498788\n",
      "\n",
      "[epoch: 339/400, batch: 344/1000, ite: 45169] train loss: 1.3014, accuracy: 90.0310%, tar: 0.0391 \n",
      "l0: 0.215359, l1: 0.210949, l2: 0.211291, l3: 0.222986, l4: 0.241928, l5: 0.314004, l6: 0.540621\n",
      "\n",
      "[epoch: 339/400, batch: 352/1000, ite: 45170] train loss: 1.3024, accuracy: 89.4641%, tar: 0.0393 \n",
      "l0: 0.808878, l1: 0.822516, l2: 0.802064, l3: 0.841901, l4: 0.958787, l5: 1.018959, l6: 1.307051\n",
      "\n",
      "[epoch: 339/400, batch: 360/1000, ite: 45171] train loss: 1.3079, accuracy: 81.5367%, tar: 0.0399 \n",
      "l0: 0.229600, l1: 0.224272, l2: 0.227245, l3: 0.255372, l4: 0.320813, l5: 0.437044, l6: 0.664914\n",
      "\n",
      "[epoch: 339/400, batch: 368/1000, ite: 45172] train loss: 1.3093, accuracy: 89.3763%, tar: 0.0401 \n",
      "l0: 0.139214, l1: 0.135494, l2: 0.143058, l3: 0.169012, l4: 0.229050, l5: 0.339814, l6: 0.564532\n",
      "\n",
      "[epoch: 339/400, batch: 376/1000, ite: 45173] train loss: 1.3102, accuracy: 89.2992%, tar: 0.0402 \n",
      "l0: 0.125709, l1: 0.127707, l2: 0.142851, l3: 0.159617, l4: 0.192096, l5: 0.300595, l6: 0.454849\n",
      "\n",
      "[epoch: 339/400, batch: 384/1000, ite: 45174] train loss: 1.3107, accuracy: 91.9819%, tar: 0.0402 \n",
      "l0: 0.183442, l1: 0.189463, l2: 0.202866, l3: 0.221371, l4: 0.226133, l5: 0.330331, l6: 0.511173\n",
      "\n",
      "[epoch: 339/400, batch: 392/1000, ite: 45175] train loss: 1.3117, accuracy: 90.8427%, tar: 0.0404 \n",
      "l0: 0.258611, l1: 0.271013, l2: 0.282386, l3: 0.304961, l4: 0.333353, l5: 0.368667, l6: 0.464785\n",
      "\n",
      "[epoch: 339/400, batch: 400/1000, ite: 45176] train loss: 1.3129, accuracy: 88.5648%, tar: 0.0405 \n",
      "l0: 0.155923, l1: 0.155009, l2: 0.164577, l3: 0.188670, l4: 0.223158, l5: 0.349351, l6: 0.489692\n",
      "\n",
      "[epoch: 339/400, batch: 408/1000, ite: 45177] train loss: 1.3137, accuracy: 90.1073%, tar: 0.0406 \n",
      "l0: 0.151613, l1: 0.151088, l2: 0.157867, l3: 0.184980, l4: 0.262041, l5: 0.425781, l6: 0.547491\n",
      "\n",
      "[epoch: 339/400, batch: 416/1000, ite: 45178] train loss: 1.3146, accuracy: 88.3679%, tar: 0.0407 \n",
      "l0: 0.107593, l1: 0.105100, l2: 0.110190, l3: 0.122531, l4: 0.170178, l5: 0.263376, l6: 0.450585\n",
      "\n",
      "[epoch: 339/400, batch: 424/1000, ite: 45179] train loss: 1.3150, accuracy: 91.4220%, tar: 0.0408 \n",
      "l0: 0.390921, l1: 0.398838, l2: 0.401312, l3: 0.430409, l4: 0.476243, l5: 0.627693, l6: 0.890979\n",
      "\n",
      "[epoch: 339/400, batch: 432/1000, ite: 45180] train loss: 1.3178, accuracy: 84.0108%, tar: 0.0411 \n",
      "l0: 0.184380, l1: 0.182267, l2: 0.184265, l3: 0.205316, l4: 0.244623, l5: 0.337815, l6: 0.687857\n",
      "\n",
      "[epoch: 339/400, batch: 440/1000, ite: 45181] train loss: 1.3189, accuracy: 90.2080%, tar: 0.0412 \n",
      "l0: 0.243370, l1: 0.231759, l2: 0.238151, l3: 0.252527, l4: 0.300947, l5: 0.394523, l6: 0.635009\n",
      "\n",
      "[epoch: 339/400, batch: 448/1000, ite: 45182] train loss: 1.3203, accuracy: 88.8984%, tar: 0.0414 \n",
      "l0: 0.235507, l1: 0.252924, l2: 0.242487, l3: 0.255802, l4: 0.274533, l5: 0.358117, l6: 0.553068\n",
      "\n",
      "[epoch: 339/400, batch: 456/1000, ite: 45183] train loss: 1.3215, accuracy: 89.0157%, tar: 0.0415 \n",
      "l0: 0.140196, l1: 0.139027, l2: 0.140597, l3: 0.160337, l4: 0.214420, l5: 0.323206, l6: 0.553844\n",
      "\n",
      "[epoch: 339/400, batch: 464/1000, ite: 45184] train loss: 1.3224, accuracy: 90.4246%, tar: 0.0416 \n",
      "l0: 0.145808, l1: 0.149640, l2: 0.151061, l3: 0.168884, l4: 0.212517, l5: 0.296128, l6: 0.487432\n",
      "\n",
      "[epoch: 339/400, batch: 472/1000, ite: 45185] train loss: 1.3230, accuracy: 92.3617%, tar: 0.0417 \n",
      "l0: 0.163271, l1: 0.162000, l2: 0.175803, l3: 0.202825, l4: 0.264154, l5: 0.348104, l6: 0.589608\n",
      "\n",
      "[epoch: 339/400, batch: 480/1000, ite: 45186] train loss: 1.3240, accuracy: 89.7807%, tar: 0.0418 \n",
      "l0: 0.192003, l1: 0.189307, l2: 0.196731, l3: 0.223341, l4: 0.270382, l5: 0.379777, l6: 0.506726\n",
      "\n",
      "[epoch: 339/400, batch: 488/1000, ite: 45187] train loss: 1.3251, accuracy: 91.7278%, tar: 0.0419 \n",
      "l0: 0.170380, l1: 0.177142, l2: 0.178723, l3: 0.200104, l4: 0.268828, l5: 0.398871, l6: 0.642710\n",
      "\n",
      "[epoch: 339/400, batch: 496/1000, ite: 45188] train loss: 1.3262, accuracy: 89.5269%, tar: 0.0420 \n",
      "l0: 0.162476, l1: 0.168995, l2: 0.173320, l3: 0.202478, l4: 0.321719, l5: 0.486522, l6: 0.611258\n",
      "\n",
      "[epoch: 339/400, batch: 504/1000, ite: 45189] train loss: 1.3274, accuracy: 92.1351%, tar: 0.0421 \n",
      "l0: 0.182835, l1: 0.197279, l2: 0.191729, l3: 0.216969, l4: 0.269194, l5: 0.389191, l6: 0.617176\n",
      "\n",
      "[epoch: 339/400, batch: 512/1000, ite: 45190] train loss: 1.3286, accuracy: 89.7272%, tar: 0.0423 \n",
      "l0: 0.107286, l1: 0.105009, l2: 0.109437, l3: 0.123900, l4: 0.150867, l5: 0.239595, l6: 0.426205\n",
      "\n",
      "[epoch: 339/400, batch: 520/1000, ite: 45191] train loss: 1.3289, accuracy: 92.1299%, tar: 0.0423 \n",
      "l0: 0.126391, l1: 0.133938, l2: 0.137251, l3: 0.151706, l4: 0.186921, l5: 0.286912, l6: 0.509798\n",
      "\n",
      "[epoch: 339/400, batch: 528/1000, ite: 45192] train loss: 1.3295, accuracy: 91.5046%, tar: 0.0424 \n",
      "l0: 0.108256, l1: 0.106093, l2: 0.113399, l3: 0.141616, l4: 0.188913, l5: 0.313530, l6: 0.488341\n",
      "\n",
      "[epoch: 339/400, batch: 536/1000, ite: 45193] train loss: 1.3301, accuracy: 91.0046%, tar: 0.0424 \n",
      "l0: 0.115332, l1: 0.116788, l2: 0.121050, l3: 0.145309, l4: 0.209433, l5: 0.332781, l6: 0.551368\n",
      "\n",
      "[epoch: 339/400, batch: 544/1000, ite: 45194] train loss: 1.3307, accuracy: 90.8811%, tar: 0.0425 \n",
      "l0: 0.157855, l1: 0.156938, l2: 0.164006, l3: 0.180924, l4: 0.219756, l5: 0.305684, l6: 0.506778\n",
      "\n",
      "[epoch: 339/400, batch: 552/1000, ite: 45195] train loss: 1.3315, accuracy: 91.3254%, tar: 0.0426 \n",
      "l0: 0.129502, l1: 0.130789, l2: 0.133228, l3: 0.147995, l4: 0.201326, l5: 0.314548, l6: 0.526227\n",
      "\n",
      "[epoch: 339/400, batch: 560/1000, ite: 45196] train loss: 1.3322, accuracy: 91.4586%, tar: 0.0427 \n",
      "l0: 0.354838, l1: 0.368562, l2: 0.372179, l3: 0.402795, l4: 0.443053, l5: 0.527046, l6: 0.771499\n",
      "\n",
      "[epoch: 339/400, batch: 568/1000, ite: 45197] train loss: 1.3344, accuracy: 88.3316%, tar: 0.0429 \n",
      "l0: 0.091406, l1: 0.091629, l2: 0.096993, l3: 0.112840, l4: 0.154722, l5: 0.236863, l6: 0.379457\n",
      "\n",
      "[epoch: 339/400, batch: 576/1000, ite: 45198] train loss: 1.3346, accuracy: 92.6505%, tar: 0.0430 \n",
      "l0: 0.223285, l1: 0.223331, l2: 0.238380, l3: 0.231787, l4: 0.239602, l5: 0.269578, l6: 0.380544\n",
      "\n",
      "[epoch: 339/400, batch: 584/1000, ite: 45199] train loss: 1.3353, accuracy: 90.4762%, tar: 0.0431 \n",
      "l0: 0.058865, l1: 0.059571, l2: 0.065259, l3: 0.082162, l4: 0.117664, l5: 0.200387, l6: 0.332354\n",
      "\n",
      "[epoch: 339/400, batch: 592/1000, ite: 45200] train loss: 1.3353, accuracy: 94.2534%, tar: 0.0431 \n",
      "l0: 0.176008, l1: 0.170863, l2: 0.184515, l3: 0.211957, l4: 0.283689, l5: 0.404092, l6: 0.651955\n",
      "\n",
      "[epoch: 339/400, batch: 600/1000, ite: 45201] train loss: 1.3364, accuracy: 89.9027%, tar: 0.0433 \n",
      "l0: 0.144094, l1: 0.146621, l2: 0.155470, l3: 0.178994, l4: 0.234519, l5: 0.352004, l6: 0.547415\n",
      "\n",
      "[epoch: 339/400, batch: 608/1000, ite: 45202] train loss: 1.3372, accuracy: 90.9051%, tar: 0.0433 \n",
      "l0: 0.303501, l1: 0.312024, l2: 0.332479, l3: 0.380533, l4: 0.463655, l5: 0.588003, l6: 0.817483\n",
      "\n",
      "[epoch: 339/400, batch: 616/1000, ite: 45203] train loss: 1.3395, accuracy: 87.8058%, tar: 0.0436 \n",
      "l0: 0.135600, l1: 0.137866, l2: 0.139176, l3: 0.156086, l4: 0.182926, l5: 0.247658, l6: 0.383838\n",
      "\n",
      "[epoch: 339/400, batch: 624/1000, ite: 45204] train loss: 1.3398, accuracy: 92.0210%, tar: 0.0436 \n",
      "l0: 0.092659, l1: 0.091399, l2: 0.095593, l3: 0.104146, l4: 0.129164, l5: 0.190836, l6: 0.308285\n",
      "\n",
      "[epoch: 339/400, batch: 632/1000, ite: 45205] train loss: 1.3398, accuracy: 94.6677%, tar: 0.0437 \n",
      "l0: 0.293151, l1: 0.305545, l2: 0.295899, l3: 0.310670, l4: 0.347476, l5: 0.470517, l6: 0.738514\n",
      "\n",
      "[epoch: 339/400, batch: 640/1000, ite: 45206] train loss: 1.3416, accuracy: 88.1155%, tar: 0.0439 \n",
      "l0: 0.068482, l1: 0.068457, l2: 0.071329, l3: 0.087825, l4: 0.152872, l5: 0.263712, l6: 0.334105\n",
      "\n",
      "[epoch: 339/400, batch: 648/1000, ite: 45207] train loss: 1.3417, accuracy: 93.7207%, tar: 0.0439 \n",
      "l0: 0.099544, l1: 0.106112, l2: 0.111894, l3: 0.126875, l4: 0.181424, l5: 0.314816, l6: 0.472770\n",
      "\n",
      "[epoch: 339/400, batch: 656/1000, ite: 45208] train loss: 1.3422, accuracy: 92.3394%, tar: 0.0439 \n",
      "l0: 0.132826, l1: 0.131669, l2: 0.140616, l3: 0.155065, l4: 0.187387, l5: 0.287968, l6: 0.420688\n",
      "\n",
      "[epoch: 339/400, batch: 664/1000, ite: 45209] train loss: 1.3426, accuracy: 91.8097%, tar: 0.0440 \n",
      "l0: 0.084903, l1: 0.097475, l2: 0.103526, l3: 0.115107, l4: 0.152041, l5: 0.234661, l6: 0.419577\n",
      "\n",
      "[epoch: 339/400, batch: 672/1000, ite: 45210] train loss: 1.3429, accuracy: 93.3911%, tar: 0.0440 \n",
      "l0: 0.123485, l1: 0.126708, l2: 0.130142, l3: 0.149946, l4: 0.208654, l5: 0.307635, l6: 0.518275\n",
      "\n",
      "[epoch: 339/400, batch: 680/1000, ite: 45211] train loss: 1.3435, accuracy: 91.3586%, tar: 0.0441 \n",
      "l0: 0.112731, l1: 0.114467, l2: 0.119806, l3: 0.143261, l4: 0.184396, l5: 0.244135, l6: 0.417453\n",
      "\n",
      "[epoch: 339/400, batch: 688/1000, ite: 45212] train loss: 1.3438, accuracy: 91.7923%, tar: 0.0442 \n",
      "l0: 0.125400, l1: 0.123974, l2: 0.127666, l3: 0.147937, l4: 0.196991, l5: 0.312833, l6: 0.515208\n",
      "\n",
      "[epoch: 339/400, batch: 696/1000, ite: 45213] train loss: 1.3444, accuracy: 90.8501%, tar: 0.0442 \n",
      "l0: 0.137411, l1: 0.131317, l2: 0.139730, l3: 0.163213, l4: 0.246100, l5: 0.409332, l6: 0.756197\n",
      "\n",
      "[epoch: 339/400, batch: 704/1000, ite: 45214] train loss: 1.3456, accuracy: 89.0678%, tar: 0.0443 \n",
      "l0: 0.175223, l1: 0.188622, l2: 0.197644, l3: 0.212376, l4: 0.255683, l5: 0.302211, l6: 0.557203\n",
      "\n",
      "[epoch: 339/400, batch: 712/1000, ite: 45215] train loss: 1.3465, accuracy: 90.9584%, tar: 0.0444 \n",
      "l0: 0.188114, l1: 0.185247, l2: 0.193640, l3: 0.211077, l4: 0.231817, l5: 0.281061, l6: 0.396176\n",
      "\n",
      "[epoch: 339/400, batch: 720/1000, ite: 45216] train loss: 1.3471, accuracy: 92.3969%, tar: 0.0445 \n",
      "l0: 0.393234, l1: 0.388156, l2: 0.402805, l3: 0.420398, l4: 0.442472, l5: 0.553037, l6: 0.520541\n",
      "\n",
      "[epoch: 339/400, batch: 728/1000, ite: 45217] train loss: 1.3490, accuracy: 88.5897%, tar: 0.0448 \n",
      "l0: 0.093016, l1: 0.092556, l2: 0.099084, l3: 0.115971, l4: 0.153910, l5: 0.270433, l6: 0.447275\n",
      "\n",
      "[epoch: 339/400, batch: 736/1000, ite: 45218] train loss: 1.3493, accuracy: 91.3294%, tar: 0.0449 \n",
      "l0: 0.130364, l1: 0.135098, l2: 0.144898, l3: 0.170362, l4: 0.231066, l5: 0.357216, l6: 0.549839\n",
      "\n",
      "[epoch: 339/400, batch: 744/1000, ite: 45219] train loss: 1.3501, accuracy: 91.5014%, tar: 0.0449 \n",
      "l0: 0.102046, l1: 0.101136, l2: 0.111027, l3: 0.128994, l4: 0.175582, l5: 0.285425, l6: 0.532139\n",
      "\n",
      "[epoch: 339/400, batch: 752/1000, ite: 45220] train loss: 1.3506, accuracy: 91.0746%, tar: 0.0450 \n",
      "l0: 0.155216, l1: 0.153783, l2: 0.162090, l3: 0.174810, l4: 0.231438, l5: 0.342045, l6: 0.570984\n",
      "\n",
      "[epoch: 339/400, batch: 760/1000, ite: 45221] train loss: 1.3514, accuracy: 89.9008%, tar: 0.0451 \n",
      "l0: 0.139561, l1: 0.132919, l2: 0.142603, l3: 0.166903, l4: 0.220933, l5: 0.349466, l6: 0.628942\n",
      "\n",
      "[epoch: 339/400, batch: 768/1000, ite: 45222] train loss: 1.3523, accuracy: 89.9063%, tar: 0.0452 \n",
      "l0: 0.129976, l1: 0.126888, l2: 0.134085, l3: 0.143313, l4: 0.205688, l5: 0.320895, l6: 0.514982\n",
      "\n",
      "[epoch: 339/400, batch: 776/1000, ite: 45223] train loss: 1.3530, accuracy: 90.3795%, tar: 0.0452 \n",
      "l0: 0.109565, l1: 0.108939, l2: 0.116280, l3: 0.143665, l4: 0.204393, l5: 0.357498, l6: 0.616044\n",
      "\n",
      "[epoch: 339/400, batch: 784/1000, ite: 45224] train loss: 1.3538, accuracy: 90.8128%, tar: 0.0453 \n",
      "l0: 0.170185, l1: 0.176645, l2: 0.178469, l3: 0.204780, l4: 0.300215, l5: 0.405877, l6: 0.633621\n",
      "\n",
      "[epoch: 339/400, batch: 792/1000, ite: 45225] train loss: 1.3549, accuracy: 89.5903%, tar: 0.0454 \n",
      "l0: 0.211790, l1: 0.221233, l2: 0.223497, l3: 0.247080, l4: 0.313255, l5: 0.445922, l6: 0.591361\n",
      "\n",
      "[epoch: 339/400, batch: 800/1000, ite: 45226] train loss: 1.3561, accuracy: 89.0273%, tar: 0.0455 \n",
      "l0: 0.159686, l1: 0.175165, l2: 0.184868, l3: 0.196828, l4: 0.254828, l5: 0.394427, l6: 0.611378\n",
      "\n",
      "[epoch: 339/400, batch: 808/1000, ite: 45227] train loss: 1.3572, accuracy: 90.8284%, tar: 0.0456 \n",
      "l0: 0.083230, l1: 0.083347, l2: 0.087040, l3: 0.103775, l4: 0.144544, l5: 0.229268, l6: 0.373573\n",
      "\n",
      "[epoch: 339/400, batch: 816/1000, ite: 45228] train loss: 1.3573, accuracy: 92.7244%, tar: 0.0456 \n",
      "l0: 0.093395, l1: 0.096895, l2: 0.105926, l3: 0.131281, l4: 0.184997, l5: 0.290048, l6: 0.569944\n",
      "\n",
      "[epoch: 339/400, batch: 824/1000, ite: 45229] train loss: 1.3579, accuracy: 91.2008%, tar: 0.0457 \n",
      "l0: 0.064985, l1: 0.067329, l2: 0.075338, l3: 0.090500, l4: 0.147932, l5: 0.257661, l6: 0.435126\n",
      "\n",
      "[epoch: 339/400, batch: 832/1000, ite: 45230] train loss: 1.3580, accuracy: 93.1193%, tar: 0.0457 \n",
      "l0: 0.183337, l1: 0.194723, l2: 0.199396, l3: 0.209865, l4: 0.237349, l5: 0.369499, l6: 0.501861\n",
      "\n",
      "[epoch: 339/400, batch: 840/1000, ite: 45231] train loss: 1.3589, accuracy: 90.7963%, tar: 0.0458 \n",
      "l0: 0.090585, l1: 0.090577, l2: 0.098609, l3: 0.117544, l4: 0.166720, l5: 0.255504, l6: 0.395059\n",
      "\n",
      "[epoch: 339/400, batch: 848/1000, ite: 45232] train loss: 1.3591, accuracy: 93.0513%, tar: 0.0458 \n",
      "l0: 0.254818, l1: 0.269513, l2: 0.270066, l3: 0.293067, l4: 0.343183, l5: 0.525764, l6: 0.875704\n",
      "\n",
      "[epoch: 339/400, batch: 856/1000, ite: 45233] train loss: 1.3610, accuracy: 85.5660%, tar: 0.0460 \n",
      "l0: 0.096937, l1: 0.095574, l2: 0.104746, l3: 0.126926, l4: 0.181833, l5: 0.282712, l6: 0.565118\n",
      "\n",
      "[epoch: 339/400, batch: 864/1000, ite: 45234] train loss: 1.3616, accuracy: 91.3207%, tar: 0.0460 \n",
      "l0: 0.116662, l1: 0.115132, l2: 0.136178, l3: 0.170544, l4: 0.210531, l5: 0.253798, l6: 0.443974\n",
      "\n",
      "[epoch: 339/400, batch: 872/1000, ite: 45235] train loss: 1.3620, accuracy: 93.3630%, tar: 0.0461 \n",
      "l0: 0.274359, l1: 0.297464, l2: 0.299911, l3: 0.323480, l4: 0.345879, l5: 0.431820, l6: 0.558538\n",
      "\n",
      "[epoch: 339/400, batch: 880/1000, ite: 45236] train loss: 1.3634, accuracy: 90.0740%, tar: 0.0463 \n",
      "l0: 0.164532, l1: 0.166953, l2: 0.177463, l3: 0.195851, l4: 0.249570, l5: 0.312694, l6: 0.431210\n",
      "\n",
      "[epoch: 339/400, batch: 888/1000, ite: 45237] train loss: 1.3641, accuracy: 91.2698%, tar: 0.0464 \n",
      "l0: 0.104901, l1: 0.104640, l2: 0.112176, l3: 0.134145, l4: 0.182310, l5: 0.311359, l6: 0.567321\n",
      "\n",
      "[epoch: 339/400, batch: 896/1000, ite: 45238] train loss: 1.3647, accuracy: 90.8287%, tar: 0.0464 \n",
      "l0: 0.086362, l1: 0.082795, l2: 0.088993, l3: 0.108029, l4: 0.149286, l5: 0.275494, l6: 0.484517\n",
      "\n",
      "[epoch: 339/400, batch: 904/1000, ite: 45239] train loss: 1.3650, accuracy: 92.0525%, tar: 0.0465 \n",
      "l0: 0.171290, l1: 0.164353, l2: 0.176066, l3: 0.200555, l4: 0.262856, l5: 0.361144, l6: 0.562359\n",
      "\n",
      "[epoch: 339/400, batch: 912/1000, ite: 45240] train loss: 1.3659, accuracy: 89.9417%, tar: 0.0466 \n",
      "l0: 0.074894, l1: 0.074791, l2: 0.083109, l3: 0.106509, l4: 0.176203, l5: 0.274881, l6: 0.463435\n",
      "\n",
      "[epoch: 339/400, batch: 920/1000, ite: 45241] train loss: 1.3662, accuracy: 92.1185%, tar: 0.0466 \n",
      "l0: 0.124952, l1: 0.131053, l2: 0.134571, l3: 0.158119, l4: 0.206888, l5: 0.294717, l6: 0.491278\n",
      "\n",
      "[epoch: 339/400, batch: 928/1000, ite: 45242] train loss: 1.3667, accuracy: 91.8733%, tar: 0.0467 \n",
      "l0: 0.089662, l1: 0.089854, l2: 0.094484, l3: 0.115670, l4: 0.181200, l5: 0.348991, l6: 0.595658\n",
      "\n",
      "[epoch: 339/400, batch: 936/1000, ite: 45243] train loss: 1.3673, accuracy: 90.4430%, tar: 0.0467 \n",
      "l0: 0.077342, l1: 0.081285, l2: 0.091258, l3: 0.112607, l4: 0.178415, l5: 0.295064, l6: 0.465777\n",
      "\n",
      "[epoch: 339/400, batch: 944/1000, ite: 45244] train loss: 1.3677, accuracy: 92.4873%, tar: 0.0467 \n",
      "l0: 0.133413, l1: 0.145453, l2: 0.158589, l3: 0.172832, l4: 0.206540, l5: 0.278244, l6: 0.413558\n",
      "\n",
      "[epoch: 339/400, batch: 952/1000, ite: 45245] train loss: 1.3681, accuracy: 91.9389%, tar: 0.0468 \n",
      "l0: 0.066276, l1: 0.066909, l2: 0.073864, l3: 0.092748, l4: 0.151585, l5: 0.269069, l6: 0.478457\n",
      "\n",
      "[epoch: 339/400, batch: 960/1000, ite: 45246] train loss: 1.3684, accuracy: 93.4436%, tar: 0.0468 \n",
      "l0: 0.104402, l1: 0.102798, l2: 0.105963, l3: 0.118863, l4: 0.149277, l5: 0.238818, l6: 0.414820\n",
      "\n",
      "[epoch: 339/400, batch: 968/1000, ite: 45247] train loss: 1.3686, accuracy: 91.6202%, tar: 0.0468 \n",
      "l0: 0.080870, l1: 0.081428, l2: 0.085565, l3: 0.108487, l4: 0.167306, l5: 0.279820, l6: 0.460072\n",
      "\n",
      "[epoch: 339/400, batch: 976/1000, ite: 45248] train loss: 1.3689, accuracy: 93.0842%, tar: 0.0469 \n",
      "l0: 0.093081, l1: 0.093807, l2: 0.101299, l3: 0.125959, l4: 0.189031, l5: 0.283682, l6: 0.484697\n",
      "\n",
      "[epoch: 339/400, batch: 984/1000, ite: 45249] train loss: 1.3693, accuracy: 92.0335%, tar: 0.0469 \n",
      "l0: 0.136252, l1: 0.135171, l2: 0.141175, l3: 0.155437, l4: 0.195667, l5: 0.310849, l6: 0.432873\n",
      "\n",
      "[epoch: 339/400, batch: 992/1000, ite: 45250] train loss: 1.3698, accuracy: 90.6652%, tar: 0.0470 \n",
      "l0: 0.079188, l1: 0.079728, l2: 0.085836, l3: 0.109557, l4: 0.158460, l5: 0.261136, l6: 0.394587\n",
      "\n",
      "[epoch: 339/400, batch: 1000/1000, ite: 45251] train loss: 1.3699, accuracy: 92.6171%, tar: 0.0470 \n",
      "l0: 0.095623, l1: 0.095395, l2: 0.102611, l3: 0.120739, l4: 0.174525, l5: 0.264989, l6: 0.437096\n",
      "\n",
      "[epoch: 340/400, batch: 8/1000, ite: 45252] train loss: 1.3702, accuracy: 91.6219%, tar: 0.0470 \n",
      "l0: 0.082748, l1: 0.084453, l2: 0.090420, l3: 0.111667, l4: 0.156798, l5: 0.251311, l6: 0.490846\n",
      "\n",
      "[epoch: 340/400, batch: 16/1000, ite: 45253] train loss: 1.3705, accuracy: 92.4441%, tar: 0.0471 \n",
      "l0: 0.071352, l1: 0.075358, l2: 0.080256, l3: 0.098078, l4: 0.145877, l5: 0.223738, l6: 0.428256\n",
      "\n",
      "[epoch: 340/400, batch: 24/1000, ite: 45254] train loss: 1.3707, accuracy: 93.4931%, tar: 0.0471 \n",
      "l0: 0.208775, l1: 0.219553, l2: 0.222505, l3: 0.232036, l4: 0.244581, l5: 0.290408, l6: 0.460571\n",
      "\n",
      "[epoch: 340/400, batch: 32/1000, ite: 45255] train loss: 1.3714, accuracy: 92.2637%, tar: 0.0472 \n",
      "l0: 0.063048, l1: 0.064619, l2: 0.069901, l3: 0.087118, l4: 0.135018, l5: 0.229342, l6: 0.380117\n",
      "\n",
      "[epoch: 340/400, batch: 40/1000, ite: 45256] train loss: 1.3714, accuracy: 94.3825%, tar: 0.0472 \n",
      "l0: 0.075129, l1: 0.075561, l2: 0.081257, l3: 0.102445, l4: 0.159729, l5: 0.256789, l6: 0.373500\n",
      "\n",
      "[epoch: 340/400, batch: 48/1000, ite: 45257] train loss: 1.3716, accuracy: 92.8459%, tar: 0.0473 \n",
      "l0: 0.113616, l1: 0.118243, l2: 0.125980, l3: 0.146000, l4: 0.202223, l5: 0.303543, l6: 0.470140\n",
      "\n",
      "[epoch: 340/400, batch: 56/1000, ite: 45258] train loss: 1.3720, accuracy: 92.2462%, tar: 0.0473 \n",
      "l0: 0.147509, l1: 0.143280, l2: 0.148874, l3: 0.170607, l4: 0.228185, l5: 0.356536, l6: 0.609509\n",
      "\n",
      "[epoch: 340/400, batch: 64/1000, ite: 45259] train loss: 1.3729, accuracy: 90.9695%, tar: 0.0474 \n",
      "l0: 0.094446, l1: 0.099564, l2: 0.106037, l3: 0.122500, l4: 0.163596, l5: 0.235384, l6: 0.360524\n",
      "\n",
      "[epoch: 340/400, batch: 72/1000, ite: 45260] train loss: 1.3730, accuracy: 92.7306%, tar: 0.0474 \n",
      "l0: 0.156625, l1: 0.158491, l2: 0.167951, l3: 0.188136, l4: 0.276305, l5: 0.431575, l6: 0.576952\n",
      "\n",
      "[epoch: 340/400, batch: 80/1000, ite: 45261] train loss: 1.3740, accuracy: 90.2438%, tar: 0.0475 \n",
      "l0: 0.123574, l1: 0.129613, l2: 0.135614, l3: 0.153539, l4: 0.194749, l5: 0.257309, l6: 0.462329\n",
      "\n",
      "[epoch: 340/400, batch: 88/1000, ite: 45262] train loss: 1.3744, accuracy: 92.4328%, tar: 0.0476 \n",
      "l0: 0.071068, l1: 0.070882, l2: 0.081391, l3: 0.100300, l4: 0.147579, l5: 0.247370, l6: 0.481659\n",
      "\n",
      "[epoch: 340/400, batch: 96/1000, ite: 45263] train loss: 1.3747, accuracy: 92.6829%, tar: 0.0476 \n",
      "l0: 0.054317, l1: 0.055841, l2: 0.061164, l3: 0.082321, l4: 0.139087, l5: 0.241156, l6: 0.402715\n",
      "\n",
      "[epoch: 340/400, batch: 104/1000, ite: 45264] train loss: 1.3748, accuracy: 93.1251%, tar: 0.0476 \n",
      "l0: 0.062759, l1: 0.065595, l2: 0.074413, l3: 0.095787, l4: 0.135833, l5: 0.214718, l6: 0.407935\n",
      "\n",
      "[epoch: 340/400, batch: 112/1000, ite: 45265] train loss: 1.3748, accuracy: 94.3298%, tar: 0.0476 \n",
      "l0: 0.081644, l1: 0.083213, l2: 0.090019, l3: 0.112265, l4: 0.175050, l5: 0.323463, l6: 0.591342\n",
      "\n",
      "[epoch: 340/400, batch: 120/1000, ite: 45266] train loss: 1.3754, accuracy: 91.2063%, tar: 0.0476 \n",
      "l0: 0.070664, l1: 0.071714, l2: 0.080328, l3: 0.098154, l4: 0.147900, l5: 0.280699, l6: 0.440137\n",
      "\n",
      "[epoch: 340/400, batch: 128/1000, ite: 45267] train loss: 1.3756, accuracy: 92.3745%, tar: 0.0477 \n",
      "l0: 0.070576, l1: 0.075684, l2: 0.081275, l3: 0.100762, l4: 0.140754, l5: 0.241360, l6: 0.447184\n",
      "\n",
      "[epoch: 340/400, batch: 136/1000, ite: 45268] train loss: 1.3758, accuracy: 93.7204%, tar: 0.0477 \n",
      "l0: 0.115839, l1: 0.137182, l2: 0.143980, l3: 0.161253, l4: 0.248641, l5: 0.374612, l6: 0.630206\n",
      "\n",
      "[epoch: 340/400, batch: 144/1000, ite: 45269] train loss: 1.3766, accuracy: 91.4190%, tar: 0.0477 \n",
      "l0: 0.066481, l1: 0.068115, l2: 0.075953, l3: 0.098145, l4: 0.167276, l5: 0.263437, l6: 0.450977\n",
      "\n",
      "[epoch: 340/400, batch: 152/1000, ite: 45270] train loss: 1.3768, accuracy: 92.7705%, tar: 0.0477 \n",
      "l0: 0.161138, l1: 0.170357, l2: 0.171639, l3: 0.175485, l4: 0.211930, l5: 0.296547, l6: 0.517518\n",
      "\n",
      "[epoch: 340/400, batch: 160/1000, ite: 45271] train loss: 1.3775, accuracy: 91.4838%, tar: 0.0478 \n",
      "l0: 0.085117, l1: 0.085541, l2: 0.091631, l3: 0.109373, l4: 0.165600, l5: 0.289444, l6: 0.471980\n",
      "\n",
      "[epoch: 340/400, batch: 168/1000, ite: 45272] train loss: 1.3778, accuracy: 92.0545%, tar: 0.0479 \n",
      "l0: 0.069589, l1: 0.070612, l2: 0.077049, l3: 0.096340, l4: 0.159499, l5: 0.267672, l6: 0.451713\n",
      "\n",
      "[epoch: 340/400, batch: 176/1000, ite: 45273] train loss: 1.3780, accuracy: 92.3785%, tar: 0.0479 \n",
      "l0: 0.044745, l1: 0.044514, l2: 0.049033, l3: 0.064602, l4: 0.106350, l5: 0.182571, l6: 0.300932\n",
      "\n",
      "[epoch: 340/400, batch: 184/1000, ite: 45274] train loss: 1.3778, accuracy: 94.3228%, tar: 0.0479 \n",
      "l0: 0.082936, l1: 0.082232, l2: 0.089503, l3: 0.112284, l4: 0.189016, l5: 0.357616, l6: 0.621390\n",
      "\n",
      "[epoch: 340/400, batch: 192/1000, ite: 45275] train loss: 1.3784, accuracy: 92.1366%, tar: 0.0479 \n",
      "l0: 0.079039, l1: 0.079257, l2: 0.085685, l3: 0.110203, l4: 0.172526, l5: 0.283139, l6: 0.552698\n",
      "\n",
      "[epoch: 340/400, batch: 200/1000, ite: 45276] train loss: 1.3789, accuracy: 91.2261%, tar: 0.0479 \n",
      "l0: 0.054853, l1: 0.055955, l2: 0.063331, l3: 0.080118, l4: 0.130022, l5: 0.245408, l6: 0.479816\n",
      "\n",
      "[epoch: 340/400, batch: 208/1000, ite: 45277] train loss: 1.3791, accuracy: 93.2484%, tar: 0.0479 \n",
      "l0: 0.080887, l1: 0.083237, l2: 0.090771, l3: 0.112105, l4: 0.176494, l5: 0.312469, l6: 0.571931\n",
      "\n",
      "[epoch: 340/400, batch: 216/1000, ite: 45278] train loss: 1.3796, accuracy: 90.9189%, tar: 0.0480 \n",
      "l0: 0.057033, l1: 0.057536, l2: 0.064335, l3: 0.085006, l4: 0.133150, l5: 0.207852, l6: 0.414426\n",
      "\n",
      "[epoch: 340/400, batch: 224/1000, ite: 45279] train loss: 1.3796, accuracy: 93.0495%, tar: 0.0480 \n",
      "l0: 0.062650, l1: 0.064585, l2: 0.071026, l3: 0.088922, l4: 0.133958, l5: 0.224707, l6: 0.405293\n",
      "\n",
      "[epoch: 340/400, batch: 232/1000, ite: 45280] train loss: 1.3797, accuracy: 93.2666%, tar: 0.0480 \n",
      "l0: 0.064396, l1: 0.067501, l2: 0.076757, l3: 0.095534, l4: 0.144227, l5: 0.246638, l6: 0.457387\n",
      "\n",
      "[epoch: 340/400, batch: 240/1000, ite: 45281] train loss: 1.3799, accuracy: 92.8087%, tar: 0.0480 \n",
      "l0: 0.082062, l1: 0.082957, l2: 0.091664, l3: 0.111910, l4: 0.169148, l5: 0.306895, l6: 0.532826\n",
      "\n",
      "[epoch: 340/400, batch: 248/1000, ite: 45282] train loss: 1.3803, accuracy: 92.4004%, tar: 0.0480 \n",
      "l0: 0.076631, l1: 0.079215, l2: 0.088002, l3: 0.108482, l4: 0.149699, l5: 0.241321, l6: 0.417512\n",
      "\n",
      "[epoch: 340/400, batch: 256/1000, ite: 45283] train loss: 1.3805, accuracy: 93.9757%, tar: 0.0480 \n",
      "l0: 0.052466, l1: 0.053044, l2: 0.062406, l3: 0.083307, l4: 0.126544, l5: 0.208452, l6: 0.383235\n",
      "\n",
      "[epoch: 340/400, batch: 264/1000, ite: 45284] train loss: 1.3805, accuracy: 93.8558%, tar: 0.0480 \n",
      "l0: 0.055317, l1: 0.056560, l2: 0.062110, l3: 0.080568, l4: 0.123618, l5: 0.198684, l6: 0.339441\n",
      "\n",
      "[epoch: 340/400, batch: 272/1000, ite: 45285] train loss: 1.3804, accuracy: 94.1293%, tar: 0.0480 \n",
      "l0: 0.068078, l1: 0.070169, l2: 0.078776, l3: 0.097445, l4: 0.136304, l5: 0.213045, l6: 0.408717\n",
      "\n",
      "[epoch: 340/400, batch: 280/1000, ite: 45286] train loss: 1.3805, accuracy: 94.3569%, tar: 0.0481 \n",
      "l0: 0.056034, l1: 0.058227, l2: 0.068064, l3: 0.091335, l4: 0.156553, l5: 0.287900, l6: 0.517321\n",
      "\n",
      "[epoch: 340/400, batch: 288/1000, ite: 45287] train loss: 1.3808, accuracy: 92.6897%, tar: 0.0481 \n",
      "l0: 0.059281, l1: 0.058501, l2: 0.066095, l3: 0.080318, l4: 0.106398, l5: 0.175763, l6: 0.309781\n",
      "\n",
      "[epoch: 340/400, batch: 296/1000, ite: 45288] train loss: 1.3806, accuracy: 94.0170%, tar: 0.0481 \n",
      "l0: 0.077159, l1: 0.077641, l2: 0.084659, l3: 0.103888, l4: 0.155456, l5: 0.264336, l6: 0.511906\n",
      "\n",
      "[epoch: 340/400, batch: 304/1000, ite: 45289] train loss: 1.3809, accuracy: 92.0652%, tar: 0.0481 \n",
      "l0: 0.069734, l1: 0.069812, l2: 0.077202, l3: 0.103670, l4: 0.151202, l5: 0.226207, l6: 0.435903\n",
      "\n",
      "[epoch: 340/400, batch: 312/1000, ite: 45290] train loss: 1.3811, accuracy: 93.2135%, tar: 0.0481 \n",
      "l0: 0.054054, l1: 0.054229, l2: 0.059713, l3: 0.074920, l4: 0.107167, l5: 0.172532, l6: 0.341954\n",
      "\n",
      "[epoch: 340/400, batch: 320/1000, ite: 45291] train loss: 1.3810, accuracy: 94.4249%, tar: 0.0481 \n",
      "l0: 0.062742, l1: 0.063572, l2: 0.071814, l3: 0.095417, l4: 0.164746, l5: 0.271489, l6: 0.443619\n",
      "\n",
      "[epoch: 340/400, batch: 328/1000, ite: 45292] train loss: 1.3812, accuracy: 92.7347%, tar: 0.0481 \n",
      "l0: 0.074020, l1: 0.076696, l2: 0.081560, l3: 0.100184, l4: 0.150447, l5: 0.242789, l6: 0.389042\n",
      "\n",
      "[epoch: 340/400, batch: 336/1000, ite: 45293] train loss: 1.3813, accuracy: 93.5479%, tar: 0.0482 \n",
      "l0: 0.062178, l1: 0.063974, l2: 0.072111, l3: 0.094197, l4: 0.155670, l5: 0.292376, l6: 0.533505\n",
      "\n",
      "[epoch: 340/400, batch: 344/1000, ite: 45294] train loss: 1.3817, accuracy: 91.9126%, tar: 0.0482 \n",
      "l0: 0.056701, l1: 0.057983, l2: 0.065912, l3: 0.085354, l4: 0.151007, l5: 0.263665, l6: 0.398500\n",
      "\n",
      "[epoch: 340/400, batch: 352/1000, ite: 45295] train loss: 1.3818, accuracy: 94.2300%, tar: 0.0482 \n",
      "l0: 0.080611, l1: 0.081725, l2: 0.089945, l3: 0.109990, l4: 0.172913, l5: 0.313502, l6: 0.579229\n",
      "\n",
      "[epoch: 340/400, batch: 360/1000, ite: 45296] train loss: 1.3823, accuracy: 90.9305%, tar: 0.0482 \n",
      "l0: 0.061857, l1: 0.062327, l2: 0.069744, l3: 0.091196, l4: 0.165187, l5: 0.301553, l6: 0.508291\n",
      "\n",
      "[epoch: 340/400, batch: 368/1000, ite: 45297] train loss: 1.3826, accuracy: 91.9218%, tar: 0.0482 \n",
      "l0: 0.076435, l1: 0.079503, l2: 0.087689, l3: 0.105828, l4: 0.163697, l5: 0.247170, l6: 0.470030\n",
      "\n",
      "[epoch: 340/400, batch: 376/1000, ite: 45298] train loss: 1.3828, accuracy: 91.7446%, tar: 0.0482 \n",
      "l0: 0.073742, l1: 0.076597, l2: 0.084578, l3: 0.108155, l4: 0.170518, l5: 0.295732, l6: 0.506923\n",
      "\n",
      "[epoch: 340/400, batch: 384/1000, ite: 45299] train loss: 1.3831, accuracy: 92.2772%, tar: 0.0482 \n",
      "l0: 0.058382, l1: 0.059788, l2: 0.069359, l3: 0.091951, l4: 0.139371, l5: 0.215617, l6: 0.363559\n",
      "\n",
      "[epoch: 340/400, batch: 392/1000, ite: 45300] train loss: 1.3831, accuracy: 93.3891%, tar: 0.0483 \n",
      "l0: 0.064134, l1: 0.065838, l2: 0.073980, l3: 0.093856, l4: 0.148326, l5: 0.254010, l6: 0.429061\n",
      "\n",
      "[epoch: 340/400, batch: 400/1000, ite: 45301] train loss: 1.3833, accuracy: 92.7717%, tar: 0.0483 \n",
      "l0: 0.041379, l1: 0.042486, l2: 0.051590, l3: 0.070830, l4: 0.110475, l5: 0.166811, l6: 0.350672\n",
      "\n",
      "[epoch: 340/400, batch: 408/1000, ite: 45302] train loss: 1.3831, accuracy: 95.2172%, tar: 0.0483 \n",
      "l0: 0.043663, l1: 0.043846, l2: 0.049229, l3: 0.063196, l4: 0.102191, l5: 0.168097, l6: 0.345401\n",
      "\n",
      "[epoch: 340/400, batch: 416/1000, ite: 45303] train loss: 1.3830, accuracy: 95.1653%, tar: 0.0483 \n",
      "l0: 0.064081, l1: 0.065282, l2: 0.072079, l3: 0.088672, l4: 0.126042, l5: 0.204408, l6: 0.350349\n",
      "\n",
      "[epoch: 340/400, batch: 424/1000, ite: 45304] train loss: 1.3830, accuracy: 93.8602%, tar: 0.0483 \n",
      "l0: 0.065526, l1: 0.065541, l2: 0.073160, l3: 0.094349, l4: 0.138622, l5: 0.251376, l6: 0.475501\n",
      "\n",
      "[epoch: 340/400, batch: 432/1000, ite: 45305] train loss: 1.3832, accuracy: 92.2876%, tar: 0.0483 \n",
      "l0: 0.060897, l1: 0.063005, l2: 0.075560, l3: 0.111287, l4: 0.197845, l5: 0.337306, l6: 0.566279\n",
      "\n",
      "[epoch: 340/400, batch: 440/1000, ite: 45306] train loss: 1.3836, accuracy: 91.9512%, tar: 0.0483 \n",
      "l0: 0.057920, l1: 0.058391, l2: 0.066096, l3: 0.082338, l4: 0.132559, l5: 0.225612, l6: 0.414606\n",
      "\n",
      "[epoch: 340/400, batch: 448/1000, ite: 45307] train loss: 1.3837, accuracy: 92.8718%, tar: 0.0483 \n",
      "l0: 0.058657, l1: 0.058794, l2: 0.066954, l3: 0.089313, l4: 0.142885, l5: 0.250324, l6: 0.456575\n",
      "\n",
      "[epoch: 340/400, batch: 456/1000, ite: 45308] train loss: 1.3839, accuracy: 92.2918%, tar: 0.0483 \n",
      "l0: 0.050182, l1: 0.051683, l2: 0.061130, l3: 0.088679, l4: 0.156234, l5: 0.258431, l6: 0.604396\n",
      "\n",
      "[epoch: 340/400, batch: 464/1000, ite: 45309] train loss: 1.3842, accuracy: 91.8587%, tar: 0.0483 \n",
      "l0: 0.050235, l1: 0.052558, l2: 0.059688, l3: 0.078285, l4: 0.127485, l5: 0.220268, l6: 0.438196\n",
      "\n",
      "[epoch: 340/400, batch: 472/1000, ite: 45310] train loss: 1.3843, accuracy: 93.6678%, tar: 0.0483 \n",
      "l0: 0.078168, l1: 0.077814, l2: 0.086431, l3: 0.103399, l4: 0.136549, l5: 0.227168, l6: 0.537267\n",
      "\n",
      "[epoch: 340/400, batch: 480/1000, ite: 45311] train loss: 1.3846, accuracy: 91.3774%, tar: 0.0483 \n",
      "l0: 0.061797, l1: 0.062848, l2: 0.072161, l3: 0.099878, l4: 0.154808, l5: 0.278699, l6: 0.537068\n",
      "\n",
      "[epoch: 340/400, batch: 488/1000, ite: 45312] train loss: 1.3850, accuracy: 91.8903%, tar: 0.0483 \n",
      "l0: 0.051253, l1: 0.051713, l2: 0.060567, l3: 0.085259, l4: 0.158286, l5: 0.273008, l6: 0.528808\n",
      "\n",
      "[epoch: 340/400, batch: 496/1000, ite: 45313] train loss: 1.3852, accuracy: 92.5489%, tar: 0.0483 \n",
      "l0: 0.049639, l1: 0.050803, l2: 0.056770, l3: 0.073155, l4: 0.115474, l5: 0.189135, l6: 0.366670\n",
      "\n",
      "[epoch: 340/400, batch: 504/1000, ite: 45314] train loss: 1.3851, accuracy: 93.3010%, tar: 0.0483 \n",
      "l0: 0.057743, l1: 0.059850, l2: 0.065889, l3: 0.084368, l4: 0.143972, l5: 0.262371, l6: 0.524822\n",
      "\n",
      "[epoch: 340/400, batch: 512/1000, ite: 45315] train loss: 1.3854, accuracy: 91.1340%, tar: 0.0484 \n",
      "l0: 0.061864, l1: 0.063478, l2: 0.071372, l3: 0.091731, l4: 0.153037, l5: 0.257506, l6: 0.522815\n",
      "\n",
      "[epoch: 340/400, batch: 520/1000, ite: 45316] train loss: 1.3857, accuracy: 91.0685%, tar: 0.0484 \n",
      "l0: 0.062333, l1: 0.064416, l2: 0.074589, l3: 0.107143, l4: 0.178407, l5: 0.334929, l6: 0.593970\n",
      "\n",
      "[epoch: 340/400, batch: 528/1000, ite: 45317] train loss: 1.3862, accuracy: 91.1603%, tar: 0.0484 \n",
      "l0: 0.042385, l1: 0.043046, l2: 0.049947, l3: 0.066107, l4: 0.109618, l5: 0.214687, l6: 0.368079\n",
      "\n",
      "[epoch: 340/400, batch: 536/1000, ite: 45318] train loss: 1.3861, accuracy: 94.9964%, tar: 0.0484 \n",
      "l0: 0.049472, l1: 0.050363, l2: 0.057586, l3: 0.078567, l4: 0.134177, l5: 0.242640, l6: 0.396196\n",
      "\n",
      "[epoch: 340/400, batch: 544/1000, ite: 45319] train loss: 1.3861, accuracy: 92.9543%, tar: 0.0484 \n",
      "l0: 0.057222, l1: 0.060305, l2: 0.069350, l3: 0.091830, l4: 0.134834, l5: 0.222658, l6: 0.396391\n",
      "\n",
      "[epoch: 340/400, batch: 552/1000, ite: 45320] train loss: 1.3862, accuracy: 93.7266%, tar: 0.0484 \n",
      "l0: 0.074342, l1: 0.076873, l2: 0.089056, l3: 0.126099, l4: 0.207841, l5: 0.331926, l6: 0.539351\n",
      "\n",
      "[epoch: 340/400, batch: 560/1000, ite: 45321] train loss: 1.3867, accuracy: 92.2888%, tar: 0.0484 \n",
      "l0: 0.040051, l1: 0.040255, l2: 0.045102, l3: 0.060725, l4: 0.103334, l5: 0.193385, l6: 0.424408\n",
      "\n",
      "[epoch: 340/400, batch: 568/1000, ite: 45322] train loss: 1.3866, accuracy: 93.9251%, tar: 0.0484 \n",
      "l0: 0.049476, l1: 0.050426, l2: 0.059395, l3: 0.076828, l4: 0.126153, l5: 0.193104, l6: 0.375882\n",
      "\n",
      "[epoch: 340/400, batch: 576/1000, ite: 45323] train loss: 1.3866, accuracy: 94.2002%, tar: 0.0484 \n",
      "l0: 0.056373, l1: 0.056966, l2: 0.064533, l3: 0.091436, l4: 0.154091, l5: 0.307169, l6: 0.552979\n",
      "\n",
      "[epoch: 340/400, batch: 584/1000, ite: 45324] train loss: 1.3869, accuracy: 92.2819%, tar: 0.0484 \n",
      "l0: 0.049997, l1: 0.051888, l2: 0.058794, l3: 0.078803, l4: 0.121841, l5: 0.203824, l6: 0.347269\n",
      "\n",
      "[epoch: 340/400, batch: 592/1000, ite: 45325] train loss: 1.3868, accuracy: 93.8057%, tar: 0.0484 \n",
      "l0: 0.050538, l1: 0.052661, l2: 0.061351, l3: 0.088957, l4: 0.142333, l5: 0.231674, l6: 0.425352\n",
      "\n",
      "[epoch: 340/400, batch: 600/1000, ite: 45326] train loss: 1.3869, accuracy: 93.7518%, tar: 0.0484 \n",
      "l0: 0.049602, l1: 0.052375, l2: 0.062231, l3: 0.084775, l4: 0.131225, l5: 0.221190, l6: 0.364233\n",
      "\n",
      "[epoch: 340/400, batch: 608/1000, ite: 45327] train loss: 1.3869, accuracy: 94.8705%, tar: 0.0484 \n",
      "l0: 0.054596, l1: 0.054975, l2: 0.062008, l3: 0.082395, l4: 0.136571, l5: 0.255464, l6: 0.410514\n",
      "\n",
      "[epoch: 340/400, batch: 616/1000, ite: 45328] train loss: 1.3869, accuracy: 93.1175%, tar: 0.0484 \n",
      "l0: 0.047360, l1: 0.050695, l2: 0.059916, l3: 0.079055, l4: 0.128556, l5: 0.217636, l6: 0.410931\n",
      "\n",
      "[epoch: 340/400, batch: 624/1000, ite: 45329] train loss: 1.3870, accuracy: 93.9421%, tar: 0.0484 \n",
      "l0: 0.052720, l1: 0.054267, l2: 0.061131, l3: 0.082878, l4: 0.137080, l5: 0.231968, l6: 0.407870\n",
      "\n",
      "[epoch: 340/400, batch: 632/1000, ite: 45330] train loss: 1.3870, accuracy: 92.5601%, tar: 0.0484 \n",
      "l0: 0.041658, l1: 0.041978, l2: 0.048092, l3: 0.064605, l4: 0.097858, l5: 0.171219, l6: 0.336410\n",
      "\n",
      "[epoch: 340/400, batch: 640/1000, ite: 45331] train loss: 1.3868, accuracy: 94.0007%, tar: 0.0484 \n",
      "l0: 0.043070, l1: 0.043740, l2: 0.051336, l3: 0.067472, l4: 0.106515, l5: 0.216807, l6: 0.366008\n",
      "\n",
      "[epoch: 340/400, batch: 648/1000, ite: 45332] train loss: 1.3867, accuracy: 94.7006%, tar: 0.0484 \n",
      "l0: 0.058368, l1: 0.059228, l2: 0.066192, l3: 0.084303, l4: 0.128761, l5: 0.257266, l6: 0.529982\n",
      "\n",
      "[epoch: 340/400, batch: 656/1000, ite: 45333] train loss: 1.3870, accuracy: 92.0084%, tar: 0.0484 \n",
      "l0: 0.039597, l1: 0.041153, l2: 0.047969, l3: 0.067177, l4: 0.106430, l5: 0.178903, l6: 0.345017\n",
      "\n",
      "[epoch: 340/400, batch: 664/1000, ite: 45334] train loss: 1.3868, accuracy: 94.7933%, tar: 0.0484 \n",
      "l0: 0.088591, l1: 0.089100, l2: 0.099865, l3: 0.125205, l4: 0.191259, l5: 0.319424, l6: 0.506713\n",
      "\n",
      "[epoch: 340/400, batch: 672/1000, ite: 45335] train loss: 1.3873, accuracy: 91.8711%, tar: 0.0484 \n",
      "l0: 0.042079, l1: 0.042146, l2: 0.049141, l3: 0.064004, l4: 0.100226, l5: 0.190038, l6: 0.306188\n",
      "\n",
      "[epoch: 340/400, batch: 680/1000, ite: 45336] train loss: 1.3871, accuracy: 95.5349%, tar: 0.0484 \n",
      "l0: 0.043116, l1: 0.043797, l2: 0.052361, l3: 0.070419, l4: 0.106217, l5: 0.176843, l6: 0.345795\n",
      "\n",
      "[epoch: 340/400, batch: 688/1000, ite: 45337] train loss: 1.3869, accuracy: 94.1337%, tar: 0.0484 \n",
      "l0: 0.040651, l1: 0.041389, l2: 0.047894, l3: 0.063035, l4: 0.096353, l5: 0.162618, l6: 0.286581\n",
      "\n",
      "[epoch: 340/400, batch: 696/1000, ite: 45338] train loss: 1.3867, accuracy: 94.5567%, tar: 0.0484 \n",
      "l0: 0.057238, l1: 0.057242, l2: 0.064718, l3: 0.087080, l4: 0.138297, l5: 0.227338, l6: 0.440293\n",
      "\n",
      "[epoch: 340/400, batch: 704/1000, ite: 45339] train loss: 1.3868, accuracy: 93.8148%, tar: 0.0484 \n",
      "l0: 0.044473, l1: 0.045677, l2: 0.053201, l3: 0.075884, l4: 0.127113, l5: 0.269281, l6: 0.541274\n",
      "\n",
      "[epoch: 340/400, batch: 712/1000, ite: 45340] train loss: 1.3870, accuracy: 93.0475%, tar: 0.0484 \n",
      "l0: 0.050431, l1: 0.052081, l2: 0.062147, l3: 0.086145, l4: 0.139614, l5: 0.243568, l6: 0.454921\n",
      "\n",
      "[epoch: 340/400, batch: 720/1000, ite: 45341] train loss: 1.3871, accuracy: 93.4103%, tar: 0.0484 \n",
      "l0: 0.057099, l1: 0.057926, l2: 0.066319, l3: 0.092893, l4: 0.171946, l5: 0.328215, l6: 0.583677\n",
      "\n",
      "[epoch: 340/400, batch: 728/1000, ite: 45342] train loss: 1.3875, accuracy: 90.8839%, tar: 0.0484 \n",
      "l0: 0.051065, l1: 0.052634, l2: 0.059372, l3: 0.079096, l4: 0.125561, l5: 0.199086, l6: 0.304313\n",
      "\n",
      "[epoch: 340/400, batch: 736/1000, ite: 45343] train loss: 1.3874, accuracy: 94.4994%, tar: 0.0484 \n",
      "l0: 0.056364, l1: 0.057201, l2: 0.068564, l3: 0.098660, l4: 0.158152, l5: 0.310273, l6: 0.557260\n",
      "\n",
      "[epoch: 340/400, batch: 744/1000, ite: 45344] train loss: 1.3878, accuracy: 92.1123%, tar: 0.0484 \n",
      "l0: 0.047602, l1: 0.048597, l2: 0.057647, l3: 0.078937, l4: 0.131373, l5: 0.236879, l6: 0.397440\n",
      "\n",
      "[epoch: 340/400, batch: 752/1000, ite: 45345] train loss: 1.3878, accuracy: 94.4397%, tar: 0.0484 \n",
      "l0: 0.045759, l1: 0.046212, l2: 0.053114, l3: 0.074606, l4: 0.123772, l5: 0.189109, l6: 0.319792\n",
      "\n",
      "[epoch: 340/400, batch: 760/1000, ite: 45346] train loss: 1.3876, accuracy: 93.9712%, tar: 0.0484 \n",
      "l0: 0.052686, l1: 0.054094, l2: 0.062480, l3: 0.074785, l4: 0.123974, l5: 0.187313, l6: 0.354355\n",
      "\n",
      "[epoch: 340/400, batch: 768/1000, ite: 45347] train loss: 1.3875, accuracy: 95.3556%, tar: 0.0484 \n",
      "l0: 0.044905, l1: 0.046217, l2: 0.054901, l3: 0.079004, l4: 0.132562, l5: 0.262207, l6: 0.452354\n",
      "\n",
      "[epoch: 340/400, batch: 776/1000, ite: 45348] train loss: 1.3876, accuracy: 93.1479%, tar: 0.0484 \n",
      "l0: 0.053130, l1: 0.054230, l2: 0.062451, l3: 0.083706, l4: 0.143429, l5: 0.263219, l6: 0.506919\n",
      "\n",
      "[epoch: 340/400, batch: 784/1000, ite: 45349] train loss: 1.3879, accuracy: 92.3680%, tar: 0.0484 \n",
      "l0: 0.087817, l1: 0.090322, l2: 0.101197, l3: 0.128839, l4: 0.198661, l5: 0.331625, l6: 0.637504\n",
      "\n",
      "[epoch: 340/400, batch: 792/1000, ite: 45350] train loss: 1.3885, accuracy: 91.3906%, tar: 0.0485 \n",
      "l0: 0.066491, l1: 0.070835, l2: 0.079846, l3: 0.096214, l4: 0.134606, l5: 0.207211, l6: 0.348346\n",
      "\n",
      "[epoch: 340/400, batch: 800/1000, ite: 45351] train loss: 1.3885, accuracy: 94.5042%, tar: 0.0485 \n",
      "l0: 0.042662, l1: 0.044450, l2: 0.051875, l3: 0.067683, l4: 0.099176, l5: 0.181551, l6: 0.352060\n",
      "\n",
      "[epoch: 340/400, batch: 808/1000, ite: 45352] train loss: 1.3883, accuracy: 94.6847%, tar: 0.0485 \n",
      "l0: 0.052163, l1: 0.052703, l2: 0.059664, l3: 0.074961, l4: 0.116197, l5: 0.239615, l6: 0.435194\n",
      "\n",
      "[epoch: 340/400, batch: 816/1000, ite: 45353] train loss: 1.3884, accuracy: 93.6487%, tar: 0.0485 \n",
      "l0: 0.050577, l1: 0.051721, l2: 0.058730, l3: 0.079630, l4: 0.130269, l5: 0.220299, l6: 0.425855\n",
      "\n",
      "[epoch: 340/400, batch: 824/1000, ite: 45354] train loss: 1.3885, accuracy: 92.7423%, tar: 0.0485 \n",
      "l0: 0.048643, l1: 0.049745, l2: 0.058594, l3: 0.080776, l4: 0.146445, l5: 0.253854, l6: 0.459676\n",
      "\n",
      "[epoch: 340/400, batch: 832/1000, ite: 45355] train loss: 1.3886, accuracy: 93.6076%, tar: 0.0485 \n",
      "l0: 0.025676, l1: 0.026320, l2: 0.030445, l3: 0.042421, l4: 0.074149, l5: 0.139355, l6: 0.307164\n",
      "\n",
      "[epoch: 340/400, batch: 840/1000, ite: 45356] train loss: 1.3883, accuracy: 95.5657%, tar: 0.0485 \n",
      "l0: 0.093187, l1: 0.108537, l2: 0.115278, l3: 0.125069, l4: 0.171898, l5: 0.341169, l6: 0.509521\n",
      "\n",
      "[epoch: 340/400, batch: 848/1000, ite: 45357] train loss: 1.3888, accuracy: 91.7395%, tar: 0.0485 \n",
      "l0: 0.040822, l1: 0.042223, l2: 0.049882, l3: 0.067120, l4: 0.108044, l5: 0.187868, l6: 0.346622\n",
      "\n",
      "[epoch: 340/400, batch: 856/1000, ite: 45358] train loss: 1.3886, accuracy: 94.0461%, tar: 0.0485 \n",
      "l0: 0.056906, l1: 0.057145, l2: 0.065019, l3: 0.080957, l4: 0.123959, l5: 0.221147, l6: 0.416807\n",
      "\n",
      "[epoch: 340/400, batch: 864/1000, ite: 45359] train loss: 1.3887, accuracy: 93.5328%, tar: 0.0485 \n",
      "l0: 0.046213, l1: 0.047005, l2: 0.055715, l3: 0.074694, l4: 0.120156, l5: 0.235514, l6: 0.375234\n",
      "\n",
      "[epoch: 340/400, batch: 872/1000, ite: 45360] train loss: 1.3886, accuracy: 94.5613%, tar: 0.0485 \n",
      "l0: 0.065309, l1: 0.065117, l2: 0.073467, l3: 0.088090, l4: 0.124413, l5: 0.203593, l6: 0.370839\n",
      "\n",
      "[epoch: 340/400, batch: 880/1000, ite: 45361] train loss: 1.3886, accuracy: 93.1400%, tar: 0.0485 \n",
      "l0: 0.041104, l1: 0.043428, l2: 0.051533, l3: 0.069950, l4: 0.124298, l5: 0.216237, l6: 0.369201\n",
      "\n",
      "[epoch: 340/400, batch: 888/1000, ite: 45362] train loss: 1.3886, accuracy: 95.2479%, tar: 0.0485 \n",
      "l0: 0.056016, l1: 0.056902, l2: 0.066464, l3: 0.089410, l4: 0.142764, l5: 0.247629, l6: 0.488718\n",
      "\n",
      "[epoch: 340/400, batch: 896/1000, ite: 45363] train loss: 1.3888, accuracy: 92.8666%, tar: 0.0485 \n",
      "l0: 0.047076, l1: 0.049099, l2: 0.057738, l3: 0.076444, l4: 0.121290, l5: 0.231074, l6: 0.422016\n",
      "\n",
      "[epoch: 340/400, batch: 904/1000, ite: 45364] train loss: 1.3888, accuracy: 93.1011%, tar: 0.0485 \n",
      "l0: 0.040748, l1: 0.045023, l2: 0.050890, l3: 0.076970, l4: 0.132458, l5: 0.224676, l6: 0.391989\n",
      "\n",
      "[epoch: 340/400, batch: 912/1000, ite: 45365] train loss: 1.3888, accuracy: 94.3973%, tar: 0.0485 \n",
      "l0: 0.073440, l1: 0.079578, l2: 0.092173, l3: 0.111915, l4: 0.160113, l5: 0.267371, l6: 0.492550\n",
      "\n",
      "[epoch: 340/400, batch: 920/1000, ite: 45366] train loss: 1.3891, accuracy: 91.6204%, tar: 0.0485 \n",
      "l0: 0.038152, l1: 0.040027, l2: 0.045102, l3: 0.061902, l4: 0.118368, l5: 0.222950, l6: 0.415350\n",
      "\n",
      "[epoch: 340/400, batch: 928/1000, ite: 45367] train loss: 1.3890, accuracy: 93.8476%, tar: 0.0485 \n",
      "l0: 0.051772, l1: 0.053298, l2: 0.063194, l3: 0.084102, l4: 0.130250, l5: 0.240515, l6: 0.427186\n",
      "\n",
      "[epoch: 340/400, batch: 936/1000, ite: 45368] train loss: 1.3891, accuracy: 92.4877%, tar: 0.0485 \n",
      "l0: 0.043991, l1: 0.045597, l2: 0.051311, l3: 0.068007, l4: 0.105731, l5: 0.185731, l6: 0.307076\n",
      "\n",
      "[epoch: 340/400, batch: 944/1000, ite: 45369] train loss: 1.3889, accuracy: 94.4373%, tar: 0.0485 \n",
      "l0: 0.041248, l1: 0.042618, l2: 0.053269, l3: 0.079072, l4: 0.115190, l5: 0.197642, l6: 0.374692\n",
      "\n",
      "[epoch: 340/400, batch: 952/1000, ite: 45370] train loss: 1.3889, accuracy: 94.8778%, tar: 0.0485 \n",
      "l0: 0.077165, l1: 0.099470, l2: 0.107750, l3: 0.130597, l4: 0.195067, l5: 0.303474, l6: 0.562198\n",
      "\n",
      "[epoch: 340/400, batch: 960/1000, ite: 45371] train loss: 1.3893, accuracy: 92.8965%, tar: 0.0485 \n",
      "l0: 0.243232, l1: 0.268957, l2: 0.281202, l3: 0.299480, l4: 0.326910, l5: 0.338469, l6: 0.489476\n",
      "\n",
      "[epoch: 340/400, batch: 968/1000, ite: 45372] train loss: 1.3903, accuracy: 90.8563%, tar: 0.0487 \n",
      "l0: 0.045194, l1: 0.048790, l2: 0.057340, l3: 0.077243, l4: 0.127917, l5: 0.194346, l6: 0.351567\n",
      "\n",
      "[epoch: 340/400, batch: 976/1000, ite: 45373] train loss: 1.3902, accuracy: 94.8376%, tar: 0.0487 \n",
      "l0: 0.048960, l1: 0.050424, l2: 0.057388, l3: 0.075129, l4: 0.121324, l5: 0.223685, l6: 0.383150\n",
      "\n",
      "[epoch: 340/400, batch: 984/1000, ite: 45374] train loss: 1.3902, accuracy: 93.3756%, tar: 0.0487 \n",
      "l0: 0.059237, l1: 0.059254, l2: 0.067460, l3: 0.085538, l4: 0.136790, l5: 0.246715, l6: 0.450141\n",
      "\n",
      "[epoch: 340/400, batch: 992/1000, ite: 45375] train loss: 1.3903, accuracy: 92.7886%, tar: 0.0487 \n",
      "l0: 0.052323, l1: 0.053935, l2: 0.062192, l3: 0.091478, l4: 0.172564, l5: 0.348004, l6: 0.624582\n",
      "\n",
      "[epoch: 340/400, batch: 1000/1000, ite: 45376] train loss: 1.3908, accuracy: 91.5886%, tar: 0.0487 \n",
      "l0: 0.066664, l1: 0.066528, l2: 0.075048, l3: 0.095191, l4: 0.132922, l5: 0.231049, l6: 0.447929\n",
      "\n",
      "[epoch: 341/400, batch: 8/1000, ite: 45377] train loss: 1.3909, accuracy: 91.9294%, tar: 0.0487 \n",
      "l0: 0.047446, l1: 0.050666, l2: 0.055632, l3: 0.069502, l4: 0.105621, l5: 0.173310, l6: 0.332774\n",
      "\n",
      "[epoch: 341/400, batch: 16/1000, ite: 45378] train loss: 1.3908, accuracy: 93.9308%, tar: 0.0487 \n",
      "l0: 0.050625, l1: 0.052548, l2: 0.059554, l3: 0.082634, l4: 0.154287, l5: 0.291510, l6: 0.510617\n",
      "\n",
      "[epoch: 341/400, batch: 24/1000, ite: 45379] train loss: 1.3910, accuracy: 92.6000%, tar: 0.0487 \n",
      "l0: 0.045594, l1: 0.046462, l2: 0.055411, l3: 0.072391, l4: 0.114659, l5: 0.225850, l6: 0.400373\n",
      "\n",
      "[epoch: 341/400, batch: 32/1000, ite: 45380] train loss: 1.3910, accuracy: 93.5559%, tar: 0.0487 \n",
      "l0: 0.068151, l1: 0.068310, l2: 0.077098, l3: 0.094476, l4: 0.132172, l5: 0.200991, l6: 0.398076\n",
      "\n",
      "[epoch: 341/400, batch: 40/1000, ite: 45381] train loss: 1.3910, accuracy: 93.2622%, tar: 0.0487 \n",
      "l0: 0.062340, l1: 0.062350, l2: 0.072075, l3: 0.094229, l4: 0.139179, l5: 0.234397, l6: 0.530648\n",
      "\n",
      "[epoch: 341/400, batch: 48/1000, ite: 45382] train loss: 1.3913, accuracy: 92.3177%, tar: 0.0487 \n",
      "l0: 0.036277, l1: 0.037514, l2: 0.044236, l3: 0.061644, l4: 0.106303, l5: 0.184611, l6: 0.388146\n",
      "\n",
      "[epoch: 341/400, batch: 56/1000, ite: 45383] train loss: 1.3912, accuracy: 93.6776%, tar: 0.0487 \n",
      "l0: 0.030768, l1: 0.031910, l2: 0.038985, l3: 0.056231, l4: 0.093777, l5: 0.169966, l6: 0.333722\n",
      "\n",
      "[epoch: 341/400, batch: 64/1000, ite: 45384] train loss: 1.3910, accuracy: 94.9106%, tar: 0.0487 \n",
      "l0: 0.050873, l1: 0.052419, l2: 0.063162, l3: 0.083008, l4: 0.138947, l5: 0.254864, l6: 0.408616\n",
      "\n",
      "[epoch: 341/400, batch: 72/1000, ite: 45385] train loss: 1.3910, accuracy: 93.6201%, tar: 0.0487 \n",
      "l0: 0.038971, l1: 0.042504, l2: 0.047470, l3: 0.063363, l4: 0.101019, l5: 0.173034, l6: 0.310288\n",
      "\n",
      "[epoch: 341/400, batch: 80/1000, ite: 45386] train loss: 1.3908, accuracy: 94.9803%, tar: 0.0487 \n",
      "l0: 0.061686, l1: 0.056315, l2: 0.062475, l3: 0.082693, l4: 0.130917, l5: 0.257955, l6: 0.495599\n",
      "\n",
      "[epoch: 341/400, batch: 88/1000, ite: 45387] train loss: 1.3910, accuracy: 92.4536%, tar: 0.0487 \n",
      "l0: 0.053000, l1: 0.054105, l2: 0.062997, l3: 0.084390, l4: 0.139702, l5: 0.235448, l6: 0.452330\n",
      "\n",
      "[epoch: 341/400, batch: 96/1000, ite: 45388] train loss: 1.3911, accuracy: 93.1615%, tar: 0.0487 \n",
      "l0: 0.052485, l1: 0.054715, l2: 0.062055, l3: 0.079576, l4: 0.119929, l5: 0.220293, l6: 0.398923\n",
      "\n",
      "[epoch: 341/400, batch: 104/1000, ite: 45389] train loss: 1.3911, accuracy: 94.3583%, tar: 0.0487 \n",
      "l0: 0.098302, l1: 0.101829, l2: 0.110098, l3: 0.140368, l4: 0.215228, l5: 0.356143, l6: 0.627850\n",
      "\n",
      "[epoch: 341/400, batch: 112/1000, ite: 45390] train loss: 1.3917, accuracy: 92.5761%, tar: 0.0487 \n",
      "l0: 0.056289, l1: 0.057793, l2: 0.067238, l3: 0.092101, l4: 0.148482, l5: 0.257008, l6: 0.450057\n",
      "\n",
      "[epoch: 341/400, batch: 120/1000, ite: 45391] train loss: 1.3919, accuracy: 92.1520%, tar: 0.0487 \n",
      "l0: 0.047330, l1: 0.048606, l2: 0.053073, l3: 0.065413, l4: 0.115794, l5: 0.206487, l6: 0.364818\n",
      "\n",
      "[epoch: 341/400, batch: 128/1000, ite: 45392] train loss: 1.3918, accuracy: 94.3998%, tar: 0.0487 \n",
      "l0: 0.044877, l1: 0.047129, l2: 0.057354, l3: 0.088370, l4: 0.156014, l5: 0.241230, l6: 0.434851\n",
      "\n",
      "[epoch: 341/400, batch: 136/1000, ite: 45393] train loss: 1.3919, accuracy: 93.5005%, tar: 0.0487 \n",
      "l0: 0.061159, l1: 0.062923, l2: 0.075851, l3: 0.108287, l4: 0.207698, l5: 0.368852, l6: 0.671418\n",
      "\n",
      "[epoch: 341/400, batch: 144/1000, ite: 45394] train loss: 1.3925, accuracy: 91.7425%, tar: 0.0487 \n",
      "l0: 0.047277, l1: 0.048657, l2: 0.057521, l3: 0.075596, l4: 0.120131, l5: 0.203744, l6: 0.453816\n",
      "\n",
      "[epoch: 341/400, batch: 152/1000, ite: 45395] train loss: 1.3925, accuracy: 94.0508%, tar: 0.0487 \n",
      "l0: 0.046607, l1: 0.049165, l2: 0.057818, l3: 0.077962, l4: 0.132234, l5: 0.261166, l6: 0.444258\n",
      "\n",
      "[epoch: 341/400, batch: 160/1000, ite: 45396] train loss: 1.3926, accuracy: 93.9563%, tar: 0.0487 \n",
      "l0: 0.047622, l1: 0.048241, l2: 0.056388, l3: 0.076731, l4: 0.123511, l5: 0.250125, l6: 0.479420\n",
      "\n",
      "[epoch: 341/400, batch: 168/1000, ite: 45397] train loss: 1.3927, accuracy: 93.7272%, tar: 0.0487 \n",
      "l0: 0.048825, l1: 0.050357, l2: 0.060168, l3: 0.095111, l4: 0.160354, l5: 0.258736, l6: 0.466236\n",
      "\n",
      "[epoch: 341/400, batch: 176/1000, ite: 45398] train loss: 1.3929, accuracy: 93.1834%, tar: 0.0487 \n",
      "l0: 0.031796, l1: 0.033925, l2: 0.040229, l3: 0.055828, l4: 0.119090, l5: 0.173524, l6: 0.270760\n",
      "\n",
      "[epoch: 341/400, batch: 184/1000, ite: 45399] train loss: 1.3926, accuracy: 95.8482%, tar: 0.0487 \n",
      "l0: 0.041817, l1: 0.042821, l2: 0.052234, l3: 0.068158, l4: 0.120115, l5: 0.217184, l6: 0.461468\n",
      "\n",
      "[epoch: 341/400, batch: 192/1000, ite: 45400] train loss: 1.3927, accuracy: 94.5413%, tar: 0.0487 \n",
      "l0: 0.047034, l1: 0.048921, l2: 0.055051, l3: 0.078193, l4: 0.132637, l5: 0.244071, l6: 0.526831\n",
      "\n",
      "[epoch: 341/400, batch: 200/1000, ite: 45401] train loss: 1.3929, accuracy: 91.0733%, tar: 0.0487 \n",
      "l0: 0.039859, l1: 0.041044, l2: 0.047259, l3: 0.064863, l4: 0.115025, l5: 0.218286, l6: 0.393890\n",
      "\n",
      "[epoch: 341/400, batch: 208/1000, ite: 45402] train loss: 1.3928, accuracy: 93.5163%, tar: 0.0487 \n",
      "l0: 0.035368, l1: 0.035584, l2: 0.042039, l3: 0.057620, l4: 0.094767, l5: 0.200031, l6: 0.401726\n",
      "\n",
      "[epoch: 341/400, batch: 216/1000, ite: 45403] train loss: 1.3927, accuracy: 94.1520%, tar: 0.0487 \n",
      "l0: 0.035188, l1: 0.036194, l2: 0.043929, l3: 0.060916, l4: 0.108351, l5: 0.185556, l6: 0.361821\n",
      "\n",
      "[epoch: 341/400, batch: 224/1000, ite: 45404] train loss: 1.3926, accuracy: 93.8622%, tar: 0.0487 \n",
      "l0: 0.040724, l1: 0.042208, l2: 0.049402, l3: 0.069622, l4: 0.126085, l5: 0.205842, l6: 0.378622\n",
      "\n",
      "[epoch: 341/400, batch: 232/1000, ite: 45405] train loss: 1.3925, accuracy: 93.9801%, tar: 0.0487 \n",
      "l0: 0.040082, l1: 0.041180, l2: 0.046352, l3: 0.064838, l4: 0.102600, l5: 0.166408, l6: 0.307231\n",
      "\n",
      "[epoch: 341/400, batch: 240/1000, ite: 45406] train loss: 1.3923, accuracy: 94.9049%, tar: 0.0487 \n",
      "l0: 0.040340, l1: 0.040876, l2: 0.049287, l3: 0.069072, l4: 0.104783, l5: 0.193718, l6: 0.387903\n",
      "\n",
      "[epoch: 341/400, batch: 248/1000, ite: 45407] train loss: 1.3922, accuracy: 93.6063%, tar: 0.0487 \n",
      "l0: 0.038382, l1: 0.039134, l2: 0.045956, l3: 0.061302, l4: 0.118170, l5: 0.219530, l6: 0.357779\n",
      "\n",
      "[epoch: 341/400, batch: 256/1000, ite: 45408] train loss: 1.3921, accuracy: 94.7152%, tar: 0.0487 \n",
      "l0: 0.034553, l1: 0.035790, l2: 0.042283, l3: 0.059489, l4: 0.094009, l5: 0.181774, l6: 0.320838\n",
      "\n",
      "[epoch: 341/400, batch: 264/1000, ite: 45409] train loss: 1.3919, accuracy: 94.6949%, tar: 0.0487 \n",
      "l0: 0.033352, l1: 0.034317, l2: 0.040867, l3: 0.057347, l4: 0.105583, l5: 0.204141, l6: 0.432836\n",
      "\n",
      "[epoch: 341/400, batch: 272/1000, ite: 45410] train loss: 1.3919, accuracy: 93.8302%, tar: 0.0487 \n",
      "l0: 0.045810, l1: 0.046239, l2: 0.056669, l3: 0.073803, l4: 0.113233, l5: 0.164887, l6: 0.284294\n",
      "\n",
      "[epoch: 341/400, batch: 280/1000, ite: 45411] train loss: 1.3917, accuracy: 94.8147%, tar: 0.0486 \n",
      "l0: 0.047854, l1: 0.048947, l2: 0.060151, l3: 0.083789, l4: 0.146742, l5: 0.243158, l6: 0.422483\n",
      "\n",
      "[epoch: 341/400, batch: 288/1000, ite: 45412] train loss: 1.3917, accuracy: 93.8181%, tar: 0.0486 \n",
      "l0: 0.041841, l1: 0.042842, l2: 0.051611, l3: 0.069037, l4: 0.120574, l5: 0.201065, l6: 0.375994\n",
      "\n",
      "[epoch: 341/400, batch: 296/1000, ite: 45413] train loss: 1.3917, accuracy: 93.9660%, tar: 0.0486 \n",
      "l0: 0.045076, l1: 0.047096, l2: 0.055494, l3: 0.076810, l4: 0.122929, l5: 0.210769, l6: 0.391190\n",
      "\n",
      "[epoch: 341/400, batch: 304/1000, ite: 45414] train loss: 1.3916, accuracy: 93.3701%, tar: 0.0486 \n",
      "l0: 0.048647, l1: 0.049473, l2: 0.055442, l3: 0.069752, l4: 0.102209, l5: 0.196799, l6: 0.335129\n",
      "\n",
      "[epoch: 341/400, batch: 312/1000, ite: 45415] train loss: 1.3915, accuracy: 94.7471%, tar: 0.0486 \n",
      "l0: 0.035089, l1: 0.036135, l2: 0.043250, l3: 0.062968, l4: 0.110682, l5: 0.220164, l6: 0.421520\n",
      "\n",
      "[epoch: 341/400, batch: 320/1000, ite: 45416] train loss: 1.3915, accuracy: 94.0638%, tar: 0.0486 \n",
      "l0: 0.046110, l1: 0.047136, l2: 0.057266, l3: 0.081666, l4: 0.140702, l5: 0.237219, l6: 0.466567\n",
      "\n",
      "[epoch: 341/400, batch: 328/1000, ite: 45417] train loss: 1.3916, accuracy: 93.3802%, tar: 0.0486 \n",
      "l0: 0.036215, l1: 0.037308, l2: 0.044964, l3: 0.063712, l4: 0.109888, l5: 0.193893, l6: 0.394473\n",
      "\n",
      "[epoch: 341/400, batch: 336/1000, ite: 45418] train loss: 1.3915, accuracy: 93.7796%, tar: 0.0486 \n",
      "l0: 0.043602, l1: 0.044836, l2: 0.054563, l3: 0.078371, l4: 0.138196, l5: 0.269549, l6: 0.485321\n",
      "\n",
      "[epoch: 341/400, batch: 344/1000, ite: 45419] train loss: 1.3917, accuracy: 92.1001%, tar: 0.0486 \n",
      "l0: 0.042754, l1: 0.043698, l2: 0.051116, l3: 0.065439, l4: 0.096146, l5: 0.179140, l6: 0.327803\n",
      "\n",
      "[epoch: 341/400, batch: 352/1000, ite: 45420] train loss: 1.3915, accuracy: 94.6506%, tar: 0.0486 \n",
      "l0: 0.044823, l1: 0.045928, l2: 0.054188, l3: 0.070591, l4: 0.132234, l5: 0.237544, l6: 0.430052\n",
      "\n",
      "[epoch: 341/400, batch: 360/1000, ite: 45421] train loss: 1.3916, accuracy: 94.4808%, tar: 0.0486 \n",
      "l0: 0.037595, l1: 0.038586, l2: 0.043912, l3: 0.053667, l4: 0.090899, l5: 0.161466, l6: 0.303356\n",
      "\n",
      "[epoch: 341/400, batch: 368/1000, ite: 45422] train loss: 1.3913, accuracy: 94.9170%, tar: 0.0486 \n",
      "l0: 0.030119, l1: 0.030945, l2: 0.037762, l3: 0.055698, l4: 0.097538, l5: 0.168915, l6: 0.346088\n",
      "\n",
      "[epoch: 341/400, batch: 376/1000, ite: 45423] train loss: 1.3911, accuracy: 95.4788%, tar: 0.0486 \n",
      "l0: 0.041370, l1: 0.042619, l2: 0.050084, l3: 0.064176, l4: 0.109259, l5: 0.207408, l6: 0.385598\n",
      "\n",
      "[epoch: 341/400, batch: 384/1000, ite: 45424] train loss: 1.3911, accuracy: 94.6030%, tar: 0.0486 \n",
      "l0: 0.032101, l1: 0.033457, l2: 0.040720, l3: 0.061415, l4: 0.108856, l5: 0.191290, l6: 0.343458\n",
      "\n",
      "[epoch: 341/400, batch: 392/1000, ite: 45425] train loss: 1.3909, accuracy: 95.0713%, tar: 0.0486 \n",
      "l0: 0.050734, l1: 0.052782, l2: 0.060498, l3: 0.082005, l4: 0.131744, l5: 0.308138, l6: 0.534820\n",
      "\n",
      "[epoch: 341/400, batch: 400/1000, ite: 45426] train loss: 1.3912, accuracy: 93.2103%, tar: 0.0486 \n",
      "l0: 0.032627, l1: 0.033048, l2: 0.038126, l3: 0.050073, l4: 0.079108, l5: 0.133706, l6: 0.273187\n",
      "\n",
      "[epoch: 341/400, batch: 408/1000, ite: 45427] train loss: 1.3908, accuracy: 95.9127%, tar: 0.0486 \n",
      "l0: 0.039158, l1: 0.039919, l2: 0.047476, l3: 0.066506, l4: 0.116371, l5: 0.218501, l6: 0.408528\n",
      "\n",
      "[epoch: 341/400, batch: 416/1000, ite: 45428] train loss: 1.3908, accuracy: 93.8121%, tar: 0.0486 \n",
      "l0: 0.034998, l1: 0.036585, l2: 0.044250, l3: 0.061090, l4: 0.098726, l5: 0.163213, l6: 0.309881\n",
      "\n",
      "[epoch: 341/400, batch: 424/1000, ite: 45429] train loss: 1.3906, accuracy: 95.6042%, tar: 0.0485 \n",
      "l0: 0.038806, l1: 0.040126, l2: 0.049501, l3: 0.063635, l4: 0.105692, l5: 0.208582, l6: 0.409447\n",
      "\n",
      "[epoch: 341/400, batch: 432/1000, ite: 45430] train loss: 1.3906, accuracy: 94.3569%, tar: 0.0485 \n",
      "l0: 0.041702, l1: 0.042245, l2: 0.050690, l3: 0.073385, l4: 0.144843, l5: 0.295594, l6: 0.510993\n",
      "\n",
      "[epoch: 341/400, batch: 440/1000, ite: 45431] train loss: 1.3908, accuracy: 92.7461%, tar: 0.0485 \n",
      "l0: 0.039885, l1: 0.040959, l2: 0.051471, l3: 0.073093, l4: 0.126797, l5: 0.245991, l6: 0.458091\n",
      "\n",
      "[epoch: 341/400, batch: 448/1000, ite: 45432] train loss: 1.3908, accuracy: 92.1662%, tar: 0.0485 \n",
      "l0: 0.037417, l1: 0.038207, l2: 0.046335, l3: 0.060213, l4: 0.102100, l5: 0.184878, l6: 0.343321\n",
      "\n",
      "[epoch: 341/400, batch: 456/1000, ite: 45433] train loss: 1.3907, accuracy: 94.5345%, tar: 0.0485 \n",
      "l0: 0.041000, l1: 0.042196, l2: 0.050243, l3: 0.066923, l4: 0.128036, l5: 0.231967, l6: 0.425218\n",
      "\n",
      "[epoch: 341/400, batch: 464/1000, ite: 45434] train loss: 1.3907, accuracy: 93.6879%, tar: 0.0485 \n",
      "l0: 0.035417, l1: 0.036610, l2: 0.044813, l3: 0.063751, l4: 0.101892, l5: 0.183744, l6: 0.334537\n",
      "\n",
      "[epoch: 341/400, batch: 472/1000, ite: 45435] train loss: 1.3905, accuracy: 95.4796%, tar: 0.0485 \n",
      "l0: 0.032901, l1: 0.034728, l2: 0.043155, l3: 0.064103, l4: 0.146028, l5: 0.254116, l6: 0.457526\n",
      "\n",
      "[epoch: 341/400, batch: 480/1000, ite: 45436] train loss: 1.3906, accuracy: 94.6518%, tar: 0.0485 \n",
      "l0: 0.035855, l1: 0.037466, l2: 0.046589, l3: 0.067315, l4: 0.119914, l5: 0.251209, l6: 0.418735\n",
      "\n",
      "[epoch: 341/400, batch: 488/1000, ite: 45437] train loss: 1.3906, accuracy: 93.7049%, tar: 0.0485 \n",
      "l0: 0.047427, l1: 0.049937, l2: 0.063359, l3: 0.086787, l4: 0.149516, l5: 0.263661, l6: 0.462803\n",
      "\n",
      "[epoch: 341/400, batch: 496/1000, ite: 45438] train loss: 1.3908, accuracy: 94.4518%, tar: 0.0485 \n",
      "l0: 0.042111, l1: 0.043149, l2: 0.052178, l3: 0.074750, l4: 0.137146, l5: 0.263587, l6: 0.488466\n",
      "\n",
      "[epoch: 341/400, batch: 504/1000, ite: 45439] train loss: 1.3909, accuracy: 92.2268%, tar: 0.0485 \n",
      "l0: 0.051790, l1: 0.055476, l2: 0.065163, l3: 0.085101, l4: 0.134703, l5: 0.223043, l6: 0.394994\n",
      "\n",
      "[epoch: 341/400, batch: 512/1000, ite: 45440] train loss: 1.3909, accuracy: 93.5701%, tar: 0.0485 \n",
      "l0: 0.044062, l1: 0.044637, l2: 0.050757, l3: 0.069269, l4: 0.105202, l5: 0.177703, l6: 0.344357\n",
      "\n",
      "[epoch: 341/400, batch: 520/1000, ite: 45441] train loss: 1.3908, accuracy: 94.3607%, tar: 0.0485 \n",
      "l0: 0.031916, l1: 0.032458, l2: 0.037911, l3: 0.053385, l4: 0.081937, l5: 0.137426, l6: 0.252527\n",
      "\n",
      "[epoch: 341/400, batch: 528/1000, ite: 45442] train loss: 1.3904, accuracy: 95.2803%, tar: 0.0485 \n",
      "l0: 0.041067, l1: 0.041518, l2: 0.048494, l3: 0.067912, l4: 0.120908, l5: 0.210996, l6: 0.366143\n",
      "\n",
      "[epoch: 341/400, batch: 536/1000, ite: 45443] train loss: 1.3903, accuracy: 94.4159%, tar: 0.0485 \n",
      "l0: 0.041168, l1: 0.042309, l2: 0.051716, l3: 0.075938, l4: 0.128638, l5: 0.239337, l6: 0.415694\n",
      "\n",
      "[epoch: 341/400, batch: 544/1000, ite: 45444] train loss: 1.3904, accuracy: 93.8051%, tar: 0.0485 \n",
      "l0: 0.047315, l1: 0.048544, l2: 0.059257, l3: 0.081912, l4: 0.145850, l5: 0.260095, l6: 0.509513\n",
      "\n",
      "[epoch: 341/400, batch: 552/1000, ite: 45445] train loss: 1.3906, accuracy: 92.5675%, tar: 0.0485 \n",
      "l0: 0.036207, l1: 0.037355, l2: 0.044802, l3: 0.062531, l4: 0.105202, l5: 0.175089, l6: 0.321790\n",
      "\n",
      "[epoch: 341/400, batch: 560/1000, ite: 45446] train loss: 1.3904, accuracy: 94.7653%, tar: 0.0485 \n",
      "l0: 0.044202, l1: 0.044921, l2: 0.054145, l3: 0.079474, l4: 0.129740, l5: 0.211629, l6: 0.433393\n",
      "\n",
      "[epoch: 341/400, batch: 568/1000, ite: 45447] train loss: 1.3904, accuracy: 93.2162%, tar: 0.0484 \n",
      "l0: 0.049298, l1: 0.051456, l2: 0.061851, l3: 0.088511, l4: 0.146597, l5: 0.232550, l6: 0.422144\n",
      "\n",
      "[epoch: 341/400, batch: 576/1000, ite: 45448] train loss: 1.3905, accuracy: 93.4807%, tar: 0.0484 \n",
      "l0: 0.036077, l1: 0.037596, l2: 0.046952, l3: 0.065864, l4: 0.113849, l5: 0.201724, l6: 0.377328\n",
      "\n",
      "[epoch: 341/400, batch: 584/1000, ite: 45449] train loss: 1.3904, accuracy: 95.2017%, tar: 0.0484 \n",
      "l0: 0.043167, l1: 0.044869, l2: 0.053886, l3: 0.076891, l4: 0.133177, l5: 0.210527, l6: 0.386570\n",
      "\n",
      "[epoch: 341/400, batch: 592/1000, ite: 45450] train loss: 1.3903, accuracy: 94.2425%, tar: 0.0484 \n",
      "l0: 0.035512, l1: 0.036870, l2: 0.043943, l3: 0.057249, l4: 0.094355, l5: 0.172800, l6: 0.333665\n",
      "\n",
      "[epoch: 341/400, batch: 600/1000, ite: 45451] train loss: 1.3901, accuracy: 95.1330%, tar: 0.0484 \n",
      "l0: 0.037060, l1: 0.038172, l2: 0.046200, l3: 0.064889, l4: 0.105571, l5: 0.203036, l6: 0.371309\n",
      "\n",
      "[epoch: 341/400, batch: 608/1000, ite: 45452] train loss: 1.3900, accuracy: 94.1098%, tar: 0.0484 \n",
      "l0: 0.040882, l1: 0.041352, l2: 0.048220, l3: 0.064500, l4: 0.102176, l5: 0.199401, l6: 0.374059\n",
      "\n",
      "[epoch: 341/400, batch: 616/1000, ite: 45453] train loss: 1.3900, accuracy: 94.1824%, tar: 0.0484 \n",
      "l0: 0.043266, l1: 0.044139, l2: 0.050618, l3: 0.067698, l4: 0.104356, l5: 0.198494, l6: 0.331325\n",
      "\n",
      "[epoch: 341/400, batch: 624/1000, ite: 45454] train loss: 1.3898, accuracy: 94.7639%, tar: 0.0484 \n",
      "l0: 0.052918, l1: 0.054905, l2: 0.065575, l3: 0.086187, l4: 0.143123, l5: 0.231316, l6: 0.421319\n",
      "\n",
      "[epoch: 341/400, batch: 632/1000, ite: 45455] train loss: 1.3899, accuracy: 93.3802%, tar: 0.0484 \n",
      "l0: 0.041825, l1: 0.043542, l2: 0.052390, l3: 0.078223, l4: 0.141634, l5: 0.256985, l6: 0.471367\n",
      "\n",
      "[epoch: 341/400, batch: 640/1000, ite: 45456] train loss: 1.3900, accuracy: 93.6527%, tar: 0.0484 \n",
      "l0: 0.050276, l1: 0.051415, l2: 0.061127, l3: 0.086347, l4: 0.151466, l5: 0.289548, l6: 0.572602\n",
      "\n",
      "[epoch: 341/400, batch: 648/1000, ite: 45457] train loss: 1.3903, accuracy: 91.8736%, tar: 0.0484 \n",
      "l0: 0.041541, l1: 0.042581, l2: 0.049663, l3: 0.072680, l4: 0.135888, l5: 0.208777, l6: 0.395894\n",
      "\n",
      "[epoch: 341/400, batch: 656/1000, ite: 45458] train loss: 1.3903, accuracy: 94.4438%, tar: 0.0484 \n",
      "l0: 0.032402, l1: 0.033528, l2: 0.040942, l3: 0.059663, l4: 0.102430, l5: 0.184507, l6: 0.357265\n",
      "\n",
      "[epoch: 341/400, batch: 664/1000, ite: 45459] train loss: 1.3901, accuracy: 94.4262%, tar: 0.0484 \n",
      "l0: 0.035829, l1: 0.038263, l2: 0.048263, l3: 0.072688, l4: 0.125139, l5: 0.211196, l6: 0.495553\n",
      "\n",
      "[epoch: 341/400, batch: 672/1000, ite: 45460] train loss: 1.3902, accuracy: 94.2979%, tar: 0.0484 \n",
      "l0: 0.040045, l1: 0.041552, l2: 0.048867, l3: 0.068087, l4: 0.110525, l5: 0.216506, l6: 0.530277\n",
      "\n",
      "[epoch: 341/400, batch: 680/1000, ite: 45461] train loss: 1.3904, accuracy: 92.5090%, tar: 0.0484 \n",
      "l0: 0.059141, l1: 0.058925, l2: 0.067120, l3: 0.090050, l4: 0.151630, l5: 0.289376, l6: 0.505694\n",
      "\n",
      "[epoch: 341/400, batch: 688/1000, ite: 45462] train loss: 1.3906, accuracy: 92.8862%, tar: 0.0484 \n",
      "l0: 0.038593, l1: 0.039329, l2: 0.048766, l3: 0.068819, l4: 0.127379, l5: 0.215875, l6: 0.401078\n",
      "\n",
      "[epoch: 341/400, batch: 696/1000, ite: 45463] train loss: 1.3906, accuracy: 94.2509%, tar: 0.0484 \n",
      "l0: 0.029415, l1: 0.030424, l2: 0.038448, l3: 0.055864, l4: 0.095856, l5: 0.181765, l6: 0.304486\n",
      "\n",
      "[epoch: 341/400, batch: 704/1000, ite: 45464] train loss: 1.3903, accuracy: 95.7199%, tar: 0.0484 \n",
      "l0: 0.033661, l1: 0.034654, l2: 0.043114, l3: 0.059210, l4: 0.094015, l5: 0.160578, l6: 0.290133\n",
      "\n",
      "[epoch: 341/400, batch: 712/1000, ite: 45465] train loss: 1.3901, accuracy: 94.8460%, tar: 0.0484 \n",
      "l0: 0.032140, l1: 0.033762, l2: 0.044391, l3: 0.066989, l4: 0.136368, l5: 0.260856, l6: 0.436173\n",
      "\n",
      "[epoch: 341/400, batch: 720/1000, ite: 45466] train loss: 1.3901, accuracy: 94.9042%, tar: 0.0483 \n",
      "l0: 0.049730, l1: 0.051774, l2: 0.060714, l3: 0.081221, l4: 0.143665, l5: 0.234194, l6: 0.369559\n",
      "\n",
      "[epoch: 341/400, batch: 728/1000, ite: 45467] train loss: 1.3901, accuracy: 93.3225%, tar: 0.0483 \n",
      "l0: 0.036764, l1: 0.039187, l2: 0.046723, l3: 0.063567, l4: 0.095493, l5: 0.173767, l6: 0.374823\n",
      "\n",
      "[epoch: 341/400, batch: 736/1000, ite: 45468] train loss: 1.3900, accuracy: 94.4435%, tar: 0.0483 \n",
      "l0: 0.043994, l1: 0.045855, l2: 0.050453, l3: 0.065808, l4: 0.106024, l5: 0.166773, l6: 0.325648\n",
      "\n",
      "[epoch: 341/400, batch: 744/1000, ite: 45469] train loss: 1.3898, accuracy: 94.1699%, tar: 0.0483 \n",
      "l0: 0.035183, l1: 0.036220, l2: 0.044086, l3: 0.060836, l4: 0.098098, l5: 0.181078, l6: 0.383268\n",
      "\n",
      "[epoch: 341/400, batch: 752/1000, ite: 45470] train loss: 1.3897, accuracy: 94.3374%, tar: 0.0483 \n",
      "l0: 0.028221, l1: 0.029933, l2: 0.036453, l3: 0.053774, l4: 0.102567, l5: 0.163532, l6: 0.273668\n",
      "\n",
      "[epoch: 341/400, batch: 760/1000, ite: 45471] train loss: 1.3894, accuracy: 95.7283%, tar: 0.0483 \n",
      "l0: 0.039476, l1: 0.040491, l2: 0.049192, l3: 0.068680, l4: 0.113957, l5: 0.205306, l6: 0.404259\n",
      "\n",
      "[epoch: 341/400, batch: 768/1000, ite: 45472] train loss: 1.3894, accuracy: 93.8956%, tar: 0.0483 \n",
      "l0: 0.031706, l1: 0.032863, l2: 0.038810, l3: 0.056010, l4: 0.109990, l5: 0.230875, l6: 0.387831\n",
      "\n",
      "[epoch: 341/400, batch: 776/1000, ite: 45473] train loss: 1.3893, accuracy: 95.2307%, tar: 0.0483 \n",
      "l0: 0.036993, l1: 0.038124, l2: 0.043846, l3: 0.059249, l4: 0.099925, l5: 0.205483, l6: 0.424962\n",
      "\n",
      "[epoch: 341/400, batch: 784/1000, ite: 45474] train loss: 1.3893, accuracy: 93.2038%, tar: 0.0483 \n",
      "l0: 0.042174, l1: 0.042587, l2: 0.049778, l3: 0.068168, l4: 0.112779, l5: 0.214183, l6: 0.402248\n",
      "\n",
      "[epoch: 341/400, batch: 792/1000, ite: 45475] train loss: 1.3892, accuracy: 93.1326%, tar: 0.0483 \n",
      "l0: 0.042721, l1: 0.043854, l2: 0.051670, l3: 0.070447, l4: 0.123828, l5: 0.222773, l6: 0.421071\n",
      "\n",
      "[epoch: 341/400, batch: 800/1000, ite: 45476] train loss: 1.3893, accuracy: 93.4823%, tar: 0.0483 \n",
      "l0: 0.037896, l1: 0.039253, l2: 0.047910, l3: 0.068246, l4: 0.107958, l5: 0.180383, l6: 0.320758\n",
      "\n",
      "[epoch: 341/400, batch: 808/1000, ite: 45477] train loss: 1.3891, accuracy: 95.2162%, tar: 0.0483 \n",
      "l0: 0.041446, l1: 0.041948, l2: 0.048756, l3: 0.062416, l4: 0.094144, l5: 0.174857, l6: 0.370781\n",
      "\n",
      "[epoch: 341/400, batch: 816/1000, ite: 45478] train loss: 1.3890, accuracy: 94.1316%, tar: 0.0483 \n",
      "l0: 0.040754, l1: 0.042149, l2: 0.051664, l3: 0.073478, l4: 0.118923, l5: 0.220783, l6: 0.399015\n",
      "\n",
      "[epoch: 341/400, batch: 824/1000, ite: 45479] train loss: 1.3889, accuracy: 94.1001%, tar: 0.0483 \n",
      "l0: 0.039282, l1: 0.041034, l2: 0.051496, l3: 0.074935, l4: 0.121959, l5: 0.247560, l6: 0.490066\n",
      "\n",
      "[epoch: 341/400, batch: 832/1000, ite: 45480] train loss: 1.3891, accuracy: 93.3864%, tar: 0.0483 \n",
      "l0: 0.031160, l1: 0.032049, l2: 0.037782, l3: 0.050408, l4: 0.078949, l5: 0.144902, l6: 0.312371\n",
      "\n",
      "[epoch: 341/400, batch: 840/1000, ite: 45481] train loss: 1.3888, accuracy: 94.9256%, tar: 0.0482 \n",
      "l0: 0.037458, l1: 0.038113, l2: 0.044589, l3: 0.058377, l4: 0.089248, l5: 0.160486, l6: 0.292883\n",
      "\n",
      "[epoch: 341/400, batch: 848/1000, ite: 45482] train loss: 1.3886, accuracy: 94.6959%, tar: 0.0482 \n",
      "l0: 0.041910, l1: 0.043713, l2: 0.051998, l3: 0.074191, l4: 0.132102, l5: 0.225410, l6: 0.393950\n",
      "\n",
      "[epoch: 341/400, batch: 856/1000, ite: 45483] train loss: 1.3885, accuracy: 93.9386%, tar: 0.0482 \n",
      "l0: 0.031631, l1: 0.032289, l2: 0.038920, l3: 0.053184, l4: 0.087814, l5: 0.173964, l6: 0.323139\n",
      "\n",
      "[epoch: 341/400, batch: 864/1000, ite: 45484] train loss: 1.3883, accuracy: 95.3636%, tar: 0.0482 \n",
      "l0: 0.036989, l1: 0.037706, l2: 0.044181, l3: 0.058862, l4: 0.096650, l5: 0.180636, l6: 0.367729\n",
      "\n",
      "[epoch: 341/400, batch: 872/1000, ite: 45485] train loss: 1.3882, accuracy: 93.6678%, tar: 0.0482 \n",
      "l0: 0.038129, l1: 0.038953, l2: 0.045802, l3: 0.063163, l4: 0.114753, l5: 0.199540, l6: 0.408055\n",
      "\n",
      "[epoch: 341/400, batch: 880/1000, ite: 45486] train loss: 1.3882, accuracy: 93.3538%, tar: 0.0482 \n",
      "l0: 0.043757, l1: 0.045012, l2: 0.052146, l3: 0.071056, l4: 0.128345, l5: 0.269447, l6: 0.417278\n",
      "\n",
      "[epoch: 341/400, batch: 888/1000, ite: 45487] train loss: 1.3882, accuracy: 93.5898%, tar: 0.0482 \n",
      "[epoch: 341/400, batch: 912/1000, ite: 45490] train loss: 1.3882, accuracy: 94.7621%, tar: 0.0482 \n",
      "l0: 0.038740, l1: 0.040257, l2: 0.048723, l3: 0.066874, l4: 0.117401, l5: 0.233619, l6: 0.492528\n",
      "\n",
      "[epoch: 341/400, batch: 920/1000, ite: 45491] train loss: 1.3883, accuracy: 92.9881%, tar: 0.0482 \n",
      "l0: 0.040138, l1: 0.042252, l2: 0.052188, l3: 0.075416, l4: 0.143640, l5: 0.266605, l6: 0.579784\n",
      "\n",
      "[epoch: 341/400, batch: 928/1000, ite: 45492] train loss: 1.3886, accuracy: 92.1201%, tar: 0.0482 \n",
      "l0: 0.030244, l1: 0.031068, l2: 0.037575, l3: 0.052284, l4: 0.088952, l5: 0.192472, l6: 0.371344\n",
      "\n",
      "[epoch: 341/400, batch: 936/1000, ite: 45493] train loss: 1.3884, accuracy: 94.6983%, tar: 0.0482 \n",
      "l0: 0.036807, l1: 0.038355, l2: 0.047274, l3: 0.062779, l4: 0.108294, l5: 0.198246, l6: 0.427565\n",
      "\n",
      "[epoch: 341/400, batch: 944/1000, ite: 45494] train loss: 1.3884, accuracy: 94.3620%, tar: 0.0482 \n",
      "l0: 0.051311, l1: 0.050607, l2: 0.060657, l3: 0.086856, l4: 0.135765, l5: 0.274127, l6: 0.477394\n",
      "\n",
      "[epoch: 341/400, batch: 952/1000, ite: 45495] train loss: 1.3886, accuracy: 93.5769%, tar: 0.0482 \n",
      "l0: 0.039870, l1: 0.041743, l2: 0.052545, l3: 0.079421, l4: 0.147604, l5: 0.297619, l6: 0.536942\n",
      "\n",
      "[epoch: 341/400, batch: 960/1000, ite: 45496] train loss: 1.3888, accuracy: 92.6304%, tar: 0.0482 \n",
      "l0: 0.030357, l1: 0.031249, l2: 0.037631, l3: 0.051470, l4: 0.086771, l5: 0.146144, l6: 0.285958\n",
      "\n",
      "[epoch: 341/400, batch: 968/1000, ite: 45497] train loss: 1.3885, accuracy: 94.6478%, tar: 0.0481 \n",
      "l0: 0.030058, l1: 0.031019, l2: 0.037877, l3: 0.052796, l4: 0.100651, l5: 0.241265, l6: 0.411806\n",
      "\n",
      "[epoch: 341/400, batch: 976/1000, ite: 45498] train loss: 1.3885, accuracy: 94.6857%, tar: 0.0481 \n",
      "l0: 0.034566, l1: 0.035479, l2: 0.043928, l3: 0.062863, l4: 0.113295, l5: 0.228328, l6: 0.451823\n",
      "\n",
      "[epoch: 341/400, batch: 984/1000, ite: 45499] train loss: 1.3885, accuracy: 93.9556%, tar: 0.0481 \n",
      "l0: 0.037094, l1: 0.038519, l2: 0.047878, l3: 0.066222, l4: 0.122576, l5: 0.231251, l6: 0.466936\n",
      "\n",
      "[epoch: 341/400, batch: 992/1000, ite: 45500] train loss: 1.3886, accuracy: 93.7332%, tar: 0.0481 \n",
      "l0: 0.038690, l1: 0.040205, l2: 0.049818, l3: 0.073277, l4: 0.132340, l5: 0.268544, l6: 0.518262\n",
      "\n",
      "[epoch: 341/400, batch: 1000/1000, ite: 45501] train loss: 1.3887, accuracy: 93.0815%, tar: 0.0481 \n",
      "l0: 0.033488, l1: 0.034849, l2: 0.043693, l3: 0.063579, l4: 0.119980, l5: 0.247360, l6: 0.421975\n",
      "\n",
      "[epoch: 342/400, batch: 8/1000, ite: 45502] train loss: 1.3887, accuracy: 94.0030%, tar: 0.0481 \n",
      "l0: 0.027017, l1: 0.028372, l2: 0.033247, l3: 0.042466, l4: 0.067154, l5: 0.128576, l6: 0.273786\n",
      "\n",
      "[epoch: 342/400, batch: 16/1000, ite: 45503] train loss: 1.3884, accuracy: 95.5074%, tar: 0.0481 \n",
      "l0: 0.031475, l1: 0.033072, l2: 0.041066, l3: 0.060912, l4: 0.109634, l5: 0.184507, l6: 0.361298\n",
      "\n",
      "[epoch: 342/400, batch: 24/1000, ite: 45504] train loss: 1.3883, accuracy: 94.8170%, tar: 0.0481 \n",
      "l0: 0.030592, l1: 0.031602, l2: 0.039251, l3: 0.056730, l4: 0.116087, l5: 0.216170, l6: 0.370432\n",
      "\n",
      "[epoch: 342/400, batch: 32/1000, ite: 45505] train loss: 1.3882, accuracy: 94.5247%, tar: 0.0481 \n",
      "l0: 0.032593, l1: 0.033671, l2: 0.041007, l3: 0.053630, l4: 0.087345, l5: 0.173956, l6: 0.402673\n",
      "\n",
      "[epoch: 342/400, batch: 40/1000, ite: 45506] train loss: 1.3881, accuracy: 94.1468%, tar: 0.0480 \n",
      "l0: 0.036075, l1: 0.036975, l2: 0.044207, l3: 0.058228, l4: 0.100312, l5: 0.200174, l6: 0.420560\n",
      "\n",
      "[epoch: 342/400, batch: 48/1000, ite: 45507] train loss: 1.3880, accuracy: 93.3771%, tar: 0.0480 \n",
      "l0: 0.025617, l1: 0.026710, l2: 0.031447, l3: 0.043732, l4: 0.072211, l5: 0.122790, l6: 0.249464\n",
      "\n",
      "[epoch: 342/400, batch: 56/1000, ite: 45508] train loss: 1.3877, accuracy: 95.8526%, tar: 0.0480 \n",
      "l0: 0.038930, l1: 0.039749, l2: 0.047562, l3: 0.063167, l4: 0.093293, l5: 0.156711, l6: 0.309136\n",
      "\n",
      "[epoch: 342/400, batch: 64/1000, ite: 45509] train loss: 1.3874, accuracy: 94.2482%, tar: 0.0480 \n",
      "l0: 0.039349, l1: 0.040834, l2: 0.051963, l3: 0.077900, l4: 0.138624, l5: 0.248532, l6: 0.513596\n",
      "\n",
      "[epoch: 342/400, batch: 72/1000, ite: 45510] train loss: 1.3876, accuracy: 93.4826%, tar: 0.0480 \n",
      "l0: 0.032386, l1: 0.035340, l2: 0.044432, l3: 0.068414, l4: 0.121227, l5: 0.196800, l6: 0.446585\n",
      "\n",
      "[epoch: 342/400, batch: 80/1000, ite: 45511] train loss: 1.3876, accuracy: 94.6246%, tar: 0.0480 \n",
      "l0: 0.041053, l1: 0.042578, l2: 0.049929, l3: 0.068132, l4: 0.124676, l5: 0.219864, l6: 0.399903\n",
      "\n",
      "[epoch: 342/400, batch: 88/1000, ite: 45512] train loss: 1.3876, accuracy: 93.7207%, tar: 0.0480 \n",
      "l0: 0.041120, l1: 0.042737, l2: 0.052059, l3: 0.073469, l4: 0.122660, l5: 0.208143, l6: 0.402646\n",
      "\n",
      "[epoch: 342/400, batch: 96/1000, ite: 45513] train loss: 1.3876, accuracy: 93.7246%, tar: 0.0480 \n",
      "l0: 0.029447, l1: 0.030347, l2: 0.037250, l3: 0.052009, l4: 0.079643, l5: 0.141913, l6: 0.300006\n",
      "\n",
      "[epoch: 342/400, batch: 104/1000, ite: 45514] train loss: 1.3873, accuracy: 94.8622%, tar: 0.0480 \n",
      "l0: 0.045821, l1: 0.047983, l2: 0.060023, l3: 0.095499, l4: 0.168440, l5: 0.270004, l6: 0.430243\n",
      "\n",
      "[epoch: 342/400, batch: 112/1000, ite: 45515] train loss: 1.3874, accuracy: 93.8543%, tar: 0.0480 \n",
      "l0: 0.039764, l1: 0.042072, l2: 0.051649, l3: 0.074989, l4: 0.128598, l5: 0.245560, l6: 0.461547\n",
      "\n",
      "[epoch: 342/400, batch: 120/1000, ite: 45516] train loss: 1.3875, accuracy: 93.5294%, tar: 0.0480 \n",
      "l0: 0.034150, l1: 0.035051, l2: 0.041970, l3: 0.054997, l4: 0.083564, l5: 0.145384, l6: 0.312603\n",
      "\n",
      "[epoch: 342/400, batch: 128/1000, ite: 45517] train loss: 1.3872, accuracy: 94.1561%, tar: 0.0480 \n",
      "l0: 0.026859, l1: 0.028128, l2: 0.034443, l3: 0.048502, l4: 0.082460, l5: 0.154411, l6: 0.290213\n",
      "\n",
      "[epoch: 342/400, batch: 136/1000, ite: 45518] train loss: 1.3870, accuracy: 95.1361%, tar: 0.0480 \n",
      "l0: 0.034553, l1: 0.035369, l2: 0.044324, l3: 0.062385, l4: 0.105510, l5: 0.189747, l6: 0.375667\n",
      "\n",
      "[epoch: 342/400, batch: 144/1000, ite: 45519] train loss: 1.3869, accuracy: 94.7610%, tar: 0.0479 \n",
      "l0: 0.035872, l1: 0.036433, l2: 0.043773, l3: 0.057228, l4: 0.093961, l5: 0.185115, l6: 0.433113\n",
      "\n",
      "[epoch: 342/400, batch: 152/1000, ite: 45520] train loss: 1.3868, accuracy: 93.4319%, tar: 0.0479 \n",
      "l0: 0.028564, l1: 0.029521, l2: 0.039589, l3: 0.058605, l4: 0.091549, l5: 0.170284, l6: 0.285420\n",
      "\n",
      "[epoch: 342/400, batch: 160/1000, ite: 45521] train loss: 1.3866, accuracy: 95.6213%, tar: 0.0479 \n",
      "l0: 0.030176, l1: 0.030732, l2: 0.035695, l3: 0.049783, l4: 0.077846, l5: 0.137014, l6: 0.279906\n",
      "\n",
      "[epoch: 342/400, batch: 168/1000, ite: 45522] train loss: 1.3862, accuracy: 94.7549%, tar: 0.0479 \n",
      "l0: 0.033119, l1: 0.034388, l2: 0.044393, l3: 0.062858, l4: 0.099824, l5: 0.188862, l6: 0.351601\n",
      "\n",
      "[epoch: 342/400, batch: 176/1000, ite: 45523] train loss: 1.3861, accuracy: 95.0548%, tar: 0.0479 \n",
      "l0: 0.037157, l1: 0.038368, l2: 0.046999, l3: 0.060364, l4: 0.097760, l5: 0.177581, l6: 0.338219\n",
      "\n",
      "[epoch: 342/400, batch: 184/1000, ite: 45524] train loss: 1.3860, accuracy: 94.1573%, tar: 0.0479 \n",
      "l0: 0.045293, l1: 0.046149, l2: 0.054624, l3: 0.081521, l4: 0.147293, l5: 0.313250, l6: 0.609141\n",
      "\n",
      "[epoch: 342/400, batch: 192/1000, ite: 45525] train loss: 1.3863, accuracy: 91.7681%, tar: 0.0479 \n",
      "l0: 0.037772, l1: 0.039587, l2: 0.048687, l3: 0.068820, l4: 0.120997, l5: 0.218535, l6: 0.425204\n",
      "\n",
      "[epoch: 342/400, batch: 200/1000, ite: 45526] train loss: 1.3863, accuracy: 93.2067%, tar: 0.0479 \n",
      "l0: 0.028794, l1: 0.029783, l2: 0.037172, l3: 0.051109, l4: 0.090979, l5: 0.154585, l6: 0.278196\n",
      "\n",
      "[epoch: 342/400, batch: 208/1000, ite: 45527] train loss: 1.3860, accuracy: 95.6203%, tar: 0.0479 \n",
      "l0: 0.030430, l1: 0.031927, l2: 0.037519, l3: 0.052431, l4: 0.088928, l5: 0.164874, l6: 0.339726\n",
      "\n",
      "[epoch: 342/400, batch: 216/1000, ite: 45528] train loss: 1.3858, accuracy: 94.9804%, tar: 0.0479 \n",
      "l0: 0.030037, l1: 0.031123, l2: 0.037471, l3: 0.051628, l4: 0.080235, l5: 0.150948, l6: 0.304237\n",
      "\n",
      "[epoch: 342/400, batch: 224/1000, ite: 45529] train loss: 1.3856, accuracy: 94.9472%, tar: 0.0479 \n",
      "l0: 0.030266, l1: 0.031626, l2: 0.038954, l3: 0.056152, l4: 0.096263, l5: 0.184732, l6: 0.373021\n",
      "\n",
      "[epoch: 342/400, batch: 232/1000, ite: 45530] train loss: 1.3855, accuracy: 94.8043%, tar: 0.0478 \n",
      "l0: 0.043864, l1: 0.045944, l2: 0.055590, l3: 0.080419, l4: 0.137929, l5: 0.270105, l6: 0.490543\n",
      "\n",
      "[epoch: 342/400, batch: 240/1000, ite: 45531] train loss: 1.3856, accuracy: 92.8518%, tar: 0.0478 \n",
      "l0: 0.040944, l1: 0.042259, l2: 0.049938, l3: 0.065667, l4: 0.107494, l5: 0.212885, l6: 0.448454\n",
      "\n",
      "[epoch: 342/400, batch: 248/1000, ite: 45532] train loss: 1.3856, accuracy: 93.9677%, tar: 0.0478 \n",
      "l0: 0.036664, l1: 0.037923, l2: 0.043682, l3: 0.061051, l4: 0.121369, l5: 0.235924, l6: 0.471037\n",
      "\n",
      "[epoch: 342/400, batch: 256/1000, ite: 45533] train loss: 1.3857, accuracy: 92.9393%, tar: 0.0478 \n",
      "l0: 0.030462, l1: 0.031747, l2: 0.040358, l3: 0.057134, l4: 0.102128, l5: 0.198145, l6: 0.469694\n",
      "\n",
      "[epoch: 342/400, batch: 264/1000, ite: 45534] train loss: 1.3857, accuracy: 94.3483%, tar: 0.0478 \n",
      "l0: 0.031204, l1: 0.032705, l2: 0.040714, l3: 0.059265, l4: 0.114462, l5: 0.215950, l6: 0.410335\n",
      "\n",
      "[epoch: 342/400, batch: 272/1000, ite: 45535] train loss: 1.3857, accuracy: 94.2814%, tar: 0.0478 \n",
      "l0: 0.033321, l1: 0.035330, l2: 0.044514, l3: 0.064202, l4: 0.109137, l5: 0.222398, l6: 0.414851\n",
      "\n",
      "[epoch: 342/400, batch: 280/1000, ite: 45536] train loss: 1.3857, accuracy: 94.5917%, tar: 0.0478 \n",
      "l0: 0.037582, l1: 0.039330, l2: 0.049205, l3: 0.068886, l4: 0.123343, l5: 0.261384, l6: 0.507449\n",
      "\n",
      "[epoch: 342/400, batch: 288/1000, ite: 45537] train loss: 1.3858, accuracy: 93.0870%, tar: 0.0478 \n",
      "l0: 0.035818, l1: 0.036798, l2: 0.045997, l3: 0.065907, l4: 0.106054, l5: 0.217868, l6: 0.440016\n",
      "\n",
      "[epoch: 342/400, batch: 296/1000, ite: 45538] train loss: 1.3858, accuracy: 93.5329%, tar: 0.0478 \n",
      "l0: 0.036247, l1: 0.038121, l2: 0.046755, l3: 0.066899, l4: 0.131076, l5: 0.269427, l6: 0.432864\n",
      "\n",
      "[epoch: 342/400, batch: 304/1000, ite: 45539] train loss: 1.3858, accuracy: 94.5802%, tar: 0.0478 \n",
      "l0: 0.032488, l1: 0.034098, l2: 0.040652, l3: 0.058869, l4: 0.131905, l5: 0.278082, l6: 0.419127\n",
      "\n",
      "[epoch: 342/400, batch: 312/1000, ite: 45540] train loss: 1.3859, accuracy: 94.9114%, tar: 0.0478 \n",
      "l0: 0.035106, l1: 0.037041, l2: 0.045074, l3: 0.067461, l4: 0.115535, l5: 0.213965, l6: 0.421583\n",
      "\n",
      "[epoch: 342/400, batch: 320/1000, ite: 45541] train loss: 1.3859, accuracy: 93.9974%, tar: 0.0478 \n",
      "l0: 0.037830, l1: 0.039937, l2: 0.049559, l3: 0.069071, l4: 0.125996, l5: 0.216508, l6: 0.505816\n",
      "\n",
      "[epoch: 342/400, batch: 328/1000, ite: 45542] train loss: 1.3860, accuracy: 93.6443%, tar: 0.0477 \n",
      "l0: 0.035353, l1: 0.036293, l2: 0.045699, l3: 0.065966, l4: 0.105336, l5: 0.169618, l6: 0.355861\n",
      "\n",
      "[epoch: 342/400, batch: 336/1000, ite: 45543] train loss: 1.3858, accuracy: 94.7789%, tar: 0.0477 \n",
      "l0: 0.040844, l1: 0.042170, l2: 0.050128, l3: 0.069597, l4: 0.125100, l5: 0.227448, l6: 0.371861\n",
      "\n",
      "[epoch: 342/400, batch: 344/1000, ite: 45544] train loss: 1.3858, accuracy: 93.7324%, tar: 0.0477 \n",
      "l0: 0.026607, l1: 0.028487, l2: 0.038006, l3: 0.055570, l4: 0.119541, l5: 0.229337, l6: 0.400214\n",
      "\n",
      "[epoch: 342/400, batch: 352/1000, ite: 45545] train loss: 1.3857, accuracy: 95.0390%, tar: 0.0477 \n",
      "l0: 0.027400, l1: 0.028165, l2: 0.034085, l3: 0.045350, l4: 0.072607, l5: 0.129014, l6: 0.270220\n",
      "\n",
      "[epoch: 342/400, batch: 360/1000, ite: 45546] train loss: 1.3854, accuracy: 95.1916%, tar: 0.0477 \n",
      "l0: 0.032183, l1: 0.033251, l2: 0.041268, l3: 0.061557, l4: 0.115574, l5: 0.248818, l6: 0.442593\n",
      "\n",
      "[epoch: 342/400, batch: 368/1000, ite: 45547] train loss: 1.3854, accuracy: 93.6742%, tar: 0.0477 \n",
      "l0: 0.037873, l1: 0.039772, l2: 0.050133, l3: 0.077974, l4: 0.161242, l5: 0.334441, l6: 0.577586\n",
      "\n",
      "[epoch: 342/400, batch: 376/1000, ite: 45548] train loss: 1.3857, accuracy: 92.9769%, tar: 0.0477 \n",
      "l0: 0.040057, l1: 0.042191, l2: 0.052485, l3: 0.074309, l4: 0.134825, l5: 0.285500, l6: 0.522207\n",
      "\n",
      "[epoch: 342/400, batch: 384/1000, ite: 45549] train loss: 1.3859, accuracy: 93.4351%, tar: 0.0477 \n",
      "l0: 0.037920, l1: 0.039175, l2: 0.048357, l3: 0.066225, l4: 0.114172, l5: 0.234070, l6: 0.480992\n",
      "\n",
      "[epoch: 342/400, batch: 392/1000, ite: 45550] train loss: 1.3860, accuracy: 93.1558%, tar: 0.0477 \n",
      "l0: 0.029756, l1: 0.031021, l2: 0.039180, l3: 0.059384, l4: 0.099799, l5: 0.179245, l6: 0.336297\n",
      "\n",
      "[epoch: 342/400, batch: 400/1000, ite: 45551] train loss: 1.3858, accuracy: 95.4445%, tar: 0.0477 \n",
      "l0: 0.030460, l1: 0.031298, l2: 0.038679, l3: 0.054597, l4: 0.093476, l5: 0.170077, l6: 0.358137\n",
      "\n",
      "[epoch: 342/400, batch: 408/1000, ite: 45552] train loss: 1.3857, accuracy: 94.3279%, tar: 0.0477 \n",
      "l0: 0.034042, l1: 0.035676, l2: 0.044666, l3: 0.066150, l4: 0.116743, l5: 0.200859, l6: 0.401071\n",
      "\n",
      "[epoch: 342/400, batch: 416/1000, ite: 45553] train loss: 1.3856, accuracy: 94.4813%, tar: 0.0476 \n",
      "l0: 0.027579, l1: 0.028727, l2: 0.035292, l3: 0.053157, l4: 0.094286, l5: 0.202951, l6: 0.452696\n",
      "\n",
      "[epoch: 342/400, batch: 424/1000, ite: 45554] train loss: 1.3856, accuracy: 94.1946%, tar: 0.0476 \n",
      "l0: 0.042622, l1: 0.044296, l2: 0.055190, l3: 0.081812, l4: 0.146394, l5: 0.267286, l6: 0.440604\n",
      "\n",
      "[epoch: 342/400, batch: 432/1000, ite: 45555] train loss: 1.3857, accuracy: 93.7698%, tar: 0.0476 \n",
      "l0: 0.033731, l1: 0.035333, l2: 0.043784, l3: 0.065313, l4: 0.130727, l5: 0.249197, l6: 0.492947\n",
      "\n",
      "[epoch: 342/400, batch: 440/1000, ite: 45556] train loss: 1.3858, accuracy: 93.2377%, tar: 0.0476 \n",
      "l0: 0.034660, l1: 0.036031, l2: 0.045625, l3: 0.063063, l4: 0.105915, l5: 0.206797, l6: 0.393486\n",
      "\n",
      "[epoch: 342/400, batch: 448/1000, ite: 45557] train loss: 1.3857, accuracy: 94.4796%, tar: 0.0476 \n",
      "l0: 0.029664, l1: 0.030583, l2: 0.036334, l3: 0.051675, l4: 0.091514, l5: 0.223859, l6: 0.338236\n",
      "\n",
      "[epoch: 342/400, batch: 456/1000, ite: 45558] train loss: 1.3856, accuracy: 94.7060%, tar: 0.0476 \n",
      "l0: 0.031380, l1: 0.032971, l2: 0.043907, l3: 0.068681, l4: 0.130293, l5: 0.263138, l6: 0.478369\n",
      "\n",
      "[epoch: 342/400, batch: 464/1000, ite: 45559] train loss: 1.3857, accuracy: 94.0743%, tar: 0.0476 \n",
      "l0: 0.026347, l1: 0.027111, l2: 0.034751, l3: 0.047700, l4: 0.074871, l5: 0.150487, l6: 0.288464\n",
      "\n",
      "[epoch: 342/400, batch: 472/1000, ite: 45560] train loss: 1.3854, accuracy: 95.1141%, tar: 0.0476 \n",
      "l0: 0.034624, l1: 0.035754, l2: 0.043736, l3: 0.064681, l4: 0.119458, l5: 0.266875, l6: 0.481159\n",
      "\n",
      "[epoch: 342/400, batch: 480/1000, ite: 45561] train loss: 1.3855, accuracy: 93.2163%, tar: 0.0476 \n",
      "l0: 0.041133, l1: 0.041988, l2: 0.052878, l3: 0.078907, l4: 0.132625, l5: 0.232404, l6: 0.452854\n",
      "\n",
      "[epoch: 342/400, batch: 488/1000, ite: 45562] train loss: 1.3856, accuracy: 93.0445%, tar: 0.0476 \n",
      "l0: 0.028216, l1: 0.029530, l2: 0.036440, l3: 0.052248, l4: 0.092364, l5: 0.168758, l6: 0.365294\n",
      "\n",
      "[epoch: 342/400, batch: 496/1000, ite: 45563] train loss: 1.3854, accuracy: 94.3781%, tar: 0.0476 \n",
      "l0: 0.027716, l1: 0.028681, l2: 0.035259, l3: 0.045231, l4: 0.072851, l5: 0.145169, l6: 0.297140\n",
      "\n",
      "[epoch: 342/400, batch: 504/1000, ite: 45564] train loss: 1.3851, accuracy: 95.8185%, tar: 0.0475 \n",
      "l0: 0.035711, l1: 0.040016, l2: 0.048187, l3: 0.066082, l4: 0.117802, l5: 0.202760, l6: 0.381138\n",
      "\n",
      "[epoch: 342/400, batch: 512/1000, ite: 45565] train loss: 1.3851, accuracy: 94.4708%, tar: 0.0475 \n",
      "l0: 0.028146, l1: 0.029449, l2: 0.037050, l3: 0.051931, l4: 0.095459, l5: 0.162024, l6: 0.369906\n",
      "\n",
      "[epoch: 342/400, batch: 520/1000, ite: 45566] train loss: 1.3849, accuracy: 94.8866%, tar: 0.0475 \n",
      "l0: 0.031259, l1: 0.032217, l2: 0.039628, l3: 0.054439, l4: 0.097786, l5: 0.175173, l6: 0.326342\n",
      "\n",
      "[epoch: 342/400, batch: 528/1000, ite: 45567] train loss: 1.3847, accuracy: 95.2803%, tar: 0.0475 \n",
      "l0: 0.032451, l1: 0.033634, l2: 0.041691, l3: 0.061329, l4: 0.112930, l5: 0.209400, l6: 0.405969\n",
      "\n",
      "[epoch: 342/400, batch: 536/1000, ite: 45568] train loss: 1.3847, accuracy: 94.2103%, tar: 0.0475 \n",
      "l0: 0.031831, l1: 0.034380, l2: 0.043182, l3: 0.061599, l4: 0.127544, l5: 0.265736, l6: 0.459704\n",
      "\n",
      "[epoch: 342/400, batch: 544/1000, ite: 45569] train loss: 1.3848, accuracy: 94.6180%, tar: 0.0475 \n",
      "l0: 0.028782, l1: 0.029807, l2: 0.037134, l3: 0.052174, l4: 0.080174, l5: 0.140584, l6: 0.299037\n",
      "\n",
      "[epoch: 342/400, batch: 552/1000, ite: 45570] train loss: 1.3845, accuracy: 95.3953%, tar: 0.0475 \n",
      "l0: 0.033160, l1: 0.033917, l2: 0.041441, l3: 0.057358, l4: 0.087437, l5: 0.140754, l6: 0.259288\n",
      "\n",
      "[epoch: 342/400, batch: 560/1000, ite: 45571] train loss: 1.3842, accuracy: 95.0516%, tar: 0.0475 \n",
      "l0: 0.036472, l1: 0.037628, l2: 0.046504, l3: 0.066736, l4: 0.112211, l5: 0.184585, l6: 0.393808\n",
      "\n",
      "[epoch: 342/400, batch: 568/1000, ite: 45572] train loss: 1.3841, accuracy: 94.6966%, tar: 0.0475 \n",
      "l0: 0.043173, l1: 0.045547, l2: 0.054987, l3: 0.079128, l4: 0.152371, l5: 0.307942, l6: 0.525089\n",
      "\n",
      "[epoch: 342/400, batch: 576/1000, ite: 45573] train loss: 1.3844, accuracy: 92.9818%, tar: 0.0475 \n",
      "l0: 0.027730, l1: 0.028697, l2: 0.034960, l3: 0.048878, l4: 0.080469, l5: 0.142875, l6: 0.273996\n",
      "\n",
      "[epoch: 342/400, batch: 584/1000, ite: 45574] train loss: 1.3841, accuracy: 95.8251%, tar: 0.0474 \n",
      "l0: 0.031693, l1: 0.032769, l2: 0.039696, l3: 0.054939, l4: 0.094765, l5: 0.182290, l6: 0.399087\n",
      "\n",
      "[epoch: 342/400, batch: 592/1000, ite: 45575] train loss: 1.3840, accuracy: 93.9016%, tar: 0.0474 \n",
      "l0: 0.039042, l1: 0.040157, l2: 0.050838, l3: 0.077145, l4: 0.147302, l5: 0.283807, l6: 0.518454\n",
      "\n",
      "[epoch: 342/400, batch: 600/1000, ite: 45576] train loss: 1.3842, accuracy: 92.8534%, tar: 0.0474 \n",
      "l0: 0.040576, l1: 0.041614, l2: 0.050639, l3: 0.070589, l4: 0.109174, l5: 0.194527, l6: 0.434009\n",
      "\n",
      "[epoch: 342/400, batch: 608/1000, ite: 45577] train loss: 1.3842, accuracy: 93.8724%, tar: 0.0474 \n",
      "l0: 0.040827, l1: 0.042337, l2: 0.049193, l3: 0.066681, l4: 0.116395, l5: 0.239472, l6: 0.477195\n",
      "\n",
      "[epoch: 342/400, batch: 616/1000, ite: 45578] train loss: 1.3842, accuracy: 92.6899%, tar: 0.0474 \n",
      "l0: 0.036112, l1: 0.037336, l2: 0.047702, l3: 0.069897, l4: 0.130210, l5: 0.261263, l6: 0.442218\n",
      "\n",
      "[epoch: 342/400, batch: 624/1000, ite: 45579] train loss: 1.3843, accuracy: 93.9419%, tar: 0.0474 \n",
      "l0: 0.056531, l1: 0.057535, l2: 0.069259, l3: 0.090279, l4: 0.141322, l5: 0.259179, l6: 0.612604\n",
      "\n",
      "[epoch: 342/400, batch: 632/1000, ite: 45580] train loss: 1.3846, accuracy: 90.6630%, tar: 0.0474 \n",
      "l0: 0.028346, l1: 0.029518, l2: 0.037419, l3: 0.052332, l4: 0.092834, l5: 0.201755, l6: 0.391827\n",
      "\n",
      "[epoch: 342/400, batch: 640/1000, ite: 45581] train loss: 1.3845, accuracy: 93.9884%, tar: 0.0474 \n",
      "l0: 0.042687, l1: 0.044206, l2: 0.051578, l3: 0.074345, l4: 0.114577, l5: 0.211461, l6: 0.450137\n",
      "\n",
      "[epoch: 342/400, batch: 648/1000, ite: 45582] train loss: 1.3846, accuracy: 93.6047%, tar: 0.0474 \n",
      "l0: 0.028447, l1: 0.029567, l2: 0.036384, l3: 0.052270, l4: 0.096301, l5: 0.158315, l6: 0.314275\n",
      "\n",
      "[epoch: 342/400, batch: 656/1000, ite: 45583] train loss: 1.3844, accuracy: 95.0599%, tar: 0.0474 \n",
      "l0: 0.035015, l1: 0.035779, l2: 0.044200, l3: 0.059061, l4: 0.102364, l5: 0.175150, l6: 0.394637\n",
      "\n",
      "[epoch: 342/400, batch: 664/1000, ite: 45584] train loss: 1.3843, accuracy: 94.2735%, tar: 0.0474 \n",
      "l0: 0.030426, l1: 0.033113, l2: 0.046910, l3: 0.071631, l4: 0.130131, l5: 0.208087, l6: 0.339135\n",
      "\n",
      "[epoch: 342/400, batch: 672/1000, ite: 45585] train loss: 1.3841, accuracy: 96.0554%, tar: 0.0474 \n",
      "l0: 0.035021, l1: 0.035819, l2: 0.045670, l3: 0.063450, l4: 0.101664, l5: 0.188931, l6: 0.355292\n",
      "\n",
      "[epoch: 342/400, batch: 680/1000, ite: 45586] train loss: 1.3840, accuracy: 93.9495%, tar: 0.0474 \n",
      "l0: 0.033349, l1: 0.033982, l2: 0.043079, l3: 0.062190, l4: 0.108813, l5: 0.230792, l6: 0.444645\n",
      "\n",
      "[epoch: 342/400, batch: 688/1000, ite: 45587] train loss: 1.3840, accuracy: 92.9721%, tar: 0.0474 \n",
      "l0: 0.030780, l1: 0.031681, l2: 0.039840, l3: 0.060050, l4: 0.095806, l5: 0.170967, l6: 0.339073\n",
      "\n",
      "[epoch: 342/400, batch: 696/1000, ite: 45588] train loss: 1.3839, accuracy: 94.6600%, tar: 0.0474 \n",
      "l0: 0.030624, l1: 0.031738, l2: 0.037965, l3: 0.051196, l4: 0.081380, l5: 0.142764, l6: 0.384477\n",
      "\n",
      "[epoch: 342/400, batch: 704/1000, ite: 45589] train loss: 1.3837, accuracy: 94.3981%, tar: 0.0473 \n",
      "l0: 0.035229, l1: 0.035547, l2: 0.041032, l3: 0.056376, l4: 0.123553, l5: 0.266419, l6: 0.384333\n",
      "\n",
      "[epoch: 342/400, batch: 712/1000, ite: 45590] train loss: 1.3837, accuracy: 94.6460%, tar: 0.0473 \n",
      "l0: 0.030441, l1: 0.031550, l2: 0.039290, l3: 0.055609, l4: 0.088461, l5: 0.181627, l6: 0.365377\n",
      "\n",
      "[epoch: 342/400, batch: 720/1000, ite: 45591] train loss: 1.3836, accuracy: 94.6878%, tar: 0.0473 \n",
      "l0: 0.036334, l1: 0.037892, l2: 0.045552, l3: 0.065955, l4: 0.110177, l5: 0.226060, l6: 0.364170\n",
      "\n",
      "[epoch: 342/400, batch: 728/1000, ite: 45592] train loss: 1.3835, accuracy: 94.0880%, tar: 0.0473 \n",
      "l0: 0.030690, l1: 0.032354, l2: 0.041394, l3: 0.061501, l4: 0.123288, l5: 0.234111, l6: 0.434120\n",
      "\n",
      "[epoch: 342/400, batch: 736/1000, ite: 45593] train loss: 1.3835, accuracy: 94.2768%, tar: 0.0473 \n",
      "l0: 0.040511, l1: 0.042169, l2: 0.052133, l3: 0.071359, l4: 0.118641, l5: 0.281937, l6: 0.493828\n",
      "\n",
      "[epoch: 342/400, batch: 744/1000, ite: 45594] train loss: 1.3836, accuracy: 93.1943%, tar: 0.0473 \n",
      "l0: 0.039487, l1: 0.041797, l2: 0.054404, l3: 0.081774, l4: 0.158846, l5: 0.281698, l6: 0.494559\n",
      "\n",
      "[epoch: 342/400, batch: 752/1000, ite: 45595] train loss: 1.3838, accuracy: 93.3699%, tar: 0.0473 \n",
      "l0: 0.034923, l1: 0.036227, l2: 0.046372, l3: 0.069339, l4: 0.128715, l5: 0.273917, l6: 0.475774\n",
      "\n",
      "[epoch: 342/400, batch: 760/1000, ite: 45596] train loss: 1.3839, accuracy: 94.1001%, tar: 0.0473 \n",
      "l0: 0.024190, l1: 0.025637, l2: 0.033138, l3: 0.047256, l4: 0.080843, l5: 0.144087, l6: 0.286584\n",
      "\n",
      "[epoch: 342/400, batch: 768/1000, ite: 45597] train loss: 1.3836, accuracy: 95.9617%, tar: 0.0473 \n",
      "l0: 0.028328, l1: 0.029558, l2: 0.038380, l3: 0.053093, l4: 0.082715, l5: 0.161288, l6: 0.392972\n",
      "\n",
      "[epoch: 342/400, batch: 776/1000, ite: 45598] train loss: 1.3835, accuracy: 95.6671%, tar: 0.0473 \n",
      "l0: 0.037370, l1: 0.039047, l2: 0.046959, l3: 0.068404, l4: 0.122311, l5: 0.259176, l6: 0.454781\n",
      "\n",
      "[epoch: 342/400, batch: 784/1000, ite: 45599] train loss: 1.3836, accuracy: 92.4191%, tar: 0.0473 \n",
      "l0: 0.027984, l1: 0.029217, l2: 0.036753, l3: 0.053964, l4: 0.090605, l5: 0.154917, l6: 0.248563\n",
      "\n",
      "[epoch: 342/400, batch: 792/1000, ite: 45600] train loss: 1.3832, accuracy: 96.1980%, tar: 0.0472 \n",
      "l0: 0.029402, l1: 0.030073, l2: 0.035683, l3: 0.047824, l4: 0.080642, l5: 0.132724, l6: 0.295371\n",
      "\n",
      "[epoch: 342/400, batch: 800/1000, ite: 45601] train loss: 1.3830, accuracy: 95.1052%, tar: 0.0472 \n",
      "l0: 0.027473, l1: 0.029576, l2: 0.037568, l3: 0.053623, l4: 0.099401, l5: 0.182916, l6: 0.344238\n",
      "\n",
      "[epoch: 342/400, batch: 808/1000, ite: 45602] train loss: 1.3828, accuracy: 96.1029%, tar: 0.0472 \n",
      "l0: 0.036392, l1: 0.037539, l2: 0.045039, l3: 0.062219, l4: 0.102746, l5: 0.191531, l6: 0.336218\n",
      "\n",
      "[epoch: 342/400, batch: 816/1000, ite: 45603] train loss: 1.3827, accuracy: 94.3078%, tar: 0.0472 \n",
      "l0: 0.031856, l1: 0.033132, l2: 0.040934, l3: 0.059098, l4: 0.111855, l5: 0.233911, l6: 0.476586\n",
      "\n",
      "[epoch: 342/400, batch: 824/1000, ite: 45604] train loss: 1.3827, accuracy: 93.1383%, tar: 0.0472 \n",
      "l0: 0.027893, l1: 0.028480, l2: 0.034500, l3: 0.046981, l4: 0.084600, l5: 0.175174, l6: 0.288929\n",
      "\n",
      "[epoch: 342/400, batch: 832/1000, ite: 45605] train loss: 1.3825, accuracy: 95.3107%, tar: 0.0472 \n",
      "l0: 0.028806, l1: 0.030494, l2: 0.041146, l3: 0.061315, l4: 0.110281, l5: 0.192197, l6: 0.391160\n",
      "\n",
      "[epoch: 342/400, batch: 840/1000, ite: 45606] train loss: 1.3824, accuracy: 94.7362%, tar: 0.0472 \n",
      "l0: 0.044976, l1: 0.046482, l2: 0.054861, l3: 0.073132, l4: 0.128039, l5: 0.243639, l6: 0.471897\n",
      "\n",
      "[epoch: 342/400, batch: 848/1000, ite: 45607] train loss: 1.3825, accuracy: 93.1686%, tar: 0.0472 \n",
      "l0: 0.037566, l1: 0.039218, l2: 0.049417, l3: 0.072955, l4: 0.128676, l5: 0.252342, l6: 0.498817\n",
      "\n",
      "[epoch: 342/400, batch: 856/1000, ite: 45608] train loss: 1.3826, accuracy: 93.4537%, tar: 0.0472 \n",
      "l0: 0.033651, l1: 0.035013, l2: 0.043730, l3: 0.060764, l4: 0.096911, l5: 0.171878, l6: 0.333003\n",
      "\n",
      "[epoch: 342/400, batch: 864/1000, ite: 45609] train loss: 1.3825, accuracy: 95.0508%, tar: 0.0472 \n",
      "l0: 0.034297, l1: 0.035548, l2: 0.041958, l3: 0.059575, l4: 0.096330, l5: 0.188347, l6: 0.364467\n",
      "\n",
      "[epoch: 342/400, batch: 872/1000, ite: 45610] train loss: 1.3823, accuracy: 94.4490%, tar: 0.0472 \n",
      "l0: 0.031964, l1: 0.033351, l2: 0.041159, l3: 0.059025, l4: 0.108807, l5: 0.206277, l6: 0.417490\n",
      "\n",
      "[epoch: 342/400, batch: 880/1000, ite: 45611] train loss: 1.3823, accuracy: 94.0188%, tar: 0.0471 \n",
      "l0: 0.026177, l1: 0.027108, l2: 0.033442, l3: 0.047898, l4: 0.076794, l5: 0.148167, l6: 0.283240\n",
      "\n",
      "[epoch: 342/400, batch: 888/1000, ite: 45612] train loss: 1.3820, accuracy: 95.3665%, tar: 0.0471 \n",
      "l0: 0.037593, l1: 0.038773, l2: 0.045679, l3: 0.061185, l4: 0.097356, l5: 0.174200, l6: 0.318266\n",
      "\n",
      "[epoch: 342/400, batch: 896/1000, ite: 45613] train loss: 1.3819, accuracy: 94.1892%, tar: 0.0471 \n",
      "l0: 0.027819, l1: 0.028679, l2: 0.035409, l3: 0.051832, l4: 0.098640, l5: 0.169058, l6: 0.280922\n",
      "\n",
      "[epoch: 342/400, batch: 904/1000, ite: 45614] train loss: 1.3816, accuracy: 95.1377%, tar: 0.0471 \n",
      "l0: 0.048106, l1: 0.048987, l2: 0.061359, l3: 0.083064, l4: 0.143906, l5: 0.290526, l6: 0.539644\n",
      "\n",
      "[epoch: 342/400, batch: 912/1000, ite: 45615] train loss: 1.3818, accuracy: 91.8612%, tar: 0.0471 \n",
      "l0: 0.031806, l1: 0.032459, l2: 0.038408, l3: 0.050858, l4: 0.087975, l5: 0.175155, l6: 0.351754\n",
      "\n",
      "[epoch: 342/400, batch: 920/1000, ite: 45616] train loss: 1.3817, accuracy: 94.5602%, tar: 0.0471 \n",
      "l0: 0.028329, l1: 0.029678, l2: 0.037293, l3: 0.054386, l4: 0.087363, l5: 0.138029, l6: 0.291938\n",
      "\n",
      "[epoch: 342/400, batch: 928/1000, ite: 45617] train loss: 1.3814, accuracy: 95.2983%, tar: 0.0471 \n",
      "l0: 0.021215, l1: 0.022141, l2: 0.028167, l3: 0.039225, l4: 0.063592, l5: 0.126774, l6: 0.281575\n",
      "\n",
      "[epoch: 342/400, batch: 936/1000, ite: 45618] train loss: 1.3811, accuracy: 96.0047%, tar: 0.0471 \n",
      "l0: 0.034171, l1: 0.035333, l2: 0.043519, l3: 0.068446, l4: 0.133159, l5: 0.230557, l6: 0.421452\n",
      "\n",
      "[epoch: 342/400, batch: 944/1000, ite: 45619] train loss: 1.3811, accuracy: 94.4743%, tar: 0.0471 \n",
      "l0: 0.035758, l1: 0.036708, l2: 0.045834, l3: 0.067513, l4: 0.114043, l5: 0.232174, l6: 0.477178\n",
      "\n",
      "[epoch: 342/400, batch: 952/1000, ite: 45620] train loss: 1.3812, accuracy: 93.1243%, tar: 0.0471 \n",
      "l0: 0.042513, l1: 0.044128, l2: 0.055936, l3: 0.079673, l4: 0.138890, l5: 0.278448, l6: 0.484542\n",
      "\n",
      "[epoch: 342/400, batch: 960/1000, ite: 45621] train loss: 1.3813, accuracy: 92.4799%, tar: 0.0471 \n",
      "l0: 0.029508, l1: 0.030687, l2: 0.036031, l3: 0.048229, l4: 0.077158, l5: 0.169202, l6: 0.309283\n",
      "\n",
      "[epoch: 342/400, batch: 968/1000, ite: 45622] train loss: 1.3811, accuracy: 94.9482%, tar: 0.0471 \n",
      "l0: 0.042164, l1: 0.042779, l2: 0.051205, l3: 0.076582, l4: 0.138334, l5: 0.228522, l6: 0.395974\n",
      "\n",
      "[epoch: 342/400, batch: 976/1000, ite: 45623] train loss: 1.3811, accuracy: 93.7064%, tar: 0.0470 \n",
      "l0: 0.031575, l1: 0.032879, l2: 0.040818, l3: 0.059008, l4: 0.097270, l5: 0.172956, l6: 0.300081\n",
      "\n",
      "[epoch: 342/400, batch: 984/1000, ite: 45624] train loss: 1.3809, accuracy: 94.7915%, tar: 0.0470 \n",
      "l0: 0.034889, l1: 0.035965, l2: 0.045877, l3: 0.074887, l4: 0.143786, l5: 0.245264, l6: 0.464003\n",
      "\n",
      "[epoch: 342/400, batch: 992/1000, ite: 45625] train loss: 1.3810, accuracy: 93.9857%, tar: 0.0470 \n",
      "l0: 0.024621, l1: 0.025425, l2: 0.031555, l3: 0.045099, l4: 0.076924, l5: 0.146204, l6: 0.306743\n",
      "\n",
      "[epoch: 342/400, batch: 1000/1000, ite: 45626] train loss: 1.3808, accuracy: 95.3707%, tar: 0.0470 \n",
      "l0: 0.038305, l1: 0.039311, l2: 0.047968, l3: 0.066870, l4: 0.115848, l5: 0.203762, l6: 0.375429\n",
      "\n",
      "[epoch: 343/400, batch: 8/1000, ite: 45627] train loss: 1.3807, accuracy: 94.5966%, tar: 0.0470 \n",
      "l0: 0.033615, l1: 0.034856, l2: 0.042805, l3: 0.062134, l4: 0.105342, l5: 0.209949, l6: 0.446285\n",
      "\n",
      "[epoch: 343/400, batch: 16/1000, ite: 45628] train loss: 1.3807, accuracy: 92.9046%, tar: 0.0470 \n",
      "l0: 0.031014, l1: 0.033596, l2: 0.043939, l3: 0.066367, l4: 0.117565, l5: 0.245839, l6: 0.443749\n",
      "\n",
      "[epoch: 343/400, batch: 24/1000, ite: 45629] train loss: 1.3807, accuracy: 95.1115%, tar: 0.0470 \n",
      "l0: 0.035516, l1: 0.036948, l2: 0.046026, l3: 0.064835, l4: 0.123054, l5: 0.237412, l6: 0.481524\n",
      "\n",
      "[epoch: 343/400, batch: 32/1000, ite: 45630] train loss: 1.3808, accuracy: 93.9028%, tar: 0.0470 \n",
      "l0: 0.031929, l1: 0.032910, l2: 0.039464, l3: 0.054945, l4: 0.083494, l5: 0.162066, l6: 0.367497\n",
      "\n",
      "[epoch: 343/400, batch: 40/1000, ite: 45631] train loss: 1.3807, accuracy: 94.6871%, tar: 0.0470 \n",
      "l0: 0.043530, l1: 0.045150, l2: 0.053976, l3: 0.075347, l4: 0.139515, l5: 0.262505, l6: 0.570337\n",
      "\n",
      "[epoch: 343/400, batch: 48/1000, ite: 45632] train loss: 1.3809, accuracy: 92.5416%, tar: 0.0470 \n",
      "l0: 0.028598, l1: 0.029651, l2: 0.037714, l3: 0.052054, l4: 0.083261, l5: 0.149821, l6: 0.277547\n",
      "\n",
      "[epoch: 343/400, batch: 56/1000, ite: 45633] train loss: 1.3806, accuracy: 95.9274%, tar: 0.0470 \n",
      "l0: 0.036615, l1: 0.037610, l2: 0.045131, l3: 0.065009, l4: 0.112249, l5: 0.182678, l6: 0.362754\n",
      "\n",
      "[epoch: 343/400, batch: 64/1000, ite: 45634] train loss: 1.3805, accuracy: 93.8870%, tar: 0.0470 \n",
      "l0: 0.028231, l1: 0.029088, l2: 0.036114, l3: 0.048783, l4: 0.080445, l5: 0.153046, l6: 0.340780\n",
      "\n",
      "[epoch: 343/400, batch: 72/1000, ite: 45635] train loss: 1.3803, accuracy: 95.1026%, tar: 0.0469 \n",
      "l0: 0.033654, l1: 0.036065, l2: 0.047998, l3: 0.070782, l4: 0.125722, l5: 0.268500, l6: 0.477454\n",
      "\n",
      "[epoch: 343/400, batch: 80/1000, ite: 45636] train loss: 1.3804, accuracy: 94.3334%, tar: 0.0469 \n",
      "l0: 0.023035, l1: 0.023857, l2: 0.029067, l3: 0.039282, l4: 0.059610, l5: 0.104486, l6: 0.208489\n",
      "\n",
      "[epoch: 343/400, batch: 88/1000, ite: 45637] train loss: 1.3800, accuracy: 96.2307%, tar: 0.0469 \n",
      "l0: 0.023503, l1: 0.024329, l2: 0.030397, l3: 0.044841, l4: 0.079671, l5: 0.159970, l6: 0.349808\n",
      "\n",
      "[epoch: 343/400, batch: 96/1000, ite: 45638] train loss: 1.3798, accuracy: 95.6141%, tar: 0.0469 \n",
      "l0: 0.035803, l1: 0.037504, l2: 0.047340, l3: 0.070173, l4: 0.139950, l5: 0.262587, l6: 0.468070\n",
      "\n",
      "[epoch: 343/400, batch: 104/1000, ite: 45639] train loss: 1.3799, accuracy: 93.5614%, tar: 0.0469 \n",
      "l0: 0.028749, l1: 0.030146, l2: 0.037669, l3: 0.052419, l4: 0.085055, l5: 0.156111, l6: 0.288273\n",
      "\n",
      "[epoch: 343/400, batch: 112/1000, ite: 45640] train loss: 1.3797, accuracy: 94.9174%, tar: 0.0469 \n",
      "l0: 0.032037, l1: 0.032519, l2: 0.040554, l3: 0.057697, l4: 0.097944, l5: 0.191428, l6: 0.360688\n",
      "\n",
      "[epoch: 343/400, batch: 120/1000, ite: 45641] train loss: 1.3795, accuracy: 94.5649%, tar: 0.0469 \n",
      "l0: 0.028718, l1: 0.030006, l2: 0.037513, l3: 0.049958, l4: 0.094781, l5: 0.174080, l6: 0.356906\n",
      "\n",
      "[epoch: 343/400, batch: 128/1000, ite: 45642] train loss: 1.3794, accuracy: 95.1937%, tar: 0.0469 \n",
      "l0: 0.033534, l1: 0.034702, l2: 0.044422, l3: 0.064705, l4: 0.114158, l5: 0.233856, l6: 0.441546\n",
      "\n",
      "[epoch: 343/400, batch: 136/1000, ite: 45643] train loss: 1.3794, accuracy: 93.3132%, tar: 0.0469 \n",
      "l0: 0.026256, l1: 0.027231, l2: 0.033578, l3: 0.044055, l4: 0.074784, l5: 0.155185, l6: 0.340658\n",
      "\n",
      "[epoch: 343/400, batch: 144/1000, ite: 45644] train loss: 1.3792, accuracy: 96.0914%, tar: 0.0469 \n",
      "l0: 0.036546, l1: 0.038486, l2: 0.046963, l3: 0.066929, l4: 0.120030, l5: 0.194560, l6: 0.314686\n",
      "\n",
      "[epoch: 343/400, batch: 152/1000, ite: 45645] train loss: 1.3791, accuracy: 95.1693%, tar: 0.0468 \n",
      "l0: 0.031210, l1: 0.031978, l2: 0.040831, l3: 0.056253, l4: 0.100702, l5: 0.193192, l6: 0.404382\n",
      "\n",
      "[epoch: 343/400, batch: 160/1000, ite: 45646] train loss: 1.3790, accuracy: 94.4074%, tar: 0.0468 \n",
      "l0: 0.037033, l1: 0.038210, l2: 0.047781, l3: 0.068061, l4: 0.113791, l5: 0.242982, l6: 0.468541\n",
      "\n",
      "[epoch: 343/400, batch: 168/1000, ite: 45647] train loss: 1.3791, accuracy: 93.0756%, tar: 0.0468 \n",
      "l0: 0.034831, l1: 0.036103, l2: 0.045529, l3: 0.065945, l4: 0.115268, l5: 0.214489, l6: 0.409633\n",
      "\n",
      "[epoch: 343/400, batch: 176/1000, ite: 45648] train loss: 1.3791, accuracy: 93.3335%, tar: 0.0468 \n",
      "l0: 0.026093, l1: 0.026804, l2: 0.033734, l3: 0.046946, l4: 0.078725, l5: 0.136219, l6: 0.267765\n",
      "\n",
      "[epoch: 343/400, batch: 184/1000, ite: 45649] train loss: 1.3788, accuracy: 95.3075%, tar: 0.0468 \n",
      "l0: 0.031739, l1: 0.033463, l2: 0.045603, l3: 0.072251, l4: 0.135810, l5: 0.300899, l6: 0.635179\n",
      "\n",
      "[epoch: 343/400, batch: 192/1000, ite: 45650] train loss: 1.3791, accuracy: 91.9932%, tar: 0.0468 \n",
      "l0: 0.034873, l1: 0.036390, l2: 0.045464, l3: 0.061771, l4: 0.108244, l5: 0.248550, l6: 0.479478\n",
      "\n",
      "[epoch: 343/400, batch: 200/1000, ite: 45651] train loss: 1.3792, accuracy: 92.9069%, tar: 0.0468 \n",
      "l0: 0.033935, l1: 0.034940, l2: 0.042964, l3: 0.057713, l4: 0.092777, l5: 0.174574, l6: 0.365743\n",
      "\n",
      "[epoch: 343/400, batch: 208/1000, ite: 45652] train loss: 1.3790, accuracy: 94.2169%, tar: 0.0468 \n",
      "l0: 0.027224, l1: 0.028946, l2: 0.036665, l3: 0.054968, l4: 0.094524, l5: 0.160959, l6: 0.318593\n",
      "\n",
      "[epoch: 343/400, batch: 216/1000, ite: 45653] train loss: 1.3788, accuracy: 95.3579%, tar: 0.0468 \n",
      "l0: 0.022913, l1: 0.024545, l2: 0.031076, l3: 0.046770, l4: 0.077228, l5: 0.146533, l6: 0.262485\n",
      "\n",
      "[epoch: 343/400, batch: 224/1000, ite: 45654] train loss: 1.3785, accuracy: 95.9383%, tar: 0.0468 \n",
      "l0: 0.036051, l1: 0.037088, l2: 0.044227, l3: 0.057065, l4: 0.090065, l5: 0.171469, l6: 0.367712\n",
      "\n",
      "[epoch: 343/400, batch: 232/1000, ite: 45655] train loss: 1.3784, accuracy: 94.6540%, tar: 0.0468 \n",
      "l0: 0.031642, l1: 0.032475, l2: 0.040378, l3: 0.056033, l4: 0.106412, l5: 0.213491, l6: 0.385846\n",
      "\n",
      "[epoch: 343/400, batch: 240/1000, ite: 45656] train loss: 1.3783, accuracy: 94.5543%, tar: 0.0467 \n",
      "l0: 0.030888, l1: 0.032469, l2: 0.042747, l3: 0.066217, l4: 0.133216, l5: 0.255859, l6: 0.472572\n",
      "\n",
      "[epoch: 343/400, batch: 248/1000, ite: 45657] train loss: 1.3784, accuracy: 94.0350%, tar: 0.0467 \n",
      "l0: 0.032140, l1: 0.034011, l2: 0.043797, l3: 0.076462, l4: 0.151264, l5: 0.258283, l6: 0.416575\n",
      "\n",
      "[epoch: 343/400, batch: 256/1000, ite: 45658] train loss: 1.3785, accuracy: 94.1673%, tar: 0.0467 \n",
      "l0: 0.035678, l1: 0.036980, l2: 0.044594, l3: 0.060887, l4: 0.105105, l5: 0.210640, l6: 0.402187\n",
      "\n",
      "[epoch: 343/400, batch: 264/1000, ite: 45659] train loss: 1.3784, accuracy: 93.2924%, tar: 0.0467 \n",
      "l0: 0.027464, l1: 0.028839, l2: 0.037408, l3: 0.055608, l4: 0.108111, l5: 0.217877, l6: 0.366257\n",
      "\n",
      "[epoch: 343/400, batch: 272/1000, ite: 45660] train loss: 1.3783, accuracy: 94.9195%, tar: 0.0467 \n",
      "l0: 0.035750, l1: 0.037720, l2: 0.050535, l3: 0.081528, l4: 0.157264, l5: 0.278273, l6: 0.480438\n",
      "\n",
      "[epoch: 343/400, batch: 280/1000, ite: 45661] train loss: 1.3784, accuracy: 93.8528%, tar: 0.0467 \n",
      "l0: 0.034196, l1: 0.035266, l2: 0.045232, l3: 0.063323, l4: 0.107393, l5: 0.174525, l6: 0.320311\n",
      "\n",
      "[epoch: 343/400, batch: 288/1000, ite: 45662] train loss: 1.3783, accuracy: 95.0074%, tar: 0.0467 \n",
      "l0: 0.029898, l1: 0.031368, l2: 0.039561, l3: 0.054498, l4: 0.101075, l5: 0.243694, l6: 0.409126\n",
      "\n",
      "[epoch: 343/400, batch: 296/1000, ite: 45663] train loss: 1.3783, accuracy: 94.2613%, tar: 0.0467 \n",
      "l0: 0.023041, l1: 0.024787, l2: 0.033836, l3: 0.059550, l4: 0.100117, l5: 0.163782, l6: 0.319089\n",
      "\n",
      "[epoch: 343/400, batch: 304/1000, ite: 45664] train loss: 1.3781, accuracy: 95.8309%, tar: 0.0467 \n",
      "l0: 0.031078, l1: 0.031975, l2: 0.038795, l3: 0.053441, l4: 0.084949, l5: 0.151294, l6: 0.284061\n",
      "\n",
      "[epoch: 343/400, batch: 312/1000, ite: 45665] train loss: 1.3778, accuracy: 94.4841%, tar: 0.0467 \n",
      "l0: 0.031179, l1: 0.031737, l2: 0.038494, l3: 0.054472, l4: 0.098181, l5: 0.186026, l6: 0.363472\n",
      "\n",
      "[epoch: 343/400, batch: 320/1000, ite: 45666] train loss: 1.3777, accuracy: 94.5069%, tar: 0.0466 \n",
      "l0: 0.025359, l1: 0.026438, l2: 0.033560, l3: 0.048342, l4: 0.082340, l5: 0.153089, l6: 0.361808\n",
      "\n",
      "[epoch: 343/400, batch: 328/1000, ite: 45667] train loss: 1.3775, accuracy: 95.0208%, tar: 0.0466 \n",
      "l0: 0.038193, l1: 0.039552, l2: 0.050476, l3: 0.074177, l4: 0.136240, l5: 0.310427, l6: 0.607088\n",
      "\n",
      "[epoch: 343/400, batch: 336/1000, ite: 45668] train loss: 1.3778, accuracy: 91.0055%, tar: 0.0466 \n",
      "l0: 0.027468, l1: 0.028957, l2: 0.036141, l3: 0.051615, l4: 0.089630, l5: 0.182847, l6: 0.331059\n",
      "\n",
      "[epoch: 343/400, batch: 344/1000, ite: 45669] train loss: 1.3776, accuracy: 95.3207%, tar: 0.0466 \n",
      "l0: 0.027342, l1: 0.028182, l2: 0.034947, l3: 0.049148, l4: 0.086527, l5: 0.156473, l6: 0.326736\n",
      "\n",
      "[epoch: 343/400, batch: 352/1000, ite: 45670] train loss: 1.3774, accuracy: 94.7319%, tar: 0.0466 \n",
      "l0: 0.022292, l1: 0.023137, l2: 0.030673, l3: 0.043782, l4: 0.069015, l5: 0.138678, l6: 0.308699\n",
      "\n",
      "[epoch: 343/400, batch: 360/1000, ite: 45671] train loss: 1.3772, accuracy: 95.1515%, tar: 0.0466 \n",
      "l0: 0.025923, l1: 0.026957, l2: 0.035119, l3: 0.049304, l4: 0.085647, l5: 0.168000, l6: 0.340343\n",
      "\n",
      "[epoch: 343/400, batch: 368/1000, ite: 45672] train loss: 1.3770, accuracy: 95.0477%, tar: 0.0466 \n",
      "l0: 0.024468, l1: 0.025476, l2: 0.032504, l3: 0.050275, l4: 0.099451, l5: 0.190376, l6: 0.358829\n",
      "\n",
      "[epoch: 343/400, batch: 376/1000, ite: 45673] train loss: 1.3769, accuracy: 94.5673%, tar: 0.0466 \n",
      "l0: 0.030986, l1: 0.033734, l2: 0.044009, l3: 0.068313, l4: 0.125522, l5: 0.214763, l6: 0.407683\n",
      "\n",
      "[epoch: 343/400, batch: 384/1000, ite: 45674] train loss: 1.3768, accuracy: 94.7611%, tar: 0.0466 \n",
      "l0: 0.029666, l1: 0.030403, l2: 0.037618, l3: 0.054416, l4: 0.100001, l5: 0.164107, l6: 0.325480\n",
      "\n",
      "[epoch: 343/400, batch: 392/1000, ite: 45675] train loss: 1.3767, accuracy: 94.8376%, tar: 0.0465 \n",
      "l0: 0.028512, l1: 0.030064, l2: 0.038692, l3: 0.052293, l4: 0.102811, l5: 0.175816, l6: 0.331787\n",
      "\n",
      "[epoch: 343/400, batch: 400/1000, ite: 45676] train loss: 1.3765, accuracy: 96.0062%, tar: 0.0465 \n",
      "l0: 0.030720, l1: 0.031949, l2: 0.040245, l3: 0.058748, l4: 0.100774, l5: 0.174909, l6: 0.346095\n",
      "\n",
      "[epoch: 343/400, batch: 408/1000, ite: 45677] train loss: 1.3763, accuracy: 94.4717%, tar: 0.0465 \n",
      "l0: 0.029572, l1: 0.031701, l2: 0.040057, l3: 0.066192, l4: 0.127545, l5: 0.241621, l6: 0.427393\n",
      "\n",
      "[epoch: 343/400, batch: 416/1000, ite: 45678] train loss: 1.3764, accuracy: 93.9644%, tar: 0.0465 \n",
      "l0: 0.027015, l1: 0.028214, l2: 0.036854, l3: 0.051740, l4: 0.088480, l5: 0.165749, l6: 0.314083\n",
      "\n",
      "[epoch: 343/400, batch: 424/1000, ite: 45679] train loss: 1.3762, accuracy: 95.4258%, tar: 0.0465 \n",
      "l0: 0.033584, l1: 0.034605, l2: 0.044303, l3: 0.062269, l4: 0.109653, l5: 0.221904, l6: 0.437514\n",
      "\n",
      "[epoch: 343/400, batch: 432/1000, ite: 45680] train loss: 1.3762, accuracy: 93.6562%, tar: 0.0465 \n",
      "l0: 0.024875, l1: 0.025809, l2: 0.033984, l3: 0.046088, l4: 0.081949, l5: 0.162811, l6: 0.355952\n",
      "\n",
      "[epoch: 343/400, batch: 440/1000, ite: 45681] train loss: 1.3760, accuracy: 94.9965%, tar: 0.0465 \n",
      "l0: 0.030065, l1: 0.031295, l2: 0.038331, l3: 0.053026, l4: 0.085733, l5: 0.157349, l6: 0.330938\n",
      "\n",
      "[epoch: 343/400, batch: 448/1000, ite: 45682] train loss: 1.3758, accuracy: 94.5472%, tar: 0.0465 \n",
      "l0: 0.037562, l1: 0.038607, l2: 0.046155, l3: 0.063927, l4: 0.106492, l5: 0.182337, l6: 0.367609\n",
      "\n",
      "[epoch: 343/400, batch: 456/1000, ite: 45683] train loss: 1.3757, accuracy: 93.3938%, tar: 0.0465 \n",
      "l0: 0.027458, l1: 0.028484, l2: 0.036094, l3: 0.052035, l4: 0.085550, l5: 0.167709, l6: 0.331571\n",
      "\n",
      "[epoch: 343/400, batch: 464/1000, ite: 45684] train loss: 1.3755, accuracy: 95.1111%, tar: 0.0465 \n",
      "l0: 0.029353, l1: 0.030724, l2: 0.036485, l3: 0.052878, l4: 0.089243, l5: 0.170918, l6: 0.288551\n",
      "\n",
      "[epoch: 343/400, batch: 472/1000, ite: 45685] train loss: 1.3753, accuracy: 95.7993%, tar: 0.0465 \n",
      "l0: 0.031178, l1: 0.032535, l2: 0.040353, l3: 0.059579, l4: 0.113246, l5: 0.191681, l6: 0.412442\n",
      "\n",
      "[epoch: 343/400, batch: 480/1000, ite: 45686] train loss: 1.3753, accuracy: 94.0210%, tar: 0.0464 \n",
      "l0: 0.027160, l1: 0.027936, l2: 0.035080, l3: 0.047993, l4: 0.092318, l5: 0.173824, l6: 0.293243\n",
      "\n",
      "[epoch: 343/400, batch: 488/1000, ite: 45687] train loss: 1.3750, accuracy: 94.9573%, tar: 0.0464 \n",
      "l0: 0.031854, l1: 0.033044, l2: 0.039931, l3: 0.057742, l4: 0.114345, l5: 0.211846, l6: 0.445978\n",
      "\n",
      "[epoch: 343/400, batch: 496/1000, ite: 45688] train loss: 1.3751, accuracy: 93.3226%, tar: 0.0464 \n",
      "l0: 0.031078, l1: 0.032098, l2: 0.040086, l3: 0.060916, l4: 0.097968, l5: 0.169205, l6: 0.334893\n",
      "\n",
      "[epoch: 343/400, batch: 504/1000, ite: 45689] train loss: 1.3749, accuracy: 94.5221%, tar: 0.0464 \n",
      "l0: 0.029707, l1: 0.030789, l2: 0.037623, l3: 0.049455, l4: 0.076411, l5: 0.132785, l6: 0.332808\n",
      "\n",
      "[epoch: 343/400, batch: 512/1000, ite: 45690] train loss: 1.3747, accuracy: 94.6837%, tar: 0.0464 \n",
      "l0: 0.031832, l1: 0.033134, l2: 0.043099, l3: 0.062109, l4: 0.118356, l5: 0.247010, l6: 0.410397\n",
      "\n",
      "[epoch: 343/400, batch: 520/1000, ite: 45691] train loss: 1.3747, accuracy: 93.9116%, tar: 0.0464 \n",
      "l0: 0.026347, l1: 0.028557, l2: 0.036282, l3: 0.053356, l4: 0.090579, l5: 0.156659, l6: 0.286227\n",
      "\n",
      "[epoch: 343/400, batch: 528/1000, ite: 45692] train loss: 1.3744, accuracy: 95.8998%, tar: 0.0464 \n",
      "l0: 0.022575, l1: 0.023855, l2: 0.031497, l3: 0.043509, l4: 0.075137, l5: 0.126600, l6: 0.283148\n",
      "\n",
      "[epoch: 343/400, batch: 536/1000, ite: 45693] train loss: 1.3742, accuracy: 95.4228%, tar: 0.0464 \n",
      "l0: 0.044295, l1: 0.046674, l2: 0.058096, l3: 0.082760, l4: 0.162652, l5: 0.259975, l6: 0.511755\n",
      "\n",
      "[epoch: 343/400, batch: 544/1000, ite: 45694] train loss: 1.3743, accuracy: 93.3276%, tar: 0.0464 \n",
      "l0: 0.032385, l1: 0.033416, l2: 0.040864, l3: 0.057298, l4: 0.099606, l5: 0.177678, l6: 0.378166\n",
      "\n",
      "[epoch: 343/400, batch: 552/1000, ite: 45695] train loss: 1.3742, accuracy: 94.4069%, tar: 0.0464 \n",
      "l0: 0.035864, l1: 0.037219, l2: 0.045057, l3: 0.060301, l4: 0.099630, l5: 0.182702, l6: 0.440962\n",
      "\n",
      "[epoch: 343/400, batch: 560/1000, ite: 45696] train loss: 1.3742, accuracy: 93.5365%, tar: 0.0464 \n",
      "l0: 0.032377, l1: 0.033640, l2: 0.040461, l3: 0.060770, l4: 0.112237, l5: 0.215067, l6: 0.413256\n",
      "\n",
      "[epoch: 343/400, batch: 568/1000, ite: 45697] train loss: 1.3742, accuracy: 93.3308%, tar: 0.0463 \n",
      "l0: 0.024349, l1: 0.026344, l2: 0.035666, l3: 0.061010, l4: 0.121520, l5: 0.196375, l6: 0.341151\n",
      "\n",
      "[epoch: 343/400, batch: 576/1000, ite: 45698] train loss: 1.3741, accuracy: 95.8422%, tar: 0.0463 \n",
      "l0: 0.023962, l1: 0.025628, l2: 0.032948, l3: 0.045595, l4: 0.079666, l5: 0.155772, l6: 0.297370\n",
      "\n",
      "[epoch: 343/400, batch: 584/1000, ite: 45699] train loss: 1.3738, accuracy: 95.9269%, tar: 0.0463 \n",
      "l0: 0.031439, l1: 0.032575, l2: 0.040700, l3: 0.058700, l4: 0.106543, l5: 0.195385, l6: 0.408541\n",
      "\n",
      "[epoch: 343/400, batch: 592/1000, ite: 45700] train loss: 1.3738, accuracy: 93.7564%, tar: 0.0463 \n",
      "l0: 0.027663, l1: 0.029065, l2: 0.037933, l3: 0.058128, l4: 0.110428, l5: 0.210974, l6: 0.439108\n",
      "\n",
      "[epoch: 343/400, batch: 600/1000, ite: 45701] train loss: 1.3738, accuracy: 93.9688%, tar: 0.0463 \n",
      "l0: 0.038036, l1: 0.039380, l2: 0.048273, l3: 0.068706, l4: 0.119549, l5: 0.233378, l6: 0.481499\n",
      "\n",
      "[epoch: 343/400, batch: 608/1000, ite: 45702] train loss: 1.3739, accuracy: 92.5155%, tar: 0.0463 \n",
      "l0: 0.031204, l1: 0.032201, l2: 0.040116, l3: 0.055396, l4: 0.101862, l5: 0.214258, l6: 0.451523\n",
      "\n",
      "[epoch: 343/400, batch: 616/1000, ite: 45703] train loss: 1.3739, accuracy: 93.6092%, tar: 0.0463 \n",
      "l0: 0.019996, l1: 0.021114, l2: 0.026635, l3: 0.036493, l4: 0.062457, l5: 0.118397, l6: 0.239567\n",
      "\n",
      "[epoch: 343/400, batch: 624/1000, ite: 45704] train loss: 1.3735, accuracy: 96.5090%, tar: 0.0463 \n",
      "l0: 0.034883, l1: 0.035971, l2: 0.044398, l3: 0.061099, l4: 0.107657, l5: 0.216329, l6: 0.465067\n",
      "\n",
      "[epoch: 343/400, batch: 632/1000, ite: 45705] train loss: 1.3736, accuracy: 93.9567%, tar: 0.0463 \n",
      "l0: 0.031512, l1: 0.033357, l2: 0.043213, l3: 0.065136, l4: 0.120670, l5: 0.244453, l6: 0.455220\n",
      "\n",
      "[epoch: 343/400, batch: 640/1000, ite: 45706] train loss: 1.3736, accuracy: 93.9024%, tar: 0.0463 \n",
      "l0: 0.026535, l1: 0.027783, l2: 0.034771, l3: 0.048607, l4: 0.081542, l5: 0.157666, l6: 0.262079\n",
      "\n",
      "[epoch: 343/400, batch: 648/1000, ite: 45707] train loss: 1.3733, accuracy: 95.7974%, tar: 0.0462 \n",
      "l0: 0.028562, l1: 0.029949, l2: 0.038540, l3: 0.059696, l4: 0.112854, l5: 0.210384, l6: 0.447606\n",
      "\n",
      "[epoch: 343/400, batch: 656/1000, ite: 45708] train loss: 1.3734, accuracy: 93.7146%, tar: 0.0462 \n",
      "l0: 0.024268, l1: 0.025175, l2: 0.032141, l3: 0.046658, l4: 0.093490, l5: 0.208194, l6: 0.367856\n",
      "\n",
      "[epoch: 343/400, batch: 664/1000, ite: 45709] train loss: 1.3732, accuracy: 95.4106%, tar: 0.0462 \n",
      "l0: 0.034152, l1: 0.035025, l2: 0.043220, l3: 0.060195, l4: 0.091727, l5: 0.155708, l6: 0.369812\n",
      "\n",
      "[epoch: 343/400, batch: 672/1000, ite: 45710] train loss: 1.3731, accuracy: 94.7930%, tar: 0.0462 \n",
      "l0: 0.024635, l1: 0.025980, l2: 0.033506, l3: 0.049888, l4: 0.096051, l5: 0.209887, l6: 0.369061\n",
      "\n",
      "[epoch: 343/400, batch: 680/1000, ite: 45711] train loss: 1.3730, accuracy: 95.6767%, tar: 0.0462 \n",
      "l0: 0.027718, l1: 0.029714, l2: 0.038268, l3: 0.051849, l4: 0.087583, l5: 0.152370, l6: 0.350080\n",
      "\n",
      "[epoch: 343/400, batch: 688/1000, ite: 45712] train loss: 1.3728, accuracy: 95.1724%, tar: 0.0462 \n",
      "l0: 0.025049, l1: 0.027145, l2: 0.035173, l3: 0.055737, l4: 0.104623, l5: 0.204186, l6: 0.508315\n",
      "\n",
      "[epoch: 343/400, batch: 696/1000, ite: 45713] train loss: 1.3729, accuracy: 94.7273%, tar: 0.0462 \n",
      "l0: 0.031689, l1: 0.032733, l2: 0.039975, l3: 0.053212, l4: 0.095852, l5: 0.203978, l6: 0.399950\n",
      "\n",
      "[epoch: 343/400, batch: 704/1000, ite: 45714] train loss: 1.3728, accuracy: 94.0673%, tar: 0.0462 \n",
      "l0: 0.039603, l1: 0.040651, l2: 0.049297, l3: 0.071316, l4: 0.130910, l5: 0.225145, l6: 0.459496\n",
      "\n",
      "[epoch: 343/400, batch: 712/1000, ite: 45715] train loss: 1.3729, accuracy: 92.5253%, tar: 0.0462 \n",
      "l0: 0.035354, l1: 0.036787, l2: 0.044326, l3: 0.059529, l4: 0.111400, l5: 0.184766, l6: 0.342456\n",
      "\n",
      "[epoch: 343/400, batch: 720/1000, ite: 45716] train loss: 1.3728, accuracy: 94.5979%, tar: 0.0462 \n",
      "l0: 0.021403, l1: 0.023568, l2: 0.031889, l3: 0.049764, l4: 0.084444, l5: 0.169170, l6: 0.392175\n",
      "\n",
      "[epoch: 343/400, batch: 728/1000, ite: 45717] train loss: 1.3727, accuracy: 95.6381%, tar: 0.0461 \n",
      "l0: 0.035941, l1: 0.037507, l2: 0.045614, l3: 0.065711, l4: 0.128106, l5: 0.246980, l6: 0.449869\n",
      "\n",
      "[epoch: 343/400, batch: 736/1000, ite: 45718] train loss: 1.3727, accuracy: 93.3791%, tar: 0.0461 \n",
      "l0: 0.032288, l1: 0.033614, l2: 0.040925, l3: 0.056720, l4: 0.092454, l5: 0.166985, l6: 0.319338\n",
      "\n",
      "[epoch: 343/400, batch: 744/1000, ite: 45719] train loss: 1.3726, accuracy: 94.7203%, tar: 0.0461 \n",
      "l0: 0.030872, l1: 0.032102, l2: 0.041079, l3: 0.057272, l4: 0.097547, l5: 0.186304, l6: 0.409256\n",
      "\n",
      "[epoch: 343/400, batch: 752/1000, ite: 45720] train loss: 1.3725, accuracy: 94.1095%, tar: 0.0461 \n",
      "l0: 0.024621, l1: 0.026334, l2: 0.036520, l3: 0.059734, l4: 0.118583, l5: 0.198531, l6: 0.366568\n",
      "\n",
      "[epoch: 343/400, batch: 760/1000, ite: 45721] train loss: 1.3724, accuracy: 95.7938%, tar: 0.0461 \n",
      "l0: 0.020502, l1: 0.021408, l2: 0.027000, l3: 0.038726, l4: 0.061545, l5: 0.119450, l6: 0.338671\n",
      "\n",
      "[epoch: 343/400, batch: 768/1000, ite: 45722] train loss: 1.3722, accuracy: 95.9472%, tar: 0.0461 \n",
      "l0: 0.025477, l1: 0.026716, l2: 0.034322, l3: 0.053920, l4: 0.098421, l5: 0.171474, l6: 0.334663\n",
      "\n",
      "[epoch: 343/400, batch: 776/1000, ite: 45723] train loss: 1.3720, accuracy: 95.0169%, tar: 0.0461 \n",
      "l0: 0.029064, l1: 0.029607, l2: 0.036166, l3: 0.048791, l4: 0.088177, l5: 0.161316, l6: 0.315857\n",
      "\n",
      "[epoch: 343/400, batch: 784/1000, ite: 45724] train loss: 1.3718, accuracy: 95.2712%, tar: 0.0461 \n",
      "l0: 0.027170, l1: 0.028401, l2: 0.035368, l3: 0.050974, l4: 0.096581, l5: 0.187569, l6: 0.415591\n",
      "\n",
      "[epoch: 343/400, batch: 792/1000, ite: 45725] train loss: 1.3717, accuracy: 95.0158%, tar: 0.0461 \n",
      "l0: 0.035989, l1: 0.037547, l2: 0.047474, l3: 0.066278, l4: 0.120026, l5: 0.235376, l6: 0.405008\n",
      "\n",
      "[epoch: 343/400, batch: 800/1000, ite: 45726] train loss: 1.3717, accuracy: 93.7714%, tar: 0.0461 \n",
      "l0: 0.024445, l1: 0.025612, l2: 0.033047, l3: 0.048959, l4: 0.094414, l5: 0.175340, l6: 0.377170\n",
      "\n",
      "[epoch: 343/400, batch: 808/1000, ite: 45727] train loss: 1.3716, accuracy: 95.2924%, tar: 0.0460 \n",
      "l0: 0.039689, l1: 0.040758, l2: 0.049555, l3: 0.067488, l4: 0.115339, l5: 0.221646, l6: 0.418238\n",
      "\n",
      "[epoch: 343/400, batch: 816/1000, ite: 45728] train loss: 1.3716, accuracy: 93.0283%, tar: 0.0460 \n",
      "l0: 0.028609, l1: 0.029348, l2: 0.036274, l3: 0.048033, l4: 0.080483, l5: 0.146439, l6: 0.284489\n",
      "\n",
      "[epoch: 343/400, batch: 824/1000, ite: 45729] train loss: 1.3714, accuracy: 95.6790%, tar: 0.0460 \n",
      "l0: 0.028373, l1: 0.030113, l2: 0.041093, l3: 0.061864, l4: 0.104667, l5: 0.196391, l6: 0.378626\n",
      "\n",
      "[epoch: 343/400, batch: 832/1000, ite: 45730] train loss: 1.3713, accuracy: 94.6706%, tar: 0.0460 \n",
      "l0: 0.033371, l1: 0.034907, l2: 0.043254, l3: 0.061767, l4: 0.108746, l5: 0.197932, l6: 0.442216\n",
      "\n",
      "[epoch: 343/400, batch: 840/1000, ite: 45731] train loss: 1.3713, accuracy: 93.7296%, tar: 0.0460 \n",
      "l0: 0.029477, l1: 0.030480, l2: 0.037048, l3: 0.054604, l4: 0.095433, l5: 0.196918, l6: 0.424227\n",
      "\n",
      "[epoch: 343/400, batch: 848/1000, ite: 45732] train loss: 1.3713, accuracy: 93.7906%, tar: 0.0460 \n",
      "l0: 0.032173, l1: 0.033075, l2: 0.040599, l3: 0.055782, l4: 0.094406, l5: 0.173755, l6: 0.379729\n",
      "\n",
      "[epoch: 343/400, batch: 856/1000, ite: 45733] train loss: 1.3712, accuracy: 93.9869%, tar: 0.0460 \n",
      "l0: 0.034551, l1: 0.036247, l2: 0.045381, l3: 0.063896, l4: 0.106494, l5: 0.214677, l6: 0.391274\n",
      "\n",
      "[epoch: 343/400, batch: 864/1000, ite: 45734] train loss: 1.3711, accuracy: 94.4944%, tar: 0.0460 \n",
      "l0: 0.029955, l1: 0.030418, l2: 0.037764, l3: 0.052606, l4: 0.093102, l5: 0.176069, l6: 0.377685\n",
      "\n",
      "[epoch: 343/400, batch: 872/1000, ite: 45735] train loss: 1.3710, accuracy: 94.6745%, tar: 0.0460 \n",
      "l0: 0.033232, l1: 0.034492, l2: 0.039962, l3: 0.053976, l4: 0.081469, l5: 0.143110, l6: 0.282694\n",
      "\n",
      "[epoch: 343/400, batch: 880/1000, ite: 45736] train loss: 1.3708, accuracy: 95.0024%, tar: 0.0460 \n",
      "l0: 0.035616, l1: 0.037607, l2: 0.045906, l3: 0.067575, l4: 0.119564, l5: 0.236854, l6: 0.390504\n",
      "\n",
      "[epoch: 343/400, batch: 888/1000, ite: 45737] train loss: 1.3707, accuracy: 93.9462%, tar: 0.0460 \n",
      "l0: 0.033264, l1: 0.034650, l2: 0.045000, l3: 0.068386, l4: 0.125507, l5: 0.253561, l6: 0.494212\n",
      "\n",
      "[epoch: 343/400, batch: 896/1000, ite: 45738] train loss: 1.3709, accuracy: 93.2662%, tar: 0.0460 \n",
      "l0: 0.028325, l1: 0.029932, l2: 0.037466, l3: 0.055578, l4: 0.104304, l5: 0.201115, l6: 0.409473\n",
      "\n",
      "[epoch: 343/400, batch: 904/1000, ite: 45739] train loss: 1.3708, accuracy: 94.1351%, tar: 0.0459 \n",
      "l0: 0.030791, l1: 0.032681, l2: 0.042693, l3: 0.061025, l4: 0.111341, l5: 0.230895, l6: 0.386417\n",
      "\n",
      "[epoch: 343/400, batch: 912/1000, ite: 45740] train loss: 1.3708, accuracy: 95.0293%, tar: 0.0459 \n",
      "l0: 0.026977, l1: 0.027877, l2: 0.035577, l3: 0.050291, l4: 0.085393, l5: 0.161259, l6: 0.320064\n",
      "\n",
      "[epoch: 343/400, batch: 920/1000, ite: 45741] train loss: 1.3706, accuracy: 94.9639%, tar: 0.0459 \n",
      "l0: 0.022914, l1: 0.023815, l2: 0.029861, l3: 0.041482, l4: 0.067963, l5: 0.131397, l6: 0.300058\n",
      "\n",
      "[epoch: 343/400, batch: 928/1000, ite: 45742] train loss: 1.3703, accuracy: 95.2119%, tar: 0.0459 \n",
      "l0: 0.031782, l1: 0.032521, l2: 0.041942, l3: 0.063764, l4: 0.119647, l5: 0.233503, l6: 0.425681\n",
      "\n",
      "[epoch: 343/400, batch: 936/1000, ite: 45743] train loss: 1.3703, accuracy: 94.1013%, tar: 0.0459 \n",
      "l0: 0.037968, l1: 0.039310, l2: 0.051196, l3: 0.074098, l4: 0.125833, l5: 0.225791, l6: 0.419406\n",
      "\n",
      "[epoch: 343/400, batch: 944/1000, ite: 45744] train loss: 1.3703, accuracy: 94.1395%, tar: 0.0459 \n",
      "l0: 0.034357, l1: 0.035771, l2: 0.046208, l3: 0.067981, l4: 0.125680, l5: 0.249151, l6: 0.495938\n",
      "\n",
      "[epoch: 343/400, batch: 952/1000, ite: 45745] train loss: 1.3704, accuracy: 93.4907%, tar: 0.0459 \n",
      "l0: 0.040572, l1: 0.041172, l2: 0.051025, l3: 0.074588, l4: 0.146377, l5: 0.265981, l6: 0.515224\n",
      "\n",
      "[epoch: 343/400, batch: 960/1000, ite: 45746] train loss: 1.3706, accuracy: 93.4205%, tar: 0.0459 \n",
      "l0: 0.028146, l1: 0.028728, l2: 0.036091, l3: 0.051460, l4: 0.093795, l5: 0.211174, l6: 0.461078\n",
      "\n",
      "[epoch: 343/400, batch: 968/1000, ite: 45747] train loss: 1.3706, accuracy: 93.1816%, tar: 0.0459 \n",
      "l0: 0.036619, l1: 0.038622, l2: 0.049449, l3: 0.078190, l4: 0.162123, l5: 0.363132, l6: 0.585274\n",
      "\n",
      "[epoch: 343/400, batch: 976/1000, ite: 45748] train loss: 1.3709, accuracy: 92.9833%, tar: 0.0459 \n",
      "l0: 0.034675, l1: 0.035845, l2: 0.044976, l3: 0.064190, l4: 0.118709, l5: 0.238700, l6: 0.459514\n",
      "\n",
      "[epoch: 343/400, batch: 984/1000, ite: 45749] train loss: 1.3710, accuracy: 93.9552%, tar: 0.0459 \n",
      "l0: 0.030171, l1: 0.031209, l2: 0.040319, l3: 0.055222, l4: 0.098051, l5: 0.209622, l6: 0.445839\n",
      "\n",
      "[epoch: 343/400, batch: 992/1000, ite: 45750] train loss: 1.3710, accuracy: 94.6686%, tar: 0.0459 \n",
      "l0: 0.037312, l1: 0.038444, l2: 0.049466, l3: 0.074386, l4: 0.130098, l5: 0.263575, l6: 0.554030\n",
      "\n",
      "[epoch: 343/400, batch: 1000/1000, ite: 45751] train loss: 1.3712, accuracy: 92.7630%, tar: 0.0459 \n",
      "l0: 0.023585, l1: 0.024335, l2: 0.030376, l3: 0.043008, l4: 0.081147, l5: 0.163020, l6: 0.316869\n",
      "\n",
      "[epoch: 344/400, batch: 8/1000, ite: 45752] train loss: 1.3710, accuracy: 94.6681%, tar: 0.0458 \n",
      "l0: 0.023725, l1: 0.025255, l2: 0.031543, l3: 0.044391, l4: 0.092690, l5: 0.197239, l6: 0.295284\n",
      "\n",
      "[epoch: 344/400, batch: 16/1000, ite: 45753] train loss: 1.3707, accuracy: 96.0003%, tar: 0.0458 \n",
      "l0: 0.037486, l1: 0.038947, l2: 0.050764, l3: 0.073993, l4: 0.131834, l5: 0.321290, l6: 0.705737\n",
      "\n",
      "[epoch: 344/400, batch: 24/1000, ite: 45754] train loss: 1.3711, accuracy: 91.3481%, tar: 0.0458 \n",
      "l0: 0.025173, l1: 0.026082, l2: 0.033426, l3: 0.045851, l4: 0.078189, l5: 0.146824, l6: 0.280263\n",
      "\n",
      "[epoch: 344/400, batch: 32/1000, ite: 45755] train loss: 1.3709, accuracy: 95.5313%, tar: 0.0458 \n",
      "l0: 0.029585, l1: 0.031663, l2: 0.040812, l3: 0.058722, l4: 0.102281, l5: 0.191624, l6: 0.380833\n",
      "\n",
      "[epoch: 344/400, batch: 40/1000, ite: 45756] train loss: 1.3708, accuracy: 95.2265%, tar: 0.0458 \n",
      "l0: 0.030821, l1: 0.031543, l2: 0.040988, l3: 0.059274, l4: 0.107359, l5: 0.200329, l6: 0.371910\n",
      "\n",
      "[epoch: 344/400, batch: 48/1000, ite: 45757] train loss: 1.3707, accuracy: 94.0600%, tar: 0.0458 \n",
      "l0: 0.032008, l1: 0.033251, l2: 0.042070, l3: 0.059568, l4: 0.096757, l5: 0.168293, l6: 0.378282\n",
      "\n",
      "[epoch: 344/400, batch: 56/1000, ite: 45758] train loss: 1.3706, accuracy: 94.0374%, tar: 0.0458 \n",
      "l0: 0.032623, l1: 0.034099, l2: 0.045242, l3: 0.069152, l4: 0.132257, l5: 0.233242, l6: 0.487795\n",
      "\n",
      "[epoch: 344/400, batch: 64/1000, ite: 45759] train loss: 1.3707, accuracy: 93.8357%, tar: 0.0458 \n",
      "l0: 0.031368, l1: 0.032414, l2: 0.040879, l3: 0.060725, l4: 0.106508, l5: 0.197052, l6: 0.377553\n",
      "\n",
      "[epoch: 344/400, batch: 72/1000, ite: 45760] train loss: 1.3706, accuracy: 93.9115%, tar: 0.0458 \n",
      "l0: 0.023244, l1: 0.024801, l2: 0.031872, l3: 0.047516, l4: 0.084260, l5: 0.177898, l6: 0.303540\n",
      "\n",
      "[epoch: 344/400, batch: 80/1000, ite: 45761] train loss: 1.3704, accuracy: 95.7751%, tar: 0.0458 \n",
      "l0: 0.028888, l1: 0.030567, l2: 0.038193, l3: 0.061520, l4: 0.121762, l5: 0.227631, l6: 0.461324\n",
      "\n",
      "[epoch: 344/400, batch: 88/1000, ite: 45762] train loss: 1.3705, accuracy: 93.7032%, tar: 0.0457 \n",
      "l0: 0.027557, l1: 0.028896, l2: 0.037703, l3: 0.055868, l4: 0.099163, l5: 0.198957, l6: 0.402202\n",
      "\n",
      "[epoch: 344/400, batch: 96/1000, ite: 45763] train loss: 1.3704, accuracy: 94.3035%, tar: 0.0457 \n",
      "l0: 0.026901, l1: 0.028122, l2: 0.036702, l3: 0.049911, l4: 0.084666, l5: 0.140166, l6: 0.305357\n",
      "\n",
      "[epoch: 344/400, batch: 104/1000, ite: 45764] train loss: 1.3702, accuracy: 95.5034%, tar: 0.0457 \n",
      "l0: 0.035497, l1: 0.037121, l2: 0.046156, l3: 0.063301, l4: 0.102587, l5: 0.202223, l6: 0.399856\n",
      "\n",
      "[epoch: 344/400, batch: 112/1000, ite: 45765] train loss: 1.3701, accuracy: 93.9147%, tar: 0.0457 \n",
      "l0: 0.024350, l1: 0.025610, l2: 0.031822, l3: 0.050225, l4: 0.092919, l5: 0.173597, l6: 0.340161\n",
      "\n",
      "[epoch: 344/400, batch: 120/1000, ite: 45766] train loss: 1.3700, accuracy: 94.6759%, tar: 0.0457 \n",
      "l0: 0.027442, l1: 0.028344, l2: 0.033634, l3: 0.046794, l4: 0.082302, l5: 0.142068, l6: 0.227840\n",
      "\n",
      "[epoch: 344/400, batch: 128/1000, ite: 45767] train loss: 1.3697, accuracy: 95.7793%, tar: 0.0457 \n",
      "l0: 0.023366, l1: 0.024297, l2: 0.030120, l3: 0.042049, l4: 0.073617, l5: 0.136764, l6: 0.284414\n",
      "\n",
      "[epoch: 344/400, batch: 136/1000, ite: 45768] train loss: 1.3694, accuracy: 95.2455%, tar: 0.0457 \n",
      "l0: 0.028423, l1: 0.029633, l2: 0.039245, l3: 0.057985, l4: 0.100463, l5: 0.188081, l6: 0.395856\n",
      "\n",
      "[epoch: 344/400, batch: 144/1000, ite: 45769] train loss: 1.3693, accuracy: 94.0418%, tar: 0.0457 \n",
      "l0: 0.032548, l1: 0.034446, l2: 0.045575, l3: 0.065097, l4: 0.132601, l5: 0.252479, l6: 0.505971\n",
      "\n",
      "[epoch: 344/400, batch: 152/1000, ite: 45770] train loss: 1.3694, accuracy: 93.3629%, tar: 0.0457 \n",
      "l0: 0.030745, l1: 0.033159, l2: 0.044786, l3: 0.065663, l4: 0.107026, l5: 0.190453, l6: 0.331397\n",
      "\n",
      "[epoch: 344/400, batch: 160/1000, ite: 45771] train loss: 1.3693, accuracy: 95.5502%, tar: 0.0457 \n",
      "l0: 0.032449, l1: 0.033712, l2: 0.042575, l3: 0.062455, l4: 0.119869, l5: 0.228727, l6: 0.527984\n",
      "\n",
      "[epoch: 344/400, batch: 168/1000, ite: 45772] train loss: 1.3694, accuracy: 92.3772%, tar: 0.0457 \n",
      "l0: 0.026600, l1: 0.028375, l2: 0.040090, l3: 0.069345, l4: 0.130290, l5: 0.202343, l6: 0.354943\n",
      "\n",
      "[epoch: 344/400, batch: 176/1000, ite: 45773] train loss: 1.3693, accuracy: 94.9014%, tar: 0.0456 \n",
      "l0: 0.024827, l1: 0.026265, l2: 0.034985, l3: 0.047831, l4: 0.087200, l5: 0.180975, l6: 0.346230\n",
      "\n",
      "[epoch: 344/400, batch: 184/1000, ite: 45774] train loss: 1.3692, accuracy: 95.3517%, tar: 0.0456 \n",
      "l0: 0.028439, l1: 0.029408, l2: 0.036855, l3: 0.054045, l4: 0.094139, l5: 0.175140, l6: 0.317627\n",
      "\n",
      "[epoch: 344/400, batch: 192/1000, ite: 45775] train loss: 1.3690, accuracy: 94.6488%, tar: 0.0456 \n",
      "l0: 0.024595, l1: 0.025552, l2: 0.032832, l3: 0.047128, l4: 0.085973, l5: 0.163487, l6: 0.317965\n",
      "\n",
      "[epoch: 344/400, batch: 200/1000, ite: 45776] train loss: 1.3688, accuracy: 94.6233%, tar: 0.0456 \n",
      "l0: 0.028181, l1: 0.029093, l2: 0.035129, l3: 0.047226, l4: 0.083282, l5: 0.169271, l6: 0.318285\n",
      "\n",
      "[epoch: 344/400, batch: 208/1000, ite: 45777] train loss: 1.3686, accuracy: 95.2359%, tar: 0.0456 \n",
      "l0: 0.035639, l1: 0.038158, l2: 0.047033, l3: 0.066328, l4: 0.121511, l5: 0.223235, l6: 0.430085\n",
      "\n",
      "[epoch: 344/400, batch: 216/1000, ite: 45778] train loss: 1.3687, accuracy: 94.2727%, tar: 0.0456 \n",
      "l0: 0.030612, l1: 0.031752, l2: 0.038692, l3: 0.056159, l4: 0.097159, l5: 0.230283, l6: 0.484257\n",
      "\n",
      "[epoch: 344/400, batch: 224/1000, ite: 45779] train loss: 1.3687, accuracy: 93.1829%, tar: 0.0456 \n",
      "l0: 0.020695, l1: 0.021155, l2: 0.026298, l3: 0.035767, l4: 0.056181, l5: 0.105122, l6: 0.245286\n",
      "\n",
      "[epoch: 344/400, batch: 232/1000, ite: 45780] train loss: 1.3684, accuracy: 96.3344%, tar: 0.0456 \n",
      "l0: 0.028827, l1: 0.030559, l2: 0.041543, l3: 0.059899, l4: 0.103853, l5: 0.186573, l6: 0.338699\n",
      "\n",
      "[epoch: 344/400, batch: 240/1000, ite: 45781] train loss: 1.3682, accuracy: 95.1870%, tar: 0.0456 \n",
      "l0: 0.035338, l1: 0.038605, l2: 0.050554, l3: 0.075252, l4: 0.141443, l5: 0.284456, l6: 0.517241\n",
      "\n",
      "[epoch: 344/400, batch: 248/1000, ite: 45782] train loss: 1.3684, accuracy: 93.1561%, tar: 0.0456 \n",
      "l0: 0.029970, l1: 0.031036, l2: 0.039456, l3: 0.055302, l4: 0.105075, l5: 0.193915, l6: 0.446294\n",
      "\n",
      "[epoch: 344/400, batch: 256/1000, ite: 45783] train loss: 1.3684, accuracy: 93.8861%, tar: 0.0455 \n",
      "l0: 0.027698, l1: 0.029341, l2: 0.038100, l3: 0.055576, l4: 0.101812, l5: 0.182223, l6: 0.348631\n",
      "\n",
      "[epoch: 344/400, batch: 264/1000, ite: 45784] train loss: 1.3683, accuracy: 95.4337%, tar: 0.0455 \n",
      "l0: 0.019611, l1: 0.020631, l2: 0.026370, l3: 0.040624, l4: 0.072351, l5: 0.126737, l6: 0.262540\n",
      "\n",
      "[epoch: 344/400, batch: 272/1000, ite: 45785] train loss: 1.3680, accuracy: 95.8445%, tar: 0.0455 \n",
      "l0: 0.026301, l1: 0.026988, l2: 0.033979, l3: 0.047743, l4: 0.072662, l5: 0.137897, l6: 0.334656\n",
      "\n",
      "[epoch: 344/400, batch: 280/1000, ite: 45786] train loss: 1.3678, accuracy: 94.9746%, tar: 0.0455 \n",
      "l0: 0.028243, l1: 0.029223, l2: 0.036273, l3: 0.051111, l4: 0.093322, l5: 0.186426, l6: 0.386251\n",
      "\n",
      "[epoch: 344/400, batch: 288/1000, ite: 45787] train loss: 1.3677, accuracy: 94.7874%, tar: 0.0455 \n",
      "l0: 0.025098, l1: 0.026075, l2: 0.032468, l3: 0.043290, l4: 0.075803, l5: 0.146149, l6: 0.374836\n",
      "\n",
      "[epoch: 344/400, batch: 296/1000, ite: 45788] train loss: 1.3675, accuracy: 94.7993%, tar: 0.0455 \n",
      "l0: 0.044168, l1: 0.044752, l2: 0.054592, l3: 0.077518, l4: 0.131277, l5: 0.257232, l6: 0.461877\n",
      "\n",
      "[epoch: 344/400, batch: 304/1000, ite: 45789] train loss: 1.3676, accuracy: 92.3176%, tar: 0.0455 \n",
      "l0: 0.025123, l1: 0.026431, l2: 0.033470, l3: 0.050975, l4: 0.084467, l5: 0.174872, l6: 0.368424\n",
      "\n",
      "[epoch: 344/400, batch: 312/1000, ite: 45790] train loss: 1.3675, accuracy: 95.0228%, tar: 0.0455 \n",
      "l0: 0.036230, l1: 0.037523, l2: 0.050579, l3: 0.070938, l4: 0.134850, l5: 0.287719, l6: 0.462312\n",
      "\n",
      "[epoch: 344/400, batch: 320/1000, ite: 45791] train loss: 1.3676, accuracy: 94.6740%, tar: 0.0455 \n",
      "l0: 0.029271, l1: 0.030372, l2: 0.038522, l3: 0.056862, l4: 0.109449, l5: 0.199822, l6: 0.382994\n",
      "\n",
      "[epoch: 344/400, batch: 328/1000, ite: 45792] train loss: 1.3675, accuracy: 94.1261%, tar: 0.0455 \n",
      "l0: 0.030074, l1: 0.030514, l2: 0.037694, l3: 0.052586, l4: 0.087757, l5: 0.172928, l6: 0.387445\n",
      "\n",
      "[epoch: 344/400, batch: 336/1000, ite: 45793] train loss: 1.3674, accuracy: 93.9268%, tar: 0.0455 \n",
      "l0: 0.020142, l1: 0.022630, l2: 0.027767, l3: 0.041452, l4: 0.083617, l5: 0.180729, l6: 0.344792\n",
      "\n",
      "[epoch: 344/400, batch: 344/1000, ite: 45794] train loss: 1.3673, accuracy: 94.9632%, tar: 0.0454 \n",
      "l0: 0.032698, l1: 0.034655, l2: 0.046395, l3: 0.077234, l4: 0.145625, l5: 0.341535, l6: 0.552954\n",
      "\n",
      "[epoch: 344/400, batch: 352/1000, ite: 45795] train loss: 1.3675, accuracy: 92.5954%, tar: 0.0454 \n",
      "l0: 0.030752, l1: 0.031640, l2: 0.040574, l3: 0.058415, l4: 0.101326, l5: 0.193851, l6: 0.438116\n",
      "\n",
      "[epoch: 344/400, batch: 360/1000, ite: 45796] train loss: 1.3675, accuracy: 93.7083%, tar: 0.0454 \n",
      "l0: 0.025684, l1: 0.027435, l2: 0.035857, l3: 0.055874, l4: 0.096948, l5: 0.181979, l6: 0.455221\n",
      "\n",
      "[epoch: 344/400, batch: 368/1000, ite: 45797] train loss: 1.3675, accuracy: 94.5843%, tar: 0.0454 \n",
      "l0: 0.021415, l1: 0.022676, l2: 0.030079, l3: 0.043349, l4: 0.078248, l5: 0.132282, l6: 0.262818\n",
      "\n",
      "[epoch: 344/400, batch: 376/1000, ite: 45798] train loss: 1.3672, accuracy: 96.2768%, tar: 0.0454 \n",
      "l0: 0.021720, l1: 0.023637, l2: 0.032945, l3: 0.052971, l4: 0.092019, l5: 0.164001, l6: 0.285072\n",
      "\n",
      "[epoch: 344/400, batch: 384/1000, ite: 45799] train loss: 1.3670, accuracy: 96.3032%, tar: 0.0454 \n",
      "l0: 0.030425, l1: 0.031809, l2: 0.040873, l3: 0.056627, l4: 0.093181, l5: 0.181547, l6: 0.375362\n",
      "\n",
      "[epoch: 344/400, batch: 392/1000, ite: 45800] train loss: 1.3669, accuracy: 94.7683%, tar: 0.0454 \n",
      "l0: 0.027774, l1: 0.029824, l2: 0.037433, l3: 0.053991, l4: 0.098236, l5: 0.190297, l6: 0.359631\n",
      "\n",
      "[epoch: 344/400, batch: 400/1000, ite: 45801] train loss: 1.3668, accuracy: 95.1664%, tar: 0.0454 \n",
      "l0: 0.035787, l1: 0.037654, l2: 0.048990, l3: 0.069984, l4: 0.124903, l5: 0.288877, l6: 0.602444\n",
      "\n",
      "[epoch: 344/400, batch: 408/1000, ite: 45802] train loss: 1.3670, accuracy: 93.2342%, tar: 0.0454 \n",
      "l0: 0.028323, l1: 0.029002, l2: 0.037171, l3: 0.052350, l4: 0.094907, l5: 0.175886, l6: 0.405933\n",
      "\n",
      "[epoch: 344/400, batch: 416/1000, ite: 45803] train loss: 1.3669, accuracy: 93.8668%, tar: 0.0454 \n",
      "l0: 0.021281, l1: 0.021714, l2: 0.027864, l3: 0.041935, l4: 0.073046, l5: 0.147962, l6: 0.275139\n",
      "\n",
      "[epoch: 344/400, batch: 424/1000, ite: 45804] train loss: 1.3667, accuracy: 95.3491%, tar: 0.0453 \n",
      "l0: 0.032445, l1: 0.034013, l2: 0.041675, l3: 0.068245, l4: 0.126008, l5: 0.245624, l6: 0.382186\n",
      "\n",
      "[epoch: 344/400, batch: 432/1000, ite: 45805] train loss: 1.3666, accuracy: 94.2209%, tar: 0.0453 \n",
      "l0: 0.021854, l1: 0.022989, l2: 0.030122, l3: 0.043540, l4: 0.074988, l5: 0.144696, l6: 0.280828\n",
      "\n",
      "[epoch: 344/400, batch: 440/1000, ite: 45806] train loss: 1.3664, accuracy: 95.6324%, tar: 0.0453 \n",
      "l0: 0.023600, l1: 0.024853, l2: 0.031212, l3: 0.049169, l4: 0.089730, l5: 0.168233, l6: 0.311250\n",
      "\n",
      "[epoch: 344/400, batch: 448/1000, ite: 45807] train loss: 1.3662, accuracy: 95.0492%, tar: 0.0453 \n",
      "l0: 0.029597, l1: 0.031018, l2: 0.038522, l3: 0.052695, l4: 0.092899, l5: 0.181108, l6: 0.352074\n",
      "\n",
      "[epoch: 344/400, batch: 456/1000, ite: 45808] train loss: 1.3661, accuracy: 95.1054%, tar: 0.0453 \n",
      "l0: 0.025352, l1: 0.026425, l2: 0.033447, l3: 0.047045, l4: 0.085734, l5: 0.225932, l6: 0.414434\n",
      "\n",
      "[epoch: 344/400, batch: 464/1000, ite: 45809] train loss: 1.3660, accuracy: 94.5120%, tar: 0.0453 \n",
      "l0: 0.031026, l1: 0.033594, l2: 0.043875, l3: 0.065425, l4: 0.121037, l5: 0.264242, l6: 0.501798\n",
      "\n",
      "[epoch: 344/400, batch: 472/1000, ite: 45810] train loss: 1.3661, accuracy: 93.6554%, tar: 0.0453 \n",
      "l0: 0.027726, l1: 0.029418, l2: 0.041080, l3: 0.067176, l4: 0.131432, l5: 0.274385, l6: 0.444721\n",
      "\n",
      "[epoch: 344/400, batch: 480/1000, ite: 45811] train loss: 1.3662, accuracy: 94.7244%, tar: 0.0453 \n",
      "l0: 0.023308, l1: 0.025310, l2: 0.035117, l3: 0.051804, l4: 0.095251, l5: 0.198489, l6: 0.410113\n",
      "\n",
      "[epoch: 344/400, batch: 488/1000, ite: 45812] train loss: 1.3661, accuracy: 95.4207%, tar: 0.0453 \n",
      "l0: 0.024652, l1: 0.025795, l2: 0.033292, l3: 0.045446, l4: 0.078593, l5: 0.167645, l6: 0.305194\n",
      "\n",
      "[epoch: 344/400, batch: 496/1000, ite: 45813] train loss: 1.3659, accuracy: 95.3513%, tar: 0.0453 \n",
      "l0: 0.030698, l1: 0.032439, l2: 0.040539, l3: 0.057138, l4: 0.113181, l5: 0.223194, l6: 0.462932\n",
      "\n",
      "[epoch: 344/400, batch: 504/1000, ite: 45814] train loss: 1.3659, accuracy: 93.3024%, tar: 0.0452 \n",
      "l0: 0.023597, l1: 0.024327, l2: 0.030484, l3: 0.043481, l4: 0.089519, l5: 0.163803, l6: 0.378192\n",
      "\n",
      "[epoch: 344/400, batch: 512/1000, ite: 45815] train loss: 1.3658, accuracy: 95.1826%, tar: 0.0452 \n",
      "l0: 0.032285, l1: 0.033556, l2: 0.043157, l3: 0.064745, l4: 0.120361, l5: 0.214007, l6: 0.459384\n",
      "\n",
      "[epoch: 344/400, batch: 520/1000, ite: 45816] train loss: 1.3659, accuracy: 93.6896%, tar: 0.0452 \n",
      "l0: 0.031224, l1: 0.032384, l2: 0.040992, l3: 0.057680, l4: 0.097498, l5: 0.202142, l6: 0.388176\n",
      "\n",
      "[epoch: 344/400, batch: 528/1000, ite: 45817] train loss: 1.3658, accuracy: 93.8461%, tar: 0.0452 \n",
      "l0: 0.031185, l1: 0.032126, l2: 0.040631, l3: 0.060095, l4: 0.103183, l5: 0.185013, l6: 0.415259\n",
      "\n",
      "[epoch: 344/400, batch: 536/1000, ite: 45818] train loss: 1.3658, accuracy: 93.5120%, tar: 0.0452 \n",
      "l0: 0.025122, l1: 0.026958, l2: 0.035225, l3: 0.049355, l4: 0.083889, l5: 0.163806, l6: 0.438243\n",
      "\n",
      "[epoch: 344/400, batch: 544/1000, ite: 45819] train loss: 1.3657, accuracy: 94.8811%, tar: 0.0452 \n",
      "l0: 0.033065, l1: 0.034456, l2: 0.042056, l3: 0.057499, l4: 0.094112, l5: 0.175469, l6: 0.386572\n",
      "\n",
      "[epoch: 344/400, batch: 552/1000, ite: 45820] train loss: 1.3656, accuracy: 95.1986%, tar: 0.0452 \n",
      "l0: 0.023725, l1: 0.024749, l2: 0.031992, l3: 0.046027, l4: 0.080149, l5: 0.148316, l6: 0.364801\n",
      "\n",
      "[epoch: 344/400, batch: 560/1000, ite: 45821] train loss: 1.3655, accuracy: 94.8759%, tar: 0.0452 \n",
      "l0: 0.026556, l1: 0.027644, l2: 0.034312, l3: 0.049952, l4: 0.096406, l5: 0.215442, l6: 0.460608\n",
      "\n",
      "[epoch: 344/400, batch: 568/1000, ite: 45822] train loss: 1.3655, accuracy: 93.3159%, tar: 0.0452 \n",
      "l0: 0.034562, l1: 0.035539, l2: 0.044350, l3: 0.067036, l4: 0.114029, l5: 0.218218, l6: 0.392017\n",
      "\n",
      "[epoch: 344/400, batch: 576/1000, ite: 45823] train loss: 1.3654, accuracy: 93.5964%, tar: 0.0452 \n",
      "l0: 0.027272, l1: 0.028094, l2: 0.035018, l3: 0.051285, l4: 0.087737, l5: 0.153952, l6: 0.307292\n",
      "\n",
      "[epoch: 344/400, batch: 584/1000, ite: 45824] train loss: 1.3652, accuracy: 95.2851%, tar: 0.0452 \n",
      "l0: 0.029814, l1: 0.031265, l2: 0.040837, l3: 0.059937, l4: 0.113335, l5: 0.237239, l6: 0.415599\n",
      "\n",
      "[epoch: 344/400, batch: 592/1000, ite: 45825] train loss: 1.3652, accuracy: 93.7447%, tar: 0.0451 \n",
      "l0: 0.032406, l1: 0.033235, l2: 0.039951, l3: 0.059694, l4: 0.103016, l5: 0.176867, l6: 0.328625\n",
      "\n",
      "[epoch: 344/400, batch: 600/1000, ite: 45826] train loss: 1.3651, accuracy: 94.4258%, tar: 0.0451 \n",
      "l0: 0.027053, l1: 0.028363, l2: 0.035959, l3: 0.053421, l4: 0.099972, l5: 0.210863, l6: 0.374232\n",
      "\n",
      "[epoch: 344/400, batch: 608/1000, ite: 45827] train loss: 1.3650, accuracy: 95.2362%, tar: 0.0451 \n",
      "l0: 0.027213, l1: 0.028055, l2: 0.034940, l3: 0.044977, l4: 0.073499, l5: 0.129862, l6: 0.254134\n",
      "\n",
      "[epoch: 344/400, batch: 616/1000, ite: 45828] train loss: 1.3647, accuracy: 95.5944%, tar: 0.0451 \n",
      "l0: 0.028836, l1: 0.029728, l2: 0.038070, l3: 0.057353, l4: 0.110512, l5: 0.210834, l6: 0.461643\n",
      "\n",
      "[epoch: 344/400, batch: 624/1000, ite: 45829] train loss: 1.3648, accuracy: 93.8555%, tar: 0.0451 \n",
      "l0: 0.026482, l1: 0.028280, l2: 0.036992, l3: 0.052461, l4: 0.093964, l5: 0.228803, l6: 0.436956\n",
      "\n",
      "[epoch: 344/400, batch: 632/1000, ite: 45830] train loss: 1.3648, accuracy: 94.6126%, tar: 0.0451 \n",
      "l0: 0.024028, l1: 0.025075, l2: 0.030678, l3: 0.039732, l4: 0.063507, l5: 0.113483, l6: 0.263517\n",
      "\n",
      "[epoch: 344/400, batch: 640/1000, ite: 45831] train loss: 1.3645, accuracy: 95.4172%, tar: 0.0451 \n",
      "l0: 0.021826, l1: 0.023127, l2: 0.030074, l3: 0.045739, l4: 0.089136, l5: 0.154550, l6: 0.355459\n",
      "\n",
      "[epoch: 344/400, batch: 648/1000, ite: 45832] train loss: 1.3643, accuracy: 95.0966%, tar: 0.0451 \n",
      "l0: 0.029243, l1: 0.031191, l2: 0.038501, l3: 0.063526, l4: 0.130252, l5: 0.245263, l6: 0.410997\n",
      "\n",
      "[epoch: 344/400, batch: 656/1000, ite: 45833] train loss: 1.3643, accuracy: 94.6716%, tar: 0.0451 \n",
      "l0: 0.026626, l1: 0.027385, l2: 0.034122, l3: 0.047474, l4: 0.079644, l5: 0.159474, l6: 0.415356\n",
      "\n",
      "[epoch: 344/400, batch: 664/1000, ite: 45834] train loss: 1.3642, accuracy: 94.1086%, tar: 0.0451 \n",
      "l0: 0.027929, l1: 0.029064, l2: 0.036797, l3: 0.057226, l4: 0.114790, l5: 0.228595, l6: 0.446661\n",
      "\n",
      "[epoch: 344/400, batch: 672/1000, ite: 45835] train loss: 1.3642, accuracy: 93.7202%, tar: 0.0450 \n",
      "l0: 0.025383, l1: 0.026106, l2: 0.032728, l3: 0.054065, l4: 0.133832, l5: 0.220388, l6: 0.364062\n",
      "\n",
      "[epoch: 344/400, batch: 680/1000, ite: 45836] train loss: 1.3642, accuracy: 94.9331%, tar: 0.0450 \n",
      "l0: 0.027517, l1: 0.028219, l2: 0.034798, l3: 0.048028, l4: 0.085606, l5: 0.169805, l6: 0.324752\n",
      "\n",
      "[epoch: 344/400, batch: 688/1000, ite: 45837] train loss: 1.3640, accuracy: 95.0177%, tar: 0.0450 \n",
      "l0: 0.032544, l1: 0.033951, l2: 0.044539, l3: 0.068293, l4: 0.122582, l5: 0.243902, l6: 0.401904\n",
      "\n",
      "[epoch: 344/400, batch: 696/1000, ite: 45838] train loss: 1.3640, accuracy: 93.8978%, tar: 0.0450 \n",
      "l0: 0.024987, l1: 0.026175, l2: 0.033730, l3: 0.048341, l4: 0.080521, l5: 0.134599, l6: 0.265462\n",
      "\n",
      "[epoch: 344/400, batch: 704/1000, ite: 45839] train loss: 1.3637, accuracy: 96.3382%, tar: 0.0450 \n",
      "l0: 0.026827, l1: 0.027988, l2: 0.037199, l3: 0.055494, l4: 0.101202, l5: 0.185364, l6: 0.364452\n",
      "\n",
      "[epoch: 344/400, batch: 712/1000, ite: 45840] train loss: 1.3636, accuracy: 94.3798%, tar: 0.0450 \n",
      "l0: 0.035058, l1: 0.035956, l2: 0.044327, l3: 0.064467, l4: 0.103619, l5: 0.186112, l6: 0.388641\n",
      "\n",
      "[epoch: 344/400, batch: 720/1000, ite: 45841] train loss: 1.3636, accuracy: 93.8802%, tar: 0.0450 \n",
      "l0: 0.025049, l1: 0.026160, l2: 0.032077, l3: 0.046987, l4: 0.077336, l5: 0.174380, l6: 0.397646\n",
      "\n",
      "[epoch: 344/400, batch: 728/1000, ite: 45842] train loss: 1.3635, accuracy: 95.2457%, tar: 0.0450 \n",
      "l0: 0.028868, l1: 0.029843, l2: 0.038000, l3: 0.056573, l4: 0.097555, l5: 0.181012, l6: 0.385093\n",
      "\n",
      "[epoch: 344/400, batch: 736/1000, ite: 45843] train loss: 1.3634, accuracy: 94.5971%, tar: 0.0450 \n",
      "l0: 0.023617, l1: 0.024568, l2: 0.032419, l3: 0.049638, l4: 0.086906, l5: 0.177677, l6: 0.390415\n",
      "\n",
      "[epoch: 344/400, batch: 744/1000, ite: 45844] train loss: 1.3633, accuracy: 94.5141%, tar: 0.0450 \n",
      "l0: 0.024809, l1: 0.025699, l2: 0.033967, l3: 0.050252, l4: 0.089568, l5: 0.177541, l6: 0.333174\n",
      "\n",
      "[epoch: 344/400, batch: 752/1000, ite: 45845] train loss: 1.3631, accuracy: 95.5593%, tar: 0.0450 \n",
      "l0: 0.024080, l1: 0.024811, l2: 0.029601, l3: 0.041002, l4: 0.070303, l5: 0.135781, l6: 0.324672\n",
      "\n",
      "[epoch: 344/400, batch: 760/1000, ite: 45846] train loss: 1.3629, accuracy: 95.6107%, tar: 0.0449 \n",
      "l0: 0.032275, l1: 0.033769, l2: 0.044261, l3: 0.068325, l4: 0.121125, l5: 0.266965, l6: 0.501829\n",
      "\n",
      "[epoch: 344/400, batch: 768/1000, ite: 45847] train loss: 1.3630, accuracy: 92.9505%, tar: 0.0449 \n",
      "l0: 0.027039, l1: 0.028199, l2: 0.035832, l3: 0.049193, l4: 0.083286, l5: 0.180202, l6: 0.361241\n",
      "\n",
      "[epoch: 344/400, batch: 776/1000, ite: 45848] train loss: 1.3629, accuracy: 94.1237%, tar: 0.0449 \n",
      "l0: 0.035900, l1: 0.038004, l2: 0.049152, l3: 0.067525, l4: 0.118063, l5: 0.190895, l6: 0.352691\n",
      "\n",
      "[epoch: 344/400, batch: 784/1000, ite: 45849] train loss: 1.3628, accuracy: 94.2484%, tar: 0.0449 \n",
      "l0: 0.026488, l1: 0.027587, l2: 0.033428, l3: 0.049064, l4: 0.098489, l5: 0.187680, l6: 0.313375\n",
      "\n",
      "[epoch: 344/400, batch: 792/1000, ite: 45850] train loss: 1.3627, accuracy: 95.7433%, tar: 0.0449 \n",
      "l0: 0.028180, l1: 0.029076, l2: 0.037192, l3: 0.052182, l4: 0.099226, l5: 0.196880, l6: 0.419707\n",
      "\n",
      "[epoch: 344/400, batch: 800/1000, ite: 45851] train loss: 1.3626, accuracy: 94.5176%, tar: 0.0449 \n",
      "l0: 0.024321, l1: 0.025327, l2: 0.032302, l3: 0.046801, l4: 0.074887, l5: 0.133895, l6: 0.256244\n",
      "\n",
      "[epoch: 344/400, batch: 808/1000, ite: 45852] train loss: 1.3624, accuracy: 95.7228%, tar: 0.0449 \n",
      "l0: 0.023131, l1: 0.024467, l2: 0.031008, l3: 0.044379, l4: 0.084328, l5: 0.199136, l6: 0.383623\n",
      "\n",
      "[epoch: 344/400, batch: 816/1000, ite: 45853] train loss: 1.3623, accuracy: 94.5334%, tar: 0.0449 \n",
      "l0: 0.026079, l1: 0.027197, l2: 0.034063, l3: 0.046686, l4: 0.082863, l5: 0.156231, l6: 0.338236\n",
      "\n",
      "[epoch: 344/400, batch: 824/1000, ite: 45854] train loss: 1.3621, accuracy: 95.2302%, tar: 0.0449 \n",
      "l0: 0.031652, l1: 0.033989, l2: 0.043959, l3: 0.067271, l4: 0.124555, l5: 0.219037, l6: 0.385233\n",
      "\n",
      "[epoch: 344/400, batch: 832/1000, ite: 45855] train loss: 1.3621, accuracy: 94.8314%, tar: 0.0449 \n",
      "l0: 0.026851, l1: 0.028593, l2: 0.036657, l3: 0.052624, l4: 0.092967, l5: 0.207226, l6: 0.411683\n",
      "\n",
      "[epoch: 344/400, batch: 840/1000, ite: 45856] train loss: 1.3620, accuracy: 95.0585%, tar: 0.0449 \n",
      "l0: 0.035123, l1: 0.036755, l2: 0.045801, l3: 0.076443, l4: 0.149201, l5: 0.264720, l6: 0.442024\n",
      "\n",
      "[epoch: 344/400, batch: 848/1000, ite: 45857] train loss: 1.3621, accuracy: 93.1128%, tar: 0.0448 \n",
      "l0: 0.029677, l1: 0.031048, l2: 0.040349, l3: 0.057488, l4: 0.100777, l5: 0.206115, l6: 0.416467\n",
      "\n",
      "[epoch: 344/400, batch: 856/1000, ite: 45858] train loss: 1.3620, accuracy: 94.6251%, tar: 0.0448 \n",
      "l0: 0.025106, l1: 0.026667, l2: 0.033728, l3: 0.050375, l4: 0.095770, l5: 0.223739, l6: 0.410913\n",
      "\n",
      "[epoch: 344/400, batch: 864/1000, ite: 45859] train loss: 1.3620, accuracy: 95.4731%, tar: 0.0448 \n",
      "l0: 0.028802, l1: 0.030358, l2: 0.038838, l3: 0.060068, l4: 0.113003, l5: 0.217674, l6: 0.468466\n",
      "\n",
      "[epoch: 344/400, batch: 872/1000, ite: 45860] train loss: 1.3620, accuracy: 94.2032%, tar: 0.0448 \n",
      "l0: 0.037628, l1: 0.038750, l2: 0.048368, l3: 0.067301, l4: 0.126992, l5: 0.286603, l6: 0.602215\n",
      "\n",
      "[epoch: 344/400, batch: 880/1000, ite: 45861] train loss: 1.3623, accuracy: 91.7992%, tar: 0.0448 \n",
      "l0: 0.024260, l1: 0.025593, l2: 0.032152, l3: 0.047261, l4: 0.076826, l5: 0.147712, l6: 0.289653\n",
      "\n",
      "[epoch: 344/400, batch: 888/1000, ite: 45862] train loss: 1.3621, accuracy: 95.9393%, tar: 0.0448 \n",
      "l0: 0.038228, l1: 0.038935, l2: 0.047956, l3: 0.066185, l4: 0.122423, l5: 0.254675, l6: 0.469898\n",
      "\n",
      "[epoch: 344/400, batch: 896/1000, ite: 45863] train loss: 1.3621, accuracy: 92.9219%, tar: 0.0448 \n",
      "l0: 0.029033, l1: 0.030785, l2: 0.039978, l3: 0.053794, l4: 0.086106, l5: 0.164624, l6: 0.304913\n",
      "\n",
      "[epoch: 344/400, batch: 904/1000, ite: 45864] train loss: 1.3620, accuracy: 95.4140%, tar: 0.0448 \n",
      "l0: 0.034401, l1: 0.035524, l2: 0.044408, l3: 0.065438, l4: 0.124040, l5: 0.219400, l6: 0.408597\n",
      "\n",
      "[epoch: 344/400, batch: 912/1000, ite: 45865] train loss: 1.3619, accuracy: 93.5081%, tar: 0.0448 \n",
      "l0: 0.029755, l1: 0.031366, l2: 0.041537, l3: 0.058551, l4: 0.112625, l5: 0.206108, l6: 0.380876\n",
      "\n",
      "[epoch: 344/400, batch: 920/1000, ite: 45866] train loss: 1.3619, accuracy: 95.3615%, tar: 0.0448 \n",
      "l0: 0.028912, l1: 0.030525, l2: 0.037524, l3: 0.054876, l4: 0.108083, l5: 0.191175, l6: 0.379541\n",
      "\n",
      "[epoch: 344/400, batch: 928/1000, ite: 45867] train loss: 1.3618, accuracy: 94.6526%, tar: 0.0448 \n",
      "l0: 0.028069, l1: 0.029330, l2: 0.037497, l3: 0.053662, l4: 0.091536, l5: 0.170372, l6: 0.337572\n",
      "\n",
      "[epoch: 344/400, batch: 936/1000, ite: 45868] train loss: 1.3617, accuracy: 94.5174%, tar: 0.0448 \n",
      "l0: 0.028855, l1: 0.029473, l2: 0.036850, l3: 0.058748, l4: 0.130107, l5: 0.209539, l6: 0.496602\n",
      "\n",
      "[epoch: 344/400, batch: 944/1000, ite: 45869] train loss: 1.3617, accuracy: 94.5844%, tar: 0.0448 \n",
      "l0: 0.029165, l1: 0.030582, l2: 0.040076, l3: 0.053855, l4: 0.097547, l5: 0.185325, l6: 0.365588\n",
      "\n",
      "[epoch: 344/400, batch: 952/1000, ite: 45870] train loss: 1.3616, accuracy: 94.6814%, tar: 0.0447 \n",
      "l0: 0.029463, l1: 0.030157, l2: 0.039368, l3: 0.057985, l4: 0.098614, l5: 0.196913, l6: 0.398944\n",
      "\n",
      "[epoch: 344/400, batch: 960/1000, ite: 45871] train loss: 1.3616, accuracy: 93.3459%, tar: 0.0447 \n",
      "l0: 0.029255, l1: 0.031074, l2: 0.040284, l3: 0.058074, l4: 0.098559, l5: 0.214716, l6: 0.464145\n",
      "\n",
      "[epoch: 344/400, batch: 968/1000, ite: 45872] train loss: 1.3616, accuracy: 94.4350%, tar: 0.0447 \n",
      "l0: 0.022684, l1: 0.026320, l2: 0.040355, l3: 0.066743, l4: 0.130049, l5: 0.248509, l6: 0.458882\n",
      "\n",
      "[epoch: 344/400, batch: 976/1000, ite: 45873] train loss: 1.3616, accuracy: 95.3325%, tar: 0.0447 \n",
      "l0: 0.027113, l1: 0.028739, l2: 0.037304, l3: 0.052510, l4: 0.095228, l5: 0.237330, l6: 0.443583\n",
      "\n",
      "[epoch: 344/400, batch: 984/1000, ite: 45874] train loss: 1.3617, accuracy: 94.1795%, tar: 0.0447 \n",
      "l0: 0.023005, l1: 0.023540, l2: 0.028567, l3: 0.039608, l4: 0.065849, l5: 0.122322, l6: 0.292413\n",
      "\n",
      "[epoch: 344/400, batch: 992/1000, ite: 45875] train loss: 1.3614, accuracy: 95.5979%, tar: 0.0447 \n",
      "l0: 0.023660, l1: 0.024296, l2: 0.030611, l3: 0.042731, l4: 0.072157, l5: 0.134977, l6: 0.267711\n",
      "\n",
      "[epoch: 344/400, batch: 1000/1000, ite: 45876] train loss: 1.3611, accuracy: 95.9848%, tar: 0.0447 \n",
      "l0: 0.021063, l1: 0.023283, l2: 0.031525, l3: 0.050732, l4: 0.105753, l5: 0.172881, l6: 0.388858\n",
      "\n",
      "[epoch: 345/400, batch: 8/1000, ite: 45877] train loss: 1.3610, accuracy: 94.9164%, tar: 0.0447 \n",
      "l0: 0.027473, l1: 0.028862, l2: 0.038575, l3: 0.054260, l4: 0.092389, l5: 0.167196, l6: 0.342805\n",
      "\n",
      "[epoch: 345/400, batch: 16/1000, ite: 45878] train loss: 1.3609, accuracy: 94.9108%, tar: 0.0447 \n",
      "l0: 0.026524, l1: 0.027984, l2: 0.034899, l3: 0.048651, l4: 0.087540, l5: 0.205245, l6: 0.342772\n",
      "\n",
      "[epoch: 345/400, batch: 24/1000, ite: 45879] train loss: 1.3608, accuracy: 95.5075%, tar: 0.0447 \n",
      "l0: 0.020099, l1: 0.020953, l2: 0.026047, l3: 0.037661, l4: 0.069098, l5: 0.116556, l6: 0.256031\n",
      "\n",
      "[epoch: 345/400, batch: 32/1000, ite: 45880] train loss: 1.3605, accuracy: 96.1712%, tar: 0.0446 \n",
      "l0: 0.025253, l1: 0.026406, l2: 0.034165, l3: 0.049078, l4: 0.090359, l5: 0.175552, l6: 0.308442\n",
      "\n",
      "[epoch: 345/400, batch: 40/1000, ite: 45881] train loss: 1.3603, accuracy: 95.4500%, tar: 0.0446 \n",
      "l0: 0.022315, l1: 0.023626, l2: 0.031105, l3: 0.044410, l4: 0.077120, l5: 0.143329, l6: 0.269127\n",
      "\n",
      "[epoch: 345/400, batch: 48/1000, ite: 45882] train loss: 1.3601, accuracy: 95.6181%, tar: 0.0446 \n",
      "l0: 0.021445, l1: 0.022427, l2: 0.029761, l3: 0.046234, l4: 0.082267, l5: 0.160147, l6: 0.341001\n",
      "\n",
      "[epoch: 345/400, batch: 56/1000, ite: 45883] train loss: 1.3599, accuracy: 95.0564%, tar: 0.0446 \n",
      "l0: 0.028607, l1: 0.030558, l2: 0.039446, l3: 0.062162, l4: 0.116274, l5: 0.207805, l6: 0.437596\n",
      "\n",
      "[epoch: 345/400, batch: 64/1000, ite: 45884] train loss: 1.3599, accuracy: 94.4396%, tar: 0.0446 \n",
      "l0: 0.020658, l1: 0.022195, l2: 0.031944, l3: 0.049401, l4: 0.085707, l5: 0.168790, l6: 0.345035\n",
      "\n",
      "[epoch: 345/400, batch: 72/1000, ite: 45885] train loss: 1.3597, accuracy: 95.9438%, tar: 0.0446 \n",
      "l0: 0.028926, l1: 0.030366, l2: 0.039595, l3: 0.055898, l4: 0.097345, l5: 0.183212, l6: 0.386523\n",
      "\n",
      "[epoch: 345/400, batch: 80/1000, ite: 45886] train loss: 1.3597, accuracy: 94.5981%, tar: 0.0446 \n",
      "l0: 0.028233, l1: 0.029508, l2: 0.036773, l3: 0.050968, l4: 0.090480, l5: 0.195164, l6: 0.361598\n",
      "\n",
      "[epoch: 345/400, batch: 88/1000, ite: 45887] train loss: 1.3596, accuracy: 94.3413%, tar: 0.0446 \n",
      "l0: 0.027598, l1: 0.028768, l2: 0.038327, l3: 0.053626, l4: 0.092804, l5: 0.170842, l6: 0.367711\n",
      "\n",
      "[epoch: 345/400, batch: 96/1000, ite: 45888] train loss: 1.3594, accuracy: 95.0869%, tar: 0.0446 \n",
      "l0: 0.031794, l1: 0.033197, l2: 0.042039, l3: 0.057418, l4: 0.091721, l5: 0.185043, l6: 0.368211\n",
      "\n",
      "[epoch: 345/400, batch: 104/1000, ite: 45889] train loss: 1.3594, accuracy: 94.0980%, tar: 0.0445 \n",
      "l0: 0.029683, l1: 0.031140, l2: 0.040998, l3: 0.061388, l4: 0.097179, l5: 0.215281, l6: 0.421656\n",
      "\n",
      "[epoch: 345/400, batch: 112/1000, ite: 45890] train loss: 1.3593, accuracy: 94.2273%, tar: 0.0445 \n",
      "l0: 0.023029, l1: 0.024425, l2: 0.031319, l3: 0.047657, l4: 0.085148, l5: 0.169429, l6: 0.308095\n",
      "\n",
      "[epoch: 345/400, batch: 120/1000, ite: 45891] train loss: 1.3592, accuracy: 95.3038%, tar: 0.0445 \n",
      "l0: 0.029760, l1: 0.030959, l2: 0.041005, l3: 0.059003, l4: 0.109947, l5: 0.252841, l6: 0.544142\n",
      "\n",
      "[epoch: 345/400, batch: 128/1000, ite: 45892] train loss: 1.3593, accuracy: 93.1862%, tar: 0.0445 \n",
      "l0: 0.025478, l1: 0.026209, l2: 0.032579, l3: 0.047635, l4: 0.083622, l5: 0.162944, l6: 0.280034\n",
      "\n",
      "[epoch: 345/400, batch: 136/1000, ite: 45893] train loss: 1.3591, accuracy: 95.5396%, tar: 0.0445 \n",
      "l0: 0.027083, l1: 0.027938, l2: 0.036598, l3: 0.052962, l4: 0.094694, l5: 0.224474, l6: 0.482894\n",
      "\n",
      "[epoch: 345/400, batch: 144/1000, ite: 45894] train loss: 1.3591, accuracy: 93.9139%, tar: 0.0445 \n",
      "l0: 0.025213, l1: 0.025870, l2: 0.032901, l3: 0.047075, l4: 0.078402, l5: 0.134780, l6: 0.276631\n",
      "\n",
      "[epoch: 345/400, batch: 152/1000, ite: 45895] train loss: 1.3589, accuracy: 95.1767%, tar: 0.0445 \n",
      "l0: 0.023973, l1: 0.025762, l2: 0.032415, l3: 0.050137, l4: 0.094223, l5: 0.174959, l6: 0.348788\n",
      "\n",
      "[epoch: 345/400, batch: 160/1000, ite: 45896] train loss: 1.3587, accuracy: 95.4761%, tar: 0.0445 \n",
      "l0: 0.026662, l1: 0.027716, l2: 0.033996, l3: 0.047564, l4: 0.084624, l5: 0.166282, l6: 0.349012\n",
      "\n",
      "[epoch: 345/400, batch: 168/1000, ite: 45897] train loss: 1.3586, accuracy: 94.2970%, tar: 0.0445 \n",
      "l0: 0.024975, l1: 0.026252, l2: 0.034473, l3: 0.052447, l4: 0.091565, l5: 0.195007, l6: 0.330400\n",
      "\n",
      "[epoch: 345/400, batch: 176/1000, ite: 45898] train loss: 1.3585, accuracy: 95.5272%, tar: 0.0445 \n",
      "l0: 0.036289, l1: 0.037410, l2: 0.048090, l3: 0.069840, l4: 0.121877, l5: 0.243022, l6: 0.450081\n",
      "\n",
      "[epoch: 345/400, batch: 184/1000, ite: 45899] train loss: 1.3585, accuracy: 93.1262%, tar: 0.0445 \n",
      "l0: 0.025093, l1: 0.025785, l2: 0.031212, l3: 0.044349, l4: 0.079515, l5: 0.146662, l6: 0.274996\n",
      "\n",
      "[epoch: 345/400, batch: 192/1000, ite: 45900] train loss: 1.3583, accuracy: 95.6066%, tar: 0.0444 \n",
      "l0: 0.028465, l1: 0.030642, l2: 0.039608, l3: 0.061214, l4: 0.115663, l5: 0.230016, l6: 0.510240\n",
      "\n",
      "[epoch: 345/400, batch: 200/1000, ite: 45901] train loss: 1.3584, accuracy: 94.0286%, tar: 0.0444 \n",
      "l0: 0.022589, l1: 0.023589, l2: 0.031327, l3: 0.046291, l4: 0.082264, l5: 0.165936, l6: 0.343404\n",
      "\n",
      "[epoch: 345/400, batch: 208/1000, ite: 45902] train loss: 1.3582, accuracy: 95.4017%, tar: 0.0444 \n",
      "l0: 0.027483, l1: 0.028918, l2: 0.039258, l3: 0.058112, l4: 0.108165, l5: 0.201628, l6: 0.408389\n",
      "\n",
      "[epoch: 345/400, batch: 216/1000, ite: 45903] train loss: 1.3582, accuracy: 94.4588%, tar: 0.0444 \n",
      "l0: 0.024683, l1: 0.025756, l2: 0.031798, l3: 0.047473, l4: 0.102761, l5: 0.167215, l6: 0.377276\n",
      "\n",
      "[epoch: 345/400, batch: 224/1000, ite: 45904] train loss: 1.3581, accuracy: 94.9098%, tar: 0.0444 \n",
      "l0: 0.023503, l1: 0.024711, l2: 0.033814, l3: 0.054119, l4: 0.104794, l5: 0.217054, l6: 0.351751\n",
      "\n",
      "[epoch: 345/400, batch: 232/1000, ite: 45905] train loss: 1.3580, accuracy: 95.4060%, tar: 0.0444 \n",
      "l0: 0.025356, l1: 0.026881, l2: 0.035556, l3: 0.054361, l4: 0.102627, l5: 0.200433, l6: 0.408605\n",
      "\n",
      "[epoch: 345/400, batch: 240/1000, ite: 45906] train loss: 1.3579, accuracy: 94.9135%, tar: 0.0444 \n",
      "l0: 0.030431, l1: 0.031381, l2: 0.037632, l3: 0.053052, l4: 0.094098, l5: 0.201065, l6: 0.360757\n",
      "\n",
      "[epoch: 345/400, batch: 248/1000, ite: 45907] train loss: 1.3578, accuracy: 93.7682%, tar: 0.0444 \n",
      "l0: 0.029662, l1: 0.032547, l2: 0.043138, l3: 0.071227, l4: 0.131955, l5: 0.216975, l6: 0.429332\n",
      "\n",
      "[epoch: 345/400, batch: 256/1000, ite: 45908] train loss: 1.3579, accuracy: 93.6105%, tar: 0.0444 \n",
      "l0: 0.030087, l1: 0.031433, l2: 0.041482, l3: 0.059807, l4: 0.109669, l5: 0.207401, l6: 0.455588\n",
      "\n",
      "[epoch: 345/400, batch: 264/1000, ite: 45909] train loss: 1.3579, accuracy: 92.8164%, tar: 0.0444 \n",
      "l0: 0.025731, l1: 0.027515, l2: 0.034876, l3: 0.049884, l4: 0.084929, l5: 0.203659, l6: 0.388076\n",
      "\n",
      "[epoch: 345/400, batch: 272/1000, ite: 45910] train loss: 1.3578, accuracy: 94.8315%, tar: 0.0444 \n",
      "l0: 0.022853, l1: 0.023546, l2: 0.030433, l3: 0.044042, l4: 0.081639, l5: 0.155154, l6: 0.320724\n",
      "\n",
      "[epoch: 345/400, batch: 280/1000, ite: 45911] train loss: 1.3576, accuracy: 95.4888%, tar: 0.0443 \n",
      "l0: 0.021709, l1: 0.022547, l2: 0.027979, l3: 0.040125, l4: 0.070036, l5: 0.141271, l6: 0.281862\n",
      "\n",
      "[epoch: 345/400, batch: 288/1000, ite: 45912] train loss: 1.3574, accuracy: 95.7995%, tar: 0.0443 \n",
      "l0: 0.027914, l1: 0.029362, l2: 0.037980, l3: 0.052624, l4: 0.089127, l5: 0.174303, l6: 0.398122\n",
      "\n",
      "[epoch: 345/400, batch: 296/1000, ite: 45913] train loss: 1.3573, accuracy: 95.1226%, tar: 0.0443 \n",
      "l0: 0.025693, l1: 0.026495, l2: 0.034625, l3: 0.046780, l4: 0.083504, l5: 0.182826, l6: 0.370114\n",
      "\n",
      "[epoch: 345/400, batch: 304/1000, ite: 45914] train loss: 1.3572, accuracy: 94.6383%, tar: 0.0443 \n",
      "l0: 0.025479, l1: 0.027331, l2: 0.035756, l3: 0.059221, l4: 0.135928, l5: 0.247876, l6: 0.445514\n",
      "\n",
      "[epoch: 345/400, batch: 312/1000, ite: 45915] train loss: 1.3572, accuracy: 94.0000%, tar: 0.0443 \n",
      "l0: 0.030574, l1: 0.032004, l2: 0.040694, l3: 0.062465, l4: 0.121924, l5: 0.242344, l6: 0.536025\n",
      "\n",
      "[epoch: 345/400, batch: 320/1000, ite: 45916] train loss: 1.3574, accuracy: 92.9102%, tar: 0.0443 \n",
      "l0: 0.023095, l1: 0.023782, l2: 0.030557, l3: 0.042901, l4: 0.070988, l5: 0.149414, l6: 0.346389\n",
      "\n",
      "[epoch: 345/400, batch: 328/1000, ite: 45917] train loss: 1.3572, accuracy: 94.9479%, tar: 0.0443 \n",
      "l0: 0.027456, l1: 0.028298, l2: 0.034957, l3: 0.050932, l4: 0.089936, l5: 0.180648, l6: 0.417717\n",
      "\n",
      "[epoch: 345/400, batch: 336/1000, ite: 45918] train loss: 1.3571, accuracy: 94.2079%, tar: 0.0443 \n",
      "l0: 0.022455, l1: 0.024004, l2: 0.031803, l3: 0.048197, l4: 0.095702, l5: 0.194979, l6: 0.359906\n",
      "\n",
      "[epoch: 345/400, batch: 344/1000, ite: 45919] train loss: 1.3570, accuracy: 95.4567%, tar: 0.0443 \n",
      "l0: 0.027735, l1: 0.029487, l2: 0.039467, l3: 0.062267, l4: 0.107766, l5: 0.202829, l6: 0.360203\n",
      "\n",
      "[epoch: 345/400, batch: 352/1000, ite: 45920] train loss: 1.3569, accuracy: 94.8624%, tar: 0.0443 \n",
      "l0: 0.026220, l1: 0.027078, l2: 0.034163, l3: 0.046142, l4: 0.071086, l5: 0.134738, l6: 0.319757\n",
      "\n",
      "[epoch: 345/400, batch: 360/1000, ite: 45921] train loss: 1.3568, accuracy: 95.2070%, tar: 0.0442 \n",
      "l0: 0.022819, l1: 0.024131, l2: 0.030848, l3: 0.041545, l4: 0.065758, l5: 0.118144, l6: 0.248270\n",
      "\n",
      "[epoch: 345/400, batch: 368/1000, ite: 45922] train loss: 1.3565, accuracy: 96.2452%, tar: 0.0442 \n",
      "l0: 0.035663, l1: 0.036504, l2: 0.045818, l3: 0.062867, l4: 0.105248, l5: 0.223098, l6: 0.511612\n",
      "\n",
      "[epoch: 345/400, batch: 376/1000, ite: 45923] train loss: 1.3566, accuracy: 92.4146%, tar: 0.0442 \n",
      "l0: 0.027756, l1: 0.028965, l2: 0.036847, l3: 0.052539, l4: 0.098909, l5: 0.207331, l6: 0.443918\n",
      "\n",
      "[epoch: 345/400, batch: 384/1000, ite: 45924] train loss: 1.3566, accuracy: 93.8415%, tar: 0.0442 \n",
      "l0: 0.030597, l1: 0.031751, l2: 0.042219, l3: 0.057941, l4: 0.095291, l5: 0.176060, l6: 0.375845\n",
      "\n",
      "[epoch: 345/400, batch: 392/1000, ite: 45925] train loss: 1.3565, accuracy: 94.5737%, tar: 0.0442 \n",
      "l0: 0.026257, l1: 0.027717, l2: 0.036136, l3: 0.052473, l4: 0.098636, l5: 0.203835, l6: 0.395472\n",
      "\n",
      "[epoch: 345/400, batch: 400/1000, ite: 45926] train loss: 1.3564, accuracy: 94.1048%, tar: 0.0442 \n",
      "l0: 0.022557, l1: 0.023425, l2: 0.029863, l3: 0.041444, l4: 0.072627, l5: 0.129160, l6: 0.239434\n",
      "\n",
      "[epoch: 345/400, batch: 408/1000, ite: 45927] train loss: 1.3561, accuracy: 96.3425%, tar: 0.0442 \n",
      "l0: 0.028561, l1: 0.030331, l2: 0.039601, l3: 0.064037, l4: 0.113967, l5: 0.205126, l6: 0.388572\n",
      "\n",
      "[epoch: 345/400, batch: 416/1000, ite: 45928] train loss: 1.3561, accuracy: 94.8167%, tar: 0.0442 \n",
      "l0: 0.022134, l1: 0.022787, l2: 0.029728, l3: 0.042856, l4: 0.076908, l5: 0.151761, l6: 0.293739\n",
      "\n",
      "[epoch: 345/400, batch: 424/1000, ite: 45929] train loss: 1.3559, accuracy: 95.9239%, tar: 0.0442 \n",
      "l0: 0.025471, l1: 0.026091, l2: 0.033109, l3: 0.044105, l4: 0.078798, l5: 0.147243, l6: 0.354213\n",
      "\n",
      "[epoch: 345/400, batch: 432/1000, ite: 45930] train loss: 1.3557, accuracy: 94.7440%, tar: 0.0442 \n",
      "l0: 0.020766, l1: 0.021848, l2: 0.027263, l3: 0.040881, l4: 0.066667, l5: 0.116840, l6: 0.241452\n",
      "\n",
      "[epoch: 345/400, batch: 440/1000, ite: 45931] train loss: 1.3554, accuracy: 95.8778%, tar: 0.0442 \n",
      "l0: 0.024248, l1: 0.024842, l2: 0.030429, l3: 0.043554, l4: 0.070870, l5: 0.123323, l6: 0.237952\n",
      "\n",
      "[epoch: 345/400, batch: 448/1000, ite: 45932] train loss: 1.3551, accuracy: 95.8274%, tar: 0.0441 \n",
      "l0: 0.030925, l1: 0.032451, l2: 0.043276, l3: 0.061410, l4: 0.107063, l5: 0.223551, l6: 0.382889\n",
      "\n",
      "[epoch: 345/400, batch: 456/1000, ite: 45933] train loss: 1.3551, accuracy: 94.8002%, tar: 0.0441 \n",
      "l0: 0.030383, l1: 0.032090, l2: 0.042130, l3: 0.062709, l4: 0.134176, l5: 0.288284, l6: 0.545566\n",
      "\n",
      "[epoch: 345/400, batch: 464/1000, ite: 45934] train loss: 1.3553, accuracy: 92.6440%, tar: 0.0441 \n",
      "l0: 0.022770, l1: 0.024066, l2: 0.032845, l3: 0.047323, l4: 0.087492, l5: 0.175644, l6: 0.314469\n",
      "\n",
      "[epoch: 345/400, batch: 472/1000, ite: 45935] train loss: 1.3551, accuracy: 95.8652%, tar: 0.0441 \n",
      "l0: 0.035718, l1: 0.037960, l2: 0.048223, l3: 0.071861, l4: 0.138140, l5: 0.270953, l6: 0.523366\n",
      "\n",
      "[epoch: 345/400, batch: 480/1000, ite: 45936] train loss: 1.3553, accuracy: 92.8263%, tar: 0.0441 \n",
      "l0: 0.026614, l1: 0.027671, l2: 0.033361, l3: 0.047921, l4: 0.094226, l5: 0.180559, l6: 0.376690\n",
      "\n",
      "[epoch: 345/400, batch: 488/1000, ite: 45937] train loss: 1.3552, accuracy: 94.7785%, tar: 0.0441 \n",
      "l0: 0.035304, l1: 0.037407, l2: 0.049889, l3: 0.076200, l4: 0.159192, l5: 0.336545, l6: 0.640897\n",
      "\n",
      "[epoch: 345/400, batch: 496/1000, ite: 45938] train loss: 1.3555, accuracy: 92.0054%, tar: 0.0441 \n",
      "l0: 0.026100, l1: 0.027729, l2: 0.035912, l3: 0.052556, l4: 0.094242, l5: 0.199826, l6: 0.415786\n",
      "\n",
      "[epoch: 345/400, batch: 504/1000, ite: 45939] train loss: 1.3554, accuracy: 94.0764%, tar: 0.0441 \n",
      "l0: 0.029973, l1: 0.030992, l2: 0.040863, l3: 0.059819, l4: 0.105176, l5: 0.218490, l6: 0.455806\n",
      "\n",
      "[epoch: 345/400, batch: 512/1000, ite: 45940] train loss: 1.3555, accuracy: 93.4276%, tar: 0.0441 \n",
      "l0: 0.029136, l1: 0.030824, l2: 0.040711, l3: 0.061815, l4: 0.092885, l5: 0.150733, l6: 0.288462\n",
      "\n",
      "[epoch: 345/400, batch: 520/1000, ite: 45941] train loss: 1.3553, accuracy: 95.8909%, tar: 0.0441 \n",
      "l0: 0.032333, l1: 0.033812, l2: 0.041924, l3: 0.059394, l4: 0.112686, l5: 0.252047, l6: 0.527445\n",
      "\n",
      "[epoch: 345/400, batch: 528/1000, ite: 45942] train loss: 1.3554, accuracy: 93.4066%, tar: 0.0441 \n",
      "l0: 0.026839, l1: 0.028340, l2: 0.039037, l3: 0.059143, l4: 0.098342, l5: 0.199395, l6: 0.428220\n",
      "\n",
      "[epoch: 345/400, batch: 536/1000, ite: 45943] train loss: 1.3554, accuracy: 94.5387%, tar: 0.0441 \n",
      "l0: 0.023423, l1: 0.024097, l2: 0.030511, l3: 0.041533, l4: 0.071121, l5: 0.123500, l6: 0.281032\n",
      "\n",
      "[epoch: 345/400, batch: 544/1000, ite: 45944] train loss: 1.3551, accuracy: 95.2375%, tar: 0.0441 \n",
      "l0: 0.028877, l1: 0.029997, l2: 0.039045, l3: 0.054162, l4: 0.103950, l5: 0.196046, l6: 0.465016\n",
      "\n",
      "[epoch: 345/400, batch: 552/1000, ite: 45945] train loss: 1.3551, accuracy: 93.5875%, tar: 0.0440 \n",
      "l0: 0.028022, l1: 0.029044, l2: 0.038139, l3: 0.055760, l4: 0.100170, l5: 0.214641, l6: 0.426774\n",
      "\n",
      "[epoch: 345/400, batch: 560/1000, ite: 45946] train loss: 1.3551, accuracy: 94.4093%, tar: 0.0440 \n",
      "l0: 0.026544, l1: 0.027983, l2: 0.035978, l3: 0.053584, l4: 0.093643, l5: 0.220001, l6: 0.405617\n",
      "\n",
      "[epoch: 345/400, batch: 568/1000, ite: 45947] train loss: 1.3551, accuracy: 94.2695%, tar: 0.0440 \n",
      "l0: 0.025587, l1: 0.026999, l2: 0.035607, l3: 0.055503, l4: 0.118031, l5: 0.230909, l6: 0.511723\n",
      "\n",
      "[epoch: 345/400, batch: 576/1000, ite: 45948] train loss: 1.3552, accuracy: 93.2799%, tar: 0.0440 \n",
      "l0: 0.032736, l1: 0.034707, l2: 0.046419, l3: 0.067687, l4: 0.125509, l5: 0.205293, l6: 0.401828\n",
      "\n",
      "[epoch: 345/400, batch: 584/1000, ite: 45949] train loss: 1.3552, accuracy: 94.6361%, tar: 0.0440 \n",
      "l0: 0.031524, l1: 0.032037, l2: 0.038323, l3: 0.055664, l4: 0.099879, l5: 0.190762, l6: 0.386167\n",
      "\n",
      "[epoch: 345/400, batch: 592/1000, ite: 45950] train loss: 1.3551, accuracy: 93.9214%, tar: 0.0440 \n",
      "l0: 0.026471, l1: 0.027945, l2: 0.035251, l3: 0.047839, l4: 0.087063, l5: 0.160558, l6: 0.400176\n",
      "\n",
      "[epoch: 345/400, batch: 600/1000, ite: 45951] train loss: 1.3550, accuracy: 94.5239%, tar: 0.0440 \n",
      "l0: 0.023112, l1: 0.024892, l2: 0.033858, l3: 0.052970, l4: 0.100343, l5: 0.200953, l6: 0.349168\n",
      "\n",
      "[epoch: 345/400, batch: 608/1000, ite: 45952] train loss: 1.3549, accuracy: 95.3207%, tar: 0.0440 \n",
      "l0: 0.029444, l1: 0.030490, l2: 0.039761, l3: 0.057151, l4: 0.102471, l5: 0.209416, l6: 0.506585\n",
      "\n",
      "[epoch: 345/400, batch: 616/1000, ite: 45953] train loss: 1.3550, accuracy: 92.8409%, tar: 0.0440 \n",
      "l0: 0.028352, l1: 0.029583, l2: 0.039031, l3: 0.056262, l4: 0.093236, l5: 0.171437, l6: 0.337252\n",
      "\n",
      "[epoch: 345/400, batch: 624/1000, ite: 45954] train loss: 1.3548, accuracy: 94.7743%, tar: 0.0440 \n",
      "l0: 0.025503, l1: 0.026835, l2: 0.035256, l3: 0.051352, l4: 0.089974, l5: 0.170419, l6: 0.385639\n",
      "\n",
      "[epoch: 345/400, batch: 632/1000, ite: 45955] train loss: 1.3548, accuracy: 95.3451%, tar: 0.0440 \n",
      "l0: 0.024826, l1: 0.026306, l2: 0.036083, l3: 0.060828, l4: 0.109980, l5: 0.187871, l6: 0.407942\n",
      "\n",
      "[epoch: 345/400, batch: 640/1000, ite: 45956] train loss: 1.3547, accuracy: 94.7605%, tar: 0.0440 \n",
      "l0: 0.026300, l1: 0.028066, l2: 0.035536, l3: 0.050714, l4: 0.086659, l5: 0.171419, l6: 0.349155\n",
      "\n",
      "[epoch: 345/400, batch: 648/1000, ite: 45957] train loss: 1.3546, accuracy: 95.3543%, tar: 0.0439 \n",
      "l0: 0.022275, l1: 0.023720, l2: 0.031218, l3: 0.049486, l4: 0.092805, l5: 0.165590, l6: 0.333078\n",
      "\n",
      "[epoch: 345/400, batch: 656/1000, ite: 45958] train loss: 1.3544, accuracy: 95.2377%, tar: 0.0439 \n",
      "l0: 0.029085, l1: 0.031204, l2: 0.041780, l3: 0.065944, l4: 0.126952, l5: 0.238317, l6: 0.421728\n",
      "\n",
      "[epoch: 345/400, batch: 664/1000, ite: 45959] train loss: 1.3544, accuracy: 94.5465%, tar: 0.0439 \n",
      "l0: 0.030800, l1: 0.032203, l2: 0.039855, l3: 0.060612, l4: 0.118071, l5: 0.201393, l6: 0.468177\n",
      "\n",
      "[epoch: 345/400, batch: 672/1000, ite: 45960] train loss: 1.3545, accuracy: 93.4006%, tar: 0.0439 \n",
      "l0: 0.024395, l1: 0.025625, l2: 0.032558, l3: 0.049208, l4: 0.110690, l5: 0.194027, l6: 0.381907\n",
      "\n",
      "[epoch: 345/400, batch: 680/1000, ite: 45961] train loss: 1.3544, accuracy: 95.3365%, tar: 0.0439 \n",
      "l0: 0.030821, l1: 0.031953, l2: 0.040943, l3: 0.057853, l4: 0.095531, l5: 0.173893, l6: 0.376045\n",
      "\n",
      "[epoch: 345/400, batch: 688/1000, ite: 45962] train loss: 1.3543, accuracy: 94.0152%, tar: 0.0439 \n",
      "l0: 0.027059, l1: 0.028288, l2: 0.036569, l3: 0.052703, l4: 0.096126, l5: 0.211326, l6: 0.427913\n",
      "\n",
      "[epoch: 345/400, batch: 696/1000, ite: 45963] train loss: 1.3543, accuracy: 93.9667%, tar: 0.0439 \n",
      "l0: 0.025229, l1: 0.026669, l2: 0.033596, l3: 0.050452, l4: 0.094914, l5: 0.187504, l6: 0.369576\n",
      "\n",
      "[epoch: 345/400, batch: 704/1000, ite: 45964] train loss: 1.3542, accuracy: 94.6540%, tar: 0.0439 \n",
      "l0: 0.022553, l1: 0.023317, l2: 0.029316, l3: 0.039593, l4: 0.074185, l5: 0.140469, l6: 0.284969\n",
      "\n",
      "[epoch: 345/400, batch: 712/1000, ite: 45965] train loss: 1.3540, accuracy: 95.7767%, tar: 0.0439 \n",
      "l0: 0.022518, l1: 0.024028, l2: 0.032165, l3: 0.048084, l4: 0.085792, l5: 0.152629, l6: 0.281211\n",
      "\n",
      "[epoch: 345/400, batch: 720/1000, ite: 45966] train loss: 1.3538, accuracy: 95.9914%, tar: 0.0439 \n",
      "l0: 0.027028, l1: 0.027704, l2: 0.035012, l3: 0.049143, l4: 0.084192, l5: 0.144957, l6: 0.274868\n",
      "\n",
      "[epoch: 345/400, batch: 728/1000, ite: 45967] train loss: 1.3535, accuracy: 95.1039%, tar: 0.0439 \n",
      "l0: 0.025199, l1: 0.026666, l2: 0.035572, l3: 0.053298, l4: 0.097116, l5: 0.224784, l6: 0.481257\n",
      "\n",
      "[epoch: 345/400, batch: 736/1000, ite: 45968] train loss: 1.3536, accuracy: 94.3816%, tar: 0.0438 \n",
      "l0: 0.029077, l1: 0.030408, l2: 0.039537, l3: 0.062004, l4: 0.128347, l5: 0.248401, l6: 0.443786\n",
      "\n",
      "[epoch: 345/400, batch: 744/1000, ite: 45969] train loss: 1.3536, accuracy: 94.3081%, tar: 0.0438 \n",
      "l0: 0.021899, l1: 0.023293, l2: 0.028735, l3: 0.042779, l4: 0.074657, l5: 0.133366, l6: 0.255070\n",
      "\n",
      "[epoch: 345/400, batch: 752/1000, ite: 45970] train loss: 1.3534, accuracy: 96.0328%, tar: 0.0438 \n",
      "l0: 0.030074, l1: 0.031618, l2: 0.040970, l3: 0.064560, l4: 0.138455, l5: 0.266120, l6: 0.535724\n",
      "\n",
      "[epoch: 345/400, batch: 760/1000, ite: 45971] train loss: 1.3535, accuracy: 93.5265%, tar: 0.0438 \n",
      "l0: 0.023907, l1: 0.024673, l2: 0.030488, l3: 0.043166, l4: 0.075031, l5: 0.138793, l6: 0.280110\n",
      "\n",
      "[epoch: 345/400, batch: 768/1000, ite: 45972] train loss: 1.3533, accuracy: 95.5623%, tar: 0.0438 \n",
      "l0: 0.030906, l1: 0.032129, l2: 0.042517, l3: 0.059746, l4: 0.102292, l5: 0.204852, l6: 0.436828\n",
      "\n",
      "[epoch: 345/400, batch: 776/1000, ite: 45973] train loss: 1.3533, accuracy: 94.1995%, tar: 0.0438 \n",
      "l0: 0.024296, l1: 0.025956, l2: 0.032606, l3: 0.042787, l4: 0.074097, l5: 0.155335, l6: 0.309776\n",
      "\n",
      "[epoch: 345/400, batch: 784/1000, ite: 45974] train loss: 1.3531, accuracy: 95.1365%, tar: 0.0438 \n",
      "l0: 0.027160, l1: 0.028144, l2: 0.034212, l3: 0.048786, l4: 0.084317, l5: 0.167246, l6: 0.330783\n",
      "\n",
      "[epoch: 345/400, batch: 792/1000, ite: 45975] train loss: 1.3530, accuracy: 94.8760%, tar: 0.0438 \n",
      "l0: 0.020573, l1: 0.021400, l2: 0.028094, l3: 0.041876, l4: 0.065800, l5: 0.136017, l6: 0.266127\n",
      "\n",
      "[epoch: 345/400, batch: 800/1000, ite: 45976] train loss: 1.3527, accuracy: 96.1636%, tar: 0.0438 \n",
      "l0: 0.025096, l1: 0.026018, l2: 0.032029, l3: 0.045817, l4: 0.087553, l5: 0.158342, l6: 0.314106\n",
      "\n",
      "[epoch: 345/400, batch: 808/1000, ite: 45977] train loss: 1.3525, accuracy: 95.3948%, tar: 0.0438 \n",
      "l0: 0.026120, l1: 0.027431, l2: 0.034469, l3: 0.049979, l4: 0.098020, l5: 0.180157, l6: 0.334030\n",
      "\n",
      "[epoch: 345/400, batch: 816/1000, ite: 45978] train loss: 1.3524, accuracy: 95.1598%, tar: 0.0438 \n",
      "l0: 0.023855, l1: 0.025350, l2: 0.033056, l3: 0.050249, l4: 0.090826, l5: 0.168821, l6: 0.300388\n",
      "\n",
      "[epoch: 345/400, batch: 824/1000, ite: 45979] train loss: 1.3522, accuracy: 95.4113%, tar: 0.0437 \n",
      "l0: 0.025115, l1: 0.026451, l2: 0.033445, l3: 0.048605, l4: 0.085848, l5: 0.180622, l6: 0.403683\n",
      "\n",
      "[epoch: 345/400, batch: 832/1000, ite: 45980] train loss: 1.3521, accuracy: 94.7956%, tar: 0.0437 \n",
      "l0: 0.030535, l1: 0.031879, l2: 0.039617, l3: 0.058740, l4: 0.127830, l5: 0.241073, l6: 0.429687\n",
      "\n",
      "[epoch: 345/400, batch: 840/1000, ite: 45981] train loss: 1.3522, accuracy: 93.7311%, tar: 0.0437 \n",
      "l0: 0.028431, l1: 0.029395, l2: 0.036824, l3: 0.050778, l4: 0.091146, l5: 0.194035, l6: 0.392868\n",
      "\n",
      "[epoch: 345/400, batch: 848/1000, ite: 45982] train loss: 1.3521, accuracy: 94.8290%, tar: 0.0437 \n",
      "l0: 0.025953, l1: 0.027199, l2: 0.034710, l3: 0.047730, l4: 0.078146, l5: 0.150913, l6: 0.340627\n",
      "\n",
      "[epoch: 345/400, batch: 856/1000, ite: 45983] train loss: 1.3520, accuracy: 95.2419%, tar: 0.0437 \n",
      "l0: 0.027812, l1: 0.029216, l2: 0.037132, l3: 0.053641, l4: 0.095726, l5: 0.218241, l6: 0.486377\n",
      "\n",
      "[epoch: 345/400, batch: 864/1000, ite: 45984] train loss: 1.3520, accuracy: 93.1609%, tar: 0.0437 \n",
      "l0: 0.028821, l1: 0.030022, l2: 0.038543, l3: 0.056463, l4: 0.099719, l5: 0.203027, l6: 0.430736\n",
      "\n",
      "[epoch: 345/400, batch: 872/1000, ite: 45985] train loss: 1.3520, accuracy: 94.1108%, tar: 0.0437 \n",
      "l0: 0.024523, l1: 0.025220, l2: 0.031822, l3: 0.045865, l4: 0.078508, l5: 0.164410, l6: 0.406300\n",
      "\n",
      "[epoch: 345/400, batch: 880/1000, ite: 45986] train loss: 1.3519, accuracy: 93.9541%, tar: 0.0437 \n",
      "l0: 0.028798, l1: 0.030513, l2: 0.037941, l3: 0.054678, l4: 0.114810, l5: 0.234213, l6: 0.429373\n",
      "\n",
      "[epoch: 345/400, batch: 888/1000, ite: 45987] train loss: 1.3519, accuracy: 94.2637%, tar: 0.0437 \n",
      "l0: 0.037242, l1: 0.039655, l2: 0.049064, l3: 0.076615, l4: 0.143931, l5: 0.285017, l6: 0.553240\n",
      "\n",
      "[epoch: 345/400, batch: 896/1000, ite: 45988] train loss: 1.3521, accuracy: 92.5820%, tar: 0.0437 \n",
      "l0: 0.022221, l1: 0.022806, l2: 0.028565, l3: 0.040046, l4: 0.068126, l5: 0.120298, l6: 0.280438\n",
      "\n",
      "[epoch: 345/400, batch: 904/1000, ite: 45989] train loss: 1.3519, accuracy: 95.5650%, tar: 0.0437 \n",
      "l0: 0.024479, l1: 0.025561, l2: 0.031972, l3: 0.044003, l4: 0.073103, l5: 0.142980, l6: 0.301293\n",
      "\n",
      "[epoch: 345/400, batch: 912/1000, ite: 45990] train loss: 1.3517, accuracy: 95.2969%, tar: 0.0437 \n",
      "l0: 0.034704, l1: 0.036889, l2: 0.046990, l3: 0.078028, l4: 0.140961, l5: 0.258279, l6: 0.445329\n",
      "\n",
      "[epoch: 345/400, batch: 920/1000, ite: 45991] train loss: 1.3517, accuracy: 94.3774%, tar: 0.0436 \n",
      "l0: 0.024213, l1: 0.026120, l2: 0.034656, l3: 0.052610, l4: 0.095361, l5: 0.181652, l6: 0.365391\n",
      "\n",
      "[epoch: 345/400, batch: 928/1000, ite: 45992] train loss: 1.3516, accuracy: 95.4421%, tar: 0.0436 \n",
      "l0: 0.022811, l1: 0.023863, l2: 0.031477, l3: 0.046883, l4: 0.088891, l5: 0.177237, l6: 0.351609\n",
      "\n",
      "[epoch: 345/400, batch: 936/1000, ite: 45993] train loss: 1.3515, accuracy: 94.7489%, tar: 0.0436 \n",
      "l0: 0.030473, l1: 0.031367, l2: 0.042017, l3: 0.065439, l4: 0.122650, l5: 0.270262, l6: 0.458931\n",
      "\n",
      "[epoch: 345/400, batch: 944/1000, ite: 45994] train loss: 1.3516, accuracy: 93.5716%, tar: 0.0436 \n",
      "l0: 0.025847, l1: 0.026756, l2: 0.035266, l3: 0.050836, l4: 0.097619, l5: 0.168015, l6: 0.349273\n",
      "\n",
      "[epoch: 345/400, batch: 952/1000, ite: 45995] train loss: 1.3515, accuracy: 95.4011%, tar: 0.0436 \n",
      "l0: 0.030620, l1: 0.033005, l2: 0.042401, l3: 0.059220, l4: 0.106301, l5: 0.211030, l6: 0.422800\n",
      "\n",
      "[epoch: 345/400, batch: 960/1000, ite: 45996] train loss: 1.3514, accuracy: 94.6706%, tar: 0.0436 \n",
      "l0: 0.030878, l1: 0.032057, l2: 0.042922, l3: 0.058378, l4: 0.109953, l5: 0.233443, l6: 0.426865\n",
      "\n",
      "[epoch: 345/400, batch: 968/1000, ite: 45997] train loss: 1.3515, accuracy: 93.7545%, tar: 0.0436 \n",
      "l0: 0.031027, l1: 0.032863, l2: 0.044161, l3: 0.068994, l4: 0.146176, l5: 0.299009, l6: 0.466885\n",
      "\n",
      "[epoch: 345/400, batch: 976/1000, ite: 45998] train loss: 1.3516, accuracy: 93.9041%, tar: 0.0436 \n",
      "l0: 0.025096, l1: 0.026227, l2: 0.034713, l3: 0.047193, l4: 0.073628, l5: 0.149825, l6: 0.289686\n",
      "\n",
      "[epoch: 345/400, batch: 984/1000, ite: 45999] train loss: 1.3514, accuracy: 95.7472%, tar: 0.0436 \n",
      "l0: 0.030590, l1: 0.033188, l2: 0.043455, l3: 0.067035, l4: 0.127575, l5: 0.233098, l6: 0.408511\n",
      "\n",
      "[epoch: 345/400, batch: 992/1000, ite: 46000] train loss: 1.3514, accuracy: 94.4310%, tar: 0.0436 \n",
      "l0: 0.019913, l1: 0.021126, l2: 0.028158, l3: 0.040016, l4: 0.069829, l5: 0.139245, l6: 0.272888\n",
      "\n",
      "[epoch: 345/400, batch: 1000/1000, ite: 46001] train loss: 0.8714, accuracy: 96.4490%, tar: 0.0199 \n",
      "l0: 0.020127, l1: 0.021660, l2: 0.028177, l3: 0.041793, l4: 0.078877, l5: 0.152615, l6: 0.320121\n",
      "\n",
      "[epoch: 346/400, batch: 8/1000, ite: 46002] train loss: 0.9306, accuracy: 94.9824%, tar: 0.0200 \n",
      "l0: 0.030361, l1: 0.032784, l2: 0.042348, l3: 0.067371, l4: 0.141142, l5: 0.288093, l6: 0.515148\n",
      "\n",
      "[epoch: 346/400, batch: 16/1000, ite: 46003] train loss: 1.1663, accuracy: 92.9030%, tar: 0.0235 \n",
      "l0: 0.028786, l1: 0.030959, l2: 0.039709, l3: 0.060194, l4: 0.121286, l5: 0.238669, l6: 0.438243\n",
      "\n",
      "[epoch: 346/400, batch: 24/1000, ite: 46004] train loss: 1.2242, accuracy: 94.4823%, tar: 0.0248 \n",
      "l0: 0.025107, l1: 0.026411, l2: 0.034032, l3: 0.045541, l4: 0.073012, l5: 0.139826, l6: 0.375840\n",
      "\n",
      "[epoch: 346/400, batch: 32/1000, ite: 46005] train loss: 1.1974, accuracy: 94.8047%, tar: 0.0249 \n",
      "l0: 0.022606, l1: 0.024312, l2: 0.033112, l3: 0.052728, l4: 0.091203, l5: 0.152582, l6: 0.325936\n",
      "\n",
      "[epoch: 346/400, batch: 40/1000, ite: 46006] train loss: 1.1697, accuracy: 95.8531%, tar: 0.0245 \n",
      "l0: 0.031679, l1: 0.032975, l2: 0.044018, l3: 0.062222, l4: 0.104516, l5: 0.204161, l6: 0.437513\n",
      "\n",
      "[epoch: 346/400, batch: 48/1000, ite: 46007] train loss: 1.1977, accuracy: 94.0753%, tar: 0.0255 \n",
      "l0: 0.025012, l1: 0.027175, l2: 0.037898, l3: 0.057110, l4: 0.098670, l5: 0.176153, l6: 0.320935\n",
      "\n",
      "[epoch: 346/400, batch: 56/1000, ite: 46008] train loss: 1.1815, accuracy: 95.0366%, tar: 0.0254 \n",
      "l0: 0.023987, l1: 0.025526, l2: 0.031941, l3: 0.044173, l4: 0.070348, l5: 0.131389, l6: 0.299637\n",
      "\n",
      "[epoch: 346/400, batch: 64/1000, ite: 46009] train loss: 1.1535, accuracy: 95.4443%, tar: 0.0253 \n",
      "l0: 0.020621, l1: 0.021557, l2: 0.027695, l3: 0.041343, l4: 0.075428, l5: 0.190173, l6: 0.368807\n",
      "\n",
      "[epoch: 346/400, batch: 72/1000, ite: 46010] train loss: 1.1503, accuracy: 95.1602%, tar: 0.0248 \n",
      "l0: 0.022258, l1: 0.023879, l2: 0.031453, l3: 0.050305, l4: 0.093564, l5: 0.163272, l6: 0.322556\n",
      "\n",
      "[epoch: 346/400, batch: 80/1000, ite: 46011] train loss: 1.1398, accuracy: 96.2074%, tar: 0.0246 \n",
      "l0: 0.022458, l1: 0.024431, l2: 0.034004, l3: 0.054171, l4: 0.110372, l5: 0.230283, l6: 0.430149\n",
      "\n",
      "[epoch: 346/400, batch: 88/1000, ite: 46012] train loss: 1.1564, accuracy: 94.3080%, tar: 0.0244 \n",
      "l0: 0.028614, l1: 0.029598, l2: 0.036776, l3: 0.054377, l4: 0.094243, l5: 0.195689, l6: 0.397731\n",
      "\n",
      "[epoch: 346/400, batch: 96/1000, ite: 46013] train loss: 1.1627, accuracy: 94.6518%, tar: 0.0247 \n",
      "l0: 0.037274, l1: 0.040192, l2: 0.054953, l3: 0.077514, l4: 0.124931, l5: 0.198274, l6: 0.335115\n",
      "\n",
      "[epoch: 346/400, batch: 104/1000, ite: 46014] train loss: 1.1657, accuracy: 94.7697%, tar: 0.0256 \n",
      "l0: 0.023909, l1: 0.025615, l2: 0.034397, l3: 0.048441, l4: 0.080406, l5: 0.183193, l6: 0.394811\n",
      "\n",
      "[epoch: 346/400, batch: 112/1000, ite: 46015] train loss: 1.1669, accuracy: 94.9377%, tar: 0.0255 \n",
      "l0: 0.027786, l1: 0.028625, l2: 0.037045, l3: 0.056144, l4: 0.099587, l5: 0.199481, l6: 0.540184\n",
      "\n",
      "[epoch: 346/400, batch: 120/1000, ite: 46016] train loss: 1.1895, accuracy: 92.6624%, tar: 0.0257 \n",
      "l0: 0.018646, l1: 0.020597, l2: 0.030796, l3: 0.049956, l4: 0.101417, l5: 0.188236, l6: 0.366596\n",
      "\n",
      "[epoch: 346/400, batch: 128/1000, ite: 46017] train loss: 1.1865, accuracy: 95.4567%, tar: 0.0252 \n",
      "l0: 0.021652, l1: 0.022969, l2: 0.029745, l3: 0.040275, l4: 0.072836, l5: 0.144512, l6: 0.309190\n",
      "\n",
      "[epoch: 346/400, batch: 136/1000, ite: 46018] train loss: 1.1736, accuracy: 95.0500%, tar: 0.0250 \n",
      "l0: 0.020640, l1: 0.021208, l2: 0.028588, l3: 0.043743, l4: 0.092083, l5: 0.199037, l6: 0.341726\n",
      "\n",
      "[epoch: 346/400, batch: 144/1000, ite: 46019] train loss: 1.1691, accuracy: 95.2177%, tar: 0.0248 \n",
      "l0: 0.027994, l1: 0.029195, l2: 0.037528, l3: 0.054515, l4: 0.100308, l5: 0.207045, l6: 0.374997\n",
      "\n",
      "[epoch: 346/400, batch: 152/1000, ite: 46020] train loss: 1.1709, accuracy: 93.7988%, tar: 0.0250 \n",
      "l0: 0.037489, l1: 0.039375, l2: 0.051304, l3: 0.074188, l4: 0.129782, l5: 0.263790, l6: 0.478145\n",
      "\n",
      "[epoch: 346/400, batch: 160/1000, ite: 46021] train loss: 1.1895, accuracy: 92.8399%, tar: 0.0256 \n",
      "l0: 0.023956, l1: 0.025324, l2: 0.032179, l3: 0.046784, l4: 0.099048, l5: 0.192190, l6: 0.329935\n",
      "\n",
      "[epoch: 346/400, batch: 168/1000, ite: 46022] train loss: 1.1846, accuracy: 94.9886%, tar: 0.0255 \n",
      "l0: 0.030236, l1: 0.031526, l2: 0.040495, l3: 0.057795, l4: 0.096211, l5: 0.202678, l6: 0.360242\n",
      "\n",
      "[epoch: 346/400, batch: 176/1000, ite: 46023] train loss: 1.1844, accuracy: 94.7063%, tar: 0.0257 \n",
      "l0: 0.029909, l1: 0.031842, l2: 0.041064, l3: 0.061158, l4: 0.118360, l5: 0.246991, l6: 0.428635\n",
      "\n",
      "[epoch: 346/400, batch: 184/1000, ite: 46024] train loss: 1.1930, accuracy: 94.0972%, tar: 0.0259 \n",
      "l0: 0.021964, l1: 0.023577, l2: 0.031046, l3: 0.051464, l4: 0.095804, l5: 0.179333, l6: 0.343068\n",
      "\n",
      "[epoch: 346/400, batch: 192/1000, ite: 46025] train loss: 1.1889, accuracy: 95.1516%, tar: 0.0257 \n",
      "l0: 0.023102, l1: 0.024855, l2: 0.030750, l3: 0.044330, l4: 0.076175, l5: 0.137849, l6: 0.271005\n",
      "\n",
      "[epoch: 346/400, batch: 200/1000, ite: 46026] train loss: 1.1770, accuracy: 95.9825%, tar: 0.0256 \n",
      "l0: 0.031173, l1: 0.033467, l2: 0.042689, l3: 0.061437, l4: 0.125726, l5: 0.234911, l6: 0.406736\n",
      "\n",
      "[epoch: 346/400, batch: 208/1000, ite: 46027] train loss: 1.1832, accuracy: 94.2691%, tar: 0.0258 \n",
      "l0: 0.029980, l1: 0.031231, l2: 0.040307, l3: 0.059353, l4: 0.107824, l5: 0.222702, l6: 0.466710\n",
      "\n",
      "[epoch: 346/400, batch: 216/1000, ite: 46028] train loss: 1.1922, accuracy: 93.1090%, tar: 0.0260 \n",
      "l0: 0.019132, l1: 0.021566, l2: 0.028815, l3: 0.042957, l4: 0.097546, l5: 0.202240, l6: 0.325550\n",
      "\n",
      "[epoch: 346/400, batch: 224/1000, ite: 46029] train loss: 1.1879, accuracy: 96.2961%, tar: 0.0257 \n",
      "l0: 0.019279, l1: 0.020113, l2: 0.026878, l3: 0.043929, l4: 0.088661, l5: 0.169554, l6: 0.298878\n",
      "\n",
      "[epoch: 346/400, batch: 232/1000, ite: 46030] train loss: 1.1808, accuracy: 95.5955%, tar: 0.0255 \n",
      "l0: 0.028119, l1: 0.031037, l2: 0.043313, l3: 0.070105, l4: 0.130891, l5: 0.233326, l6: 0.451679\n",
      "\n",
      "[epoch: 346/400, batch: 240/1000, ite: 46031] train loss: 1.1894, accuracy: 93.9896%, tar: 0.0256 \n",
      "l0: 0.023291, l1: 0.023882, l2: 0.031220, l3: 0.043771, l4: 0.067812, l5: 0.119782, l6: 0.219292\n",
      "\n",
      "[epoch: 346/400, batch: 248/1000, ite: 46032] train loss: 1.1760, accuracy: 96.6796%, tar: 0.0255 \n",
      "l0: 0.019412, l1: 0.019805, l2: 0.025128, l3: 0.036735, l4: 0.065543, l5: 0.125848, l6: 0.249157\n",
      "\n",
      "[epoch: 346/400, batch: 256/1000, ite: 46033] train loss: 1.1646, accuracy: 96.5690%, tar: 0.0253 \n",
      "l0: 0.023151, l1: 0.024116, l2: 0.031192, l3: 0.043314, l4: 0.088122, l5: 0.156539, l6: 0.300164\n",
      "\n",
      "[epoch: 346/400, batch: 264/1000, ite: 46034] train loss: 1.1588, accuracy: 95.4382%, tar: 0.0253 \n",
      "l0: 0.028515, l1: 0.029991, l2: 0.038250, l3: 0.053126, l4: 0.090326, l5: 0.160183, l6: 0.327688\n",
      "\n",
      "[epoch: 346/400, batch: 272/1000, ite: 46035] train loss: 1.1561, accuracy: 95.0563%, tar: 0.0254 \n",
      "l0: 0.029851, l1: 0.031101, l2: 0.039257, l3: 0.054931, l4: 0.099502, l5: 0.176421, l6: 0.389162\n",
      "\n",
      "[epoch: 346/400, batch: 280/1000, ite: 46036] train loss: 1.1577, accuracy: 94.4848%, tar: 0.0255 \n",
      "l0: 0.019048, l1: 0.020564, l2: 0.027569, l3: 0.039725, l4: 0.072962, l5: 0.181616, l6: 0.391136\n",
      "\n",
      "[epoch: 346/400, batch: 288/1000, ite: 46037] train loss: 1.1575, accuracy: 95.6348%, tar: 0.0253 \n",
      "l0: 0.016619, l1: 0.017607, l2: 0.024548, l3: 0.037448, l4: 0.068723, l5: 0.155841, l6: 0.337179\n",
      "\n",
      "[epoch: 346/400, batch: 296/1000, ite: 46038] train loss: 1.1534, accuracy: 95.9163%, tar: 0.0251 \n",
      "l0: 0.025646, l1: 0.027455, l2: 0.037171, l3: 0.054999, l4: 0.094274, l5: 0.186821, l6: 0.379756\n",
      "\n",
      "[epoch: 346/400, batch: 304/1000, ite: 46039] train loss: 1.1546, accuracy: 94.9617%, tar: 0.0251 \n",
      "l0: 0.030895, l1: 0.032129, l2: 0.042107, l3: 0.062599, l4: 0.114285, l5: 0.216797, l6: 0.405602\n",
      "\n",
      "[epoch: 346/400, batch: 312/1000, ite: 46040] train loss: 1.1586, accuracy: 94.3206%, tar: 0.0253 \n",
      "l0: 0.022061, l1: 0.022999, l2: 0.028909, l3: 0.039932, l4: 0.069471, l5: 0.126220, l6: 0.316052\n",
      "\n",
      "[epoch: 346/400, batch: 320/1000, ite: 46041] train loss: 1.1535, accuracy: 94.9069%, tar: 0.0252 \n",
      "l0: 0.028589, l1: 0.030320, l2: 0.036145, l3: 0.058609, l4: 0.114237, l5: 0.194803, l6: 0.391633\n",
      "\n",
      "[epoch: 346/400, batch: 328/1000, ite: 46042] train loss: 1.1558, accuracy: 94.0724%, tar: 0.0253 \n",
      "l0: 0.019357, l1: 0.020091, l2: 0.026532, l3: 0.037060, l4: 0.060039, l5: 0.117380, l6: 0.278210\n",
      "\n",
      "[epoch: 346/400, batch: 336/1000, ite: 46043] train loss: 1.1486, accuracy: 95.7335%, tar: 0.0251 \n",
      "l0: 0.033351, l1: 0.034937, l2: 0.042933, l3: 0.061448, l4: 0.112406, l5: 0.248214, l6: 0.482196\n",
      "\n",
      "[epoch: 346/400, batch: 344/1000, ite: 46044] train loss: 1.1567, accuracy: 93.2890%, tar: 0.0253 \n",
      "l0: 0.026024, l1: 0.027678, l2: 0.035850, l3: 0.055910, l4: 0.106142, l5: 0.198378, l6: 0.385833\n",
      "\n",
      "[epoch: 346/400, batch: 352/1000, ite: 46045] train loss: 1.1583, accuracy: 94.9587%, tar: 0.0253 \n",
      "l0: 0.037154, l1: 0.038780, l2: 0.049654, l3: 0.072893, l4: 0.138515, l5: 0.285281, l6: 0.544168\n",
      "\n",
      "[epoch: 346/400, batch: 360/1000, ite: 46046] train loss: 1.1703, accuracy: 92.3898%, tar: 0.0256 \n",
      "l0: 0.030624, l1: 0.032823, l2: 0.043714, l3: 0.067592, l4: 0.130903, l5: 0.234138, l6: 0.435039\n",
      "\n",
      "[epoch: 346/400, batch: 368/1000, ite: 46047] train loss: 1.1755, accuracy: 94.2326%, tar: 0.0257 \n",
      "l0: 0.023853, l1: 0.025343, l2: 0.032614, l3: 0.051672, l4: 0.108342, l5: 0.205737, l6: 0.404473\n",
      "\n",
      "[epoch: 346/400, batch: 376/1000, ite: 46048] train loss: 1.1774, accuracy: 94.6658%, tar: 0.0257 \n",
      "l0: 0.024538, l1: 0.025551, l2: 0.032128, l3: 0.046680, l4: 0.084516, l5: 0.141210, l6: 0.318192\n",
      "\n",
      "[epoch: 346/400, batch: 384/1000, ite: 46049] train loss: 1.1738, accuracy: 95.3629%, tar: 0.0256 \n",
      "l0: 0.026258, l1: 0.027344, l2: 0.034387, l3: 0.049990, l4: 0.085112, l5: 0.155002, l6: 0.320674\n",
      "\n",
      "[epoch: 346/400, batch: 392/1000, ite: 46050] train loss: 1.1708, accuracy: 94.4486%, tar: 0.0256 \n",
      "l0: 0.028367, l1: 0.030178, l2: 0.041357, l3: 0.059725, l4: 0.097802, l5: 0.185931, l6: 0.384541\n",
      "\n",
      "[epoch: 346/400, batch: 400/1000, ite: 46051] train loss: 1.1718, accuracy: 94.4506%, tar: 0.0257 \n",
      "l0: 0.030826, l1: 0.031753, l2: 0.037911, l3: 0.056070, l4: 0.113172, l5: 0.228719, l6: 0.487402\n",
      "\n",
      "[epoch: 346/400, batch: 408/1000, ite: 46052] train loss: 1.1777, accuracy: 92.8815%, tar: 0.0258 \n",
      "l0: 0.019091, l1: 0.019893, l2: 0.025587, l3: 0.034522, l4: 0.060176, l5: 0.113590, l6: 0.293344\n",
      "\n",
      "[epoch: 346/400, batch: 416/1000, ite: 46053] train loss: 1.1719, accuracy: 96.3138%, tar: 0.0257 \n",
      "l0: 0.024003, l1: 0.025107, l2: 0.032301, l3: 0.052061, l4: 0.096195, l5: 0.186059, l6: 0.415537\n",
      "\n",
      "[epoch: 346/400, batch: 424/1000, ite: 46054] train loss: 1.1733, accuracy: 93.9966%, tar: 0.0256 \n",
      "l0: 0.027242, l1: 0.028459, l2: 0.037086, l3: 0.054626, l4: 0.097044, l5: 0.179586, l6: 0.327389\n",
      "\n",
      "[epoch: 346/400, batch: 432/1000, ite: 46055] train loss: 1.1717, accuracy: 94.5781%, tar: 0.0257 \n",
      "l0: 0.025087, l1: 0.026171, l2: 0.034429, l3: 0.052182, l4: 0.099293, l5: 0.222144, l6: 0.438581\n",
      "\n",
      "[epoch: 346/400, batch: 440/1000, ite: 46056] train loss: 1.1749, accuracy: 94.1814%, tar: 0.0257 \n",
      "l0: 0.031753, l1: 0.032918, l2: 0.042059, l3: 0.063379, l4: 0.111465, l5: 0.193492, l6: 0.438999\n",
      "\n",
      "[epoch: 346/400, batch: 448/1000, ite: 46057] train loss: 1.1782, accuracy: 93.5124%, tar: 0.0258 \n",
      "l0: 0.027818, l1: 0.029061, l2: 0.038257, l3: 0.055019, l4: 0.104118, l5: 0.231431, l6: 0.461275\n",
      "\n",
      "[epoch: 346/400, batch: 456/1000, ite: 46058] train loss: 1.1822, accuracy: 94.2383%, tar: 0.0258 \n",
      "l0: 0.025902, l1: 0.027039, l2: 0.034687, l3: 0.050799, l4: 0.091288, l5: 0.185629, l6: 0.402218\n",
      "\n",
      "[epoch: 346/400, batch: 464/1000, ite: 46059] train loss: 1.1830, accuracy: 94.1740%, tar: 0.0258 \n",
      "l0: 0.026708, l1: 0.028138, l2: 0.036194, l3: 0.052760, l4: 0.101457, l5: 0.217138, l6: 0.418532\n",
      "\n",
      "[epoch: 346/400, batch: 472/1000, ite: 46060] train loss: 1.1850, accuracy: 94.2134%, tar: 0.0258 \n",
      "l0: 0.025628, l1: 0.027104, l2: 0.036602, l3: 0.055419, l4: 0.104014, l5: 0.211215, l6: 0.369274\n",
      "\n",
      "[epoch: 346/400, batch: 480/1000, ite: 46061] train loss: 1.1854, accuracy: 94.9129%, tar: 0.0258 \n",
      "l0: 0.024465, l1: 0.025461, l2: 0.032880, l3: 0.047883, l4: 0.092372, l5: 0.178588, l6: 0.310550\n",
      "\n",
      "[epoch: 346/400, batch: 488/1000, ite: 46062] train loss: 1.1829, accuracy: 95.4163%, tar: 0.0258 \n",
      "l0: 0.020806, l1: 0.021530, l2: 0.027682, l3: 0.037083, l4: 0.064355, l5: 0.117363, l6: 0.262445\n",
      "\n",
      "[epoch: 346/400, batch: 496/1000, ite: 46063] train loss: 1.1772, accuracy: 95.6856%, tar: 0.0257 \n",
      "l0: 0.027022, l1: 0.027834, l2: 0.035447, l3: 0.050138, l4: 0.078700, l5: 0.156739, l6: 0.322774\n",
      "\n",
      "[epoch: 346/400, batch: 504/1000, ite: 46064] train loss: 1.1749, accuracy: 94.9421%, tar: 0.0257 \n",
      "l0: 0.028589, l1: 0.030369, l2: 0.041974, l3: 0.067568, l4: 0.132276, l5: 0.239360, l6: 0.481928\n",
      "\n",
      "[epoch: 346/400, batch: 512/1000, ite: 46065] train loss: 1.1798, accuracy: 93.9306%, tar: 0.0258 \n",
      "l0: 0.023322, l1: 0.024668, l2: 0.030830, l3: 0.046121, l4: 0.091655, l5: 0.174946, l6: 0.327390\n",
      "\n",
      "[epoch: 346/400, batch: 520/1000, ite: 46066] train loss: 1.1779, accuracy: 94.6334%, tar: 0.0257 \n",
      "l0: 0.026266, l1: 0.027646, l2: 0.034446, l3: 0.048520, l4: 0.087289, l5: 0.152265, l6: 0.353259\n",
      "\n",
      "[epoch: 346/400, batch: 528/1000, ite: 46067] train loss: 1.1766, accuracy: 95.6252%, tar: 0.0257 \n",
      "l0: 0.027472, l1: 0.029185, l2: 0.037388, l3: 0.056095, l4: 0.106250, l5: 0.249854, l6: 0.470087\n",
      "\n",
      "[epoch: 346/400, batch: 536/1000, ite: 46068] train loss: 1.1805, accuracy: 93.8236%, tar: 0.0258 \n",
      "l0: 0.022817, l1: 0.024148, l2: 0.033046, l3: 0.052376, l4: 0.098177, l5: 0.229868, l6: 0.395194\n",
      "\n",
      "[epoch: 346/400, batch: 544/1000, ite: 46069] train loss: 1.1816, accuracy: 94.5004%, tar: 0.0257 \n",
      "l0: 0.028136, l1: 0.029891, l2: 0.039293, l3: 0.055967, l4: 0.095850, l5: 0.175322, l6: 0.321345\n",
      "\n",
      "[epoch: 346/400, batch: 552/1000, ite: 46070] train loss: 1.1801, accuracy: 94.8987%, tar: 0.0258 \n",
      "l0: 0.022884, l1: 0.023936, l2: 0.030994, l3: 0.045455, l4: 0.081849, l5: 0.164462, l6: 0.368036\n",
      "\n",
      "[epoch: 346/400, batch: 560/1000, ite: 46071] train loss: 1.1791, accuracy: 94.3908%, tar: 0.0257 \n",
      "l0: 0.028842, l1: 0.029961, l2: 0.038385, l3: 0.058736, l4: 0.113959, l5: 0.198978, l6: 0.337445\n",
      "\n",
      "[epoch: 346/400, batch: 568/1000, ite: 46072] train loss: 1.1787, accuracy: 94.1750%, tar: 0.0258 \n",
      "l0: 0.022911, l1: 0.023903, l2: 0.030346, l3: 0.041949, l4: 0.070017, l5: 0.149936, l6: 0.328642\n",
      "\n",
      "[epoch: 346/400, batch: 576/1000, ite: 46073] train loss: 1.1763, accuracy: 95.4659%, tar: 0.0257 \n",
      "l0: 0.028930, l1: 0.030240, l2: 0.039927, l3: 0.057991, l4: 0.098310, l5: 0.189087, l6: 0.403601\n",
      "\n",
      "[epoch: 346/400, batch: 584/1000, ite: 46074] train loss: 1.1774, accuracy: 93.8840%, tar: 0.0258 \n",
      "l0: 0.022000, l1: 0.022832, l2: 0.028703, l3: 0.043114, l4: 0.074395, l5: 0.147677, l6: 0.320807\n",
      "\n",
      "[epoch: 346/400, batch: 592/1000, ite: 46075] train loss: 1.1748, accuracy: 95.2959%, tar: 0.0257 \n",
      "l0: 0.021717, l1: 0.022655, l2: 0.030827, l3: 0.046753, l4: 0.082873, l5: 0.176444, l6: 0.439461\n",
      "\n",
      "[epoch: 346/400, batch: 600/1000, ite: 46076] train loss: 1.1760, accuracy: 94.4026%, tar: 0.0257 \n",
      "l0: 0.024875, l1: 0.026396, l2: 0.035519, l3: 0.052783, l4: 0.097128, l5: 0.195455, l6: 0.440518\n",
      "\n",
      "[epoch: 346/400, batch: 608/1000, ite: 46077] train loss: 1.1779, accuracy: 94.3422%, tar: 0.0257 \n",
      "l0: 0.029152, l1: 0.030752, l2: 0.039936, l3: 0.057518, l4: 0.102338, l5: 0.231575, l6: 0.467249\n",
      "\n",
      "[epoch: 346/400, batch: 616/1000, ite: 46078] train loss: 1.1811, accuracy: 94.1752%, tar: 0.0257 \n",
      "l0: 0.028283, l1: 0.029600, l2: 0.036468, l3: 0.051234, l4: 0.088326, l5: 0.203720, l6: 0.425238\n",
      "\n",
      "[epoch: 346/400, batch: 624/1000, ite: 46079] train loss: 1.1826, accuracy: 93.4719%, tar: 0.0257 \n",
      "l0: 0.027621, l1: 0.029431, l2: 0.036747, l3: 0.057211, l4: 0.113285, l5: 0.207572, l6: 0.372126\n",
      "\n",
      "[epoch: 346/400, batch: 632/1000, ite: 46080] train loss: 1.1831, accuracy: 94.3680%, tar: 0.0258 \n",
      "l0: 0.028703, l1: 0.029907, l2: 0.035688, l3: 0.047983, l4: 0.077247, l5: 0.174365, l6: 0.351724\n",
      "\n",
      "[epoch: 346/400, batch: 640/1000, ite: 46081] train loss: 1.1821, accuracy: 95.0877%, tar: 0.0258 \n",
      "l0: 0.021532, l1: 0.022181, l2: 0.027578, l3: 0.039722, l4: 0.067257, l5: 0.140561, l6: 0.322806\n",
      "\n",
      "[epoch: 346/400, batch: 648/1000, ite: 46082] train loss: 1.1795, accuracy: 95.6123%, tar: 0.0257 \n",
      "l0: 0.022877, l1: 0.024496, l2: 0.032316, l3: 0.048087, l4: 0.091972, l5: 0.183397, l6: 0.428064\n",
      "\n",
      "[epoch: 346/400, batch: 656/1000, ite: 46083] train loss: 1.1805, accuracy: 94.7808%, tar: 0.0257 \n",
      "l0: 0.023235, l1: 0.024964, l2: 0.034550, l3: 0.051961, l4: 0.095100, l5: 0.167537, l6: 0.279172\n",
      "\n",
      "[epoch: 346/400, batch: 664/1000, ite: 46084] train loss: 1.1779, accuracy: 95.7347%, tar: 0.0257 \n",
      "l0: 0.019344, l1: 0.020736, l2: 0.027896, l3: 0.041806, l4: 0.082422, l5: 0.165744, l6: 0.344915\n",
      "\n",
      "[epoch: 346/400, batch: 672/1000, ite: 46085] train loss: 1.1765, accuracy: 95.8721%, tar: 0.0256 \n",
      "l0: 0.026078, l1: 0.026368, l2: 0.032343, l3: 0.045903, l4: 0.078863, l5: 0.136007, l6: 0.260632\n",
      "\n",
      "[epoch: 346/400, batch: 680/1000, ite: 46086] train loss: 1.1729, accuracy: 95.1428%, tar: 0.0256 \n",
      "l0: 0.024773, l1: 0.025397, l2: 0.033743, l3: 0.047702, l4: 0.083292, l5: 0.160833, l6: 0.353702\n",
      "\n",
      "[epoch: 346/400, batch: 688/1000, ite: 46087] train loss: 1.1720, accuracy: 95.3183%, tar: 0.0256 \n",
      "l0: 0.024838, l1: 0.025719, l2: 0.032046, l3: 0.048764, l4: 0.087356, l5: 0.162907, l6: 0.328565\n",
      "\n",
      "[epoch: 346/400, batch: 696/1000, ite: 46088] train loss: 1.1706, accuracy: 94.7435%, tar: 0.0256 \n",
      "l0: 0.023310, l1: 0.024725, l2: 0.032299, l3: 0.048839, l4: 0.083167, l5: 0.167216, l6: 0.374200\n",
      "\n",
      "[epoch: 346/400, batch: 704/1000, ite: 46089] train loss: 1.1702, accuracy: 95.0239%, tar: 0.0256 \n",
      "l0: 0.023099, l1: 0.024191, l2: 0.031669, l3: 0.046356, l4: 0.082462, l5: 0.152978, l6: 0.338891\n",
      "\n",
      "[epoch: 346/400, batch: 712/1000, ite: 46090] train loss: 1.1689, accuracy: 95.5584%, tar: 0.0255 \n",
      "l0: 0.029622, l1: 0.031402, l2: 0.042813, l3: 0.071256, l4: 0.143141, l5: 0.310279, l6: 0.568917\n",
      "\n",
      "[epoch: 346/400, batch: 720/1000, ite: 46091] train loss: 1.1755, accuracy: 93.3970%, tar: 0.0256 \n",
      "l0: 0.029690, l1: 0.030884, l2: 0.039145, l3: 0.053254, l4: 0.095859, l5: 0.186164, l6: 0.373815\n",
      "\n",
      "[epoch: 346/400, batch: 728/1000, ite: 46092] train loss: 1.1756, accuracy: 94.1777%, tar: 0.0256 \n",
      "l0: 0.025541, l1: 0.027116, l2: 0.034685, l3: 0.049371, l4: 0.089632, l5: 0.214447, l6: 0.421015\n",
      "\n",
      "[epoch: 346/400, batch: 736/1000, ite: 46093] train loss: 1.1768, accuracy: 93.9909%, tar: 0.0256 \n",
      "l0: 0.024520, l1: 0.026390, l2: 0.034672, l3: 0.052596, l4: 0.096393, l5: 0.203813, l6: 0.398942\n",
      "\n",
      "[epoch: 346/400, batch: 744/1000, ite: 46094] train loss: 1.1774, accuracy: 94.8352%, tar: 0.0256 \n",
      "l0: 0.023209, l1: 0.024479, l2: 0.033427, l3: 0.051966, l4: 0.098668, l5: 0.177441, l6: 0.339248\n",
      "\n",
      "[epoch: 346/400, batch: 752/1000, ite: 46095] train loss: 1.1766, accuracy: 95.4010%, tar: 0.0256 \n",
      "l0: 0.021423, l1: 0.022135, l2: 0.029244, l3: 0.042127, l4: 0.071650, l5: 0.145301, l6: 0.313658\n",
      "\n",
      "[epoch: 346/400, batch: 760/1000, ite: 46096] train loss: 1.1744, accuracy: 95.4708%, tar: 0.0255 \n",
      "l0: 0.033104, l1: 0.034603, l2: 0.047489, l3: 0.068648, l4: 0.120666, l5: 0.237969, l6: 0.498293\n",
      "\n",
      "[epoch: 346/400, batch: 768/1000, ite: 46097] train loss: 1.1782, accuracy: 93.7103%, tar: 0.0256 \n",
      "l0: 0.028106, l1: 0.029232, l2: 0.037548, l3: 0.051724, l4: 0.089096, l5: 0.186610, l6: 0.413946\n",
      "\n",
      "[epoch: 346/400, batch: 776/1000, ite: 46098] train loss: 1.1789, accuracy: 94.2071%, tar: 0.0256 \n",
      "l0: 0.023170, l1: 0.024343, l2: 0.035295, l3: 0.057272, l4: 0.110776, l5: 0.217428, l6: 0.411525\n",
      "\n",
      "[epoch: 346/400, batch: 784/1000, ite: 46099] train loss: 1.1801, accuracy: 95.1568%, tar: 0.0256 \n",
      "l0: 0.017445, l1: 0.018473, l2: 0.024867, l3: 0.034838, l4: 0.056048, l5: 0.099783, l6: 0.216213\n",
      "\n",
      "[epoch: 346/400, batch: 792/1000, ite: 46100] train loss: 1.1752, accuracy: 97.0337%, tar: 0.0255 \n",
      "l0: 0.030126, l1: 0.031486, l2: 0.040405, l3: 0.057579, l4: 0.108831, l5: 0.251670, l6: 0.529023\n",
      "\n",
      "[epoch: 346/400, batch: 800/1000, ite: 46101] train loss: 1.1792, accuracy: 92.5922%, tar: 0.0256 \n",
      "l0: 0.029277, l1: 0.031416, l2: 0.041682, l3: 0.062816, l4: 0.116836, l5: 0.239172, l6: 0.533124\n",
      "\n",
      "[epoch: 346/400, batch: 808/1000, ite: 46102] train loss: 1.1833, accuracy: 93.8268%, tar: 0.0256 \n",
      "l0: 0.028203, l1: 0.029423, l2: 0.038153, l3: 0.055160, l4: 0.085667, l5: 0.176515, l6: 0.333130\n",
      "\n",
      "[epoch: 346/400, batch: 816/1000, ite: 46103] train loss: 1.1823, accuracy: 95.0630%, tar: 0.0256 \n",
      "l0: 0.032475, l1: 0.033240, l2: 0.041518, l3: 0.056780, l4: 0.095333, l5: 0.181983, l6: 0.354953\n",
      "\n",
      "[epoch: 346/400, batch: 824/1000, ite: 46104] train loss: 1.1820, accuracy: 94.0664%, tar: 0.0257 \n",
      "l0: 0.026988, l1: 0.028405, l2: 0.037027, l3: 0.053920, l4: 0.098134, l5: 0.198125, l6: 0.385520\n",
      "\n",
      "[epoch: 346/400, batch: 832/1000, ite: 46105] train loss: 1.1824, accuracy: 94.1767%, tar: 0.0257 \n",
      "l0: 0.024666, l1: 0.026780, l2: 0.034503, l3: 0.052459, l4: 0.094293, l5: 0.191081, l6: 0.349524\n",
      "\n",
      "[epoch: 346/400, batch: 840/1000, ite: 46106] train loss: 1.1820, accuracy: 95.2259%, tar: 0.0257 \n",
      "l0: 0.019511, l1: 0.020797, l2: 0.027840, l3: 0.041907, l4: 0.081027, l5: 0.141668, l6: 0.214680\n",
      "\n",
      "[epoch: 346/400, batch: 848/1000, ite: 46107] train loss: 1.1782, accuracy: 97.0925%, tar: 0.0257 \n",
      "l0: 0.032686, l1: 0.034757, l2: 0.044426, l3: 0.064108, l4: 0.121144, l5: 0.267511, l6: 0.541544\n",
      "\n",
      "[epoch: 346/400, batch: 856/1000, ite: 46108] train loss: 1.1825, accuracy: 92.7331%, tar: 0.0257 \n",
      "l0: 0.026148, l1: 0.027358, l2: 0.036836, l3: 0.052716, l4: 0.081569, l5: 0.153444, l6: 0.323491\n",
      "\n",
      "[epoch: 346/400, batch: 864/1000, ite: 46109] train loss: 1.1811, accuracy: 94.9948%, tar: 0.0257 \n",
      "l0: 0.027232, l1: 0.028636, l2: 0.035714, l3: 0.051150, l4: 0.091483, l5: 0.190015, l6: 0.363284\n",
      "\n",
      "[epoch: 346/400, batch: 872/1000, ite: 46110] train loss: 1.1809, accuracy: 94.7254%, tar: 0.0257 \n",
      "l0: 0.022146, l1: 0.023208, l2: 0.029926, l3: 0.043357, l4: 0.076893, l5: 0.144586, l6: 0.326639\n",
      "\n",
      "[epoch: 346/400, batch: 880/1000, ite: 46111] train loss: 1.1793, accuracy: 95.5939%, tar: 0.0257 \n",
      "l0: 0.017350, l1: 0.018491, l2: 0.022433, l3: 0.034855, l4: 0.089498, l5: 0.149246, l6: 0.311454\n",
      "\n",
      "[epoch: 346/400, batch: 888/1000, ite: 46112] train loss: 1.1774, accuracy: 96.0908%, tar: 0.0256 \n",
      "l0: 0.020534, l1: 0.021696, l2: 0.028566, l3: 0.046045, l4: 0.080361, l5: 0.163012, l6: 0.304221\n",
      "\n",
      "[epoch: 346/400, batch: 896/1000, ite: 46113] train loss: 1.1755, accuracy: 95.6181%, tar: 0.0256 \n",
      "l0: 0.030274, l1: 0.032234, l2: 0.041380, l3: 0.065010, l4: 0.117037, l5: 0.237733, l6: 0.494589\n",
      "\n",
      "[epoch: 346/400, batch: 904/1000, ite: 46114] train loss: 1.1785, accuracy: 93.8158%, tar: 0.0256 \n",
      "l0: 0.018632, l1: 0.019288, l2: 0.024949, l3: 0.035521, l4: 0.068575, l5: 0.149014, l6: 0.304174\n",
      "\n",
      "[epoch: 346/400, batch: 912/1000, ite: 46115] train loss: 1.1764, accuracy: 96.0387%, tar: 0.0256 \n",
      "l0: 0.027414, l1: 0.028104, l2: 0.034412, l3: 0.047361, l4: 0.080188, l5: 0.173662, l6: 0.353694\n",
      "\n",
      "[epoch: 346/400, batch: 920/1000, ite: 46116] train loss: 1.1757, accuracy: 93.9629%, tar: 0.0256 \n",
      "l0: 0.032780, l1: 0.034042, l2: 0.044090, l3: 0.064696, l4: 0.124269, l5: 0.263657, l6: 0.576546\n",
      "\n",
      "[epoch: 346/400, batch: 928/1000, ite: 46117] train loss: 1.1804, accuracy: 92.2208%, tar: 0.0256 \n",
      "l0: 0.040821, l1: 0.042929, l2: 0.056005, l3: 0.084950, l4: 0.158365, l5: 0.307088, l6: 0.633698\n",
      "\n",
      "[epoch: 346/400, batch: 936/1000, ite: 46118] train loss: 1.1871, accuracy: 91.3483%, tar: 0.0258 \n",
      "l0: 0.024540, l1: 0.026084, l2: 0.035075, l3: 0.054374, l4: 0.101355, l5: 0.216572, l6: 0.443191\n",
      "\n",
      "[epoch: 346/400, batch: 944/1000, ite: 46119] train loss: 1.1885, accuracy: 94.5295%, tar: 0.0258 \n",
      "l0: 0.018488, l1: 0.019749, l2: 0.027207, l3: 0.040702, l4: 0.077385, l5: 0.153125, l6: 0.345395\n",
      "\n",
      "[epoch: 346/400, batch: 952/1000, ite: 46120] train loss: 1.1871, accuracy: 95.7708%, tar: 0.0257 \n",
      "l0: 0.026642, l1: 0.028441, l2: 0.036535, l3: 0.058371, l4: 0.107577, l5: 0.201412, l6: 0.373361\n",
      "\n",
      "[epoch: 346/400, batch: 960/1000, ite: 46121] train loss: 1.1873, accuracy: 95.1188%, tar: 0.0257 \n",
      "l0: 0.025087, l1: 0.025728, l2: 0.032314, l3: 0.044638, l4: 0.073602, l5: 0.128234, l6: 0.278209\n",
      "\n",
      "[epoch: 346/400, batch: 968/1000, ite: 46122] train loss: 1.1848, accuracy: 95.6871%, tar: 0.0257 \n",
      "l0: 0.025547, l1: 0.027022, l2: 0.033025, l3: 0.047546, l4: 0.088419, l5: 0.176407, l6: 0.361636\n",
      "\n",
      "[epoch: 346/400, batch: 976/1000, ite: 46123] train loss: 1.1844, accuracy: 94.8726%, tar: 0.0257 \n",
      "l0: 0.019919, l1: 0.020663, l2: 0.028027, l3: 0.040701, l4: 0.071026, l5: 0.138883, l6: 0.312094\n",
      "\n",
      "[epoch: 346/400, batch: 984/1000, ite: 46124] train loss: 1.1825, accuracy: 95.5612%, tar: 0.0257 \n",
      "l0: 0.030779, l1: 0.032378, l2: 0.041273, l3: 0.063791, l4: 0.095066, l5: 0.175897, l6: 0.407124\n",
      "\n",
      "[epoch: 346/400, batch: 992/1000, ite: 46125] train loss: 1.1830, accuracy: 94.7931%, tar: 0.0257 \n",
      "l0: 0.022569, l1: 0.023521, l2: 0.030884, l3: 0.046448, l4: 0.081639, l5: 0.145830, l6: 0.264606\n",
      "\n",
      "[epoch: 346/400, batch: 1000/1000, ite: 46126] train loss: 1.1806, accuracy: 95.8363%, tar: 0.0257 \n",
      "l0: 0.026083, l1: 0.027225, l2: 0.035956, l3: 0.052226, l4: 0.092247, l5: 0.189368, l6: 0.381940\n",
      "\n",
      "[epoch: 347/400, batch: 8/1000, ite: 46127] train loss: 1.1808, accuracy: 94.3332%, tar: 0.0257 \n",
      "l0: 0.022585, l1: 0.022901, l2: 0.029856, l3: 0.043096, l4: 0.071535, l5: 0.146167, l6: 0.324732\n",
      "\n",
      "[epoch: 347/400, batch: 16/1000, ite: 46128] train loss: 1.1792, accuracy: 94.8245%, tar: 0.0257 \n",
      "l0: 0.021793, l1: 0.023415, l2: 0.033898, l3: 0.049218, l4: 0.089788, l5: 0.164218, l6: 0.352690\n",
      "\n",
      "[epoch: 347/400, batch: 24/1000, ite: 46129] train loss: 1.1786, accuracy: 95.7133%, tar: 0.0256 \n",
      "l0: 0.023350, l1: 0.025421, l2: 0.035532, l3: 0.058072, l4: 0.104939, l5: 0.211796, l6: 0.502021\n",
      "\n",
      "[epoch: 347/400, batch: 32/1000, ite: 46130] train loss: 1.1809, accuracy: 94.3652%, tar: 0.0256 \n",
      "l0: 0.021130, l1: 0.022446, l2: 0.030139, l3: 0.043537, l4: 0.083802, l5: 0.158687, l6: 0.297783\n",
      "\n",
      "[epoch: 347/400, batch: 40/1000, ite: 46131] train loss: 1.1791, accuracy: 95.7030%, tar: 0.0256 \n",
      "l0: 0.029398, l1: 0.030781, l2: 0.039231, l3: 0.056649, l4: 0.111227, l5: 0.239525, l6: 0.526785\n",
      "\n",
      "[epoch: 347/400, batch: 48/1000, ite: 46132] train loss: 1.1821, accuracy: 92.7808%, tar: 0.0256 \n",
      "l0: 0.023734, l1: 0.025239, l2: 0.034036, l3: 0.051076, l4: 0.104702, l5: 0.185913, l6: 0.383265\n",
      "\n",
      "[epoch: 347/400, batch: 56/1000, ite: 46133] train loss: 1.1822, accuracy: 95.2085%, tar: 0.0256 \n",
      "l0: 0.020855, l1: 0.021820, l2: 0.029240, l3: 0.044023, l4: 0.083653, l5: 0.153076, l6: 0.308601\n",
      "\n",
      "[epoch: 347/400, batch: 64/1000, ite: 46134] train loss: 1.1807, accuracy: 95.5108%, tar: 0.0256 \n",
      "l0: 0.028554, l1: 0.030354, l2: 0.040543, l3: 0.060196, l4: 0.103700, l5: 0.205870, l6: 0.410824\n",
      "\n",
      "[epoch: 347/400, batch: 72/1000, ite: 46135] train loss: 1.1816, accuracy: 94.5006%, tar: 0.0256 \n",
      "l0: 0.020625, l1: 0.021987, l2: 0.027742, l3: 0.039572, l4: 0.072984, l5: 0.139099, l6: 0.257068\n",
      "\n",
      "[epoch: 347/400, batch: 80/1000, ite: 46136] train loss: 1.1791, accuracy: 96.1258%, tar: 0.0255 \n",
      "l0: 0.023183, l1: 0.024343, l2: 0.031881, l3: 0.045669, l4: 0.082587, l5: 0.184209, l6: 0.325120\n",
      "\n",
      "[epoch: 347/400, batch: 88/1000, ite: 46137] train loss: 1.1782, accuracy: 94.5042%, tar: 0.0255 \n",
      "l0: 0.029278, l1: 0.030748, l2: 0.040582, l3: 0.059562, l4: 0.098858, l5: 0.179669, l6: 0.406172\n",
      "\n",
      "[epoch: 347/400, batch: 96/1000, ite: 46138] train loss: 1.1787, accuracy: 93.9194%, tar: 0.0255 \n",
      "l0: 0.028006, l1: 0.030009, l2: 0.041339, l3: 0.059837, l4: 0.105531, l5: 0.167476, l6: 0.344149\n",
      "\n",
      "[epoch: 347/400, batch: 104/1000, ite: 46139] train loss: 1.1783, accuracy: 94.9385%, tar: 0.0256 \n",
      "l0: 0.018975, l1: 0.020246, l2: 0.026997, l3: 0.039263, l4: 0.067779, l5: 0.123852, l6: 0.261594\n",
      "\n",
      "[epoch: 347/400, batch: 112/1000, ite: 46140] train loss: 1.1758, accuracy: 96.2264%, tar: 0.0255 \n",
      "l0: 0.023720, l1: 0.024783, l2: 0.030785, l3: 0.044703, l4: 0.078771, l5: 0.154500, l6: 0.297541\n",
      "\n",
      "[epoch: 347/400, batch: 120/1000, ite: 46141] train loss: 1.1743, accuracy: 95.7466%, tar: 0.0255 \n",
      "l0: 0.026855, l1: 0.027965, l2: 0.036056, l3: 0.051948, l4: 0.094371, l5: 0.182972, l6: 0.341636\n",
      "\n",
      "[epoch: 347/400, batch: 128/1000, ite: 46142] train loss: 1.1738, accuracy: 94.9654%, tar: 0.0255 \n",
      "l0: 0.016881, l1: 0.017520, l2: 0.022575, l3: 0.030729, l4: 0.047430, l5: 0.083164, l6: 0.184468\n",
      "\n",
      "[epoch: 347/400, batch: 136/1000, ite: 46143] train loss: 1.1698, accuracy: 96.7652%, tar: 0.0255 \n",
      "l0: 0.035048, l1: 0.036309, l2: 0.047200, l3: 0.066801, l4: 0.118465, l5: 0.249487, l6: 0.480581\n",
      "\n",
      "[epoch: 347/400, batch: 144/1000, ite: 46144] train loss: 1.1722, accuracy: 92.8404%, tar: 0.0255 \n",
      "l0: 0.021399, l1: 0.022510, l2: 0.028368, l3: 0.044364, l4: 0.089659, l5: 0.189863, l6: 0.333701\n",
      "\n",
      "[epoch: 347/400, batch: 152/1000, ite: 46145] train loss: 1.1715, accuracy: 95.0888%, tar: 0.0255 \n",
      "l0: 0.027545, l1: 0.028229, l2: 0.034950, l3: 0.049657, l4: 0.079656, l5: 0.129753, l6: 0.272848\n",
      "\n",
      "[epoch: 347/400, batch: 160/1000, ite: 46146] train loss: 1.1696, accuracy: 95.5123%, tar: 0.0255 \n",
      "l0: 0.024631, l1: 0.025557, l2: 0.032774, l3: 0.048082, l4: 0.084582, l5: 0.151441, l6: 0.332469\n",
      "\n",
      "[epoch: 347/400, batch: 168/1000, ite: 46147] train loss: 1.1687, accuracy: 94.7087%, tar: 0.0255 \n",
      "l0: 0.021226, l1: 0.022416, l2: 0.029043, l3: 0.044070, l4: 0.094372, l5: 0.170926, l6: 0.312658\n",
      "\n",
      "[epoch: 347/400, batch: 176/1000, ite: 46148] train loss: 1.1677, accuracy: 95.5953%, tar: 0.0255 \n",
      "l0: 0.026395, l1: 0.027474, l2: 0.034584, l3: 0.054534, l4: 0.116854, l5: 0.223072, l6: 0.418208\n",
      "\n",
      "[epoch: 347/400, batch: 184/1000, ite: 46149] train loss: 1.1687, accuracy: 93.9237%, tar: 0.0255 \n",
      "l0: 0.024106, l1: 0.026084, l2: 0.036497, l3: 0.058043, l4: 0.113889, l5: 0.223576, l6: 0.446405\n",
      "\n",
      "[epoch: 347/400, batch: 192/1000, ite: 46150] train loss: 1.1702, accuracy: 94.4434%, tar: 0.0255 \n",
      "l0: 0.025575, l1: 0.026777, l2: 0.036402, l3: 0.051859, l4: 0.099091, l5: 0.193266, l6: 0.395350\n",
      "\n",
      "[epoch: 347/400, batch: 200/1000, ite: 46151] train loss: 1.1706, accuracy: 94.7500%, tar: 0.0255 \n",
      "l0: 0.030711, l1: 0.033392, l2: 0.045026, l3: 0.070977, l4: 0.141078, l5: 0.270174, l6: 0.459309\n",
      "\n",
      "[epoch: 347/400, batch: 208/1000, ite: 46152] train loss: 1.1729, accuracy: 93.8688%, tar: 0.0255 \n",
      "l0: 0.024726, l1: 0.027147, l2: 0.035118, l3: 0.055237, l4: 0.113846, l5: 0.214895, l6: 0.426916\n",
      "\n",
      "[epoch: 347/400, batch: 216/1000, ite: 46153] train loss: 1.1739, accuracy: 94.5298%, tar: 0.0255 \n",
      "l0: 0.028065, l1: 0.029751, l2: 0.037574, l3: 0.053886, l4: 0.089156, l5: 0.171500, l6: 0.390664\n",
      "\n",
      "[epoch: 347/400, batch: 224/1000, ite: 46154] train loss: 1.1740, accuracy: 93.7784%, tar: 0.0255 \n",
      "l0: 0.026602, l1: 0.027838, l2: 0.036318, l3: 0.052812, l4: 0.103704, l5: 0.242014, l6: 0.496257\n",
      "\n",
      "[epoch: 347/400, batch: 232/1000, ite: 46155] train loss: 1.1760, accuracy: 93.4724%, tar: 0.0255 \n",
      "l0: 0.025147, l1: 0.026151, l2: 0.034542, l3: 0.046050, l4: 0.074340, l5: 0.140506, l6: 0.272407\n",
      "\n",
      "[epoch: 347/400, batch: 240/1000, ite: 46156] train loss: 1.1742, accuracy: 95.6752%, tar: 0.0255 \n",
      "l0: 0.026032, l1: 0.027184, l2: 0.032963, l3: 0.047120, l4: 0.081216, l5: 0.162524, l6: 0.326828\n",
      "\n",
      "[epoch: 347/400, batch: 248/1000, ite: 46157] train loss: 1.1733, accuracy: 95.2224%, tar: 0.0255 \n",
      "l0: 0.022083, l1: 0.024001, l2: 0.033317, l3: 0.049901, l4: 0.088269, l5: 0.167928, l6: 0.309087\n",
      "\n",
      "[epoch: 347/400, batch: 256/1000, ite: 46158] train loss: 1.1723, accuracy: 96.6640%, tar: 0.0255 \n",
      "l0: 0.015519, l1: 0.016756, l2: 0.024800, l3: 0.038480, l4: 0.069614, l5: 0.136585, l6: 0.297846\n",
      "\n",
      "[epoch: 347/400, batch: 264/1000, ite: 46159] train loss: 1.1706, accuracy: 96.2708%, tar: 0.0254 \n",
      "l0: 0.026878, l1: 0.027768, l2: 0.033579, l3: 0.048051, l4: 0.078546, l5: 0.146086, l6: 0.325910\n",
      "\n",
      "[epoch: 347/400, batch: 272/1000, ite: 46160] train loss: 1.1697, accuracy: 94.9443%, tar: 0.0254 \n",
      "l0: 0.021886, l1: 0.023323, l2: 0.031144, l3: 0.049677, l4: 0.104470, l5: 0.197886, l6: 0.439587\n",
      "\n",
      "[epoch: 347/400, batch: 280/1000, ite: 46161] train loss: 1.1706, accuracy: 93.7704%, tar: 0.0254 \n",
      "l0: 0.027208, l1: 0.029060, l2: 0.039042, l3: 0.060099, l4: 0.124455, l5: 0.247258, l6: 0.483415\n",
      "\n",
      "[epoch: 347/400, batch: 288/1000, ite: 46162] train loss: 1.1726, accuracy: 93.3362%, tar: 0.0254 \n",
      "l0: 0.024866, l1: 0.026027, l2: 0.035391, l3: 0.053993, l4: 0.093035, l5: 0.197460, l6: 0.469411\n",
      "\n",
      "[epoch: 347/400, batch: 296/1000, ite: 46163] train loss: 1.1739, accuracy: 93.7393%, tar: 0.0254 \n",
      "l0: 0.020374, l1: 0.021449, l2: 0.029512, l3: 0.045421, l4: 0.080035, l5: 0.154979, l6: 0.285033\n",
      "\n",
      "[epoch: 347/400, batch: 304/1000, ite: 46164] train loss: 1.1724, accuracy: 95.8409%, tar: 0.0254 \n",
      "l0: 0.025214, l1: 0.026749, l2: 0.035468, l3: 0.055865, l4: 0.102692, l5: 0.236126, l6: 0.492304\n",
      "\n",
      "[epoch: 347/400, batch: 312/1000, ite: 46165] train loss: 1.1742, accuracy: 93.9707%, tar: 0.0254 \n",
      "l0: 0.023797, l1: 0.025088, l2: 0.030966, l3: 0.044777, l4: 0.079469, l5: 0.186591, l6: 0.391205\n",
      "\n",
      "[epoch: 347/400, batch: 320/1000, ite: 46166] train loss: 1.1742, accuracy: 94.5262%, tar: 0.0254 \n",
      "l0: 0.027325, l1: 0.028643, l2: 0.038184, l3: 0.054159, l4: 0.100480, l5: 0.207316, l6: 0.414710\n",
      "\n",
      "[epoch: 347/400, batch: 328/1000, ite: 46167] train loss: 1.1749, accuracy: 93.9791%, tar: 0.0254 \n",
      "l0: 0.025746, l1: 0.027099, l2: 0.033619, l3: 0.045765, l4: 0.079728, l5: 0.145597, l6: 0.281846\n",
      "\n",
      "[epoch: 347/400, batch: 336/1000, ite: 46168] train loss: 1.1735, accuracy: 95.7961%, tar: 0.0254 \n",
      "l0: 0.024192, l1: 0.025121, l2: 0.032729, l3: 0.046906, l4: 0.085532, l5: 0.180775, l6: 0.398838\n",
      "\n",
      "[epoch: 347/400, batch: 344/1000, ite: 46169] train loss: 1.1736, accuracy: 94.0522%, tar: 0.0254 \n",
      "l0: 0.017378, l1: 0.018982, l2: 0.024789, l3: 0.038136, l4: 0.075171, l5: 0.141331, l6: 0.251198\n",
      "\n",
      "[epoch: 347/400, batch: 352/1000, ite: 46170] train loss: 1.1716, accuracy: 96.0066%, tar: 0.0254 \n",
      "l0: 0.022535, l1: 0.024408, l2: 0.035159, l3: 0.055979, l4: 0.114916, l5: 0.209646, l6: 0.346999\n",
      "\n",
      "[epoch: 347/400, batch: 360/1000, ite: 46171] train loss: 1.1715, accuracy: 95.5486%, tar: 0.0253 \n",
      "l0: 0.024280, l1: 0.025430, l2: 0.029540, l3: 0.038926, l4: 0.064004, l5: 0.141935, l6: 0.312649\n",
      "\n",
      "[epoch: 347/400, batch: 368/1000, ite: 46172] train loss: 1.1703, accuracy: 95.4715%, tar: 0.0253 \n",
      "l0: 0.025502, l1: 0.026701, l2: 0.035117, l3: 0.053982, l4: 0.101247, l5: 0.169462, l6: 0.387007\n",
      "\n",
      "[epoch: 347/400, batch: 376/1000, ite: 46173] train loss: 1.1704, accuracy: 94.1349%, tar: 0.0253 \n",
      "l0: 0.022330, l1: 0.023588, l2: 0.029835, l3: 0.044045, l4: 0.076719, l5: 0.144243, l6: 0.298562\n",
      "\n",
      "[epoch: 347/400, batch: 384/1000, ite: 46174] train loss: 1.1691, accuracy: 95.2071%, tar: 0.0253 \n",
      "l0: 0.026411, l1: 0.028321, l2: 0.034716, l3: 0.048916, l4: 0.091259, l5: 0.172799, l6: 0.363112\n",
      "\n",
      "[epoch: 347/400, batch: 392/1000, ite: 46175] train loss: 1.1689, accuracy: 94.5507%, tar: 0.0253 \n",
      "l0: 0.019715, l1: 0.021837, l2: 0.028630, l3: 0.043019, l4: 0.079598, l5: 0.164898, l6: 0.309952\n",
      "\n",
      "[epoch: 347/400, batch: 400/1000, ite: 46176] train loss: 1.1678, accuracy: 95.4401%, tar: 0.0253 \n",
      "l0: 0.022448, l1: 0.025483, l2: 0.037900, l3: 0.067190, l4: 0.125138, l5: 0.260288, l6: 0.461686\n",
      "\n",
      "[epoch: 347/400, batch: 408/1000, ite: 46177] train loss: 1.1695, accuracy: 95.5880%, tar: 0.0253 \n",
      "l0: 0.019584, l1: 0.021480, l2: 0.028474, l3: 0.043942, l4: 0.077515, l5: 0.137734, l6: 0.256540\n",
      "\n",
      "[epoch: 347/400, batch: 416/1000, ite: 46178] train loss: 1.1677, accuracy: 96.9009%, tar: 0.0252 \n",
      "l0: 0.027195, l1: 0.029298, l2: 0.038207, l3: 0.058643, l4: 0.097062, l5: 0.203990, l6: 0.393349\n",
      "\n",
      "[epoch: 347/400, batch: 424/1000, ite: 46179] train loss: 1.1681, accuracy: 94.9393%, tar: 0.0252 \n",
      "l0: 0.026089, l1: 0.028020, l2: 0.038665, l3: 0.056900, l4: 0.109612, l5: 0.223718, l6: 0.421920\n",
      "\n",
      "[epoch: 347/400, batch: 432/1000, ite: 46180] train loss: 1.1690, accuracy: 94.9679%, tar: 0.0253 \n",
      "l0: 0.021297, l1: 0.022074, l2: 0.027171, l3: 0.038948, l4: 0.070680, l5: 0.149493, l6: 0.336822\n",
      "\n",
      "[epoch: 347/400, batch: 440/1000, ite: 46181] train loss: 1.1681, accuracy: 95.7298%, tar: 0.0252 \n",
      "l0: 0.024155, l1: 0.025741, l2: 0.035800, l3: 0.062091, l4: 0.117514, l5: 0.200928, l6: 0.483157\n",
      "\n",
      "[epoch: 347/400, batch: 448/1000, ite: 46182] train loss: 1.1696, accuracy: 94.4588%, tar: 0.0252 \n",
      "l0: 0.021008, l1: 0.021898, l2: 0.027298, l3: 0.043521, l4: 0.084871, l5: 0.150759, l6: 0.299911\n",
      "\n",
      "[epoch: 347/400, batch: 456/1000, ite: 46183] train loss: 1.1684, accuracy: 95.7903%, tar: 0.0252 \n",
      "l0: 0.034780, l1: 0.036782, l2: 0.046773, l3: 0.074114, l4: 0.151850, l5: 0.301738, l6: 0.639944\n",
      "\n",
      "[epoch: 347/400, batch: 464/1000, ite: 46184] train loss: 1.1725, accuracy: 91.7192%, tar: 0.0253 \n",
      "l0: 0.023079, l1: 0.023850, l2: 0.030352, l3: 0.045095, l4: 0.072434, l5: 0.144691, l6: 0.336738\n",
      "\n",
      "[epoch: 347/400, batch: 472/1000, ite: 46185] train loss: 1.1717, accuracy: 95.2582%, tar: 0.0252 \n",
      "l0: 0.026186, l1: 0.027753, l2: 0.035950, l3: 0.051983, l4: 0.100105, l5: 0.215225, l6: 0.492739\n",
      "\n",
      "[epoch: 347/400, batch: 480/1000, ite: 46186] train loss: 1.1732, accuracy: 93.9275%, tar: 0.0252 \n",
      "l0: 0.023103, l1: 0.023969, l2: 0.030472, l3: 0.043261, l4: 0.071720, l5: 0.133523, l6: 0.348996\n",
      "\n",
      "[epoch: 347/400, batch: 488/1000, ite: 46187] train loss: 1.1724, accuracy: 94.9638%, tar: 0.0252 \n",
      "l0: 0.027781, l1: 0.028688, l2: 0.037873, l3: 0.051870, l4: 0.095432, l5: 0.206890, l6: 0.393294\n",
      "\n",
      "[epoch: 347/400, batch: 496/1000, ite: 46188] train loss: 1.1728, accuracy: 94.3576%, tar: 0.0253 \n",
      "l0: 0.028302, l1: 0.029301, l2: 0.037963, l3: 0.056891, l4: 0.106101, l5: 0.206956, l6: 0.452184\n",
      "\n",
      "[epoch: 347/400, batch: 504/1000, ite: 46189] train loss: 1.1739, accuracy: 93.9572%, tar: 0.0253 \n",
      "l0: 0.028736, l1: 0.029984, l2: 0.039310, l3: 0.057470, l4: 0.109647, l5: 0.230946, l6: 0.468965\n",
      "\n",
      "[epoch: 347/400, batch: 512/1000, ite: 46190] train loss: 1.1753, accuracy: 94.2493%, tar: 0.0253 \n",
      "l0: 0.027723, l1: 0.028651, l2: 0.035643, l3: 0.054112, l4: 0.100072, l5: 0.218389, l6: 0.454760\n",
      "\n",
      "[epoch: 347/400, batch: 520/1000, ite: 46191] train loss: 1.1763, accuracy: 94.1711%, tar: 0.0253 \n",
      "l0: 0.022171, l1: 0.023631, l2: 0.031553, l3: 0.048197, l4: 0.093090, l5: 0.176859, l6: 0.359619\n",
      "\n",
      "[epoch: 347/400, batch: 528/1000, ite: 46192] train loss: 1.1760, accuracy: 94.9498%, tar: 0.0253 \n",
      "l0: 0.034478, l1: 0.035741, l2: 0.046619, l3: 0.068637, l4: 0.123464, l5: 0.232354, l6: 0.409579\n",
      "\n",
      "[epoch: 347/400, batch: 536/1000, ite: 46193] train loss: 1.1769, accuracy: 94.2495%, tar: 0.0253 \n",
      "l0: 0.029250, l1: 0.030979, l2: 0.039647, l3: 0.062368, l4: 0.142513, l5: 0.252739, l6: 0.455396\n",
      "\n",
      "[epoch: 347/400, batch: 544/1000, ite: 46194] train loss: 1.1785, accuracy: 93.8159%, tar: 0.0253 \n",
      "l0: 0.029023, l1: 0.030479, l2: 0.040422, l3: 0.061994, l4: 0.121730, l5: 0.219313, l6: 0.461490\n",
      "\n",
      "[epoch: 347/400, batch: 552/1000, ite: 46195] train loss: 1.1798, accuracy: 93.9497%, tar: 0.0254 \n",
      "l0: 0.022781, l1: 0.024026, l2: 0.031883, l3: 0.045419, l4: 0.093277, l5: 0.190378, l6: 0.375203\n",
      "\n",
      "[epoch: 347/400, batch: 560/1000, ite: 46196] train loss: 1.1797, accuracy: 94.4042%, tar: 0.0254 \n",
      "l0: 0.020952, l1: 0.021817, l2: 0.027485, l3: 0.039473, l4: 0.073289, l5: 0.152913, l6: 0.336647\n",
      "\n",
      "[epoch: 347/400, batch: 568/1000, ite: 46197] train loss: 1.1789, accuracy: 94.7058%, tar: 0.0253 \n",
      "l0: 0.021309, l1: 0.022623, l2: 0.029707, l3: 0.045550, l4: 0.086982, l5: 0.164581, l6: 0.313255\n",
      "\n",
      "[epoch: 347/400, batch: 576/1000, ite: 46198] train loss: 1.1780, accuracy: 95.1959%, tar: 0.0253 \n",
      "l0: 0.025147, l1: 0.026414, l2: 0.034330, l3: 0.053886, l4: 0.102472, l5: 0.183877, l6: 0.350653\n",
      "\n",
      "[epoch: 347/400, batch: 584/1000, ite: 46199] train loss: 1.1778, accuracy: 95.0375%, tar: 0.0253 \n",
      "l0: 0.023719, l1: 0.024420, l2: 0.032534, l3: 0.048963, l4: 0.101101, l5: 0.172521, l6: 0.279618\n",
      "\n",
      "[epoch: 347/400, batch: 592/1000, ite: 46200] train loss: 1.1767, accuracy: 95.6742%, tar: 0.0253 \n",
      "l0: 0.023874, l1: 0.024852, l2: 0.030740, l3: 0.041074, l4: 0.070677, l5: 0.135108, l6: 0.262878\n",
      "\n",
      "[epoch: 347/400, batch: 600/1000, ite: 46201] train loss: 1.1752, accuracy: 95.6284%, tar: 0.0253 \n",
      "l0: 0.017666, l1: 0.018833, l2: 0.025044, l3: 0.038267, l4: 0.084089, l5: 0.148642, l6: 0.309620\n",
      "\n",
      "[epoch: 347/400, batch: 608/1000, ite: 46202] train loss: 1.1741, accuracy: 96.1739%, tar: 0.0253 \n",
      "l0: 0.025433, l1: 0.026531, l2: 0.036902, l3: 0.059204, l4: 0.133023, l5: 0.239951, l6: 0.439463\n",
      "\n",
      "[epoch: 347/400, batch: 616/1000, ite: 46203] train loss: 1.1752, accuracy: 94.8404%, tar: 0.0253 \n",
      "l0: 0.026570, l1: 0.028389, l2: 0.036579, l3: 0.059868, l4: 0.099419, l5: 0.204712, l6: 0.357556\n",
      "\n",
      "[epoch: 347/400, batch: 624/1000, ite: 46204] train loss: 1.1752, accuracy: 95.2548%, tar: 0.0253 \n",
      "l0: 0.018143, l1: 0.018920, l2: 0.026908, l3: 0.041992, l4: 0.076176, l5: 0.144201, l6: 0.314414\n",
      "\n",
      "[epoch: 347/400, batch: 632/1000, ite: 46205] train loss: 1.1742, accuracy: 95.8361%, tar: 0.0252 \n",
      "l0: 0.026292, l1: 0.026924, l2: 0.033486, l3: 0.047689, l4: 0.080786, l5: 0.154123, l6: 0.324814\n",
      "\n",
      "[epoch: 347/400, batch: 640/1000, ite: 46206] train loss: 1.1735, accuracy: 94.3947%, tar: 0.0252 \n",
      "l0: 0.027630, l1: 0.028913, l2: 0.038036, l3: 0.053891, l4: 0.094321, l5: 0.189555, l6: 0.406935\n",
      "\n",
      "[epoch: 347/400, batch: 648/1000, ite: 46207] train loss: 1.1739, accuracy: 94.4128%, tar: 0.0252 \n",
      "l0: 0.031398, l1: 0.033546, l2: 0.045421, l3: 0.070109, l4: 0.135217, l5: 0.243252, l6: 0.471654\n",
      "\n",
      "[epoch: 347/400, batch: 656/1000, ite: 46208] train loss: 1.1754, accuracy: 94.0867%, tar: 0.0253 \n",
      "l0: 0.025953, l1: 0.026891, l2: 0.033348, l3: 0.045938, l4: 0.079115, l5: 0.152457, l6: 0.335201\n",
      "\n",
      "[epoch: 347/400, batch: 664/1000, ite: 46209] train loss: 1.1748, accuracy: 94.3101%, tar: 0.0253 \n",
      "l0: 0.028458, l1: 0.032296, l2: 0.044353, l3: 0.072832, l4: 0.134210, l5: 0.226288, l6: 0.450757\n",
      "\n",
      "[epoch: 347/400, batch: 672/1000, ite: 46210] train loss: 1.1761, accuracy: 94.4513%, tar: 0.0253 \n",
      "l0: 0.025428, l1: 0.026602, l2: 0.034928, l3: 0.056258, l4: 0.104514, l5: 0.219100, l6: 0.509657\n",
      "\n",
      "[epoch: 347/400, batch: 680/1000, ite: 46211] train loss: 1.1776, accuracy: 92.9919%, tar: 0.0253 \n",
      "l0: 0.033839, l1: 0.036382, l2: 0.047959, l3: 0.076473, l4: 0.148290, l5: 0.333190, l6: 0.662646\n",
      "\n",
      "[epoch: 347/400, batch: 688/1000, ite: 46212] train loss: 1.1815, accuracy: 92.9601%, tar: 0.0253 \n",
      "l0: 0.029752, l1: 0.031878, l2: 0.043267, l3: 0.067344, l4: 0.123186, l5: 0.262956, l6: 0.494042\n",
      "\n",
      "[epoch: 347/400, batch: 696/1000, ite: 46213] train loss: 1.1832, accuracy: 92.5976%, tar: 0.0254 \n",
      "l0: 0.037895, l1: 0.039585, l2: 0.051409, l3: 0.075991, l4: 0.141369, l5: 0.284557, l6: 0.516577\n",
      "\n",
      "[epoch: 347/400, batch: 704/1000, ite: 46214] train loss: 1.1855, accuracy: 92.5855%, tar: 0.0254 \n",
      "l0: 0.018978, l1: 0.019559, l2: 0.024542, l3: 0.034918, l4: 0.063422, l5: 0.130114, l6: 0.266976\n",
      "\n",
      "[epoch: 347/400, batch: 712/1000, ite: 46215] train loss: 1.1838, accuracy: 95.8091%, tar: 0.0254 \n",
      "l0: 0.029773, l1: 0.031148, l2: 0.039270, l3: 0.057827, l4: 0.105314, l5: 0.251385, l6: 0.499771\n",
      "\n",
      "[epoch: 347/400, batch: 720/1000, ite: 46216] train loss: 1.1853, accuracy: 93.4497%, tar: 0.0254 \n",
      "l0: 0.026810, l1: 0.027869, l2: 0.035609, l3: 0.052512, l4: 0.096472, l5: 0.193090, l6: 0.423063\n",
      "\n",
      "[epoch: 347/400, batch: 728/1000, ite: 46217] train loss: 1.1858, accuracy: 94.0010%, tar: 0.0254 \n",
      "l0: 0.037950, l1: 0.039030, l2: 0.047925, l3: 0.067576, l4: 0.113039, l5: 0.248034, l6: 0.532295\n",
      "\n",
      "[epoch: 347/400, batch: 736/1000, ite: 46218] train loss: 1.1878, accuracy: 92.1943%, tar: 0.0255 \n",
      "l0: 0.022871, l1: 0.024435, l2: 0.030373, l3: 0.045510, l4: 0.078991, l5: 0.157754, l6: 0.326928\n",
      "\n",
      "[epoch: 347/400, batch: 744/1000, ite: 46219] train loss: 1.1870, accuracy: 95.3268%, tar: 0.0255 \n",
      "l0: 0.016434, l1: 0.017230, l2: 0.022367, l3: 0.032507, l4: 0.054125, l5: 0.106663, l6: 0.223713\n",
      "\n",
      "[epoch: 347/400, batch: 752/1000, ite: 46220] train loss: 1.1848, accuracy: 96.5859%, tar: 0.0254 \n",
      "l0: 0.022549, l1: 0.023591, l2: 0.029587, l3: 0.042328, l4: 0.086419, l5: 0.189502, l6: 0.387963\n",
      "\n",
      "[epoch: 347/400, batch: 760/1000, ite: 46221] train loss: 1.1847, accuracy: 94.4412%, tar: 0.0254 \n",
      "l0: 0.024054, l1: 0.025130, l2: 0.032606, l3: 0.047476, l4: 0.084687, l5: 0.170404, l6: 0.356704\n",
      "\n",
      "[epoch: 347/400, batch: 768/1000, ite: 46222] train loss: 1.1844, accuracy: 95.1119%, tar: 0.0254 \n",
      "l0: 0.024653, l1: 0.026126, l2: 0.033941, l3: 0.049691, l4: 0.082111, l5: 0.157674, l6: 0.313270\n",
      "\n",
      "[epoch: 347/400, batch: 776/1000, ite: 46223] train loss: 1.1836, accuracy: 95.5088%, tar: 0.0254 \n",
      "l0: 0.035053, l1: 0.037493, l2: 0.049973, l3: 0.071457, l4: 0.128947, l5: 0.248600, l6: 0.501429\n",
      "\n",
      "[epoch: 347/400, batch: 784/1000, ite: 46224] train loss: 1.1853, accuracy: 94.0675%, tar: 0.0254 \n",
      "l0: 0.023875, l1: 0.024998, l2: 0.031958, l3: 0.046038, l4: 0.075784, l5: 0.143280, l6: 0.320707\n",
      "\n",
      "[epoch: 347/400, batch: 792/1000, ite: 46225] train loss: 1.1845, accuracy: 95.4072%, tar: 0.0254 \n",
      "l0: 0.025526, l1: 0.026932, l2: 0.033359, l3: 0.045660, l4: 0.081200, l5: 0.152280, l6: 0.284895\n",
      "\n",
      "[epoch: 347/400, batch: 800/1000, ite: 46226] train loss: 1.1834, accuracy: 95.6629%, tar: 0.0254 \n",
      "l0: 0.023505, l1: 0.024888, l2: 0.032840, l3: 0.046859, l4: 0.079864, l5: 0.154651, l6: 0.298164\n",
      "\n",
      "[epoch: 347/400, batch: 808/1000, ite: 46227] train loss: 1.1825, accuracy: 95.2774%, tar: 0.0254 \n",
      "l0: 0.033265, l1: 0.035055, l2: 0.041999, l3: 0.059799, l4: 0.110775, l5: 0.221110, l6: 0.408646\n",
      "\n",
      "[epoch: 347/400, batch: 816/1000, ite: 46228] train loss: 1.1831, accuracy: 93.9646%, tar: 0.0255 \n",
      "l0: 0.023644, l1: 0.024792, l2: 0.033018, l3: 0.052313, l4: 0.098006, l5: 0.182311, l6: 0.365897\n",
      "\n",
      "[epoch: 347/400, batch: 824/1000, ite: 46229] train loss: 1.1829, accuracy: 94.7453%, tar: 0.0254 \n",
      "l0: 0.025783, l1: 0.026754, l2: 0.034341, l3: 0.048431, l4: 0.085232, l5: 0.183644, l6: 0.361830\n",
      "\n",
      "[epoch: 347/400, batch: 832/1000, ite: 46230] train loss: 1.1827, accuracy: 94.8410%, tar: 0.0255 \n",
      "l0: 0.021801, l1: 0.022852, l2: 0.028634, l3: 0.042433, l4: 0.080984, l5: 0.181099, l6: 0.348914\n",
      "\n",
      "[epoch: 347/400, batch: 840/1000, ite: 46231] train loss: 1.1823, accuracy: 95.8545%, tar: 0.0254 \n",
      "l0: 0.023280, l1: 0.024169, l2: 0.031574, l3: 0.047797, l4: 0.096662, l5: 0.196697, l6: 0.411633\n",
      "\n",
      "[epoch: 347/400, batch: 848/1000, ite: 46232] train loss: 1.1826, accuracy: 94.9368%, tar: 0.0254 \n",
      "l0: 0.030937, l1: 0.032391, l2: 0.041944, l3: 0.063759, l4: 0.119291, l5: 0.250148, l6: 0.463086\n",
      "\n",
      "[epoch: 347/400, batch: 856/1000, ite: 46233] train loss: 1.1838, accuracy: 93.2163%, tar: 0.0254 \n",
      "l0: 0.029851, l1: 0.030730, l2: 0.036793, l3: 0.049535, l4: 0.086003, l5: 0.163545, l6: 0.329360\n",
      "\n",
      "[epoch: 347/400, batch: 864/1000, ite: 46234] train loss: 1.1833, accuracy: 94.7358%, tar: 0.0255 \n",
      "l0: 0.032269, l1: 0.033459, l2: 0.042320, l3: 0.063665, l4: 0.129912, l5: 0.271850, l6: 0.489669\n",
      "\n",
      "[epoch: 347/400, batch: 872/1000, ite: 46235] train loss: 1.1849, accuracy: 93.1070%, tar: 0.0255 \n",
      "l0: 0.025023, l1: 0.026384, l2: 0.035114, l3: 0.051931, l4: 0.099175, l5: 0.204383, l6: 0.399667\n",
      "\n",
      "[epoch: 347/400, batch: 880/1000, ite: 46236] train loss: 1.1852, accuracy: 94.6438%, tar: 0.0255 \n",
      "l0: 0.024941, l1: 0.026644, l2: 0.034888, l3: 0.053896, l4: 0.098039, l5: 0.194430, l6: 0.338250\n",
      "\n",
      "[epoch: 347/400, batch: 888/1000, ite: 46237] train loss: 1.1849, accuracy: 94.9308%, tar: 0.0255 \n",
      "l0: 0.025296, l1: 0.027330, l2: 0.035892, l3: 0.058224, l4: 0.099158, l5: 0.203008, l6: 0.400917\n",
      "\n",
      "[epoch: 347/400, batch: 896/1000, ite: 46238] train loss: 1.1851, accuracy: 94.4061%, tar: 0.0255 \n",
      "l0: 0.021674, l1: 0.023347, l2: 0.032288, l3: 0.044923, l4: 0.077452, l5: 0.158355, l6: 0.326900\n",
      "\n",
      "[epoch: 347/400, batch: 904/1000, ite: 46239] train loss: 1.1844, accuracy: 95.7563%, tar: 0.0255 \n",
      "l0: 0.023507, l1: 0.024411, l2: 0.031601, l3: 0.049626, l4: 0.096612, l5: 0.180902, l6: 0.374073\n",
      "\n",
      "[epoch: 347/400, batch: 912/1000, ite: 46240] train loss: 1.1843, accuracy: 94.6679%, tar: 0.0255 \n",
      "l0: 0.022938, l1: 0.024505, l2: 0.035648, l3: 0.054030, l4: 0.106082, l5: 0.186265, l6: 0.404002\n",
      "\n",
      "[epoch: 347/400, batch: 920/1000, ite: 46241] train loss: 1.1846, accuracy: 94.4492%, tar: 0.0255 \n",
      "l0: 0.033066, l1: 0.034310, l2: 0.041895, l3: 0.064825, l4: 0.109611, l5: 0.214491, l6: 0.424876\n",
      "\n",
      "[epoch: 347/400, batch: 928/1000, ite: 46242] train loss: 1.1852, accuracy: 92.6282%, tar: 0.0255 \n",
      "l0: 0.025297, l1: 0.026494, l2: 0.035026, l3: 0.047603, l4: 0.072369, l5: 0.127897, l6: 0.290135\n",
      "\n",
      "[epoch: 347/400, batch: 936/1000, ite: 46243] train loss: 1.1842, accuracy: 95.5399%, tar: 0.0255 \n",
      "l0: 0.017562, l1: 0.018459, l2: 0.024417, l3: 0.033974, l4: 0.055562, l5: 0.105433, l6: 0.243270\n",
      "\n",
      "[epoch: 347/400, batch: 944/1000, ite: 46244] train loss: 1.1824, accuracy: 96.7708%, tar: 0.0255 \n",
      "l0: 0.026454, l1: 0.027369, l2: 0.036312, l3: 0.051926, l4: 0.085165, l5: 0.162066, l6: 0.349917\n",
      "\n",
      "[epoch: 347/400, batch: 952/1000, ite: 46245] train loss: 1.1820, accuracy: 95.0305%, tar: 0.0255 \n",
      "l0: 0.021909, l1: 0.023037, l2: 0.031111, l3: 0.042226, l4: 0.071937, l5: 0.149906, l6: 0.318229\n",
      "\n",
      "[epoch: 347/400, batch: 960/1000, ite: 46246] train loss: 1.1812, accuracy: 96.0778%, tar: 0.0254 \n",
      "l0: 0.024119, l1: 0.025618, l2: 0.033791, l3: 0.049881, l4: 0.095489, l5: 0.220503, l6: 0.416366\n",
      "\n",
      "[epoch: 347/400, batch: 968/1000, ite: 46247] train loss: 1.1816, accuracy: 93.7056%, tar: 0.0254 \n",
      "l0: 0.025204, l1: 0.026378, l2: 0.033914, l3: 0.049505, l4: 0.085663, l5: 0.146226, l6: 0.253091\n",
      "\n",
      "[epoch: 347/400, batch: 976/1000, ite: 46248] train loss: 1.1804, accuracy: 95.3932%, tar: 0.0254 \n",
      "l0: 0.028670, l1: 0.030205, l2: 0.038481, l3: 0.054202, l4: 0.086645, l5: 0.159574, l6: 0.316084\n",
      "\n",
      "[epoch: 347/400, batch: 984/1000, ite: 46249] train loss: 1.1798, accuracy: 95.7496%, tar: 0.0255 \n",
      "l0: 0.023092, l1: 0.024167, l2: 0.033639, l3: 0.048880, l4: 0.089159, l5: 0.194428, l6: 0.350909\n",
      "\n",
      "[epoch: 347/400, batch: 992/1000, ite: 46250] train loss: 1.1795, accuracy: 95.5179%, tar: 0.0254 \n",
      "l0: 0.020741, l1: 0.021491, l2: 0.029955, l3: 0.041330, l4: 0.069492, l5: 0.130719, l6: 0.327074\n",
      "\n",
      "[epoch: 347/400, batch: 1000/1000, ite: 46251] train loss: 1.1787, accuracy: 95.8173%, tar: 0.0254 \n",
      "l0: 0.023792, l1: 0.024975, l2: 0.032648, l3: 0.050273, l4: 0.094737, l5: 0.190217, l6: 0.446357\n",
      "\n",
      "[epoch: 348/400, batch: 8/1000, ite: 46252] train loss: 1.1793, accuracy: 93.8361%, tar: 0.0254 \n",
      "l0: 0.023110, l1: 0.024317, l2: 0.033304, l3: 0.048951, l4: 0.087004, l5: 0.167691, l6: 0.310719\n",
      "\n",
      "[epoch: 348/400, batch: 16/1000, ite: 46253] train loss: 1.1785, accuracy: 95.0576%, tar: 0.0254 \n",
      "l0: 0.028616, l1: 0.030009, l2: 0.039823, l3: 0.055434, l4: 0.099168, l5: 0.200146, l6: 0.398899\n",
      "\n",
      "[epoch: 348/400, batch: 24/1000, ite: 46254] train loss: 1.1789, accuracy: 95.1091%, tar: 0.0254 \n",
      "l0: 0.021866, l1: 0.023926, l2: 0.033934, l3: 0.050053, l4: 0.083997, l5: 0.156218, l6: 0.295649\n",
      "\n",
      "[epoch: 348/400, batch: 32/1000, ite: 46255] train loss: 1.1780, accuracy: 96.2004%, tar: 0.0254 \n",
      "l0: 0.021586, l1: 0.022365, l2: 0.029797, l3: 0.044866, l4: 0.076581, l5: 0.130083, l6: 0.277931\n",
      "\n",
      "[epoch: 348/400, batch: 40/1000, ite: 46256] train loss: 1.1769, accuracy: 96.0386%, tar: 0.0254 \n",
      "l0: 0.025650, l1: 0.026948, l2: 0.033976, l3: 0.045817, l4: 0.077348, l5: 0.172269, l6: 0.339827\n",
      "\n",
      "[epoch: 348/400, batch: 48/1000, ite: 46257] train loss: 1.1764, accuracy: 95.3572%, tar: 0.0254 \n",
      "l0: 0.029143, l1: 0.030181, l2: 0.037917, l3: 0.054460, l4: 0.089472, l5: 0.170324, l6: 0.386736\n",
      "\n",
      "[epoch: 348/400, batch: 56/1000, ite: 46258] train loss: 1.1765, accuracy: 94.5599%, tar: 0.0254 \n",
      "l0: 0.024854, l1: 0.026043, l2: 0.033258, l3: 0.046394, l4: 0.078448, l5: 0.154696, l6: 0.329740\n",
      "\n",
      "[epoch: 348/400, batch: 64/1000, ite: 46259] train loss: 1.1760, accuracy: 94.9427%, tar: 0.0254 \n",
      "l0: 0.028326, l1: 0.029677, l2: 0.038608, l3: 0.059073, l4: 0.115005, l5: 0.201264, l6: 0.429951\n",
      "\n",
      "[epoch: 348/400, batch: 72/1000, ite: 46260] train loss: 1.1766, accuracy: 94.3696%, tar: 0.0254 \n",
      "l0: 0.025271, l1: 0.026710, l2: 0.035615, l3: 0.054638, l4: 0.098180, l5: 0.190544, l6: 0.399722\n",
      "\n",
      "[epoch: 348/400, batch: 80/1000, ite: 46261] train loss: 1.1768, accuracy: 94.8343%, tar: 0.0254 \n",
      "l0: 0.016845, l1: 0.017719, l2: 0.023575, l3: 0.034697, l4: 0.061050, l5: 0.105707, l6: 0.256601\n",
      "\n",
      "[epoch: 348/400, batch: 88/1000, ite: 46262] train loss: 1.1753, accuracy: 96.1602%, tar: 0.0254 \n",
      "l0: 0.026078, l1: 0.028058, l2: 0.039083, l3: 0.059407, l4: 0.115673, l5: 0.244352, l6: 0.476310\n",
      "\n",
      "[epoch: 348/400, batch: 96/1000, ite: 46263] train loss: 1.1764, accuracy: 94.0339%, tar: 0.0254 \n",
      "l0: 0.024287, l1: 0.025781, l2: 0.034286, l3: 0.056353, l4: 0.102823, l5: 0.188841, l6: 0.333738\n",
      "\n",
      "[epoch: 348/400, batch: 104/1000, ite: 46264] train loss: 1.1761, accuracy: 95.4615%, tar: 0.0254 \n",
      "l0: 0.023935, l1: 0.024718, l2: 0.033390, l3: 0.050021, l4: 0.089296, l5: 0.164863, l6: 0.306683\n",
      "\n",
      "[epoch: 348/400, batch: 112/1000, ite: 46265] train loss: 1.1754, accuracy: 95.5691%, tar: 0.0254 \n",
      "l0: 0.021415, l1: 0.022510, l2: 0.031072, l3: 0.048411, l4: 0.088461, l5: 0.174528, l6: 0.339752\n",
      "\n",
      "[epoch: 348/400, batch: 120/1000, ite: 46266] train loss: 1.1750, accuracy: 95.3490%, tar: 0.0254 \n",
      "l0: 0.029259, l1: 0.030855, l2: 0.040731, l3: 0.060061, l4: 0.106034, l5: 0.217038, l6: 0.597557\n",
      "\n",
      "[epoch: 348/400, batch: 128/1000, ite: 46267] train loss: 1.1769, accuracy: 91.9497%, tar: 0.0254 \n",
      "l0: 0.025374, l1: 0.027008, l2: 0.036736, l3: 0.053262, l4: 0.108164, l5: 0.263275, l6: 0.495643\n",
      "\n",
      "[epoch: 348/400, batch: 136/1000, ite: 46268] train loss: 1.1781, accuracy: 94.4820%, tar: 0.0254 \n",
      "l0: 0.024216, l1: 0.025964, l2: 0.032237, l3: 0.045346, l4: 0.079495, l5: 0.148043, l6: 0.281919\n",
      "\n",
      "[epoch: 348/400, batch: 144/1000, ite: 46269] train loss: 1.1772, accuracy: 95.6002%, tar: 0.0254 \n",
      "l0: 0.022479, l1: 0.023581, l2: 0.030965, l3: 0.044524, l4: 0.079079, l5: 0.161538, l6: 0.386494\n",
      "\n",
      "[epoch: 348/400, batch: 152/1000, ite: 46270] train loss: 1.1771, accuracy: 94.6546%, tar: 0.0254 \n",
      "l0: 0.024114, l1: 0.026057, l2: 0.034860, l3: 0.054912, l4: 0.099515, l5: 0.175797, l6: 0.422696\n",
      "\n",
      "[epoch: 348/400, batch: 160/1000, ite: 46271] train loss: 1.1774, accuracy: 94.4950%, tar: 0.0254 \n",
      "l0: 0.019863, l1: 0.021133, l2: 0.027761, l3: 0.042089, l4: 0.073626, l5: 0.146356, l6: 0.312735\n",
      "\n",
      "[epoch: 348/400, batch: 168/1000, ite: 46272] train loss: 1.1766, accuracy: 95.8830%, tar: 0.0253 \n",
      "l0: 0.028722, l1: 0.029847, l2: 0.038393, l3: 0.054302, l4: 0.090413, l5: 0.179297, l6: 0.347314\n",
      "\n",
      "[epoch: 348/400, batch: 176/1000, ite: 46273] train loss: 1.1764, accuracy: 94.3758%, tar: 0.0253 \n",
      "l0: 0.018616, l1: 0.019932, l2: 0.025185, l3: 0.039032, l4: 0.066954, l5: 0.131340, l6: 0.243170\n",
      "\n",
      "[epoch: 348/400, batch: 184/1000, ite: 46274] train loss: 1.1750, accuracy: 96.2649%, tar: 0.0253 \n",
      "l0: 0.021015, l1: 0.021658, l2: 0.028381, l3: 0.041888, l4: 0.069174, l5: 0.135777, l6: 0.292504\n",
      "\n",
      "[epoch: 348/400, batch: 192/1000, ite: 46275] train loss: 1.1740, accuracy: 95.5702%, tar: 0.0253 \n",
      "l0: 0.021086, l1: 0.023554, l2: 0.032809, l3: 0.051028, l4: 0.095888, l5: 0.193138, l6: 0.374520\n",
      "\n",
      "[epoch: 348/400, batch: 200/1000, ite: 46276] train loss: 1.1740, accuracy: 95.3456%, tar: 0.0253 \n",
      "l0: 0.026731, l1: 0.027949, l2: 0.035987, l3: 0.052052, l4: 0.089912, l5: 0.175773, l6: 0.341515\n",
      "\n",
      "[epoch: 348/400, batch: 208/1000, ite: 46277] train loss: 1.1738, accuracy: 94.7812%, tar: 0.0253 \n",
      "l0: 0.025818, l1: 0.027160, l2: 0.033773, l3: 0.050017, l4: 0.081755, l5: 0.144858, l6: 0.283448\n",
      "\n",
      "[epoch: 348/400, batch: 216/1000, ite: 46278] train loss: 1.1729, accuracy: 95.4700%, tar: 0.0253 \n",
      "l0: 0.022831, l1: 0.024272, l2: 0.030719, l3: 0.048082, l4: 0.093325, l5: 0.191098, l6: 0.383700\n",
      "\n",
      "[epoch: 348/400, batch: 224/1000, ite: 46279] train loss: 1.1729, accuracy: 95.0262%, tar: 0.0253 \n",
      "l0: 0.021459, l1: 0.023088, l2: 0.032176, l3: 0.052059, l4: 0.109602, l5: 0.213401, l6: 0.426788\n",
      "\n",
      "[epoch: 348/400, batch: 232/1000, ite: 46280] train loss: 1.1734, accuracy: 94.9976%, tar: 0.0253 \n",
      "l0: 0.024170, l1: 0.025067, l2: 0.031839, l3: 0.045441, l4: 0.086068, l5: 0.186348, l6: 0.397049\n",
      "\n",
      "[epoch: 348/400, batch: 240/1000, ite: 46281] train loss: 1.1735, accuracy: 94.4397%, tar: 0.0253 \n",
      "l0: 0.025994, l1: 0.027330, l2: 0.035638, l3: 0.050925, l4: 0.100783, l5: 0.185106, l6: 0.391391\n",
      "\n",
      "[epoch: 348/400, batch: 248/1000, ite: 46282] train loss: 1.1737, accuracy: 94.4496%, tar: 0.0253 \n",
      "l0: 0.017009, l1: 0.017863, l2: 0.023349, l3: 0.035616, l4: 0.064468, l5: 0.121259, l6: 0.255071\n",
      "\n",
      "[epoch: 348/400, batch: 256/1000, ite: 46283] train loss: 1.1723, accuracy: 96.4038%, tar: 0.0252 \n",
      "l0: 0.018879, l1: 0.019633, l2: 0.024904, l3: 0.037049, l4: 0.065549, l5: 0.122502, l6: 0.302201\n",
      "\n",
      "[epoch: 348/400, batch: 264/1000, ite: 46284] train loss: 1.1713, accuracy: 95.8201%, tar: 0.0252 \n",
      "l0: 0.025122, l1: 0.026078, l2: 0.034733, l3: 0.049682, l4: 0.089101, l5: 0.161645, l6: 0.357037\n",
      "\n",
      "[epoch: 348/400, batch: 272/1000, ite: 46285] train loss: 1.1711, accuracy: 94.6717%, tar: 0.0252 \n",
      "l0: 0.015705, l1: 0.016506, l2: 0.021304, l3: 0.030285, l4: 0.053878, l5: 0.102772, l6: 0.234760\n",
      "\n",
      "[epoch: 348/400, batch: 280/1000, ite: 46286] train loss: 1.1695, accuracy: 96.9167%, tar: 0.0252 \n",
      "l0: 0.022562, l1: 0.024962, l2: 0.035634, l3: 0.060101, l4: 0.110250, l5: 0.215284, l6: 0.396612\n",
      "\n",
      "[epoch: 348/400, batch: 288/1000, ite: 46287] train loss: 1.1699, accuracy: 94.9660%, tar: 0.0252 \n",
      "l0: 0.027154, l1: 0.028046, l2: 0.036474, l3: 0.052386, l4: 0.091741, l5: 0.180315, l6: 0.366633\n",
      "\n",
      "[epoch: 348/400, batch: 296/1000, ite: 46288] train loss: 1.1698, accuracy: 94.5601%, tar: 0.0252 \n",
      "l0: 0.019589, l1: 0.020815, l2: 0.026189, l3: 0.041495, l4: 0.081474, l5: 0.143312, l6: 0.258332\n",
      "\n",
      "[epoch: 348/400, batch: 304/1000, ite: 46289] train loss: 1.1687, accuracy: 95.8300%, tar: 0.0252 \n",
      "l0: 0.025806, l1: 0.027269, l2: 0.035982, l3: 0.055650, l4: 0.096562, l5: 0.183168, l6: 0.416253\n",
      "\n",
      "[epoch: 348/400, batch: 312/1000, ite: 46290] train loss: 1.1690, accuracy: 93.8656%, tar: 0.0252 \n",
      "l0: 0.021965, l1: 0.023287, l2: 0.030657, l3: 0.042762, l4: 0.069675, l5: 0.135301, l6: 0.280406\n",
      "\n",
      "[epoch: 348/400, batch: 320/1000, ite: 46291] train loss: 1.1681, accuracy: 96.0663%, tar: 0.0252 \n",
      "l0: 0.029263, l1: 0.031088, l2: 0.040020, l3: 0.061208, l4: 0.110654, l5: 0.217963, l6: 0.520981\n",
      "\n",
      "[epoch: 348/400, batch: 328/1000, ite: 46292] train loss: 1.1694, accuracy: 92.9024%, tar: 0.0252 \n",
      "l0: 0.026739, l1: 0.029821, l2: 0.040602, l3: 0.065994, l4: 0.130441, l5: 0.242457, l6: 0.431958\n",
      "\n",
      "[epoch: 348/400, batch: 336/1000, ite: 46293] train loss: 1.1701, accuracy: 94.7228%, tar: 0.0252 \n",
      "l0: 0.025064, l1: 0.026915, l2: 0.035846, l3: 0.054723, l4: 0.100096, l5: 0.174070, l6: 0.313272\n",
      "\n",
      "[epoch: 348/400, batch: 344/1000, ite: 46294] train loss: 1.1697, accuracy: 95.4721%, tar: 0.0252 \n",
      "l0: 0.028965, l1: 0.030161, l2: 0.036023, l3: 0.048141, l4: 0.097874, l5: 0.221832, l6: 0.488874\n",
      "\n",
      "[epoch: 348/400, batch: 352/1000, ite: 46295] train loss: 1.1707, accuracy: 93.7208%, tar: 0.0252 \n",
      "l0: 0.026779, l1: 0.027583, l2: 0.036312, l3: 0.052842, l4: 0.086990, l5: 0.167043, l6: 0.374234\n",
      "\n",
      "[epoch: 348/400, batch: 360/1000, ite: 46296] train loss: 1.1706, accuracy: 94.1723%, tar: 0.0252 \n",
      "l0: 0.018515, l1: 0.019302, l2: 0.024773, l3: 0.034593, l4: 0.052713, l5: 0.094081, l6: 0.202114\n",
      "\n",
      "[epoch: 348/400, batch: 368/1000, ite: 46297] train loss: 1.1689, accuracy: 96.6400%, tar: 0.0252 \n",
      "l0: 0.026560, l1: 0.027993, l2: 0.037691, l3: 0.053810, l4: 0.107926, l5: 0.271589, l6: 0.556247\n",
      "\n",
      "[epoch: 348/400, batch: 376/1000, ite: 46298] train loss: 1.1705, accuracy: 93.1269%, tar: 0.0252 \n",
      "l0: 0.021739, l1: 0.023127, l2: 0.029505, l3: 0.042386, l4: 0.072788, l5: 0.135177, l6: 0.256837\n",
      "\n",
      "[epoch: 348/400, batch: 384/1000, ite: 46299] train loss: 1.1694, accuracy: 95.2285%, tar: 0.0252 \n",
      "l0: 0.025849, l1: 0.027411, l2: 0.039067, l3: 0.061506, l4: 0.122366, l5: 0.218524, l6: 0.402886\n",
      "\n",
      "[epoch: 348/400, batch: 392/1000, ite: 46300] train loss: 1.1698, accuracy: 94.6603%, tar: 0.0252 \n",
      "l0: 0.017795, l1: 0.018926, l2: 0.026213, l3: 0.040868, l4: 0.069254, l5: 0.141497, l6: 0.298184\n",
      "\n",
      "[epoch: 348/400, batch: 400/1000, ite: 46301] train loss: 1.1690, accuracy: 95.5729%, tar: 0.0251 \n",
      "l0: 0.024593, l1: 0.025799, l2: 0.035570, l3: 0.055551, l4: 0.101453, l5: 0.196357, l6: 0.355498\n",
      "\n",
      "[epoch: 348/400, batch: 408/1000, ite: 46302] train loss: 1.1689, accuracy: 94.5747%, tar: 0.0251 \n",
      "l0: 0.021955, l1: 0.022596, l2: 0.031263, l3: 0.044033, l4: 0.078335, l5: 0.153997, l6: 0.319663\n",
      "\n",
      "[epoch: 348/400, batch: 416/1000, ite: 46303] train loss: 1.1684, accuracy: 95.1714%, tar: 0.0251 \n",
      "l0: 0.029244, l1: 0.030706, l2: 0.040029, l3: 0.063056, l4: 0.122053, l5: 0.219534, l6: 0.386403\n",
      "\n",
      "[epoch: 348/400, batch: 424/1000, ite: 46304] train loss: 1.1687, accuracy: 94.3121%, tar: 0.0251 \n",
      "l0: 0.021410, l1: 0.022195, l2: 0.029868, l3: 0.046490, l4: 0.086146, l5: 0.168781, l6: 0.329038\n",
      "\n",
      "[epoch: 348/400, batch: 432/1000, ite: 46305] train loss: 1.1683, accuracy: 95.2817%, tar: 0.0251 \n",
      "l0: 0.023077, l1: 0.023725, l2: 0.029229, l3: 0.044196, l4: 0.084870, l5: 0.164796, l6: 0.323486\n",
      "\n",
      "[epoch: 348/400, batch: 440/1000, ite: 46306] train loss: 1.1678, accuracy: 94.9093%, tar: 0.0251 \n",
      "l0: 0.022734, l1: 0.023740, l2: 0.031478, l3: 0.043727, l4: 0.074720, l5: 0.158522, l6: 0.311336\n",
      "\n",
      "[epoch: 348/400, batch: 448/1000, ite: 46307] train loss: 1.1672, accuracy: 94.8800%, tar: 0.0251 \n",
      "l0: 0.025734, l1: 0.027322, l2: 0.035717, l3: 0.051220, l4: 0.088330, l5: 0.178975, l6: 0.423364\n",
      "\n",
      "[epoch: 348/400, batch: 456/1000, ite: 46308] train loss: 1.1675, accuracy: 94.0241%, tar: 0.0251 \n",
      "l0: 0.022220, l1: 0.023828, l2: 0.031268, l3: 0.046986, l4: 0.084931, l5: 0.172220, l6: 0.385084\n",
      "\n",
      "[epoch: 348/400, batch: 464/1000, ite: 46309] train loss: 1.1675, accuracy: 95.2116%, tar: 0.0251 \n",
      "l0: 0.020097, l1: 0.020994, l2: 0.027899, l3: 0.041502, l4: 0.069631, l5: 0.119761, l6: 0.271390\n",
      "\n",
      "[epoch: 348/400, batch: 472/1000, ite: 46310] train loss: 1.1664, accuracy: 96.0607%, tar: 0.0251 \n",
      "l0: 0.030702, l1: 0.032157, l2: 0.040206, l3: 0.063689, l4: 0.116432, l5: 0.226918, l6: 0.477315\n",
      "\n",
      "[epoch: 348/400, batch: 480/1000, ite: 46311] train loss: 1.1674, accuracy: 93.9464%, tar: 0.0251 \n",
      "l0: 0.023725, l1: 0.025623, l2: 0.034819, l3: 0.052837, l4: 0.109490, l5: 0.245867, l6: 0.520534\n",
      "\n",
      "[epoch: 348/400, batch: 488/1000, ite: 46312] train loss: 1.1685, accuracy: 94.5211%, tar: 0.0251 \n",
      "l0: 0.027275, l1: 0.028671, l2: 0.036885, l3: 0.056632, l4: 0.110526, l5: 0.241474, l6: 0.448502\n",
      "\n",
      "[epoch: 348/400, batch: 496/1000, ite: 46313] train loss: 1.1693, accuracy: 93.8683%, tar: 0.0251 \n",
      "l0: 0.023097, l1: 0.024747, l2: 0.033706, l3: 0.053905, l4: 0.109811, l5: 0.216202, l6: 0.355511\n",
      "\n",
      "[epoch: 348/400, batch: 504/1000, ite: 46314] train loss: 1.1693, accuracy: 95.1093%, tar: 0.0251 \n",
      "l0: 0.024497, l1: 0.025519, l2: 0.033246, l3: 0.045034, l4: 0.084101, l5: 0.159704, l6: 0.372632\n",
      "\n",
      "[epoch: 348/400, batch: 512/1000, ite: 46315] train loss: 1.1692, accuracy: 95.2235%, tar: 0.0251 \n",
      "l0: 0.024831, l1: 0.026868, l2: 0.035907, l3: 0.056149, l4: 0.115204, l5: 0.206517, l6: 0.352204\n",
      "\n",
      "[epoch: 348/400, batch: 520/1000, ite: 46316] train loss: 1.1692, accuracy: 95.4021%, tar: 0.0251 \n",
      "l0: 0.026698, l1: 0.027225, l2: 0.032932, l3: 0.044843, l4: 0.071736, l5: 0.118366, l6: 0.267941\n",
      "\n",
      "[epoch: 348/400, batch: 528/1000, ite: 46317] train loss: 1.1683, accuracy: 95.3554%, tar: 0.0251 \n",
      "l0: 0.035415, l1: 0.037361, l2: 0.046815, l3: 0.074675, l4: 0.155516, l5: 0.339372, l6: 0.710416\n",
      "\n",
      "[epoch: 348/400, batch: 536/1000, ite: 46318] train loss: 1.1713, accuracy: 90.3473%, tar: 0.0251 \n",
      "l0: 0.028350, l1: 0.029538, l2: 0.037789, l3: 0.054072, l4: 0.098452, l5: 0.193632, l6: 0.397783\n",
      "\n",
      "[epoch: 348/400, batch: 544/1000, ite: 46319] train loss: 1.1715, accuracy: 93.9550%, tar: 0.0252 \n",
      "l0: 0.028022, l1: 0.029937, l2: 0.041098, l3: 0.065429, l4: 0.127340, l5: 0.252138, l6: 0.472954\n",
      "\n",
      "[epoch: 348/400, batch: 552/1000, ite: 46320] train loss: 1.1725, accuracy: 93.5540%, tar: 0.0252 \n",
      "l0: 0.028119, l1: 0.030094, l2: 0.039857, l3: 0.066195, l4: 0.145896, l5: 0.299177, l6: 0.510681\n",
      "\n",
      "[epoch: 348/400, batch: 560/1000, ite: 46321] train loss: 1.1740, accuracy: 93.4148%, tar: 0.0252 \n",
      "l0: 0.025213, l1: 0.026511, l2: 0.034529, l3: 0.048803, l4: 0.097892, l5: 0.201099, l6: 0.421855\n",
      "\n",
      "[epoch: 348/400, batch: 568/1000, ite: 46322] train loss: 1.1743, accuracy: 94.0915%, tar: 0.0252 \n",
      "l0: 0.022957, l1: 0.024053, l2: 0.032857, l3: 0.049469, l4: 0.084056, l5: 0.171867, l6: 0.365654\n",
      "\n",
      "[epoch: 348/400, batch: 576/1000, ite: 46323] train loss: 1.1741, accuracy: 94.9499%, tar: 0.0252 \n",
      "l0: 0.015964, l1: 0.017024, l2: 0.023318, l3: 0.035530, l4: 0.065289, l5: 0.123912, l6: 0.279492\n",
      "\n",
      "[epoch: 348/400, batch: 584/1000, ite: 46324] train loss: 1.1731, accuracy: 95.5183%, tar: 0.0251 \n",
      "l0: 0.030663, l1: 0.032117, l2: 0.040036, l3: 0.060632, l4: 0.116304, l5: 0.235350, l6: 0.490875\n",
      "\n",
      "[epoch: 348/400, batch: 592/1000, ite: 46325] train loss: 1.1741, accuracy: 92.9336%, tar: 0.0252 \n",
      "l0: 0.026210, l1: 0.027892, l2: 0.034839, l3: 0.059455, l4: 0.101739, l5: 0.203011, l6: 0.406369\n",
      "\n",
      "[epoch: 348/400, batch: 600/1000, ite: 46326] train loss: 1.1744, accuracy: 94.5802%, tar: 0.0252 \n",
      "l0: 0.020116, l1: 0.020843, l2: 0.027820, l3: 0.043071, l4: 0.088013, l5: 0.174152, l6: 0.436902\n",
      "\n",
      "[epoch: 348/400, batch: 608/1000, ite: 46327] train loss: 1.1747, accuracy: 94.2908%, tar: 0.0251 \n",
      "l0: 0.024462, l1: 0.025297, l2: 0.033752, l3: 0.049696, l4: 0.085752, l5: 0.166080, l6: 0.342877\n",
      "\n",
      "[epoch: 348/400, batch: 616/1000, ite: 46328] train loss: 1.1744, accuracy: 94.8840%, tar: 0.0251 \n",
      "l0: 0.021228, l1: 0.022592, l2: 0.030610, l3: 0.041950, l4: 0.072960, l5: 0.151351, l6: 0.367232\n",
      "\n",
      "[epoch: 348/400, batch: 624/1000, ite: 46329] train loss: 1.1741, accuracy: 95.1006%, tar: 0.0251 \n",
      "l0: 0.028353, l1: 0.029849, l2: 0.037876, l3: 0.056716, l4: 0.109524, l5: 0.230261, l6: 0.436577\n",
      "\n",
      "[epoch: 348/400, batch: 632/1000, ite: 46330] train loss: 1.1747, accuracy: 94.5269%, tar: 0.0251 \n",
      "l0: 0.019139, l1: 0.020098, l2: 0.026321, l3: 0.036424, l4: 0.062646, l5: 0.149846, l6: 0.292442\n",
      "\n",
      "[epoch: 348/400, batch: 640/1000, ite: 46331] train loss: 1.1739, accuracy: 95.6541%, tar: 0.0251 \n",
      "l0: 0.024339, l1: 0.025356, l2: 0.033185, l3: 0.051275, l4: 0.091998, l5: 0.173342, l6: 0.329835\n",
      "\n",
      "[epoch: 348/400, batch: 648/1000, ite: 46332] train loss: 1.1735, accuracy: 95.0110%, tar: 0.0251 \n",
      "l0: 0.030669, l1: 0.032133, l2: 0.041145, l3: 0.061368, l4: 0.122555, l5: 0.229435, l6: 0.406132\n",
      "\n",
      "[epoch: 348/400, batch: 656/1000, ite: 46333] train loss: 1.1740, accuracy: 93.5999%, tar: 0.0251 \n",
      "l0: 0.022880, l1: 0.024305, l2: 0.031121, l3: 0.045082, l4: 0.088666, l5: 0.199219, l6: 0.361638\n",
      "\n",
      "[epoch: 348/400, batch: 664/1000, ite: 46334] train loss: 1.1739, accuracy: 95.8280%, tar: 0.0251 \n",
      "l0: 0.023098, l1: 0.023816, l2: 0.030541, l3: 0.042527, l4: 0.070089, l5: 0.132965, l6: 0.288606\n",
      "\n",
      "[epoch: 348/400, batch: 672/1000, ite: 46335] train loss: 1.1731, accuracy: 95.4528%, tar: 0.0251 \n",
      "l0: 0.025300, l1: 0.027103, l2: 0.036719, l3: 0.056474, l4: 0.101457, l5: 0.192758, l6: 0.377706\n",
      "\n",
      "[epoch: 348/400, batch: 680/1000, ite: 46336] train loss: 1.1732, accuracy: 95.1042%, tar: 0.0251 \n",
      "l0: 0.024490, l1: 0.025103, l2: 0.033820, l3: 0.049821, l4: 0.097203, l5: 0.206484, l6: 0.424041\n",
      "\n",
      "[epoch: 348/400, batch: 688/1000, ite: 46337] train loss: 1.1735, accuracy: 94.7969%, tar: 0.0251 \n",
      "l0: 0.029197, l1: 0.030388, l2: 0.037764, l3: 0.055278, l4: 0.095675, l5: 0.236077, l6: 0.446507\n",
      "\n",
      "[epoch: 348/400, batch: 696/1000, ite: 46338] train loss: 1.1741, accuracy: 93.6743%, tar: 0.0251 \n",
      "l0: 0.020040, l1: 0.021514, l2: 0.028570, l3: 0.038939, l4: 0.068970, l5: 0.152421, l6: 0.347732\n",
      "\n",
      "[epoch: 348/400, batch: 704/1000, ite: 46339] train loss: 1.1737, accuracy: 95.6775%, tar: 0.0251 \n",
      "l0: 0.024212, l1: 0.025453, l2: 0.034584, l3: 0.052671, l4: 0.100656, l5: 0.192097, l6: 0.375948\n",
      "\n",
      "[epoch: 348/400, batch: 712/1000, ite: 46340] train loss: 1.1738, accuracy: 94.4554%, tar: 0.0251 \n",
      "l0: 0.023130, l1: 0.024399, l2: 0.034034, l3: 0.048402, l4: 0.083069, l5: 0.162609, l6: 0.300486\n",
      "\n",
      "[epoch: 348/400, batch: 720/1000, ite: 46341] train loss: 1.1732, accuracy: 95.9637%, tar: 0.0251 \n",
      "l0: 0.025321, l1: 0.027190, l2: 0.035885, l3: 0.059302, l4: 0.114014, l5: 0.208103, l6: 0.521200\n",
      "\n",
      "[epoch: 348/400, batch: 728/1000, ite: 46342] train loss: 1.1742, accuracy: 94.5370%, tar: 0.0251 \n",
      "l0: 0.029094, l1: 0.030412, l2: 0.039557, l3: 0.058033, l4: 0.102903, l5: 0.262568, l6: 0.443720\n",
      "\n",
      "[epoch: 348/400, batch: 736/1000, ite: 46343] train loss: 1.1749, accuracy: 93.6725%, tar: 0.0251 \n",
      "l0: 0.022503, l1: 0.024564, l2: 0.031285, l3: 0.046115, l4: 0.084973, l5: 0.184916, l6: 0.346697\n",
      "\n",
      "[epoch: 348/400, batch: 744/1000, ite: 46344] train loss: 1.1747, accuracy: 95.6619%, tar: 0.0251 \n",
      "l0: 0.026337, l1: 0.027724, l2: 0.035973, l3: 0.055988, l4: 0.105721, l5: 0.194013, l6: 0.394163\n",
      "\n",
      "[epoch: 348/400, batch: 752/1000, ite: 46345] train loss: 1.1749, accuracy: 94.5035%, tar: 0.0251 \n",
      "l0: 0.023782, l1: 0.024886, l2: 0.032650, l3: 0.048632, l4: 0.083551, l5: 0.158864, l6: 0.320014\n",
      "\n",
      "[epoch: 348/400, batch: 760/1000, ite: 46346] train loss: 1.1744, accuracy: 95.0902%, tar: 0.0251 \n",
      "l0: 0.022759, l1: 0.024680, l2: 0.034250, l3: 0.052473, l4: 0.102996, l5: 0.194578, l6: 0.403984\n",
      "\n",
      "[epoch: 348/400, batch: 768/1000, ite: 46347] train loss: 1.1746, accuracy: 95.1747%, tar: 0.0251 \n",
      "l0: 0.025543, l1: 0.026894, l2: 0.033356, l3: 0.051231, l4: 0.097970, l5: 0.172226, l6: 0.338595\n",
      "\n",
      "[epoch: 348/400, batch: 776/1000, ite: 46348] train loss: 1.1744, accuracy: 95.0530%, tar: 0.0251 \n",
      "l0: 0.027075, l1: 0.028572, l2: 0.037786, l3: 0.056367, l4: 0.103876, l5: 0.231803, l6: 0.406352\n",
      "\n",
      "[epoch: 348/400, batch: 784/1000, ite: 46349] train loss: 1.1747, accuracy: 93.9213%, tar: 0.0251 \n",
      "l0: 0.026780, l1: 0.028693, l2: 0.037191, l3: 0.054970, l4: 0.101338, l5: 0.220585, l6: 0.475846\n",
      "\n",
      "[epoch: 348/400, batch: 792/1000, ite: 46350] train loss: 1.1754, accuracy: 94.1870%, tar: 0.0251 \n",
      "l0: 0.020872, l1: 0.021875, l2: 0.026982, l3: 0.037437, l4: 0.063768, l5: 0.169254, l6: 0.310184\n",
      "\n",
      "[epoch: 348/400, batch: 800/1000, ite: 46351] train loss: 1.1748, accuracy: 95.2229%, tar: 0.0251 \n",
      "l0: 0.028517, l1: 0.029648, l2: 0.036798, l3: 0.050388, l4: 0.080449, l5: 0.162757, l6: 0.290362\n",
      "\n",
      "[epoch: 348/400, batch: 808/1000, ite: 46352] train loss: 1.1743, accuracy: 94.8587%, tar: 0.0251 \n",
      "l0: 0.022254, l1: 0.023022, l2: 0.030073, l3: 0.045559, l4: 0.075666, l5: 0.165193, l6: 0.311029\n",
      "\n",
      "[epoch: 348/400, batch: 816/1000, ite: 46353] train loss: 1.1737, accuracy: 95.6486%, tar: 0.0251 \n",
      "l0: 0.026501, l1: 0.028335, l2: 0.037231, l3: 0.058002, l4: 0.106584, l5: 0.211873, l6: 0.379563\n",
      "\n",
      "[epoch: 348/400, batch: 824/1000, ite: 46354] train loss: 1.1739, accuracy: 94.7425%, tar: 0.0251 \n",
      "l0: 0.021895, l1: 0.023069, l2: 0.030027, l3: 0.044359, l4: 0.077591, l5: 0.149996, l6: 0.372341\n",
      "\n",
      "[epoch: 348/400, batch: 832/1000, ite: 46355] train loss: 1.1737, accuracy: 95.0014%, tar: 0.0251 \n",
      "l0: 0.025830, l1: 0.027344, l2: 0.035863, l3: 0.050403, l4: 0.093068, l5: 0.185598, l6: 0.376430\n",
      "\n",
      "[epoch: 348/400, batch: 840/1000, ite: 46356] train loss: 1.1737, accuracy: 95.6161%, tar: 0.0251 \n",
      "l0: 0.030363, l1: 0.031145, l2: 0.037837, l3: 0.056364, l4: 0.101211, l5: 0.197140, l6: 0.371389\n",
      "\n",
      "[epoch: 348/400, batch: 848/1000, ite: 46357] train loss: 1.1738, accuracy: 94.1185%, tar: 0.0251 \n",
      "l0: 0.019480, l1: 0.021136, l2: 0.029336, l3: 0.045925, l4: 0.090766, l5: 0.180700, l6: 0.364897\n",
      "\n",
      "[epoch: 348/400, batch: 856/1000, ite: 46358] train loss: 1.1737, accuracy: 95.4893%, tar: 0.0251 \n",
      "l0: 0.024615, l1: 0.025734, l2: 0.032630, l3: 0.046592, l4: 0.081667, l5: 0.160468, l6: 0.318801\n",
      "\n",
      "[epoch: 348/400, batch: 864/1000, ite: 46359] train loss: 1.1732, accuracy: 94.8380%, tar: 0.0251 \n",
      "l0: 0.030842, l1: 0.033320, l2: 0.043106, l3: 0.065308, l4: 0.139123, l5: 0.288846, l6: 0.459613\n",
      "\n",
      "[epoch: 348/400, batch: 872/1000, ite: 46360] train loss: 1.1742, accuracy: 93.5365%, tar: 0.0251 \n",
      "l0: 0.021825, l1: 0.022924, l2: 0.028819, l3: 0.041080, l4: 0.070549, l5: 0.146805, l6: 0.355984\n",
      "\n",
      "[epoch: 348/400, batch: 880/1000, ite: 46361] train loss: 1.1739, accuracy: 94.9828%, tar: 0.0251 \n",
      "l0: 0.022547, l1: 0.023675, l2: 0.031363, l3: 0.045934, l4: 0.075170, l5: 0.172680, l6: 0.344697\n",
      "\n",
      "[epoch: 348/400, batch: 888/1000, ite: 46362] train loss: 1.1736, accuracy: 95.5273%, tar: 0.0251 \n",
      "l0: 0.034235, l1: 0.035830, l2: 0.043510, l3: 0.060017, l4: 0.102580, l5: 0.233407, l6: 0.510624\n",
      "\n",
      "[epoch: 348/400, batch: 896/1000, ite: 46363] train loss: 1.1746, accuracy: 93.1215%, tar: 0.0251 \n",
      "l0: 0.024853, l1: 0.026400, l2: 0.034997, l3: 0.053806, l4: 0.102604, l5: 0.230817, l6: 0.544125\n",
      "\n",
      "[epoch: 348/400, batch: 904/1000, ite: 46364] train loss: 1.1757, accuracy: 93.4698%, tar: 0.0251 \n",
      "l0: 0.025767, l1: 0.026902, l2: 0.033515, l3: 0.046494, l4: 0.093326, l5: 0.170497, l6: 0.317477\n",
      "\n",
      "[epoch: 348/400, batch: 912/1000, ite: 46365] train loss: 1.1753, accuracy: 95.4053%, tar: 0.0251 \n",
      "l0: 0.035448, l1: 0.037495, l2: 0.048485, l3: 0.073921, l4: 0.132397, l5: 0.240945, l6: 0.480230\n",
      "\n",
      "[epoch: 348/400, batch: 920/1000, ite: 46366] train loss: 1.1762, accuracy: 93.3865%, tar: 0.0252 \n",
      "l0: 0.022943, l1: 0.023835, l2: 0.030491, l3: 0.045716, l4: 0.082120, l5: 0.160810, l6: 0.367106\n",
      "\n",
      "[epoch: 348/400, batch: 928/1000, ite: 46367] train loss: 1.1761, accuracy: 94.5113%, tar: 0.0252 \n",
      "l0: 0.022929, l1: 0.024111, l2: 0.032720, l3: 0.047104, l4: 0.086730, l5: 0.178440, l6: 0.386855\n",
      "\n",
      "[epoch: 348/400, batch: 936/1000, ite: 46368] train loss: 1.1760, accuracy: 95.5908%, tar: 0.0251 \n",
      "l0: 0.024714, l1: 0.026704, l2: 0.035755, l3: 0.054244, l4: 0.110694, l5: 0.227689, l6: 0.398253\n",
      "\n",
      "[epoch: 348/400, batch: 944/1000, ite: 46369] train loss: 1.1763, accuracy: 94.8989%, tar: 0.0251 \n",
      "l0: 0.025215, l1: 0.026372, l2: 0.035044, l3: 0.051973, l4: 0.118436, l5: 0.229777, l6: 0.392341\n",
      "\n",
      "[epoch: 348/400, batch: 952/1000, ite: 46370] train loss: 1.1766, accuracy: 95.0637%, tar: 0.0251 \n",
      "l0: 0.027864, l1: 0.030784, l2: 0.040720, l3: 0.060921, l4: 0.113851, l5: 0.222130, l6: 0.445762\n",
      "\n",
      "[epoch: 348/400, batch: 960/1000, ite: 46371] train loss: 1.1772, accuracy: 93.7569%, tar: 0.0252 \n",
      "l0: 0.021670, l1: 0.022995, l2: 0.031119, l3: 0.048354, l4: 0.106353, l5: 0.197504, l6: 0.401320\n",
      "\n",
      "[epoch: 348/400, batch: 968/1000, ite: 46372] train loss: 1.1774, accuracy: 95.6143%, tar: 0.0251 \n",
      "l0: 0.027612, l1: 0.028750, l2: 0.036879, l3: 0.052775, l4: 0.093580, l5: 0.186189, l6: 0.407913\n",
      "\n",
      "[epoch: 348/400, batch: 976/1000, ite: 46373] train loss: 1.1775, accuracy: 94.0545%, tar: 0.0251 \n",
      "l0: 0.026110, l1: 0.027004, l2: 0.033756, l3: 0.046252, l4: 0.078568, l5: 0.130593, l6: 0.254142\n",
      "\n",
      "[epoch: 348/400, batch: 984/1000, ite: 46374] train loss: 1.1767, accuracy: 95.2383%, tar: 0.0252 \n",
      "l0: 0.023904, l1: 0.024887, l2: 0.030312, l3: 0.041375, l4: 0.071386, l5: 0.115593, l6: 0.252672\n",
      "\n",
      "[epoch: 348/400, batch: 992/1000, ite: 46375] train loss: 1.1758, accuracy: 95.7766%, tar: 0.0251 \n",
      "l0: 0.018682, l1: 0.019521, l2: 0.026341, l3: 0.038839, l4: 0.063597, l5: 0.125175, l6: 0.273006\n",
      "\n",
      "[epoch: 348/400, batch: 1000/1000, ite: 46376] train loss: 1.1749, accuracy: 95.8102%, tar: 0.0251 \n",
      "l0: 0.022626, l1: 0.024786, l2: 0.034285, l3: 0.053850, l4: 0.109501, l5: 0.216804, l6: 0.378525\n",
      "\n",
      "[epoch: 349/400, batch: 8/1000, ite: 46377] train loss: 1.1750, accuracy: 95.7169%, tar: 0.0251 \n",
      "l0: 0.023921, l1: 0.026051, l2: 0.035552, l3: 0.054971, l4: 0.108057, l5: 0.245623, l6: 0.488104\n",
      "\n",
      "[epoch: 349/400, batch: 16/1000, ite: 46378] train loss: 1.1758, accuracy: 93.6323%, tar: 0.0251 \n",
      "l0: 0.019493, l1: 0.020755, l2: 0.027262, l3: 0.042338, l4: 0.082905, l5: 0.172812, l6: 0.394059\n",
      "\n",
      "[epoch: 349/400, batch: 24/1000, ite: 46379] train loss: 1.1758, accuracy: 95.2012%, tar: 0.0251 \n",
      "l0: 0.028963, l1: 0.030310, l2: 0.042242, l3: 0.063507, l4: 0.113530, l5: 0.212266, l6: 0.424758\n",
      "\n",
      "[epoch: 349/400, batch: 32/1000, ite: 46380] train loss: 1.1762, accuracy: 94.2148%, tar: 0.0251 \n",
      "l0: 0.025615, l1: 0.028234, l2: 0.039501, l3: 0.063425, l4: 0.126706, l5: 0.231144, l6: 0.401313\n",
      "\n",
      "[epoch: 349/400, batch: 40/1000, ite: 46381] train loss: 1.1766, accuracy: 94.6913%, tar: 0.0251 \n",
      "l0: 0.021839, l1: 0.022847, l2: 0.030387, l3: 0.043929, l4: 0.074358, l5: 0.143021, l6: 0.306959\n",
      "\n",
      "[epoch: 349/400, batch: 48/1000, ite: 46382] train loss: 1.1760, accuracy: 95.6424%, tar: 0.0251 \n",
      "l0: 0.023906, l1: 0.025161, l2: 0.033407, l3: 0.048640, l4: 0.087083, l5: 0.183484, l6: 0.396101\n",
      "\n",
      "[epoch: 349/400, batch: 56/1000, ite: 46383] train loss: 1.1761, accuracy: 93.9717%, tar: 0.0251 \n",
      "l0: 0.017801, l1: 0.019541, l2: 0.028062, l3: 0.045790, l4: 0.089182, l5: 0.177423, l6: 0.384644\n",
      "\n",
      "[epoch: 349/400, batch: 64/1000, ite: 46384] train loss: 1.1760, accuracy: 95.3007%, tar: 0.0251 \n",
      "l0: 0.026267, l1: 0.027282, l2: 0.034425, l3: 0.048319, l4: 0.083606, l5: 0.157725, l6: 0.298760\n",
      "\n",
      "[epoch: 349/400, batch: 72/1000, ite: 46385] train loss: 1.1755, accuracy: 94.8643%, tar: 0.0251 \n",
      "l0: 0.024664, l1: 0.025673, l2: 0.034029, l3: 0.059379, l4: 0.116824, l5: 0.206990, l6: 0.460730\n",
      "\n",
      "[epoch: 349/400, batch: 80/1000, ite: 46386] train loss: 1.1760, accuracy: 94.3634%, tar: 0.0251 \n",
      "l0: 0.021208, l1: 0.022766, l2: 0.030964, l3: 0.050551, l4: 0.085480, l5: 0.163672, l6: 0.365022\n",
      "\n",
      "[epoch: 349/400, batch: 88/1000, ite: 46387] train loss: 1.1758, accuracy: 95.5609%, tar: 0.0251 \n",
      "l0: 0.025486, l1: 0.026440, l2: 0.035064, l3: 0.050792, l4: 0.089461, l5: 0.219368, l6: 0.464395\n",
      "\n",
      "[epoch: 349/400, batch: 96/1000, ite: 46388] train loss: 1.1764, accuracy: 93.2441%, tar: 0.0251 \n",
      "l0: 0.026179, l1: 0.027546, l2: 0.036977, l3: 0.057909, l4: 0.106453, l5: 0.197908, l6: 0.380041\n",
      "\n",
      "[epoch: 349/400, batch: 104/1000, ite: 46389] train loss: 1.1765, accuracy: 94.9385%, tar: 0.0251 \n",
      "l0: 0.020304, l1: 0.021171, l2: 0.027902, l3: 0.039793, l4: 0.074520, l5: 0.135184, l6: 0.310687\n",
      "\n",
      "[epoch: 349/400, batch: 112/1000, ite: 46390] train loss: 1.1759, accuracy: 95.4392%, tar: 0.0251 \n",
      "l0: 0.025504, l1: 0.027398, l2: 0.035254, l3: 0.052072, l4: 0.093349, l5: 0.168454, l6: 0.342060\n",
      "\n",
      "[epoch: 349/400, batch: 120/1000, ite: 46391] train loss: 1.1757, accuracy: 95.5047%, tar: 0.0251 \n",
      "l0: 0.016170, l1: 0.016975, l2: 0.023390, l3: 0.035395, l4: 0.062874, l5: 0.142752, l6: 0.297987\n",
      "\n",
      "[epoch: 349/400, batch: 128/1000, ite: 46392] train loss: 1.1750, accuracy: 95.7060%, tar: 0.0250 \n",
      "l0: 0.031387, l1: 0.032706, l2: 0.041412, l3: 0.057325, l4: 0.091872, l5: 0.179886, l6: 0.394820\n",
      "\n",
      "[epoch: 349/400, batch: 136/1000, ite: 46393] train loss: 1.1751, accuracy: 93.8500%, tar: 0.0251 \n",
      "l0: 0.030704, l1: 0.032675, l2: 0.042397, l3: 0.060624, l4: 0.120830, l5: 0.249171, l6: 0.468640\n",
      "\n",
      "[epoch: 349/400, batch: 144/1000, ite: 46394] train loss: 1.1759, accuracy: 93.6143%, tar: 0.0251 \n",
      "l0: 0.021564, l1: 0.023069, l2: 0.029795, l3: 0.045987, l4: 0.093985, l5: 0.190832, l6: 0.355417\n",
      "\n",
      "[epoch: 349/400, batch: 152/1000, ite: 46395] train loss: 1.1757, accuracy: 94.9559%, tar: 0.0251 \n",
      "l0: 0.025150, l1: 0.026532, l2: 0.034801, l3: 0.049397, l4: 0.087662, l5: 0.170391, l6: 0.382304\n",
      "\n",
      "[epoch: 349/400, batch: 160/1000, ite: 46396] train loss: 1.1757, accuracy: 94.5954%, tar: 0.0251 \n",
      "l0: 0.020044, l1: 0.020706, l2: 0.027028, l3: 0.040368, l4: 0.068149, l5: 0.122252, l6: 0.247778\n",
      "\n",
      "[epoch: 349/400, batch: 168/1000, ite: 46397] train loss: 1.1747, accuracy: 95.8711%, tar: 0.0251 \n",
      "l0: 0.025118, l1: 0.026415, l2: 0.034148, l3: 0.049939, l4: 0.086226, l5: 0.168190, l6: 0.354515\n",
      "\n",
      "[epoch: 349/400, batch: 176/1000, ite: 46398] train loss: 1.1746, accuracy: 94.6130%, tar: 0.0251 \n",
      "l0: 0.019518, l1: 0.020387, l2: 0.026152, l3: 0.038193, l4: 0.074193, l5: 0.144798, l6: 0.336763\n",
      "\n",
      "[epoch: 349/400, batch: 184/1000, ite: 46399] train loss: 1.1741, accuracy: 95.2120%, tar: 0.0250 \n",
      "l0: 0.021985, l1: 0.023253, l2: 0.030542, l3: 0.047692, l4: 0.091083, l5: 0.173205, l6: 0.354146\n",
      "\n",
      "[epoch: 349/400, batch: 192/1000, ite: 46400] train loss: 1.1739, accuracy: 94.7952%, tar: 0.0250 \n",
      "l0: 0.025871, l1: 0.027552, l2: 0.036379, l3: 0.054680, l4: 0.101950, l5: 0.216768, l6: 0.447028\n",
      "\n",
      "[epoch: 349/400, batch: 200/1000, ite: 46401] train loss: 1.1744, accuracy: 93.8090%, tar: 0.0250 \n",
      "l0: 0.027116, l1: 0.027868, l2: 0.034085, l3: 0.047867, l4: 0.080219, l5: 0.139817, l6: 0.296051\n",
      "\n",
      "[epoch: 349/400, batch: 208/1000, ite: 46402] train loss: 1.1738, accuracy: 95.2915%, tar: 0.0250 \n",
      "l0: 0.027262, l1: 0.028080, l2: 0.033595, l3: 0.044367, l4: 0.073006, l5: 0.151628, l6: 0.400884\n",
      "\n",
      "[epoch: 349/400, batch: 216/1000, ite: 46403] train loss: 1.1738, accuracy: 94.1436%, tar: 0.0250 \n",
      "l0: 0.019642, l1: 0.020929, l2: 0.028081, l3: 0.046525, l4: 0.092186, l5: 0.172456, l6: 0.300011\n",
      "\n",
      "[epoch: 349/400, batch: 224/1000, ite: 46404] train loss: 1.1734, accuracy: 95.8782%, tar: 0.0250 \n",
      "l0: 0.021142, l1: 0.021727, l2: 0.029204, l3: 0.041375, l4: 0.078852, l5: 0.202561, l6: 0.410949\n",
      "\n",
      "[epoch: 349/400, batch: 232/1000, ite: 46405] train loss: 1.1735, accuracy: 94.2457%, tar: 0.0250 \n",
      "l0: 0.023110, l1: 0.024573, l2: 0.034137, l3: 0.050944, l4: 0.100604, l5: 0.205600, l6: 0.396799\n",
      "\n",
      "[epoch: 349/400, batch: 240/1000, ite: 46406] train loss: 1.1736, accuracy: 95.1124%, tar: 0.0250 \n",
      "l0: 0.029281, l1: 0.031534, l2: 0.042440, l3: 0.061794, l4: 0.118194, l5: 0.219498, l6: 0.469086\n",
      "\n",
      "[epoch: 349/400, batch: 248/1000, ite: 46407] train loss: 1.1743, accuracy: 93.7067%, tar: 0.0250 \n",
      "l0: 0.022724, l1: 0.024388, l2: 0.032149, l3: 0.049268, l4: 0.093443, l5: 0.189577, l6: 0.324251\n",
      "\n",
      "[epoch: 349/400, batch: 256/1000, ite: 46408] train loss: 1.1740, accuracy: 95.6867%, tar: 0.0250 \n",
      "l0: 0.021963, l1: 0.023158, l2: 0.028960, l3: 0.047748, l4: 0.094296, l5: 0.166873, l6: 0.346325\n",
      "\n",
      "[epoch: 349/400, batch: 264/1000, ite: 46409] train loss: 1.1738, accuracy: 94.6252%, tar: 0.0250 \n",
      "l0: 0.020456, l1: 0.021295, l2: 0.028618, l3: 0.041844, l4: 0.065462, l5: 0.115488, l6: 0.226940\n",
      "\n",
      "[epoch: 349/400, batch: 272/1000, ite: 46410] train loss: 1.1728, accuracy: 96.1139%, tar: 0.0250 \n",
      "l0: 0.020495, l1: 0.021590, l2: 0.029273, l3: 0.044315, l4: 0.076657, l5: 0.174116, l6: 0.375787\n",
      "\n",
      "[epoch: 349/400, batch: 280/1000, ite: 46411] train loss: 1.1726, accuracy: 95.6002%, tar: 0.0250 \n",
      "l0: 0.031423, l1: 0.033283, l2: 0.044724, l3: 0.066023, l4: 0.118661, l5: 0.267250, l6: 0.561515\n",
      "\n",
      "[epoch: 349/400, batch: 288/1000, ite: 46412] train loss: 1.1739, accuracy: 93.7006%, tar: 0.0250 \n",
      "l0: 0.024514, l1: 0.026157, l2: 0.035165, l3: 0.048672, l4: 0.089828, l5: 0.200999, l6: 0.406273\n",
      "\n",
      "[epoch: 349/400, batch: 296/1000, ite: 46413] train loss: 1.1741, accuracy: 94.8388%, tar: 0.0250 \n",
      "l0: 0.022549, l1: 0.023918, l2: 0.030678, l3: 0.049305, l4: 0.100954, l5: 0.228655, l6: 0.527095\n",
      "\n",
      "[epoch: 349/400, batch: 304/1000, ite: 46414] train loss: 1.1749, accuracy: 94.0691%, tar: 0.0250 \n",
      "l0: 0.023987, l1: 0.025464, l2: 0.033883, l3: 0.051935, l4: 0.099087, l5: 0.214339, l6: 0.459898\n",
      "\n",
      "[epoch: 349/400, batch: 312/1000, ite: 46415] train loss: 1.1754, accuracy: 94.4074%, tar: 0.0250 \n",
      "l0: 0.018592, l1: 0.020092, l2: 0.027552, l3: 0.039288, l4: 0.077129, l5: 0.140785, l6: 0.288645\n",
      "\n",
      "[epoch: 349/400, batch: 320/1000, ite: 46416] train loss: 1.1747, accuracy: 96.2423%, tar: 0.0250 \n",
      "l0: 0.022405, l1: 0.023167, l2: 0.030274, l3: 0.043167, l4: 0.073681, l5: 0.162794, l6: 0.330687\n",
      "\n",
      "[epoch: 349/400, batch: 328/1000, ite: 46417] train loss: 1.1744, accuracy: 95.0945%, tar: 0.0250 \n",
      "l0: 0.024191, l1: 0.024802, l2: 0.031307, l3: 0.044487, l4: 0.074087, l5: 0.137791, l6: 0.319942\n",
      "\n",
      "[epoch: 349/400, batch: 336/1000, ite: 46418] train loss: 1.1739, accuracy: 94.9158%, tar: 0.0250 \n",
      "l0: 0.025300, l1: 0.026788, l2: 0.036479, l3: 0.055455, l4: 0.095873, l5: 0.177699, l6: 0.341272\n",
      "\n",
      "[epoch: 349/400, batch: 344/1000, ite: 46419] train loss: 1.1737, accuracy: 95.3130%, tar: 0.0250 \n",
      "l0: 0.024806, l1: 0.026359, l2: 0.035775, l3: 0.055515, l4: 0.101139, l5: 0.194088, l6: 0.383827\n",
      "\n",
      "[epoch: 349/400, batch: 352/1000, ite: 46420] train loss: 1.1738, accuracy: 95.0549%, tar: 0.0250 \n",
      "l0: 0.024652, l1: 0.026989, l2: 0.036397, l3: 0.056540, l4: 0.095504, l5: 0.202273, l6: 0.416153\n",
      "\n",
      "[epoch: 349/400, batch: 360/1000, ite: 46421] train loss: 1.1741, accuracy: 94.8755%, tar: 0.0250 \n",
      "l0: 0.025597, l1: 0.027208, l2: 0.036129, l3: 0.057506, l4: 0.121084, l5: 0.226842, l6: 0.439407\n",
      "\n",
      "[epoch: 349/400, batch: 368/1000, ite: 46422] train loss: 1.1746, accuracy: 94.6039%, tar: 0.0250 \n",
      "l0: 0.021643, l1: 0.023166, l2: 0.031394, l3: 0.051561, l4: 0.111921, l5: 0.203500, l6: 0.357240\n",
      "\n",
      "[epoch: 349/400, batch: 376/1000, ite: 46423] train loss: 1.1745, accuracy: 95.2280%, tar: 0.0250 \n",
      "l0: 0.025001, l1: 0.026032, l2: 0.033055, l3: 0.048859, l4: 0.096757, l5: 0.178512, l6: 0.333132\n",
      "\n",
      "[epoch: 349/400, batch: 384/1000, ite: 46424] train loss: 1.1743, accuracy: 94.6515%, tar: 0.0250 \n",
      "l0: 0.023863, l1: 0.025940, l2: 0.033613, l3: 0.053898, l4: 0.127460, l5: 0.272330, l6: 0.466826\n",
      "\n",
      "[epoch: 349/400, batch: 392/1000, ite: 46425] train loss: 1.1750, accuracy: 94.3569%, tar: 0.0250 \n",
      "l0: 0.026279, l1: 0.028859, l2: 0.040356, l3: 0.061356, l4: 0.119101, l5: 0.225330, l6: 0.451650\n",
      "\n",
      "[epoch: 349/400, batch: 400/1000, ite: 46426] train loss: 1.1756, accuracy: 94.4462%, tar: 0.0250 \n",
      "l0: 0.021295, l1: 0.022614, l2: 0.029754, l3: 0.048024, l4: 0.092341, l5: 0.199520, l6: 0.407236\n",
      "\n",
      "[epoch: 349/400, batch: 408/1000, ite: 46427] train loss: 1.1757, accuracy: 93.7776%, tar: 0.0250 \n",
      "l0: 0.014800, l1: 0.015318, l2: 0.020935, l3: 0.033109, l4: 0.058151, l5: 0.150475, l6: 0.268836\n",
      "\n",
      "[epoch: 349/400, batch: 416/1000, ite: 46428] train loss: 1.1749, accuracy: 96.1576%, tar: 0.0249 \n",
      "l0: 0.030967, l1: 0.032719, l2: 0.041091, l3: 0.058708, l4: 0.110895, l5: 0.227416, l6: 0.485555\n",
      "\n",
      "[epoch: 349/400, batch: 424/1000, ite: 46429] train loss: 1.1756, accuracy: 93.4702%, tar: 0.0250 \n",
      "l0: 0.019753, l1: 0.020862, l2: 0.026915, l3: 0.040337, l4: 0.073072, l5: 0.144296, l6: 0.313347\n",
      "\n",
      "[epoch: 349/400, batch: 432/1000, ite: 46430] train loss: 1.1751, accuracy: 95.5913%, tar: 0.0249 \n",
      "l0: 0.026416, l1: 0.028439, l2: 0.038342, l3: 0.065161, l4: 0.161175, l5: 0.247071, l6: 0.525515\n",
      "\n",
      "[epoch: 349/400, batch: 440/1000, ite: 46431] train loss: 1.1762, accuracy: 93.2446%, tar: 0.0249 \n",
      "l0: 0.025565, l1: 0.027081, l2: 0.035923, l3: 0.050995, l4: 0.078926, l5: 0.138939, l6: 0.335698\n",
      "\n",
      "[epoch: 349/400, batch: 448/1000, ite: 46432] train loss: 1.1758, accuracy: 94.5427%, tar: 0.0249 \n",
      "l0: 0.031387, l1: 0.032886, l2: 0.042837, l3: 0.063854, l4: 0.113204, l5: 0.228831, l6: 0.415817\n",
      "\n",
      "[epoch: 349/400, batch: 456/1000, ite: 46433] train loss: 1.1762, accuracy: 93.6825%, tar: 0.0250 \n",
      "l0: 0.024105, l1: 0.025167, l2: 0.033592, l3: 0.049746, l4: 0.091685, l5: 0.162238, l6: 0.336442\n",
      "\n",
      "[epoch: 349/400, batch: 464/1000, ite: 46434] train loss: 1.1760, accuracy: 94.7732%, tar: 0.0250 \n",
      "l0: 0.020147, l1: 0.021559, l2: 0.030650, l3: 0.049749, l4: 0.093974, l5: 0.178362, l6: 0.372376\n",
      "\n",
      "[epoch: 349/400, batch: 472/1000, ite: 46435] train loss: 1.1759, accuracy: 94.9366%, tar: 0.0249 \n",
      "l0: 0.024925, l1: 0.026044, l2: 0.033461, l3: 0.048327, l4: 0.088296, l5: 0.182119, l6: 0.356768\n",
      "\n",
      "[epoch: 349/400, batch: 480/1000, ite: 46436] train loss: 1.1758, accuracy: 95.0561%, tar: 0.0249 \n",
      "l0: 0.027818, l1: 0.028972, l2: 0.037092, l3: 0.056282, l4: 0.099284, l5: 0.193055, l6: 0.383273\n",
      "\n",
      "[epoch: 349/400, batch: 488/1000, ite: 46437] train loss: 1.1758, accuracy: 94.2225%, tar: 0.0250 \n",
      "l0: 0.026900, l1: 0.028317, l2: 0.038397, l3: 0.056692, l4: 0.117533, l5: 0.257991, l6: 0.475549\n",
      "\n",
      "[epoch: 349/400, batch: 496/1000, ite: 46438] train loss: 1.1765, accuracy: 93.6838%, tar: 0.0250 \n",
      "l0: 0.029445, l1: 0.031006, l2: 0.040656, l3: 0.060224, l4: 0.110753, l5: 0.254299, l6: 0.496257\n",
      "\n",
      "[epoch: 349/400, batch: 504/1000, ite: 46439] train loss: 1.1773, accuracy: 92.6186%, tar: 0.0250 \n",
      "l0: 0.021232, l1: 0.022371, l2: 0.028406, l3: 0.042161, l4: 0.070991, l5: 0.152877, l6: 0.315543\n",
      "\n",
      "[epoch: 349/400, batch: 512/1000, ite: 46440] train loss: 1.1769, accuracy: 95.5445%, tar: 0.0250 \n",
      "l0: 0.019247, l1: 0.020163, l2: 0.025331, l3: 0.039141, l4: 0.066186, l5: 0.132124, l6: 0.281827\n",
      "\n",
      "[epoch: 349/400, batch: 520/1000, ite: 46441] train loss: 1.1762, accuracy: 95.5226%, tar: 0.0249 \n",
      "l0: 0.023911, l1: 0.025359, l2: 0.033169, l3: 0.048045, l4: 0.092109, l5: 0.175195, l6: 0.364560\n",
      "\n",
      "[epoch: 349/400, batch: 528/1000, ite: 46442] train loss: 1.1761, accuracy: 94.8071%, tar: 0.0249 \n",
      "l0: 0.019537, l1: 0.020144, l2: 0.025209, l3: 0.035666, l4: 0.065383, l5: 0.129857, l6: 0.271160\n",
      "\n",
      "[epoch: 349/400, batch: 536/1000, ite: 46443] train loss: 1.1753, accuracy: 95.9736%, tar: 0.0249 \n",
      "l0: 0.035686, l1: 0.037333, l2: 0.047603, l3: 0.068266, l4: 0.122031, l5: 0.259299, l6: 0.541021\n",
      "\n",
      "[epoch: 349/400, batch: 544/1000, ite: 46444] train loss: 1.1764, accuracy: 92.8164%, tar: 0.0250 \n",
      "l0: 0.022012, l1: 0.023625, l2: 0.033651, l3: 0.051985, l4: 0.089664, l5: 0.173155, l6: 0.363996\n",
      "\n",
      "[epoch: 349/400, batch: 552/1000, ite: 46445] train loss: 1.1763, accuracy: 95.5888%, tar: 0.0250 \n",
      "l0: 0.028265, l1: 0.029908, l2: 0.038865, l3: 0.066458, l4: 0.131990, l5: 0.320305, l6: 0.587954\n",
      "\n",
      "[epoch: 349/400, batch: 560/1000, ite: 46446] train loss: 1.1777, accuracy: 93.2383%, tar: 0.0250 \n",
      "l0: 0.026862, l1: 0.028676, l2: 0.035778, l3: 0.057281, l4: 0.123124, l5: 0.230024, l6: 0.397752\n",
      "\n",
      "[epoch: 349/400, batch: 568/1000, ite: 46447] train loss: 1.1779, accuracy: 94.6138%, tar: 0.0250 \n",
      "l0: 0.028055, l1: 0.029596, l2: 0.038307, l3: 0.053819, l4: 0.098718, l5: 0.196986, l6: 0.407473\n",
      "\n",
      "[epoch: 349/400, batch: 576/1000, ite: 46448] train loss: 1.1781, accuracy: 94.6482%, tar: 0.0250 \n",
      "l0: 0.021831, l1: 0.022556, l2: 0.029295, l3: 0.042299, l4: 0.070473, l5: 0.122979, l6: 0.247828\n",
      "\n",
      "[epoch: 349/400, batch: 584/1000, ite: 46449] train loss: 1.1773, accuracy: 95.6109%, tar: 0.0250 \n",
      "l0: 0.022484, l1: 0.024497, l2: 0.031842, l3: 0.048759, l4: 0.091152, l5: 0.186112, l6: 0.359231\n",
      "\n",
      "[epoch: 349/400, batch: 592/1000, ite: 46450] train loss: 1.1772, accuracy: 95.5815%, tar: 0.0250 \n",
      "l0: 0.019967, l1: 0.021232, l2: 0.029990, l3: 0.046157, l4: 0.097316, l5: 0.168928, l6: 0.284554\n",
      "\n",
      "[epoch: 349/400, batch: 600/1000, ite: 46451] train loss: 1.1767, accuracy: 95.5974%, tar: 0.0249 \n",
      "l0: 0.021257, l1: 0.022069, l2: 0.028355, l3: 0.038720, l4: 0.060991, l5: 0.124315, l6: 0.302614\n",
      "\n",
      "[epoch: 349/400, batch: 608/1000, ite: 46452] train loss: 1.1761, accuracy: 96.1145%, tar: 0.0249 \n",
      "l0: 0.027883, l1: 0.028838, l2: 0.037241, l3: 0.051694, l4: 0.086903, l5: 0.174466, l6: 0.444329\n",
      "\n",
      "[epoch: 349/400, batch: 616/1000, ite: 46453] train loss: 1.1764, accuracy: 93.9586%, tar: 0.0249 \n",
      "l0: 0.022436, l1: 0.023630, l2: 0.032121, l3: 0.046538, l4: 0.079021, l5: 0.176966, l6: 0.328726\n",
      "\n",
      "[epoch: 349/400, batch: 624/1000, ite: 46454] train loss: 1.1761, accuracy: 95.9216%, tar: 0.0249 \n",
      "l0: 0.024841, l1: 0.026539, l2: 0.033513, l3: 0.053992, l4: 0.100311, l5: 0.224181, l6: 0.474109\n",
      "\n",
      "[epoch: 349/400, batch: 632/1000, ite: 46455] train loss: 1.1766, accuracy: 93.1796%, tar: 0.0249 \n",
      "l0: 0.026913, l1: 0.028764, l2: 0.037456, l3: 0.053547, l4: 0.102681, l5: 0.219140, l6: 0.390958\n",
      "\n",
      "[epoch: 349/400, batch: 640/1000, ite: 46456] train loss: 1.1768, accuracy: 94.7513%, tar: 0.0249 \n",
      "l0: 0.021616, l1: 0.022617, l2: 0.028746, l3: 0.041107, l4: 0.072994, l5: 0.129769, l6: 0.280798\n",
      "\n",
      "[epoch: 349/400, batch: 648/1000, ite: 46457] train loss: 1.1762, accuracy: 95.1267%, tar: 0.0249 \n",
      "l0: 0.026959, l1: 0.028652, l2: 0.035930, l3: 0.052367, l4: 0.093432, l5: 0.188118, l6: 0.418432\n",
      "\n",
      "[epoch: 349/400, batch: 656/1000, ite: 46458] train loss: 1.1764, accuracy: 94.1733%, tar: 0.0249 \n",
      "l0: 0.023595, l1: 0.025074, l2: 0.034408, l3: 0.050889, l4: 0.099013, l5: 0.211507, l6: 0.401811\n",
      "\n",
      "[epoch: 349/400, batch: 664/1000, ite: 46459] train loss: 1.1766, accuracy: 94.9511%, tar: 0.0249 \n",
      "l0: 0.020086, l1: 0.022451, l2: 0.033090, l3: 0.056688, l4: 0.113284, l5: 0.226046, l6: 0.434476\n",
      "\n",
      "[epoch: 349/400, batch: 672/1000, ite: 46460] train loss: 1.1770, accuracy: 95.8583%, tar: 0.0249 \n",
      "l0: 0.022645, l1: 0.023890, l2: 0.032266, l3: 0.046896, l4: 0.094573, l5: 0.171843, l6: 0.285092\n",
      "\n",
      "[epoch: 349/400, batch: 680/1000, ite: 46461] train loss: 1.1765, accuracy: 95.6064%, tar: 0.0249 \n",
      "l0: 0.021914, l1: 0.023436, l2: 0.030104, l3: 0.039402, l4: 0.068559, l5: 0.134185, l6: 0.296092\n",
      "\n",
      "[epoch: 349/400, batch: 688/1000, ite: 46462] train loss: 1.1759, accuracy: 96.2149%, tar: 0.0249 \n",
      "l0: 0.023905, l1: 0.026176, l2: 0.036359, l3: 0.057230, l4: 0.109093, l5: 0.205330, l6: 0.357395\n",
      "\n",
      "[epoch: 349/400, batch: 696/1000, ite: 46463] train loss: 1.1760, accuracy: 95.4254%, tar: 0.0249 \n",
      "l0: 0.019213, l1: 0.020093, l2: 0.028439, l3: 0.039827, l4: 0.073296, l5: 0.161750, l6: 0.331984\n",
      "\n",
      "[epoch: 349/400, batch: 704/1000, ite: 46464] train loss: 1.1756, accuracy: 95.5174%, tar: 0.0249 \n",
      "l0: 0.019098, l1: 0.020468, l2: 0.028831, l3: 0.041645, l4: 0.069556, l5: 0.131254, l6: 0.264899\n",
      "\n",
      "[epoch: 349/400, batch: 712/1000, ite: 46465] train loss: 1.1749, accuracy: 95.7330%, tar: 0.0249 \n",
      "l0: 0.027614, l1: 0.029141, l2: 0.036924, l3: 0.054092, l4: 0.100539, l5: 0.191733, l6: 0.366383\n",
      "\n",
      "[epoch: 349/400, batch: 720/1000, ite: 46466] train loss: 1.1749, accuracy: 94.3490%, tar: 0.0249 \n",
      "l0: 0.028535, l1: 0.029912, l2: 0.038836, l3: 0.054598, l4: 0.087112, l5: 0.160123, l6: 0.359408\n",
      "\n",
      "[epoch: 349/400, batch: 728/1000, ite: 46467] train loss: 1.1748, accuracy: 95.0019%, tar: 0.0249 \n",
      "l0: 0.020336, l1: 0.021224, l2: 0.028355, l3: 0.042120, l4: 0.071959, l5: 0.133623, l6: 0.281577\n",
      "\n",
      "[epoch: 349/400, batch: 736/1000, ite: 46468] train loss: 1.1741, accuracy: 95.8666%, tar: 0.0249 \n",
      "l0: 0.027334, l1: 0.029201, l2: 0.035908, l3: 0.054309, l4: 0.103481, l5: 0.207412, l6: 0.433320\n",
      "\n",
      "[epoch: 349/400, batch: 744/1000, ite: 46469] train loss: 1.1745, accuracy: 93.6160%, tar: 0.0249 \n",
      "l0: 0.021684, l1: 0.022058, l2: 0.027966, l3: 0.037257, l4: 0.055594, l5: 0.104335, l6: 0.248960\n",
      "\n",
      "[epoch: 349/400, batch: 752/1000, ite: 46470] train loss: 1.1736, accuracy: 96.3229%, tar: 0.0249 \n",
      "l0: 0.021470, l1: 0.022475, l2: 0.026971, l3: 0.035666, l4: 0.059006, l5: 0.113428, l6: 0.245522\n",
      "\n",
      "[epoch: 349/400, batch: 760/1000, ite: 46471] train loss: 1.1728, accuracy: 95.6081%, tar: 0.0249 \n",
      "l0: 0.019141, l1: 0.020491, l2: 0.026450, l3: 0.039259, l4: 0.076158, l5: 0.163695, l6: 0.371191\n",
      "\n",
      "[epoch: 349/400, batch: 768/1000, ite: 46472] train loss: 1.1726, accuracy: 95.5021%, tar: 0.0249 \n",
      "l0: 0.018436, l1: 0.019312, l2: 0.025992, l3: 0.039600, l4: 0.064630, l5: 0.104694, l6: 0.221267\n",
      "\n",
      "[epoch: 349/400, batch: 776/1000, ite: 46473] train loss: 1.1717, accuracy: 96.1661%, tar: 0.0249 \n",
      "l0: 0.028739, l1: 0.030125, l2: 0.039213, l3: 0.058418, l4: 0.105431, l5: 0.183890, l6: 0.400747\n",
      "\n",
      "[epoch: 349/400, batch: 784/1000, ite: 46474] train loss: 1.1718, accuracy: 94.4425%, tar: 0.0249 \n",
      "l0: 0.028597, l1: 0.029444, l2: 0.038757, l3: 0.054749, l4: 0.093138, l5: 0.167585, l6: 0.382014\n",
      "\n",
      "[epoch: 349/400, batch: 792/1000, ite: 46475] train loss: 1.1718, accuracy: 93.9742%, tar: 0.0249 \n",
      "l0: 0.020833, l1: 0.022243, l2: 0.030140, l3: 0.046809, l4: 0.090629, l5: 0.173422, l6: 0.352292\n",
      "\n",
      "[epoch: 349/400, batch: 800/1000, ite: 46476] train loss: 1.1717, accuracy: 95.5451%, tar: 0.0249 \n",
      "l0: 0.020969, l1: 0.021942, l2: 0.029450, l3: 0.044678, l4: 0.076447, l5: 0.160112, l6: 0.321528\n",
      "\n",
      "[epoch: 349/400, batch: 808/1000, ite: 46477] train loss: 1.1713, accuracy: 95.4075%, tar: 0.0249 \n",
      "l0: 0.024661, l1: 0.026516, l2: 0.035577, l3: 0.051491, l4: 0.098637, l5: 0.199897, l6: 0.404523\n",
      "\n",
      "[epoch: 349/400, batch: 816/1000, ite: 46478] train loss: 1.1715, accuracy: 94.7922%, tar: 0.0249 \n",
      "l0: 0.027656, l1: 0.028944, l2: 0.039167, l3: 0.059199, l4: 0.111036, l5: 0.235017, l6: 0.472719\n",
      "\n",
      "[epoch: 349/400, batch: 824/1000, ite: 46479] train loss: 1.1721, accuracy: 92.6392%, tar: 0.0249 \n",
      "l0: 0.025940, l1: 0.027597, l2: 0.037542, l3: 0.057205, l4: 0.094664, l5: 0.174929, l6: 0.352940\n",
      "\n",
      "[epoch: 349/400, batch: 832/1000, ite: 46480] train loss: 1.1720, accuracy: 95.5919%, tar: 0.0249 \n",
      "l0: 0.017964, l1: 0.020203, l2: 0.027803, l3: 0.044834, l4: 0.079041, l5: 0.141231, l6: 0.251045\n",
      "\n",
      "[epoch: 349/400, batch: 840/1000, ite: 46481] train loss: 1.1713, accuracy: 96.3940%, tar: 0.0249 \n",
      "l0: 0.026580, l1: 0.027396, l2: 0.035744, l3: 0.053407, l4: 0.096145, l5: 0.171598, l6: 0.362927\n",
      "\n",
      "[epoch: 349/400, batch: 848/1000, ite: 46482] train loss: 1.1712, accuracy: 94.0370%, tar: 0.0249 \n",
      "l0: 0.021977, l1: 0.023788, l2: 0.030271, l3: 0.048736, l4: 0.096535, l5: 0.216207, l6: 0.387347\n",
      "\n",
      "[epoch: 349/400, batch: 856/1000, ite: 46483] train loss: 1.1713, accuracy: 94.7267%, tar: 0.0248 \n",
      "l0: 0.024344, l1: 0.025275, l2: 0.033253, l3: 0.048507, l4: 0.084686, l5: 0.175238, l6: 0.348109\n",
      "\n",
      "[epoch: 349/400, batch: 864/1000, ite: 46484] train loss: 1.1712, accuracy: 95.1884%, tar: 0.0248 \n",
      "l0: 0.025890, l1: 0.027015, l2: 0.035207, l3: 0.051800, l4: 0.096134, l5: 0.203466, l6: 0.427335\n",
      "\n",
      "[epoch: 349/400, batch: 872/1000, ite: 46485] train loss: 1.1714, accuracy: 94.5321%, tar: 0.0248 \n",
      "l0: 0.020713, l1: 0.022381, l2: 0.029283, l3: 0.042732, l4: 0.077605, l5: 0.181147, l6: 0.365533\n",
      "\n",
      "[epoch: 349/400, batch: 880/1000, ite: 46486] train loss: 1.1713, accuracy: 95.0033%, tar: 0.0248 \n",
      "l0: 0.028596, l1: 0.029987, l2: 0.038826, l3: 0.055623, l4: 0.114640, l5: 0.234429, l6: 0.468432\n",
      "\n",
      "[epoch: 349/400, batch: 888/1000, ite: 46487] train loss: 1.1719, accuracy: 93.2109%, tar: 0.0248 \n",
      "l0: 0.021236, l1: 0.022766, l2: 0.029563, l3: 0.046554, l4: 0.087373, l5: 0.192933, l6: 0.336433\n",
      "\n",
      "[epoch: 349/400, batch: 896/1000, ite: 46488] train loss: 1.1717, accuracy: 95.2311%, tar: 0.0248 \n",
      "l0: 0.025994, l1: 0.027608, l2: 0.037308, l3: 0.058170, l4: 0.120524, l5: 0.254582, l6: 0.479471\n",
      "\n",
      "[epoch: 349/400, batch: 904/1000, ite: 46489] train loss: 1.1723, accuracy: 93.4784%, tar: 0.0248 \n",
      "l0: 0.030256, l1: 0.031622, l2: 0.041388, l3: 0.065503, l4: 0.118364, l5: 0.227467, l6: 0.428454\n",
      "\n",
      "[epoch: 349/400, batch: 912/1000, ite: 46490] train loss: 1.1728, accuracy: 94.3519%, tar: 0.0249 \n",
      "l0: 0.021905, l1: 0.022900, l2: 0.029740, l3: 0.043827, l4: 0.072918, l5: 0.132333, l6: 0.319648\n",
      "\n",
      "[epoch: 349/400, batch: 920/1000, ite: 46491] train loss: 1.1724, accuracy: 95.6661%, tar: 0.0248 \n",
      "l0: 0.024013, l1: 0.024843, l2: 0.033037, l3: 0.047981, l4: 0.106179, l5: 0.191150, l6: 0.352335\n",
      "\n",
      "[epoch: 349/400, batch: 928/1000, ite: 46492] train loss: 1.1723, accuracy: 95.7327%, tar: 0.0248 \n",
      "l0: 0.021118, l1: 0.022232, l2: 0.027719, l3: 0.041448, l4: 0.075951, l5: 0.167913, l6: 0.444716\n",
      "\n",
      "[epoch: 349/400, batch: 936/1000, ite: 46493] train loss: 1.1724, accuracy: 94.4014%, tar: 0.0248 \n",
      "l0: 0.025418, l1: 0.026633, l2: 0.032987, l3: 0.045719, l4: 0.081285, l5: 0.172147, l6: 0.372184\n",
      "\n",
      "[epoch: 349/400, batch: 944/1000, ite: 46494] train loss: 1.1724, accuracy: 95.3403%, tar: 0.0248 \n",
      "l0: 0.026924, l1: 0.027552, l2: 0.034263, l3: 0.048913, l4: 0.083878, l5: 0.160569, l6: 0.350090\n",
      "\n",
      "[epoch: 349/400, batch: 952/1000, ite: 46495] train loss: 1.1722, accuracy: 94.7349%, tar: 0.0248 \n",
      "l0: 0.024099, l1: 0.025211, l2: 0.034000, l3: 0.051416, l4: 0.098863, l5: 0.189876, l6: 0.392671\n",
      "\n",
      "[epoch: 349/400, batch: 960/1000, ite: 46496] train loss: 1.1723, accuracy: 94.6619%, tar: 0.0248 \n",
      "l0: 0.019717, l1: 0.020524, l2: 0.025952, l3: 0.036349, l4: 0.061351, l5: 0.107965, l6: 0.308158\n",
      "\n",
      "[epoch: 349/400, batch: 968/1000, ite: 46497] train loss: 1.1717, accuracy: 95.7682%, tar: 0.0248 \n",
      "l0: 0.023741, l1: 0.024573, l2: 0.034182, l3: 0.055018, l4: 0.101074, l5: 0.190099, l6: 0.359126\n",
      "\n",
      "[epoch: 349/400, batch: 976/1000, ite: 46498] train loss: 1.1717, accuracy: 94.8297%, tar: 0.0248 \n",
      "l0: 0.019809, l1: 0.020868, l2: 0.026511, l3: 0.036413, l4: 0.062753, l5: 0.151875, l6: 0.372541\n",
      "\n",
      "[epoch: 349/400, batch: 984/1000, ite: 46499] train loss: 1.1715, accuracy: 95.8235%, tar: 0.0248 \n",
      "l0: 0.025567, l1: 0.026754, l2: 0.033986, l3: 0.051090, l4: 0.083430, l5: 0.151014, l6: 0.298342\n",
      "\n",
      "[epoch: 349/400, batch: 992/1000, ite: 46500] train loss: 1.1711, accuracy: 95.7729%, tar: 0.0248 \n",
      "l0: 0.027979, l1: 0.028815, l2: 0.035946, l3: 0.048897, l4: 0.081521, l5: 0.152449, l6: 0.350499\n",
      "\n",
      "[epoch: 349/400, batch: 1000/1000, ite: 46501] train loss: 1.1709, accuracy: 94.2422%, tar: 0.0248 \n",
      "l0: 0.024938, l1: 0.026230, l2: 0.033644, l3: 0.047349, l4: 0.081424, l5: 0.172404, l6: 0.355458\n",
      "\n",
      "[epoch: 350/400, batch: 8/1000, ite: 46502] train loss: 1.1707, accuracy: 94.5237%, tar: 0.0248 \n",
      "l0: 0.021521, l1: 0.022618, l2: 0.029616, l3: 0.041699, l4: 0.067850, l5: 0.121247, l6: 0.248055\n",
      "\n",
      "[epoch: 350/400, batch: 16/1000, ite: 46503] train loss: 1.1700, accuracy: 95.9233%, tar: 0.0248 \n",
      "l0: 0.030994, l1: 0.032552, l2: 0.042347, l3: 0.058315, l4: 0.115058, l5: 0.272546, l6: 0.587696\n",
      "\n",
      "[epoch: 350/400, batch: 24/1000, ite: 46504] train loss: 1.1711, accuracy: 92.3170%, tar: 0.0248 \n",
      "l0: 0.020644, l1: 0.021686, l2: 0.028800, l3: 0.044351, l4: 0.079354, l5: 0.151043, l6: 0.338062\n",
      "\n",
      "[epoch: 350/400, batch: 32/1000, ite: 46505] train loss: 1.1708, accuracy: 95.2526%, tar: 0.0248 \n",
      "l0: 0.021693, l1: 0.022773, l2: 0.030496, l3: 0.045070, l4: 0.076966, l5: 0.147753, l6: 0.319120\n",
      "\n",
      "[epoch: 350/400, batch: 40/1000, ite: 46506] train loss: 1.1705, accuracy: 95.7318%, tar: 0.0248 \n",
      "l0: 0.028930, l1: 0.030796, l2: 0.041664, l3: 0.062084, l4: 0.105783, l5: 0.206845, l6: 0.415247\n",
      "\n",
      "[epoch: 350/400, batch: 48/1000, ite: 46507] train loss: 1.1707, accuracy: 94.4684%, tar: 0.0248 \n",
      "l0: 0.025303, l1: 0.027171, l2: 0.036268, l3: 0.060118, l4: 0.137819, l5: 0.249381, l6: 0.409287\n",
      "\n",
      "[epoch: 350/400, batch: 56/1000, ite: 46508] train loss: 1.1711, accuracy: 94.8674%, tar: 0.0248 \n",
      "l0: 0.023113, l1: 0.024365, l2: 0.030852, l3: 0.041665, l4: 0.074731, l5: 0.149134, l6: 0.317121\n",
      "\n",
      "[epoch: 350/400, batch: 64/1000, ite: 46509] train loss: 1.1707, accuracy: 95.6796%, tar: 0.0248 \n",
      "l0: 0.030351, l1: 0.031887, l2: 0.041104, l3: 0.058039, l4: 0.122147, l5: 0.304595, l6: 0.491245\n",
      "\n",
      "[epoch: 350/400, batch: 72/1000, ite: 46510] train loss: 1.1715, accuracy: 93.2488%, tar: 0.0248 \n",
      "l0: 0.021871, l1: 0.023740, l2: 0.033798, l3: 0.055072, l4: 0.104747, l5: 0.228666, l6: 0.432038\n",
      "\n",
      "[epoch: 350/400, batch: 80/1000, ite: 46511] train loss: 1.1718, accuracy: 94.3539%, tar: 0.0248 \n",
      "l0: 0.025535, l1: 0.027325, l2: 0.038444, l3: 0.058385, l4: 0.109376, l5: 0.185794, l6: 0.404321\n",
      "\n",
      "[epoch: 350/400, batch: 88/1000, ite: 46512] train loss: 1.1720, accuracy: 94.9241%, tar: 0.0248 \n",
      "l0: 0.028894, l1: 0.031351, l2: 0.041836, l3: 0.060913, l4: 0.106107, l5: 0.214205, l6: 0.428254\n",
      "\n",
      "[epoch: 350/400, batch: 96/1000, ite: 46513] train loss: 1.1724, accuracy: 94.2730%, tar: 0.0248 \n",
      "l0: 0.028981, l1: 0.031071, l2: 0.039367, l3: 0.057550, l4: 0.130467, l5: 0.253220, l6: 0.511252\n",
      "\n",
      "[epoch: 350/400, batch: 104/1000, ite: 46514] train loss: 1.1731, accuracy: 94.0940%, tar: 0.0248 \n",
      "l0: 0.025044, l1: 0.026625, l2: 0.035611, l3: 0.048778, l4: 0.087594, l5: 0.207460, l6: 0.411693\n",
      "\n",
      "[epoch: 350/400, batch: 112/1000, ite: 46515] train loss: 1.1733, accuracy: 94.5273%, tar: 0.0248 \n",
      "l0: 0.021887, l1: 0.023265, l2: 0.030046, l3: 0.046457, l4: 0.083542, l5: 0.181501, l6: 0.387149\n",
      "\n",
      "[epoch: 350/400, batch: 120/1000, ite: 46516] train loss: 1.1733, accuracy: 95.2611%, tar: 0.0248 \n",
      "l0: 0.020061, l1: 0.020941, l2: 0.027888, l3: 0.042004, l4: 0.080769, l5: 0.166125, l6: 0.334839\n",
      "\n",
      "[epoch: 350/400, batch: 128/1000, ite: 46517] train loss: 1.1730, accuracy: 95.2518%, tar: 0.0248 \n",
      "l0: 0.028348, l1: 0.029621, l2: 0.038862, l3: 0.056813, l4: 0.107592, l5: 0.217214, l6: 0.432683\n",
      "\n",
      "[epoch: 350/400, batch: 136/1000, ite: 46518] train loss: 1.1733, accuracy: 93.7576%, tar: 0.0248 \n",
      "l0: 0.024309, l1: 0.025337, l2: 0.033253, l3: 0.046730, l4: 0.073742, l5: 0.143839, l6: 0.314700\n",
      "\n",
      "[epoch: 350/400, batch: 144/1000, ite: 46519] train loss: 1.1730, accuracy: 95.7023%, tar: 0.0248 \n",
      "l0: 0.027750, l1: 0.029313, l2: 0.039316, l3: 0.063764, l4: 0.123580, l5: 0.212840, l6: 0.380507\n",
      "\n",
      "[epoch: 350/400, batch: 152/1000, ite: 46520] train loss: 1.1731, accuracy: 94.2085%, tar: 0.0248 \n",
      "l0: 0.025410, l1: 0.026740, l2: 0.034241, l3: 0.052620, l4: 0.101595, l5: 0.214270, l6: 0.442831\n",
      "\n",
      "[epoch: 350/400, batch: 160/1000, ite: 46521] train loss: 1.1735, accuracy: 93.5493%, tar: 0.0248 \n",
      "l0: 0.019985, l1: 0.020941, l2: 0.027698, l3: 0.042470, l4: 0.074269, l5: 0.146302, l6: 0.323662\n",
      "\n",
      "[epoch: 350/400, batch: 168/1000, ite: 46522] train loss: 1.1731, accuracy: 95.0995%, tar: 0.0248 \n",
      "l0: 0.017893, l1: 0.018341, l2: 0.024568, l3: 0.036359, l4: 0.065387, l5: 0.158822, l6: 0.288246\n",
      "\n",
      "[epoch: 350/400, batch: 176/1000, ite: 46523] train loss: 1.1726, accuracy: 95.8224%, tar: 0.0248 \n",
      "l0: 0.016212, l1: 0.018365, l2: 0.028074, l3: 0.046563, l4: 0.091171, l5: 0.203364, l6: 0.376669\n",
      "\n",
      "[epoch: 350/400, batch: 184/1000, ite: 46524] train loss: 1.1726, accuracy: 96.3605%, tar: 0.0248 \n",
      "l0: 0.021067, l1: 0.021916, l2: 0.029395, l3: 0.042795, l4: 0.070087, l5: 0.124753, l6: 0.284903\n",
      "\n",
      "[epoch: 350/400, batch: 192/1000, ite: 46525] train loss: 1.1720, accuracy: 95.2984%, tar: 0.0248 \n",
      "l0: 0.023133, l1: 0.024081, l2: 0.032751, l3: 0.049364, l4: 0.079368, l5: 0.150574, l6: 0.307076\n",
      "\n",
      "[epoch: 350/400, batch: 200/1000, ite: 46526] train loss: 1.1716, accuracy: 95.1419%, tar: 0.0248 \n",
      "l0: 0.020019, l1: 0.021024, l2: 0.029767, l3: 0.046406, l4: 0.089667, l5: 0.183982, l6: 0.333043\n",
      "\n",
      "[epoch: 350/400, batch: 208/1000, ite: 46527] train loss: 1.1714, accuracy: 95.5948%, tar: 0.0248 \n",
      "l0: 0.026009, l1: 0.027959, l2: 0.037943, l3: 0.057911, l4: 0.106984, l5: 0.210020, l6: 0.469356\n",
      "\n",
      "[epoch: 350/400, batch: 216/1000, ite: 46528] train loss: 1.1719, accuracy: 94.0867%, tar: 0.0248 \n",
      "l0: 0.023281, l1: 0.024810, l2: 0.033243, l3: 0.050945, l4: 0.087107, l5: 0.148198, l6: 0.289694\n",
      "\n",
      "[epoch: 350/400, batch: 224/1000, ite: 46529] train loss: 1.1715, accuracy: 95.6284%, tar: 0.0248 \n",
      "l0: 0.021081, l1: 0.021974, l2: 0.029014, l3: 0.040006, l4: 0.069598, l5: 0.128290, l6: 0.265790\n",
      "\n",
      "[epoch: 350/400, batch: 232/1000, ite: 46530] train loss: 1.1708, accuracy: 95.7960%, tar: 0.0248 \n",
      "l0: 0.022206, l1: 0.023192, l2: 0.028860, l3: 0.043507, l4: 0.084259, l5: 0.224718, l6: 0.445870\n",
      "\n",
      "[epoch: 350/400, batch: 240/1000, ite: 46531] train loss: 1.1711, accuracy: 95.0035%, tar: 0.0248 \n",
      "l0: 0.025567, l1: 0.026334, l2: 0.033963, l3: 0.047400, l4: 0.086343, l5: 0.176749, l6: 0.397921\n",
      "\n",
      "[epoch: 350/400, batch: 248/1000, ite: 46532] train loss: 1.1712, accuracy: 94.4280%, tar: 0.0248 \n",
      "l0: 0.022824, l1: 0.024497, l2: 0.032454, l3: 0.048196, l4: 0.089670, l5: 0.172220, l6: 0.354706\n",
      "\n",
      "[epoch: 350/400, batch: 296/1000, ite: 46538] train loss: 1.1702, accuracy: 93.9371%, tar: 0.0247 \n",
      "l0: 0.019750, l1: 0.021179, l2: 0.029052, l3: 0.048965, l4: 0.093787, l5: 0.204063, l6: 0.388814\n",
      "\n",
      "[epoch: 350/400, batch: 304/1000, ite: 46539] train loss: 1.1702, accuracy: 95.5802%, tar: 0.0247 \n",
      "l0: 0.021068, l1: 0.021669, l2: 0.026947, l3: 0.038153, l4: 0.064322, l5: 0.113726, l6: 0.248184\n",
      "\n",
      "[epoch: 350/400, batch: 312/1000, ite: 46540] train loss: 1.1695, accuracy: 95.6547%, tar: 0.0247 \n",
      "l0: 0.028341, l1: 0.029169, l2: 0.036183, l3: 0.050027, l4: 0.085781, l5: 0.170077, l6: 0.388291\n",
      "\n",
      "[epoch: 350/400, batch: 320/1000, ite: 46541] train loss: 1.1695, accuracy: 94.6756%, tar: 0.0247 \n",
      "l0: 0.022719, l1: 0.024194, l2: 0.034525, l3: 0.050162, l4: 0.099407, l5: 0.239162, l6: 0.516550\n",
      "\n",
      "[epoch: 350/400, batch: 328/1000, ite: 46542] train loss: 1.1701, accuracy: 94.4531%, tar: 0.0247 \n",
      "l0: 0.026971, l1: 0.028051, l2: 0.035138, l3: 0.055262, l4: 0.102352, l5: 0.216871, l6: 0.387807\n",
      "\n",
      "[epoch: 350/400, batch: 336/1000, ite: 46543] train loss: 1.1702, accuracy: 94.0668%, tar: 0.0247 \n",
      "l0: 0.019534, l1: 0.020610, l2: 0.028196, l3: 0.041850, l4: 0.085263, l5: 0.170991, l6: 0.329999\n",
      "\n",
      "[epoch: 350/400, batch: 344/1000, ite: 46544] train loss: 1.1699, accuracy: 95.9806%, tar: 0.0247 \n",
      "l0: 0.022483, l1: 0.023691, l2: 0.032196, l3: 0.051675, l4: 0.115663, l5: 0.235138, l6: 0.458627\n",
      "\n",
      "[epoch: 350/400, batch: 352/1000, ite: 46545] train loss: 1.1704, accuracy: 94.0122%, tar: 0.0247 \n",
      "l0: 0.024614, l1: 0.025833, l2: 0.034473, l3: 0.049841, l4: 0.101440, l5: 0.222263, l6: 0.374773\n",
      "\n",
      "[epoch: 350/400, batch: 360/1000, ite: 46546] train loss: 1.1705, accuracy: 94.2362%, tar: 0.0247 \n",
      "l0: 0.019624, l1: 0.020813, l2: 0.027988, l3: 0.040971, l4: 0.071222, l5: 0.133346, l6: 0.275458\n",
      "\n",
      "[epoch: 350/400, batch: 368/1000, ite: 46547] train loss: 1.1699, accuracy: 95.6184%, tar: 0.0247 \n",
      "l0: 0.024820, l1: 0.025866, l2: 0.033799, l3: 0.047957, l4: 0.083158, l5: 0.155012, l6: 0.337118\n",
      "\n",
      "[epoch: 350/400, batch: 376/1000, ite: 46548] train loss: 1.1697, accuracy: 95.2868%, tar: 0.0247 \n",
      "l0: 0.017401, l1: 0.019667, l2: 0.029571, l3: 0.049320, l4: 0.090434, l5: 0.154998, l6: 0.339061\n",
      "\n",
      "[epoch: 350/400, batch: 384/1000, ite: 46549] train loss: 1.1695, accuracy: 95.9927%, tar: 0.0247 \n",
      "l0: 0.021160, l1: 0.023028, l2: 0.030824, l3: 0.044884, l4: 0.076441, l5: 0.147900, l6: 0.326734\n",
      "\n",
      "[epoch: 350/400, batch: 392/1000, ite: 46550] train loss: 1.1692, accuracy: 95.6779%, tar: 0.0247 \n",
      "l0: 0.022080, l1: 0.022919, l2: 0.031257, l3: 0.047311, l4: 0.075682, l5: 0.118815, l6: 0.227821\n",
      "\n",
      "[epoch: 350/400, batch: 400/1000, ite: 46551] train loss: 1.1685, accuracy: 96.4366%, tar: 0.0247 \n",
      "l0: 0.029933, l1: 0.031055, l2: 0.039223, l3: 0.060495, l4: 0.118129, l5: 0.251092, l6: 0.541269\n",
      "\n",
      "[epoch: 350/400, batch: 408/1000, ite: 46552] train loss: 1.1693, accuracy: 93.3591%, tar: 0.0247 \n",
      "l0: 0.029066, l1: 0.030862, l2: 0.041652, l3: 0.059421, l4: 0.108432, l5: 0.248888, l6: 0.481334\n",
      "\n",
      "[epoch: 350/400, batch: 416/1000, ite: 46553] train loss: 1.1699, accuracy: 93.4979%, tar: 0.0247 \n",
      "l0: 0.027641, l1: 0.029034, l2: 0.037301, l3: 0.054042, l4: 0.093348, l5: 0.188036, l6: 0.429201\n",
      "\n",
      "[epoch: 350/400, batch: 424/1000, ite: 46554] train loss: 1.1701, accuracy: 93.9323%, tar: 0.0247 \n",
      "l0: 0.020934, l1: 0.022036, l2: 0.029013, l3: 0.043644, l4: 0.068415, l5: 0.125912, l6: 0.303850\n",
      "\n",
      "[epoch: 350/400, batch: 432/1000, ite: 46555] train loss: 1.1696, accuracy: 96.1763%, tar: 0.0247 \n",
      "l0: 0.028856, l1: 0.031908, l2: 0.044765, l3: 0.079408, l4: 0.155929, l5: 0.324074, l6: 0.586267\n",
      "\n",
      "[epoch: 350/400, batch: 440/1000, ite: 46556] train loss: 1.1708, accuracy: 93.0387%, tar: 0.0247 \n",
      "l0: 0.022294, l1: 0.023723, l2: 0.031719, l3: 0.053339, l4: 0.104750, l5: 0.203630, l6: 0.377835\n",
      "\n",
      "[epoch: 350/400, batch: 448/1000, ite: 46557] train loss: 1.1709, accuracy: 94.9026%, tar: 0.0247 \n",
      "l0: 0.031044, l1: 0.032242, l2: 0.042371, l3: 0.061642, l4: 0.119814, l5: 0.289964, l6: 0.636892\n",
      "\n",
      "[epoch: 350/400, batch: 456/1000, ite: 46558] train loss: 1.1721, accuracy: 91.1788%, tar: 0.0247 \n",
      "l0: 0.018638, l1: 0.019569, l2: 0.025788, l3: 0.039242, l4: 0.070903, l5: 0.130542, l6: 0.262550\n",
      "\n",
      "[epoch: 350/400, batch: 464/1000, ite: 46559] train loss: 1.1715, accuracy: 96.0133%, tar: 0.0247 \n",
      "l0: 0.020657, l1: 0.021681, l2: 0.029211, l3: 0.045495, l4: 0.084404, l5: 0.191731, l6: 0.357773\n",
      "\n",
      "[epoch: 350/400, batch: 472/1000, ite: 46560] train loss: 1.1714, accuracy: 95.1980%, tar: 0.0247 \n",
      "l0: 0.018715, l1: 0.019707, l2: 0.025719, l3: 0.036515, l4: 0.061640, l5: 0.126156, l6: 0.286134\n",
      "\n",
      "[epoch: 350/400, batch: 480/1000, ite: 46561] train loss: 1.1709, accuracy: 95.9051%, tar: 0.0247 \n",
      "l0: 0.026624, l1: 0.028008, l2: 0.035277, l3: 0.051945, l4: 0.121802, l5: 0.221196, l6: 0.416777\n",
      "\n",
      "[epoch: 350/400, batch: 488/1000, ite: 46562] train loss: 1.1712, accuracy: 95.0732%, tar: 0.0247 \n",
      "l0: 0.021170, l1: 0.021864, l2: 0.028851, l3: 0.041532, l4: 0.073952, l5: 0.142639, l6: 0.341163\n",
      "\n",
      "[epoch: 350/400, batch: 496/1000, ite: 46563] train loss: 1.1709, accuracy: 95.4820%, tar: 0.0247 \n",
      "l0: 0.025679, l1: 0.026335, l2: 0.032161, l3: 0.043555, l4: 0.075684, l5: 0.147052, l6: 0.327080\n",
      "\n",
      "[epoch: 350/400, batch: 504/1000, ite: 46564] train loss: 1.1706, accuracy: 95.3506%, tar: 0.0247 \n",
      "l0: 0.020194, l1: 0.021122, l2: 0.027442, l3: 0.039354, l4: 0.075195, l5: 0.163086, l6: 0.304923\n",
      "\n",
      "[epoch: 350/400, batch: 512/1000, ite: 46565] train loss: 1.1702, accuracy: 96.0458%, tar: 0.0247 \n",
      "l0: 0.028983, l1: 0.029530, l2: 0.037467, l3: 0.048461, l4: 0.079704, l5: 0.163081, l6: 0.343754\n",
      "\n",
      "[epoch: 350/400, batch: 520/1000, ite: 46566] train loss: 1.1701, accuracy: 94.5108%, tar: 0.0247 \n",
      "l0: 0.019095, l1: 0.020519, l2: 0.028281, l3: 0.043204, l4: 0.076831, l5: 0.162999, l6: 0.343150\n",
      "\n",
      "[epoch: 350/400, batch: 528/1000, ite: 46567] train loss: 1.1699, accuracy: 95.1864%, tar: 0.0247 \n",
      "l0: 0.017426, l1: 0.017999, l2: 0.025647, l3: 0.038115, l4: 0.062532, l5: 0.103103, l6: 0.244542\n",
      "\n",
      "[epoch: 350/400, batch: 536/1000, ite: 46568] train loss: 1.1691, accuracy: 96.6284%, tar: 0.0246 \n",
      "l0: 0.022715, l1: 0.025305, l2: 0.034864, l3: 0.061135, l4: 0.115737, l5: 0.206694, l6: 0.387436\n",
      "\n",
      "[epoch: 350/400, batch: 544/1000, ite: 46569] train loss: 1.1693, accuracy: 95.0703%, tar: 0.0246 \n",
      "l0: 0.018619, l1: 0.020374, l2: 0.026783, l3: 0.041632, l4: 0.079706, l5: 0.178877, l6: 0.431053\n",
      "\n",
      "[epoch: 350/400, batch: 552/1000, ite: 46570] train loss: 1.1694, accuracy: 94.2437%, tar: 0.0246 \n",
      "l0: 0.028395, l1: 0.029494, l2: 0.038977, l3: 0.054515, l4: 0.094030, l5: 0.179413, l6: 0.377251\n",
      "\n",
      "[epoch: 350/400, batch: 560/1000, ite: 46571] train loss: 1.1694, accuracy: 94.2569%, tar: 0.0246 \n",
      "l0: 0.022126, l1: 0.022468, l2: 0.027480, l3: 0.038012, l4: 0.063943, l5: 0.109109, l6: 0.247947\n",
      "\n",
      "[epoch: 350/400, batch: 568/1000, ite: 46572] train loss: 1.1687, accuracy: 95.7439%, tar: 0.0246 \n",
      "l0: 0.019559, l1: 0.021273, l2: 0.030538, l3: 0.049839, l4: 0.094916, l5: 0.180618, l6: 0.351019\n",
      "\n",
      "[epoch: 350/400, batch: 576/1000, ite: 46573] train loss: 1.1686, accuracy: 95.1891%, tar: 0.0246 \n",
      "l0: 0.018432, l1: 0.019691, l2: 0.027746, l3: 0.040325, l4: 0.073063, l5: 0.159873, l6: 0.323109\n",
      "\n",
      "[epoch: 350/400, batch: 584/1000, ite: 46574] train loss: 1.1683, accuracy: 96.3880%, tar: 0.0246 \n",
      "l0: 0.023300, l1: 0.024436, l2: 0.031463, l3: 0.047349, l4: 0.085383, l5: 0.161651, l6: 0.385726\n",
      "\n",
      "[epoch: 350/400, batch: 592/1000, ite: 46575] train loss: 1.1683, accuracy: 94.8752%, tar: 0.0246 \n",
      "l0: 0.022901, l1: 0.024050, l2: 0.032013, l3: 0.052338, l4: 0.121700, l5: 0.225724, l6: 0.392168\n",
      "\n",
      "[epoch: 350/400, batch: 600/1000, ite: 46576] train loss: 1.1684, accuracy: 94.5500%, tar: 0.0246 \n",
      "l0: 0.019303, l1: 0.020545, l2: 0.027479, l3: 0.041741, l4: 0.068522, l5: 0.134988, l6: 0.374865\n",
      "\n",
      "[epoch: 350/400, batch: 608/1000, ite: 46577] train loss: 1.1682, accuracy: 95.4567%, tar: 0.0246 \n",
      "l0: 0.030001, l1: 0.030826, l2: 0.039633, l3: 0.055689, l4: 0.090377, l5: 0.173028, l6: 0.386876\n",
      "\n",
      "[epoch: 350/400, batch: 616/1000, ite: 46578] train loss: 1.1683, accuracy: 93.6510%, tar: 0.0246 \n",
      "l0: 0.026745, l1: 0.027617, l2: 0.037179, l3: 0.053094, l4: 0.091352, l5: 0.175807, l6: 0.386387\n",
      "\n",
      "[epoch: 350/400, batch: 624/1000, ite: 46579] train loss: 1.1683, accuracy: 94.1124%, tar: 0.0246 \n",
      "l0: 0.020935, l1: 0.023739, l2: 0.034354, l3: 0.059151, l4: 0.101484, l5: 0.176067, l6: 0.378161\n",
      "\n",
      "[epoch: 350/400, batch: 632/1000, ite: 46580] train loss: 1.1683, accuracy: 95.8746%, tar: 0.0246 \n",
      "l0: 0.028773, l1: 0.029718, l2: 0.037539, l3: 0.054612, l4: 0.104881, l5: 0.216652, l6: 0.427052\n",
      "\n",
      "[epoch: 350/400, batch: 640/1000, ite: 46581] train loss: 1.1686, accuracy: 93.0235%, tar: 0.0246 \n",
      "l0: 0.024577, l1: 0.025811, l2: 0.034595, l3: 0.049753, l4: 0.090486, l5: 0.204538, l6: 0.385149\n",
      "\n",
      "[epoch: 350/400, batch: 648/1000, ite: 46582] train loss: 1.1687, accuracy: 94.9181%, tar: 0.0246 \n",
      "l0: 0.018479, l1: 0.020348, l2: 0.027866, l3: 0.041130, l4: 0.074425, l5: 0.154824, l6: 0.338152\n",
      "\n",
      "[epoch: 350/400, batch: 656/1000, ite: 46583] train loss: 1.1684, accuracy: 96.0954%, tar: 0.0246 \n",
      "l0: 0.022362, l1: 0.023471, l2: 0.030373, l3: 0.041612, l4: 0.072005, l5: 0.151577, l6: 0.327874\n",
      "\n",
      "[epoch: 350/400, batch: 664/1000, ite: 46584] train loss: 1.1681, accuracy: 94.8463%, tar: 0.0246 \n",
      "l0: 0.026125, l1: 0.027367, l2: 0.034771, l3: 0.053789, l4: 0.098899, l5: 0.225857, l6: 0.508742\n",
      "\n",
      "[epoch: 350/400, batch: 672/1000, ite: 46585] train loss: 1.1687, accuracy: 92.6782%, tar: 0.0246 \n",
      "l0: 0.023759, l1: 0.025489, l2: 0.034406, l3: 0.052278, l4: 0.105081, l5: 0.230009, l6: 0.428523\n",
      "\n",
      "[epoch: 350/400, batch: 680/1000, ite: 46586] train loss: 1.1690, accuracy: 94.7354%, tar: 0.0246 \n",
      "l0: 0.022699, l1: 0.024016, l2: 0.029713, l3: 0.042788, l4: 0.074978, l5: 0.146182, l6: 0.377779\n",
      "\n",
      "[epoch: 350/400, batch: 688/1000, ite: 46587] train loss: 1.1689, accuracy: 95.0563%, tar: 0.0246 \n",
      "l0: 0.026509, l1: 0.028142, l2: 0.037903, l3: 0.057814, l4: 0.116627, l5: 0.219181, l6: 0.415308\n",
      "\n",
      "[epoch: 350/400, batch: 696/1000, ite: 46588] train loss: 1.1691, accuracy: 94.2160%, tar: 0.0246 \n",
      "l0: 0.025013, l1: 0.026401, l2: 0.035006, l3: 0.053863, l4: 0.101099, l5: 0.222872, l6: 0.411814\n",
      "\n",
      "[epoch: 350/400, batch: 704/1000, ite: 46589] train loss: 1.1693, accuracy: 94.2554%, tar: 0.0246 \n",
      "l0: 0.026644, l1: 0.028509, l2: 0.037513, l3: 0.058013, l4: 0.113335, l5: 0.204894, l6: 0.396098\n",
      "\n",
      "[epoch: 350/400, batch: 712/1000, ite: 46590] train loss: 1.1695, accuracy: 94.4893%, tar: 0.0246 \n",
      "l0: 0.018947, l1: 0.020401, l2: 0.027910, l3: 0.042814, l4: 0.076822, l5: 0.148176, l6: 0.308431\n",
      "\n",
      "[epoch: 350/400, batch: 720/1000, ite: 46591] train loss: 1.1691, accuracy: 95.7135%, tar: 0.0246 \n",
      "l0: 0.020483, l1: 0.021134, l2: 0.026572, l3: 0.035951, l4: 0.062957, l5: 0.118406, l6: 0.262621\n",
      "\n",
      "[epoch: 350/400, batch: 728/1000, ite: 46592] train loss: 1.1685, accuracy: 95.8758%, tar: 0.0246 \n",
      "l0: 0.024546, l1: 0.025720, l2: 0.034947, l3: 0.053326, l4: 0.083359, l5: 0.149320, l6: 0.315566\n",
      "\n",
      "[epoch: 350/400, batch: 736/1000, ite: 46593] train loss: 1.1683, accuracy: 95.9882%, tar: 0.0246 \n",
      "l0: 0.016383, l1: 0.017340, l2: 0.023885, l3: 0.034461, l4: 0.060572, l5: 0.110785, l6: 0.234197\n",
      "\n",
      "[epoch: 350/400, batch: 744/1000, ite: 46594] train loss: 1.1675, accuracy: 96.4287%, tar: 0.0246 \n",
      "l0: 0.021785, l1: 0.022796, l2: 0.030222, l3: 0.041988, l4: 0.073370, l5: 0.128419, l6: 0.302196\n",
      "\n",
      "[epoch: 350/400, batch: 752/1000, ite: 46595] train loss: 1.1671, accuracy: 95.3373%, tar: 0.0246 \n",
      "l0: 0.017424, l1: 0.018570, l2: 0.025239, l3: 0.037599, l4: 0.064981, l5: 0.142783, l6: 0.285142\n",
      "\n",
      "[epoch: 350/400, batch: 760/1000, ite: 46596] train loss: 1.1667, accuracy: 95.5760%, tar: 0.0246 \n",
      "l0: 0.026831, l1: 0.027975, l2: 0.035532, l3: 0.048703, l4: 0.077023, l5: 0.127213, l6: 0.270060\n",
      "\n",
      "[epoch: 350/400, batch: 768/1000, ite: 46597] train loss: 1.1662, accuracy: 95.7373%, tar: 0.0246 \n",
      "l0: 0.024512, l1: 0.025714, l2: 0.033717, l3: 0.050032, l4: 0.091301, l5: 0.176817, l6: 0.375952\n",
      "\n",
      "[epoch: 350/400, batch: 776/1000, ite: 46598] train loss: 1.1662, accuracy: 94.2339%, tar: 0.0246 \n",
      "l0: 0.023466, l1: 0.024539, l2: 0.032363, l3: 0.050697, l4: 0.092402, l5: 0.193358, l6: 0.371789\n",
      "\n",
      "[epoch: 350/400, batch: 784/1000, ite: 46599] train loss: 1.1662, accuracy: 95.1362%, tar: 0.0246 \n",
      "l0: 0.025753, l1: 0.027039, l2: 0.035439, l3: 0.054525, l4: 0.100479, l5: 0.205146, l6: 0.384293\n",
      "\n",
      "[epoch: 350/400, batch: 792/1000, ite: 46600] train loss: 1.1663, accuracy: 93.5179%, tar: 0.0246 \n",
      "l0: 0.023309, l1: 0.024266, l2: 0.032227, l3: 0.048062, l4: 0.086116, l5: 0.164638, l6: 0.306167\n",
      "\n",
      "[epoch: 350/400, batch: 800/1000, ite: 46601] train loss: 1.1660, accuracy: 94.9419%, tar: 0.0246 \n",
      "l0: 0.026761, l1: 0.028320, l2: 0.034683, l3: 0.046879, l4: 0.080870, l5: 0.206383, l6: 0.490343\n",
      "\n",
      "[epoch: 350/400, batch: 808/1000, ite: 46602] train loss: 1.1664, accuracy: 93.7657%, tar: 0.0246 \n",
      "l0: 0.018638, l1: 0.019412, l2: 0.026540, l3: 0.039198, l4: 0.088086, l5: 0.149804, l6: 0.292397\n",
      "\n",
      "[epoch: 350/400, batch: 816/1000, ite: 46603] train loss: 1.1660, accuracy: 95.6910%, tar: 0.0246 \n",
      "l0: 0.022178, l1: 0.024721, l2: 0.033409, l3: 0.052725, l4: 0.100279, l5: 0.208506, l6: 0.434638\n",
      "\n",
      "[epoch: 350/400, batch: 824/1000, ite: 46604] train loss: 1.1663, accuracy: 94.1457%, tar: 0.0246 \n",
      "l0: 0.026118, l1: 0.027638, l2: 0.036030, l3: 0.051542, l4: 0.104164, l5: 0.210884, l6: 0.387278\n",
      "\n",
      "[epoch: 350/400, batch: 832/1000, ite: 46605] train loss: 1.1664, accuracy: 94.6940%, tar: 0.0246 \n",
      "l0: 0.023938, l1: 0.025607, l2: 0.033048, l3: 0.050241, l4: 0.093241, l5: 0.181643, l6: 0.369162\n",
      "\n",
      "[epoch: 350/400, batch: 840/1000, ite: 46606] train loss: 1.1663, accuracy: 94.7516%, tar: 0.0246 \n",
      "l0: 0.018988, l1: 0.020714, l2: 0.030133, l3: 0.049145, l4: 0.100127, l5: 0.183193, l6: 0.290362\n",
      "\n",
      "[epoch: 350/400, batch: 848/1000, ite: 46607] train loss: 1.1660, accuracy: 96.0639%, tar: 0.0245 \n",
      "l0: 0.021147, l1: 0.022379, l2: 0.028848, l3: 0.042267, l4: 0.077210, l5: 0.143960, l6: 0.288821\n",
      "\n",
      "[epoch: 350/400, batch: 856/1000, ite: 46608] train loss: 1.1656, accuracy: 95.1909%, tar: 0.0245 \n",
      "l0: 0.023895, l1: 0.024858, l2: 0.030737, l3: 0.044359, l4: 0.081431, l5: 0.135407, l6: 0.290284\n",
      "\n",
      "[epoch: 350/400, batch: 864/1000, ite: 46609] train loss: 1.1652, accuracy: 95.6581%, tar: 0.0245 \n",
      "l0: 0.022456, l1: 0.023637, l2: 0.031181, l3: 0.050335, l4: 0.094212, l5: 0.196834, l6: 0.387420\n",
      "\n",
      "[epoch: 350/400, batch: 872/1000, ite: 46610] train loss: 1.1653, accuracy: 94.9520%, tar: 0.0245 \n",
      "l0: 0.022311, l1: 0.023126, l2: 0.029075, l3: 0.042385, l4: 0.073133, l5: 0.142602, l6: 0.284707\n",
      "\n",
      "[epoch: 350/400, batch: 880/1000, ite: 46611] train loss: 1.1649, accuracy: 95.3972%, tar: 0.0245 \n",
      "l0: 0.027395, l1: 0.028590, l2: 0.036072, l3: 0.051343, l4: 0.090321, l5: 0.212367, l6: 0.420280\n",
      "\n",
      "[epoch: 350/400, batch: 888/1000, ite: 46612] train loss: 1.1651, accuracy: 93.7316%, tar: 0.0245 \n",
      "l0: 0.029424, l1: 0.031799, l2: 0.042721, l3: 0.064894, l4: 0.128516, l5: 0.262095, l6: 0.546100\n",
      "\n",
      "[epoch: 350/400, batch: 896/1000, ite: 46613] train loss: 1.1659, accuracy: 92.9224%, tar: 0.0245 \n",
      "l0: 0.023623, l1: 0.024966, l2: 0.032059, l3: 0.046109, l4: 0.079606, l5: 0.125614, l6: 0.271421\n",
      "\n",
      "[epoch: 350/400, batch: 904/1000, ite: 46614] train loss: 1.1654, accuracy: 95.7814%, tar: 0.0245 \n",
      "l0: 0.024152, l1: 0.025612, l2: 0.032898, l3: 0.048767, l4: 0.090823, l5: 0.180817, l6: 0.360556\n",
      "\n",
      "[epoch: 350/400, batch: 912/1000, ite: 46615] train loss: 1.1653, accuracy: 94.8916%, tar: 0.0245 \n",
      "l0: 0.022800, l1: 0.023335, l2: 0.030950, l3: 0.043627, l4: 0.073922, l5: 0.156385, l6: 0.317543\n",
      "\n",
      "[epoch: 350/400, batch: 920/1000, ite: 46616] train loss: 1.1651, accuracy: 95.0513%, tar: 0.0245 \n",
      "l0: 0.030642, l1: 0.032724, l2: 0.042701, l3: 0.065510, l4: 0.130846, l5: 0.238251, l6: 0.387402\n",
      "\n",
      "[epoch: 350/400, batch: 928/1000, ite: 46617] train loss: 1.1653, accuracy: 94.2397%, tar: 0.0245 \n",
      "l0: 0.023596, l1: 0.024909, l2: 0.033430, l3: 0.049324, l4: 0.094646, l5: 0.238256, l6: 0.460877\n",
      "\n",
      "[epoch: 350/400, batch: 936/1000, ite: 46618] train loss: 1.1657, accuracy: 94.9193%, tar: 0.0245 \n",
      "l0: 0.024039, l1: 0.024486, l2: 0.032953, l3: 0.045658, l4: 0.089270, l5: 0.202372, l6: 0.395436\n",
      "\n",
      "[epoch: 350/400, batch: 944/1000, ite: 46619] train loss: 1.1657, accuracy: 94.6505%, tar: 0.0245 \n",
      "l0: 0.038013, l1: 0.041485, l2: 0.055774, l3: 0.083786, l4: 0.158891, l5: 0.344998, l6: 0.580284\n",
      "\n",
      "[epoch: 350/400, batch: 952/1000, ite: 46620] train loss: 1.1669, accuracy: 92.0013%, tar: 0.0246 \n",
      "l0: 0.022387, l1: 0.024579, l2: 0.034347, l3: 0.058127, l4: 0.111355, l5: 0.248598, l6: 0.493359\n",
      "\n",
      "[epoch: 350/400, batch: 960/1000, ite: 46621] train loss: 1.1674, accuracy: 94.1679%, tar: 0.0246 \n",
      "l0: 0.028090, l1: 0.028901, l2: 0.035552, l3: 0.050491, l4: 0.091665, l5: 0.202186, l6: 0.495567\n",
      "\n",
      "[epoch: 350/400, batch: 968/1000, ite: 46622] train loss: 1.1678, accuracy: 93.3752%, tar: 0.0246 \n",
      "l0: 0.020321, l1: 0.020986, l2: 0.028428, l3: 0.042082, l4: 0.075570, l5: 0.130604, l6: 0.322048\n",
      "\n",
      "[epoch: 350/400, batch: 976/1000, ite: 46623] train loss: 1.1675, accuracy: 95.9859%, tar: 0.0246 \n",
      "l0: 0.028215, l1: 0.029383, l2: 0.036411, l3: 0.055203, l4: 0.123624, l5: 0.222919, l6: 0.434386\n",
      "\n",
      "[epoch: 350/400, batch: 984/1000, ite: 46624] train loss: 1.1679, accuracy: 93.4055%, tar: 0.0246 \n",
      "l0: 0.019501, l1: 0.020286, l2: 0.026376, l3: 0.041523, l4: 0.086216, l5: 0.139142, l6: 0.305957\n",
      "\n",
      "[epoch: 350/400, batch: 992/1000, ite: 46625] train loss: 1.1675, accuracy: 95.7056%, tar: 0.0246 \n",
      "l0: 0.021751, l1: 0.023166, l2: 0.028844, l3: 0.041305, l4: 0.077975, l5: 0.141276, l6: 0.310674\n",
      "\n",
      "[epoch: 350/400, batch: 1000/1000, ite: 46626] train loss: 1.1672, accuracy: 95.2674%, tar: 0.0246 \n",
      "l0: 0.024194, l1: 0.025290, l2: 0.031168, l3: 0.044555, l4: 0.074302, l5: 0.139257, l6: 0.351561\n",
      "\n",
      "[epoch: 351/400, batch: 8/1000, ite: 46627] train loss: 1.1670, accuracy: 95.0972%, tar: 0.0246 \n",
      "l0: 0.026495, l1: 0.028307, l2: 0.037864, l3: 0.055267, l4: 0.087078, l5: 0.150061, l6: 0.355623\n",
      "\n",
      "[epoch: 351/400, batch: 16/1000, ite: 46628] train loss: 1.1669, accuracy: 94.8782%, tar: 0.0246 \n",
      "l0: 0.028608, l1: 0.029667, l2: 0.038614, l3: 0.054402, l4: 0.100973, l5: 0.222482, l6: 0.461057\n",
      "\n",
      "[epoch: 351/400, batch: 24/1000, ite: 46629] train loss: 1.1673, accuracy: 93.8181%, tar: 0.0246 \n",
      "l0: 0.026964, l1: 0.028238, l2: 0.035911, l3: 0.055277, l4: 0.114869, l5: 0.197942, l6: 0.407846\n",
      "\n",
      "[epoch: 351/400, batch: 32/1000, ite: 46630] train loss: 1.1674, accuracy: 94.2962%, tar: 0.0246 \n",
      "l0: 0.018801, l1: 0.019996, l2: 0.025528, l3: 0.036664, l4: 0.067527, l5: 0.133651, l6: 0.312074\n",
      "\n",
      "[epoch: 351/400, batch: 40/1000, ite: 46631] train loss: 1.1671, accuracy: 95.6864%, tar: 0.0246 \n",
      "l0: 0.028479, l1: 0.030345, l2: 0.040128, l3: 0.062025, l4: 0.102401, l5: 0.194191, l6: 0.411292\n",
      "\n",
      "[epoch: 351/400, batch: 48/1000, ite: 46632] train loss: 1.1673, accuracy: 94.5333%, tar: 0.0246 \n",
      "l0: 0.019561, l1: 0.020888, l2: 0.027807, l3: 0.041668, l4: 0.075932, l5: 0.157924, l6: 0.338263\n",
      "\n",
      "[epoch: 351/400, batch: 56/1000, ite: 46633] train loss: 1.1670, accuracy: 95.8450%, tar: 0.0246 \n",
      "l0: 0.017467, l1: 0.018467, l2: 0.024619, l3: 0.039225, l4: 0.078025, l5: 0.141308, l6: 0.286012\n",
      "\n",
      "[epoch: 351/400, batch: 64/1000, ite: 46634] train loss: 1.1666, accuracy: 95.7393%, tar: 0.0245 \n",
      "l0: 0.021170, l1: 0.022998, l2: 0.032051, l3: 0.052907, l4: 0.113513, l5: 0.237989, l6: 0.375656\n",
      "\n",
      "[epoch: 351/400, batch: 72/1000, ite: 46635] train loss: 1.1667, accuracy: 95.1992%, tar: 0.0245 \n",
      "l0: 0.023022, l1: 0.024083, l2: 0.030443, l3: 0.044928, l4: 0.080148, l5: 0.159205, l6: 0.314268\n",
      "\n",
      "[epoch: 351/400, batch: 80/1000, ite: 46636] train loss: 1.1665, accuracy: 95.4697%, tar: 0.0245 \n",
      "l0: 0.021245, l1: 0.022922, l2: 0.032407, l3: 0.048320, l4: 0.089054, l5: 0.176129, l6: 0.385197\n",
      "\n",
      "[epoch: 351/400, batch: 88/1000, ite: 46637] train loss: 1.1665, accuracy: 95.0375%, tar: 0.0245 \n",
      "l0: 0.018077, l1: 0.019375, l2: 0.028554, l3: 0.046307, l4: 0.087534, l5: 0.195991, l6: 0.394508\n",
      "\n",
      "[epoch: 351/400, batch: 96/1000, ite: 46638] train loss: 1.1665, accuracy: 95.8412%, tar: 0.0245 \n",
      "l0: 0.020824, l1: 0.021738, l2: 0.028204, l3: 0.040129, l4: 0.076701, l5: 0.165390, l6: 0.439547\n",
      "\n",
      "[epoch: 351/400, batch: 104/1000, ite: 46639] train loss: 1.1666, accuracy: 94.4489%, tar: 0.0245 \n",
      "l0: 0.027355, l1: 0.029935, l2: 0.039329, l3: 0.066871, l4: 0.142134, l5: 0.265155, l6: 0.545969\n",
      "\n",
      "[epoch: 351/400, batch: 112/1000, ite: 46640] train loss: 1.1674, accuracy: 93.7763%, tar: 0.0245 \n",
      "l0: 0.026782, l1: 0.028522, l2: 0.040035, l3: 0.063458, l4: 0.117150, l5: 0.241409, l6: 0.524790\n",
      "\n",
      "[epoch: 351/400, batch: 120/1000, ite: 46641] train loss: 1.1680, accuracy: 93.3951%, tar: 0.0245 \n",
      "l0: 0.021070, l1: 0.022085, l2: 0.029434, l3: 0.043408, l4: 0.080470, l5: 0.145708, l6: 0.286466\n",
      "\n",
      "[epoch: 351/400, batch: 128/1000, ite: 46642] train loss: 1.1676, accuracy: 95.9142%, tar: 0.0245 \n",
      "l0: 0.025756, l1: 0.027952, l2: 0.037336, l3: 0.055943, l4: 0.109855, l5: 0.212137, l6: 0.450006\n",
      "\n",
      "[epoch: 351/400, batch: 136/1000, ite: 46643] train loss: 1.1680, accuracy: 94.8378%, tar: 0.0245 \n",
      "l0: 0.020431, l1: 0.021073, l2: 0.027642, l3: 0.040794, l4: 0.079075, l5: 0.155437, l6: 0.359166\n",
      "\n",
      "[epoch: 351/400, batch: 144/1000, ite: 46644] train loss: 1.1678, accuracy: 94.9314%, tar: 0.0245 \n",
      "l0: 0.023475, l1: 0.024711, l2: 0.034170, l3: 0.053240, l4: 0.111068, l5: 0.216329, l6: 0.415977\n",
      "\n",
      "[epoch: 351/400, batch: 152/1000, ite: 46645] train loss: 1.1680, accuracy: 94.9567%, tar: 0.0245 \n",
      "l0: 0.020023, l1: 0.021605, l2: 0.029815, l3: 0.045332, l4: 0.082262, l5: 0.160868, l6: 0.294845\n",
      "\n",
      "[epoch: 351/400, batch: 160/1000, ite: 46646] train loss: 1.1677, accuracy: 95.5699%, tar: 0.0245 \n",
      "l0: 0.025096, l1: 0.026864, l2: 0.035008, l3: 0.053306, l4: 0.102755, l5: 0.217220, l6: 0.466300\n",
      "\n",
      "[epoch: 351/400, batch: 168/1000, ite: 46647] train loss: 1.1680, accuracy: 93.8884%, tar: 0.0245 \n",
      "l0: 0.023014, l1: 0.024290, l2: 0.030862, l3: 0.042946, l4: 0.078045, l5: 0.173885, l6: 0.416187\n",
      "\n",
      "[epoch: 351/400, batch: 176/1000, ite: 46648] train loss: 1.1681, accuracy: 94.3612%, tar: 0.0245 \n",
      "l0: 0.020033, l1: 0.020788, l2: 0.026239, l3: 0.035242, l4: 0.058056, l5: 0.114155, l6: 0.216861\n",
      "\n",
      "[epoch: 351/400, batch: 184/1000, ite: 46649] train loss: 1.1674, accuracy: 96.2728%, tar: 0.0245 \n",
      "l0: 0.025870, l1: 0.027678, l2: 0.038022, l3: 0.058644, l4: 0.127122, l5: 0.263952, l6: 0.451075\n",
      "\n",
      "[epoch: 351/400, batch: 192/1000, ite: 46650] train loss: 1.1678, accuracy: 93.5225%, tar: 0.0245 \n",
      "l0: 0.019437, l1: 0.020429, l2: 0.026387, l3: 0.036896, l4: 0.062773, l5: 0.120967, l6: 0.257242\n",
      "\n",
      "[epoch: 351/400, batch: 200/1000, ite: 46651] train loss: 1.1673, accuracy: 96.2547%, tar: 0.0245 \n",
      "l0: 0.025427, l1: 0.026959, l2: 0.035458, l3: 0.051084, l4: 0.097112, l5: 0.170242, l6: 0.361437\n",
      "\n",
      "[epoch: 351/400, batch: 208/1000, ite: 46652] train loss: 1.1672, accuracy: 94.3601%, tar: 0.0245 \n",
      "l0: 0.022836, l1: 0.023927, l2: 0.030088, l3: 0.041869, l4: 0.073867, l5: 0.142999, l6: 0.365322\n",
      "\n",
      "[epoch: 351/400, batch: 216/1000, ite: 46653] train loss: 1.1671, accuracy: 94.5895%, tar: 0.0245 \n",
      "l0: 0.024282, l1: 0.025911, l2: 0.032507, l3: 0.052221, l4: 0.100242, l5: 0.195424, l6: 0.411505\n",
      "\n",
      "[epoch: 351/400, batch: 224/1000, ite: 46654] train loss: 1.1672, accuracy: 94.3000%, tar: 0.0245 \n",
      "l0: 0.026308, l1: 0.027404, l2: 0.037905, l3: 0.052848, l4: 0.100279, l5: 0.222536, l6: 0.470646\n",
      "\n",
      "[epoch: 351/400, batch: 232/1000, ite: 46655] train loss: 1.1676, accuracy: 93.8747%, tar: 0.0245 \n",
      "l0: 0.027292, l1: 0.028898, l2: 0.036595, l3: 0.053335, l4: 0.095924, l5: 0.214792, l6: 0.438596\n",
      "\n",
      "[epoch: 351/400, batch: 240/1000, ite: 46656] train loss: 1.1679, accuracy: 94.2221%, tar: 0.0245 \n",
      "l0: 0.020101, l1: 0.021217, l2: 0.027262, l3: 0.040135, l4: 0.073022, l5: 0.134363, l6: 0.316887\n",
      "\n",
      "[epoch: 351/400, batch: 248/1000, ite: 46657] train loss: 1.1675, accuracy: 95.2078%, tar: 0.0245 \n",
      "l0: 0.017553, l1: 0.019042, l2: 0.026075, l3: 0.044624, l4: 0.081403, l5: 0.155478, l6: 0.292566\n",
      "\n",
      "[epoch: 351/400, batch: 256/1000, ite: 46658] train loss: 1.1672, accuracy: 95.3230%, tar: 0.0245 \n",
      "l0: 0.024458, l1: 0.026957, l2: 0.038732, l3: 0.069433, l4: 0.141219, l5: 0.271067, l6: 0.480466\n",
      "\n",
      "[epoch: 351/400, batch: 264/1000, ite: 46659] train loss: 1.1678, accuracy: 94.4446%, tar: 0.0245 \n",
      "l0: 0.020015, l1: 0.021405, l2: 0.029008, l3: 0.045163, l4: 0.077495, l5: 0.147336, l6: 0.371921\n",
      "\n",
      "[epoch: 351/400, batch: 272/1000, ite: 46660] train loss: 1.1676, accuracy: 94.8141%, tar: 0.0245 \n",
      "l0: 0.021900, l1: 0.023433, l2: 0.031190, l3: 0.048254, l4: 0.106087, l5: 0.202091, l6: 0.403909\n",
      "\n",
      "[epoch: 351/400, batch: 280/1000, ite: 46661] train loss: 1.1678, accuracy: 94.6082%, tar: 0.0245 \n",
      "l0: 0.020665, l1: 0.021883, l2: 0.029489, l3: 0.043609, l4: 0.084468, l5: 0.176124, l6: 0.422833\n",
      "\n",
      "[epoch: 351/400, batch: 288/1000, ite: 46662] train loss: 1.1678, accuracy: 95.1147%, tar: 0.0245 \n",
      "l0: 0.023100, l1: 0.023960, l2: 0.031538, l3: 0.044869, l4: 0.082954, l5: 0.172917, l6: 0.374376\n",
      "\n",
      "[epoch: 351/400, batch: 296/1000, ite: 46663] train loss: 1.1678, accuracy: 94.1155%, tar: 0.0245 \n",
      "l0: 0.026236, l1: 0.027698, l2: 0.035436, l3: 0.050581, l4: 0.089145, l5: 0.237788, l6: 0.520459\n",
      "\n",
      "[epoch: 351/400, batch: 304/1000, ite: 46664] train loss: 1.1683, accuracy: 93.7536%, tar: 0.0245 \n",
      "l0: 0.023081, l1: 0.024405, l2: 0.032663, l3: 0.050061, l4: 0.097380, l5: 0.188776, l6: 0.393600\n",
      "\n",
      "[epoch: 351/400, batch: 312/1000, ite: 46665] train loss: 1.1684, accuracy: 94.6577%, tar: 0.0245 \n",
      "l0: 0.023820, l1: 0.025650, l2: 0.034334, l3: 0.052657, l4: 0.093244, l5: 0.164704, l6: 0.346506\n",
      "\n",
      "[epoch: 351/400, batch: 320/1000, ite: 46666] train loss: 1.1683, accuracy: 95.0522%, tar: 0.0245 \n",
      "l0: 0.024003, l1: 0.024985, l2: 0.033007, l3: 0.048219, l4: 0.079110, l5: 0.155497, l6: 0.325644\n",
      "\n",
      "[epoch: 351/400, batch: 328/1000, ite: 46667] train loss: 1.1681, accuracy: 95.1757%, tar: 0.0245 \n",
      "l0: 0.023874, l1: 0.025294, l2: 0.035419, l3: 0.052538, l4: 0.110924, l5: 0.201681, l6: 0.385345\n",
      "\n",
      "[epoch: 351/400, batch: 336/1000, ite: 46668] train loss: 1.1681, accuracy: 94.9866%, tar: 0.0245 \n",
      "l0: 0.019127, l1: 0.020580, l2: 0.028062, l3: 0.042926, l4: 0.076131, l5: 0.176759, l6: 0.403251\n",
      "\n",
      "[epoch: 351/400, batch: 344/1000, ite: 46669] train loss: 1.1681, accuracy: 94.5508%, tar: 0.0245 \n",
      "l0: 0.026678, l1: 0.028026, l2: 0.037324, l3: 0.055661, l4: 0.106795, l5: 0.237707, l6: 0.418982\n",
      "\n",
      "[epoch: 351/400, batch: 352/1000, ite: 46670] train loss: 1.1684, accuracy: 93.7818%, tar: 0.0245 \n",
      "l0: 0.020889, l1: 0.023104, l2: 0.032080, l3: 0.048440, l4: 0.089434, l5: 0.181723, l6: 0.437303\n",
      "\n",
      "[epoch: 351/400, batch: 360/1000, ite: 46671] train loss: 1.1686, accuracy: 94.9444%, tar: 0.0245 \n",
      "l0: 0.025488, l1: 0.026527, l2: 0.033078, l3: 0.045488, l4: 0.073608, l5: 0.157585, l6: 0.337129\n",
      "\n",
      "[epoch: 351/400, batch: 368/1000, ite: 46672] train loss: 1.1684, accuracy: 94.8475%, tar: 0.0245 \n",
      "l0: 0.017718, l1: 0.019735, l2: 0.027869, l3: 0.045271, l4: 0.081079, l5: 0.150470, l6: 0.262819\n",
      "\n",
      "[epoch: 351/400, batch: 376/1000, ite: 46673] train loss: 1.1679, accuracy: 96.4321%, tar: 0.0244 \n",
      "l0: 0.020276, l1: 0.021565, l2: 0.027018, l3: 0.041566, l4: 0.079618, l5: 0.161474, l6: 0.420781\n",
      "\n",
      "[epoch: 351/400, batch: 384/1000, ite: 46674] train loss: 1.1680, accuracy: 94.4667%, tar: 0.0244 \n",
      "l0: 0.025503, l1: 0.026652, l2: 0.033886, l3: 0.047959, l4: 0.086777, l5: 0.159939, l6: 0.287380\n",
      "\n",
      "[epoch: 351/400, batch: 392/1000, ite: 46675] train loss: 1.1677, accuracy: 95.2324%, tar: 0.0244 \n",
      "l0: 0.015844, l1: 0.019007, l2: 0.028942, l3: 0.051304, l4: 0.096405, l5: 0.182247, l6: 0.345186\n",
      "\n",
      "[epoch: 351/400, batch: 400/1000, ite: 46676] train loss: 1.1676, accuracy: 96.4639%, tar: 0.0244 \n",
      "l0: 0.028661, l1: 0.030214, l2: 0.040099, l3: 0.055986, l4: 0.090031, l5: 0.181448, l6: 0.383163\n",
      "\n",
      "[epoch: 351/400, batch: 408/1000, ite: 46677] train loss: 1.1676, accuracy: 94.3022%, tar: 0.0244 \n",
      "l0: 0.023731, l1: 0.025785, l2: 0.034748, l3: 0.053381, l4: 0.103590, l5: 0.181178, l6: 0.362397\n",
      "\n",
      "[epoch: 351/400, batch: 416/1000, ite: 46678] train loss: 1.1676, accuracy: 95.4341%, tar: 0.0244 \n",
      "l0: 0.025884, l1: 0.027695, l2: 0.037806, l3: 0.054787, l4: 0.115865, l5: 0.258506, l6: 0.473741\n",
      "\n",
      "[epoch: 351/400, batch: 424/1000, ite: 46679] train loss: 1.1680, accuracy: 93.2457%, tar: 0.0244 \n",
      "l0: 0.027621, l1: 0.028776, l2: 0.039350, l3: 0.057217, l4: 0.101583, l5: 0.207966, l6: 0.382757\n",
      "\n",
      "[epoch: 351/400, batch: 432/1000, ite: 46680] train loss: 1.1681, accuracy: 93.8206%, tar: 0.0244 \n",
      "l0: 0.020804, l1: 0.021628, l2: 0.029322, l3: 0.043922, l4: 0.088996, l5: 0.156391, l6: 0.345859\n",
      "\n",
      "[epoch: 351/400, batch: 440/1000, ite: 46681] train loss: 1.1680, accuracy: 95.4101%, tar: 0.0244 \n",
      "l0: 0.032937, l1: 0.034795, l2: 0.045754, l3: 0.064435, l4: 0.120540, l5: 0.294418, l6: 0.574524\n",
      "\n",
      "[epoch: 351/400, batch: 448/1000, ite: 46682] train loss: 1.1688, accuracy: 92.2820%, tar: 0.0244 \n",
      "l0: 0.024415, l1: 0.025938, l2: 0.031841, l3: 0.044402, l4: 0.076314, l5: 0.146315, l6: 0.267417\n",
      "\n",
      "[epoch: 351/400, batch: 456/1000, ite: 46683] train loss: 1.1684, accuracy: 95.8885%, tar: 0.0244 \n",
      "l0: 0.025555, l1: 0.027128, l2: 0.037296, l3: 0.058427, l4: 0.101981, l5: 0.184739, l6: 0.350371\n",
      "\n",
      "[epoch: 351/400, batch: 464/1000, ite: 46684] train loss: 1.1684, accuracy: 94.8165%, tar: 0.0244 \n",
      "l0: 0.030937, l1: 0.033134, l2: 0.043215, l3: 0.069448, l4: 0.155214, l5: 0.283667, l6: 0.532907\n",
      "\n",
      "[epoch: 351/400, batch: 472/1000, ite: 46685] train loss: 1.1691, accuracy: 92.7572%, tar: 0.0245 \n",
      "l0: 0.022527, l1: 0.023720, l2: 0.031536, l3: 0.044519, l4: 0.081468, l5: 0.172126, l6: 0.324846\n",
      "\n",
      "[epoch: 351/400, batch: 480/1000, ite: 46686] train loss: 1.1689, accuracy: 95.6494%, tar: 0.0245 \n",
      "l0: 0.020014, l1: 0.021042, l2: 0.028470, l3: 0.040017, l4: 0.067585, l5: 0.146080, l6: 0.362286\n",
      "\n",
      "[epoch: 351/400, batch: 488/1000, ite: 46687] train loss: 1.1687, accuracy: 95.6501%, tar: 0.0244 \n",
      "l0: 0.016666, l1: 0.017909, l2: 0.024076, l3: 0.034098, l4: 0.063163, l5: 0.129763, l6: 0.321625\n",
      "\n",
      "[epoch: 351/400, batch: 496/1000, ite: 46688] train loss: 1.1684, accuracy: 96.0309%, tar: 0.0244 \n",
      "l0: 0.026140, l1: 0.026707, l2: 0.033159, l3: 0.043505, l4: 0.072876, l5: 0.129176, l6: 0.298562\n",
      "\n",
      "[epoch: 351/400, batch: 504/1000, ite: 46689] train loss: 1.1681, accuracy: 95.2017%, tar: 0.0244 \n",
      "l0: 0.027573, l1: 0.029074, l2: 0.037884, l3: 0.055202, l4: 0.108599, l5: 0.223926, l6: 0.439438\n",
      "\n",
      "[epoch: 351/400, batch: 512/1000, ite: 46690] train loss: 1.1684, accuracy: 93.8223%, tar: 0.0244 \n",
      "l0: 0.022571, l1: 0.023645, l2: 0.029142, l3: 0.043378, l4: 0.074334, l5: 0.129128, l6: 0.258182\n",
      "\n",
      "[epoch: 351/400, batch: 520/1000, ite: 46691] train loss: 1.1679, accuracy: 95.2877%, tar: 0.0244 \n",
      "l0: 0.021520, l1: 0.023174, l2: 0.030161, l3: 0.046183, l4: 0.076584, l5: 0.166478, l6: 0.299317\n",
      "\n",
      "[epoch: 351/400, batch: 528/1000, ite: 46692] train loss: 1.1676, accuracy: 95.5860%, tar: 0.0244 \n",
      "l0: 0.023386, l1: 0.025693, l2: 0.033210, l3: 0.052877, l4: 0.109195, l5: 0.238310, l6: 0.410393\n",
      "\n",
      "[epoch: 351/400, batch: 536/1000, ite: 46693] train loss: 1.1678, accuracy: 94.4084%, tar: 0.0244 \n",
      "l0: 0.030400, l1: 0.031884, l2: 0.042018, l3: 0.065201, l4: 0.129754, l5: 0.260716, l6: 0.497232\n",
      "\n",
      "[epoch: 351/400, batch: 544/1000, ite: 46694] train loss: 1.1684, accuracy: 92.6623%, tar: 0.0244 \n",
      "l0: 0.024854, l1: 0.026485, l2: 0.035068, l3: 0.054231, l4: 0.119634, l5: 0.242815, l6: 0.543152\n",
      "\n",
      "[epoch: 351/400, batch: 552/1000, ite: 46695] train loss: 1.1690, accuracy: 93.9915%, tar: 0.0244 \n",
      "l0: 0.022275, l1: 0.023325, l2: 0.032235, l3: 0.046652, l4: 0.092995, l5: 0.198932, l6: 0.384948\n",
      "\n",
      "[epoch: 351/400, batch: 560/1000, ite: 46696] train loss: 1.1690, accuracy: 95.3379%, tar: 0.0244 \n",
      "l0: 0.023143, l1: 0.024659, l2: 0.032810, l3: 0.052690, l4: 0.105739, l5: 0.244615, l6: 0.462468\n",
      "\n",
      "[epoch: 351/400, batch: 568/1000, ite: 46697] train loss: 1.1694, accuracy: 94.1150%, tar: 0.0244 \n",
      "l0: 0.022826, l1: 0.023259, l2: 0.029171, l3: 0.041540, l4: 0.063270, l5: 0.116112, l6: 0.240178\n",
      "\n",
      "[epoch: 351/400, batch: 576/1000, ite: 46698] train loss: 1.1688, accuracy: 96.0392%, tar: 0.0244 \n",
      "l0: 0.023963, l1: 0.025141, l2: 0.035337, l3: 0.053147, l4: 0.093247, l5: 0.202988, l6: 0.438201\n",
      "\n",
      "[epoch: 351/400, batch: 584/1000, ite: 46699] train loss: 1.1690, accuracy: 94.0851%, tar: 0.0244 \n",
      "l0: 0.022602, l1: 0.023575, l2: 0.031277, l3: 0.047211, l4: 0.081204, l5: 0.153914, l6: 0.307732\n",
      "\n",
      "[epoch: 351/400, batch: 592/1000, ite: 46700] train loss: 1.1687, accuracy: 95.2496%, tar: 0.0244 \n",
      "l0: 0.024662, l1: 0.026052, l2: 0.034810, l3: 0.049251, l4: 0.108001, l5: 0.189392, l6: 0.354745\n",
      "\n",
      "[epoch: 351/400, batch: 600/1000, ite: 46701] train loss: 1.1687, accuracy: 94.7669%, tar: 0.0244 \n",
      "l0: 0.021846, l1: 0.022957, l2: 0.029899, l3: 0.044086, l4: 0.076341, l5: 0.138742, l6: 0.299395\n",
      "\n",
      "[epoch: 351/400, batch: 608/1000, ite: 46702] train loss: 1.1684, accuracy: 95.3207%, tar: 0.0244 \n",
      "l0: 0.017464, l1: 0.018229, l2: 0.024072, l3: 0.034830, l4: 0.063413, l5: 0.133758, l6: 0.263342\n",
      "\n",
      "[epoch: 351/400, batch: 616/1000, ite: 46703] train loss: 1.1679, accuracy: 96.1605%, tar: 0.0244 \n",
      "l0: 0.030265, l1: 0.031979, l2: 0.043153, l3: 0.062093, l4: 0.115410, l5: 0.283993, l6: 0.519571\n",
      "\n",
      "[epoch: 351/400, batch: 624/1000, ite: 46704] train loss: 1.1685, accuracy: 92.8926%, tar: 0.0244 \n",
      "l0: 0.021429, l1: 0.021981, l2: 0.028997, l3: 0.038667, l4: 0.065634, l5: 0.131625, l6: 0.405975\n",
      "\n",
      "[epoch: 351/400, batch: 632/1000, ite: 46705] train loss: 1.1685, accuracy: 95.4365%, tar: 0.0244 \n",
      "l0: 0.019911, l1: 0.020905, l2: 0.026993, l3: 0.039098, l4: 0.081805, l5: 0.155724, l6: 0.303804\n",
      "\n",
      "[epoch: 351/400, batch: 640/1000, ite: 46706] train loss: 1.1682, accuracy: 95.8445%, tar: 0.0244 \n",
      "l0: 0.019188, l1: 0.020135, l2: 0.025749, l3: 0.038350, l4: 0.076975, l5: 0.146590, l6: 0.286886\n",
      "\n",
      "[epoch: 351/400, batch: 648/1000, ite: 46707] train loss: 1.1678, accuracy: 95.6312%, tar: 0.0244 \n",
      "l0: 0.026780, l1: 0.028075, l2: 0.036479, l3: 0.056771, l4: 0.103318, l5: 0.217358, l6: 0.482070\n",
      "\n",
      "[epoch: 351/400, batch: 656/1000, ite: 46708] train loss: 1.1682, accuracy: 92.9766%, tar: 0.0244 \n",
      "l0: 0.021610, l1: 0.022690, l2: 0.028978, l3: 0.043551, l4: 0.077718, l5: 0.156071, l6: 0.298230\n",
      "\n",
      "[epoch: 351/400, batch: 664/1000, ite: 46709] train loss: 1.1679, accuracy: 95.5783%, tar: 0.0244 \n",
      "l0: 0.017580, l1: 0.018758, l2: 0.024693, l3: 0.041110, l4: 0.077091, l5: 0.164343, l6: 0.277500\n",
      "\n",
      "[epoch: 351/400, batch: 672/1000, ite: 46710] train loss: 1.1675, accuracy: 95.4283%, tar: 0.0244 \n",
      "l0: 0.022339, l1: 0.023138, l2: 0.031610, l3: 0.045705, l4: 0.086770, l5: 0.169258, l6: 0.339786\n",
      "\n",
      "[epoch: 351/400, batch: 680/1000, ite: 46711] train loss: 1.1674, accuracy: 94.8720%, tar: 0.0244 \n",
      "l0: 0.021424, l1: 0.022226, l2: 0.027715, l3: 0.041041, l4: 0.076195, l5: 0.136452, l6: 0.298601\n",
      "\n",
      "[epoch: 351/400, batch: 688/1000, ite: 46712] train loss: 1.1670, accuracy: 95.2980%, tar: 0.0244 \n",
      "l0: 0.023316, l1: 0.024638, l2: 0.030897, l3: 0.043019, l4: 0.067484, l5: 0.109739, l6: 0.209370\n",
      "\n",
      "[epoch: 351/400, batch: 696/1000, ite: 46713] train loss: 1.1664, accuracy: 96.2748%, tar: 0.0244 \n",
      "l0: 0.020909, l1: 0.022430, l2: 0.031375, l3: 0.051836, l4: 0.100695, l5: 0.210460, l6: 0.336955\n",
      "\n",
      "[epoch: 351/400, batch: 704/1000, ite: 46714] train loss: 1.1663, accuracy: 95.8138%, tar: 0.0244 \n",
      "l0: 0.030619, l1: 0.032102, l2: 0.041461, l3: 0.061572, l4: 0.116623, l5: 0.269850, l6: 0.586308\n",
      "\n",
      "[epoch: 351/400, batch: 712/1000, ite: 46715] train loss: 1.1671, accuracy: 92.1296%, tar: 0.0244 \n",
      "l0: 0.055743, l1: 0.067242, l2: 0.073561, l3: 0.106044, l4: 0.165270, l5: 0.304127, l6: 0.378635\n",
      "\n",
      "[epoch: 351/400, batch: 720/1000, ite: 46716] train loss: 1.1676, accuracy: 93.4141%, tar: 0.0244 \n",
      "l0: 0.019802, l1: 0.021443, l2: 0.029776, l3: 0.048575, l4: 0.096339, l5: 0.186791, l6: 0.342983\n",
      "\n",
      "[epoch: 351/400, batch: 728/1000, ite: 46717] train loss: 1.1675, accuracy: 95.9201%, tar: 0.0244 \n",
      "l0: 0.015065, l1: 0.015597, l2: 0.021501, l3: 0.031944, l4: 0.053126, l5: 0.099069, l6: 0.207876\n",
      "\n",
      "[epoch: 351/400, batch: 736/1000, ite: 46718] train loss: 1.1668, accuracy: 97.1013%, tar: 0.0244 \n",
      "l0: 0.023270, l1: 0.024299, l2: 0.031441, l3: 0.046787, l4: 0.086076, l5: 0.144008, l6: 0.316325\n",
      "\n",
      "[epoch: 351/400, batch: 744/1000, ite: 46719] train loss: 1.1666, accuracy: 95.0733%, tar: 0.0244 \n",
      "l0: 0.017585, l1: 0.018764, l2: 0.026572, l3: 0.040036, l4: 0.071251, l5: 0.123901, l6: 0.236620\n",
      "\n",
      "[epoch: 351/400, batch: 752/1000, ite: 46720] train loss: 1.1660, accuracy: 96.5226%, tar: 0.0244 \n",
      "l0: 0.015869, l1: 0.017306, l2: 0.024755, l3: 0.041753, l4: 0.073538, l5: 0.131206, l6: 0.364688\n",
      "\n",
      "[epoch: 351/400, batch: 760/1000, ite: 46721] train loss: 1.1658, accuracy: 96.1659%, tar: 0.0244 \n",
      "l0: 0.029794, l1: 0.031127, l2: 0.040222, l3: 0.060662, l4: 0.102697, l5: 0.212515, l6: 0.359750\n",
      "\n",
      "[epoch: 351/400, batch: 768/1000, ite: 46722] train loss: 1.1659, accuracy: 94.8935%, tar: 0.0244 \n",
      "l0: 0.021643, l1: 0.022496, l2: 0.028176, l3: 0.039146, l4: 0.065916, l5: 0.129039, l6: 0.290368\n",
      "\n",
      "[epoch: 351/400, batch: 776/1000, ite: 46723] train loss: 1.1655, accuracy: 95.5970%, tar: 0.0244 \n",
      "l0: 0.032950, l1: 0.033897, l2: 0.043774, l3: 0.060762, l4: 0.108016, l5: 0.217016, l6: 0.431764\n",
      "\n",
      "[epoch: 351/400, batch: 784/1000, ite: 46724] train loss: 1.1658, accuracy: 93.6013%, tar: 0.0244 \n",
      "l0: 0.027827, l1: 0.029505, l2: 0.035846, l3: 0.053164, l4: 0.091217, l5: 0.157243, l6: 0.317736\n",
      "\n",
      "[epoch: 351/400, batch: 792/1000, ite: 46725] train loss: 1.1656, accuracy: 95.8597%, tar: 0.0244 \n",
      "l0: 0.031401, l1: 0.032956, l2: 0.041201, l3: 0.058776, l4: 0.111661, l5: 0.258305, l6: 0.452064\n",
      "\n",
      "[epoch: 351/400, batch: 800/1000, ite: 46726] train loss: 1.1660, accuracy: 93.3514%, tar: 0.0244 \n",
      "l0: 0.047068, l1: 0.041086, l2: 0.047740, l3: 0.058284, l4: 0.100849, l5: 0.167189, l6: 0.331923\n",
      "\n",
      "[epoch: 351/400, batch: 808/1000, ite: 46727] train loss: 1.1659, accuracy: 95.2668%, tar: 0.0245 \n",
      "l0: 0.019416, l1: 0.020057, l2: 0.025069, l3: 0.035243, l4: 0.055452, l5: 0.099697, l6: 0.203634\n",
      "\n",
      "[epoch: 351/400, batch: 816/1000, ite: 46728] train loss: 1.1652, accuracy: 96.5112%, tar: 0.0245 \n",
      "l0: 0.029682, l1: 0.031028, l2: 0.037153, l3: 0.049722, l4: 0.092046, l5: 0.183523, l6: 0.387599\n",
      "\n",
      "[epoch: 351/400, batch: 824/1000, ite: 46729] train loss: 1.1653, accuracy: 94.2295%, tar: 0.0245 \n",
      "l0: 0.019512, l1: 0.021314, l2: 0.028132, l3: 0.045144, l4: 0.084514, l5: 0.178178, l6: 0.346895\n",
      "\n",
      "[epoch: 351/400, batch: 832/1000, ite: 46730] train loss: 1.1652, accuracy: 95.4197%, tar: 0.0245 \n",
      "l0: 0.033157, l1: 0.033937, l2: 0.044947, l3: 0.066925, l4: 0.122427, l5: 0.244323, l6: 0.411707\n",
      "\n",
      "[epoch: 351/400, batch: 840/1000, ite: 46731] train loss: 1.1655, accuracy: 93.5181%, tar: 0.0245 \n",
      "l0: 0.029322, l1: 0.031033, l2: 0.040313, l3: 0.056991, l4: 0.095755, l5: 0.172610, l6: 0.276256\n",
      "\n",
      "[epoch: 351/400, batch: 848/1000, ite: 46732] train loss: 1.1652, accuracy: 95.8734%, tar: 0.0245 \n",
      "l0: 0.029931, l1: 0.031092, l2: 0.038871, l3: 0.057381, l4: 0.100022, l5: 0.212699, l6: 0.428463\n",
      "\n",
      "[epoch: 351/400, batch: 856/1000, ite: 46733] train loss: 1.1654, accuracy: 93.5473%, tar: 0.0245 \n",
      "l0: 0.026387, l1: 0.026585, l2: 0.032710, l3: 0.044939, l4: 0.072437, l5: 0.136428, l6: 0.268889\n",
      "\n",
      "[epoch: 351/400, batch: 864/1000, ite: 46734] train loss: 1.1651, accuracy: 95.5018%, tar: 0.0245 \n",
      "l0: 0.021121, l1: 0.022776, l2: 0.031608, l3: 0.044878, l4: 0.081745, l5: 0.165765, l6: 0.350184\n",
      "\n",
      "[epoch: 351/400, batch: 872/1000, ite: 46735] train loss: 1.1649, accuracy: 96.6545%, tar: 0.0245 \n",
      "l0: 0.032342, l1: 0.033754, l2: 0.042378, l3: 0.064348, l4: 0.111486, l5: 0.199313, l6: 0.392579\n",
      "\n",
      "[epoch: 351/400, batch: 880/1000, ite: 46736] train loss: 1.1651, accuracy: 94.6910%, tar: 0.0245 \n",
      "l0: 0.025190, l1: 0.025898, l2: 0.032352, l3: 0.049038, l4: 0.087571, l5: 0.151150, l6: 0.284324\n",
      "\n",
      "[epoch: 351/400, batch: 888/1000, ite: 46737] train loss: 1.1648, accuracy: 95.8041%, tar: 0.0245 \n",
      "l0: 0.032005, l1: 0.032507, l2: 0.040028, l3: 0.058529, l4: 0.102570, l5: 0.203936, l6: 0.411870\n",
      "\n",
      "[epoch: 351/400, batch: 896/1000, ite: 46738] train loss: 1.1650, accuracy: 94.0203%, tar: 0.0245 \n",
      "l0: 0.032967, l1: 0.033815, l2: 0.042908, l3: 0.063875, l4: 0.118226, l5: 0.270030, l6: 0.518906\n",
      "\n",
      "[epoch: 351/400, batch: 904/1000, ite: 46739] train loss: 1.1656, accuracy: 92.8350%, tar: 0.0245 \n",
      "l0: 0.030380, l1: 0.031914, l2: 0.041566, l3: 0.061865, l4: 0.106177, l5: 0.192415, l6: 0.365577\n",
      "\n",
      "[epoch: 351/400, batch: 912/1000, ite: 46740] train loss: 1.1656, accuracy: 95.4004%, tar: 0.0245 \n",
      "l0: 0.026941, l1: 0.027741, l2: 0.036052, l3: 0.052527, l4: 0.092893, l5: 0.166723, l6: 0.316108\n",
      "\n",
      "[epoch: 351/400, batch: 920/1000, ite: 46741] train loss: 1.1654, accuracy: 95.6760%, tar: 0.0245 \n",
      "l0: 0.022000, l1: 0.022352, l2: 0.027242, l3: 0.037328, l4: 0.067244, l5: 0.128962, l6: 0.249563\n",
      "\n",
      "[epoch: 351/400, batch: 928/1000, ite: 46742] train loss: 1.1650, accuracy: 95.9857%, tar: 0.0245 \n",
      "l0: 0.032080, l1: 0.033194, l2: 0.042787, l3: 0.063951, l4: 0.116912, l5: 0.243906, l6: 0.520016\n",
      "\n",
      "[epoch: 351/400, batch: 936/1000, ite: 46743] train loss: 1.1655, accuracy: 93.0538%, tar: 0.0245 \n",
      "l0: 0.040087, l1: 0.040832, l2: 0.049373, l3: 0.067343, l4: 0.115074, l5: 0.220318, l6: 0.477668\n",
      "\n",
      "[epoch: 351/400, batch: 944/1000, ite: 46744] train loss: 1.1660, accuracy: 92.8652%, tar: 0.0245 \n",
      "l0: 0.063129, l1: 0.069697, l2: 0.081006, l3: 0.108257, l4: 0.194375, l5: 0.327962, l6: 0.471324\n",
      "\n",
      "[epoch: 351/400, batch: 952/1000, ite: 46745] train loss: 1.1668, accuracy: 91.8583%, tar: 0.0246 \n",
      "l0: 0.050833, l1: 0.051750, l2: 0.058609, l3: 0.074625, l4: 0.125024, l5: 0.223901, l6: 0.418630\n",
      "\n",
      "[epoch: 351/400, batch: 960/1000, ite: 46746] train loss: 1.1672, accuracy: 93.5159%, tar: 0.0246 \n",
      "l0: 0.031633, l1: 0.032538, l2: 0.042272, l3: 0.068059, l4: 0.122845, l5: 0.228133, l6: 0.403772\n",
      "\n",
      "[epoch: 351/400, batch: 968/1000, ite: 46747] train loss: 1.1674, accuracy: 94.2638%, tar: 0.0246 \n",
      "l0: 0.029049, l1: 0.030719, l2: 0.040233, l3: 0.059305, l4: 0.105190, l5: 0.220732, l6: 0.423113\n",
      "\n",
      "[epoch: 351/400, batch: 976/1000, ite: 46748] train loss: 1.1676, accuracy: 94.5962%, tar: 0.0246 \n",
      "l0: 0.031986, l1: 0.033895, l2: 0.045643, l3: 0.072636, l4: 0.128539, l5: 0.209077, l6: 0.435358\n",
      "\n",
      "[epoch: 351/400, batch: 984/1000, ite: 46749] train loss: 1.1679, accuracy: 94.8918%, tar: 0.0247 \n",
      "l0: 0.034050, l1: 0.035187, l2: 0.042654, l3: 0.057907, l4: 0.099248, l5: 0.179241, l6: 0.386505\n",
      "\n",
      "[epoch: 351/400, batch: 992/1000, ite: 46750] train loss: 1.1680, accuracy: 94.0896%, tar: 0.0247 \n",
      "l0: 0.027371, l1: 0.029425, l2: 0.036126, l3: 0.052740, l4: 0.083190, l5: 0.153726, l6: 0.297132\n",
      "\n",
      "[epoch: 351/400, batch: 1000/1000, ite: 46751] train loss: 1.1677, accuracy: 95.8114%, tar: 0.0247 \n",
      "l0: 0.029458, l1: 0.030061, l2: 0.038041, l3: 0.053121, l4: 0.089233, l5: 0.161062, l6: 0.305374\n",
      "\n",
      "[epoch: 352/400, batch: 8/1000, ite: 46752] train loss: 1.1675, accuracy: 94.5275%, tar: 0.0247 \n",
      "l0: 0.040197, l1: 0.041610, l2: 0.052207, l3: 0.077523, l4: 0.154783, l5: 0.283991, l6: 0.473753\n",
      "\n",
      "[epoch: 352/400, batch: 16/1000, ite: 46753] train loss: 1.1681, accuracy: 93.0207%, tar: 0.0247 \n",
      "l0: 0.082842, l1: 0.090411, l2: 0.097982, l3: 0.115893, l4: 0.156448, l5: 0.228696, l6: 0.595360\n",
      "\n",
      "[epoch: 352/400, batch: 24/1000, ite: 46754] train loss: 1.1692, accuracy: 91.6955%, tar: 0.0248 \n",
      "l0: 0.039743, l1: 0.042382, l2: 0.049478, l3: 0.069417, l4: 0.125656, l5: 0.216780, l6: 0.414044\n",
      "\n",
      "[epoch: 352/400, batch: 32/1000, ite: 46755] train loss: 1.1694, accuracy: 93.5972%, tar: 0.0248 \n",
      "l0: 0.039681, l1: 0.042059, l2: 0.054911, l3: 0.080678, l4: 0.142996, l5: 0.261080, l6: 0.426985\n",
      "\n",
      "[epoch: 352/400, batch: 40/1000, ite: 46756] train loss: 1.1699, accuracy: 93.5512%, tar: 0.0248 \n",
      "l0: 0.027600, l1: 0.034636, l2: 0.041855, l3: 0.051159, l4: 0.074369, l5: 0.143830, l6: 0.275839\n",
      "\n",
      "[epoch: 352/400, batch: 48/1000, ite: 46757] train loss: 1.1695, accuracy: 95.9723%, tar: 0.0248 \n",
      "l0: 0.047686, l1: 0.049083, l2: 0.058772, l3: 0.082161, l4: 0.139266, l5: 0.243694, l6: 0.488032\n",
      "\n",
      "[epoch: 352/400, batch: 56/1000, ite: 46758] train loss: 1.1701, accuracy: 92.4857%, tar: 0.0249 \n",
      "l0: 0.035031, l1: 0.036080, l2: 0.043555, l3: 0.067978, l4: 0.116151, l5: 0.209067, l6: 0.488046\n",
      "\n",
      "[epoch: 352/400, batch: 64/1000, ite: 46759] train loss: 1.1705, accuracy: 93.8490%, tar: 0.0249 \n",
      "l0: 0.053128, l1: 0.061551, l2: 0.070868, l3: 0.093402, l4: 0.139779, l5: 0.177827, l6: 0.271004\n",
      "\n",
      "[epoch: 352/400, batch: 72/1000, ite: 46760] train loss: 1.1705, accuracy: 95.3359%, tar: 0.0249 \n",
      "l0: 0.034393, l1: 0.036007, l2: 0.046242, l3: 0.066667, l4: 0.125631, l5: 0.243450, l6: 0.506884\n",
      "\n",
      "[epoch: 352/400, batch: 80/1000, ite: 46761] train loss: 1.1710, accuracy: 93.7630%, tar: 0.0249 \n",
      "l0: 0.047826, l1: 0.049743, l2: 0.060016, l3: 0.088338, l4: 0.139635, l5: 0.233161, l6: 0.369850\n",
      "\n",
      "[epoch: 352/400, batch: 88/1000, ite: 46762] train loss: 1.1713, accuracy: 94.1477%, tar: 0.0249 \n",
      "l0: 0.035628, l1: 0.036969, l2: 0.045897, l3: 0.069051, l4: 0.115044, l5: 0.213958, l6: 0.410743\n",
      "\n",
      "[epoch: 352/400, batch: 96/1000, ite: 46763] train loss: 1.1715, accuracy: 94.2097%, tar: 0.0250 \n",
      "l0: 0.039721, l1: 0.040955, l2: 0.049230, l3: 0.067026, l4: 0.119624, l5: 0.218032, l6: 0.423858\n",
      "\n",
      "[epoch: 352/400, batch: 104/1000, ite: 46764] train loss: 1.1718, accuracy: 93.8526%, tar: 0.0250 \n",
      "l0: 0.033115, l1: 0.033928, l2: 0.043037, l3: 0.063466, l4: 0.122402, l5: 0.238638, l6: 0.452801\n",
      "\n",
      "[epoch: 352/400, batch: 112/1000, ite: 46765] train loss: 1.1722, accuracy: 94.2118%, tar: 0.0250 \n",
      "l0: 0.034940, l1: 0.039872, l2: 0.046397, l3: 0.063540, l4: 0.105859, l5: 0.198420, l6: 0.364477\n",
      "\n",
      "[epoch: 352/400, batch: 120/1000, ite: 46766] train loss: 1.1722, accuracy: 94.6281%, tar: 0.0250 \n",
      "l0: 0.043837, l1: 0.051446, l2: 0.061246, l3: 0.089417, l4: 0.168155, l5: 0.296281, l6: 0.481522\n",
      "\n",
      "[epoch: 352/400, batch: 128/1000, ite: 46767] train loss: 1.1729, accuracy: 93.7728%, tar: 0.0250 \n",
      "l0: 0.041372, l1: 0.042131, l2: 0.049600, l3: 0.068918, l4: 0.118993, l5: 0.213779, l6: 0.392002\n",
      "\n",
      "[epoch: 352/400, batch: 136/1000, ite: 46768] train loss: 1.1731, accuracy: 93.7719%, tar: 0.0250 \n",
      "l0: 0.061335, l1: 0.074662, l2: 0.083947, l3: 0.110738, l4: 0.190470, l5: 0.328616, l6: 0.534130\n",
      "\n",
      "[epoch: 352/400, batch: 144/1000, ite: 46769] train loss: 1.1741, accuracy: 91.3704%, tar: 0.0251 \n",
      "l0: 0.041289, l1: 0.042685, l2: 0.052440, l3: 0.074644, l4: 0.131343, l5: 0.240128, l6: 0.478690\n",
      "\n",
      "[epoch: 352/400, batch: 152/1000, ite: 46770] train loss: 1.1745, accuracy: 92.8414%, tar: 0.0251 \n",
      "l0: 0.029116, l1: 0.030367, l2: 0.036184, l3: 0.046413, l4: 0.077282, l5: 0.157744, l6: 0.309731\n",
      "\n",
      "[epoch: 352/400, batch: 160/1000, ite: 46771] train loss: 1.1743, accuracy: 95.4626%, tar: 0.0251 \n",
      "l0: 0.039921, l1: 0.043564, l2: 0.053744, l3: 0.078459, l4: 0.131466, l5: 0.222852, l6: 0.424584\n",
      "\n",
      "[epoch: 352/400, batch: 168/1000, ite: 46772] train loss: 1.1746, accuracy: 93.7341%, tar: 0.0251 \n",
      "l0: 0.038993, l1: 0.044345, l2: 0.050492, l3: 0.067466, l4: 0.112588, l5: 0.190875, l6: 0.355303\n",
      "\n",
      "[epoch: 352/400, batch: 176/1000, ite: 46773] train loss: 1.1747, accuracy: 94.0988%, tar: 0.0252 \n",
      "l0: 0.082616, l1: 0.081423, l2: 0.095034, l3: 0.121454, l4: 0.175319, l5: 0.266610, l6: 0.393649\n",
      "\n",
      "[epoch: 352/400, batch: 184/1000, ite: 46774] train loss: 1.1752, accuracy: 94.1799%, tar: 0.0252 \n",
      "l0: 0.036838, l1: 0.037883, l2: 0.046348, l3: 0.063203, l4: 0.110057, l5: 0.193168, l6: 0.415603\n",
      "\n",
      "[epoch: 352/400, batch: 192/1000, ite: 46775] train loss: 1.1754, accuracy: 93.9438%, tar: 0.0252 \n",
      "l0: 0.032606, l1: 0.034012, l2: 0.041853, l3: 0.058981, l4: 0.089436, l5: 0.158312, l6: 0.283400\n",
      "\n",
      "[epoch: 352/400, batch: 200/1000, ite: 46776] train loss: 1.1752, accuracy: 95.3556%, tar: 0.0253 \n",
      "l0: 0.039501, l1: 0.040909, l2: 0.050280, l3: 0.073277, l4: 0.124266, l5: 0.225314, l6: 0.374886\n",
      "\n",
      "[epoch: 352/400, batch: 208/1000, ite: 46777] train loss: 1.1754, accuracy: 94.1090%, tar: 0.0253 \n",
      "l0: 0.065085, l1: 0.081274, l2: 0.088747, l3: 0.097893, l4: 0.139480, l5: 0.240104, l6: 0.311462\n",
      "\n",
      "[epoch: 352/400, batch: 216/1000, ite: 46778] train loss: 1.1756, accuracy: 94.5507%, tar: 0.0253 \n",
      "l0: 0.035839, l1: 0.039727, l2: 0.046832, l3: 0.062529, l4: 0.101876, l5: 0.300757, l6: 0.408208\n",
      "\n",
      "[epoch: 352/400, batch: 224/1000, ite: 46779] train loss: 1.1760, accuracy: 93.0619%, tar: 0.0253 \n",
      "l0: 0.109358, l1: 0.106350, l2: 0.123172, l3: 0.153049, l4: 0.206050, l5: 0.310447, l6: 0.501757\n",
      "\n",
      "[epoch: 352/400, batch: 232/1000, ite: 46780] train loss: 1.1770, accuracy: 93.2606%, tar: 0.0254 \n",
      "l0: 0.041579, l1: 0.043070, l2: 0.056535, l3: 0.078521, l4: 0.125456, l5: 0.233582, l6: 0.411619\n",
      "\n",
      "[epoch: 352/400, batch: 240/1000, ite: 46781] train loss: 1.1773, accuracy: 93.9312%, tar: 0.0255 \n",
      "l0: 0.039811, l1: 0.040930, l2: 0.051397, l3: 0.080792, l4: 0.124341, l5: 0.223291, l6: 0.392716\n",
      "\n",
      "[epoch: 352/400, batch: 248/1000, ite: 46782] train loss: 1.1775, accuracy: 94.1511%, tar: 0.0255 \n",
      "l0: 0.045124, l1: 0.045952, l2: 0.053015, l3: 0.071395, l4: 0.121859, l5: 0.237708, l6: 0.433581\n",
      "\n",
      "[epoch: 352/400, batch: 256/1000, ite: 46783] train loss: 1.1778, accuracy: 94.0448%, tar: 0.0255 \n",
      "l0: 0.050562, l1: 0.065152, l2: 0.075230, l3: 0.099099, l4: 0.143723, l5: 0.234675, l6: 0.396103\n",
      "\n",
      "[epoch: 352/400, batch: 264/1000, ite: 46784] train loss: 1.1782, accuracy: 92.9055%, tar: 0.0255 \n",
      "l0: 0.037373, l1: 0.038582, l2: 0.048464, l3: 0.075834, l4: 0.137221, l5: 0.225879, l6: 0.423806\n",
      "\n",
      "[epoch: 352/400, batch: 272/1000, ite: 46785] train loss: 1.1785, accuracy: 94.5660%, tar: 0.0256 \n",
      "l0: 0.250607, l1: 0.268839, l2: 0.315699, l3: 0.515130, l4: 0.566465, l5: 1.151967, l6: 0.713425\n",
      "\n",
      "[epoch: 352/400, batch: 280/1000, ite: 46786] train loss: 1.1826, accuracy: 92.1659%, tar: 0.0258 \n",
      "l0: 0.031759, l1: 0.032959, l2: 0.040935, l3: 0.057142, l4: 0.107614, l5: 0.190819, l6: 0.423818\n",
      "\n",
      "[epoch: 352/400, batch: 288/1000, ite: 46787] train loss: 1.1827, accuracy: 94.6430%, tar: 0.0259 \n",
      "l0: 0.046410, l1: 0.044740, l2: 0.053393, l3: 0.072009, l4: 0.115639, l5: 0.193100, l6: 0.345222\n",
      "\n",
      "[epoch: 352/400, batch: 296/1000, ite: 46788] train loss: 1.1828, accuracy: 94.8536%, tar: 0.0259 \n",
      "l0: 0.046377, l1: 0.047979, l2: 0.057485, l3: 0.079214, l4: 0.118593, l5: 0.216041, l6: 0.397981\n",
      "\n",
      "[epoch: 352/400, batch: 304/1000, ite: 46789] train loss: 1.1830, accuracy: 94.3701%, tar: 0.0259 \n",
      "l0: 0.037083, l1: 0.037212, l2: 0.043615, l3: 0.061086, l4: 0.138596, l5: 0.227557, l6: 0.375534\n",
      "\n",
      "[epoch: 352/400, batch: 312/1000, ite: 46790] train loss: 1.1832, accuracy: 93.6676%, tar: 0.0259 \n",
      "l0: 0.041757, l1: 0.043401, l2: 0.054541, l3: 0.079511, l4: 0.143047, l5: 0.274521, l6: 0.521154\n",
      "\n",
      "[epoch: 352/400, batch: 320/1000, ite: 46791] train loss: 1.1838, accuracy: 92.8558%, tar: 0.0259 \n",
      "l0: 0.041980, l1: 0.044369, l2: 0.054056, l3: 0.070953, l4: 0.116366, l5: 0.221165, l6: 0.392361\n",
      "\n",
      "[epoch: 352/400, batch: 328/1000, ite: 46792] train loss: 1.1840, accuracy: 93.9666%, tar: 0.0260 \n",
      "l0: 0.048583, l1: 0.050137, l2: 0.058132, l3: 0.078322, l4: 0.137198, l5: 0.241067, l6: 0.484760\n",
      "\n",
      "[epoch: 352/400, batch: 336/1000, ite: 46793] train loss: 1.1845, accuracy: 92.3696%, tar: 0.0260 \n",
      "l0: 0.038449, l1: 0.042878, l2: 0.049438, l3: 0.067824, l4: 0.111212, l5: 0.211139, l6: 0.426054\n",
      "\n",
      "[epoch: 352/400, batch: 344/1000, ite: 46794] train loss: 1.1848, accuracy: 93.0913%, tar: 0.0260 \n",
      "l0: 0.030317, l1: 0.031464, l2: 0.037357, l3: 0.051344, l4: 0.094544, l5: 0.169327, l6: 0.315316\n",
      "\n",
      "[epoch: 352/400, batch: 352/1000, ite: 46795] train loss: 1.1847, accuracy: 95.1824%, tar: 0.0260 \n",
      "l0: 0.116319, l1: 0.128513, l2: 0.141096, l3: 0.186702, l4: 0.239575, l5: 0.573070, l6: 0.579835\n",
      "\n",
      "[epoch: 352/400, batch: 360/1000, ite: 46796] train loss: 1.1863, accuracy: 92.3960%, tar: 0.0261 \n",
      "l0: 0.060921, l1: 0.063705, l2: 0.072269, l3: 0.099151, l4: 0.162555, l5: 0.285759, l6: 0.548501\n",
      "\n",
      "[epoch: 352/400, batch: 368/1000, ite: 46797] train loss: 1.1872, accuracy: 90.5919%, tar: 0.0262 \n",
      "l0: 0.088588, l1: 0.091638, l2: 0.101078, l3: 0.128131, l4: 0.179860, l5: 0.300346, l6: 0.541272\n",
      "\n",
      "[epoch: 352/400, batch: 376/1000, ite: 46798] train loss: 1.1881, accuracy: 92.6389%, tar: 0.0262 \n",
      "l0: 0.046857, l1: 0.048238, l2: 0.054279, l3: 0.071568, l4: 0.110452, l5: 0.208852, l6: 0.383843\n",
      "\n",
      "[epoch: 352/400, batch: 384/1000, ite: 46799] train loss: 1.1883, accuracy: 93.7939%, tar: 0.0263 \n",
      "l0: 0.045395, l1: 0.047169, l2: 0.053856, l3: 0.077906, l4: 0.123357, l5: 0.244620, l6: 0.478938\n",
      "\n",
      "[epoch: 352/400, batch: 392/1000, ite: 46800] train loss: 1.1888, accuracy: 92.8345%, tar: 0.0263 \n",
      "l0: 0.045363, l1: 0.046025, l2: 0.053854, l3: 0.072263, l4: 0.116330, l5: 0.220744, l6: 0.446944\n",
      "\n",
      "[epoch: 352/400, batch: 400/1000, ite: 46801] train loss: 1.1891, accuracy: 93.7698%, tar: 0.0263 \n",
      "l0: 0.041075, l1: 0.043553, l2: 0.049038, l3: 0.061367, l4: 0.092861, l5: 0.180985, l6: 0.334744\n",
      "\n",
      "[epoch: 352/400, batch: 408/1000, ite: 46802] train loss: 1.1891, accuracy: 94.3168%, tar: 0.0263 \n",
      "l0: 0.036752, l1: 0.037832, l2: 0.043627, l3: 0.058007, l4: 0.095254, l5: 0.193495, l6: 0.340276\n",
      "\n",
      "[epoch: 352/400, batch: 416/1000, ite: 46803] train loss: 1.1890, accuracy: 94.3090%, tar: 0.0263 \n",
      "l0: 0.035805, l1: 0.036597, l2: 0.043136, l3: 0.058137, l4: 0.108223, l5: 0.201936, l6: 0.387084\n",
      "\n",
      "[epoch: 352/400, batch: 424/1000, ite: 46804] train loss: 1.1891, accuracy: 94.6962%, tar: 0.0264 \n",
      "l0: 0.033019, l1: 0.034707, l2: 0.038994, l3: 0.053084, l4: 0.099086, l5: 0.189384, l6: 0.323075\n",
      "\n",
      "[epoch: 352/400, batch: 432/1000, ite: 46805] train loss: 1.1890, accuracy: 94.9424%, tar: 0.0264 \n",
      "l0: 0.030336, l1: 0.030593, l2: 0.037147, l3: 0.050926, l4: 0.081551, l5: 0.160106, l6: 0.307896\n",
      "\n",
      "[epoch: 352/400, batch: 440/1000, ite: 46806] train loss: 1.1888, accuracy: 95.3606%, tar: 0.0264 \n",
      "l0: 0.044351, l1: 0.045951, l2: 0.055568, l3: 0.079607, l4: 0.128723, l5: 0.232285, l6: 0.503751\n",
      "\n",
      "[epoch: 352/400, batch: 448/1000, ite: 46807] train loss: 1.1893, accuracy: 93.2678%, tar: 0.0264 \n",
      "l0: 0.072688, l1: 0.076113, l2: 0.085189, l3: 0.114935, l4: 0.195888, l5: 0.312190, l6: 0.518119\n",
      "\n",
      "[epoch: 352/400, batch: 456/1000, ite: 46808] train loss: 1.1902, accuracy: 92.9478%, tar: 0.0265 \n",
      "l0: 0.050517, l1: 0.050617, l2: 0.060737, l3: 0.087956, l4: 0.146657, l5: 0.246545, l6: 0.437279\n",
      "\n",
      "[epoch: 352/400, batch: 464/1000, ite: 46809] train loss: 1.1906, accuracy: 93.3805%, tar: 0.0265 \n",
      "l0: 0.029985, l1: 0.030585, l2: 0.035673, l3: 0.048251, l4: 0.076508, l5: 0.157761, l6: 0.295010\n",
      "\n",
      "[epoch: 352/400, batch: 472/1000, ite: 46810] train loss: 1.1903, accuracy: 95.4496%, tar: 0.0265 \n",
      "l0: 0.036333, l1: 0.037790, l2: 0.045044, l3: 0.059282, l4: 0.097415, l5: 0.168800, l6: 0.311896\n",
      "\n",
      "[epoch: 352/400, batch: 480/1000, ite: 46811] train loss: 1.1902, accuracy: 94.8386%, tar: 0.0265 \n",
      "l0: 0.033982, l1: 0.035342, l2: 0.042167, l3: 0.055236, l4: 0.090962, l5: 0.185924, l6: 0.376944\n",
      "\n",
      "[epoch: 352/400, batch: 488/1000, ite: 46812] train loss: 1.1902, accuracy: 94.7237%, tar: 0.0265 \n",
      "l0: 0.037930, l1: 0.038858, l2: 0.046354, l3: 0.063768, l4: 0.124470, l5: 0.245485, l6: 0.408353\n",
      "\n",
      "[epoch: 352/400, batch: 496/1000, ite: 46813] train loss: 1.1904, accuracy: 93.9442%, tar: 0.0265 \n",
      "l0: 0.039133, l1: 0.040365, l2: 0.047079, l3: 0.061520, l4: 0.102490, l5: 0.172093, l6: 0.364173\n",
      "\n",
      "[epoch: 352/400, batch: 504/1000, ite: 46814] train loss: 1.1904, accuracy: 94.1809%, tar: 0.0265 \n",
      "l0: 0.044196, l1: 0.044803, l2: 0.052670, l3: 0.068578, l4: 0.118829, l5: 0.219090, l6: 0.397356\n",
      "\n",
      "[epoch: 352/400, batch: 512/1000, ite: 46815] train loss: 1.1906, accuracy: 93.4215%, tar: 0.0266 \n",
      "l0: 0.034270, l1: 0.035996, l2: 0.045339, l3: 0.064578, l4: 0.115361, l5: 0.198057, l6: 0.437309\n",
      "\n",
      "[epoch: 352/400, batch: 520/1000, ite: 46816] train loss: 1.1908, accuracy: 94.4966%, tar: 0.0266 \n",
      "l0: 0.028113, l1: 0.029443, l2: 0.035582, l3: 0.047094, l4: 0.077990, l5: 0.137803, l6: 0.261685\n",
      "\n",
      "[epoch: 352/400, batch: 528/1000, ite: 46817] train loss: 1.1905, accuracy: 95.2741%, tar: 0.0266 \n",
      "l0: 0.040809, l1: 0.041982, l2: 0.047405, l3: 0.062885, l4: 0.104143, l5: 0.178796, l6: 0.366567\n",
      "\n",
      "[epoch: 352/400, batch: 536/1000, ite: 46818] train loss: 1.1905, accuracy: 94.1564%, tar: 0.0266 \n",
      "l0: 0.044096, l1: 0.046165, l2: 0.057022, l3: 0.082614, l4: 0.151961, l5: 0.316042, l6: 0.491176\n",
      "\n",
      "[epoch: 352/400, batch: 544/1000, ite: 46819] train loss: 1.1911, accuracy: 92.9093%, tar: 0.0266 \n",
      "l0: 0.038679, l1: 0.041410, l2: 0.052147, l3: 0.072166, l4: 0.122790, l5: 0.220986, l6: 0.392869\n",
      "\n",
      "[epoch: 352/400, batch: 552/1000, ite: 46820] train loss: 1.1913, accuracy: 94.9768%, tar: 0.0266 \n",
      "l0: 0.035977, l1: 0.037141, l2: 0.043101, l3: 0.059408, l4: 0.097632, l5: 0.186103, l6: 0.363198\n",
      "\n",
      "[epoch: 352/400, batch: 560/1000, ite: 46821] train loss: 1.1913, accuracy: 94.2971%, tar: 0.0266 \n",
      "l0: 0.035659, l1: 0.036716, l2: 0.042238, l3: 0.055339, l4: 0.089725, l5: 0.164917, l6: 0.315498\n",
      "\n",
      "[epoch: 352/400, batch: 568/1000, ite: 46822] train loss: 1.1912, accuracy: 94.7144%, tar: 0.0266 \n",
      "l0: 0.034636, l1: 0.035426, l2: 0.041789, l3: 0.058991, l4: 0.105619, l5: 0.204333, l6: 0.388707\n",
      "\n",
      "[epoch: 352/400, batch: 576/1000, ite: 46823] train loss: 1.1912, accuracy: 93.7683%, tar: 0.0267 \n",
      "l0: 0.029536, l1: 0.030117, l2: 0.036571, l3: 0.051697, l4: 0.085887, l5: 0.157946, l6: 0.316075\n",
      "\n",
      "[epoch: 352/400, batch: 584/1000, ite: 46824] train loss: 1.1910, accuracy: 95.0615%, tar: 0.0267 \n",
      "l0: 0.046880, l1: 0.048637, l2: 0.060078, l3: 0.084175, l4: 0.142646, l5: 0.278248, l6: 0.503423\n",
      "\n",
      "[epoch: 352/400, batch: 592/1000, ite: 46825] train loss: 1.1916, accuracy: 92.5814%, tar: 0.0267 \n",
      "l0: 0.028463, l1: 0.029811, l2: 0.037635, l3: 0.056262, l4: 0.137872, l5: 0.214489, l6: 0.405705\n",
      "\n",
      "[epoch: 352/400, batch: 600/1000, ite: 46826] train loss: 1.1918, accuracy: 94.3845%, tar: 0.0267 \n",
      "l0: 0.039129, l1: 0.040090, l2: 0.047486, l3: 0.074370, l4: 0.136907, l5: 0.310501, l6: 0.562480\n",
      "\n",
      "[epoch: 352/400, batch: 608/1000, ite: 46827] train loss: 1.1925, accuracy: 92.5084%, tar: 0.0267 \n",
      "l0: 0.031290, l1: 0.031683, l2: 0.039188, l3: 0.053227, l4: 0.088877, l5: 0.162654, l6: 0.299280\n",
      "\n",
      "[epoch: 352/400, batch: 616/1000, ite: 46828] train loss: 1.1922, accuracy: 94.6580%, tar: 0.0267 \n",
      "l0: 0.029910, l1: 0.031002, l2: 0.037005, l3: 0.052548, l4: 0.086422, l5: 0.169900, l6: 0.325762\n",
      "\n",
      "[epoch: 352/400, batch: 624/1000, ite: 46829] train loss: 1.1921, accuracy: 94.5398%, tar: 0.0267 \n",
      "l0: 0.035380, l1: 0.036849, l2: 0.045010, l3: 0.064150, l4: 0.106480, l5: 0.157296, l6: 0.343535\n",
      "\n",
      "[epoch: 352/400, batch: 632/1000, ite: 46830] train loss: 1.1920, accuracy: 95.1879%, tar: 0.0267 \n",
      "l0: 0.046825, l1: 0.047824, l2: 0.057804, l3: 0.078081, l4: 0.135468, l5: 0.265870, l6: 0.557566\n",
      "\n",
      "[epoch: 352/400, batch: 640/1000, ite: 46831] train loss: 1.1927, accuracy: 93.0098%, tar: 0.0267 \n",
      "l0: 0.029618, l1: 0.031471, l2: 0.040170, l3: 0.057237, l4: 0.101952, l5: 0.179942, l6: 0.328294\n",
      "\n",
      "[epoch: 352/400, batch: 648/1000, ite: 46832] train loss: 1.1926, accuracy: 95.2263%, tar: 0.0268 \n",
      "l0: 0.031889, l1: 0.032975, l2: 0.041360, l3: 0.055867, l4: 0.085624, l5: 0.143051, l6: 0.275851\n",
      "\n",
      "[epoch: 352/400, batch: 656/1000, ite: 46833] train loss: 1.1923, accuracy: 95.2102%, tar: 0.0268 \n",
      "l0: 0.049665, l1: 0.051644, l2: 0.062384, l3: 0.087784, l4: 0.142690, l5: 0.263494, l6: 0.470814\n",
      "\n",
      "[epoch: 352/400, batch: 664/1000, ite: 46834] train loss: 1.1928, accuracy: 93.3834%, tar: 0.0268 \n",
      "l0: 0.028084, l1: 0.028835, l2: 0.036729, l3: 0.054804, l4: 0.097491, l5: 0.184687, l6: 0.298235\n",
      "\n",
      "[epoch: 352/400, batch: 672/1000, ite: 46835] train loss: 1.1926, accuracy: 94.9426%, tar: 0.0268 \n",
      "l0: 0.031882, l1: 0.032893, l2: 0.042081, l3: 0.058530, l4: 0.100269, l5: 0.178438, l6: 0.412533\n",
      "\n",
      "[epoch: 352/400, batch: 680/1000, ite: 46836] train loss: 1.1927, accuracy: 94.3088%, tar: 0.0268 \n",
      "l0: 0.038147, l1: 0.040666, l2: 0.049948, l3: 0.071786, l4: 0.126136, l5: 0.213642, l6: 0.384813\n",
      "\n",
      "[epoch: 352/400, batch: 688/1000, ite: 46837] train loss: 1.1928, accuracy: 94.8707%, tar: 0.0268 \n",
      "l0: 0.033429, l1: 0.034663, l2: 0.043653, l3: 0.059224, l4: 0.099432, l5: 0.162224, l6: 0.318951\n",
      "\n",
      "[epoch: 352/400, batch: 696/1000, ite: 46838] train loss: 1.1927, accuracy: 95.2570%, tar: 0.0268 \n",
      "l0: 0.033750, l1: 0.034556, l2: 0.042835, l3: 0.058012, l4: 0.094031, l5: 0.201905, l6: 0.407342\n",
      "\n",
      "[epoch: 352/400, batch: 704/1000, ite: 46839] train loss: 1.1928, accuracy: 93.8153%, tar: 0.0268 \n",
      "l0: 0.023686, l1: 0.025251, l2: 0.033441, l3: 0.047744, l4: 0.078317, l5: 0.153337, l6: 0.274371\n",
      "\n",
      "[epoch: 352/400, batch: 712/1000, ite: 46840] train loss: 1.1925, accuracy: 95.9058%, tar: 0.0268 \n",
      "l0: 0.031789, l1: 0.033187, l2: 0.041121, l3: 0.058767, l4: 0.102920, l5: 0.174948, l6: 0.335592\n",
      "\n",
      "[epoch: 352/400, batch: 720/1000, ite: 46841] train loss: 1.1924, accuracy: 95.3716%, tar: 0.0268 \n",
      "l0: 0.032101, l1: 0.033694, l2: 0.043866, l3: 0.066659, l4: 0.114365, l5: 0.204726, l6: 0.375097\n",
      "\n",
      "[epoch: 352/400, batch: 728/1000, ite: 46842] train loss: 1.1925, accuracy: 95.4917%, tar: 0.0268 \n",
      "l0: 0.053481, l1: 0.055584, l2: 0.066587, l3: 0.087417, l4: 0.153415, l5: 0.299125, l6: 0.546479\n",
      "\n",
      "[epoch: 352/400, batch: 736/1000, ite: 46843] train loss: 1.1932, accuracy: 91.8334%, tar: 0.0269 \n",
      "l0: 0.033893, l1: 0.035449, l2: 0.043852, l3: 0.065064, l4: 0.111460, l5: 0.218508, l6: 0.368821\n",
      "\n",
      "[epoch: 352/400, batch: 744/1000, ite: 46844] train loss: 1.1933, accuracy: 94.1134%, tar: 0.0269 \n",
      "l0: 0.018067, l1: 0.019025, l2: 0.025547, l3: 0.038290, l4: 0.060883, l5: 0.101936, l6: 0.216906\n",
      "\n",
      "[epoch: 352/400, batch: 752/1000, ite: 46845] train loss: 1.1927, accuracy: 97.0967%, tar: 0.0269 \n",
      "l0: 0.027887, l1: 0.028957, l2: 0.036927, l3: 0.050332, l4: 0.081421, l5: 0.144708, l6: 0.335387\n",
      "\n",
      "[epoch: 352/400, batch: 760/1000, ite: 46846] train loss: 1.1926, accuracy: 95.4951%, tar: 0.0269 \n",
      "l0: 0.034787, l1: 0.035736, l2: 0.042036, l3: 0.058935, l4: 0.107953, l5: 0.202950, l6: 0.344732\n",
      "\n",
      "[epoch: 352/400, batch: 768/1000, ite: 46847] train loss: 1.1925, accuracy: 94.4005%, tar: 0.0269 \n",
      "l0: 0.040722, l1: 0.042077, l2: 0.054373, l3: 0.079421, l4: 0.135749, l5: 0.266428, l6: 0.492743\n",
      "\n",
      "[epoch: 352/400, batch: 776/1000, ite: 46848] train loss: 1.1930, accuracy: 92.5360%, tar: 0.0269 \n",
      "l0: 0.031750, l1: 0.033314, l2: 0.041856, l3: 0.056807, l4: 0.085307, l5: 0.134444, l6: 0.255520\n",
      "\n",
      "[epoch: 352/400, batch: 784/1000, ite: 46849] train loss: 1.1927, accuracy: 96.0343%, tar: 0.0269 \n",
      "l0: 0.025099, l1: 0.026588, l2: 0.032958, l3: 0.046920, l4: 0.094188, l5: 0.175410, l6: 0.357827\n",
      "\n",
      "[epoch: 352/400, batch: 792/1000, ite: 46850] train loss: 1.1926, accuracy: 95.6566%, tar: 0.0269 \n",
      "l0: 0.032260, l1: 0.033899, l2: 0.045143, l3: 0.064368, l4: 0.114346, l5: 0.236939, l6: 0.471877\n",
      "\n",
      "[epoch: 352/400, batch: 800/1000, ite: 46851] train loss: 1.1930, accuracy: 94.5064%, tar: 0.0269 \n",
      "l0: 0.030717, l1: 0.031513, l2: 0.039013, l3: 0.056186, l4: 0.099822, l5: 0.187703, l6: 0.369958\n",
      "\n",
      "[epoch: 352/400, batch: 808/1000, ite: 46852] train loss: 1.1930, accuracy: 93.8264%, tar: 0.0269 \n",
      "l0: 0.043203, l1: 0.044467, l2: 0.054904, l3: 0.079022, l4: 0.126141, l5: 0.250006, l6: 0.525602\n",
      "\n",
      "[epoch: 352/400, batch: 816/1000, ite: 46853] train loss: 1.1935, accuracy: 92.8617%, tar: 0.0269 \n",
      "l0: 0.027809, l1: 0.030309, l2: 0.039132, l3: 0.058978, l4: 0.091883, l5: 0.153841, l6: 0.285852\n",
      "\n",
      "[epoch: 352/400, batch: 824/1000, ite: 46854] train loss: 1.1933, accuracy: 95.8241%, tar: 0.0269 \n",
      "l0: 0.026352, l1: 0.027753, l2: 0.036402, l3: 0.056374, l4: 0.096770, l5: 0.177319, l6: 0.351593\n",
      "\n",
      "[epoch: 352/400, batch: 832/1000, ite: 46855] train loss: 1.1932, accuracy: 95.0851%, tar: 0.0269 \n",
      "l0: 0.025786, l1: 0.027000, l2: 0.035981, l3: 0.059175, l4: 0.109474, l5: 0.199255, l6: 0.378591\n",
      "\n",
      "[epoch: 352/400, batch: 840/1000, ite: 46856] train loss: 1.1932, accuracy: 94.9600%, tar: 0.0269 \n",
      "l0: 0.027089, l1: 0.028299, l2: 0.033832, l3: 0.047796, l4: 0.082178, l5: 0.186676, l6: 0.308470\n",
      "\n",
      "[epoch: 352/400, batch: 848/1000, ite: 46857] train loss: 1.1930, accuracy: 95.5022%, tar: 0.0269 \n",
      "l0: 0.029901, l1: 0.030813, l2: 0.036599, l3: 0.050180, l4: 0.084472, l5: 0.173376, l6: 0.316364\n",
      "\n",
      "[epoch: 352/400, batch: 856/1000, ite: 46858] train loss: 1.1929, accuracy: 95.1214%, tar: 0.0269 \n",
      "l0: 0.034558, l1: 0.035855, l2: 0.047103, l3: 0.067593, l4: 0.113237, l5: 0.250040, l6: 0.491261\n",
      "\n",
      "[epoch: 352/400, batch: 864/1000, ite: 46859] train loss: 1.1933, accuracy: 92.7609%, tar: 0.0269 \n",
      "l0: 0.030988, l1: 0.031634, l2: 0.038329, l3: 0.051673, l4: 0.089877, l5: 0.171959, l6: 0.353887\n",
      "\n",
      "[epoch: 352/400, batch: 872/1000, ite: 46860] train loss: 1.1932, accuracy: 95.2031%, tar: 0.0269 \n",
      "l0: 0.027938, l1: 0.029062, l2: 0.037655, l3: 0.055691, l4: 0.100627, l5: 0.203443, l6: 0.396329\n",
      "\n",
      "[epoch: 352/400, batch: 880/1000, ite: 46861] train loss: 1.1933, accuracy: 94.2003%, tar: 0.0269 \n",
      "l0: 0.032633, l1: 0.033753, l2: 0.040986, l3: 0.056850, l4: 0.088305, l5: 0.167090, l6: 0.299501\n",
      "\n",
      "[epoch: 352/400, batch: 888/1000, ite: 46862] train loss: 1.1931, accuracy: 94.8250%, tar: 0.0269 \n",
      "l0: 0.038290, l1: 0.039623, l2: 0.052046, l3: 0.074719, l4: 0.130175, l5: 0.245233, l6: 0.515488\n",
      "\n",
      "[epoch: 352/400, batch: 896/1000, ite: 46863] train loss: 1.1936, accuracy: 93.1747%, tar: 0.0270 \n",
      "l0: 0.027890, l1: 0.029069, l2: 0.036469, l3: 0.051492, l4: 0.085310, l5: 0.154496, l6: 0.278052\n",
      "\n",
      "[epoch: 352/400, batch: 904/1000, ite: 46864] train loss: 1.1933, accuracy: 95.2776%, tar: 0.0270 \n",
      "l0: 0.033160, l1: 0.034685, l2: 0.041719, l3: 0.061121, l4: 0.115996, l5: 0.228362, l6: 0.506726\n",
      "\n",
      "[epoch: 352/400, batch: 912/1000, ite: 46865] train loss: 1.1937, accuracy: 93.0870%, tar: 0.0270 \n",
      "l0: 0.027921, l1: 0.029266, l2: 0.039197, l3: 0.056611, l4: 0.095621, l5: 0.215796, l6: 0.350859\n",
      "\n",
      "[epoch: 352/400, batch: 920/1000, ite: 46866] train loss: 1.1937, accuracy: 94.4117%, tar: 0.0270 \n",
      "l0: 0.029270, l1: 0.030309, l2: 0.036552, l3: 0.056550, l4: 0.103958, l5: 0.189036, l6: 0.442357\n",
      "\n",
      "[epoch: 352/400, batch: 928/1000, ite: 46867] train loss: 1.1938, accuracy: 94.0899%, tar: 0.0270 \n",
      "l0: 0.026482, l1: 0.027331, l2: 0.033703, l3: 0.047129, l4: 0.082757, l5: 0.155339, l6: 0.329724\n",
      "\n",
      "[epoch: 352/400, batch: 936/1000, ite: 46868] train loss: 1.1936, accuracy: 95.2231%, tar: 0.0270 \n",
      "l0: 0.033770, l1: 0.035297, l2: 0.043859, l3: 0.059966, l4: 0.092662, l5: 0.209668, l6: 0.421248\n",
      "\n",
      "[epoch: 352/400, batch: 944/1000, ite: 46869] train loss: 1.1938, accuracy: 94.1678%, tar: 0.0270 \n",
      "l0: 0.023811, l1: 0.024592, l2: 0.032142, l3: 0.045779, l4: 0.075734, l5: 0.129415, l6: 0.277786\n",
      "\n",
      "[epoch: 352/400, batch: 952/1000, ite: 46870] train loss: 1.1935, accuracy: 95.4592%, tar: 0.0270 \n",
      "l0: 0.026162, l1: 0.027674, l2: 0.037334, l3: 0.055660, l4: 0.107660, l5: 0.240785, l6: 0.461829\n",
      "\n",
      "[epoch: 352/400, batch: 960/1000, ite: 46871] train loss: 1.1937, accuracy: 93.9836%, tar: 0.0270 \n",
      "l0: 0.030198, l1: 0.031132, l2: 0.038109, l3: 0.053895, l4: 0.102917, l5: 0.214649, l6: 0.399837\n",
      "\n",
      "[epoch: 352/400, batch: 968/1000, ite: 46872] train loss: 1.1938, accuracy: 94.7400%, tar: 0.0270 \n",
      "l0: 0.022937, l1: 0.023704, l2: 0.029614, l3: 0.041068, l4: 0.070729, l5: 0.148198, l6: 0.310963\n",
      "\n",
      "[epoch: 352/400, batch: 976/1000, ite: 46873] train loss: 1.1936, accuracy: 95.4586%, tar: 0.0270 \n",
      "l0: 0.028244, l1: 0.029595, l2: 0.037558, l3: 0.053397, l4: 0.089244, l5: 0.188472, l6: 0.379825\n",
      "\n",
      "[epoch: 352/400, batch: 984/1000, ite: 46874] train loss: 1.1936, accuracy: 94.9348%, tar: 0.0270 \n",
      "l0: 0.030427, l1: 0.031851, l2: 0.041009, l3: 0.067272, l4: 0.114086, l5: 0.205865, l6: 0.481512\n",
      "\n",
      "[epoch: 352/400, batch: 992/1000, ite: 46875] train loss: 1.1939, accuracy: 92.9214%, tar: 0.0270 \n",
      "l0: 0.028554, l1: 0.029809, l2: 0.038690, l3: 0.058949, l4: 0.106762, l5: 0.224529, l6: 0.440889\n",
      "\n",
      "[epoch: 352/400, batch: 1000/1000, ite: 46876] train loss: 1.1941, accuracy: 93.7270%, tar: 0.0270 \n",
      "l0: 0.029049, l1: 0.030080, l2: 0.039433, l3: 0.056925, l4: 0.095658, l5: 0.188323, l6: 0.381583\n",
      "\n",
      "[epoch: 353/400, batch: 8/1000, ite: 46877] train loss: 1.1941, accuracy: 94.2337%, tar: 0.0270 \n",
      "l0: 0.038305, l1: 0.039216, l2: 0.047306, l3: 0.064914, l4: 0.111424, l5: 0.210510, l6: 0.535446\n",
      "\n",
      "[epoch: 353/400, batch: 16/1000, ite: 46878] train loss: 1.1945, accuracy: 92.0619%, tar: 0.0270 \n",
      "l0: 0.022237, l1: 0.022735, l2: 0.030174, l3: 0.041927, l4: 0.071115, l5: 0.141071, l6: 0.294102\n",
      "\n",
      "[epoch: 353/400, batch: 24/1000, ite: 46879] train loss: 1.1942, accuracy: 95.6935%, tar: 0.0270 \n",
      "l0: 0.023852, l1: 0.024572, l2: 0.030966, l3: 0.045278, l4: 0.077153, l5: 0.131263, l6: 0.264786\n",
      "\n",
      "[epoch: 353/400, batch: 32/1000, ite: 46880] train loss: 1.1939, accuracy: 95.6750%, tar: 0.0270 \n",
      "l0: 0.029511, l1: 0.030496, l2: 0.038762, l3: 0.055781, l4: 0.116568, l5: 0.231999, l6: 0.422468\n",
      "\n",
      "[epoch: 353/400, batch: 40/1000, ite: 46881] train loss: 1.1941, accuracy: 93.9028%, tar: 0.0270 \n",
      "l0: 0.022115, l1: 0.023348, l2: 0.030336, l3: 0.043601, l4: 0.076250, l5: 0.144932, l6: 0.279151\n",
      "\n",
      "[epoch: 353/400, batch: 48/1000, ite: 46882] train loss: 1.1937, accuracy: 95.4731%, tar: 0.0270 \n",
      "l0: 0.029497, l1: 0.030842, l2: 0.038582, l3: 0.063146, l4: 0.124960, l5: 0.235202, l6: 0.411235\n",
      "\n",
      "[epoch: 353/400, batch: 56/1000, ite: 46883] train loss: 1.1939, accuracy: 93.6954%, tar: 0.0270 \n",
      "l0: 0.020539, l1: 0.022391, l2: 0.029868, l3: 0.044546, l4: 0.080654, l5: 0.166757, l6: 0.350946\n",
      "\n",
      "[epoch: 353/400, batch: 64/1000, ite: 46884] train loss: 1.1937, accuracy: 95.1823%, tar: 0.0270 \n",
      "l0: 0.023127, l1: 0.024554, l2: 0.032501, l3: 0.048090, l4: 0.092700, l5: 0.189534, l6: 0.368407\n",
      "\n",
      "[epoch: 353/400, batch: 72/1000, ite: 46885] train loss: 1.1937, accuracy: 95.3963%, tar: 0.0270 \n",
      "l0: 0.022964, l1: 0.024100, l2: 0.032292, l3: 0.047557, l4: 0.086460, l5: 0.177336, l6: 0.342844\n",
      "\n",
      "[epoch: 353/400, batch: 80/1000, ite: 46886] train loss: 1.1936, accuracy: 95.2195%, tar: 0.0270 \n",
      "l0: 0.026299, l1: 0.027790, l2: 0.037073, l3: 0.053730, l4: 0.098987, l5: 0.169530, l6: 0.347918\n",
      "\n",
      "[epoch: 353/400, batch: 88/1000, ite: 46887] train loss: 1.1935, accuracy: 95.3658%, tar: 0.0270 \n",
      "l0: 0.028601, l1: 0.030044, l2: 0.038841, l3: 0.059836, l4: 0.118612, l5: 0.238288, l6: 0.441109\n",
      "\n",
      "[epoch: 353/400, batch: 96/1000, ite: 46888] train loss: 1.1937, accuracy: 93.7086%, tar: 0.0270 \n",
      "l0: 0.031170, l1: 0.032148, l2: 0.041799, l3: 0.058443, l4: 0.094864, l5: 0.213531, l6: 0.456381\n",
      "\n",
      "[epoch: 353/400, batch: 104/1000, ite: 46889] train loss: 1.1940, accuracy: 93.6932%, tar: 0.0270 \n",
      "l0: 0.019294, l1: 0.020327, l2: 0.027350, l3: 0.040252, l4: 0.076336, l5: 0.143001, l6: 0.296662\n",
      "\n",
      "[epoch: 353/400, batch: 112/1000, ite: 46890] train loss: 1.1936, accuracy: 95.9023%, tar: 0.0270 \n",
      "l0: 0.027706, l1: 0.028546, l2: 0.037726, l3: 0.052286, l4: 0.089585, l5: 0.178620, l6: 0.420462\n",
      "\n",
      "[epoch: 353/400, batch: 120/1000, ite: 46891] train loss: 1.1937, accuracy: 94.6156%, tar: 0.0270 \n",
      "l0: 0.020990, l1: 0.022146, l2: 0.028240, l3: 0.043657, l4: 0.074395, l5: 0.166358, l6: 0.339725\n",
      "\n",
      "[epoch: 353/400, batch: 128/1000, ite: 46892] train loss: 1.1936, accuracy: 94.9198%, tar: 0.0270 \n",
      "l0: 0.024371, l1: 0.025820, l2: 0.035243, l3: 0.058902, l4: 0.135846, l5: 0.226371, l6: 0.346528\n",
      "\n",
      "[epoch: 353/400, batch: 136/1000, ite: 46893] train loss: 1.1936, accuracy: 96.2200%, tar: 0.0270 \n",
      "l0: 0.026810, l1: 0.028193, l2: 0.037377, l3: 0.055326, l4: 0.110622, l5: 0.257513, l6: 0.485057\n",
      "\n",
      "[epoch: 353/400, batch: 144/1000, ite: 46894] train loss: 1.1939, accuracy: 94.1106%, tar: 0.0270 \n",
      "l0: 0.025425, l1: 0.026455, l2: 0.032891, l3: 0.050554, l4: 0.097023, l5: 0.196263, l6: 0.340651\n",
      "\n",
      "[epoch: 353/400, batch: 152/1000, ite: 46895] train loss: 1.1938, accuracy: 95.1366%, tar: 0.0270 \n",
      "l0: 0.028878, l1: 0.030990, l2: 0.039875, l3: 0.062329, l4: 0.105838, l5: 0.196981, l6: 0.418971\n",
      "\n",
      "[epoch: 353/400, batch: 160/1000, ite: 46896] train loss: 1.1939, accuracy: 95.1037%, tar: 0.0270 \n",
      "l0: 0.021001, l1: 0.021710, l2: 0.026353, l3: 0.041339, l4: 0.072011, l5: 0.127428, l6: 0.267967\n",
      "\n",
      "[epoch: 353/400, batch: 168/1000, ite: 46897] train loss: 1.1935, accuracy: 96.1503%, tar: 0.0270 \n",
      "l0: 0.022388, l1: 0.023212, l2: 0.029391, l3: 0.042202, l4: 0.073092, l5: 0.141341, l6: 0.296338\n",
      "\n",
      "[epoch: 353/400, batch: 176/1000, ite: 46898] train loss: 1.1933, accuracy: 95.1068%, tar: 0.0269 \n",
      "l0: 0.035504, l1: 0.037658, l2: 0.046010, l3: 0.067763, l4: 0.113515, l5: 0.198848, l6: 0.341982\n",
      "\n",
      "[epoch: 353/400, batch: 184/1000, ite: 46899] train loss: 1.1932, accuracy: 94.8518%, tar: 0.0270 \n",
      "l0: 0.026256, l1: 0.027746, l2: 0.036386, l3: 0.055305, l4: 0.114179, l5: 0.226892, l6: 0.410043\n",
      "\n",
      "[epoch: 353/400, batch: 192/1000, ite: 46900] train loss: 1.1934, accuracy: 94.8581%, tar: 0.0270 \n",
      "l0: 0.024646, l1: 0.025523, l2: 0.032561, l3: 0.048978, l4: 0.089254, l5: 0.190061, l6: 0.340891\n",
      "\n",
      "[epoch: 353/400, batch: 200/1000, ite: 46901] train loss: 1.1933, accuracy: 95.0207%, tar: 0.0270 \n",
      "l0: 0.025085, l1: 0.026578, l2: 0.035169, l3: 0.050961, l4: 0.089469, l5: 0.184688, l6: 0.453168\n",
      "\n",
      "[epoch: 353/400, batch: 208/1000, ite: 46902] train loss: 1.1934, accuracy: 94.0650%, tar: 0.0269 \n",
      "l0: 0.031785, l1: 0.033314, l2: 0.041762, l3: 0.063673, l4: 0.148143, l5: 0.248483, l6: 0.480171\n",
      "\n",
      "[epoch: 353/400, batch: 216/1000, ite: 46903] train loss: 1.1938, accuracy: 93.3578%, tar: 0.0270 \n",
      "l0: 0.024630, l1: 0.026205, l2: 0.034760, l3: 0.053367, l4: 0.096515, l5: 0.203847, l6: 0.437068\n",
      "\n",
      "[epoch: 353/400, batch: 224/1000, ite: 46904] train loss: 1.1939, accuracy: 94.3466%, tar: 0.0270 \n",
      "l0: 0.027213, l1: 0.027977, l2: 0.034353, l3: 0.052133, l4: 0.100482, l5: 0.161499, l6: 0.313304\n",
      "\n",
      "[epoch: 353/400, batch: 232/1000, ite: 46905] train loss: 1.1938, accuracy: 95.5757%, tar: 0.0270 \n",
      "l0: 0.032702, l1: 0.034346, l2: 0.044461, l3: 0.067117, l4: 0.124215, l5: 0.276480, l6: 0.612417\n",
      "\n",
      "[epoch: 353/400, batch: 240/1000, ite: 46906] train loss: 1.1945, accuracy: 91.6464%, tar: 0.0270 \n",
      "l0: 0.023415, l1: 0.025115, l2: 0.032325, l3: 0.046681, l4: 0.083554, l5: 0.183671, l6: 0.317925\n",
      "\n",
      "[epoch: 353/400, batch: 248/1000, ite: 46907] train loss: 1.1943, accuracy: 95.5681%, tar: 0.0270 \n",
      "l0: 0.031731, l1: 0.032643, l2: 0.039633, l3: 0.052727, l4: 0.090320, l5: 0.169137, l6: 0.383575\n",
      "\n",
      "[epoch: 353/400, batch: 256/1000, ite: 46908] train loss: 1.1943, accuracy: 94.2867%, tar: 0.0270 \n",
      "l0: 0.024641, l1: 0.025601, l2: 0.033470, l3: 0.049506, l4: 0.090180, l5: 0.181758, l6: 0.328222\n",
      "\n",
      "[epoch: 353/400, batch: 264/1000, ite: 46909] train loss: 1.1941, accuracy: 95.3710%, tar: 0.0270 \n",
      "l0: 0.032375, l1: 0.033762, l2: 0.042832, l3: 0.060473, l4: 0.104175, l5: 0.197019, l6: 0.395232\n",
      "\n",
      "[epoch: 353/400, batch: 272/1000, ite: 46910] train loss: 1.1942, accuracy: 94.5934%, tar: 0.0270 \n",
      "l0: 0.023966, l1: 0.025155, l2: 0.032290, l3: 0.047456, l4: 0.086348, l5: 0.156220, l6: 0.342243\n",
      "\n",
      "[epoch: 353/400, batch: 280/1000, ite: 46911] train loss: 1.1941, accuracy: 95.2006%, tar: 0.0270 \n",
      "l0: 0.025158, l1: 0.026347, l2: 0.035755, l3: 0.051288, l4: 0.083195, l5: 0.158516, l6: 0.307870\n",
      "\n",
      "[epoch: 353/400, batch: 288/1000, ite: 46912] train loss: 1.1939, accuracy: 95.1362%, tar: 0.0270 \n",
      "l0: 0.033897, l1: 0.035019, l2: 0.044977, l3: 0.067337, l4: 0.118713, l5: 0.233602, l6: 0.424242\n",
      "\n",
      "[epoch: 353/400, batch: 296/1000, ite: 46913] train loss: 1.1941, accuracy: 93.2133%, tar: 0.0270 \n",
      "l0: 0.025094, l1: 0.026616, l2: 0.034518, l3: 0.050535, l4: 0.097076, l5: 0.184602, l6: 0.434070\n",
      "\n",
      "[epoch: 353/400, batch: 304/1000, ite: 46914] train loss: 1.1942, accuracy: 94.4563%, tar: 0.0270 \n",
      "l0: 0.031779, l1: 0.033451, l2: 0.042779, l3: 0.061140, l4: 0.114416, l5: 0.241005, l6: 0.436120\n",
      "\n",
      "[epoch: 353/400, batch: 312/1000, ite: 46915] train loss: 1.1944, accuracy: 94.1844%, tar: 0.0270 \n",
      "l0: 0.027032, l1: 0.028732, l2: 0.040081, l3: 0.059778, l4: 0.102867, l5: 0.208669, l6: 0.419164\n",
      "\n",
      "[epoch: 353/400, batch: 320/1000, ite: 46916] train loss: 1.1945, accuracy: 94.5427%, tar: 0.0270 \n",
      "l0: 0.024393, l1: 0.025201, l2: 0.031038, l3: 0.042682, l4: 0.080422, l5: 0.167577, l6: 0.345033\n",
      "\n",
      "[epoch: 353/400, batch: 328/1000, ite: 46917] train loss: 1.1944, accuracy: 94.4734%, tar: 0.0270 \n",
      "l0: 0.024013, l1: 0.025205, l2: 0.033332, l3: 0.049613, l4: 0.082960, l5: 0.162691, l6: 0.335494\n",
      "\n",
      "[epoch: 353/400, batch: 336/1000, ite: 46918] train loss: 1.1942, accuracy: 95.1703%, tar: 0.0270 \n",
      "l0: 0.022799, l1: 0.024057, l2: 0.031522, l3: 0.045345, l4: 0.079680, l5: 0.144176, l6: 0.282198\n",
      "\n",
      "[epoch: 353/400, batch: 344/1000, ite: 46919] train loss: 1.1939, accuracy: 95.5428%, tar: 0.0270 \n",
      "l0: 0.027108, l1: 0.027827, l2: 0.034410, l3: 0.048385, l4: 0.087915, l5: 0.182071, l6: 0.341442\n",
      "\n",
      "[epoch: 353/400, batch: 352/1000, ite: 46920] train loss: 1.1938, accuracy: 95.2169%, tar: 0.0270 \n",
      "l0: 0.029555, l1: 0.031139, l2: 0.040379, l3: 0.057648, l4: 0.103599, l5: 0.229351, l6: 0.439866\n",
      "\n",
      "[epoch: 353/400, batch: 360/1000, ite: 46921] train loss: 1.1940, accuracy: 93.9432%, tar: 0.0270 \n",
      "l0: 0.023637, l1: 0.025298, l2: 0.034231, l3: 0.051294, l4: 0.095699, l5: 0.167939, l6: 0.282477\n",
      "\n",
      "[epoch: 353/400, batch: 368/1000, ite: 46922] train loss: 1.1938, accuracy: 96.1884%, tar: 0.0270 \n",
      "l0: 0.029593, l1: 0.030443, l2: 0.039856, l3: 0.054626, l4: 0.089577, l5: 0.185741, l6: 0.370131\n",
      "\n",
      "[epoch: 353/400, batch: 376/1000, ite: 46923] train loss: 1.1938, accuracy: 93.7582%, tar: 0.0270 \n",
      "l0: 0.027860, l1: 0.028818, l2: 0.036280, l3: 0.051233, l4: 0.082925, l5: 0.159906, l6: 0.326394\n",
      "\n",
      "[epoch: 353/400, batch: 384/1000, ite: 46924] train loss: 1.1936, accuracy: 94.9881%, tar: 0.0270 \n",
      "l0: 0.024438, l1: 0.026499, l2: 0.035131, l3: 0.051124, l4: 0.088014, l5: 0.191602, l6: 0.385834\n",
      "\n",
      "[epoch: 353/400, batch: 392/1000, ite: 46925] train loss: 1.1936, accuracy: 95.6684%, tar: 0.0270 \n",
      "l0: 0.021688, l1: 0.022902, l2: 0.030441, l3: 0.046046, l4: 0.075856, l5: 0.146725, l6: 0.413196\n",
      "\n",
      "[epoch: 353/400, batch: 400/1000, ite: 46926] train loss: 1.1936, accuracy: 94.7171%, tar: 0.0270 \n",
      "l0: 0.033909, l1: 0.035177, l2: 0.044286, l3: 0.061129, l4: 0.107982, l5: 0.233188, l6: 0.495292\n",
      "\n",
      "[epoch: 353/400, batch: 408/1000, ite: 46927] train loss: 1.1939, accuracy: 92.6332%, tar: 0.0270 \n",
      "l0: 0.027240, l1: 0.028871, l2: 0.036909, l3: 0.057560, l4: 0.110125, l5: 0.217502, l6: 0.396592\n",
      "\n",
      "[epoch: 353/400, batch: 416/1000, ite: 46928] train loss: 1.1940, accuracy: 93.6199%, tar: 0.0270 \n",
      "l0: 0.021622, l1: 0.022814, l2: 0.029878, l3: 0.049217, l4: 0.092549, l5: 0.177957, l6: 0.342955\n",
      "\n",
      "[epoch: 353/400, batch: 424/1000, ite: 46929] train loss: 1.1939, accuracy: 95.4863%, tar: 0.0270 \n",
      "l0: 0.024501, l1: 0.025716, l2: 0.032960, l3: 0.049988, l4: 0.086813, l5: 0.156584, l6: 0.324368\n",
      "\n",
      "[epoch: 353/400, batch: 432/1000, ite: 46930] train loss: 1.1937, accuracy: 95.2825%, tar: 0.0270 \n",
      "l0: 0.034241, l1: 0.035337, l2: 0.044645, l3: 0.066189, l4: 0.110638, l5: 0.213804, l6: 0.402986\n",
      "\n",
      "[epoch: 353/400, batch: 440/1000, ite: 46931] train loss: 1.1938, accuracy: 93.3718%, tar: 0.0270 \n",
      "l0: 0.045288, l1: 0.046720, l2: 0.056788, l3: 0.079757, l4: 0.145318, l5: 0.312479, l6: 0.669455\n",
      "\n",
      "[epoch: 353/400, batch: 448/1000, ite: 46932] train loss: 1.1947, accuracy: 90.3754%, tar: 0.0270 \n",
      "l0: 0.025473, l1: 0.026359, l2: 0.034105, l3: 0.048242, l4: 0.081389, l5: 0.141971, l6: 0.341579\n",
      "\n",
      "[epoch: 353/400, batch: 456/1000, ite: 46933] train loss: 1.1946, accuracy: 94.6838%, tar: 0.0270 \n",
      "l0: 0.024064, l1: 0.024845, l2: 0.031393, l3: 0.045656, l4: 0.084415, l5: 0.194109, l6: 0.400629\n",
      "\n",
      "[epoch: 353/400, batch: 464/1000, ite: 46934] train loss: 1.1946, accuracy: 93.8499%, tar: 0.0270 \n",
      "l0: 0.028243, l1: 0.031055, l2: 0.040606, l3: 0.062194, l4: 0.127433, l5: 0.267814, l6: 0.473496\n",
      "\n",
      "[epoch: 353/400, batch: 472/1000, ite: 46935] train loss: 1.1949, accuracy: 93.7559%, tar: 0.0270 \n",
      "l0: 0.020571, l1: 0.021603, l2: 0.028929, l3: 0.040615, l4: 0.072755, l5: 0.130653, l6: 0.303087\n",
      "\n",
      "[epoch: 353/400, batch: 480/1000, ite: 46936] train loss: 1.1946, accuracy: 95.3385%, tar: 0.0270 \n",
      "l0: 0.022010, l1: 0.024567, l2: 0.034208, l3: 0.051494, l4: 0.085441, l5: 0.160082, l6: 0.332497\n",
      "\n",
      "[epoch: 353/400, batch: 488/1000, ite: 46937] train loss: 1.1945, accuracy: 96.0172%, tar: 0.0270 \n",
      "l0: 0.024517, l1: 0.026297, l2: 0.034150, l3: 0.048268, l4: 0.095390, l5: 0.157324, l6: 0.267107\n",
      "\n",
      "[epoch: 353/400, batch: 496/1000, ite: 46938] train loss: 1.1942, accuracy: 95.9814%, tar: 0.0270 \n",
      "l0: 0.025200, l1: 0.026828, l2: 0.036519, l3: 0.053619, l4: 0.090536, l5: 0.175159, l6: 0.363861\n",
      "\n",
      "[epoch: 353/400, batch: 504/1000, ite: 46939] train loss: 1.1941, accuracy: 94.5944%, tar: 0.0270 \n",
      "l0: 0.024793, l1: 0.026065, l2: 0.032713, l3: 0.046859, l4: 0.086636, l5: 0.195548, l6: 0.360480\n",
      "\n",
      "[epoch: 353/400, batch: 512/1000, ite: 46940] train loss: 1.1941, accuracy: 94.9855%, tar: 0.0270 \n",
      "l0: 0.021592, l1: 0.023110, l2: 0.029976, l3: 0.046262, l4: 0.088834, l5: 0.200290, l6: 0.421665\n",
      "\n",
      "[epoch: 353/400, batch: 520/1000, ite: 46941] train loss: 1.1941, accuracy: 94.3645%, tar: 0.0270 \n",
      "l0: 0.024418, l1: 0.025486, l2: 0.033080, l3: 0.047535, l4: 0.077076, l5: 0.138116, l6: 0.307845\n",
      "\n",
      "[epoch: 353/400, batch: 528/1000, ite: 46942] train loss: 1.1939, accuracy: 95.5726%, tar: 0.0269 \n",
      "l0: 0.027292, l1: 0.028391, l2: 0.037495, l3: 0.051851, l4: 0.087125, l5: 0.153364, l6: 0.302967\n",
      "\n",
      "[epoch: 353/400, batch: 536/1000, ite: 46943] train loss: 1.1937, accuracy: 95.2807%, tar: 0.0270 \n",
      "l0: 0.033508, l1: 0.035672, l2: 0.047096, l3: 0.066123, l4: 0.103786, l5: 0.200693, l6: 0.391865\n",
      "\n",
      "[epoch: 353/400, batch: 544/1000, ite: 46944] train loss: 1.1938, accuracy: 93.9716%, tar: 0.0270 \n",
      "l0: 0.023705, l1: 0.024949, l2: 0.032118, l3: 0.043580, l4: 0.071414, l5: 0.122277, l6: 0.296895\n",
      "\n",
      "[epoch: 353/400, batch: 552/1000, ite: 46945] train loss: 1.1935, accuracy: 95.5793%, tar: 0.0270 \n",
      "l0: 0.018377, l1: 0.019269, l2: 0.025389, l3: 0.037608, l4: 0.071700, l5: 0.158722, l6: 0.324297\n",
      "\n",
      "[epoch: 353/400, batch: 560/1000, ite: 46946] train loss: 1.1932, accuracy: 95.8923%, tar: 0.0269 \n",
      "l0: 0.033564, l1: 0.034874, l2: 0.043846, l3: 0.064502, l4: 0.111496, l5: 0.227176, l6: 0.484302\n",
      "\n",
      "[epoch: 353/400, batch: 568/1000, ite: 46947] train loss: 1.1935, accuracy: 94.0550%, tar: 0.0270 \n",
      "l0: 0.028102, l1: 0.029583, l2: 0.040030, l3: 0.060819, l4: 0.123924, l5: 0.227237, l6: 0.396352\n",
      "\n",
      "[epoch: 353/400, batch: 576/1000, ite: 46948] train loss: 1.1937, accuracy: 94.0779%, tar: 0.0270 \n",
      "l0: 0.028869, l1: 0.029605, l2: 0.034411, l3: 0.053611, l4: 0.101884, l5: 0.186153, l6: 0.383243\n",
      "\n",
      "[epoch: 353/400, batch: 584/1000, ite: 46949] train loss: 1.1937, accuracy: 94.9837%, tar: 0.0270 \n",
      "l0: 0.029799, l1: 0.031790, l2: 0.043390, l3: 0.065581, l4: 0.124857, l5: 0.267827, l6: 0.481706\n",
      "\n",
      "[epoch: 353/400, batch: 592/1000, ite: 46950] train loss: 1.1940, accuracy: 94.0987%, tar: 0.0270 \n",
      "l0: 0.024731, l1: 0.025660, l2: 0.032738, l3: 0.046821, l4: 0.082794, l5: 0.181685, l6: 0.376396\n",
      "\n",
      "[epoch: 353/400, batch: 600/1000, ite: 46951] train loss: 1.1940, accuracy: 94.5305%, tar: 0.0270 \n",
      "l0: 0.027785, l1: 0.029615, l2: 0.038438, l3: 0.062277, l4: 0.122219, l5: 0.236127, l6: 0.487856\n",
      "\n",
      "[epoch: 353/400, batch: 608/1000, ite: 46952] train loss: 1.1943, accuracy: 94.1181%, tar: 0.0270 \n",
      "l0: 0.026014, l1: 0.027950, l2: 0.035815, l3: 0.049704, l4: 0.083296, l5: 0.186197, l6: 0.433279\n",
      "\n",
      "[epoch: 353/400, batch: 616/1000, ite: 46953] train loss: 1.1944, accuracy: 94.6989%, tar: 0.0270 \n",
      "l0: 0.024910, l1: 0.026153, l2: 0.031982, l3: 0.043467, l4: 0.073802, l5: 0.136971, l6: 0.361251\n",
      "\n",
      "[epoch: 353/400, batch: 624/1000, ite: 46954] train loss: 1.1943, accuracy: 94.7603%, tar: 0.0270 \n",
      "l0: 0.024232, l1: 0.027362, l2: 0.035695, l3: 0.052569, l4: 0.093536, l5: 0.172077, l6: 0.292624\n",
      "\n",
      "[epoch: 353/400, batch: 632/1000, ite: 46955] train loss: 1.1941, accuracy: 95.5541%, tar: 0.0270 \n",
      "l0: 0.025524, l1: 0.026432, l2: 0.033374, l3: 0.044630, l4: 0.067263, l5: 0.139452, l6: 0.290113\n",
      "\n",
      "[epoch: 353/400, batch: 640/1000, ite: 46956] train loss: 1.1938, accuracy: 95.0702%, tar: 0.0269 \n",
      "l0: 0.024514, l1: 0.025640, l2: 0.033347, l3: 0.049706, l4: 0.082591, l5: 0.168341, l6: 0.348554\n",
      "\n",
      "[epoch: 353/400, batch: 648/1000, ite: 46957] train loss: 1.1937, accuracy: 94.7682%, tar: 0.0269 \n",
      "l0: 0.025960, l1: 0.027491, l2: 0.035696, l3: 0.051890, l4: 0.093925, l5: 0.197218, l6: 0.383874\n",
      "\n",
      "[epoch: 353/400, batch: 656/1000, ite: 46958] train loss: 1.1937, accuracy: 95.5045%, tar: 0.0269 \n",
      "l0: 0.022136, l1: 0.022959, l2: 0.030447, l3: 0.042843, l4: 0.074715, l5: 0.173883, l6: 0.447873\n",
      "\n",
      "[epoch: 353/400, batch: 664/1000, ite: 46959] train loss: 1.1937, accuracy: 94.4699%, tar: 0.0269 \n",
      "l0: 0.023259, l1: 0.024596, l2: 0.034519, l3: 0.057818, l4: 0.106270, l5: 0.205290, l6: 0.435687\n",
      "\n",
      "[epoch: 353/400, batch: 672/1000, ite: 46960] train loss: 1.1939, accuracy: 94.6105%, tar: 0.0269 \n",
      "l0: 0.025253, l1: 0.026155, l2: 0.033935, l3: 0.046025, l4: 0.081671, l5: 0.169703, l6: 0.372297\n",
      "\n",
      "[epoch: 353/400, batch: 680/1000, ite: 46961] train loss: 1.1938, accuracy: 94.4769%, tar: 0.0269 \n",
      "l0: 0.025180, l1: 0.026588, l2: 0.034115, l3: 0.046468, l4: 0.086225, l5: 0.180473, l6: 0.335304\n",
      "\n",
      "[epoch: 353/400, batch: 688/1000, ite: 46962] train loss: 1.1937, accuracy: 95.2739%, tar: 0.0269 \n",
      "l0: 0.022768, l1: 0.024066, l2: 0.031883, l3: 0.046137, l4: 0.085525, l5: 0.196928, l6: 0.367147\n",
      "\n",
      "[epoch: 353/400, batch: 696/1000, ite: 46963] train loss: 1.1937, accuracy: 94.9109%, tar: 0.0269 \n",
      "l0: 0.019291, l1: 0.020972, l2: 0.030520, l3: 0.051298, l4: 0.097005, l5: 0.180132, l6: 0.339435\n",
      "\n",
      "[epoch: 353/400, batch: 704/1000, ite: 46964] train loss: 1.1935, accuracy: 95.9781%, tar: 0.0269 \n",
      "l0: 0.027686, l1: 0.028947, l2: 0.036784, l3: 0.056078, l4: 0.105975, l5: 0.233707, l6: 0.442340\n",
      "\n",
      "[epoch: 353/400, batch: 712/1000, ite: 46965] train loss: 1.1937, accuracy: 94.0826%, tar: 0.0269 \n",
      "l0: 0.028813, l1: 0.030160, l2: 0.036999, l3: 0.055552, l4: 0.098516, l5: 0.174296, l6: 0.326897\n",
      "\n",
      "[epoch: 353/400, batch: 720/1000, ite: 46966] train loss: 1.1936, accuracy: 95.0369%, tar: 0.0269 \n",
      "l0: 0.028268, l1: 0.030544, l2: 0.040037, l3: 0.064037, l4: 0.138215, l5: 0.345585, l6: 0.588092\n",
      "\n",
      "[epoch: 353/400, batch: 728/1000, ite: 46967] train loss: 1.1943, accuracy: 93.3295%, tar: 0.0269 \n",
      "l0: 0.026812, l1: 0.027786, l2: 0.036587, l3: 0.050390, l4: 0.086123, l5: 0.160107, l6: 0.320750\n",
      "\n",
      "[epoch: 353/400, batch: 736/1000, ite: 46968] train loss: 1.1941, accuracy: 94.7550%, tar: 0.0269 \n",
      "l0: 0.028352, l1: 0.029709, l2: 0.036574, l3: 0.050742, l4: 0.084507, l5: 0.173477, l6: 0.381873\n",
      "\n",
      "[epoch: 353/400, batch: 744/1000, ite: 46969] train loss: 1.1941, accuracy: 94.6213%, tar: 0.0269 \n",
      "l0: 0.026258, l1: 0.028284, l2: 0.036400, l3: 0.057158, l4: 0.122370, l5: 0.241603, l6: 0.389933\n",
      "\n",
      "[epoch: 353/400, batch: 752/1000, ite: 46970] train loss: 1.1942, accuracy: 94.5573%, tar: 0.0269 \n",
      "l0: 0.024224, l1: 0.025324, l2: 0.033743, l3: 0.047469, l4: 0.081465, l5: 0.144249, l6: 0.305469\n",
      "\n",
      "[epoch: 353/400, batch: 760/1000, ite: 46971] train loss: 1.1940, accuracy: 95.2914%, tar: 0.0269 \n",
      "l0: 0.027100, l1: 0.028496, l2: 0.036259, l3: 0.050190, l4: 0.094537, l5: 0.210618, l6: 0.441830\n",
      "\n",
      "[epoch: 353/400, batch: 768/1000, ite: 46972] train loss: 1.1941, accuracy: 93.9650%, tar: 0.0269 \n",
      "l0: 0.028642, l1: 0.030103, l2: 0.038376, l3: 0.054511, l4: 0.098384, l5: 0.189221, l6: 0.358918\n",
      "\n",
      "[epoch: 353/400, batch: 776/1000, ite: 46973] train loss: 1.1941, accuracy: 94.6782%, tar: 0.0269 \n",
      "l0: 0.024344, l1: 0.025686, l2: 0.034024, l3: 0.050186, l4: 0.089086, l5: 0.192315, l6: 0.356619\n",
      "\n",
      "[epoch: 353/400, batch: 784/1000, ite: 46974] train loss: 1.1940, accuracy: 95.3847%, tar: 0.0269 \n",
      "l0: 0.026100, l1: 0.028678, l2: 0.040198, l3: 0.067419, l4: 0.127794, l5: 0.234154, l6: 0.395111\n",
      "\n",
      "[epoch: 353/400, batch: 792/1000, ite: 46975] train loss: 1.1941, accuracy: 95.1498%, tar: 0.0269 \n",
      "l0: 0.022459, l1: 0.024147, l2: 0.033776, l3: 0.059832, l4: 0.104943, l5: 0.202149, l6: 0.401851\n",
      "\n",
      "[epoch: 353/400, batch: 800/1000, ite: 46976] train loss: 1.1942, accuracy: 94.8362%, tar: 0.0269 \n",
      "l0: 0.025391, l1: 0.028244, l2: 0.039607, l3: 0.061540, l4: 0.104380, l5: 0.177750, l6: 0.307016\n",
      "\n",
      "[epoch: 353/400, batch: 808/1000, ite: 46977] train loss: 1.1941, accuracy: 95.2837%, tar: 0.0269 \n",
      "l0: 0.021848, l1: 0.023587, l2: 0.031444, l3: 0.046190, l4: 0.091221, l5: 0.204646, l6: 0.346364\n",
      "\n",
      "[epoch: 353/400, batch: 816/1000, ite: 46978] train loss: 1.1940, accuracy: 94.9156%, tar: 0.0269 \n",
      "l0: 0.023058, l1: 0.023847, l2: 0.031947, l3: 0.050421, l4: 0.089019, l5: 0.164119, l6: 0.345214\n",
      "\n",
      "[epoch: 353/400, batch: 824/1000, ite: 46979] train loss: 1.1939, accuracy: 94.9440%, tar: 0.0269 \n",
      "l0: 0.020861, l1: 0.021717, l2: 0.030974, l3: 0.046729, l4: 0.099747, l5: 0.176923, l6: 0.344914\n",
      "\n",
      "[epoch: 353/400, batch: 832/1000, ite: 46980] train loss: 1.1938, accuracy: 96.1951%, tar: 0.0269 \n",
      "l0: 0.032593, l1: 0.034246, l2: 0.047039, l3: 0.077180, l4: 0.142290, l5: 0.297653, l6: 0.521040\n",
      "\n",
      "[epoch: 353/400, batch: 840/1000, ite: 46981] train loss: 1.1943, accuracy: 93.2181%, tar: 0.0269 \n",
      "l0: 0.024777, l1: 0.026027, l2: 0.033814, l3: 0.048580, l4: 0.086182, l5: 0.153864, l6: 0.309475\n",
      "\n",
      "[epoch: 353/400, batch: 848/1000, ite: 46982] train loss: 1.1941, accuracy: 95.1609%, tar: 0.0269 \n",
      "l0: 0.025539, l1: 0.026954, l2: 0.035660, l3: 0.053559, l4: 0.095868, l5: 0.189388, l6: 0.352102\n",
      "\n",
      "[epoch: 353/400, batch: 856/1000, ite: 46983] train loss: 1.1940, accuracy: 95.0916%, tar: 0.0269 \n",
      "l0: 0.025185, l1: 0.025758, l2: 0.034107, l3: 0.048229, l4: 0.082723, l5: 0.143469, l6: 0.291842\n",
      "\n",
      "[epoch: 353/400, batch: 864/1000, ite: 46984] train loss: 1.1937, accuracy: 95.5895%, tar: 0.0269 \n",
      "l0: 0.026012, l1: 0.027451, l2: 0.035877, l3: 0.053414, l4: 0.100939, l5: 0.205591, l6: 0.401866\n",
      "\n",
      "[epoch: 353/400, batch: 872/1000, ite: 46985] train loss: 1.1938, accuracy: 94.9639%, tar: 0.0269 \n",
      "l0: 0.025507, l1: 0.026560, l2: 0.033354, l3: 0.047042, l4: 0.081169, l5: 0.165101, l6: 0.339613\n",
      "\n",
      "[epoch: 353/400, batch: 880/1000, ite: 46986] train loss: 1.1937, accuracy: 94.8251%, tar: 0.0269 \n",
      "l0: 0.018135, l1: 0.019164, l2: 0.025147, l3: 0.036935, l4: 0.060425, l5: 0.108960, l6: 0.253844\n",
      "\n",
      "[epoch: 353/400, batch: 888/1000, ite: 46987] train loss: 1.1933, accuracy: 96.7021%, tar: 0.0269 \n",
      "l0: 0.028749, l1: 0.030173, l2: 0.035983, l3: 0.048970, l4: 0.085936, l5: 0.184084, l6: 0.371303\n",
      "\n",
      "[epoch: 353/400, batch: 896/1000, ite: 46988] train loss: 1.1932, accuracy: 94.1588%, tar: 0.0269 \n",
      "l0: 0.027622, l1: 0.028926, l2: 0.037353, l3: 0.053605, l4: 0.099719, l5: 0.218357, l6: 0.410380\n",
      "\n",
      "[epoch: 353/400, batch: 904/1000, ite: 46989] train loss: 1.1933, accuracy: 93.7674%, tar: 0.0269 \n",
      "l0: 0.024338, l1: 0.025289, l2: 0.031165, l3: 0.042652, l4: 0.070026, l5: 0.126177, l6: 0.249072\n",
      "\n",
      "[epoch: 353/400, batch: 912/1000, ite: 46990] train loss: 1.1930, accuracy: 95.7641%, tar: 0.0269 \n",
      "l0: 0.021064, l1: 0.022304, l2: 0.029268, l3: 0.044742, l4: 0.086016, l5: 0.157257, l6: 0.337314\n",
      "\n",
      "[epoch: 353/400, batch: 920/1000, ite: 46991] train loss: 1.1928, accuracy: 95.1232%, tar: 0.0269 \n",
      "l0: 0.020280, l1: 0.021734, l2: 0.030653, l3: 0.052082, l4: 0.107717, l5: 0.179630, l6: 0.350007\n",
      "\n",
      "[epoch: 353/400, batch: 928/1000, ite: 46992] train loss: 1.1927, accuracy: 95.6894%, tar: 0.0269 \n",
      "l0: 0.023437, l1: 0.024845, l2: 0.032624, l3: 0.047507, l4: 0.083854, l5: 0.159110, l6: 0.319442\n",
      "\n",
      "[epoch: 353/400, batch: 936/1000, ite: 46993] train loss: 1.1925, accuracy: 95.2573%, tar: 0.0269 \n",
      "l0: 0.027024, l1: 0.028066, l2: 0.035491, l3: 0.051576, l4: 0.099744, l5: 0.198614, l6: 0.421559\n",
      "\n",
      "[epoch: 353/400, batch: 944/1000, ite: 46994] train loss: 1.1927, accuracy: 94.3361%, tar: 0.0269 \n",
      "l0: 0.026254, l1: 0.027425, l2: 0.035730, l3: 0.050700, l4: 0.090783, l5: 0.182832, l6: 0.360328\n",
      "\n",
      "[epoch: 353/400, batch: 952/1000, ite: 46995] train loss: 1.1926, accuracy: 94.7030%, tar: 0.0269 \n",
      "l0: 0.023627, l1: 0.024890, l2: 0.031915, l3: 0.048333, l4: 0.094749, l5: 0.188682, l6: 0.351028\n",
      "\n",
      "[epoch: 353/400, batch: 960/1000, ite: 46996] train loss: 1.1925, accuracy: 94.9449%, tar: 0.0269 \n",
      "l0: 0.020709, l1: 0.021644, l2: 0.027176, l3: 0.038450, l4: 0.075132, l5: 0.171338, l6: 0.292437\n",
      "\n",
      "[epoch: 353/400, batch: 968/1000, ite: 46997] train loss: 1.1923, accuracy: 95.6570%, tar: 0.0269 \n",
      "l0: 0.028677, l1: 0.031147, l2: 0.040408, l3: 0.062336, l4: 0.116022, l5: 0.248723, l6: 0.526440\n",
      "\n",
      "[epoch: 353/400, batch: 976/1000, ite: 46998] train loss: 1.1927, accuracy: 94.2253%, tar: 0.0269 \n",
      "l0: 0.027512, l1: 0.028280, l2: 0.036117, l3: 0.046942, l4: 0.079064, l5: 0.182598, l6: 0.334450\n",
      "\n",
      "[epoch: 353/400, batch: 984/1000, ite: 46999] train loss: 1.1926, accuracy: 94.8451%, tar: 0.0269 \n",
      "l0: 0.023806, l1: 0.025581, l2: 0.033048, l3: 0.046235, l4: 0.103394, l5: 0.192331, l6: 0.346222\n",
      "\n",
      "[epoch: 353/400, batch: 992/1000, ite: 47000] train loss: 1.1925, accuracy: 94.9825%, tar: 0.0269 \n",
      "l0: 0.020572, l1: 0.021822, l2: 0.028769, l3: 0.040803, l4: 0.082631, l5: 0.147539, l6: 0.279680\n",
      "\n",
      "[epoch: 353/400, batch: 1000/1000, ite: 47001] train loss: 1.1922, accuracy: 95.7235%, tar: 0.0269 \n",
      "l0: 0.022989, l1: 0.024246, l2: 0.033228, l3: 0.050202, l4: 0.091054, l5: 0.178789, l6: 0.334014\n",
      "\n",
      "[epoch: 354/400, batch: 8/1000, ite: 47002] train loss: 1.1921, accuracy: 95.3884%, tar: 0.0269 \n",
      "l0: 0.023357, l1: 0.024167, l2: 0.030844, l3: 0.044091, l4: 0.079241, l5: 0.160169, l6: 0.325119\n",
      "\n",
      "[epoch: 354/400, batch: 16/1000, ite: 47003] train loss: 1.1919, accuracy: 95.0466%, tar: 0.0268 \n",
      "l0: 0.023590, l1: 0.024378, l2: 0.032665, l3: 0.048170, l4: 0.078924, l5: 0.145127, l6: 0.331870\n",
      "\n",
      "[epoch: 354/400, batch: 24/1000, ite: 47004] train loss: 1.1917, accuracy: 95.4706%, tar: 0.0268 \n",
      "l0: 0.025606, l1: 0.026735, l2: 0.034649, l3: 0.049677, l4: 0.077519, l5: 0.193576, l6: 0.350662\n",
      "\n",
      "[epoch: 354/400, batch: 32/1000, ite: 47005] train loss: 1.1917, accuracy: 95.2149%, tar: 0.0268 \n",
      "l0: 0.020922, l1: 0.021852, l2: 0.028243, l3: 0.040228, l4: 0.077044, l5: 0.164656, l6: 0.323401\n",
      "\n",
      "[epoch: 354/400, batch: 40/1000, ite: 47006] train loss: 1.1915, accuracy: 96.0944%, tar: 0.0268 \n",
      "l0: 0.026755, l1: 0.027827, l2: 0.035698, l3: 0.051937, l4: 0.099202, l5: 0.212161, l6: 0.447747\n",
      "\n",
      "[epoch: 354/400, batch: 48/1000, ite: 47007] train loss: 1.1916, accuracy: 93.7561%, tar: 0.0268 \n",
      "l0: 0.031527, l1: 0.033766, l2: 0.043969, l3: 0.061974, l4: 0.104883, l5: 0.234776, l6: 0.488579\n",
      "\n",
      "[epoch: 354/400, batch: 56/1000, ite: 47008] train loss: 1.1919, accuracy: 93.2155%, tar: 0.0268 \n",
      "l0: 0.023560, l1: 0.024674, l2: 0.031760, l3: 0.048172, l4: 0.078853, l5: 0.140884, l6: 0.312510\n",
      "\n",
      "[epoch: 354/400, batch: 64/1000, ite: 47009] train loss: 1.1917, accuracy: 94.9149%, tar: 0.0268 \n",
      "l0: 0.036697, l1: 0.038135, l2: 0.048447, l3: 0.073621, l4: 0.170063, l5: 0.284683, l6: 0.625058\n",
      "\n",
      "[epoch: 354/400, batch: 72/1000, ite: 47010] train loss: 1.1924, accuracy: 91.7426%, tar: 0.0268 \n",
      "l0: 0.020389, l1: 0.021162, l2: 0.028005, l3: 0.038993, l4: 0.066269, l5: 0.136208, l6: 0.304258\n",
      "\n",
      "[epoch: 354/400, batch: 80/1000, ite: 47011] train loss: 1.1922, accuracy: 95.5056%, tar: 0.0268 \n",
      "l0: 0.019968, l1: 0.021526, l2: 0.029835, l3: 0.045627, l4: 0.086472, l5: 0.187099, l6: 0.370920\n",
      "\n",
      "[epoch: 354/400, batch: 88/1000, ite: 47012] train loss: 1.1921, accuracy: 95.3924%, tar: 0.0268 \n",
      "l0: 0.022509, l1: 0.023789, l2: 0.031170, l3: 0.044685, l4: 0.081672, l5: 0.199311, l6: 0.455313\n",
      "\n",
      "[epoch: 354/400, batch: 96/1000, ite: 47013] train loss: 1.1922, accuracy: 94.2641%, tar: 0.0268 \n",
      "l0: 0.024243, l1: 0.025776, l2: 0.034964, l3: 0.054044, l4: 0.105601, l5: 0.220071, l6: 0.456510\n",
      "\n",
      "[epoch: 354/400, batch: 104/1000, ite: 47014] train loss: 1.1924, accuracy: 93.6831%, tar: 0.0268 \n",
      "l0: 0.021041, l1: 0.023469, l2: 0.031910, l3: 0.058244, l4: 0.127655, l5: 0.216951, l6: 0.368684\n",
      "\n",
      "[epoch: 354/400, batch: 112/1000, ite: 47015] train loss: 1.1924, accuracy: 95.8614%, tar: 0.0268 \n",
      "l0: 0.021637, l1: 0.023549, l2: 0.031123, l3: 0.053272, l4: 0.099285, l5: 0.172070, l6: 0.305712\n",
      "\n",
      "[epoch: 354/400, batch: 120/1000, ite: 47016] train loss: 1.1923, accuracy: 95.8652%, tar: 0.0268 \n",
      "l0: 0.027311, l1: 0.028717, l2: 0.035178, l3: 0.053811, l4: 0.098840, l5: 0.203569, l6: 0.403206\n",
      "\n",
      "[epoch: 354/400, batch: 128/1000, ite: 47017] train loss: 1.1923, accuracy: 94.4973%, tar: 0.0268 \n",
      "l0: 0.022333, l1: 0.023346, l2: 0.031869, l3: 0.046322, l4: 0.082979, l5: 0.158420, l6: 0.294441\n",
      "\n",
      "[epoch: 354/400, batch: 136/1000, ite: 47018] train loss: 1.1921, accuracy: 95.4791%, tar: 0.0268 \n",
      "l0: 0.021881, l1: 0.023444, l2: 0.031553, l3: 0.048204, l4: 0.094581, l5: 0.177077, l6: 0.314103\n",
      "\n",
      "[epoch: 354/400, batch: 144/1000, ite: 47019] train loss: 1.1920, accuracy: 95.3696%, tar: 0.0268 \n",
      "l0: 0.018231, l1: 0.019163, l2: 0.024136, l3: 0.032895, l4: 0.054623, l5: 0.112606, l6: 0.237010\n",
      "\n",
      "[epoch: 354/400, batch: 152/1000, ite: 47020] train loss: 1.1915, accuracy: 96.1731%, tar: 0.0268 \n",
      "l0: 0.016640, l1: 0.017733, l2: 0.025609, l3: 0.039519, l4: 0.070368, l5: 0.162795, l6: 0.328223\n",
      "\n",
      "[epoch: 354/400, batch: 160/1000, ite: 47021] train loss: 1.1913, accuracy: 96.1160%, tar: 0.0268 \n",
      "l0: 0.022795, l1: 0.023685, l2: 0.030551, l3: 0.048218, l4: 0.103907, l5: 0.199491, l6: 0.345605\n",
      "\n",
      "[epoch: 354/400, batch: 168/1000, ite: 47022] train loss: 1.1913, accuracy: 94.9175%, tar: 0.0268 \n",
      "l0: 0.024423, l1: 0.026213, l2: 0.034559, l3: 0.049791, l4: 0.085497, l5: 0.152615, l6: 0.316454\n",
      "\n",
      "[epoch: 354/400, batch: 176/1000, ite: 47023] train loss: 1.1911, accuracy: 95.6256%, tar: 0.0268 \n",
      "l0: 0.020984, l1: 0.022164, l2: 0.028676, l3: 0.038851, l4: 0.071444, l5: 0.154776, l6: 0.294056\n",
      "\n",
      "[epoch: 354/400, batch: 184/1000, ite: 47024] train loss: 1.1908, accuracy: 96.0770%, tar: 0.0268 \n",
      "l0: 0.027665, l1: 0.029183, l2: 0.038597, l3: 0.059984, l4: 0.098319, l5: 0.203362, l6: 0.449525\n",
      "\n",
      "[epoch: 354/400, batch: 192/1000, ite: 47025] train loss: 1.1910, accuracy: 94.2128%, tar: 0.0268 \n",
      "l0: 0.029782, l1: 0.030760, l2: 0.038215, l3: 0.055395, l4: 0.101964, l5: 0.172335, l6: 0.369120\n",
      "\n",
      "[epoch: 354/400, batch: 200/1000, ite: 47026] train loss: 1.1910, accuracy: 94.7982%, tar: 0.0268 \n",
      "l0: 0.021210, l1: 0.022180, l2: 0.029650, l3: 0.043461, l4: 0.077407, l5: 0.174121, l6: 0.362939\n",
      "\n",
      "[epoch: 354/400, batch: 208/1000, ite: 47027] train loss: 1.1909, accuracy: 95.0489%, tar: 0.0268 \n",
      "l0: 0.028651, l1: 0.030073, l2: 0.040088, l3: 0.057917, l4: 0.097018, l5: 0.172116, l6: 0.351512\n",
      "\n",
      "[epoch: 354/400, batch: 216/1000, ite: 47028] train loss: 1.1908, accuracy: 94.1960%, tar: 0.0268 \n",
      "l0: 0.026032, l1: 0.027375, l2: 0.035158, l3: 0.052082, l4: 0.099661, l5: 0.208255, l6: 0.400351\n",
      "\n",
      "[epoch: 354/400, batch: 224/1000, ite: 47029] train loss: 1.1909, accuracy: 94.3326%, tar: 0.0268 \n",
      "l0: 0.023671, l1: 0.024838, l2: 0.031779, l3: 0.049869, l4: 0.083521, l5: 0.175048, l6: 0.367485\n",
      "\n",
      "[epoch: 354/400, batch: 232/1000, ite: 47030] train loss: 1.1908, accuracy: 95.1952%, tar: 0.0268 \n",
      "l0: 0.018356, l1: 0.020440, l2: 0.028455, l3: 0.041734, l4: 0.074303, l5: 0.147854, l6: 0.313285\n",
      "\n",
      "[epoch: 354/400, batch: 240/1000, ite: 47031] train loss: 1.1906, accuracy: 95.8041%, tar: 0.0268 \n",
      "l0: 0.033229, l1: 0.035007, l2: 0.044430, l3: 0.063037, l4: 0.120674, l5: 0.266974, l6: 0.515210\n",
      "\n",
      "[epoch: 354/400, batch: 248/1000, ite: 47032] train loss: 1.1910, accuracy: 92.8694%, tar: 0.0268 \n",
      "l0: 0.015597, l1: 0.016460, l2: 0.022717, l3: 0.035040, l4: 0.056676, l5: 0.098510, l6: 0.217109\n",
      "\n",
      "[epoch: 354/400, batch: 256/1000, ite: 47033] train loss: 1.1905, accuracy: 96.4178%, tar: 0.0268 \n",
      "l0: 0.024642, l1: 0.026123, l2: 0.033421, l3: 0.045965, l4: 0.080039, l5: 0.156930, l6: 0.299418\n",
      "\n",
      "[epoch: 354/400, batch: 264/1000, ite: 47034] train loss: 1.1903, accuracy: 95.7545%, tar: 0.0268 \n",
      "l0: 0.023985, l1: 0.024936, l2: 0.033400, l3: 0.051970, l4: 0.112493, l5: 0.211601, l6: 0.420679\n",
      "\n",
      "[epoch: 354/400, batch: 272/1000, ite: 47035] train loss: 1.1904, accuracy: 94.2904%, tar: 0.0268 \n",
      "l0: 0.026041, l1: 0.027252, l2: 0.035471, l3: 0.051995, l4: 0.096317, l5: 0.203447, l6: 0.401221\n",
      "\n",
      "[epoch: 354/400, batch: 280/1000, ite: 47036] train loss: 1.1905, accuracy: 93.9951%, tar: 0.0268 \n",
      "l0: 0.024007, l1: 0.024641, l2: 0.031372, l3: 0.043837, l4: 0.079024, l5: 0.163671, l6: 0.381671\n",
      "\n",
      "[epoch: 354/400, batch: 288/1000, ite: 47037] train loss: 1.1904, accuracy: 94.4303%, tar: 0.0268 \n",
      "l0: 0.027279, l1: 0.028888, l2: 0.037676, l3: 0.058853, l4: 0.108777, l5: 0.223090, l6: 0.443892\n",
      "\n",
      "[epoch: 354/400, batch: 296/1000, ite: 47038] train loss: 1.1906, accuracy: 93.8570%, tar: 0.0268 \n",
      "l0: 0.020655, l1: 0.022059, l2: 0.028777, l3: 0.046319, l4: 0.093868, l5: 0.182593, l6: 0.352511\n",
      "\n",
      "[epoch: 354/400, batch: 304/1000, ite: 47039] train loss: 1.1905, accuracy: 95.2343%, tar: 0.0267 \n",
      "l0: 0.022233, l1: 0.023231, l2: 0.029938, l3: 0.043141, l4: 0.072681, l5: 0.149134, l6: 0.303875\n",
      "\n",
      "[epoch: 354/400, batch: 312/1000, ite: 47040] train loss: 1.1903, accuracy: 95.7033%, tar: 0.0267 \n",
      "l0: 0.019526, l1: 0.020831, l2: 0.025845, l3: 0.038259, l4: 0.070914, l5: 0.137198, l6: 0.275070\n",
      "\n",
      "[epoch: 354/400, batch: 320/1000, ite: 47041] train loss: 1.1900, accuracy: 95.8696%, tar: 0.0267 \n",
      "l0: 0.023182, l1: 0.025305, l2: 0.033964, l3: 0.052305, l4: 0.103671, l5: 0.242649, l6: 0.490177\n",
      "\n",
      "[epoch: 354/400, batch: 328/1000, ite: 47042] train loss: 1.1903, accuracy: 93.6304%, tar: 0.0267 \n",
      "l0: 0.020683, l1: 0.021608, l2: 0.028554, l3: 0.044358, l4: 0.082857, l5: 0.157680, l6: 0.297747\n",
      "\n",
      "[epoch: 354/400, batch: 336/1000, ite: 47043] train loss: 1.1900, accuracy: 95.4752%, tar: 0.0267 \n",
      "l0: 0.025581, l1: 0.026910, l2: 0.036498, l3: 0.055444, l4: 0.111848, l5: 0.197345, l6: 0.440834\n",
      "\n",
      "[epoch: 354/400, batch: 344/1000, ite: 47044] train loss: 1.1902, accuracy: 93.9411%, tar: 0.0267 \n",
      "l0: 0.024560, l1: 0.025636, l2: 0.034191, l3: 0.046947, l4: 0.074777, l5: 0.145079, l6: 0.318500\n",
      "\n",
      "[epoch: 354/400, batch: 352/1000, ite: 47045] train loss: 1.1900, accuracy: 95.3511%, tar: 0.0267 \n",
      "l0: 0.023329, l1: 0.024428, l2: 0.030289, l3: 0.042762, l4: 0.081582, l5: 0.170514, l6: 0.394228\n",
      "\n",
      "[epoch: 354/400, batch: 360/1000, ite: 47046] train loss: 1.1900, accuracy: 95.0726%, tar: 0.0267 \n",
      "l0: 0.022537, l1: 0.023687, l2: 0.031829, l3: 0.049007, l4: 0.088405, l5: 0.163338, l6: 0.300441\n",
      "\n",
      "[epoch: 354/400, batch: 368/1000, ite: 47047] train loss: 1.1898, accuracy: 95.6158%, tar: 0.0267 \n",
      "l0: 0.025800, l1: 0.027126, l2: 0.035907, l3: 0.048073, l4: 0.088887, l5: 0.187589, l6: 0.365122\n",
      "\n",
      "[epoch: 354/400, batch: 376/1000, ite: 47048] train loss: 1.1897, accuracy: 94.6455%, tar: 0.0267 \n",
      "l0: 0.033704, l1: 0.034935, l2: 0.045061, l3: 0.068632, l4: 0.131172, l5: 0.292789, l6: 0.593833\n",
      "\n",
      "[epoch: 354/400, batch: 384/1000, ite: 47049] train loss: 1.1903, accuracy: 91.7651%, tar: 0.0267 \n",
      "l0: 0.022802, l1: 0.023979, l2: 0.033339, l3: 0.053231, l4: 0.098381, l5: 0.160206, l6: 0.372468\n",
      "\n",
      "[epoch: 354/400, batch: 392/1000, ite: 47050] train loss: 1.1903, accuracy: 95.1636%, tar: 0.0267 \n",
      "l0: 0.022406, l1: 0.023856, l2: 0.031751, l3: 0.051647, l4: 0.105628, l5: 0.206677, l6: 0.411681\n",
      "\n",
      "[epoch: 354/400, batch: 400/1000, ite: 47051] train loss: 1.1903, accuracy: 94.9704%, tar: 0.0267 \n",
      "l0: 0.017109, l1: 0.019380, l2: 0.028650, l3: 0.043066, l4: 0.075256, l5: 0.156470, l6: 0.283932\n",
      "\n",
      "[epoch: 354/400, batch: 408/1000, ite: 47052] train loss: 1.1901, accuracy: 96.9501%, tar: 0.0267 \n",
      "l0: 0.030596, l1: 0.032315, l2: 0.043085, l3: 0.064292, l4: 0.117239, l5: 0.236793, l6: 0.523528\n",
      "\n",
      "[epoch: 354/400, batch: 416/1000, ite: 47053] train loss: 1.1904, accuracy: 92.7320%, tar: 0.0267 \n",
      "l0: 0.020211, l1: 0.021166, l2: 0.028753, l3: 0.044189, l4: 0.095670, l5: 0.167180, l6: 0.339416\n",
      "\n",
      "[epoch: 354/400, batch: 424/1000, ite: 47054] train loss: 1.1903, accuracy: 95.4188%, tar: 0.0267 \n",
      "l0: 0.022052, l1: 0.023084, l2: 0.030136, l3: 0.044666, l4: 0.072534, l5: 0.154997, l6: 0.343687\n",
      "\n",
      "[epoch: 354/400, batch: 432/1000, ite: 47055] train loss: 1.1902, accuracy: 95.0542%, tar: 0.0267 \n",
      "l0: 0.031402, l1: 0.033114, l2: 0.041350, l3: 0.059114, l4: 0.103055, l5: 0.230069, l6: 0.513030\n",
      "\n",
      "[epoch: 354/400, batch: 440/1000, ite: 47056] train loss: 1.1905, accuracy: 93.1479%, tar: 0.0267 \n",
      "l0: 0.023486, l1: 0.024920, l2: 0.032456, l3: 0.049267, l4: 0.116486, l5: 0.221671, l6: 0.419299\n",
      "\n",
      "[epoch: 354/400, batch: 448/1000, ite: 47057] train loss: 1.1906, accuracy: 94.3404%, tar: 0.0267 \n",
      "l0: 0.026691, l1: 0.028167, l2: 0.038198, l3: 0.056214, l4: 0.104187, l5: 0.237593, l6: 0.487328\n",
      "\n",
      "[epoch: 354/400, batch: 456/1000, ite: 47058] train loss: 1.1909, accuracy: 93.6311%, tar: 0.0267 \n",
      "l0: 0.025881, l1: 0.026923, l2: 0.035807, l3: 0.050144, l4: 0.084290, l5: 0.153938, l6: 0.313656\n",
      "\n",
      "[epoch: 354/400, batch: 464/1000, ite: 47059] train loss: 1.1907, accuracy: 94.6773%, tar: 0.0267 \n",
      "l0: 0.020057, l1: 0.021712, l2: 0.029022, l3: 0.043388, l4: 0.093247, l5: 0.214306, l6: 0.503960\n",
      "\n",
      "[epoch: 354/400, batch: 472/1000, ite: 47060] train loss: 1.1909, accuracy: 95.1192%, tar: 0.0267 \n",
      "l0: 0.021826, l1: 0.024735, l2: 0.036004, l3: 0.057567, l4: 0.102057, l5: 0.194116, l6: 0.361064\n",
      "\n",
      "[epoch: 354/400, batch: 480/1000, ite: 47061] train loss: 1.1909, accuracy: 95.3902%, tar: 0.0267 \n",
      "l0: 0.021953, l1: 0.023246, l2: 0.031391, l3: 0.045335, l4: 0.078204, l5: 0.155045, l6: 0.295456\n",
      "\n",
      "[epoch: 354/400, batch: 488/1000, ite: 47062] train loss: 1.1907, accuracy: 95.6948%, tar: 0.0267 \n",
      "l0: 0.025124, l1: 0.026913, l2: 0.035222, l3: 0.055947, l4: 0.119039, l5: 0.249163, l6: 0.455580\n",
      "\n",
      "[epoch: 354/400, batch: 496/1000, ite: 47063] train loss: 1.1909, accuracy: 94.0474%, tar: 0.0267 \n",
      "l0: 0.022928, l1: 0.024617, l2: 0.033779, l3: 0.051638, l4: 0.105604, l5: 0.211434, l6: 0.381942\n",
      "\n",
      "[epoch: 354/400, batch: 504/1000, ite: 47064] train loss: 1.1909, accuracy: 94.8297%, tar: 0.0267 \n",
      "l0: 0.022043, l1: 0.023835, l2: 0.031744, l3: 0.048171, l4: 0.089266, l5: 0.165670, l6: 0.386989\n",
      "\n",
      "[epoch: 354/400, batch: 512/1000, ite: 47065] train loss: 1.1909, accuracy: 94.9558%, tar: 0.0267 \n",
      "l0: 0.021447, l1: 0.022650, l2: 0.028303, l3: 0.042473, l4: 0.092670, l5: 0.191311, l6: 0.344945\n",
      "\n",
      "[epoch: 354/400, batch: 520/1000, ite: 47066] train loss: 1.1908, accuracy: 94.5151%, tar: 0.0267 \n",
      "l0: 0.022875, l1: 0.023902, l2: 0.032782, l3: 0.048694, l4: 0.092720, l5: 0.156759, l6: 0.293762\n",
      "\n",
      "[epoch: 354/400, batch: 528/1000, ite: 47067] train loss: 1.1906, accuracy: 95.6000%, tar: 0.0267 \n",
      "l0: 0.020956, l1: 0.022449, l2: 0.029872, l3: 0.049342, l4: 0.116281, l5: 0.207093, l6: 0.449585\n",
      "\n",
      "[epoch: 354/400, batch: 536/1000, ite: 47068] train loss: 1.1907, accuracy: 93.5382%, tar: 0.0267 \n",
      "l0: 0.024807, l1: 0.026076, l2: 0.034328, l3: 0.049378, l4: 0.086780, l5: 0.168343, l6: 0.358453\n",
      "\n",
      "[epoch: 354/400, batch: 544/1000, ite: 47069] train loss: 1.1907, accuracy: 94.4131%, tar: 0.0267 \n",
      "l0: 0.031454, l1: 0.033578, l2: 0.043329, l3: 0.069105, l4: 0.134750, l5: 0.261228, l6: 0.551646\n",
      "\n",
      "[epoch: 354/400, batch: 552/1000, ite: 47070] train loss: 1.1911, accuracy: 92.6134%, tar: 0.0267 \n",
      "l0: 0.023185, l1: 0.026025, l2: 0.038214, l3: 0.066486, l4: 0.119452, l5: 0.220863, l6: 0.385077\n",
      "\n",
      "[epoch: 354/400, batch: 560/1000, ite: 47071] train loss: 1.1912, accuracy: 94.5183%, tar: 0.0267 \n",
      "l0: 0.024360, l1: 0.025408, l2: 0.034054, l3: 0.050059, l4: 0.087233, l5: 0.195128, l6: 0.454076\n",
      "\n",
      "[epoch: 354/400, batch: 568/1000, ite: 47072] train loss: 1.1913, accuracy: 93.9544%, tar: 0.0267 \n",
      "l0: 0.026894, l1: 0.028282, l2: 0.036019, l3: 0.052108, l4: 0.092205, l5: 0.182562, l6: 0.345839\n",
      "\n",
      "[epoch: 354/400, batch: 576/1000, ite: 47073] train loss: 1.1913, accuracy: 94.4967%, tar: 0.0267 \n",
      "l0: 0.022431, l1: 0.022872, l2: 0.029984, l3: 0.044307, l4: 0.082078, l5: 0.144972, l6: 0.312937\n",
      "\n",
      "[epoch: 354/400, batch: 584/1000, ite: 47074] train loss: 1.1911, accuracy: 95.2586%, tar: 0.0267 \n",
      "l0: 0.020115, l1: 0.021269, l2: 0.028183, l3: 0.044491, l4: 0.083741, l5: 0.157243, l6: 0.295610\n",
      "\n",
      "[epoch: 354/400, batch: 592/1000, ite: 47075] train loss: 1.1908, accuracy: 96.6369%, tar: 0.0267 \n",
      "l0: 0.026336, l1: 0.027705, l2: 0.037899, l3: 0.061399, l4: 0.109055, l5: 0.205316, l6: 0.433408\n",
      "\n",
      "[epoch: 354/400, batch: 600/1000, ite: 47076] train loss: 1.1910, accuracy: 94.7189%, tar: 0.0267 \n",
      "l0: 0.019555, l1: 0.020613, l2: 0.028562, l3: 0.045067, l4: 0.077922, l5: 0.150587, l6: 0.287062\n",
      "\n",
      "[epoch: 354/400, batch: 608/1000, ite: 47077] train loss: 1.1907, accuracy: 95.5707%, tar: 0.0266 \n",
      "l0: 0.023772, l1: 0.024413, l2: 0.031361, l3: 0.044604, l4: 0.079265, l5: 0.151440, l6: 0.309288\n",
      "\n",
      "[epoch: 354/400, batch: 616/1000, ite: 47078] train loss: 1.1905, accuracy: 95.1576%, tar: 0.0266 \n",
      "l0: 0.023104, l1: 0.024352, l2: 0.032673, l3: 0.052692, l4: 0.099017, l5: 0.199682, l6: 0.337207\n",
      "\n",
      "[epoch: 354/400, batch: 624/1000, ite: 47079] train loss: 1.1904, accuracy: 95.0613%, tar: 0.0266 \n",
      "l0: 0.022311, l1: 0.024770, l2: 0.031911, l3: 0.047278, l4: 0.088867, l5: 0.183702, l6: 0.397185\n",
      "\n",
      "[epoch: 354/400, batch: 632/1000, ite: 47080] train loss: 1.1904, accuracy: 95.4893%, tar: 0.0266 \n",
      "l0: 0.026804, l1: 0.027788, l2: 0.035709, l3: 0.054811, l4: 0.093917, l5: 0.172971, l6: 0.345842\n",
      "\n",
      "[epoch: 354/400, batch: 640/1000, ite: 47081] train loss: 1.1904, accuracy: 94.4463%, tar: 0.0266 \n",
      "l0: 0.027156, l1: 0.028495, l2: 0.036684, l3: 0.051717, l4: 0.087904, l5: 0.193389, l6: 0.405932\n",
      "\n",
      "[epoch: 354/400, batch: 648/1000, ite: 47082] train loss: 1.1904, accuracy: 93.6069%, tar: 0.0266 \n",
      "l0: 0.024917, l1: 0.026619, l2: 0.033949, l3: 0.050016, l4: 0.106068, l5: 0.260844, l6: 0.526935\n",
      "\n",
      "[epoch: 354/400, batch: 656/1000, ite: 47083] train loss: 1.1908, accuracy: 93.5857%, tar: 0.0266 \n",
      "l0: 0.025160, l1: 0.026082, l2: 0.032807, l3: 0.048814, l4: 0.093596, l5: 0.192690, l6: 0.406443\n",
      "\n",
      "[epoch: 354/400, batch: 664/1000, ite: 47084] train loss: 1.1908, accuracy: 94.2039%, tar: 0.0266 \n",
      "l0: 0.026824, l1: 0.028586, l2: 0.038967, l3: 0.058079, l4: 0.108098, l5: 0.187057, l6: 0.424114\n",
      "\n",
      "[epoch: 354/400, batch: 672/1000, ite: 47085] train loss: 1.1909, accuracy: 94.2951%, tar: 0.0266 \n",
      "l0: 0.023212, l1: 0.023975, l2: 0.030870, l3: 0.044724, l4: 0.082108, l5: 0.155712, l6: 0.334398\n",
      "\n",
      "[epoch: 354/400, batch: 680/1000, ite: 47086] train loss: 1.1908, accuracy: 94.7558%, tar: 0.0266 \n",
      "l0: 0.022751, l1: 0.023361, l2: 0.029398, l3: 0.039468, l4: 0.066712, l5: 0.124929, l6: 0.247629\n",
      "\n",
      "[epoch: 354/400, batch: 688/1000, ite: 47087] train loss: 1.1904, accuracy: 96.0587%, tar: 0.0266 \n",
      "l0: 0.022427, l1: 0.024470, l2: 0.031935, l3: 0.046623, l4: 0.091159, l5: 0.215859, l6: 0.421521\n",
      "\n",
      "[epoch: 354/400, batch: 696/1000, ite: 47088] train loss: 1.1905, accuracy: 95.6688%, tar: 0.0266 \n",
      "l0: 0.017654, l1: 0.018858, l2: 0.024938, l3: 0.039263, l4: 0.082036, l5: 0.174458, l6: 0.396902\n",
      "\n",
      "[epoch: 354/400, batch: 704/1000, ite: 47089] train loss: 1.1905, accuracy: 95.6592%, tar: 0.0266 \n",
      "l0: 0.022772, l1: 0.023827, l2: 0.031426, l3: 0.045254, l4: 0.087219, l5: 0.155578, l6: 0.275386\n",
      "\n",
      "[epoch: 354/400, batch: 712/1000, ite: 47090] train loss: 1.1902, accuracy: 95.8210%, tar: 0.0266 \n",
      "l0: 0.023449, l1: 0.024786, l2: 0.033895, l3: 0.047687, l4: 0.077743, l5: 0.126283, l6: 0.277406\n",
      "\n",
      "[epoch: 354/400, batch: 720/1000, ite: 47091] train loss: 1.1899, accuracy: 95.6988%, tar: 0.0266 \n",
      "l0: 0.026569, l1: 0.027808, l2: 0.036289, l3: 0.053226, l4: 0.103153, l5: 0.211388, l6: 0.411859\n",
      "\n",
      "[epoch: 354/400, batch: 728/1000, ite: 47092] train loss: 1.1900, accuracy: 95.0005%, tar: 0.0266 \n",
      "l0: 0.020870, l1: 0.021831, l2: 0.028792, l3: 0.043222, l4: 0.079425, l5: 0.141301, l6: 0.276698\n",
      "\n",
      "[epoch: 354/400, batch: 736/1000, ite: 47093] train loss: 1.1898, accuracy: 95.6764%, tar: 0.0266 \n",
      "l0: 0.020190, l1: 0.021102, l2: 0.028779, l3: 0.043518, l4: 0.075601, l5: 0.150972, l6: 0.322910\n",
      "\n",
      "[epoch: 354/400, batch: 744/1000, ite: 47094] train loss: 1.1896, accuracy: 95.1193%, tar: 0.0266 \n",
      "l0: 0.030541, l1: 0.032533, l2: 0.041898, l3: 0.063913, l4: 0.115949, l5: 0.272100, l6: 0.561838\n",
      "\n",
      "[epoch: 354/400, batch: 752/1000, ite: 47095] train loss: 1.1900, accuracy: 92.0092%, tar: 0.0266 \n",
      "l0: 0.024289, l1: 0.025024, l2: 0.033627, l3: 0.046342, l4: 0.075822, l5: 0.177686, l6: 0.323199\n",
      "\n",
      "[epoch: 354/400, batch: 760/1000, ite: 47096] train loss: 1.1899, accuracy: 95.1284%, tar: 0.0266 \n",
      "l0: 0.026242, l1: 0.027767, l2: 0.036769, l3: 0.055725, l4: 0.112483, l5: 0.248860, l6: 0.453138\n",
      "\n",
      "[epoch: 354/400, batch: 768/1000, ite: 47097] train loss: 1.1901, accuracy: 94.2946%, tar: 0.0266 \n",
      "l0: 0.021777, l1: 0.023315, l2: 0.030410, l3: 0.047802, l4: 0.087361, l5: 0.154465, l6: 0.352284\n",
      "\n",
      "[epoch: 354/400, batch: 776/1000, ite: 47098] train loss: 1.1900, accuracy: 95.4232%, tar: 0.0266 \n",
      "l0: 0.018310, l1: 0.019276, l2: 0.026405, l3: 0.040373, l4: 0.078070, l5: 0.163550, l6: 0.316933\n",
      "\n",
      "[epoch: 354/400, batch: 784/1000, ite: 47099] train loss: 1.1898, accuracy: 95.5665%, tar: 0.0266 \n",
      "l0: 0.026738, l1: 0.028009, l2: 0.035797, l3: 0.053870, l4: 0.095340, l5: 0.191854, l6: 0.377586\n",
      "\n",
      "[epoch: 354/400, batch: 792/1000, ite: 47100] train loss: 1.1898, accuracy: 94.8836%, tar: 0.0266 \n",
      "l0: 0.027700, l1: 0.030205, l2: 0.041573, l3: 0.061656, l4: 0.107183, l5: 0.227562, l6: 0.511924\n",
      "\n",
      "[epoch: 354/400, batch: 800/1000, ite: 47101] train loss: 1.1901, accuracy: 93.6064%, tar: 0.0266 \n",
      "l0: 0.024956, l1: 0.026961, l2: 0.035165, l3: 0.056139, l4: 0.115033, l5: 0.199913, l6: 0.368687\n",
      "\n",
      "[epoch: 354/400, batch: 808/1000, ite: 47102] train loss: 1.1901, accuracy: 95.0493%, tar: 0.0266 \n",
      "l0: 0.022108, l1: 0.023109, l2: 0.029446, l3: 0.044979, l4: 0.078877, l5: 0.139978, l6: 0.270588\n",
      "\n",
      "[epoch: 354/400, batch: 816/1000, ite: 47103] train loss: 1.1898, accuracy: 95.9411%, tar: 0.0266 \n",
      "l0: 0.022398, l1: 0.023106, l2: 0.030350, l3: 0.043206, l4: 0.072110, l5: 0.169581, l6: 0.338489\n",
      "\n",
      "[epoch: 354/400, batch: 824/1000, ite: 47104] train loss: 1.1897, accuracy: 95.1620%, tar: 0.0266 \n",
      "l0: 0.017754, l1: 0.018641, l2: 0.023296, l3: 0.032172, l4: 0.052147, l5: 0.106377, l6: 0.250684\n",
      "\n",
      "[epoch: 354/400, batch: 832/1000, ite: 47105] train loss: 1.1893, accuracy: 96.2808%, tar: 0.0266 \n",
      "l0: 0.019293, l1: 0.019938, l2: 0.026153, l3: 0.039530, l4: 0.071779, l5: 0.148807, l6: 0.287717\n",
      "\n",
      "[epoch: 354/400, batch: 840/1000, ite: 47106] train loss: 1.1891, accuracy: 95.8860%, tar: 0.0266 \n",
      "l0: 0.026155, l1: 0.027462, l2: 0.036448, l3: 0.054014, l4: 0.101914, l5: 0.229239, l6: 0.393994\n",
      "\n",
      "[epoch: 354/400, batch: 848/1000, ite: 47107] train loss: 1.1891, accuracy: 94.0740%, tar: 0.0266 \n",
      "l0: 0.024055, l1: 0.025463, l2: 0.033111, l3: 0.046726, l4: 0.079937, l5: 0.170003, l6: 0.359002\n",
      "\n",
      "[epoch: 354/400, batch: 856/1000, ite: 47108] train loss: 1.1891, accuracy: 94.9514%, tar: 0.0266 \n",
      "l0: 0.029599, l1: 0.030957, l2: 0.038711, l3: 0.059710, l4: 0.115590, l5: 0.241694, l6: 0.424855\n",
      "\n",
      "[epoch: 354/400, batch: 864/1000, ite: 47109] train loss: 1.1892, accuracy: 93.3898%, tar: 0.0266 \n",
      "l0: 0.021539, l1: 0.022536, l2: 0.027902, l3: 0.041964, l4: 0.078350, l5: 0.159346, l6: 0.299462\n",
      "\n",
      "[epoch: 354/400, batch: 872/1000, ite: 47110] train loss: 1.1890, accuracy: 95.6000%, tar: 0.0266 \n",
      "l0: 0.024968, l1: 0.026092, l2: 0.032998, l3: 0.046583, l4: 0.088574, l5: 0.224126, l6: 0.454830\n",
      "\n",
      "[epoch: 354/400, batch: 880/1000, ite: 47111] train loss: 1.1892, accuracy: 94.2243%, tar: 0.0266 \n",
      "l0: 0.018710, l1: 0.019865, l2: 0.026954, l3: 0.041769, l4: 0.079968, l5: 0.151123, l6: 0.327626\n",
      "\n",
      "[epoch: 354/400, batch: 888/1000, ite: 47112] train loss: 1.1890, accuracy: 95.8156%, tar: 0.0265 \n",
      "l0: 0.028174, l1: 0.030182, l2: 0.039153, l3: 0.058250, l4: 0.104551, l5: 0.181235, l6: 0.326114\n",
      "\n",
      "[epoch: 354/400, batch: 896/1000, ite: 47113] train loss: 1.1889, accuracy: 94.8810%, tar: 0.0266 \n",
      "l0: 0.020868, l1: 0.022264, l2: 0.030505, l3: 0.044510, l4: 0.078107, l5: 0.174292, l6: 0.314386\n",
      "\n",
      "[epoch: 354/400, batch: 904/1000, ite: 47114] train loss: 1.1887, accuracy: 95.7078%, tar: 0.0265 \n",
      "l0: 0.022100, l1: 0.023840, l2: 0.031826, l3: 0.046681, l4: 0.086240, l5: 0.142806, l6: 0.259857\n",
      "\n",
      "[epoch: 354/400, batch: 912/1000, ite: 47115] train loss: 1.1885, accuracy: 96.4697%, tar: 0.0265 \n",
      "l0: 0.023266, l1: 0.024107, l2: 0.031636, l3: 0.044391, l4: 0.077207, l5: 0.171994, l6: 0.423830\n",
      "\n",
      "[epoch: 354/400, batch: 920/1000, ite: 47116] train loss: 1.1885, accuracy: 94.1504%, tar: 0.0265 \n",
      "l0: 0.025370, l1: 0.027898, l2: 0.039979, l3: 0.064499, l4: 0.131537, l5: 0.262924, l6: 0.392133\n",
      "\n",
      "[epoch: 354/400, batch: 928/1000, ite: 47117] train loss: 1.1886, accuracy: 95.3787%, tar: 0.0265 \n",
      "l0: 0.021891, l1: 0.022342, l2: 0.028644, l3: 0.039095, l4: 0.076048, l5: 0.156224, l6: 0.304984\n",
      "\n",
      "[epoch: 354/400, batch: 936/1000, ite: 47118] train loss: 1.1884, accuracy: 95.3069%, tar: 0.0265 \n",
      "l0: 0.023154, l1: 0.024520, l2: 0.033422, l3: 0.049190, l4: 0.092450, l5: 0.193360, l6: 0.395608\n",
      "\n",
      "[epoch: 354/400, batch: 944/1000, ite: 47119] train loss: 1.1885, accuracy: 93.9534%, tar: 0.0265 \n",
      "l0: 0.023777, l1: 0.025202, l2: 0.037151, l3: 0.055195, l4: 0.093485, l5: 0.154368, l6: 0.303125\n",
      "\n",
      "[epoch: 354/400, batch: 952/1000, ite: 47120] train loss: 1.1883, accuracy: 95.8167%, tar: 0.0265 \n",
      "l0: 0.021673, l1: 0.023137, l2: 0.031565, l3: 0.048086, l4: 0.093957, l5: 0.189907, l6: 0.362601\n",
      "\n",
      "[epoch: 354/400, batch: 960/1000, ite: 47121] train loss: 1.1882, accuracy: 95.2048%, tar: 0.0265 \n",
      "l0: 0.027294, l1: 0.028743, l2: 0.038205, l3: 0.055878, l4: 0.112349, l5: 0.203296, l6: 0.443035\n",
      "\n",
      "[epoch: 354/400, batch: 968/1000, ite: 47122] train loss: 1.1884, accuracy: 94.4492%, tar: 0.0265 \n",
      "l0: 0.025141, l1: 0.026377, l2: 0.034596, l3: 0.050666, l4: 0.102773, l5: 0.212754, l6: 0.472802\n",
      "\n",
      "[epoch: 354/400, batch: 976/1000, ite: 47123] train loss: 1.1886, accuracy: 92.9018%, tar: 0.0265 \n",
      "l0: 0.025238, l1: 0.026538, l2: 0.035314, l3: 0.052110, l4: 0.093285, l5: 0.165832, l6: 0.357358\n",
      "\n",
      "[epoch: 354/400, batch: 984/1000, ite: 47124] train loss: 1.1885, accuracy: 95.2012%, tar: 0.0265 \n",
      "l0: 0.021773, l1: 0.022934, l2: 0.031727, l3: 0.046395, l4: 0.085382, l5: 0.166149, l6: 0.301715\n",
      "\n",
      "[epoch: 354/400, batch: 992/1000, ite: 47125] train loss: 1.1883, accuracy: 95.7406%, tar: 0.0265 \n",
      "l0: 0.020880, l1: 0.022396, l2: 0.029767, l3: 0.044796, l4: 0.078078, l5: 0.165592, l6: 0.375185\n",
      "\n",
      "[epoch: 354/400, batch: 1000/1000, ite: 47126] train loss: 1.1883, accuracy: 94.6443%, tar: 0.0265 \n",
      "l0: 0.020870, l1: 0.022743, l2: 0.030788, l3: 0.046050, l4: 0.088713, l5: 0.180304, l6: 0.420299\n",
      "\n",
      "[epoch: 355/400, batch: 8/1000, ite: 47127] train loss: 1.1883, accuracy: 95.2304%, tar: 0.0265 \n",
      "l0: 0.024928, l1: 0.026373, l2: 0.032818, l3: 0.048117, l4: 0.084855, l5: 0.182849, l6: 0.385078\n",
      "\n",
      "[epoch: 355/400, batch: 16/1000, ite: 47128] train loss: 1.1883, accuracy: 94.6762%, tar: 0.0265 \n",
      "l0: 0.017424, l1: 0.018500, l2: 0.024725, l3: 0.039489, l4: 0.084331, l5: 0.181366, l6: 0.365277\n",
      "\n",
      "[epoch: 355/400, batch: 24/1000, ite: 47129] train loss: 1.1882, accuracy: 94.7105%, tar: 0.0265 \n",
      "l0: 0.018458, l1: 0.020882, l2: 0.030903, l3: 0.054893, l4: 0.102979, l5: 0.172220, l6: 0.315281\n",
      "\n",
      "[epoch: 355/400, batch: 32/1000, ite: 47130] train loss: 1.1881, accuracy: 95.8956%, tar: 0.0265 \n",
      "l0: 0.025201, l1: 0.026952, l2: 0.036037, l3: 0.057025, l4: 0.116655, l5: 0.243278, l6: 0.475313\n",
      "\n",
      "[epoch: 355/400, batch: 40/1000, ite: 47131] train loss: 1.1883, accuracy: 94.5397%, tar: 0.0265 \n",
      "l0: 0.029010, l1: 0.031012, l2: 0.040113, l3: 0.057592, l4: 0.104562, l5: 0.204352, l6: 0.396545\n",
      "\n",
      "[epoch: 355/400, batch: 48/1000, ite: 47132] train loss: 1.1884, accuracy: 94.3104%, tar: 0.0265 \n",
      "l0: 0.026925, l1: 0.028547, l2: 0.036358, l3: 0.050816, l4: 0.090463, l5: 0.200891, l6: 0.351984\n",
      "\n",
      "[epoch: 355/400, batch: 56/1000, ite: 47133] train loss: 1.1884, accuracy: 94.8232%, tar: 0.0265 \n",
      "l0: 0.022540, l1: 0.023463, l2: 0.029752, l3: 0.044364, l4: 0.078859, l5: 0.152959, l6: 0.292140\n",
      "\n",
      "[epoch: 355/400, batch: 64/1000, ite: 47134] train loss: 1.1881, accuracy: 96.2254%, tar: 0.0265 \n",
      "l0: 0.024646, l1: 0.025882, l2: 0.033043, l3: 0.044804, l4: 0.079876, l5: 0.165636, l6: 0.320933\n",
      "\n",
      "[epoch: 355/400, batch: 72/1000, ite: 47135] train loss: 1.1880, accuracy: 94.5608%, tar: 0.0265 \n",
      "l0: 0.026289, l1: 0.027691, l2: 0.035205, l3: 0.049118, l4: 0.086968, l5: 0.170598, l6: 0.372289\n",
      "\n",
      "[epoch: 355/400, batch: 80/1000, ite: 47136] train loss: 1.1880, accuracy: 94.6956%, tar: 0.0265 \n",
      "l0: 0.028241, l1: 0.029475, l2: 0.037382, l3: 0.051927, l4: 0.088118, l5: 0.189655, l6: 0.396897\n",
      "\n",
      "[epoch: 355/400, batch: 88/1000, ite: 47137] train loss: 1.1880, accuracy: 94.0794%, tar: 0.0265 \n",
      "l0: 0.023169, l1: 0.024602, l2: 0.033492, l3: 0.048748, l4: 0.093637, l5: 0.198719, l6: 0.354540\n",
      "\n",
      "[epoch: 355/400, batch: 96/1000, ite: 47138] train loss: 1.1879, accuracy: 95.1216%, tar: 0.0265 \n",
      "l0: 0.018416, l1: 0.020693, l2: 0.029494, l3: 0.046635, l4: 0.085501, l5: 0.163924, l6: 0.369310\n",
      "\n",
      "[epoch: 355/400, batch: 112/1000, ite: 47140] train loss: 1.1877, accuracy: 95.2531%, tar: 0.0265 \n",
      "l0: 0.025305, l1: 0.027751, l2: 0.041625, l3: 0.063745, l4: 0.116257, l5: 0.221666, l6: 0.410959\n",
      "\n",
      "[epoch: 355/400, batch: 120/1000, ite: 47141] train loss: 1.1878, accuracy: 94.9041%, tar: 0.0265 \n",
      "l0: 0.024422, l1: 0.025364, l2: 0.033477, l3: 0.047687, l4: 0.085723, l5: 0.173073, l6: 0.425037\n",
      "\n",
      "[epoch: 355/400, batch: 128/1000, ite: 47142] train loss: 1.1878, accuracy: 94.1899%, tar: 0.0265 \n",
      "l0: 0.022078, l1: 0.023366, l2: 0.030424, l3: 0.046997, l4: 0.094559, l5: 0.158929, l6: 0.297170\n",
      "\n",
      "[epoch: 355/400, batch: 136/1000, ite: 47143] train loss: 1.1877, accuracy: 95.7596%, tar: 0.0265 \n",
      "l0: 0.020804, l1: 0.021659, l2: 0.028699, l3: 0.042311, l4: 0.073827, l5: 0.178955, l6: 0.355250\n",
      "\n",
      "[epoch: 355/400, batch: 144/1000, ite: 47144] train loss: 1.1876, accuracy: 94.5032%, tar: 0.0265 \n",
      "l0: 0.022760, l1: 0.024175, l2: 0.030554, l3: 0.044963, l4: 0.080990, l5: 0.173197, l6: 0.340219\n",
      "\n",
      "[epoch: 355/400, batch: 152/1000, ite: 47145] train loss: 1.1875, accuracy: 95.7602%, tar: 0.0265 \n",
      "l0: 0.024037, l1: 0.025479, l2: 0.034027, l3: 0.053080, l4: 0.105945, l5: 0.206306, l6: 0.389371\n",
      "\n",
      "[epoch: 355/400, batch: 160/1000, ite: 47146] train loss: 1.1875, accuracy: 94.4117%, tar: 0.0265 \n",
      "l0: 0.021344, l1: 0.022638, l2: 0.031501, l3: 0.048829, l4: 0.091003, l5: 0.175405, l6: 0.351255\n",
      "\n",
      "[epoch: 355/400, batch: 168/1000, ite: 47147] train loss: 1.1874, accuracy: 95.1574%, tar: 0.0265 \n",
      "l0: 0.027082, l1: 0.029281, l2: 0.039345, l3: 0.058810, l4: 0.128406, l5: 0.274657, l6: 0.476052\n",
      "\n",
      "[epoch: 355/400, batch: 176/1000, ite: 47148] train loss: 1.1877, accuracy: 94.5589%, tar: 0.0265 \n",
      "l0: 0.021241, l1: 0.022527, l2: 0.030264, l3: 0.044512, l4: 0.082600, l5: 0.193663, l6: 0.372489\n",
      "\n",
      "[epoch: 355/400, batch: 184/1000, ite: 47149] train loss: 1.1877, accuracy: 95.0318%, tar: 0.0264 \n",
      "l0: 0.021105, l1: 0.022025, l2: 0.026648, l3: 0.040411, l4: 0.077341, l5: 0.179410, l6: 0.374444\n",
      "\n",
      "[epoch: 355/400, batch: 192/1000, ite: 47150] train loss: 1.1876, accuracy: 94.9564%, tar: 0.0264 \n",
      "l0: 0.015013, l1: 0.015864, l2: 0.021161, l3: 0.032918, l4: 0.067029, l5: 0.168733, l6: 0.304455\n",
      "\n",
      "[epoch: 355/400, batch: 200/1000, ite: 47151] train loss: 1.1874, accuracy: 96.0912%, tar: 0.0264 \n",
      "l0: 0.023868, l1: 0.025611, l2: 0.034895, l3: 0.052891, l4: 0.104572, l5: 0.201917, l6: 0.337860\n",
      "\n",
      "[epoch: 355/400, batch: 208/1000, ite: 47152] train loss: 1.1873, accuracy: 95.7635%, tar: 0.0264 \n",
      "l0: 0.023923, l1: 0.025863, l2: 0.036738, l3: 0.063289, l4: 0.120990, l5: 0.222391, l6: 0.440336\n",
      "\n",
      "[epoch: 355/400, batch: 216/1000, ite: 47153] train loss: 1.1875, accuracy: 94.4137%, tar: 0.0264 \n",
      "l0: 0.024730, l1: 0.025636, l2: 0.033244, l3: 0.045537, l4: 0.078791, l5: 0.127662, l6: 0.277217\n",
      "\n",
      "[epoch: 355/400, batch: 224/1000, ite: 47154] train loss: 1.1872, accuracy: 95.6065%, tar: 0.0264 \n",
      "l0: 0.024046, l1: 0.024905, l2: 0.033337, l3: 0.051540, l4: 0.110576, l5: 0.236664, l6: 0.405966\n",
      "\n",
      "[epoch: 355/400, batch: 232/1000, ite: 47155] train loss: 1.1873, accuracy: 94.4968%, tar: 0.0264 \n",
      "l0: 0.028319, l1: 0.030119, l2: 0.038639, l3: 0.055206, l4: 0.107092, l5: 0.232193, l6: 0.532131\n",
      "\n",
      "[epoch: 355/400, batch: 240/1000, ite: 47156] train loss: 1.1877, accuracy: 93.9395%, tar: 0.0264 \n",
      "l0: 0.020440, l1: 0.021457, l2: 0.027614, l3: 0.042442, l4: 0.095231, l5: 0.189313, l6: 0.315668\n",
      "\n",
      "[epoch: 355/400, batch: 248/1000, ite: 47157] train loss: 1.1875, accuracy: 95.6279%, tar: 0.0264 \n",
      "l0: 0.021891, l1: 0.022841, l2: 0.028612, l3: 0.047896, l4: 0.086555, l5: 0.170749, l6: 0.395199\n",
      "\n",
      "[epoch: 355/400, batch: 256/1000, ite: 47158] train loss: 1.1875, accuracy: 95.0093%, tar: 0.0264 \n",
      "l0: 0.019201, l1: 0.019837, l2: 0.026745, l3: 0.039231, l4: 0.067471, l5: 0.137703, l6: 0.291878\n",
      "\n",
      "[epoch: 355/400, batch: 264/1000, ite: 47159] train loss: 1.1873, accuracy: 95.8385%, tar: 0.0264 \n",
      "l0: 0.030011, l1: 0.031591, l2: 0.040315, l3: 0.057112, l4: 0.107461, l5: 0.248891, l6: 0.461561\n",
      "\n",
      "[epoch: 355/400, batch: 272/1000, ite: 47160] train loss: 1.1875, accuracy: 93.1437%, tar: 0.0264 \n",
      "l0: 0.017156, l1: 0.018837, l2: 0.026600, l3: 0.041791, l4: 0.083558, l5: 0.154348, l6: 0.275068\n",
      "\n",
      "[epoch: 355/400, batch: 280/1000, ite: 47161] train loss: 1.1872, accuracy: 96.4058%, tar: 0.0264 \n",
      "l0: 0.022779, l1: 0.023812, l2: 0.031127, l3: 0.044544, l4: 0.082025, l5: 0.197028, l6: 0.386971\n",
      "\n",
      "[epoch: 355/400, batch: 288/1000, ite: 47162] train loss: 1.1872, accuracy: 94.6210%, tar: 0.0264 \n",
      "l0: 0.034433, l1: 0.036081, l2: 0.047863, l3: 0.075893, l4: 0.153878, l5: 0.300007, l6: 0.662165\n",
      "\n",
      "[epoch: 355/400, batch: 296/1000, ite: 47163] train loss: 1.1879, accuracy: 90.5895%, tar: 0.0264 \n",
      "l0: 0.025046, l1: 0.027038, l2: 0.036076, l3: 0.057075, l4: 0.118036, l5: 0.237985, l6: 0.492092\n",
      "\n",
      "[epoch: 355/400, batch: 304/1000, ite: 47164] train loss: 1.1882, accuracy: 93.7841%, tar: 0.0264 \n",
      "l0: 0.022864, l1: 0.024743, l2: 0.034868, l3: 0.054038, l4: 0.093382, l5: 0.168168, l6: 0.326680\n",
      "\n",
      "[epoch: 355/400, batch: 312/1000, ite: 47165] train loss: 1.1880, accuracy: 95.2116%, tar: 0.0264 \n",
      "l0: 0.018584, l1: 0.019722, l2: 0.026795, l3: 0.039794, l4: 0.072662, l5: 0.131205, l6: 0.315116\n",
      "\n",
      "[epoch: 355/400, batch: 320/1000, ite: 47166] train loss: 1.1878, accuracy: 95.7604%, tar: 0.0264 \n",
      "l0: 0.023004, l1: 0.024569, l2: 0.034888, l3: 0.058298, l4: 0.111550, l5: 0.212475, l6: 0.445719\n",
      "\n",
      "[epoch: 355/400, batch: 328/1000, ite: 47167] train loss: 1.1880, accuracy: 94.3940%, tar: 0.0264 \n",
      "l0: 0.024228, l1: 0.025289, l2: 0.033389, l3: 0.050335, l4: 0.092859, l5: 0.191660, l6: 0.351984\n",
      "\n",
      "[epoch: 355/400, batch: 336/1000, ite: 47168] train loss: 1.1879, accuracy: 94.7281%, tar: 0.0264 \n",
      "l0: 0.020510, l1: 0.021281, l2: 0.027364, l3: 0.039816, l4: 0.069581, l5: 0.163451, l6: 0.403318\n",
      "\n",
      "[epoch: 355/400, batch: 344/1000, ite: 47169] train loss: 1.1879, accuracy: 94.8107%, tar: 0.0264 \n",
      "l0: 0.026459, l1: 0.027481, l2: 0.033923, l3: 0.049623, l4: 0.093036, l5: 0.182502, l6: 0.424611\n",
      "\n",
      "[epoch: 355/400, batch: 352/1000, ite: 47170] train loss: 1.1880, accuracy: 94.0265%, tar: 0.0264 \n",
      "l0: 0.024824, l1: 0.026925, l2: 0.036962, l3: 0.054580, l4: 0.101605, l5: 0.196890, l6: 0.384608\n",
      "\n",
      "[epoch: 355/400, batch: 360/1000, ite: 47171] train loss: 1.1880, accuracy: 95.0718%, tar: 0.0264 \n",
      "l0: 0.021722, l1: 0.022699, l2: 0.030835, l3: 0.044219, l4: 0.077924, l5: 0.162327, l6: 0.341739\n",
      "\n",
      "[epoch: 355/400, batch: 368/1000, ite: 47172] train loss: 1.1879, accuracy: 95.4440%, tar: 0.0264 \n",
      "l0: 0.025143, l1: 0.026057, l2: 0.033177, l3: 0.047556, l4: 0.074563, l5: 0.150594, l6: 0.393755\n",
      "\n",
      "[epoch: 355/400, batch: 376/1000, ite: 47173] train loss: 1.1879, accuracy: 94.3097%, tar: 0.0264 \n",
      "l0: 0.021557, l1: 0.022790, l2: 0.031786, l3: 0.048982, l4: 0.093353, l5: 0.173415, l6: 0.407440\n",
      "\n",
      "[epoch: 355/400, batch: 384/1000, ite: 47174] train loss: 1.1879, accuracy: 94.9361%, tar: 0.0264 \n",
      "l0: 0.020953, l1: 0.022335, l2: 0.029728, l3: 0.047434, l4: 0.090373, l5: 0.185208, l6: 0.338473\n",
      "\n",
      "[epoch: 355/400, batch: 392/1000, ite: 47175] train loss: 1.1878, accuracy: 95.2753%, tar: 0.0264 \n",
      "l0: 0.022113, l1: 0.023053, l2: 0.031513, l3: 0.047880, l4: 0.086059, l5: 0.192185, l6: 0.362530\n",
      "\n",
      "[epoch: 355/400, batch: 400/1000, ite: 47176] train loss: 1.1877, accuracy: 94.7024%, tar: 0.0264 \n",
      "l0: 0.023576, l1: 0.024395, l2: 0.031207, l3: 0.045544, l4: 0.077741, l5: 0.148726, l6: 0.337385\n",
      "\n",
      "[epoch: 355/400, batch: 408/1000, ite: 47177] train loss: 1.1876, accuracy: 94.9617%, tar: 0.0264 \n",
      "l0: 0.018323, l1: 0.019636, l2: 0.025440, l3: 0.039646, l4: 0.076480, l5: 0.161034, l6: 0.324166\n",
      "\n",
      "[epoch: 355/400, batch: 416/1000, ite: 47178] train loss: 1.1874, accuracy: 95.7918%, tar: 0.0264 \n",
      "l0: 0.019883, l1: 0.021074, l2: 0.028887, l3: 0.049508, l4: 0.088914, l5: 0.193278, l6: 0.364140\n",
      "\n",
      "[epoch: 355/400, batch: 424/1000, ite: 47179] train loss: 1.1874, accuracy: 95.1848%, tar: 0.0264 \n",
      "l0: 0.018305, l1: 0.019655, l2: 0.026865, l3: 0.041852, l4: 0.086839, l5: 0.187202, l6: 0.403935\n",
      "\n",
      "[epoch: 355/400, batch: 432/1000, ite: 47180] train loss: 1.1874, accuracy: 95.3826%, tar: 0.0263 \n",
      "l0: 0.024918, l1: 0.026469, l2: 0.034111, l3: 0.054281, l4: 0.105002, l5: 0.228621, l6: 0.573914\n",
      "\n",
      "[epoch: 355/400, batch: 440/1000, ite: 47181] train loss: 1.1878, accuracy: 92.7391%, tar: 0.0263 \n",
      "l0: 0.023218, l1: 0.024374, l2: 0.031037, l3: 0.044587, l4: 0.072261, l5: 0.138969, l6: 0.364973\n",
      "\n",
      "[epoch: 355/400, batch: 448/1000, ite: 47182] train loss: 1.1877, accuracy: 95.1110%, tar: 0.0263 \n",
      "l0: 0.033129, l1: 0.034633, l2: 0.043705, l3: 0.071937, l4: 0.158858, l5: 0.287098, l6: 0.491682\n",
      "\n",
      "[epoch: 355/400, batch: 456/1000, ite: 47183] train loss: 1.1880, accuracy: 92.8953%, tar: 0.0264 \n",
      "l0: 0.016775, l1: 0.017631, l2: 0.023545, l3: 0.035250, l4: 0.060029, l5: 0.107636, l6: 0.271693\n",
      "\n",
      "[epoch: 355/400, batch: 464/1000, ite: 47184] train loss: 1.1877, accuracy: 96.0441%, tar: 0.0263 \n",
      "l0: 0.021635, l1: 0.022687, l2: 0.030071, l3: 0.045102, l4: 0.083491, l5: 0.170064, l6: 0.355349\n",
      "\n",
      "[epoch: 355/400, batch: 472/1000, ite: 47185] train loss: 1.1876, accuracy: 94.9100%, tar: 0.0263 \n",
      "l0: 0.019937, l1: 0.020903, l2: 0.028827, l3: 0.042760, l4: 0.070910, l5: 0.134857, l6: 0.321549\n",
      "\n",
      "[epoch: 355/400, batch: 480/1000, ite: 47186] train loss: 1.1874, accuracy: 94.9731%, tar: 0.0263 \n",
      "l0: 0.025097, l1: 0.026819, l2: 0.035631, l3: 0.054219, l4: 0.101395, l5: 0.202332, l6: 0.424271\n",
      "\n",
      "[epoch: 355/400, batch: 488/1000, ite: 47187] train loss: 1.1875, accuracy: 95.4755%, tar: 0.0263 \n",
      "l0: 0.027870, l1: 0.029009, l2: 0.036777, l3: 0.053697, l4: 0.097956, l5: 0.245642, l6: 0.488129\n",
      "\n",
      "[epoch: 355/400, batch: 496/1000, ite: 47188] train loss: 1.1878, accuracy: 93.0579%, tar: 0.0263 \n",
      "l0: 0.023755, l1: 0.024957, l2: 0.032619, l3: 0.044336, l4: 0.082089, l5: 0.172746, l6: 0.322892\n",
      "\n",
      "[epoch: 355/400, batch: 504/1000, ite: 47189] train loss: 1.1876, accuracy: 95.4431%, tar: 0.0263 \n",
      "l0: 0.021154, l1: 0.022112, l2: 0.029344, l3: 0.042941, l4: 0.075800, l5: 0.138991, l6: 0.304639\n",
      "\n",
      "[epoch: 355/400, batch: 512/1000, ite: 47190] train loss: 1.1874, accuracy: 95.4065%, tar: 0.0263 \n",
      "l0: 0.019929, l1: 0.021562, l2: 0.028272, l3: 0.042853, l4: 0.079834, l5: 0.164124, l6: 0.334624\n",
      "\n",
      "[epoch: 355/400, batch: 520/1000, ite: 47191] train loss: 1.1873, accuracy: 96.0998%, tar: 0.0263 \n",
      "l0: 0.018407, l1: 0.020739, l2: 0.027656, l3: 0.042447, l4: 0.086566, l5: 0.193698, l6: 0.349703\n",
      "\n",
      "[epoch: 355/400, batch: 528/1000, ite: 47192] train loss: 1.1872, accuracy: 96.1422%, tar: 0.0263 \n",
      "l0: 0.023029, l1: 0.024847, l2: 0.032962, l3: 0.053196, l4: 0.101998, l5: 0.202404, l6: 0.388808\n",
      "\n",
      "[epoch: 355/400, batch: 536/1000, ite: 47193] train loss: 1.1873, accuracy: 94.4197%, tar: 0.0263 \n",
      "l0: 0.027098, l1: 0.028785, l2: 0.037979, l3: 0.058872, l4: 0.119186, l5: 0.239402, l6: 0.514937\n",
      "\n",
      "[epoch: 355/400, batch: 544/1000, ite: 47194] train loss: 1.1876, accuracy: 93.1008%, tar: 0.0263 \n",
      "l0: 0.018082, l1: 0.019095, l2: 0.025951, l3: 0.038532, l4: 0.068889, l5: 0.135409, l6: 0.269957\n",
      "\n",
      "[epoch: 355/400, batch: 552/1000, ite: 47195] train loss: 1.1873, accuracy: 95.9061%, tar: 0.0263 \n",
      "l0: 0.018614, l1: 0.019573, l2: 0.026385, l3: 0.040290, l4: 0.078124, l5: 0.165306, l6: 0.344812\n",
      "\n",
      "[epoch: 355/400, batch: 560/1000, ite: 47196] train loss: 1.1872, accuracy: 95.2680%, tar: 0.0263 \n",
      "l0: 0.027673, l1: 0.029180, l2: 0.037447, l3: 0.053154, l4: 0.101247, l5: 0.215015, l6: 0.429755\n",
      "\n",
      "[epoch: 355/400, batch: 568/1000, ite: 47197] train loss: 1.1873, accuracy: 93.7245%, tar: 0.0263 \n",
      "l0: 0.026795, l1: 0.028383, l2: 0.036285, l3: 0.053981, l4: 0.107741, l5: 0.245739, l6: 0.437324\n",
      "\n",
      "[epoch: 355/400, batch: 576/1000, ite: 47198] train loss: 1.1874, accuracy: 93.9207%, tar: 0.0263 \n",
      "l0: 0.021846, l1: 0.022799, l2: 0.030957, l3: 0.044031, l4: 0.071985, l5: 0.146756, l6: 0.273349\n",
      "\n",
      "[epoch: 355/400, batch: 584/1000, ite: 47199] train loss: 1.1872, accuracy: 95.6144%, tar: 0.0263 \n",
      "l0: 0.019354, l1: 0.020294, l2: 0.026222, l3: 0.038975, l4: 0.067166, l5: 0.123510, l6: 0.226929\n",
      "\n",
      "[epoch: 355/400, batch: 592/1000, ite: 47200] train loss: 1.1868, accuracy: 96.2419%, tar: 0.0263 \n",
      "l0: 0.024038, l1: 0.025592, l2: 0.032443, l3: 0.047045, l4: 0.081983, l5: 0.169501, l6: 0.409298\n",
      "\n",
      "[epoch: 355/400, batch: 600/1000, ite: 47201] train loss: 1.1869, accuracy: 94.3108%, tar: 0.0263 \n",
      "l0: 0.026104, l1: 0.027370, l2: 0.036293, l3: 0.057364, l4: 0.133101, l5: 0.255612, l6: 0.491324\n",
      "\n",
      "[epoch: 355/400, batch: 608/1000, ite: 47202] train loss: 1.1871, accuracy: 93.8188%, tar: 0.0263 \n",
      "l0: 0.025315, l1: 0.026316, l2: 0.034206, l3: 0.048061, l4: 0.082475, l5: 0.174282, l6: 0.323842\n",
      "\n",
      "[epoch: 355/400, batch: 616/1000, ite: 47203] train loss: 1.1870, accuracy: 94.4343%, tar: 0.0263 \n",
      "l0: 0.025168, l1: 0.026946, l2: 0.038160, l3: 0.058066, l4: 0.114271, l5: 0.249907, l6: 0.501494\n",
      "\n",
      "[epoch: 355/400, batch: 624/1000, ite: 47204] train loss: 1.1873, accuracy: 93.0800%, tar: 0.0263 \n",
      "l0: 0.018978, l1: 0.020025, l2: 0.025891, l3: 0.037671, l4: 0.064459, l5: 0.124210, l6: 0.239525\n",
      "\n",
      "[epoch: 355/400, batch: 632/1000, ite: 47205] train loss: 1.1870, accuracy: 96.3199%, tar: 0.0263 \n",
      "l0: 0.027703, l1: 0.029880, l2: 0.041653, l3: 0.071427, l4: 0.137902, l5: 0.240275, l6: 0.432613\n",
      "\n",
      "[epoch: 355/400, batch: 640/1000, ite: 47206] train loss: 1.1871, accuracy: 94.1876%, tar: 0.0263 \n",
      "l0: 0.022995, l1: 0.024138, l2: 0.030904, l3: 0.048499, l4: 0.103571, l5: 0.200307, l6: 0.363037\n",
      "\n",
      "[epoch: 355/400, batch: 648/1000, ite: 47207] train loss: 1.1871, accuracy: 94.9305%, tar: 0.0263 \n",
      "l0: 0.024524, l1: 0.025943, l2: 0.034998, l3: 0.049130, l4: 0.090523, l5: 0.184575, l6: 0.346548\n",
      "\n",
      "[epoch: 355/400, batch: 656/1000, ite: 47208] train loss: 1.1871, accuracy: 95.0517%, tar: 0.0263 \n",
      "l0: 0.026391, l1: 0.028083, l2: 0.035978, l3: 0.050505, l4: 0.086191, l5: 0.183793, l6: 0.409102\n",
      "\n",
      "[epoch: 355/400, batch: 664/1000, ite: 47209] train loss: 1.1871, accuracy: 94.4642%, tar: 0.0263 \n",
      "l0: 0.021180, l1: 0.021837, l2: 0.030212, l3: 0.048388, l4: 0.088765, l5: 0.203352, l6: 0.398450\n",
      "\n",
      "[epoch: 355/400, batch: 672/1000, ite: 47210] train loss: 1.1871, accuracy: 94.5770%, tar: 0.0263 \n",
      "l0: 0.023715, l1: 0.024669, l2: 0.032606, l3: 0.046231, l4: 0.080343, l5: 0.137412, l6: 0.295539\n",
      "\n",
      "[epoch: 355/400, batch: 680/1000, ite: 47211] train loss: 1.1869, accuracy: 95.7537%, tar: 0.0263 \n",
      "l0: 0.024047, l1: 0.025782, l2: 0.033757, l3: 0.049740, l4: 0.100024, l5: 0.208541, l6: 0.362219\n",
      "\n",
      "[epoch: 355/400, batch: 688/1000, ite: 47212] train loss: 1.1869, accuracy: 95.3315%, tar: 0.0263 \n",
      "l0: 0.021467, l1: 0.022797, l2: 0.030086, l3: 0.045732, l4: 0.102374, l5: 0.191578, l6: 0.396625\n",
      "\n",
      "[epoch: 355/400, batch: 696/1000, ite: 47213] train loss: 1.1869, accuracy: 95.1088%, tar: 0.0263 \n",
      "l0: 0.019130, l1: 0.020838, l2: 0.027624, l3: 0.040882, l4: 0.078644, l5: 0.157087, l6: 0.323519\n",
      "\n",
      "[epoch: 355/400, batch: 704/1000, ite: 47214] train loss: 1.1868, accuracy: 96.1607%, tar: 0.0263 \n",
      "l0: 0.023231, l1: 0.023983, l2: 0.029674, l3: 0.043426, l4: 0.072993, l5: 0.145677, l6: 0.305238\n",
      "\n",
      "[epoch: 355/400, batch: 712/1000, ite: 47215] train loss: 1.1866, accuracy: 94.8698%, tar: 0.0263 \n",
      "l0: 0.029773, l1: 0.030364, l2: 0.039461, l3: 0.055259, l4: 0.083129, l5: 0.154078, l6: 0.343066\n",
      "\n",
      "[epoch: 355/400, batch: 720/1000, ite: 47216] train loss: 1.1865, accuracy: 94.5990%, tar: 0.0263 \n",
      "l0: 0.024656, l1: 0.026159, l2: 0.032695, l3: 0.046130, l4: 0.082395, l5: 0.159400, l6: 0.325018\n",
      "\n",
      "[epoch: 355/400, batch: 728/1000, ite: 47217] train loss: 1.1864, accuracy: 94.9835%, tar: 0.0263 \n",
      "l0: 0.026998, l1: 0.028952, l2: 0.035936, l3: 0.055488, l4: 0.102899, l5: 0.170462, l6: 0.279401\n",
      "\n",
      "[epoch: 355/400, batch: 736/1000, ite: 47218] train loss: 1.1862, accuracy: 95.5199%, tar: 0.0263 \n",
      "l0: 0.022060, l1: 0.023178, l2: 0.033236, l3: 0.050828, l4: 0.096636, l5: 0.199506, l6: 0.378884\n",
      "\n",
      "[epoch: 355/400, batch: 744/1000, ite: 47219] train loss: 1.1862, accuracy: 95.0613%, tar: 0.0263 \n",
      "l0: 0.025840, l1: 0.026978, l2: 0.034032, l3: 0.054587, l4: 0.098473, l5: 0.202617, l6: 0.403462\n",
      "\n",
      "[epoch: 355/400, batch: 752/1000, ite: 47220] train loss: 1.1863, accuracy: 93.8674%, tar: 0.0263 \n",
      "l0: 0.025769, l1: 0.026933, l2: 0.035887, l3: 0.058719, l4: 0.112025, l5: 0.185839, l6: 0.416017\n",
      "\n",
      "[epoch: 355/400, batch: 760/1000, ite: 47221] train loss: 1.1864, accuracy: 94.3478%, tar: 0.0263 \n",
      "l0: 0.024428, l1: 0.025888, l2: 0.033406, l3: 0.048122, l4: 0.080725, l5: 0.129857, l6: 0.296714\n",
      "\n",
      "[epoch: 355/400, batch: 768/1000, ite: 47222] train loss: 1.1862, accuracy: 95.8083%, tar: 0.0263 \n",
      "l0: 0.025380, l1: 0.026547, l2: 0.034295, l3: 0.049329, l4: 0.100337, l5: 0.182113, l6: 0.391762\n",
      "\n",
      "[epoch: 355/400, batch: 776/1000, ite: 47223] train loss: 1.1862, accuracy: 95.2017%, tar: 0.0263 \n",
      "l0: 0.020068, l1: 0.021236, l2: 0.028034, l3: 0.039894, l4: 0.066264, l5: 0.126637, l6: 0.276780\n",
      "\n",
      "[epoch: 355/400, batch: 784/1000, ite: 47224] train loss: 1.1859, accuracy: 95.7109%, tar: 0.0262 \n",
      "l0: 0.023099, l1: 0.024696, l2: 0.037022, l3: 0.064050, l4: 0.124609, l5: 0.235525, l6: 0.457207\n",
      "\n",
      "[epoch: 355/400, batch: 792/1000, ite: 47225] train loss: 1.1861, accuracy: 94.9424%, tar: 0.0262 \n",
      "l0: 0.029407, l1: 0.031484, l2: 0.043379, l3: 0.071672, l4: 0.146484, l5: 0.277440, l6: 0.476762\n",
      "\n",
      "[epoch: 355/400, batch: 800/1000, ite: 47226] train loss: 1.1864, accuracy: 93.8395%, tar: 0.0262 \n",
      "l0: 0.020070, l1: 0.020700, l2: 0.026347, l3: 0.038457, l4: 0.073047, l5: 0.155911, l6: 0.286521\n",
      "\n",
      "[epoch: 355/400, batch: 808/1000, ite: 47227] train loss: 1.1862, accuracy: 95.6534%, tar: 0.0262 \n",
      "l0: 0.021774, l1: 0.022897, l2: 0.029611, l3: 0.040939, l4: 0.073036, l5: 0.146042, l6: 0.317655\n",
      "\n",
      "[epoch: 355/400, batch: 816/1000, ite: 47228] train loss: 1.1860, accuracy: 95.9169%, tar: 0.0262 \n",
      "l0: 0.020642, l1: 0.021498, l2: 0.028222, l3: 0.039702, l4: 0.064770, l5: 0.137081, l6: 0.260364\n",
      "\n",
      "[epoch: 355/400, batch: 824/1000, ite: 47229] train loss: 1.1857, accuracy: 96.0926%, tar: 0.0262 \n",
      "l0: 0.026084, l1: 0.027457, l2: 0.035808, l3: 0.051610, l4: 0.082593, l5: 0.148845, l6: 0.269152\n",
      "\n",
      "[epoch: 355/400, batch: 832/1000, ite: 47230] train loss: 1.1855, accuracy: 95.6912%, tar: 0.0262 \n",
      "l0: 0.028601, l1: 0.030376, l2: 0.038824, l3: 0.059069, l4: 0.107774, l5: 0.220510, l6: 0.425982\n",
      "\n",
      "[epoch: 355/400, batch: 840/1000, ite: 47231] train loss: 1.1856, accuracy: 93.6664%, tar: 0.0262 \n",
      "l0: 0.023303, l1: 0.024479, l2: 0.033107, l3: 0.048969, l4: 0.082697, l5: 0.156269, l6: 0.322728\n",
      "\n",
      "[epoch: 355/400, batch: 848/1000, ite: 47232] train loss: 1.1855, accuracy: 95.0909%, tar: 0.0262 \n",
      "l0: 0.019261, l1: 0.020184, l2: 0.026824, l3: 0.039645, l4: 0.076967, l5: 0.151569, l6: 0.328974\n",
      "\n",
      "[epoch: 355/400, batch: 856/1000, ite: 47233] train loss: 1.1853, accuracy: 95.2552%, tar: 0.0262 \n",
      "l0: 0.016891, l1: 0.017953, l2: 0.024048, l3: 0.036598, l4: 0.065570, l5: 0.138589, l6: 0.304802\n",
      "\n",
      "[epoch: 355/400, batch: 864/1000, ite: 47234] train loss: 1.1851, accuracy: 95.7345%, tar: 0.0262 \n",
      "l0: 0.020737, l1: 0.021226, l2: 0.027459, l3: 0.038469, l4: 0.065195, l5: 0.120047, l6: 0.255879\n",
      "\n",
      "[epoch: 355/400, batch: 872/1000, ite: 47235] train loss: 1.1848, accuracy: 95.7793%, tar: 0.0262 \n",
      "l0: 0.025996, l1: 0.027238, l2: 0.035402, l3: 0.047537, l4: 0.076186, l5: 0.153693, l6: 0.315243\n",
      "\n",
      "[epoch: 355/400, batch: 880/1000, ite: 47236] train loss: 1.1847, accuracy: 95.4475%, tar: 0.0262 \n",
      "l0: 0.021332, l1: 0.023488, l2: 0.032359, l3: 0.051827, l4: 0.098826, l5: 0.193408, l6: 0.403174\n",
      "\n",
      "[epoch: 355/400, batch: 888/1000, ite: 47237] train loss: 1.1847, accuracy: 94.7453%, tar: 0.0262 \n",
      "l0: 0.024697, l1: 0.025832, l2: 0.034226, l3: 0.049352, l4: 0.084714, l5: 0.167329, l6: 0.338954\n",
      "\n",
      "[epoch: 355/400, batch: 896/1000, ite: 47238] train loss: 1.1846, accuracy: 94.6868%, tar: 0.0262 \n",
      "l0: 0.020462, l1: 0.022529, l2: 0.033029, l3: 0.053085, l4: 0.096022, l5: 0.183830, l6: 0.361043\n",
      "\n",
      "[epoch: 355/400, batch: 904/1000, ite: 47239] train loss: 1.1846, accuracy: 95.9378%, tar: 0.0262 \n",
      "l0: 0.023840, l1: 0.025303, l2: 0.035176, l3: 0.050706, l4: 0.082398, l5: 0.158528, l6: 0.323759\n",
      "\n",
      "[epoch: 355/400, batch: 912/1000, ite: 47240] train loss: 1.1845, accuracy: 95.5866%, tar: 0.0262 \n",
      "l0: 0.033295, l1: 0.035036, l2: 0.045653, l3: 0.066456, l4: 0.124952, l5: 0.255080, l6: 0.509841\n",
      "\n",
      "[epoch: 355/400, batch: 920/1000, ite: 47241] train loss: 1.1848, accuracy: 92.8825%, tar: 0.0262 \n",
      "l0: 0.019582, l1: 0.020951, l2: 0.028285, l3: 0.042956, l4: 0.079301, l5: 0.171576, l6: 0.303786\n",
      "\n",
      "[epoch: 355/400, batch: 928/1000, ite: 47242] train loss: 1.1846, accuracy: 95.6886%, tar: 0.0262 \n",
      "l0: 0.023473, l1: 0.024823, l2: 0.032533, l3: 0.046389, l4: 0.077491, l5: 0.139530, l6: 0.285585\n",
      "\n",
      "[epoch: 355/400, batch: 936/1000, ite: 47243] train loss: 1.1844, accuracy: 95.4893%, tar: 0.0262 \n",
      "l0: 0.026388, l1: 0.027975, l2: 0.038251, l3: 0.056683, l4: 0.105723, l5: 0.188759, l6: 0.367880\n",
      "\n",
      "[epoch: 355/400, batch: 944/1000, ite: 47244] train loss: 1.1844, accuracy: 95.2264%, tar: 0.0262 \n",
      "l0: 0.029947, l1: 0.030975, l2: 0.041628, l3: 0.057473, l4: 0.094908, l5: 0.180372, l6: 0.386939\n",
      "\n",
      "[epoch: 355/400, batch: 952/1000, ite: 47245] train loss: 1.1844, accuracy: 93.7138%, tar: 0.0262 \n",
      "l0: 0.023640, l1: 0.025158, l2: 0.035246, l3: 0.052225, l4: 0.094731, l5: 0.225410, l6: 0.497202\n",
      "\n",
      "[epoch: 355/400, batch: 960/1000, ite: 47246] train loss: 1.1846, accuracy: 93.6134%, tar: 0.0262 \n",
      "l0: 0.018145, l1: 0.019398, l2: 0.026857, l3: 0.042155, l4: 0.074539, l5: 0.151025, l6: 0.361858\n",
      "\n",
      "[epoch: 355/400, batch: 968/1000, ite: 47247] train loss: 1.1845, accuracy: 94.7166%, tar: 0.0262 \n",
      "l0: 0.026110, l1: 0.028024, l2: 0.038832, l3: 0.053856, l4: 0.092146, l5: 0.201862, l6: 0.411679\n",
      "\n",
      "[epoch: 355/400, batch: 976/1000, ite: 47248] train loss: 1.1846, accuracy: 94.7086%, tar: 0.0262 \n",
      "l0: 0.025822, l1: 0.027504, l2: 0.035057, l3: 0.048967, l4: 0.092762, l5: 0.194887, l6: 0.436177\n",
      "\n",
      "[epoch: 355/400, batch: 984/1000, ite: 47249] train loss: 1.1847, accuracy: 93.8268%, tar: 0.0262 \n",
      "l0: 0.021936, l1: 0.023101, l2: 0.030087, l3: 0.041318, l4: 0.069202, l5: 0.130782, l6: 0.301690\n",
      "\n",
      "[epoch: 355/400, batch: 992/1000, ite: 47250] train loss: 1.1845, accuracy: 95.5104%, tar: 0.0262 \n",
      "l0: 0.022358, l1: 0.022950, l2: 0.028586, l3: 0.039598, l4: 0.058313, l5: 0.106039, l6: 0.261324\n",
      "\n",
      "[epoch: 355/400, batch: 1000/1000, ite: 47251] train loss: 1.1842, accuracy: 95.9956%, tar: 0.0262 \n",
      "l0: 0.024169, l1: 0.025399, l2: 0.034450, l3: 0.052362, l4: 0.096071, l5: 0.225123, l6: 0.442296\n",
      "\n",
      "[epoch: 356/400, batch: 8/1000, ite: 47252] train loss: 1.1843, accuracy: 93.7512%, tar: 0.0262 \n",
      "l0: 0.022512, l1: 0.024019, l2: 0.032338, l3: 0.048762, l4: 0.088987, l5: 0.195183, l6: 0.410053\n",
      "\n",
      "[epoch: 356/400, batch: 16/1000, ite: 47253] train loss: 1.1844, accuracy: 95.0352%, tar: 0.0262 \n",
      "l0: 0.025098, l1: 0.026491, l2: 0.035773, l3: 0.053590, l4: 0.099100, l5: 0.198286, l6: 0.431483\n",
      "\n",
      "[epoch: 356/400, batch: 24/1000, ite: 47254] train loss: 1.1844, accuracy: 94.4483%, tar: 0.0262 \n",
      "l0: 0.025651, l1: 0.027260, l2: 0.037090, l3: 0.051963, l4: 0.098595, l5: 0.239356, l6: 0.436610\n",
      "\n",
      "[epoch: 356/400, batch: 32/1000, ite: 47255] train loss: 1.1846, accuracy: 93.2886%, tar: 0.0262 \n",
      "l0: 0.021459, l1: 0.022036, l2: 0.028563, l3: 0.044801, l4: 0.082843, l5: 0.176296, l6: 0.352799\n",
      "\n",
      "[epoch: 356/400, batch: 40/1000, ite: 47256] train loss: 1.1845, accuracy: 95.3558%, tar: 0.0262 \n",
      "l0: 0.021645, l1: 0.023497, l2: 0.031624, l3: 0.047241, l4: 0.089545, l5: 0.180734, l6: 0.377501\n",
      "\n",
      "[epoch: 356/400, batch: 48/1000, ite: 47257] train loss: 1.1845, accuracy: 94.9388%, tar: 0.0262 \n",
      "l0: 0.026334, l1: 0.027688, l2: 0.036504, l3: 0.051849, l4: 0.093257, l5: 0.188342, l6: 0.439423\n",
      "\n",
      "[epoch: 356/400, batch: 56/1000, ite: 47258] train loss: 1.1846, accuracy: 93.9797%, tar: 0.0262 \n",
      "l0: 0.019052, l1: 0.019804, l2: 0.026640, l3: 0.040137, l4: 0.074446, l5: 0.158526, l6: 0.311752\n",
      "\n",
      "[epoch: 356/400, batch: 64/1000, ite: 47259] train loss: 1.1844, accuracy: 95.5083%, tar: 0.0262 \n",
      "l0: 0.017773, l1: 0.018285, l2: 0.024282, l3: 0.034324, l4: 0.056875, l5: 0.115362, l6: 0.312268\n",
      "\n",
      "[epoch: 356/400, batch: 72/1000, ite: 47260] train loss: 1.1842, accuracy: 95.5229%, tar: 0.0262 \n",
      "l0: 0.032459, l1: 0.034222, l2: 0.045340, l3: 0.068405, l4: 0.133264, l5: 0.286720, l6: 0.551620\n",
      "\n",
      "[epoch: 356/400, batch: 80/1000, ite: 47261] train loss: 1.1846, accuracy: 92.6847%, tar: 0.0262 \n",
      "l0: 0.023912, l1: 0.025042, l2: 0.032424, l3: 0.047458, l4: 0.087233, l5: 0.174101, l6: 0.378680\n",
      "\n",
      "[epoch: 356/400, batch: 88/1000, ite: 47262] train loss: 1.1846, accuracy: 93.8877%, tar: 0.0262 \n",
      "l0: 0.033476, l1: 0.035800, l2: 0.049084, l3: 0.077272, l4: 0.145969, l5: 0.283438, l6: 0.521965\n",
      "\n",
      "[epoch: 356/400, batch: 96/1000, ite: 47263] train loss: 1.1850, accuracy: 92.6964%, tar: 0.0262 \n",
      "l0: 0.022673, l1: 0.023842, l2: 0.030063, l3: 0.044353, l4: 0.081026, l5: 0.157492, l6: 0.308170\n",
      "\n",
      "[epoch: 356/400, batch: 104/1000, ite: 47264] train loss: 1.1848, accuracy: 95.7180%, tar: 0.0262 \n",
      "l0: 0.019465, l1: 0.021618, l2: 0.029237, l3: 0.047670, l4: 0.094143, l5: 0.171565, l6: 0.335092\n",
      "\n",
      "[epoch: 356/400, batch: 112/1000, ite: 47265] train loss: 1.1847, accuracy: 96.3319%, tar: 0.0262 \n",
      "l0: 0.018894, l1: 0.020522, l2: 0.029801, l3: 0.043913, l4: 0.074275, l5: 0.149541, l6: 0.299984\n",
      "\n",
      "[epoch: 356/400, batch: 120/1000, ite: 47266] train loss: 1.1845, accuracy: 95.9395%, tar: 0.0262 \n",
      "l0: 0.028301, l1: 0.029095, l2: 0.036104, l3: 0.053093, l4: 0.091890, l5: 0.181742, l6: 0.382279\n",
      "\n",
      "[epoch: 356/400, batch: 128/1000, ite: 47267] train loss: 1.1845, accuracy: 93.8618%, tar: 0.0262 \n",
      "l0: 0.020406, l1: 0.021110, l2: 0.025977, l3: 0.038040, l4: 0.066136, l5: 0.128588, l6: 0.313694\n",
      "\n",
      "[epoch: 356/400, batch: 136/1000, ite: 47268] train loss: 1.1843, accuracy: 95.2785%, tar: 0.0262 \n",
      "l0: 0.017918, l1: 0.018992, l2: 0.025187, l3: 0.039092, l4: 0.072613, l5: 0.158444, l6: 0.355194\n",
      "\n",
      "[epoch: 356/400, batch: 144/1000, ite: 47269] train loss: 1.1842, accuracy: 95.4664%, tar: 0.0262 \n",
      "l0: 0.024201, l1: 0.025701, l2: 0.032799, l3: 0.051745, l4: 0.094534, l5: 0.179343, l6: 0.361597\n",
      "\n",
      "[epoch: 356/400, batch: 152/1000, ite: 47270] train loss: 1.1842, accuracy: 94.8691%, tar: 0.0262 \n",
      "l0: 0.019209, l1: 0.020107, l2: 0.026239, l3: 0.040302, l4: 0.080397, l5: 0.165895, l6: 0.371563\n",
      "\n",
      "[epoch: 356/400, batch: 160/1000, ite: 47271] train loss: 1.1841, accuracy: 94.9079%, tar: 0.0261 \n",
      "l0: 0.021506, l1: 0.022954, l2: 0.032675, l3: 0.047631, l4: 0.087767, l5: 0.206778, l6: 0.406819\n",
      "\n",
      "[epoch: 356/400, batch: 168/1000, ite: 47272] train loss: 1.1841, accuracy: 94.7533%, tar: 0.0261 \n",
      "l0: 0.016329, l1: 0.017476, l2: 0.024916, l3: 0.041138, l4: 0.077131, l5: 0.145613, l6: 0.280168\n",
      "\n",
      "[epoch: 356/400, batch: 176/1000, ite: 47273] train loss: 1.1839, accuracy: 95.9436%, tar: 0.0261 \n",
      "l0: 0.023466, l1: 0.025020, l2: 0.034895, l3: 0.048139, l4: 0.086470, l5: 0.185949, l6: 0.410396\n",
      "\n",
      "[epoch: 356/400, batch: 184/1000, ite: 47274] train loss: 1.1839, accuracy: 94.9537%, tar: 0.0261 \n",
      "l0: 0.021986, l1: 0.022950, l2: 0.030566, l3: 0.042255, l4: 0.074630, l5: 0.130025, l6: 0.247138\n",
      "\n",
      "[epoch: 356/400, batch: 192/1000, ite: 47275] train loss: 1.1837, accuracy: 95.8458%, tar: 0.0261 \n",
      "l0: 0.022963, l1: 0.023943, l2: 0.031141, l3: 0.045385, l4: 0.075345, l5: 0.158695, l6: 0.333171\n",
      "\n",
      "[epoch: 356/400, batch: 200/1000, ite: 47276] train loss: 1.1835, accuracy: 94.9812%, tar: 0.0261 \n",
      "l0: 0.022599, l1: 0.023696, l2: 0.030261, l3: 0.043478, l4: 0.087604, l5: 0.198325, l6: 0.411893\n",
      "\n",
      "[epoch: 356/400, batch: 208/1000, ite: 47277] train loss: 1.1836, accuracy: 94.1725%, tar: 0.0261 \n",
      "l0: 0.019084, l1: 0.019886, l2: 0.025248, l3: 0.035012, l4: 0.058308, l5: 0.104320, l6: 0.229042\n",
      "\n",
      "[epoch: 356/400, batch: 216/1000, ite: 47278] train loss: 1.1832, accuracy: 96.2734%, tar: 0.0261 \n",
      "l0: 0.024974, l1: 0.026323, l2: 0.034402, l3: 0.051100, l4: 0.105295, l5: 0.184122, l6: 0.378598\n",
      "\n",
      "[epoch: 356/400, batch: 224/1000, ite: 47279] train loss: 1.1832, accuracy: 94.0615%, tar: 0.0261 \n",
      "l0: 0.021910, l1: 0.022964, l2: 0.033114, l3: 0.051591, l4: 0.097367, l5: 0.159111, l6: 0.340601\n",
      "\n",
      "[epoch: 356/400, batch: 232/1000, ite: 47280] train loss: 1.1831, accuracy: 95.2984%, tar: 0.0261 \n",
      "l0: 0.021258, l1: 0.022659, l2: 0.030051, l3: 0.048708, l4: 0.095335, l5: 0.180843, l6: 0.389182\n",
      "\n",
      "[epoch: 356/400, batch: 240/1000, ite: 47281] train loss: 1.1831, accuracy: 94.6470%, tar: 0.0261 \n",
      "l0: 0.018704, l1: 0.019813, l2: 0.025899, l3: 0.036901, l4: 0.067308, l5: 0.122540, l6: 0.295215\n",
      "\n",
      "[epoch: 356/400, batch: 248/1000, ite: 47282] train loss: 1.1829, accuracy: 95.4376%, tar: 0.0261 \n",
      "l0: 0.020714, l1: 0.021770, l2: 0.029939, l3: 0.044383, l4: 0.084416, l5: 0.153694, l6: 0.328273\n",
      "\n",
      "[epoch: 356/400, batch: 256/1000, ite: 47283] train loss: 1.1828, accuracy: 94.9917%, tar: 0.0261 \n",
      "l0: 0.021766, l1: 0.023118, l2: 0.032078, l3: 0.048321, l4: 0.088430, l5: 0.203090, l6: 0.354830\n",
      "\n",
      "[epoch: 356/400, batch: 264/1000, ite: 47284] train loss: 1.1827, accuracy: 95.0600%, tar: 0.0261 \n",
      "l0: 0.020945, l1: 0.022979, l2: 0.035317, l3: 0.059169, l4: 0.103056, l5: 0.203968, l6: 0.403673\n",
      "\n",
      "[epoch: 356/400, batch: 272/1000, ite: 47285] train loss: 1.1828, accuracy: 95.1807%, tar: 0.0261 \n",
      "l0: 0.019131, l1: 0.021209, l2: 0.031225, l3: 0.048009, l4: 0.090468, l5: 0.210858, l6: 0.402469\n",
      "\n",
      "[epoch: 356/400, batch: 280/1000, ite: 47286] train loss: 1.1828, accuracy: 95.8304%, tar: 0.0261 \n",
      "l0: 0.022071, l1: 0.023269, l2: 0.031451, l3: 0.046123, l4: 0.077990, l5: 0.157132, l6: 0.344742\n",
      "\n",
      "[epoch: 356/400, batch: 288/1000, ite: 47287] train loss: 1.1827, accuracy: 95.1230%, tar: 0.0261 \n",
      "l0: 0.025625, l1: 0.027177, l2: 0.036803, l3: 0.061359, l4: 0.124214, l5: 0.288661, l6: 0.541753\n",
      "\n",
      "[epoch: 356/400, batch: 296/1000, ite: 47288] train loss: 1.1831, accuracy: 92.7961%, tar: 0.0261 \n",
      "l0: 0.022636, l1: 0.023855, l2: 0.030890, l3: 0.045480, l4: 0.087490, l5: 0.155037, l6: 0.329903\n",
      "\n",
      "[epoch: 356/400, batch: 304/1000, ite: 47289] train loss: 1.1830, accuracy: 95.2916%, tar: 0.0261 \n",
      "l0: 0.026352, l1: 0.027682, l2: 0.034569, l3: 0.046065, l4: 0.079241, l5: 0.158513, l6: 0.349951\n",
      "\n",
      "[epoch: 356/400, batch: 312/1000, ite: 47290] train loss: 1.1829, accuracy: 94.8157%, tar: 0.0261 \n",
      "l0: 0.023963, l1: 0.025929, l2: 0.035043, l3: 0.055783, l4: 0.110664, l5: 0.248592, l6: 0.462820\n",
      "\n",
      "[epoch: 356/400, batch: 320/1000, ite: 47291] train loss: 1.1831, accuracy: 93.7878%, tar: 0.0261 \n",
      "l0: 0.023972, l1: 0.025630, l2: 0.036419, l3: 0.054917, l4: 0.105391, l5: 0.187027, l6: 0.367645\n",
      "\n",
      "[epoch: 356/400, batch: 328/1000, ite: 47292] train loss: 1.1831, accuracy: 95.2685%, tar: 0.0261 \n",
      "l0: 0.023785, l1: 0.026308, l2: 0.036607, l3: 0.057129, l4: 0.116634, l5: 0.222584, l6: 0.351821\n",
      "\n",
      "[epoch: 356/400, batch: 336/1000, ite: 47293] train loss: 1.1831, accuracy: 95.2159%, tar: 0.0261 \n",
      "l0: 0.026975, l1: 0.028496, l2: 0.036788, l3: 0.054051, l4: 0.102836, l5: 0.226031, l6: 0.470909\n",
      "\n",
      "[epoch: 356/400, batch: 344/1000, ite: 47294] train loss: 1.1833, accuracy: 93.4344%, tar: 0.0261 \n",
      "l0: 0.019232, l1: 0.020262, l2: 0.027109, l3: 0.044185, l4: 0.089136, l5: 0.161791, l6: 0.320029\n",
      "\n",
      "[epoch: 356/400, batch: 352/1000, ite: 47295] train loss: 1.1831, accuracy: 95.4568%, tar: 0.0261 \n",
      "l0: 0.017578, l1: 0.020257, l2: 0.030164, l3: 0.055976, l4: 0.112898, l5: 0.219823, l6: 0.395569\n",
      "\n",
      "[epoch: 356/400, batch: 360/1000, ite: 47296] train loss: 1.1832, accuracy: 96.0160%, tar: 0.0261 \n",
      "l0: 0.024446, l1: 0.026164, l2: 0.033466, l3: 0.052059, l4: 0.097567, l5: 0.186097, l6: 0.335848\n",
      "\n",
      "[epoch: 356/400, batch: 368/1000, ite: 47297] train loss: 1.1831, accuracy: 94.6859%, tar: 0.0261 \n",
      "l0: 0.022516, l1: 0.023961, l2: 0.029616, l3: 0.044143, l4: 0.077849, l5: 0.139955, l6: 0.286773\n",
      "\n",
      "[epoch: 356/400, batch: 376/1000, ite: 47298] train loss: 1.1829, accuracy: 95.5593%, tar: 0.0261 \n",
      "l0: 0.023284, l1: 0.024425, l2: 0.033217, l3: 0.052014, l4: 0.098248, l5: 0.193647, l6: 0.366691\n",
      "\n",
      "[epoch: 356/400, batch: 384/1000, ite: 47299] train loss: 1.1829, accuracy: 94.4499%, tar: 0.0261 \n",
      "l0: 0.020627, l1: 0.022166, l2: 0.030108, l3: 0.047696, l4: 0.091788, l5: 0.195454, l6: 0.401161\n",
      "\n",
      "[epoch: 356/400, batch: 392/1000, ite: 47300] train loss: 1.1829, accuracy: 94.8145%, tar: 0.0261 \n",
      "l0: 0.021252, l1: 0.022375, l2: 0.028940, l3: 0.044006, l4: 0.087683, l5: 0.202650, l6: 0.391314\n",
      "\n",
      "[epoch: 356/400, batch: 400/1000, ite: 47301] train loss: 1.1829, accuracy: 93.6662%, tar: 0.0261 \n",
      "l0: 0.028567, l1: 0.031754, l2: 0.044852, l3: 0.080924, l4: 0.172468, l5: 0.333280, l6: 0.564941\n",
      "\n",
      "[epoch: 356/400, batch: 408/1000, ite: 47302] train loss: 1.1834, accuracy: 93.0052%, tar: 0.0261 \n",
      "l0: 0.019033, l1: 0.020989, l2: 0.028772, l3: 0.048575, l4: 0.091849, l5: 0.172362, l6: 0.322208\n",
      "\n",
      "[epoch: 356/400, batch: 416/1000, ite: 47303] train loss: 1.1833, accuracy: 95.6277%, tar: 0.0260 \n",
      "l0: 0.016442, l1: 0.018270, l2: 0.025668, l3: 0.040707, l4: 0.077073, l5: 0.144404, l6: 0.341993\n",
      "\n",
      "[epoch: 356/400, batch: 424/1000, ite: 47304] train loss: 1.1832, accuracy: 96.2604%, tar: 0.0260 \n",
      "l0: 0.026592, l1: 0.027674, l2: 0.035436, l3: 0.049722, l4: 0.090650, l5: 0.204549, l6: 0.463067\n",
      "\n",
      "[epoch: 356/400, batch: 432/1000, ite: 47305] train loss: 1.1833, accuracy: 93.6148%, tar: 0.0260 \n",
      "l0: 0.024148, l1: 0.025568, l2: 0.033593, l3: 0.047878, l4: 0.092157, l5: 0.190565, l6: 0.331957\n",
      "\n",
      "[epoch: 356/400, batch: 440/1000, ite: 47306] train loss: 1.1832, accuracy: 94.4748%, tar: 0.0260 \n",
      "l0: 0.017266, l1: 0.018044, l2: 0.023509, l3: 0.034382, l4: 0.061847, l5: 0.120101, l6: 0.253766\n",
      "\n",
      "[epoch: 356/400, batch: 448/1000, ite: 47307] train loss: 1.1829, accuracy: 95.5238%, tar: 0.0260 \n",
      "l0: 0.022642, l1: 0.023127, l2: 0.031734, l3: 0.044686, l4: 0.074878, l5: 0.149413, l6: 0.316142\n",
      "\n",
      "[epoch: 356/400, batch: 456/1000, ite: 47308] train loss: 1.1828, accuracy: 95.4317%, tar: 0.0260 \n",
      "l0: 0.031698, l1: 0.034398, l2: 0.044256, l3: 0.067694, l4: 0.123602, l5: 0.223593, l6: 0.457531\n",
      "\n",
      "[epoch: 356/400, batch: 464/1000, ite: 47309] train loss: 1.1830, accuracy: 93.3983%, tar: 0.0260 \n",
      "l0: 0.013832, l1: 0.014633, l2: 0.020363, l3: 0.029915, l4: 0.051627, l5: 0.108570, l6: 0.251513\n",
      "\n",
      "[epoch: 356/400, batch: 472/1000, ite: 47310] train loss: 1.1826, accuracy: 97.0374%, tar: 0.0260 \n",
      "l0: 0.021141, l1: 0.022881, l2: 0.031312, l3: 0.054555, l4: 0.096774, l5: 0.200311, l6: 0.389657\n",
      "\n",
      "[epoch: 356/400, batch: 480/1000, ite: 47311] train loss: 1.1827, accuracy: 94.7835%, tar: 0.0260 \n",
      "l0: 0.018785, l1: 0.019916, l2: 0.026432, l3: 0.039972, l4: 0.070391, l5: 0.149123, l6: 0.283055\n",
      "\n",
      "[epoch: 356/400, batch: 488/1000, ite: 47312] train loss: 1.1824, accuracy: 95.8683%, tar: 0.0260 \n",
      "l0: 0.021794, l1: 0.023297, l2: 0.031561, l3: 0.048319, l4: 0.084527, l5: 0.210044, l6: 0.400749\n",
      "\n",
      "[epoch: 356/400, batch: 496/1000, ite: 47313] train loss: 1.1825, accuracy: 94.5568%, tar: 0.0260 \n",
      "l0: 0.019270, l1: 0.020652, l2: 0.027487, l3: 0.042592, l4: 0.078949, l5: 0.157802, l6: 0.375948\n",
      "\n",
      "[epoch: 356/400, batch: 504/1000, ite: 47314] train loss: 1.1824, accuracy: 95.2580%, tar: 0.0260 \n",
      "l0: 0.016949, l1: 0.018163, l2: 0.023287, l3: 0.037312, l4: 0.072424, l5: 0.186738, l6: 0.344838\n",
      "\n",
      "[epoch: 356/400, batch: 512/1000, ite: 47315] train loss: 1.1823, accuracy: 95.5279%, tar: 0.0260 \n",
      "l0: 0.021116, l1: 0.022419, l2: 0.029770, l3: 0.043872, l4: 0.076753, l5: 0.143815, l6: 0.266230\n",
      "\n",
      "[epoch: 356/400, batch: 520/1000, ite: 47316] train loss: 1.1821, accuracy: 96.0383%, tar: 0.0260 \n",
      "l0: 0.024193, l1: 0.024910, l2: 0.034530, l3: 0.047903, l4: 0.081454, l5: 0.153058, l6: 0.339960\n",
      "\n",
      "[epoch: 356/400, batch: 528/1000, ite: 47317] train loss: 1.1820, accuracy: 95.2658%, tar: 0.0260 \n",
      "l0: 0.018157, l1: 0.019026, l2: 0.025067, l3: 0.036721, l4: 0.063211, l5: 0.130681, l6: 0.266883\n",
      "\n",
      "[epoch: 356/400, batch: 536/1000, ite: 47318] train loss: 1.1817, accuracy: 95.9870%, tar: 0.0260 \n",
      "l0: 0.020074, l1: 0.021088, l2: 0.029284, l3: 0.044203, l4: 0.081761, l5: 0.149808, l6: 0.290757\n",
      "\n",
      "[epoch: 356/400, batch: 544/1000, ite: 47319] train loss: 1.1815, accuracy: 95.6229%, tar: 0.0260 \n",
      "l0: 0.021381, l1: 0.022296, l2: 0.029163, l3: 0.042047, l4: 0.075227, l5: 0.156765, l6: 0.316227\n",
      "\n",
      "[epoch: 356/400, batch: 552/1000, ite: 47320] train loss: 1.1814, accuracy: 95.7837%, tar: 0.0260 \n",
      "l0: 0.026645, l1: 0.027742, l2: 0.035197, l3: 0.052015, l4: 0.100457, l5: 0.190337, l6: 0.414950\n",
      "\n",
      "[epoch: 356/400, batch: 560/1000, ite: 47321] train loss: 1.1814, accuracy: 94.4724%, tar: 0.0260 \n",
      "l0: 0.023755, l1: 0.025377, l2: 0.034884, l3: 0.053630, l4: 0.104403, l5: 0.243221, l6: 0.427245\n",
      "\n",
      "[epoch: 356/400, batch: 568/1000, ite: 47322] train loss: 1.1816, accuracy: 95.1523%, tar: 0.0260 \n",
      "l0: 0.021358, l1: 0.022530, l2: 0.031277, l3: 0.051271, l4: 0.099560, l5: 0.152509, l6: 0.342489\n",
      "\n",
      "[epoch: 356/400, batch: 576/1000, ite: 47323] train loss: 1.1815, accuracy: 95.8045%, tar: 0.0260 \n",
      "l0: 0.025832, l1: 0.027600, l2: 0.035654, l3: 0.053805, l4: 0.094549, l5: 0.195667, l6: 0.376152\n",
      "\n",
      "[epoch: 356/400, batch: 584/1000, ite: 47324] train loss: 1.1815, accuracy: 94.6784%, tar: 0.0260 \n",
      "l0: 0.030927, l1: 0.033044, l2: 0.041109, l3: 0.059791, l4: 0.113686, l5: 0.283543, l6: 0.472578\n",
      "\n",
      "[epoch: 356/400, batch: 592/1000, ite: 47325] train loss: 1.1817, accuracy: 93.0990%, tar: 0.0260 \n",
      "l0: 0.023757, l1: 0.025005, l2: 0.034005, l3: 0.047080, l4: 0.077601, l5: 0.134057, l6: 0.299829\n",
      "\n",
      "[epoch: 356/400, batch: 600/1000, ite: 47326] train loss: 1.1816, accuracy: 95.4067%, tar: 0.0260 \n",
      "l0: 0.024235, l1: 0.025457, l2: 0.032068, l3: 0.046036, l4: 0.081458, l5: 0.167810, l6: 0.350189\n",
      "\n",
      "[epoch: 356/400, batch: 608/1000, ite: 47327] train loss: 1.1815, accuracy: 94.9624%, tar: 0.0260 \n",
      "l0: 0.018752, l1: 0.019336, l2: 0.025345, l3: 0.037784, l4: 0.061112, l5: 0.114410, l6: 0.278752\n",
      "\n",
      "[epoch: 356/400, batch: 616/1000, ite: 47328] train loss: 1.1812, accuracy: 96.0147%, tar: 0.0260 \n",
      "l0: 0.023218, l1: 0.024120, l2: 0.031442, l3: 0.043822, l4: 0.078792, l5: 0.154573, l6: 0.300622\n",
      "\n",
      "[epoch: 356/400, batch: 624/1000, ite: 47329] train loss: 1.1811, accuracy: 95.2697%, tar: 0.0260 \n",
      "l0: 0.021067, l1: 0.022250, l2: 0.029016, l3: 0.041195, l4: 0.084092, l5: 0.189544, l6: 0.384851\n",
      "\n",
      "[epoch: 356/400, batch: 632/1000, ite: 47330] train loss: 1.1810, accuracy: 95.0913%, tar: 0.0260 \n",
      "l0: 0.024766, l1: 0.026604, l2: 0.038288, l3: 0.062972, l4: 0.121603, l5: 0.213042, l6: 0.349855\n",
      "\n",
      "[epoch: 356/400, batch: 640/1000, ite: 47331] train loss: 1.1810, accuracy: 95.0228%, tar: 0.0260 \n",
      "l0: 0.031534, l1: 0.033189, l2: 0.042255, l3: 0.060400, l4: 0.111876, l5: 0.250715, l6: 0.531109\n",
      "\n",
      "[epoch: 356/400, batch: 648/1000, ite: 47332] train loss: 1.1814, accuracy: 93.2316%, tar: 0.0260 \n",
      "l0: 0.024275, l1: 0.025531, l2: 0.036068, l3: 0.055033, l4: 0.106698, l5: 0.276307, l6: 0.620554\n",
      "\n",
      "[epoch: 356/400, batch: 656/1000, ite: 47333] train loss: 1.1818, accuracy: 92.3687%, tar: 0.0260 \n",
      "l0: 0.015442, l1: 0.016256, l2: 0.023470, l3: 0.034622, l4: 0.053654, l5: 0.094725, l6: 0.196578\n",
      "\n",
      "[epoch: 356/400, batch: 664/1000, ite: 47334] train loss: 1.1814, accuracy: 96.6632%, tar: 0.0260 \n",
      "l0: 0.026581, l1: 0.028029, l2: 0.034343, l3: 0.052728, l4: 0.115119, l5: 0.252791, l6: 0.517445\n",
      "\n",
      "[epoch: 356/400, batch: 672/1000, ite: 47335] train loss: 1.1817, accuracy: 92.8231%, tar: 0.0260 \n",
      "l0: 0.022293, l1: 0.024047, l2: 0.033428, l3: 0.054138, l4: 0.100962, l5: 0.182673, l6: 0.373087\n",
      "\n",
      "[epoch: 356/400, batch: 680/1000, ite: 47336] train loss: 1.1817, accuracy: 95.1445%, tar: 0.0260 \n",
      "l0: 0.016748, l1: 0.018587, l2: 0.027031, l3: 0.039385, l4: 0.075641, l5: 0.162395, l6: 0.384205\n",
      "\n",
      "[epoch: 356/400, batch: 688/1000, ite: 47337] train loss: 1.1816, accuracy: 96.1192%, tar: 0.0260 \n",
      "l0: 0.018731, l1: 0.019702, l2: 0.028253, l3: 0.045144, l4: 0.085304, l5: 0.169101, l6: 0.361626\n",
      "\n",
      "[epoch: 356/400, batch: 696/1000, ite: 47338] train loss: 1.1815, accuracy: 95.4461%, tar: 0.0259 \n",
      "l0: 0.023421, l1: 0.024411, l2: 0.031544, l3: 0.044509, l4: 0.078575, l5: 0.157827, l6: 0.385096\n",
      "\n",
      "[epoch: 356/400, batch: 704/1000, ite: 47339] train loss: 1.1815, accuracy: 94.4908%, tar: 0.0259 \n",
      "l0: 0.025278, l1: 0.026387, l2: 0.033771, l3: 0.048096, l4: 0.085664, l5: 0.167570, l6: 0.330767\n",
      "\n",
      "[epoch: 356/400, batch: 712/1000, ite: 47340] train loss: 1.1814, accuracy: 95.1132%, tar: 0.0259 \n",
      "l0: 0.021267, l1: 0.022229, l2: 0.029372, l3: 0.042390, l4: 0.074067, l5: 0.154327, l6: 0.362296\n",
      "\n",
      "[epoch: 356/400, batch: 720/1000, ite: 47341] train loss: 1.1813, accuracy: 95.1052%, tar: 0.0259 \n",
      "l0: 0.022657, l1: 0.023996, l2: 0.030892, l3: 0.042278, l4: 0.076945, l5: 0.170146, l6: 0.342606\n",
      "\n",
      "[epoch: 356/400, batch: 728/1000, ite: 47342] train loss: 1.1812, accuracy: 95.5961%, tar: 0.0259 \n",
      "l0: 0.022852, l1: 0.024529, l2: 0.030509, l3: 0.052174, l4: 0.093183, l5: 0.176700, l6: 0.306075\n",
      "\n",
      "[epoch: 356/400, batch: 736/1000, ite: 47343] train loss: 1.1811, accuracy: 95.7091%, tar: 0.0259 \n",
      "l0: 0.024256, l1: 0.025302, l2: 0.032771, l3: 0.047790, l4: 0.089073, l5: 0.214873, l6: 0.432631\n",
      "\n",
      "[epoch: 356/400, batch: 744/1000, ite: 47344] train loss: 1.1812, accuracy: 93.7625%, tar: 0.0259 \n",
      "l0: 0.027779, l1: 0.029025, l2: 0.036591, l3: 0.053014, l4: 0.093437, l5: 0.221133, l6: 0.449564\n",
      "\n",
      "[epoch: 356/400, batch: 752/1000, ite: 47345] train loss: 1.1813, accuracy: 93.3120%, tar: 0.0259 \n",
      "l0: 0.022744, l1: 0.024826, l2: 0.032865, l3: 0.047104, l4: 0.085135, l5: 0.162817, l6: 0.454572\n",
      "\n",
      "[epoch: 356/400, batch: 760/1000, ite: 47346] train loss: 1.1814, accuracy: 94.5071%, tar: 0.0259 \n",
      "l0: 0.021966, l1: 0.023181, l2: 0.029651, l3: 0.045705, l4: 0.090449, l5: 0.180622, l6: 0.375198\n",
      "\n",
      "[epoch: 356/400, batch: 768/1000, ite: 47347] train loss: 1.1814, accuracy: 93.8347%, tar: 0.0259 \n",
      "l0: 0.019956, l1: 0.021476, l2: 0.029309, l3: 0.047304, l4: 0.096225, l5: 0.202171, l6: 0.368578\n",
      "\n",
      "[epoch: 356/400, batch: 776/1000, ite: 47348] train loss: 1.1814, accuracy: 95.5457%, tar: 0.0259 \n",
      "l0: 0.017935, l1: 0.019745, l2: 0.025673, l3: 0.039711, l4: 0.067753, l5: 0.129236, l6: 0.290329\n",
      "\n",
      "[epoch: 356/400, batch: 784/1000, ite: 47349] train loss: 1.1812, accuracy: 95.6485%, tar: 0.0259 \n",
      "l0: 0.019775, l1: 0.020771, l2: 0.029835, l3: 0.044239, l4: 0.071159, l5: 0.128649, l6: 0.249850\n",
      "\n",
      "[epoch: 356/400, batch: 792/1000, ite: 47350] train loss: 1.1809, accuracy: 95.8025%, tar: 0.0259 \n",
      "l0: 0.024125, l1: 0.025338, l2: 0.033763, l3: 0.048159, l4: 0.076254, l5: 0.136948, l6: 0.288714\n",
      "\n",
      "[epoch: 356/400, batch: 800/1000, ite: 47351] train loss: 1.1807, accuracy: 95.6884%, tar: 0.0259 \n",
      "l0: 0.022617, l1: 0.023729, l2: 0.029438, l3: 0.042045, l4: 0.072808, l5: 0.157457, l6: 0.339700\n",
      "\n",
      "[epoch: 356/400, batch: 808/1000, ite: 47352] train loss: 1.1806, accuracy: 95.0088%, tar: 0.0259 \n",
      "l0: 0.022661, l1: 0.024083, l2: 0.032875, l3: 0.052012, l4: 0.093174, l5: 0.210284, l6: 0.382453\n",
      "\n",
      "[epoch: 356/400, batch: 816/1000, ite: 47353] train loss: 1.1806, accuracy: 94.4689%, tar: 0.0259 \n",
      "l0: 0.026525, l1: 0.027254, l2: 0.033811, l3: 0.047918, l4: 0.090594, l5: 0.186448, l6: 0.379972\n",
      "\n",
      "[epoch: 356/400, batch: 824/1000, ite: 47354] train loss: 1.1806, accuracy: 94.2861%, tar: 0.0259 \n",
      "l0: 0.020721, l1: 0.022512, l2: 0.031537, l3: 0.052544, l4: 0.093792, l5: 0.202536, l6: 0.409030\n",
      "\n",
      "[epoch: 356/400, batch: 832/1000, ite: 47355] train loss: 1.1807, accuracy: 95.2790%, tar: 0.0259 \n",
      "l0: 0.019849, l1: 0.021175, l2: 0.028155, l3: 0.041812, l4: 0.076443, l5: 0.129865, l6: 0.303562\n",
      "\n",
      "[epoch: 356/400, batch: 840/1000, ite: 47356] train loss: 1.1805, accuracy: 95.7008%, tar: 0.0259 \n",
      "l0: 0.018340, l1: 0.020065, l2: 0.028853, l3: 0.042543, l4: 0.079534, l5: 0.162046, l6: 0.321442\n",
      "\n",
      "[epoch: 356/400, batch: 848/1000, ite: 47357] train loss: 1.1804, accuracy: 96.1799%, tar: 0.0259 \n",
      "l0: 0.028716, l1: 0.030843, l2: 0.041936, l3: 0.063126, l4: 0.115632, l5: 0.228655, l6: 0.411530\n",
      "\n",
      "[epoch: 356/400, batch: 856/1000, ite: 47358] train loss: 1.1805, accuracy: 93.9118%, tar: 0.0259 \n",
      "l0: 0.018448, l1: 0.020150, l2: 0.027768, l3: 0.046278, l4: 0.119238, l5: 0.246967, l6: 0.436174\n",
      "\n",
      "[epoch: 356/400, batch: 864/1000, ite: 47359] train loss: 1.1806, accuracy: 95.4696%, tar: 0.0259 \n",
      "l0: 0.023017, l1: 0.024052, l2: 0.031624, l3: 0.045371, l4: 0.086109, l5: 0.167302, l6: 0.346714\n",
      "\n",
      "[epoch: 356/400, batch: 872/1000, ite: 47360] train loss: 1.1805, accuracy: 95.0822%, tar: 0.0259 \n",
      "l0: 0.027035, l1: 0.028078, l2: 0.036009, l3: 0.051962, l4: 0.086153, l5: 0.170539, l6: 0.405461\n",
      "\n",
      "[epoch: 356/400, batch: 880/1000, ite: 47361] train loss: 1.1805, accuracy: 94.3365%, tar: 0.0259 \n",
      "l0: 0.018763, l1: 0.020202, l2: 0.028233, l3: 0.045439, l4: 0.090334, l5: 0.181380, l6: 0.367409\n",
      "\n",
      "[epoch: 356/400, batch: 888/1000, ite: 47362] train loss: 1.1805, accuracy: 95.5734%, tar: 0.0259 \n",
      "l0: 0.028616, l1: 0.029726, l2: 0.039122, l3: 0.054812, l4: 0.092023, l5: 0.198759, l6: 0.362623\n",
      "\n",
      "[epoch: 356/400, batch: 896/1000, ite: 47363] train loss: 1.1805, accuracy: 94.4362%, tar: 0.0259 \n",
      "l0: 0.024915, l1: 0.026084, l2: 0.034439, l3: 0.048663, l4: 0.094188, l5: 0.198368, l6: 0.400533\n",
      "\n",
      "[epoch: 356/400, batch: 904/1000, ite: 47364] train loss: 1.1805, accuracy: 94.7781%, tar: 0.0259 \n",
      "l0: 0.023882, l1: 0.024589, l2: 0.032973, l3: 0.048398, l4: 0.088694, l5: 0.190007, l6: 0.336453\n",
      "\n",
      "[epoch: 356/400, batch: 912/1000, ite: 47365] train loss: 1.1805, accuracy: 94.7925%, tar: 0.0259 \n",
      "l0: 0.020021, l1: 0.020967, l2: 0.028498, l3: 0.047203, l4: 0.107441, l5: 0.195610, l6: 0.367452\n",
      "\n",
      "[epoch: 356/400, batch: 920/1000, ite: 47366] train loss: 1.1804, accuracy: 94.8155%, tar: 0.0259 \n",
      "l0: 0.029360, l1: 0.030634, l2: 0.039471, l3: 0.062016, l4: 0.121053, l5: 0.232985, l6: 0.449208\n",
      "\n",
      "[epoch: 356/400, batch: 928/1000, ite: 47367] train loss: 1.1806, accuracy: 93.8143%, tar: 0.0259 \n",
      "l0: 0.021226, l1: 0.022859, l2: 0.033055, l3: 0.053423, l4: 0.100483, l5: 0.186695, l6: 0.360340\n",
      "\n",
      "[epoch: 356/400, batch: 936/1000, ite: 47368] train loss: 1.1806, accuracy: 95.2841%, tar: 0.0259 \n",
      "l0: 0.027003, l1: 0.028518, l2: 0.036034, l3: 0.058103, l4: 0.127043, l5: 0.259044, l6: 0.488647\n",
      "\n",
      "[epoch: 356/400, batch: 944/1000, ite: 47369] train loss: 1.1808, accuracy: 94.6280%, tar: 0.0259 \n",
      "l0: 0.017785, l1: 0.018859, l2: 0.024619, l3: 0.037209, l4: 0.062783, l5: 0.116342, l6: 0.290609\n",
      "\n",
      "[epoch: 356/400, batch: 952/1000, ite: 47370] train loss: 1.1806, accuracy: 96.1647%, tar: 0.0259 \n",
      "l0: 0.023549, l1: 0.024468, l2: 0.031008, l3: 0.044116, l4: 0.078084, l5: 0.188405, l6: 0.351040\n",
      "\n",
      "[epoch: 356/400, batch: 960/1000, ite: 47371] train loss: 1.1805, accuracy: 94.7005%, tar: 0.0259 \n",
      "l0: 0.022257, l1: 0.023390, l2: 0.030406, l3: 0.046195, l4: 0.087684, l5: 0.176139, l6: 0.339416\n",
      "\n",
      "[epoch: 356/400, batch: 968/1000, ite: 47372] train loss: 1.1805, accuracy: 95.2466%, tar: 0.0259 \n",
      "l0: 0.025131, l1: 0.027145, l2: 0.038196, l3: 0.058484, l4: 0.103100, l5: 0.205788, l6: 0.417691\n",
      "\n",
      "[epoch: 356/400, batch: 976/1000, ite: 47373] train loss: 1.1806, accuracy: 94.5105%, tar: 0.0259 \n",
      "l0: 0.026074, l1: 0.027260, l2: 0.036115, l3: 0.051619, l4: 0.090787, l5: 0.158567, l6: 0.302344\n",
      "\n",
      "[epoch: 356/400, batch: 984/1000, ite: 47374] train loss: 1.1804, accuracy: 95.4149%, tar: 0.0259 \n",
      "l0: 0.023675, l1: 0.025487, l2: 0.033532, l3: 0.050870, l4: 0.092191, l5: 0.170781, l6: 0.379662\n",
      "\n",
      "[epoch: 356/400, batch: 992/1000, ite: 47375] train loss: 1.1804, accuracy: 95.4573%, tar: 0.0259 \n",
      "l0: 0.017307, l1: 0.018642, l2: 0.025259, l3: 0.035241, l4: 0.059505, l5: 0.128374, l6: 0.296556\n",
      "\n",
      "[epoch: 356/400, batch: 1000/1000, ite: 47376] train loss: 1.1802, accuracy: 96.7892%, tar: 0.0259 \n",
      "l0: 0.020682, l1: 0.022568, l2: 0.032791, l3: 0.051158, l4: 0.104876, l5: 0.201348, l6: 0.353568\n",
      "\n",
      "[epoch: 357/400, batch: 8/1000, ite: 47377] train loss: 1.1802, accuracy: 95.7551%, tar: 0.0259 \n",
      "l0: 0.020987, l1: 0.022661, l2: 0.028442, l3: 0.041164, l4: 0.077122, l5: 0.143461, l6: 0.312995\n",
      "\n",
      "[epoch: 357/400, batch: 16/1000, ite: 47378] train loss: 1.1800, accuracy: 95.3283%, tar: 0.0259 \n",
      "l0: 0.026777, l1: 0.028953, l2: 0.039755, l3: 0.061857, l4: 0.128096, l5: 0.240673, l6: 0.371970\n",
      "\n",
      "[epoch: 357/400, batch: 24/1000, ite: 47379] train loss: 1.1801, accuracy: 94.4754%, tar: 0.0259 \n",
      "l0: 0.020801, l1: 0.021952, l2: 0.028747, l3: 0.041802, l4: 0.079023, l5: 0.147984, l6: 0.398655\n",
      "\n",
      "[epoch: 357/400, batch: 32/1000, ite: 47380] train loss: 1.1801, accuracy: 95.4802%, tar: 0.0259 \n",
      "l0: 0.020995, l1: 0.022476, l2: 0.031217, l3: 0.049258, l4: 0.091779, l5: 0.189954, l6: 0.425624\n",
      "\n",
      "[epoch: 357/400, batch: 40/1000, ite: 47381] train loss: 1.1801, accuracy: 94.9462%, tar: 0.0258 \n",
      "l0: 0.023682, l1: 0.025469, l2: 0.033266, l3: 0.048431, l4: 0.088834, l5: 0.180772, l6: 0.350008\n",
      "\n",
      "[epoch: 357/400, batch: 48/1000, ite: 47382] train loss: 1.1801, accuracy: 94.6728%, tar: 0.0258 \n",
      "l0: 0.020519, l1: 0.021459, l2: 0.028799, l3: 0.043381, l4: 0.085480, l5: 0.178242, l6: 0.356996\n",
      "\n",
      "[epoch: 357/400, batch: 56/1000, ite: 47383] train loss: 1.1800, accuracy: 95.0941%, tar: 0.0258 \n",
      "l0: 0.021656, l1: 0.023084, l2: 0.031794, l3: 0.045954, l4: 0.081380, l5: 0.154095, l6: 0.363916\n",
      "\n",
      "[epoch: 357/400, batch: 64/1000, ite: 47384] train loss: 1.1799, accuracy: 95.4901%, tar: 0.0258 \n",
      "l0: 0.021460, l1: 0.022721, l2: 0.031593, l3: 0.050032, l4: 0.098219, l5: 0.210080, l6: 0.380765\n",
      "\n",
      "[epoch: 357/400, batch: 72/1000, ite: 47385] train loss: 1.1799, accuracy: 94.6856%, tar: 0.0258 \n",
      "l0: 0.024957, l1: 0.027562, l2: 0.039422, l3: 0.064081, l4: 0.110516, l5: 0.232316, l6: 0.441472\n",
      "\n",
      "[epoch: 357/400, batch: 80/1000, ite: 47386] train loss: 1.1801, accuracy: 94.2821%, tar: 0.0258 \n",
      "l0: 0.020205, l1: 0.021494, l2: 0.028275, l3: 0.040631, l4: 0.074637, l5: 0.141764, l6: 0.339915\n",
      "\n",
      "[epoch: 357/400, batch: 88/1000, ite: 47387] train loss: 1.1800, accuracy: 95.4867%, tar: 0.0258 \n",
      "l0: 0.029133, l1: 0.030873, l2: 0.040133, l3: 0.062292, l4: 0.130151, l5: 0.258085, l6: 0.540869\n",
      "\n",
      "[epoch: 357/400, batch: 96/1000, ite: 47388] train loss: 1.1803, accuracy: 92.5547%, tar: 0.0258 \n",
      "l0: 0.022308, l1: 0.023355, l2: 0.031265, l3: 0.046962, l4: 0.084219, l5: 0.186765, l6: 0.416218\n",
      "\n",
      "[epoch: 357/400, batch: 104/1000, ite: 47389] train loss: 1.1803, accuracy: 93.9849%, tar: 0.0258 \n",
      "l0: 0.020024, l1: 0.021635, l2: 0.029166, l3: 0.044910, l4: 0.090313, l5: 0.196667, l6: 0.386537\n",
      "\n",
      "[epoch: 357/400, batch: 112/1000, ite: 47390] train loss: 1.1804, accuracy: 94.9535%, tar: 0.0258 \n",
      "l0: 0.021117, l1: 0.023373, l2: 0.032803, l3: 0.055176, l4: 0.107921, l5: 0.182370, l6: 0.313499\n",
      "\n",
      "[epoch: 357/400, batch: 120/1000, ite: 47391] train loss: 1.1803, accuracy: 95.6779%, tar: 0.0258 \n",
      "l0: 0.015585, l1: 0.016660, l2: 0.022639, l3: 0.033524, l4: 0.062216, l5: 0.140123, l6: 0.272699\n",
      "\n",
      "[epoch: 357/400, batch: 128/1000, ite: 47392] train loss: 1.1800, accuracy: 95.7482%, tar: 0.0258 \n",
      "l0: 0.023902, l1: 0.025579, l2: 0.035764, l3: 0.051007, l4: 0.092333, l5: 0.200208, l6: 0.371103\n",
      "\n",
      "[epoch: 357/400, batch: 136/1000, ite: 47393] train loss: 1.1800, accuracy: 94.9263%, tar: 0.0258 \n",
      "l0: 0.027859, l1: 0.030163, l2: 0.040748, l3: 0.067369, l4: 0.133655, l5: 0.253943, l6: 0.500137\n",
      "\n",
      "[epoch: 357/400, batch: 144/1000, ite: 47394] train loss: 1.1803, accuracy: 94.1402%, tar: 0.0258 \n",
      "l0: 0.017933, l1: 0.018778, l2: 0.024659, l3: 0.039182, l4: 0.070674, l5: 0.141803, l6: 0.287448\n",
      "\n",
      "[epoch: 357/400, batch: 152/1000, ite: 47395] train loss: 1.1801, accuracy: 95.7287%, tar: 0.0258 \n",
      "l0: 0.023140, l1: 0.024526, l2: 0.033900, l3: 0.053616, l4: 0.097413, l5: 0.189936, l6: 0.387105\n",
      "\n",
      "[epoch: 357/400, batch: 160/1000, ite: 47396] train loss: 1.1801, accuracy: 95.4238%, tar: 0.0258 \n",
      "l0: 0.026419, l1: 0.027761, l2: 0.037658, l3: 0.056813, l4: 0.119779, l5: 0.252137, l6: 0.469628\n",
      "\n",
      "[epoch: 357/400, batch: 168/1000, ite: 47397] train loss: 1.1803, accuracy: 94.0675%, tar: 0.0258 \n",
      "l0: 0.018137, l1: 0.018456, l2: 0.024289, l3: 0.037879, l4: 0.062543, l5: 0.113401, l6: 0.212702\n",
      "\n",
      "[epoch: 357/400, batch: 176/1000, ite: 47398] train loss: 1.1799, accuracy: 96.2344%, tar: 0.0258 \n",
      "l0: 0.022863, l1: 0.023900, l2: 0.032079, l3: 0.050986, l4: 0.087795, l5: 0.169467, l6: 0.357703\n",
      "\n",
      "[epoch: 357/400, batch: 200/1000, ite: 47401] train loss: 1.1800, accuracy: 94.7402%, tar: 0.0258 \n",
      "l0: 0.020477, l1: 0.021257, l2: 0.027594, l3: 0.037663, l4: 0.067449, l5: 0.130147, l6: 0.309638\n",
      "\n",
      "[epoch: 357/400, batch: 208/1000, ite: 47402] train loss: 1.1798, accuracy: 95.2620%, tar: 0.0258 \n",
      "l0: 0.026102, l1: 0.028067, l2: 0.034837, l3: 0.054479, l4: 0.120115, l5: 0.289668, l6: 0.547538\n",
      "\n",
      "[epoch: 357/400, batch: 216/1000, ite: 47403] train loss: 1.1801, accuracy: 93.1721%, tar: 0.0258 \n",
      "l0: 0.024197, l1: 0.025300, l2: 0.035355, l3: 0.061556, l4: 0.116523, l5: 0.219467, l6: 0.384940\n",
      "\n",
      "[epoch: 357/400, batch: 224/1000, ite: 47404] train loss: 1.1802, accuracy: 94.2365%, tar: 0.0258 \n",
      "l0: 0.026422, l1: 0.027835, l2: 0.037184, l3: 0.054722, l4: 0.095885, l5: 0.188549, l6: 0.418315\n",
      "\n",
      "[epoch: 357/400, batch: 232/1000, ite: 47405] train loss: 1.1802, accuracy: 93.9115%, tar: 0.0258 \n",
      "l0: 0.033781, l1: 0.035251, l2: 0.045782, l3: 0.065343, l4: 0.120777, l5: 0.261304, l6: 0.552434\n",
      "\n",
      "[epoch: 357/400, batch: 240/1000, ite: 47406] train loss: 1.1806, accuracy: 91.7626%, tar: 0.0258 \n",
      "l0: 0.018775, l1: 0.019622, l2: 0.026175, l3: 0.039283, l4: 0.071348, l5: 0.125648, l6: 0.353327\n",
      "\n",
      "[epoch: 357/400, batch: 248/1000, ite: 47407] train loss: 1.1805, accuracy: 95.1363%, tar: 0.0258 \n",
      "l0: 0.019210, l1: 0.020597, l2: 0.028626, l3: 0.043885, l4: 0.073436, l5: 0.136317, l6: 0.269227\n",
      "\n",
      "[epoch: 357/400, batch: 256/1000, ite: 47408] train loss: 1.1802, accuracy: 96.3656%, tar: 0.0258 \n",
      "l0: 0.022058, l1: 0.023598, l2: 0.031727, l3: 0.052573, l4: 0.099377, l5: 0.211075, l6: 0.426604\n",
      "\n",
      "[epoch: 357/400, batch: 264/1000, ite: 47409] train loss: 1.1803, accuracy: 94.7850%, tar: 0.0258 \n",
      "l0: 0.019527, l1: 0.020691, l2: 0.026986, l3: 0.041965, l4: 0.084228, l5: 0.164427, l6: 0.275351\n",
      "\n",
      "[epoch: 357/400, batch: 272/1000, ite: 47410] train loss: 1.1801, accuracy: 95.7680%, tar: 0.0258 \n",
      "l0: 0.022071, l1: 0.023478, l2: 0.032673, l3: 0.052720, l4: 0.111748, l5: 0.224561, l6: 0.408814\n",
      "\n",
      "[epoch: 357/400, batch: 280/1000, ite: 47411] train loss: 1.1802, accuracy: 95.0743%, tar: 0.0258 \n",
      "l0: 0.026631, l1: 0.027622, l2: 0.036182, l3: 0.053152, l4: 0.098848, l5: 0.213018, l6: 0.436543\n",
      "\n",
      "[epoch: 357/400, batch: 288/1000, ite: 47412] train loss: 1.1803, accuracy: 93.4279%, tar: 0.0258 \n",
      "l0: 0.019458, l1: 0.021111, l2: 0.028825, l3: 0.043970, l4: 0.089151, l5: 0.194257, l6: 0.408789\n",
      "\n",
      "[epoch: 357/400, batch: 296/1000, ite: 47413] train loss: 1.1803, accuracy: 95.5451%, tar: 0.0258 \n",
      "l0: 0.028940, l1: 0.030009, l2: 0.038000, l3: 0.057287, l4: 0.106794, l5: 0.225809, l6: 0.437812\n",
      "\n",
      "[epoch: 357/400, batch: 304/1000, ite: 47414] train loss: 1.1805, accuracy: 93.8528%, tar: 0.0258 \n",
      "l0: 0.019983, l1: 0.020721, l2: 0.027045, l3: 0.042889, l4: 0.087190, l5: 0.185352, l6: 0.407149\n",
      "\n",
      "[epoch: 357/400, batch: 312/1000, ite: 47415] train loss: 1.1805, accuracy: 94.2827%, tar: 0.0258 \n",
      "l0: 0.016423, l1: 0.017828, l2: 0.023565, l3: 0.036170, l4: 0.059987, l5: 0.120209, l6: 0.245199\n",
      "\n",
      "[epoch: 357/400, batch: 320/1000, ite: 47416] train loss: 1.1802, accuracy: 96.2220%, tar: 0.0258 \n",
      "l0: 0.026531, l1: 0.027520, l2: 0.034636, l3: 0.051175, l4: 0.091439, l5: 0.182460, l6: 0.423179\n",
      "\n",
      "[epoch: 357/400, batch: 328/1000, ite: 47417] train loss: 1.1803, accuracy: 93.8249%, tar: 0.0258 \n",
      "l0: 0.019273, l1: 0.021087, l2: 0.029731, l3: 0.049769, l4: 0.098234, l5: 0.203998, l6: 0.408239\n",
      "\n",
      "[epoch: 357/400, batch: 336/1000, ite: 47418] train loss: 1.1803, accuracy: 95.0285%, tar: 0.0258 \n",
      "l0: 0.023068, l1: 0.024392, l2: 0.034189, l3: 0.051848, l4: 0.095685, l5: 0.197058, l6: 0.373927\n",
      "\n",
      "[epoch: 357/400, batch: 344/1000, ite: 47419] train loss: 1.1803, accuracy: 94.4927%, tar: 0.0258 \n",
      "l0: 0.019438, l1: 0.020922, l2: 0.027807, l3: 0.040835, l4: 0.074497, l5: 0.145573, l6: 0.323036\n",
      "\n",
      "[epoch: 357/400, batch: 352/1000, ite: 47420] train loss: 1.1802, accuracy: 95.8894%, tar: 0.0258 \n",
      "l0: 0.020416, l1: 0.021710, l2: 0.030432, l3: 0.050050, l4: 0.134980, l5: 0.245206, l6: 0.420646\n",
      "\n",
      "[epoch: 357/400, batch: 360/1000, ite: 47421] train loss: 1.1803, accuracy: 95.5247%, tar: 0.0258 \n",
      "l0: 0.023616, l1: 0.024819, l2: 0.032239, l3: 0.046322, l4: 0.081150, l5: 0.141056, l6: 0.308699\n",
      "\n",
      "[epoch: 357/400, batch: 368/1000, ite: 47422] train loss: 1.1801, accuracy: 94.9992%, tar: 0.0258 \n",
      "l0: 0.022943, l1: 0.024431, l2: 0.034224, l3: 0.051893, l4: 0.098697, l5: 0.215180, l6: 0.394736\n",
      "\n",
      "[epoch: 357/400, batch: 376/1000, ite: 47423] train loss: 1.1802, accuracy: 94.8746%, tar: 0.0257 \n",
      "l0: 0.017562, l1: 0.018648, l2: 0.024996, l3: 0.041493, l4: 0.084898, l5: 0.196366, l6: 0.364045\n",
      "\n",
      "[epoch: 357/400, batch: 384/1000, ite: 47424] train loss: 1.1801, accuracy: 95.8666%, tar: 0.0257 \n",
      "l0: 0.022254, l1: 0.022770, l2: 0.029665, l3: 0.045605, l4: 0.081303, l5: 0.162479, l6: 0.341147\n",
      "\n",
      "[epoch: 357/400, batch: 392/1000, ite: 47425] train loss: 1.1801, accuracy: 94.1628%, tar: 0.0257 \n",
      "l0: 0.016523, l1: 0.017744, l2: 0.025106, l3: 0.040151, l4: 0.079084, l5: 0.156031, l6: 0.294358\n",
      "\n",
      "[epoch: 357/400, batch: 400/1000, ite: 47426] train loss: 1.1799, accuracy: 96.6120%, tar: 0.0257 \n",
      "l0: 0.020867, l1: 0.022641, l2: 0.031501, l3: 0.045885, l4: 0.089727, l5: 0.191024, l6: 0.388909\n",
      "\n",
      "[epoch: 357/400, batch: 408/1000, ite: 47427] train loss: 1.1799, accuracy: 95.0976%, tar: 0.0257 \n",
      "l0: 0.019220, l1: 0.020457, l2: 0.026742, l3: 0.038414, l4: 0.067266, l5: 0.141427, l6: 0.281406\n",
      "\n",
      "[epoch: 357/400, batch: 416/1000, ite: 47428] train loss: 1.1797, accuracy: 95.9249%, tar: 0.0257 \n",
      "l0: 0.021870, l1: 0.022483, l2: 0.028069, l3: 0.038733, l4: 0.059355, l5: 0.104536, l6: 0.196766\n",
      "\n",
      "[epoch: 357/400, batch: 424/1000, ite: 47429] train loss: 1.1793, accuracy: 96.0300%, tar: 0.0257 \n",
      "l0: 0.022162, l1: 0.024462, l2: 0.034389, l3: 0.051314, l4: 0.100358, l5: 0.212948, l6: 0.433309\n",
      "\n",
      "[epoch: 357/400, batch: 432/1000, ite: 47430] train loss: 1.1794, accuracy: 95.0011%, tar: 0.0257 \n",
      "l0: 0.020273, l1: 0.021270, l2: 0.027838, l3: 0.039110, l4: 0.074562, l5: 0.146033, l6: 0.289174\n",
      "\n",
      "[epoch: 357/400, batch: 440/1000, ite: 47431] train loss: 1.1792, accuracy: 95.8753%, tar: 0.0257 \n",
      "l0: 0.022240, l1: 0.023332, l2: 0.031779, l3: 0.049001, l4: 0.094250, l5: 0.273750, l6: 0.501430\n",
      "\n",
      "[epoch: 357/400, batch: 448/1000, ite: 47432] train loss: 1.1795, accuracy: 92.7968%, tar: 0.0257 \n",
      "l0: 0.021151, l1: 0.022950, l2: 0.031432, l3: 0.051855, l4: 0.099017, l5: 0.205767, l6: 0.461121\n",
      "\n",
      "[epoch: 357/400, batch: 456/1000, ite: 47433] train loss: 1.1796, accuracy: 94.3617%, tar: 0.0257 \n",
      "l0: 0.016005, l1: 0.016743, l2: 0.021374, l3: 0.033390, l4: 0.073029, l5: 0.162402, l6: 0.337658\n",
      "\n",
      "[epoch: 357/400, batch: 464/1000, ite: 47434] train loss: 1.1795, accuracy: 95.2385%, tar: 0.0257 \n",
      "l0: 0.018993, l1: 0.020212, l2: 0.026782, l3: 0.039514, l4: 0.066809, l5: 0.139258, l6: 0.266592\n",
      "\n",
      "[epoch: 357/400, batch: 472/1000, ite: 47435] train loss: 1.1792, accuracy: 95.8411%, tar: 0.0257 \n",
      "l0: 0.020931, l1: 0.021601, l2: 0.028695, l3: 0.043210, l4: 0.076764, l5: 0.164932, l6: 0.348641\n",
      "\n",
      "[epoch: 357/400, batch: 480/1000, ite: 47436] train loss: 1.1791, accuracy: 95.0858%, tar: 0.0257 \n",
      "l0: 0.027186, l1: 0.028473, l2: 0.038123, l3: 0.055490, l4: 0.103938, l5: 0.238427, l6: 0.516714\n",
      "\n",
      "[epoch: 357/400, batch: 488/1000, ite: 47437] train loss: 1.1794, accuracy: 93.7173%, tar: 0.0257 \n",
      "l0: 0.024611, l1: 0.025255, l2: 0.033746, l3: 0.050031, l4: 0.094393, l5: 0.171950, l6: 0.344418\n",
      "\n",
      "[epoch: 357/400, batch: 496/1000, ite: 47438] train loss: 1.1793, accuracy: 95.1064%, tar: 0.0257 \n",
      "l0: 0.016321, l1: 0.017630, l2: 0.025502, l3: 0.043597, l4: 0.094879, l5: 0.179603, l6: 0.356884\n",
      "\n",
      "[epoch: 357/400, batch: 504/1000, ite: 47439] train loss: 1.1793, accuracy: 95.7948%, tar: 0.0257 \n",
      "l0: 0.021163, l1: 0.022172, l2: 0.029127, l3: 0.043232, l4: 0.078913, l5: 0.139533, l6: 0.293763\n",
      "\n",
      "[epoch: 357/400, batch: 512/1000, ite: 47440] train loss: 1.1791, accuracy: 95.1960%, tar: 0.0257 \n",
      "l0: 0.027281, l1: 0.028499, l2: 0.037102, l3: 0.057227, l4: 0.125212, l5: 0.263732, l6: 0.495767\n",
      "\n",
      "[epoch: 357/400, batch: 520/1000, ite: 47441] train loss: 1.1793, accuracy: 93.0550%, tar: 0.0257 \n",
      "l0: 0.024892, l1: 0.027323, l2: 0.040138, l3: 0.061556, l4: 0.108474, l5: 0.199209, l6: 0.380097\n",
      "\n",
      "[epoch: 357/400, batch: 528/1000, ite: 47442] train loss: 1.1794, accuracy: 94.9778%, tar: 0.0257 \n",
      "l0: 0.018687, l1: 0.019685, l2: 0.026729, l3: 0.037139, l4: 0.062261, l5: 0.127109, l6: 0.289203\n",
      "\n",
      "[epoch: 357/400, batch: 536/1000, ite: 47443] train loss: 1.1792, accuracy: 95.7618%, tar: 0.0257 \n",
      "l0: 0.023566, l1: 0.025294, l2: 0.034392, l3: 0.052760, l4: 0.099738, l5: 0.227261, l6: 0.391642\n",
      "\n",
      "[epoch: 357/400, batch: 544/1000, ite: 47444] train loss: 1.1792, accuracy: 94.4787%, tar: 0.0257 \n",
      "l0: 0.020434, l1: 0.022687, l2: 0.031381, l3: 0.048006, l4: 0.083132, l5: 0.163589, l6: 0.319390\n",
      "\n",
      "[epoch: 357/400, batch: 552/1000, ite: 47445] train loss: 1.1791, accuracy: 95.8733%, tar: 0.0257 \n",
      "l0: 0.023851, l1: 0.025155, l2: 0.033187, l3: 0.047867, l4: 0.084336, l5: 0.204152, l6: 0.443308\n",
      "\n",
      "[epoch: 357/400, batch: 560/1000, ite: 47446] train loss: 1.1792, accuracy: 94.3488%, tar: 0.0257 \n",
      "l0: 0.024212, l1: 0.025268, l2: 0.033615, l3: 0.047224, l4: 0.100048, l5: 0.197705, l6: 0.419740\n",
      "\n",
      "[epoch: 357/400, batch: 568/1000, ite: 47447] train loss: 1.1792, accuracy: 94.1436%, tar: 0.0257 \n",
      "l0: 0.020142, l1: 0.021273, l2: 0.028481, l3: 0.044245, l4: 0.082443, l5: 0.164607, l6: 0.363705\n",
      "\n",
      "[epoch: 357/400, batch: 576/1000, ite: 47448] train loss: 1.1792, accuracy: 95.2892%, tar: 0.0257 \n",
      "l0: 0.021325, l1: 0.022579, l2: 0.030812, l3: 0.048205, l4: 0.089565, l5: 0.175544, l6: 0.355109\n",
      "\n",
      "[epoch: 357/400, batch: 584/1000, ite: 47449] train loss: 1.1791, accuracy: 94.6567%, tar: 0.0257 \n",
      "l0: 0.023378, l1: 0.024268, l2: 0.031381, l3: 0.044300, l4: 0.071782, l5: 0.147359, l6: 0.358536\n",
      "\n",
      "[epoch: 357/400, batch: 592/1000, ite: 47450] train loss: 1.1791, accuracy: 94.8541%, tar: 0.0257 \n",
      "l0: 0.015073, l1: 0.016001, l2: 0.022901, l3: 0.035137, l4: 0.065353, l5: 0.123164, l6: 0.242910\n",
      "\n",
      "[epoch: 357/400, batch: 600/1000, ite: 47451] train loss: 1.1788, accuracy: 96.9109%, tar: 0.0257 \n",
      "l0: 0.019332, l1: 0.020788, l2: 0.028194, l3: 0.048009, l4: 0.085371, l5: 0.172800, l6: 0.354105\n",
      "\n",
      "[epoch: 357/400, batch: 608/1000, ite: 47452] train loss: 1.1787, accuracy: 95.0621%, tar: 0.0257 \n",
      "l0: 0.029423, l1: 0.032309, l2: 0.044796, l3: 0.067826, l4: 0.122962, l5: 0.229605, l6: 0.458411\n",
      "\n",
      "[epoch: 357/400, batch: 616/1000, ite: 47453] train loss: 1.1789, accuracy: 94.2217%, tar: 0.0257 \n",
      "l0: 0.015080, l1: 0.015855, l2: 0.021482, l3: 0.032816, l4: 0.053640, l5: 0.093971, l6: 0.182669\n",
      "\n",
      "[epoch: 357/400, batch: 624/1000, ite: 47454] train loss: 1.1785, accuracy: 96.7323%, tar: 0.0257 \n",
      "l0: 0.022313, l1: 0.023405, l2: 0.029926, l3: 0.042380, l4: 0.081069, l5: 0.162734, l6: 0.370914\n",
      "\n",
      "[epoch: 357/400, batch: 632/1000, ite: 47455] train loss: 1.1784, accuracy: 95.0291%, tar: 0.0256 \n",
      "l0: 0.024214, l1: 0.025147, l2: 0.033421, l3: 0.046265, l4: 0.076731, l5: 0.150752, l6: 0.329114\n",
      "\n",
      "[epoch: 357/400, batch: 640/1000, ite: 47456] train loss: 1.1783, accuracy: 94.7458%, tar: 0.0256 \n",
      "l0: 0.025063, l1: 0.026331, l2: 0.034588, l3: 0.051279, l4: 0.090454, l5: 0.171405, l6: 0.331727\n",
      "\n",
      "[epoch: 357/400, batch: 648/1000, ite: 47457] train loss: 1.1783, accuracy: 94.2052%, tar: 0.0256 \n",
      "l0: 0.020177, l1: 0.021778, l2: 0.029111, l3: 0.042317, l4: 0.087905, l5: 0.171631, l6: 0.401950\n",
      "\n",
      "[epoch: 357/400, batch: 656/1000, ite: 47458] train loss: 1.1783, accuracy: 95.4493%, tar: 0.0256 \n",
      "l0: 0.022787, l1: 0.023863, l2: 0.032329, l3: 0.052883, l4: 0.089755, l5: 0.158831, l6: 0.387218\n",
      "\n",
      "[epoch: 357/400, batch: 664/1000, ite: 47459] train loss: 1.1782, accuracy: 95.1580%, tar: 0.0256 \n",
      "l0: 0.023210, l1: 0.024521, l2: 0.032515, l3: 0.047949, l4: 0.088915, l5: 0.211988, l6: 0.475279\n",
      "\n",
      "[epoch: 357/400, batch: 672/1000, ite: 47460] train loss: 1.1784, accuracy: 93.9835%, tar: 0.0256 \n",
      "l0: 0.019020, l1: 0.019636, l2: 0.025176, l3: 0.033084, l4: 0.055064, l5: 0.098290, l6: 0.246038\n",
      "\n",
      "[epoch: 357/400, batch: 680/1000, ite: 47461] train loss: 1.1781, accuracy: 96.1633%, tar: 0.0256 \n",
      "l0: 0.018512, l1: 0.019686, l2: 0.027425, l3: 0.042982, l4: 0.078196, l5: 0.154866, l6: 0.316567\n",
      "\n",
      "[epoch: 357/400, batch: 688/1000, ite: 47462] train loss: 1.1780, accuracy: 95.6179%, tar: 0.0256 \n",
      "l0: 0.026429, l1: 0.028145, l2: 0.036989, l3: 0.059255, l4: 0.117223, l5: 0.260982, l6: 0.465048\n",
      "\n",
      "[epoch: 357/400, batch: 696/1000, ite: 47463] train loss: 1.1781, accuracy: 93.6343%, tar: 0.0256 \n",
      "l0: 0.023237, l1: 0.024467, l2: 0.032422, l3: 0.049345, l4: 0.086857, l5: 0.191705, l6: 0.393600\n",
      "\n",
      "[epoch: 357/400, batch: 704/1000, ite: 47464] train loss: 1.1782, accuracy: 94.3598%, tar: 0.0256 \n",
      "l0: 0.022074, l1: 0.022978, l2: 0.030069, l3: 0.044277, l4: 0.075322, l5: 0.147952, l6: 0.347352\n",
      "\n",
      "[epoch: 357/400, batch: 712/1000, ite: 47465] train loss: 1.1781, accuracy: 95.1557%, tar: 0.0256 \n",
      "l0: 0.030218, l1: 0.031809, l2: 0.040890, l3: 0.060200, l4: 0.115254, l5: 0.245339, l6: 0.484599\n",
      "\n",
      "[epoch: 357/400, batch: 720/1000, ite: 47466] train loss: 1.1783, accuracy: 92.9006%, tar: 0.0256 \n",
      "l0: 0.020421, l1: 0.022031, l2: 0.030974, l3: 0.046881, l4: 0.082587, l5: 0.179485, l6: 0.400617\n",
      "\n",
      "[epoch: 357/400, batch: 728/1000, ite: 47467] train loss: 1.1783, accuracy: 95.1286%, tar: 0.0256 \n",
      "l0: 0.021040, l1: 0.021932, l2: 0.027515, l3: 0.037977, l4: 0.075117, l5: 0.136617, l6: 0.264806\n",
      "\n",
      "[epoch: 357/400, batch: 736/1000, ite: 47468] train loss: 1.1781, accuracy: 95.6043%, tar: 0.0256 \n",
      "l0: 0.021538, l1: 0.022770, l2: 0.030084, l3: 0.050509, l4: 0.095543, l5: 0.195598, l6: 0.378221\n",
      "\n",
      "[epoch: 357/400, batch: 744/1000, ite: 47469] train loss: 1.1781, accuracy: 94.5914%, tar: 0.0256 \n",
      "l0: 0.026066, l1: 0.027320, l2: 0.035064, l3: 0.052979, l4: 0.086414, l5: 0.148795, l6: 0.358428\n",
      "\n",
      "[epoch: 357/400, batch: 752/1000, ite: 47470] train loss: 1.1780, accuracy: 94.7174%, tar: 0.0256 \n",
      "l0: 0.018535, l1: 0.019488, l2: 0.028375, l3: 0.044180, l4: 0.087344, l5: 0.170671, l6: 0.427151\n",
      "\n",
      "[epoch: 357/400, batch: 760/1000, ite: 47471] train loss: 1.1781, accuracy: 95.0512%, tar: 0.0256 \n",
      "l0: 0.023369, l1: 0.024301, l2: 0.031467, l3: 0.046515, l4: 0.086760, l5: 0.181061, l6: 0.323297\n",
      "\n",
      "[epoch: 357/400, batch: 768/1000, ite: 47472] train loss: 1.1780, accuracy: 94.9206%, tar: 0.0256 \n",
      "l0: 0.021677, l1: 0.022983, l2: 0.032273, l3: 0.047646, l4: 0.090615, l5: 0.216394, l6: 0.430603\n",
      "\n",
      "[epoch: 357/400, batch: 776/1000, ite: 47473] train loss: 1.1780, accuracy: 94.3395%, tar: 0.0256 \n",
      "l0: 0.021962, l1: 0.023032, l2: 0.030159, l3: 0.044697, l4: 0.084542, l5: 0.187905, l6: 0.498218\n",
      "\n",
      "[epoch: 357/400, batch: 784/1000, ite: 47474] train loss: 1.1782, accuracy: 94.0079%, tar: 0.0256 \n",
      "l0: 0.020990, l1: 0.021626, l2: 0.027801, l3: 0.040172, l4: 0.067025, l5: 0.137256, l6: 0.338937\n",
      "\n",
      "[epoch: 357/400, batch: 792/1000, ite: 47475] train loss: 1.1781, accuracy: 94.6201%, tar: 0.0256 \n",
      "l0: 0.029289, l1: 0.030327, l2: 0.037627, l3: 0.052472, l4: 0.083635, l5: 0.164866, l6: 0.414722\n",
      "\n",
      "[epoch: 357/400, batch: 800/1000, ite: 47476] train loss: 1.1781, accuracy: 94.7387%, tar: 0.0256 \n",
      "l0: 0.018568, l1: 0.019972, l2: 0.027050, l3: 0.041480, l4: 0.076103, l5: 0.162984, l6: 0.353911\n",
      "\n",
      "[epoch: 357/400, batch: 808/1000, ite: 47477] train loss: 1.1780, accuracy: 95.3745%, tar: 0.0256 \n",
      "l0: 0.016675, l1: 0.017928, l2: 0.025004, l3: 0.037573, l4: 0.068470, l5: 0.122658, l6: 0.252617\n",
      "\n",
      "[epoch: 357/400, batch: 816/1000, ite: 47478] train loss: 1.1778, accuracy: 96.5387%, tar: 0.0256 \n",
      "l0: 0.032034, l1: 0.032961, l2: 0.041221, l3: 0.059516, l4: 0.110240, l5: 0.239743, l6: 0.478129\n",
      "\n",
      "[epoch: 357/400, batch: 824/1000, ite: 47479] train loss: 1.1780, accuracy: 93.1112%, tar: 0.0256 \n",
      "l0: 0.016989, l1: 0.018130, l2: 0.024685, l3: 0.036013, l4: 0.061865, l5: 0.133759, l6: 0.294349\n",
      "\n",
      "[epoch: 357/400, batch: 832/1000, ite: 47480] train loss: 1.1778, accuracy: 96.1986%, tar: 0.0256 \n",
      "l0: 0.016703, l1: 0.017995, l2: 0.024702, l3: 0.038217, l4: 0.066889, l5: 0.123489, l6: 0.310876\n",
      "\n",
      "[epoch: 357/400, batch: 840/1000, ite: 47481] train loss: 1.1776, accuracy: 96.1790%, tar: 0.0256 \n",
      "l0: 0.015731, l1: 0.016456, l2: 0.021960, l3: 0.033664, l4: 0.060539, l5: 0.120466, l6: 0.308176\n",
      "\n",
      "[epoch: 357/400, batch: 848/1000, ite: 47482] train loss: 1.1774, accuracy: 95.3912%, tar: 0.0256 \n",
      "l0: 0.020669, l1: 0.022169, l2: 0.030359, l3: 0.054517, l4: 0.096966, l5: 0.184751, l6: 0.391782\n",
      "\n",
      "[epoch: 357/400, batch: 856/1000, ite: 47483] train loss: 1.1774, accuracy: 95.4175%, tar: 0.0256 \n",
      "l0: 0.021676, l1: 0.023673, l2: 0.031040, l3: 0.047805, l4: 0.092024, l5: 0.168155, l6: 0.330222\n",
      "\n",
      "[epoch: 357/400, batch: 864/1000, ite: 47484] train loss: 1.1773, accuracy: 96.1757%, tar: 0.0256 \n",
      "l0: 0.023548, l1: 0.024588, l2: 0.034005, l3: 0.051333, l4: 0.092960, l5: 0.202753, l6: 0.446799\n",
      "\n",
      "[epoch: 357/400, batch: 872/1000, ite: 47485] train loss: 1.1774, accuracy: 94.6829%, tar: 0.0256 \n",
      "l0: 0.016479, l1: 0.017728, l2: 0.024577, l3: 0.040380, l4: 0.079622, l5: 0.171944, l6: 0.302491\n",
      "\n",
      "[epoch: 357/400, batch: 880/1000, ite: 47486] train loss: 1.1773, accuracy: 95.6206%, tar: 0.0256 \n",
      "l0: 0.020246, l1: 0.021163, l2: 0.027655, l3: 0.039562, l4: 0.069608, l5: 0.140414, l6: 0.303095\n",
      "\n",
      "[epoch: 357/400, batch: 888/1000, ite: 47487] train loss: 1.1771, accuracy: 96.1056%, tar: 0.0256 \n",
      "l0: 0.028842, l1: 0.029823, l2: 0.037624, l3: 0.051278, l4: 0.079980, l5: 0.147340, l6: 0.321707\n",
      "\n",
      "[epoch: 357/400, batch: 896/1000, ite: 47488] train loss: 1.1770, accuracy: 94.9864%, tar: 0.0256 \n",
      "l0: 0.020803, l1: 0.022792, l2: 0.031269, l3: 0.049195, l4: 0.104018, l5: 0.198166, l6: 0.346206\n",
      "\n",
      "[epoch: 357/400, batch: 904/1000, ite: 47489] train loss: 1.1770, accuracy: 95.3393%, tar: 0.0256 \n",
      "l0: 0.020413, l1: 0.021321, l2: 0.028057, l3: 0.041992, l4: 0.076443, l5: 0.151623, l6: 0.392105\n",
      "\n",
      "[epoch: 357/400, batch: 912/1000, ite: 47490] train loss: 1.1769, accuracy: 94.1583%, tar: 0.0256 \n",
      "l0: 0.022262, l1: 0.023875, l2: 0.032557, l3: 0.050896, l4: 0.104219, l5: 0.209969, l6: 0.374495\n",
      "\n",
      "[epoch: 357/400, batch: 920/1000, ite: 47491] train loss: 1.1769, accuracy: 95.3207%, tar: 0.0256 \n",
      "l0: 0.018086, l1: 0.020392, l2: 0.031171, l3: 0.050741, l4: 0.096953, l5: 0.193072, l6: 0.344471\n",
      "\n",
      "[epoch: 357/400, batch: 928/1000, ite: 47492] train loss: 1.1769, accuracy: 95.9640%, tar: 0.0256 \n",
      "l0: 0.020745, l1: 0.022168, l2: 0.029846, l3: 0.041813, l4: 0.075454, l5: 0.148525, l6: 0.283933\n",
      "\n",
      "[epoch: 357/400, batch: 936/1000, ite: 47493] train loss: 1.1767, accuracy: 95.8188%, tar: 0.0256 \n",
      "l0: 0.031802, l1: 0.032535, l2: 0.041458, l3: 0.056181, l4: 0.097107, l5: 0.189067, l6: 0.409579\n",
      "\n",
      "[epoch: 357/400, batch: 944/1000, ite: 47494] train loss: 1.1768, accuracy: 93.8347%, tar: 0.0256 \n",
      "l0: 0.024025, l1: 0.025005, l2: 0.033764, l3: 0.049549, l4: 0.085472, l5: 0.167703, l6: 0.324730\n",
      "\n",
      "[epoch: 357/400, batch: 952/1000, ite: 47495] train loss: 1.1767, accuracy: 94.8985%, tar: 0.0256 \n",
      "l0: 0.029869, l1: 0.031393, l2: 0.038024, l3: 0.050972, l4: 0.101884, l5: 0.224664, l6: 0.420338\n",
      "\n",
      "[epoch: 357/400, batch: 960/1000, ite: 47496] train loss: 1.1768, accuracy: 94.0033%, tar: 0.0256 \n",
      "l0: 0.028876, l1: 0.029903, l2: 0.037456, l3: 0.055496, l4: 0.104094, l5: 0.213933, l6: 0.429545\n",
      "\n",
      "[epoch: 357/400, batch: 968/1000, ite: 47497] train loss: 1.1769, accuracy: 93.8072%, tar: 0.0256 \n",
      "l0: 0.029193, l1: 0.030889, l2: 0.039740, l3: 0.055529, l4: 0.091155, l5: 0.174342, l6: 0.371036\n",
      "\n",
      "[epoch: 357/400, batch: 976/1000, ite: 47498] train loss: 1.1769, accuracy: 94.4831%, tar: 0.0256 \n",
      "l0: 0.013018, l1: 0.013414, l2: 0.018866, l3: 0.028437, l4: 0.049292, l5: 0.098549, l6: 0.196401\n",
      "\n",
      "[epoch: 357/400, batch: 984/1000, ite: 47499] train loss: 1.1765, accuracy: 96.9128%, tar: 0.0256 \n",
      "l0: 0.024519, l1: 0.026460, l2: 0.033899, l3: 0.051283, l4: 0.097906, l5: 0.212497, l6: 0.379362\n",
      "\n",
      "[epoch: 357/400, batch: 992/1000, ite: 47500] train loss: 1.1765, accuracy: 95.1370%, tar: 0.0256 \n",
      "l0: 0.018916, l1: 0.019933, l2: 0.027461, l3: 0.042419, l4: 0.082058, l5: 0.151352, l6: 0.305897\n",
      "\n",
      "[epoch: 357/400, batch: 1000/1000, ite: 47501] train loss: 1.1764, accuracy: 95.7593%, tar: 0.0255 \n",
      "l0: 0.027686, l1: 0.028919, l2: 0.037801, l3: 0.055619, l4: 0.116088, l5: 0.218119, l6: 0.398997\n",
      "\n",
      "[epoch: 358/400, batch: 8/1000, ite: 47502] train loss: 1.1765, accuracy: 94.6159%, tar: 0.0256 \n",
      "l0: 0.028416, l1: 0.030575, l2: 0.044287, l3: 0.069237, l4: 0.130743, l5: 0.306185, l6: 0.501372\n",
      "\n",
      "[epoch: 358/400, batch: 16/1000, ite: 47503] train loss: 1.1767, accuracy: 93.1532%, tar: 0.0256 \n",
      "l0: 0.020238, l1: 0.021112, l2: 0.027475, l3: 0.041448, l4: 0.081218, l5: 0.184250, l6: 0.399662\n",
      "\n",
      "[epoch: 358/400, batch: 24/1000, ite: 47504] train loss: 1.1767, accuracy: 94.2279%, tar: 0.0255 \n",
      "l0: 0.017297, l1: 0.018128, l2: 0.025070, l3: 0.038894, l4: 0.069958, l5: 0.146395, l6: 0.277666\n",
      "\n",
      "[epoch: 358/400, batch: 32/1000, ite: 47505] train loss: 1.1765, accuracy: 95.9459%, tar: 0.0255 \n",
      "l0: 0.026001, l1: 0.026882, l2: 0.033910, l3: 0.051065, l4: 0.095608, l5: 0.206567, l6: 0.540565\n",
      "\n",
      "[epoch: 358/400, batch: 40/1000, ite: 47506] train loss: 1.1768, accuracy: 92.2485%, tar: 0.0255 \n",
      "l0: 0.023397, l1: 0.025492, l2: 0.034594, l3: 0.052948, l4: 0.108382, l5: 0.241002, l6: 0.447809\n",
      "\n",
      "[epoch: 358/400, batch: 48/1000, ite: 47507] train loss: 1.1769, accuracy: 94.3635%, tar: 0.0255 \n",
      "l0: 0.023711, l1: 0.025700, l2: 0.036524, l3: 0.055354, l4: 0.109377, l5: 0.212485, l6: 0.384872\n",
      "\n",
      "[epoch: 358/400, batch: 56/1000, ite: 47508] train loss: 1.1770, accuracy: 95.4823%, tar: 0.0255 \n",
      "l0: 0.019540, l1: 0.021131, l2: 0.029428, l3: 0.040310, l4: 0.077787, l5: 0.174734, l6: 0.308952\n",
      "\n",
      "[epoch: 358/400, batch: 64/1000, ite: 47509] train loss: 1.1768, accuracy: 95.9664%, tar: 0.0255 \n",
      "l0: 0.022626, l1: 0.024777, l2: 0.033751, l3: 0.052942, l4: 0.096238, l5: 0.188150, l6: 0.416093\n",
      "\n",
      "[epoch: 358/400, batch: 72/1000, ite: 47510] train loss: 1.1769, accuracy: 94.4395%, tar: 0.0255 \n",
      "l0: 0.022177, l1: 0.023525, l2: 0.030314, l3: 0.046526, l4: 0.093115, l5: 0.184947, l6: 0.390802\n",
      "\n",
      "[epoch: 358/400, batch: 80/1000, ite: 47511] train loss: 1.1769, accuracy: 94.1080%, tar: 0.0255 \n",
      "l0: 0.023531, l1: 0.025670, l2: 0.034938, l3: 0.058108, l4: 0.113261, l5: 0.227007, l6: 0.414557\n",
      "\n",
      "[epoch: 358/400, batch: 88/1000, ite: 47512] train loss: 1.1770, accuracy: 94.8393%, tar: 0.0255 \n",
      "l0: 0.018472, l1: 0.019853, l2: 0.031040, l3: 0.051723, l4: 0.093088, l5: 0.193199, l6: 0.393741\n",
      "\n",
      "[epoch: 358/400, batch: 96/1000, ite: 47513] train loss: 1.1770, accuracy: 95.1261%, tar: 0.0255 \n",
      "l0: 0.021457, l1: 0.022524, l2: 0.029572, l3: 0.042887, l4: 0.079505, l5: 0.159263, l6: 0.347619\n",
      "\n",
      "[epoch: 358/400, batch: 104/1000, ite: 47514] train loss: 1.1769, accuracy: 94.7893%, tar: 0.0255 \n",
      "l0: 0.023100, l1: 0.024651, l2: 0.035481, l3: 0.054598, l4: 0.095586, l5: 0.213108, l6: 0.457085\n",
      "\n",
      "[epoch: 358/400, batch: 112/1000, ite: 47515] train loss: 1.1770, accuracy: 94.4432%, tar: 0.0255 \n",
      "l0: 0.024445, l1: 0.025844, l2: 0.035565, l3: 0.051751, l4: 0.089972, l5: 0.191652, l6: 0.381036\n",
      "\n",
      "[epoch: 358/400, batch: 120/1000, ite: 47516] train loss: 1.1770, accuracy: 94.5475%, tar: 0.0255 \n",
      "l0: 0.029213, l1: 0.030775, l2: 0.040212, l3: 0.060972, l4: 0.110383, l5: 0.228874, l6: 0.464079\n",
      "\n",
      "[epoch: 358/400, batch: 128/1000, ite: 47517] train loss: 1.1772, accuracy: 92.6763%, tar: 0.0255 \n",
      "l0: 0.022355, l1: 0.022872, l2: 0.029952, l3: 0.040938, l4: 0.063138, l5: 0.112026, l6: 0.268781\n",
      "\n",
      "[epoch: 358/400, batch: 136/1000, ite: 47518] train loss: 1.1770, accuracy: 95.7344%, tar: 0.0255 \n",
      "l0: 0.015237, l1: 0.016084, l2: 0.021945, l3: 0.033176, l4: 0.065402, l5: 0.118773, l6: 0.268091\n",
      "\n",
      "[epoch: 358/400, batch: 144/1000, ite: 47519] train loss: 1.1768, accuracy: 95.9651%, tar: 0.0255 \n",
      "l0: 0.026041, l1: 0.027476, l2: 0.038196, l3: 0.055429, l4: 0.093522, l5: 0.210402, l6: 0.395065\n",
      "\n",
      "[epoch: 358/400, batch: 152/1000, ite: 47520] train loss: 1.1768, accuracy: 95.0695%, tar: 0.0255 \n",
      "l0: 0.031608, l1: 0.034135, l2: 0.045535, l3: 0.068777, l4: 0.133345, l5: 0.253578, l6: 0.435166\n",
      "\n",
      "[epoch: 358/400, batch: 160/1000, ite: 47521] train loss: 1.1770, accuracy: 93.6292%, tar: 0.0255 \n",
      "l0: 0.025392, l1: 0.026512, l2: 0.033812, l3: 0.048075, l4: 0.088200, l5: 0.198828, l6: 0.460120\n",
      "\n",
      "[epoch: 358/400, batch: 168/1000, ite: 47522] train loss: 1.1771, accuracy: 93.1194%, tar: 0.0255 \n",
      "l0: 0.022263, l1: 0.023482, l2: 0.032553, l3: 0.050901, l4: 0.099975, l5: 0.187496, l6: 0.408578\n",
      "\n",
      "[epoch: 358/400, batch: 176/1000, ite: 47523] train loss: 1.1771, accuracy: 94.5581%, tar: 0.0255 \n",
      "l0: 0.020272, l1: 0.021995, l2: 0.030873, l3: 0.047477, l4: 0.097511, l5: 0.176421, l6: 0.352143\n",
      "\n",
      "[epoch: 358/400, batch: 184/1000, ite: 47524] train loss: 1.1771, accuracy: 95.3413%, tar: 0.0255 \n",
      "l0: 0.031132, l1: 0.033072, l2: 0.042101, l3: 0.058940, l4: 0.115816, l5: 0.238572, l6: 0.429998\n",
      "\n",
      "[epoch: 358/400, batch: 192/1000, ite: 47525] train loss: 1.1772, accuracy: 93.7532%, tar: 0.0255 \n",
      "l0: 0.019567, l1: 0.020415, l2: 0.026626, l3: 0.037124, l4: 0.057491, l5: 0.094100, l6: 0.172382\n",
      "\n",
      "[epoch: 358/400, batch: 200/1000, ite: 47526] train loss: 1.1768, accuracy: 96.9508%, tar: 0.0255 \n",
      "l0: 0.014041, l1: 0.015359, l2: 0.021586, l3: 0.034289, l4: 0.060978, l5: 0.123174, l6: 0.265757\n",
      "\n",
      "[epoch: 358/400, batch: 208/1000, ite: 47527] train loss: 1.1766, accuracy: 96.5518%, tar: 0.0255 \n",
      "l0: 0.023302, l1: 0.024596, l2: 0.034413, l3: 0.049280, l4: 0.101096, l5: 0.203498, l6: 0.454860\n",
      "\n",
      "[epoch: 358/400, batch: 216/1000, ite: 47528] train loss: 1.1767, accuracy: 95.0086%, tar: 0.0255 \n",
      "l0: 0.024405, l1: 0.025841, l2: 0.036915, l3: 0.054067, l4: 0.098167, l5: 0.223828, l6: 0.483169\n",
      "\n",
      "[epoch: 358/400, batch: 224/1000, ite: 47529] train loss: 1.1769, accuracy: 93.4542%, tar: 0.0255 \n",
      "l0: 0.017982, l1: 0.018887, l2: 0.025078, l3: 0.039399, l4: 0.081050, l5: 0.147803, l6: 0.303288\n",
      "\n",
      "[epoch: 358/400, batch: 232/1000, ite: 47530] train loss: 1.1767, accuracy: 95.7626%, tar: 0.0255 \n",
      "l0: 0.027435, l1: 0.030083, l2: 0.038953, l3: 0.059657, l4: 0.101069, l5: 0.209410, l6: 0.370975\n",
      "\n",
      "[epoch: 358/400, batch: 240/1000, ite: 47531] train loss: 1.1767, accuracy: 94.6821%, tar: 0.0255 \n",
      "l0: 0.023885, l1: 0.025925, l2: 0.033002, l3: 0.051813, l4: 0.106824, l5: 0.235567, l6: 0.414906\n",
      "\n",
      "[epoch: 358/400, batch: 248/1000, ite: 47532] train loss: 1.1768, accuracy: 93.8127%, tar: 0.0255 \n",
      "l0: 0.020932, l1: 0.022590, l2: 0.031892, l3: 0.046069, l4: 0.084907, l5: 0.178853, l6: 0.327693\n",
      "\n",
      "[epoch: 358/400, batch: 256/1000, ite: 47533] train loss: 1.1767, accuracy: 96.1987%, tar: 0.0255 \n",
      "l0: 0.016551, l1: 0.017276, l2: 0.022479, l3: 0.032174, l4: 0.056139, l5: 0.115516, l6: 0.313906\n",
      "\n",
      "[epoch: 358/400, batch: 264/1000, ite: 47534] train loss: 1.1766, accuracy: 95.4706%, tar: 0.0255 \n",
      "l0: 0.022855, l1: 0.024172, l2: 0.029987, l3: 0.041422, l4: 0.074003, l5: 0.171639, l6: 0.383964\n",
      "\n",
      "[epoch: 358/400, batch: 272/1000, ite: 47535] train loss: 1.1765, accuracy: 94.8648%, tar: 0.0255 \n",
      "l0: 0.018495, l1: 0.020010, l2: 0.028682, l3: 0.041750, l4: 0.072481, l5: 0.146266, l6: 0.280455\n",
      "\n",
      "[epoch: 358/400, batch: 280/1000, ite: 47536] train loss: 1.1763, accuracy: 95.9699%, tar: 0.0255 \n",
      "l0: 0.023552, l1: 0.024421, l2: 0.030774, l3: 0.042980, l4: 0.078044, l5: 0.150135, l6: 0.356964\n",
      "\n",
      "[epoch: 358/400, batch: 288/1000, ite: 47537] train loss: 1.1763, accuracy: 95.0126%, tar: 0.0255 \n",
      "l0: 0.022023, l1: 0.023511, l2: 0.032046, l3: 0.049675, l4: 0.096537, l5: 0.194392, l6: 0.395650\n",
      "\n",
      "[epoch: 358/400, batch: 296/1000, ite: 47538] train loss: 1.1763, accuracy: 94.9518%, tar: 0.0255 \n",
      "l0: 0.025273, l1: 0.026636, l2: 0.035187, l3: 0.055744, l4: 0.113468, l5: 0.208004, l6: 0.389982\n",
      "\n",
      "[epoch: 358/400, batch: 304/1000, ite: 47539] train loss: 1.1763, accuracy: 94.7752%, tar: 0.0255 \n",
      "l0: 0.024639, l1: 0.026137, l2: 0.034953, l3: 0.052043, l4: 0.083922, l5: 0.147169, l6: 0.327650\n",
      "\n",
      "[epoch: 358/400, batch: 312/1000, ite: 47540] train loss: 1.1762, accuracy: 95.2001%, tar: 0.0255 \n",
      "l0: 0.026251, l1: 0.027393, l2: 0.037535, l3: 0.059276, l4: 0.103625, l5: 0.205826, l6: 0.427833\n",
      "\n",
      "[epoch: 358/400, batch: 320/1000, ite: 47541] train loss: 1.1763, accuracy: 93.7912%, tar: 0.0255 \n",
      "l0: 0.016149, l1: 0.016894, l2: 0.021547, l3: 0.031199, l4: 0.053252, l5: 0.095179, l6: 0.239366\n",
      "\n",
      "[epoch: 358/400, batch: 328/1000, ite: 47542] train loss: 1.1760, accuracy: 96.6831%, tar: 0.0255 \n",
      "l0: 0.025655, l1: 0.027173, l2: 0.034363, l3: 0.050736, l4: 0.083979, l5: 0.167033, l6: 0.374634\n",
      "\n",
      "[epoch: 358/400, batch: 336/1000, ite: 47543] train loss: 1.1760, accuracy: 94.4032%, tar: 0.0255 \n",
      "l0: 0.021769, l1: 0.022730, l2: 0.030947, l3: 0.047402, l4: 0.084923, l5: 0.181168, l6: 0.417431\n",
      "\n",
      "[epoch: 358/400, batch: 344/1000, ite: 47544] train loss: 1.1760, accuracy: 94.2585%, tar: 0.0255 \n",
      "l0: 0.014997, l1: 0.016282, l2: 0.023740, l3: 0.041007, l4: 0.087152, l5: 0.151639, l6: 0.269745\n",
      "\n",
      "[epoch: 358/400, batch: 352/1000, ite: 47545] train loss: 1.1759, accuracy: 96.6848%, tar: 0.0255 \n",
      "l0: 0.016377, l1: 0.017314, l2: 0.024770, l3: 0.037232, l4: 0.079660, l5: 0.153140, l6: 0.280173\n",
      "\n",
      "[epoch: 358/400, batch: 360/1000, ite: 47546] train loss: 1.1757, accuracy: 96.2990%, tar: 0.0255 \n",
      "l0: 0.020897, l1: 0.022020, l2: 0.028077, l3: 0.043216, l4: 0.086364, l5: 0.158933, l6: 0.292634\n",
      "\n",
      "[epoch: 358/400, batch: 368/1000, ite: 47547] train loss: 1.1755, accuracy: 95.7734%, tar: 0.0255 \n",
      "l0: 0.019190, l1: 0.019839, l2: 0.027736, l3: 0.041403, l4: 0.075205, l5: 0.163241, l6: 0.406744\n",
      "\n",
      "[epoch: 358/400, batch: 376/1000, ite: 47548] train loss: 1.1755, accuracy: 94.8039%, tar: 0.0255 \n",
      "l0: 0.017439, l1: 0.018375, l2: 0.024121, l3: 0.035569, l4: 0.053499, l5: 0.092249, l6: 0.280992\n",
      "\n",
      "[epoch: 358/400, batch: 384/1000, ite: 47549] train loss: 1.1753, accuracy: 95.7376%, tar: 0.0254 \n",
      "l0: 0.021572, l1: 0.023091, l2: 0.033137, l3: 0.052444, l4: 0.115439, l5: 0.217894, l6: 0.405071\n",
      "\n",
      "[epoch: 358/400, batch: 392/1000, ite: 47550] train loss: 1.1754, accuracy: 94.8238%, tar: 0.0254 \n",
      "l0: 0.023003, l1: 0.024196, l2: 0.032482, l3: 0.047307, l4: 0.082248, l5: 0.193680, l6: 0.409175\n",
      "\n",
      "[epoch: 358/400, batch: 400/1000, ite: 47551] train loss: 1.1754, accuracy: 94.3073%, tar: 0.0254 \n",
      "l0: 0.024872, l1: 0.027238, l2: 0.038011, l3: 0.061624, l4: 0.125462, l5: 0.250291, l6: 0.494500\n",
      "\n",
      "[epoch: 358/400, batch: 408/1000, ite: 47552] train loss: 1.1756, accuracy: 94.2475%, tar: 0.0254 \n",
      "l0: 0.019765, l1: 0.020827, l2: 0.027922, l3: 0.041084, l4: 0.068365, l5: 0.124085, l6: 0.279589\n",
      "\n",
      "[epoch: 358/400, batch: 416/1000, ite: 47553] train loss: 1.1754, accuracy: 95.7871%, tar: 0.0254 \n",
      "l0: 0.016429, l1: 0.017431, l2: 0.023450, l3: 0.036781, l4: 0.072979, l5: 0.145635, l6: 0.255421\n",
      "\n",
      "[epoch: 358/400, batch: 424/1000, ite: 47554] train loss: 1.1752, accuracy: 95.9036%, tar: 0.0254 \n",
      "l0: 0.021782, l1: 0.023027, l2: 0.030787, l3: 0.047163, l4: 0.090398, l5: 0.153479, l6: 0.335119\n",
      "\n",
      "[epoch: 358/400, batch: 432/1000, ite: 47555] train loss: 1.1751, accuracy: 95.4154%, tar: 0.0254 \n",
      "l0: 0.024225, l1: 0.026176, l2: 0.034726, l3: 0.056287, l4: 0.118301, l5: 0.252468, l6: 0.430207\n",
      "\n",
      "[epoch: 358/400, batch: 440/1000, ite: 47556] train loss: 1.1752, accuracy: 94.3053%, tar: 0.0254 \n",
      "l0: 0.017946, l1: 0.019427, l2: 0.027365, l3: 0.042736, l4: 0.083859, l5: 0.146491, l6: 0.259488\n",
      "\n",
      "[epoch: 358/400, batch: 448/1000, ite: 47557] train loss: 1.1750, accuracy: 95.9941%, tar: 0.0254 \n",
      "l0: 0.019533, l1: 0.021842, l2: 0.031089, l3: 0.048991, l4: 0.088492, l5: 0.192412, l6: 0.367331\n",
      "\n",
      "[epoch: 358/400, batch: 456/1000, ite: 47558] train loss: 1.1750, accuracy: 95.4007%, tar: 0.0254 \n",
      "l0: 0.021553, l1: 0.023089, l2: 0.032639, l3: 0.049824, l4: 0.092777, l5: 0.196322, l6: 0.416442\n",
      "\n",
      "[epoch: 358/400, batch: 464/1000, ite: 47559] train loss: 1.1751, accuracy: 94.3624%, tar: 0.0254 \n",
      "l0: 0.020915, l1: 0.022338, l2: 0.032084, l3: 0.048573, l4: 0.081927, l5: 0.155191, l6: 0.404308\n",
      "\n",
      "[epoch: 358/400, batch: 472/1000, ite: 47560] train loss: 1.1751, accuracy: 95.1568%, tar: 0.0254 \n",
      "l0: 0.022140, l1: 0.023482, l2: 0.031787, l3: 0.044924, l4: 0.077883, l5: 0.152463, l6: 0.338542\n",
      "\n",
      "[epoch: 358/400, batch: 480/1000, ite: 47561] train loss: 1.1750, accuracy: 95.4736%, tar: 0.0254 \n",
      "l0: 0.025761, l1: 0.026838, l2: 0.033224, l3: 0.046563, l4: 0.102680, l5: 0.199266, l6: 0.382760\n",
      "\n",
      "[epoch: 358/400, batch: 488/1000, ite: 47562] train loss: 1.1750, accuracy: 94.6349%, tar: 0.0254 \n",
      "l0: 0.021477, l1: 0.022688, l2: 0.029879, l3: 0.047668, l4: 0.092393, l5: 0.236670, l6: 0.537791\n",
      "\n",
      "[epoch: 358/400, batch: 496/1000, ite: 47563] train loss: 1.1752, accuracy: 93.5133%, tar: 0.0254 \n",
      "l0: 0.024204, l1: 0.025562, l2: 0.035711, l3: 0.057046, l4: 0.106221, l5: 0.198322, l6: 0.403952\n",
      "\n",
      "[epoch: 358/400, batch: 504/1000, ite: 47564] train loss: 1.1753, accuracy: 94.6925%, tar: 0.0254 \n",
      "l0: 0.019241, l1: 0.020804, l2: 0.029101, l3: 0.047685, l4: 0.090015, l5: 0.201578, l6: 0.385225\n",
      "\n",
      "[epoch: 358/400, batch: 512/1000, ite: 47565] train loss: 1.1753, accuracy: 95.2689%, tar: 0.0254 \n",
      "l0: 0.022184, l1: 0.023457, l2: 0.030399, l3: 0.046523, l4: 0.092745, l5: 0.196410, l6: 0.360517\n",
      "\n",
      "[epoch: 358/400, batch: 520/1000, ite: 47566] train loss: 1.1753, accuracy: 94.7153%, tar: 0.0254 \n",
      "l0: 0.017052, l1: 0.018580, l2: 0.025532, l3: 0.035935, l4: 0.064922, l5: 0.128766, l6: 0.255071\n",
      "\n",
      "[epoch: 358/400, batch: 528/1000, ite: 47567] train loss: 1.1750, accuracy: 96.2664%, tar: 0.0254 \n",
      "l0: 0.019968, l1: 0.020779, l2: 0.027651, l3: 0.043053, l4: 0.084306, l5: 0.177566, l6: 0.325980\n",
      "\n",
      "[epoch: 358/400, batch: 536/1000, ite: 47568] train loss: 1.1749, accuracy: 95.4415%, tar: 0.0254 \n",
      "l0: 0.022846, l1: 0.024396, l2: 0.032340, l3: 0.051355, l4: 0.097366, l5: 0.209101, l6: 0.405452\n",
      "\n",
      "[epoch: 358/400, batch: 544/1000, ite: 47569] train loss: 1.1750, accuracy: 94.3307%, tar: 0.0254 \n",
      "l0: 0.015434, l1: 0.016751, l2: 0.023423, l3: 0.035317, l4: 0.061635, l5: 0.121036, l6: 0.268666\n",
      "\n",
      "[epoch: 358/400, batch: 552/1000, ite: 47570] train loss: 1.1747, accuracy: 96.1713%, tar: 0.0254 \n",
      "l0: 0.019956, l1: 0.021390, l2: 0.026278, l3: 0.038246, l4: 0.080468, l5: 0.138908, l6: 0.247324\n",
      "\n",
      "[epoch: 358/400, batch: 560/1000, ite: 47571] train loss: 1.1745, accuracy: 96.3538%, tar: 0.0254 \n",
      "l0: 0.024724, l1: 0.025750, l2: 0.032623, l3: 0.047582, l4: 0.094601, l5: 0.186800, l6: 0.345023\n",
      "\n",
      "[epoch: 358/400, batch: 568/1000, ite: 47572] train loss: 1.1745, accuracy: 95.0591%, tar: 0.0254 \n",
      "l0: 0.020016, l1: 0.022287, l2: 0.028948, l3: 0.042350, l4: 0.080044, l5: 0.170692, l6: 0.331152\n",
      "\n",
      "[epoch: 358/400, batch: 576/1000, ite: 47573] train loss: 1.1744, accuracy: 95.5350%, tar: 0.0254 \n",
      "l0: 0.017578, l1: 0.019118, l2: 0.026374, l3: 0.039638, l4: 0.073174, l5: 0.155569, l6: 0.304569\n",
      "\n",
      "[epoch: 358/400, batch: 584/1000, ite: 47574] train loss: 1.1742, accuracy: 96.0464%, tar: 0.0254 \n",
      "l0: 0.021075, l1: 0.022088, l2: 0.029176, l3: 0.041056, l4: 0.071201, l5: 0.128358, l6: 0.303277\n",
      "\n",
      "[epoch: 358/400, batch: 592/1000, ite: 47575] train loss: 1.1741, accuracy: 95.7216%, tar: 0.0254 \n",
      "l0: 0.016841, l1: 0.018490, l2: 0.025919, l3: 0.039317, l4: 0.079838, l5: 0.150617, l6: 0.309778\n",
      "\n",
      "[epoch: 358/400, batch: 600/1000, ite: 47576] train loss: 1.1739, accuracy: 96.0879%, tar: 0.0254 \n",
      "l0: 0.019752, l1: 0.020953, l2: 0.029345, l3: 0.046364, l4: 0.096325, l5: 0.177736, l6: 0.329329\n",
      "\n",
      "[epoch: 358/400, batch: 608/1000, ite: 47577] train loss: 1.1739, accuracy: 96.0635%, tar: 0.0254 \n",
      "l0: 0.021174, l1: 0.022021, l2: 0.029482, l3: 0.042277, l4: 0.073525, l5: 0.142454, l6: 0.309811\n",
      "\n",
      "[epoch: 358/400, batch: 616/1000, ite: 47578] train loss: 1.1737, accuracy: 95.6365%, tar: 0.0254 \n",
      "l0: 0.023956, l1: 0.025773, l2: 0.035330, l3: 0.051136, l4: 0.093893, l5: 0.214311, l6: 0.445281\n",
      "\n",
      "[epoch: 358/400, batch: 624/1000, ite: 47579] train loss: 1.1738, accuracy: 93.9460%, tar: 0.0254 \n",
      "l0: 0.021686, l1: 0.023475, l2: 0.032334, l3: 0.048590, l4: 0.092597, l5: 0.198944, l6: 0.419271\n",
      "\n",
      "[epoch: 358/400, batch: 632/1000, ite: 47580] train loss: 1.1739, accuracy: 95.1491%, tar: 0.0254 \n",
      "l0: 0.018576, l1: 0.019654, l2: 0.025951, l3: 0.038333, l4: 0.073191, l5: 0.159947, l6: 0.335988\n",
      "\n",
      "[epoch: 358/400, batch: 640/1000, ite: 47581] train loss: 1.1738, accuracy: 95.3658%, tar: 0.0254 \n",
      "l0: 0.021278, l1: 0.022590, l2: 0.030811, l3: 0.048003, l4: 0.109904, l5: 0.221528, l6: 0.417635\n",
      "\n",
      "[epoch: 358/400, batch: 648/1000, ite: 47582] train loss: 1.1739, accuracy: 94.6566%, tar: 0.0254 \n",
      "l0: 0.026302, l1: 0.028080, l2: 0.035626, l3: 0.051977, l4: 0.098088, l5: 0.185913, l6: 0.449374\n",
      "\n",
      "[epoch: 358/400, batch: 656/1000, ite: 47583] train loss: 1.1740, accuracy: 93.7972%, tar: 0.0254 \n",
      "l0: 0.034049, l1: 0.035830, l2: 0.045232, l3: 0.063749, l4: 0.106155, l5: 0.206922, l6: 0.386034\n",
      "\n",
      "[epoch: 358/400, batch: 664/1000, ite: 47584] train loss: 1.1740, accuracy: 94.1839%, tar: 0.0254 \n",
      "l0: 0.022643, l1: 0.023884, l2: 0.033725, l3: 0.054043, l4: 0.097786, l5: 0.212318, l6: 0.369229\n",
      "\n",
      "[epoch: 358/400, batch: 672/1000, ite: 47585] train loss: 1.1740, accuracy: 94.7254%, tar: 0.0254 \n",
      "l0: 0.022002, l1: 0.022927, l2: 0.030100, l3: 0.044725, l4: 0.082349, l5: 0.155091, l6: 0.323370\n",
      "\n",
      "[epoch: 358/400, batch: 680/1000, ite: 47586] train loss: 1.1739, accuracy: 95.2747%, tar: 0.0254 \n",
      "l0: 0.015347, l1: 0.016417, l2: 0.022501, l3: 0.035366, l4: 0.061149, l5: 0.117571, l6: 0.271930\n",
      "\n",
      "[epoch: 358/400, batch: 688/1000, ite: 47587] train loss: 1.1737, accuracy: 96.1464%, tar: 0.0253 \n",
      "l0: 0.019684, l1: 0.020623, l2: 0.027439, l3: 0.037212, l4: 0.064896, l5: 0.134528, l6: 0.280486\n",
      "\n",
      "[epoch: 358/400, batch: 696/1000, ite: 47588] train loss: 1.1735, accuracy: 95.8738%, tar: 0.0253 \n",
      "l0: 0.021667, l1: 0.022554, l2: 0.029145, l3: 0.040772, l4: 0.074307, l5: 0.160756, l6: 0.360793\n",
      "\n",
      "[epoch: 358/400, batch: 704/1000, ite: 47589] train loss: 1.1734, accuracy: 95.3520%, tar: 0.0253 \n",
      "l0: 0.027919, l1: 0.029030, l2: 0.036919, l3: 0.052459, l4: 0.095723, l5: 0.184593, l6: 0.406024\n",
      "\n",
      "[epoch: 358/400, batch: 712/1000, ite: 47590] train loss: 1.1735, accuracy: 94.0519%, tar: 0.0253 \n",
      "l0: 0.017061, l1: 0.018282, l2: 0.024365, l3: 0.038746, l4: 0.074659, l5: 0.157989, l6: 0.302412\n",
      "\n",
      "[epoch: 358/400, batch: 720/1000, ite: 47591] train loss: 1.1733, accuracy: 95.3939%, tar: 0.0253 \n",
      "l0: 0.018845, l1: 0.019564, l2: 0.024542, l3: 0.035410, l4: 0.078234, l5: 0.141087, l6: 0.294819\n",
      "\n",
      "[epoch: 358/400, batch: 728/1000, ite: 47592] train loss: 1.1732, accuracy: 96.0386%, tar: 0.0253 \n",
      "l0: 0.024183, l1: 0.024828, l2: 0.033640, l3: 0.046937, l4: 0.078046, l5: 0.156970, l6: 0.317488\n",
      "\n",
      "[epoch: 358/400, batch: 736/1000, ite: 47593] train loss: 1.1731, accuracy: 94.7780%, tar: 0.0253 \n",
      "l0: 0.027176, l1: 0.028330, l2: 0.037040, l3: 0.054468, l4: 0.094837, l5: 0.189040, l6: 0.417184\n",
      "\n",
      "[epoch: 358/400, batch: 744/1000, ite: 47594] train loss: 1.1731, accuracy: 93.5615%, tar: 0.0253 \n",
      "l0: 0.021533, l1: 0.022776, l2: 0.031515, l3: 0.046408, l4: 0.080538, l5: 0.166632, l6: 0.366812\n",
      "\n",
      "[epoch: 358/400, batch: 752/1000, ite: 47595] train loss: 1.1731, accuracy: 95.0717%, tar: 0.0253 \n",
      "l0: 0.019633, l1: 0.021224, l2: 0.031233, l3: 0.053606, l4: 0.105325, l5: 0.210997, l6: 0.377602\n",
      "\n",
      "[epoch: 358/400, batch: 760/1000, ite: 47596] train loss: 1.1731, accuracy: 95.1162%, tar: 0.0253 \n",
      "l0: 0.022359, l1: 0.023822, l2: 0.032781, l3: 0.047586, l4: 0.088984, l5: 0.215433, l6: 0.411989\n",
      "\n",
      "[epoch: 358/400, batch: 768/1000, ite: 47597] train loss: 1.1732, accuracy: 94.5022%, tar: 0.0253 \n",
      "l0: 0.024372, l1: 0.026446, l2: 0.034773, l3: 0.053574, l4: 0.098401, l5: 0.227263, l6: 0.488900\n",
      "\n",
      "[epoch: 358/400, batch: 776/1000, ite: 47598] train loss: 1.1733, accuracy: 93.6899%, tar: 0.0253 \n",
      "l0: 0.019163, l1: 0.020405, l2: 0.027618, l3: 0.042814, l4: 0.069105, l5: 0.139794, l6: 0.264171\n",
      "\n",
      "[epoch: 358/400, batch: 784/1000, ite: 47599] train loss: 1.1731, accuracy: 96.0352%, tar: 0.0253 \n",
      "l0: 0.023386, l1: 0.024693, l2: 0.032282, l3: 0.049746, l4: 0.101398, l5: 0.208501, l6: 0.417970\n",
      "\n",
      "[epoch: 358/400, batch: 792/1000, ite: 47600] train loss: 1.1732, accuracy: 94.4085%, tar: 0.0253 \n",
      "l0: 0.027650, l1: 0.028889, l2: 0.037265, l3: 0.056802, l4: 0.103051, l5: 0.215189, l6: 0.395827\n",
      "\n",
      "[epoch: 358/400, batch: 800/1000, ite: 47601] train loss: 1.1732, accuracy: 94.4273%, tar: 0.0253 \n",
      "l0: 0.017586, l1: 0.018531, l2: 0.027167, l3: 0.037588, l4: 0.067410, l5: 0.128742, l6: 0.246805\n",
      "\n",
      "[epoch: 358/400, batch: 808/1000, ite: 47602] train loss: 1.1730, accuracy: 96.1657%, tar: 0.0253 \n",
      "l0: 0.018083, l1: 0.019505, l2: 0.025508, l3: 0.041835, l4: 0.083142, l5: 0.193564, l6: 0.373577\n",
      "\n",
      "[epoch: 358/400, batch: 816/1000, ite: 47603] train loss: 1.1730, accuracy: 95.2648%, tar: 0.0253 \n",
      "l0: 0.021742, l1: 0.023110, l2: 0.034284, l3: 0.058890, l4: 0.123139, l5: 0.205080, l6: 0.388420\n",
      "\n",
      "[epoch: 358/400, batch: 824/1000, ite: 47604] train loss: 1.1730, accuracy: 95.0219%, tar: 0.0253 \n",
      "l0: 0.019316, l1: 0.020266, l2: 0.026597, l3: 0.039562, l4: 0.070086, l5: 0.129545, l6: 0.256735\n",
      "\n",
      "[epoch: 358/400, batch: 832/1000, ite: 47605] train loss: 1.1728, accuracy: 96.4773%, tar: 0.0253 \n",
      "l0: 0.022532, l1: 0.025136, l2: 0.035184, l3: 0.061453, l4: 0.120749, l5: 0.220721, l6: 0.392171\n",
      "\n",
      "[epoch: 358/400, batch: 840/1000, ite: 47606] train loss: 1.1729, accuracy: 95.5414%, tar: 0.0253 \n",
      "l0: 0.024068, l1: 0.025383, l2: 0.033646, l3: 0.058313, l4: 0.116732, l5: 0.256176, l6: 0.469793\n",
      "\n",
      "[epoch: 358/400, batch: 848/1000, ite: 47607] train loss: 1.1731, accuracy: 93.2504%, tar: 0.0253 \n",
      "l0: 0.019334, l1: 0.020925, l2: 0.027895, l3: 0.038035, l4: 0.064795, l5: 0.150282, l6: 0.274445\n",
      "\n",
      "[epoch: 358/400, batch: 856/1000, ite: 47608] train loss: 1.1729, accuracy: 96.4597%, tar: 0.0253 \n",
      "l0: 0.017925, l1: 0.018723, l2: 0.025434, l3: 0.036572, l4: 0.064248, l5: 0.123375, l6: 0.256847\n",
      "\n",
      "[epoch: 358/400, batch: 864/1000, ite: 47609] train loss: 1.1726, accuracy: 96.1153%, tar: 0.0253 \n",
      "l0: 0.018742, l1: 0.019917, l2: 0.027216, l3: 0.041809, l4: 0.081064, l5: 0.188240, l6: 0.319149\n",
      "\n",
      "[epoch: 358/400, batch: 872/1000, ite: 47610] train loss: 1.1726, accuracy: 94.7612%, tar: 0.0253 \n",
      "l0: 0.019901, l1: 0.020599, l2: 0.025869, l3: 0.034867, l4: 0.059968, l5: 0.117402, l6: 0.241486\n",
      "\n",
      "[epoch: 358/400, batch: 880/1000, ite: 47611] train loss: 1.1723, accuracy: 96.1902%, tar: 0.0253 \n",
      "l0: 0.020852, l1: 0.021836, l2: 0.027109, l3: 0.038492, l4: 0.076171, l5: 0.171396, l6: 0.326401\n",
      "\n",
      "[epoch: 358/400, batch: 888/1000, ite: 47612] train loss: 1.1722, accuracy: 95.5163%, tar: 0.0253 \n",
      "l0: 0.021170, l1: 0.022109, l2: 0.028659, l3: 0.039560, l4: 0.074325, l5: 0.174106, l6: 0.356605\n",
      "\n",
      "[epoch: 358/400, batch: 896/1000, ite: 47613] train loss: 1.1721, accuracy: 94.5745%, tar: 0.0253 \n",
      "l0: 0.017824, l1: 0.019405, l2: 0.028562, l3: 0.045315, l4: 0.096709, l5: 0.215392, l6: 0.409239\n",
      "\n",
      "[epoch: 358/400, batch: 904/1000, ite: 47614] train loss: 1.1722, accuracy: 95.3257%, tar: 0.0253 \n",
      "l0: 0.017957, l1: 0.018911, l2: 0.024135, l3: 0.034617, l4: 0.061972, l5: 0.121984, l6: 0.265864\n",
      "\n",
      "[epoch: 358/400, batch: 912/1000, ite: 47615] train loss: 1.1720, accuracy: 95.8288%, tar: 0.0253 \n",
      "l0: 0.029830, l1: 0.031496, l2: 0.040204, l3: 0.069897, l4: 0.123623, l5: 0.217810, l6: 0.497597\n",
      "\n",
      "[epoch: 358/400, batch: 920/1000, ite: 47616] train loss: 1.1722, accuracy: 93.3377%, tar: 0.0253 \n",
      "l0: 0.021738, l1: 0.022972, l2: 0.031330, l3: 0.047199, l4: 0.092088, l5: 0.199815, l6: 0.487721\n",
      "\n",
      "[epoch: 358/400, batch: 928/1000, ite: 47617] train loss: 1.1723, accuracy: 93.9609%, tar: 0.0253 \n",
      "l0: 0.024817, l1: 0.049867, l2: 0.055192, l3: 0.065074, l4: 0.109648, l5: 0.281306, l6: 0.459830\n",
      "\n",
      "[epoch: 358/400, batch: 936/1000, ite: 47618] train loss: 1.1725, accuracy: 94.5591%, tar: 0.0253 \n",
      "l0: 0.025091, l1: 0.026300, l2: 0.034281, l3: 0.049097, l4: 0.082299, l5: 0.177394, l6: 0.319133\n",
      "\n",
      "[epoch: 358/400, batch: 944/1000, ite: 47619] train loss: 1.1724, accuracy: 95.0178%, tar: 0.0253 \n",
      "l0: 0.017725, l1: 0.018257, l2: 0.024899, l3: 0.038155, l4: 0.070743, l5: 0.135769, l6: 0.245464\n",
      "\n",
      "[epoch: 358/400, batch: 952/1000, ite: 47620] train loss: 1.1722, accuracy: 96.2735%, tar: 0.0253 \n",
      "l0: 0.024034, l1: 0.025498, l2: 0.032485, l3: 0.045504, l4: 0.084489, l5: 0.169330, l6: 0.372758\n",
      "\n",
      "[epoch: 358/400, batch: 960/1000, ite: 47621] train loss: 1.1722, accuracy: 94.9434%, tar: 0.0253 \n",
      "l0: 0.029042, l1: 0.030196, l2: 0.041357, l3: 0.057397, l4: 0.098912, l5: 0.195826, l6: 0.435069\n",
      "\n",
      "[epoch: 358/400, batch: 968/1000, ite: 47622] train loss: 1.1723, accuracy: 93.6863%, tar: 0.0253 \n",
      "l0: 0.026259, l1: 0.027923, l2: 0.037425, l3: 0.059897, l4: 0.119493, l5: 0.232046, l6: 0.480940\n",
      "\n",
      "[epoch: 358/400, batch: 976/1000, ite: 47623] train loss: 1.1724, accuracy: 93.2715%, tar: 0.0253 \n",
      "l0: 0.031688, l1: 0.033177, l2: 0.043408, l3: 0.061802, l4: 0.100764, l5: 0.174521, l6: 0.346123\n",
      "\n",
      "[epoch: 358/400, batch: 984/1000, ite: 47624] train loss: 1.1724, accuracy: 94.2995%, tar: 0.0253 \n",
      "l0: 0.023236, l1: 0.024730, l2: 0.033217, l3: 0.053654, l4: 0.138472, l5: 0.224103, l6: 0.423542\n",
      "\n",
      "[epoch: 358/400, batch: 992/1000, ite: 47625] train loss: 1.1725, accuracy: 94.9571%, tar: 0.0253 \n",
      "l0: 0.025495, l1: 0.026900, l2: 0.034652, l3: 0.051531, l4: 0.092810, l5: 0.175971, l6: 0.324266\n",
      "\n",
      "[epoch: 358/400, batch: 1000/1000, ite: 47626] train loss: 1.1725, accuracy: 95.0474%, tar: 0.0253 \n",
      "l0: 0.037802, l1: 0.044327, l2: 0.052531, l3: 0.068502, l4: 0.101260, l5: 0.177419, l6: 0.374527\n",
      "\n",
      "[epoch: 359/400, batch: 8/1000, ite: 47627] train loss: 1.1725, accuracy: 94.2683%, tar: 0.0253 \n",
      "l0: 0.024401, l1: 0.026202, l2: 0.035898, l3: 0.056080, l4: 0.096813, l5: 0.192945, l6: 0.378440\n",
      "\n",
      "[epoch: 359/400, batch: 16/1000, ite: 47628] train loss: 1.1725, accuracy: 95.7032%, tar: 0.0253 \n",
      "l0: 0.024987, l1: 0.027306, l2: 0.037796, l3: 0.059304, l4: 0.127074, l5: 0.282804, l6: 0.520244\n",
      "\n",
      "[epoch: 359/400, batch: 24/1000, ite: 47629] train loss: 1.1728, accuracy: 94.2435%, tar: 0.0253 \n",
      "l0: 0.022772, l1: 0.023890, l2: 0.030653, l3: 0.040485, l4: 0.065724, l5: 0.112742, l6: 0.300936\n",
      "\n",
      "[epoch: 359/400, batch: 32/1000, ite: 47630] train loss: 1.1726, accuracy: 95.7479%, tar: 0.0253 \n",
      "l0: 0.020570, l1: 0.021782, l2: 0.025840, l3: 0.037801, l4: 0.064157, l5: 0.129763, l6: 0.274932\n",
      "\n",
      "[epoch: 359/400, batch: 40/1000, ite: 47631] train loss: 1.1724, accuracy: 95.6557%, tar: 0.0253 \n",
      "l0: 0.028207, l1: 0.030855, l2: 0.041288, l3: 0.058591, l4: 0.101094, l5: 0.258488, l6: 0.526988\n",
      "\n",
      "[epoch: 359/400, batch: 48/1000, ite: 47632] train loss: 1.1727, accuracy: 93.7503%, tar: 0.0253 \n",
      "l0: 0.021360, l1: 0.027756, l2: 0.037449, l3: 0.055943, l4: 0.083261, l5: 0.158917, l6: 0.274071\n",
      "\n",
      "[epoch: 359/400, batch: 56/1000, ite: 47633] train loss: 1.1725, accuracy: 95.6896%, tar: 0.0253 \n",
      "l0: 0.035968, l1: 0.037815, l2: 0.045859, l3: 0.061491, l4: 0.103325, l5: 0.185589, l6: 0.365524\n",
      "\n",
      "[epoch: 359/400, batch: 64/1000, ite: 47634] train loss: 1.1725, accuracy: 93.9788%, tar: 0.0253 \n",
      "l0: 0.023206, l1: 0.024590, l2: 0.033041, l3: 0.051645, l4: 0.099236, l5: 0.176066, l6: 0.372847\n",
      "\n",
      "[epoch: 359/400, batch: 72/1000, ite: 47635] train loss: 1.1725, accuracy: 95.0469%, tar: 0.0253 \n",
      "l0: 0.024118, l1: 0.024615, l2: 0.030686, l3: 0.042195, l4: 0.066576, l5: 0.115319, l6: 0.232988\n",
      "\n",
      "[epoch: 359/400, batch: 80/1000, ite: 47636] train loss: 1.1723, accuracy: 96.3593%, tar: 0.0253 \n",
      "l0: 0.025416, l1: 0.026352, l2: 0.032717, l3: 0.046797, l4: 0.086013, l5: 0.171355, l6: 0.349895\n",
      "\n",
      "[epoch: 359/400, batch: 88/1000, ite: 47637] train loss: 1.1722, accuracy: 94.6474%, tar: 0.0253 \n",
      "l0: 0.023528, l1: 0.025263, l2: 0.033848, l3: 0.056560, l4: 0.107514, l5: 0.189847, l6: 0.333537\n",
      "\n",
      "[epoch: 359/400, batch: 96/1000, ite: 47638] train loss: 1.1722, accuracy: 95.9303%, tar: 0.0253 \n",
      "l0: 0.022047, l1: 0.022899, l2: 0.027955, l3: 0.039142, l4: 0.064573, l5: 0.131150, l6: 0.260209\n",
      "\n",
      "[epoch: 359/400, batch: 104/1000, ite: 47639] train loss: 1.1720, accuracy: 95.8288%, tar: 0.0253 \n",
      "l0: 0.022018, l1: 0.023929, l2: 0.032499, l3: 0.049819, l4: 0.083286, l5: 0.148128, l6: 0.342035\n",
      "\n",
      "[epoch: 359/400, batch: 112/1000, ite: 47640] train loss: 1.1719, accuracy: 95.0509%, tar: 0.0253 \n",
      "l0: 0.021554, l1: 0.023130, l2: 0.034380, l3: 0.054719, l4: 0.103500, l5: 0.192368, l6: 0.425196\n",
      "\n",
      "[epoch: 359/400, batch: 120/1000, ite: 47641] train loss: 1.1720, accuracy: 95.0297%, tar: 0.0253 \n",
      "l0: 0.023874, l1: 0.024995, l2: 0.033093, l3: 0.053281, l4: 0.114206, l5: 0.201855, l6: 0.397110\n",
      "\n",
      "[epoch: 359/400, batch: 128/1000, ite: 47642] train loss: 1.1720, accuracy: 94.3485%, tar: 0.0253 \n",
      "l0: 0.023918, l1: 0.025093, l2: 0.033995, l3: 0.050372, l4: 0.094572, l5: 0.189147, l6: 0.347968\n",
      "\n",
      "[epoch: 359/400, batch: 136/1000, ite: 47643] train loss: 1.1720, accuracy: 95.3372%, tar: 0.0253 \n",
      "l0: 0.033482, l1: 0.035922, l2: 0.045446, l3: 0.067377, l4: 0.119835, l5: 0.251575, l6: 0.531141\n",
      "\n",
      "[epoch: 359/400, batch: 144/1000, ite: 47644] train loss: 1.1723, accuracy: 93.2179%, tar: 0.0253 \n",
      "l0: 0.031477, l1: 0.032711, l2: 0.040401, l3: 0.057661, l4: 0.096738, l5: 0.209346, l6: 0.438094\n",
      "\n",
      "[epoch: 359/400, batch: 152/1000, ite: 47645] train loss: 1.1724, accuracy: 93.3345%, tar: 0.0253 \n",
      "l0: 0.035601, l1: 0.036936, l2: 0.047038, l3: 0.071665, l4: 0.132491, l5: 0.261978, l6: 0.542085\n",
      "\n",
      "[epoch: 359/400, batch: 160/1000, ite: 47646] train loss: 1.1727, accuracy: 92.2026%, tar: 0.0253 \n",
      "l0: 0.026927, l1: 0.029807, l2: 0.040116, l3: 0.064822, l4: 0.116815, l5: 0.200642, l6: 0.415086\n",
      "\n",
      "[epoch: 359/400, batch: 168/1000, ite: 47647] train loss: 1.1728, accuracy: 94.8905%, tar: 0.0253 \n",
      "l0: 0.034994, l1: 0.036920, l2: 0.050146, l3: 0.081278, l4: 0.167099, l5: 0.294691, l6: 0.511659\n",
      "\n",
      "[epoch: 359/400, batch: 176/1000, ite: 47648] train loss: 1.1731, accuracy: 92.3000%, tar: 0.0253 \n",
      "l0: 0.032301, l1: 0.033399, l2: 0.041917, l3: 0.059481, l4: 0.125800, l5: 0.251399, l6: 0.459284\n",
      "\n",
      "[epoch: 359/400, batch: 184/1000, ite: 47649] train loss: 1.1733, accuracy: 93.1160%, tar: 0.0253 \n",
      "l0: 0.035350, l1: 0.038445, l2: 0.050666, l3: 0.073692, l4: 0.123855, l5: 0.211830, l6: 0.373415\n",
      "\n",
      "[epoch: 359/400, batch: 192/1000, ite: 47650] train loss: 1.1733, accuracy: 94.4348%, tar: 0.0253 \n",
      "l0: 0.025693, l1: 0.027103, l2: 0.036093, l3: 0.055903, l4: 0.103916, l5: 0.207656, l6: 0.370244\n",
      "\n",
      "[epoch: 359/400, batch: 200/1000, ite: 47651] train loss: 1.1733, accuracy: 94.7743%, tar: 0.0253 \n",
      "l0: 0.025073, l1: 0.027237, l2: 0.036092, l3: 0.052373, l4: 0.088700, l5: 0.156515, l6: 0.350551\n",
      "\n",
      "[epoch: 359/400, batch: 208/1000, ite: 47652] train loss: 1.1733, accuracy: 95.5909%, tar: 0.0253 \n",
      "l0: 0.023678, l1: 0.024564, l2: 0.031054, l3: 0.045893, l4: 0.082685, l5: 0.179756, l6: 0.403250\n",
      "\n",
      "[epoch: 359/400, batch: 216/1000, ite: 47653] train loss: 1.1733, accuracy: 94.5995%, tar: 0.0253 \n",
      "l0: 0.025767, l1: 0.026955, l2: 0.034335, l3: 0.051403, l4: 0.095855, l5: 0.189653, l6: 0.368101\n",
      "\n",
      "[epoch: 359/400, batch: 224/1000, ite: 47654] train loss: 1.1733, accuracy: 94.0667%, tar: 0.0253 \n",
      "l0: 0.034363, l1: 0.036471, l2: 0.046539, l3: 0.069813, l4: 0.135313, l5: 0.245579, l6: 0.441894\n",
      "\n",
      "[epoch: 359/400, batch: 232/1000, ite: 47655] train loss: 1.1735, accuracy: 94.4021%, tar: 0.0253 \n",
      "l0: 0.024180, l1: 0.025993, l2: 0.033303, l3: 0.049172, l4: 0.090122, l5: 0.204951, l6: 0.420873\n",
      "\n",
      "[epoch: 359/400, batch: 240/1000, ite: 47656] train loss: 1.1735, accuracy: 94.6621%, tar: 0.0253 \n",
      "l0: 0.028898, l1: 0.029850, l2: 0.038104, l3: 0.056720, l4: 0.099270, l5: 0.200670, l6: 0.384121\n",
      "\n",
      "[epoch: 359/400, batch: 248/1000, ite: 47657] train loss: 1.1736, accuracy: 94.1305%, tar: 0.0253 \n",
      "l0: 0.023009, l1: 0.024185, l2: 0.030297, l3: 0.041823, l4: 0.072989, l5: 0.156531, l6: 0.325913\n",
      "\n",
      "[epoch: 359/400, batch: 256/1000, ite: 47658] train loss: 1.1735, accuracy: 95.1566%, tar: 0.0253 \n",
      "l0: 0.025941, l1: 0.026999, l2: 0.034433, l3: 0.049063, l4: 0.085059, l5: 0.169021, l6: 0.339882\n",
      "\n",
      "[epoch: 359/400, batch: 264/1000, ite: 47659] train loss: 1.1734, accuracy: 94.5447%, tar: 0.0253 \n",
      "l0: 0.024714, l1: 0.025508, l2: 0.034665, l3: 0.049484, l4: 0.081720, l5: 0.152013, l6: 0.329636\n",
      "\n",
      "[epoch: 359/400, batch: 272/1000, ite: 47660] train loss: 1.1733, accuracy: 94.8563%, tar: 0.0253 \n",
      "l0: 0.030672, l1: 0.031328, l2: 0.041981, l3: 0.063207, l4: 0.120040, l5: 0.276344, l6: 0.565919\n",
      "\n",
      "[epoch: 359/400, batch: 280/1000, ite: 47661] train loss: 1.1736, accuracy: 92.9935%, tar: 0.0253 \n",
      "l0: 0.026114, l1: 0.027955, l2: 0.037744, l3: 0.053716, l4: 0.098986, l5: 0.180459, l6: 0.369485\n",
      "\n",
      "[epoch: 359/400, batch: 288/1000, ite: 47662] train loss: 1.1736, accuracy: 95.1822%, tar: 0.0253 \n",
      "l0: 0.024595, l1: 0.025794, l2: 0.032619, l3: 0.050626, l4: 0.112803, l5: 0.249909, l6: 0.445763\n",
      "\n",
      "[epoch: 359/400, batch: 296/1000, ite: 47663] train loss: 1.1738, accuracy: 93.5332%, tar: 0.0253 \n",
      "l0: 0.020354, l1: 0.021421, l2: 0.027579, l3: 0.042309, l4: 0.069708, l5: 0.134590, l6: 0.260433\n",
      "\n",
      "[epoch: 359/400, batch: 304/1000, ite: 47664] train loss: 1.1736, accuracy: 95.8852%, tar: 0.0253 \n",
      "l0: 0.019967, l1: 0.021484, l2: 0.029600, l3: 0.049016, l4: 0.095666, l5: 0.159282, l6: 0.319935\n",
      "\n",
      "[epoch: 359/400, batch: 312/1000, ite: 47665] train loss: 1.1735, accuracy: 95.6959%, tar: 0.0253 \n",
      "l0: 0.028471, l1: 0.029886, l2: 0.037749, l3: 0.052180, l4: 0.097085, l5: 0.190695, l6: 0.332624\n",
      "\n",
      "[epoch: 359/400, batch: 320/1000, ite: 47666] train loss: 1.1734, accuracy: 95.3973%, tar: 0.0253 \n",
      "l0: 0.030070, l1: 0.031242, l2: 0.039398, l3: 0.054742, l4: 0.094844, l5: 0.186215, l6: 0.381240\n",
      "\n",
      "[epoch: 359/400, batch: 328/1000, ite: 47667] train loss: 1.1734, accuracy: 94.3786%, tar: 0.0253 \n",
      "l0: 0.024137, l1: 0.026628, l2: 0.036482, l3: 0.064076, l4: 0.122348, l5: 0.236511, l6: 0.424769\n",
      "\n",
      "[epoch: 359/400, batch: 336/1000, ite: 47668] train loss: 1.1736, accuracy: 94.9183%, tar: 0.0253 \n",
      "l0: 0.024354, l1: 0.026108, l2: 0.036126, l3: 0.055469, l4: 0.107127, l5: 0.204035, l6: 0.444060\n",
      "\n",
      "[epoch: 359/400, batch: 344/1000, ite: 47669] train loss: 1.1737, accuracy: 93.8433%, tar: 0.0253 \n",
      "l0: 0.018820, l1: 0.020080, l2: 0.026838, l3: 0.040366, l4: 0.077893, l5: 0.164905, l6: 0.324248\n",
      "\n",
      "[epoch: 359/400, batch: 352/1000, ite: 47670] train loss: 1.1736, accuracy: 95.8511%, tar: 0.0253 \n",
      "l0: 0.020619, l1: 0.021684, l2: 0.029868, l3: 0.045086, l4: 0.078654, l5: 0.160144, l6: 0.358132\n",
      "\n",
      "[epoch: 359/400, batch: 360/1000, ite: 47671] train loss: 1.1735, accuracy: 95.4516%, tar: 0.0253 \n",
      "l0: 0.022263, l1: 0.023682, l2: 0.032518, l3: 0.051002, l4: 0.088498, l5: 0.173902, l6: 0.354730\n",
      "\n",
      "[epoch: 359/400, batch: 368/1000, ite: 47672] train loss: 1.1735, accuracy: 95.1105%, tar: 0.0253 \n",
      "l0: 0.027251, l1: 0.028534, l2: 0.036166, l3: 0.050902, l4: 0.089639, l5: 0.200431, l6: 0.489246\n",
      "\n",
      "[epoch: 359/400, batch: 376/1000, ite: 47673] train loss: 1.1736, accuracy: 93.1769%, tar: 0.0253 \n",
      "l0: 0.018506, l1: 0.019324, l2: 0.026467, l3: 0.040547, l4: 0.079525, l5: 0.171583, l6: 0.419966\n",
      "\n",
      "[epoch: 359/400, batch: 384/1000, ite: 47674] train loss: 1.1736, accuracy: 95.2037%, tar: 0.0253 \n",
      "l0: 0.024211, l1: 0.025494, l2: 0.033204, l3: 0.044849, l4: 0.074561, l5: 0.153210, l6: 0.297632\n",
      "\n",
      "[epoch: 359/400, batch: 392/1000, ite: 47675] train loss: 1.1735, accuracy: 95.8627%, tar: 0.0253 \n",
      "l0: 0.025826, l1: 0.027517, l2: 0.035055, l3: 0.050200, l4: 0.086623, l5: 0.188407, l6: 0.393010\n",
      "\n",
      "[epoch: 359/400, batch: 400/1000, ite: 47676] train loss: 1.1735, accuracy: 94.3249%, tar: 0.0253 \n",
      "l0: 0.018186, l1: 0.019368, l2: 0.025182, l3: 0.037637, l4: 0.072590, l5: 0.147118, l6: 0.340157\n",
      "\n",
      "[epoch: 359/400, batch: 408/1000, ite: 47677] train loss: 1.1734, accuracy: 95.8068%, tar: 0.0253 \n",
      "l0: 0.022876, l1: 0.024014, l2: 0.035129, l3: 0.054731, l4: 0.104074, l5: 0.224185, l6: 0.387937\n",
      "\n",
      "[epoch: 359/400, batch: 416/1000, ite: 47678] train loss: 1.1735, accuracy: 95.1139%, tar: 0.0253 \n",
      "l0: 0.025308, l1: 0.026478, l2: 0.035063, l3: 0.052819, l4: 0.098062, l5: 0.187303, l6: 0.355814\n",
      "\n",
      "[epoch: 359/400, batch: 424/1000, ite: 47679] train loss: 1.1734, accuracy: 95.2941%, tar: 0.0253 \n",
      "l0: 0.024694, l1: 0.026075, l2: 0.034424, l3: 0.050385, l4: 0.086543, l5: 0.173772, l6: 0.440122\n",
      "\n",
      "[epoch: 359/400, batch: 432/1000, ite: 47680] train loss: 1.1735, accuracy: 94.3412%, tar: 0.0253 \n",
      "l0: 0.018934, l1: 0.020475, l2: 0.027603, l3: 0.041782, l4: 0.091785, l5: 0.167625, l6: 0.303191\n",
      "\n",
      "[epoch: 359/400, batch: 440/1000, ite: 47681] train loss: 1.1734, accuracy: 96.3288%, tar: 0.0253 \n",
      "l0: 0.025850, l1: 0.027276, l2: 0.034280, l3: 0.051369, l4: 0.100733, l5: 0.223728, l6: 0.473062\n",
      "\n",
      "[epoch: 359/400, batch: 448/1000, ite: 47682] train loss: 1.1735, accuracy: 94.1204%, tar: 0.0253 \n",
      "l0: 0.020138, l1: 0.021539, l2: 0.028685, l3: 0.046199, l4: 0.087590, l5: 0.175699, l6: 0.335986\n",
      "\n",
      "[epoch: 359/400, batch: 456/1000, ite: 47683] train loss: 1.1735, accuracy: 95.0215%, tar: 0.0253 \n",
      "l0: 0.017690, l1: 0.019390, l2: 0.028120, l3: 0.041447, l4: 0.081590, l5: 0.169589, l6: 0.394253\n",
      "\n",
      "[epoch: 359/400, batch: 464/1000, ite: 47684] train loss: 1.1734, accuracy: 95.6466%, tar: 0.0253 \n",
      "l0: 0.020434, l1: 0.021367, l2: 0.027658, l3: 0.041580, l4: 0.076759, l5: 0.161864, l6: 0.313683\n",
      "\n",
      "[epoch: 359/400, batch: 472/1000, ite: 47685] train loss: 1.1733, accuracy: 95.3511%, tar: 0.0253 \n",
      "l0: 0.022125, l1: 0.023724, l2: 0.031857, l3: 0.051698, l4: 0.087633, l5: 0.162963, l6: 0.325711\n",
      "\n",
      "[epoch: 359/400, batch: 480/1000, ite: 47686] train loss: 1.1733, accuracy: 95.7478%, tar: 0.0253 \n",
      "l0: 0.019912, l1: 0.020640, l2: 0.025614, l3: 0.038993, l4: 0.072987, l5: 0.132992, l6: 0.359558\n",
      "\n",
      "[epoch: 359/400, batch: 488/1000, ite: 47687] train loss: 1.1732, accuracy: 94.8876%, tar: 0.0253 \n",
      "l0: 0.021863, l1: 0.022728, l2: 0.029139, l3: 0.040068, l4: 0.078593, l5: 0.153701, l6: 0.447048\n",
      "\n",
      "[epoch: 359/400, batch: 496/1000, ite: 47688] train loss: 1.1732, accuracy: 93.8857%, tar: 0.0253 \n",
      "l0: 0.020538, l1: 0.021891, l2: 0.029227, l3: 0.040371, l4: 0.076027, l5: 0.132829, l6: 0.242865\n",
      "\n",
      "[epoch: 359/400, batch: 504/1000, ite: 47689] train loss: 1.1730, accuracy: 96.0769%, tar: 0.0253 \n",
      "l0: 0.019181, l1: 0.019977, l2: 0.025224, l3: 0.038521, l4: 0.075539, l5: 0.136716, l6: 0.254569\n",
      "\n",
      "[epoch: 359/400, batch: 512/1000, ite: 47690] train loss: 1.1728, accuracy: 95.8220%, tar: 0.0253 \n",
      "l0: 0.024183, l1: 0.025641, l2: 0.032809, l3: 0.050162, l4: 0.088444, l5: 0.181503, l6: 0.397737\n",
      "\n",
      "[epoch: 359/400, batch: 520/1000, ite: 47691] train loss: 1.1728, accuracy: 95.1426%, tar: 0.0253 \n",
      "l0: 0.019692, l1: 0.020951, l2: 0.027034, l3: 0.046000, l4: 0.088527, l5: 0.182794, l6: 0.314182\n",
      "\n",
      "[epoch: 359/400, batch: 528/1000, ite: 47692] train loss: 1.1727, accuracy: 95.4017%, tar: 0.0253 \n",
      "l0: 0.031651, l1: 0.033249, l2: 0.042109, l3: 0.061590, l4: 0.115898, l5: 0.255859, l6: 0.597371\n",
      "\n",
      "[epoch: 359/400, batch: 536/1000, ite: 47693] train loss: 1.1730, accuracy: 91.9921%, tar: 0.0253 \n",
      "l0: 0.031091, l1: 0.032849, l2: 0.043133, l3: 0.059926, l4: 0.119274, l5: 0.261471, l6: 0.544310\n",
      "\n",
      "[epoch: 359/400, batch: 544/1000, ite: 47694] train loss: 1.1733, accuracy: 93.1999%, tar: 0.0253 \n",
      "l0: 0.030738, l1: 0.032362, l2: 0.041126, l3: 0.059763, l4: 0.101607, l5: 0.211283, l6: 0.435870\n",
      "\n",
      "[epoch: 359/400, batch: 552/1000, ite: 47695] train loss: 1.1734, accuracy: 93.7796%, tar: 0.0253 \n",
      "l0: 0.018761, l1: 0.019622, l2: 0.025507, l3: 0.038270, l4: 0.075549, l5: 0.153886, l6: 0.302443\n",
      "\n",
      "[epoch: 359/400, batch: 560/1000, ite: 47696] train loss: 1.1733, accuracy: 95.8944%, tar: 0.0253 \n",
      "l0: 0.023086, l1: 0.024034, l2: 0.031465, l3: 0.048592, l4: 0.092026, l5: 0.194655, l6: 0.448347\n",
      "\n",
      "[epoch: 359/400, batch: 568/1000, ite: 47697] train loss: 1.1734, accuracy: 94.3670%, tar: 0.0253 \n",
      "l0: 0.020205, l1: 0.021504, l2: 0.029819, l3: 0.044237, l4: 0.079240, l5: 0.142062, l6: 0.292866\n",
      "\n",
      "[epoch: 359/400, batch: 576/1000, ite: 47698] train loss: 1.1732, accuracy: 96.1090%, tar: 0.0253 \n",
      "l0: 0.028666, l1: 0.031063, l2: 0.043573, l3: 0.067826, l4: 0.133467, l5: 0.254092, l6: 0.449740\n",
      "\n",
      "[epoch: 359/400, batch: 584/1000, ite: 47699] train loss: 1.1734, accuracy: 94.0491%, tar: 0.0253 \n",
      "l0: 0.025696, l1: 0.026772, l2: 0.034651, l3: 0.049838, l4: 0.085912, l5: 0.201334, l6: 0.409625\n",
      "\n",
      "[epoch: 359/400, batch: 592/1000, ite: 47700] train loss: 1.1734, accuracy: 94.1255%, tar: 0.0253 \n",
      "l0: 0.026269, l1: 0.027135, l2: 0.034606, l3: 0.049071, l4: 0.085919, l5: 0.167503, l6: 0.379480\n",
      "\n",
      "[epoch: 359/400, batch: 600/1000, ite: 47701] train loss: 1.1734, accuracy: 93.9743%, tar: 0.0253 \n",
      "l0: 0.016423, l1: 0.016977, l2: 0.022045, l3: 0.030328, l4: 0.048145, l5: 0.082602, l6: 0.166896\n",
      "\n",
      "[epoch: 359/400, batch: 608/1000, ite: 47702] train loss: 1.1731, accuracy: 96.9628%, tar: 0.0253 \n",
      "l0: 0.021806, l1: 0.022567, l2: 0.029829, l3: 0.039685, l4: 0.072604, l5: 0.148103, l6: 0.287146\n",
      "\n",
      "[epoch: 359/400, batch: 616/1000, ite: 47703] train loss: 1.1729, accuracy: 95.6069%, tar: 0.0253 \n",
      "l0: 0.022457, l1: 0.023860, l2: 0.031117, l3: 0.045221, l4: 0.084154, l5: 0.203447, l6: 0.409949\n",
      "\n",
      "[epoch: 359/400, batch: 624/1000, ite: 47704] train loss: 1.1729, accuracy: 94.6637%, tar: 0.0253 \n",
      "l0: 0.019363, l1: 0.020522, l2: 0.028406, l3: 0.045757, l4: 0.088888, l5: 0.173429, l6: 0.289285\n",
      "\n",
      "[epoch: 359/400, batch: 632/1000, ite: 47705] train loss: 1.1728, accuracy: 96.1123%, tar: 0.0253 \n",
      "l0: 0.025303, l1: 0.026262, l2: 0.033104, l3: 0.050728, l4: 0.090385, l5: 0.175942, l6: 0.359270\n",
      "\n",
      "[epoch: 359/400, batch: 640/1000, ite: 47706] train loss: 1.1728, accuracy: 94.5530%, tar: 0.0253 \n",
      "l0: 0.019922, l1: 0.020631, l2: 0.028724, l3: 0.040843, l4: 0.068966, l5: 0.127443, l6: 0.281075\n",
      "\n",
      "[epoch: 359/400, batch: 648/1000, ite: 47707] train loss: 1.1726, accuracy: 95.8281%, tar: 0.0253 \n",
      "l0: 0.020676, l1: 0.021834, l2: 0.030415, l3: 0.045774, l4: 0.082631, l5: 0.185257, l6: 0.380779\n",
      "\n",
      "[epoch: 359/400, batch: 656/1000, ite: 47708] train loss: 1.1726, accuracy: 94.5340%, tar: 0.0252 \n",
      "l0: 0.024881, l1: 0.025683, l2: 0.034175, l3: 0.050358, l4: 0.089917, l5: 0.175043, l6: 0.363970\n",
      "\n",
      "[epoch: 359/400, batch: 664/1000, ite: 47709] train loss: 1.1726, accuracy: 94.9140%, tar: 0.0252 \n",
      "l0: 0.021455, l1: 0.022679, l2: 0.030798, l3: 0.045967, l4: 0.084450, l5: 0.180294, l6: 0.363766\n",
      "\n",
      "[epoch: 359/400, batch: 672/1000, ite: 47710] train loss: 1.1725, accuracy: 95.0985%, tar: 0.0252 \n",
      "l0: 0.021446, l1: 0.023829, l2: 0.032537, l3: 0.053126, l4: 0.102549, l5: 0.182093, l6: 0.365943\n",
      "\n",
      "[epoch: 359/400, batch: 680/1000, ite: 47711] train loss: 1.1725, accuracy: 95.4418%, tar: 0.0252 \n",
      "l0: 0.022402, l1: 0.023783, l2: 0.031477, l3: 0.051251, l4: 0.101774, l5: 0.202460, l6: 0.485717\n",
      "\n",
      "[epoch: 359/400, batch: 688/1000, ite: 47712] train loss: 1.1727, accuracy: 93.1401%, tar: 0.0252 \n",
      "l0: 0.019951, l1: 0.020955, l2: 0.027762, l3: 0.039555, l4: 0.062995, l5: 0.114263, l6: 0.297726\n",
      "\n",
      "[epoch: 359/400, batch: 696/1000, ite: 47713] train loss: 1.1725, accuracy: 95.8593%, tar: 0.0252 \n",
      "l0: 0.020030, l1: 0.021438, l2: 0.030441, l3: 0.044237, l4: 0.082444, l5: 0.183000, l6: 0.374656\n",
      "\n",
      "[epoch: 359/400, batch: 704/1000, ite: 47714] train loss: 1.1725, accuracy: 95.8510%, tar: 0.0252 \n",
      "l0: 0.020398, l1: 0.021727, l2: 0.029979, l3: 0.046447, l4: 0.082664, l5: 0.150835, l6: 0.280955\n",
      "\n",
      "[epoch: 359/400, batch: 712/1000, ite: 47715] train loss: 1.1723, accuracy: 95.9800%, tar: 0.0252 \n",
      "l0: 0.025656, l1: 0.027630, l2: 0.036502, l3: 0.064560, l4: 0.126261, l5: 0.238868, l6: 0.451240\n",
      "\n",
      "[epoch: 359/400, batch: 720/1000, ite: 47716] train loss: 1.1725, accuracy: 94.2176%, tar: 0.0252 \n",
      "l0: 0.018547, l1: 0.019517, l2: 0.026607, l3: 0.040947, l4: 0.070504, l5: 0.146641, l6: 0.297667\n",
      "\n",
      "[epoch: 359/400, batch: 728/1000, ite: 47717] train loss: 1.1723, accuracy: 95.7940%, tar: 0.0252 \n",
      "l0: 0.025171, l1: 0.027045, l2: 0.034879, l3: 0.052916, l4: 0.098780, l5: 0.199466, l6: 0.391505\n",
      "\n",
      "[epoch: 359/400, batch: 736/1000, ite: 47718] train loss: 1.1724, accuracy: 94.4733%, tar: 0.0252 \n",
      "l0: 0.023819, l1: 0.025904, l2: 0.033812, l3: 0.048038, l4: 0.090876, l5: 0.188499, l6: 0.348318\n",
      "\n",
      "[epoch: 359/400, batch: 744/1000, ite: 47719] train loss: 1.1723, accuracy: 95.6009%, tar: 0.0252 \n",
      "l0: 0.030935, l1: 0.032930, l2: 0.043747, l3: 0.065117, l4: 0.121382, l5: 0.269884, l6: 0.482651\n",
      "\n",
      "[epoch: 359/400, batch: 752/1000, ite: 47720] train loss: 1.1725, accuracy: 92.5445%, tar: 0.0252 \n",
      "l0: 0.024476, l1: 0.026178, l2: 0.033255, l3: 0.048951, l4: 0.095353, l5: 0.215205, l6: 0.409411\n",
      "\n",
      "[epoch: 359/400, batch: 760/1000, ite: 47721] train loss: 1.1726, accuracy: 95.0302%, tar: 0.0252 \n",
      "l0: 0.026346, l1: 0.028016, l2: 0.036580, l3: 0.051545, l4: 0.104168, l5: 0.262042, l6: 0.473204\n",
      "\n",
      "[epoch: 359/400, batch: 768/1000, ite: 47722] train loss: 1.1728, accuracy: 93.1589%, tar: 0.0252 \n",
      "l0: 0.024809, l1: 0.026197, l2: 0.036644, l3: 0.056953, l4: 0.110711, l5: 0.202621, l6: 0.399935\n",
      "\n",
      "[epoch: 359/400, batch: 776/1000, ite: 47723] train loss: 1.1728, accuracy: 94.1692%, tar: 0.0252 \n",
      "l0: 0.021745, l1: 0.023212, l2: 0.031628, l3: 0.044799, l4: 0.088505, l5: 0.164955, l6: 0.296016\n",
      "\n",
      "[epoch: 359/400, batch: 784/1000, ite: 47724] train loss: 1.1727, accuracy: 95.8266%, tar: 0.0252 \n",
      "l0: 0.023422, l1: 0.024535, l2: 0.031854, l3: 0.047865, l4: 0.092630, l5: 0.178150, l6: 0.370203\n",
      "\n",
      "[epoch: 359/400, batch: 792/1000, ite: 47725] train loss: 1.1727, accuracy: 95.5029%, tar: 0.0252 \n",
      "l0: 0.025536, l1: 0.026662, l2: 0.034641, l3: 0.052009, l4: 0.095711, l5: 0.190157, l6: 0.393209\n",
      "\n",
      "[epoch: 359/400, batch: 800/1000, ite: 47726] train loss: 1.1727, accuracy: 93.8390%, tar: 0.0252 \n",
      "l0: 0.016495, l1: 0.017612, l2: 0.023218, l3: 0.033434, l4: 0.069713, l5: 0.163635, l6: 0.301191\n",
      "\n",
      "[epoch: 359/400, batch: 808/1000, ite: 47727] train loss: 1.1726, accuracy: 96.3123%, tar: 0.0252 \n",
      "l0: 0.023707, l1: 0.025315, l2: 0.033120, l3: 0.051784, l4: 0.098603, l5: 0.222300, l6: 0.471981\n",
      "\n",
      "[epoch: 359/400, batch: 816/1000, ite: 47728] train loss: 1.1727, accuracy: 94.6356%, tar: 0.0252 \n",
      "l0: 0.027121, l1: 0.029111, l2: 0.040972, l3: 0.060233, l4: 0.104953, l5: 0.247030, l6: 0.465669\n",
      "\n",
      "[epoch: 359/400, batch: 824/1000, ite: 47729] train loss: 1.1728, accuracy: 94.2890%, tar: 0.0252 \n",
      "l0: 0.020594, l1: 0.021385, l2: 0.027991, l3: 0.039017, l4: 0.063951, l5: 0.135310, l6: 0.305381\n",
      "\n",
      "[epoch: 359/400, batch: 832/1000, ite: 47730] train loss: 1.1727, accuracy: 95.8080%, tar: 0.0252 \n",
      "l0: 0.023882, l1: 0.024658, l2: 0.031628, l3: 0.043601, l4: 0.077087, l5: 0.155018, l6: 0.306046\n",
      "\n",
      "[epoch: 359/400, batch: 840/1000, ite: 47731] train loss: 1.1726, accuracy: 94.8943%, tar: 0.0252 \n",
      "l0: 0.024918, l1: 0.026139, l2: 0.033969, l3: 0.051020, l4: 0.107074, l5: 0.221330, l6: 0.455007\n",
      "\n",
      "[epoch: 359/400, batch: 848/1000, ite: 47732] train loss: 1.1727, accuracy: 94.1734%, tar: 0.0252 \n",
      "l0: 0.021395, l1: 0.022542, l2: 0.029720, l3: 0.044773, l4: 0.078658, l5: 0.145419, l6: 0.340566\n",
      "\n",
      "[epoch: 359/400, batch: 856/1000, ite: 47733] train loss: 1.1726, accuracy: 94.8011%, tar: 0.0252 \n",
      "l0: 0.033244, l1: 0.035060, l2: 0.043769, l3: 0.066897, l4: 0.138554, l5: 0.329305, l6: 0.613698\n",
      "\n",
      "[epoch: 359/400, batch: 864/1000, ite: 47734] train loss: 1.1730, accuracy: 91.4242%, tar: 0.0252 \n",
      "l0: 0.023479, l1: 0.024590, l2: 0.031231, l3: 0.049519, l4: 0.087039, l5: 0.180280, l6: 0.394641\n",
      "\n",
      "[epoch: 359/400, batch: 872/1000, ite: 47735] train loss: 1.1730, accuracy: 94.7464%, tar: 0.0252 \n",
      "l0: 0.021880, l1: 0.024324, l2: 0.033849, l3: 0.065057, l4: 0.147900, l5: 0.249762, l6: 0.400024\n",
      "\n",
      "[epoch: 359/400, batch: 880/1000, ite: 47736] train loss: 1.1731, accuracy: 95.6268%, tar: 0.0252 \n",
      "l0: 0.020158, l1: 0.021325, l2: 0.028339, l3: 0.040334, l4: 0.069267, l5: 0.147766, l6: 0.292988\n",
      "\n",
      "[epoch: 359/400, batch: 888/1000, ite: 47737] train loss: 1.1730, accuracy: 95.8857%, tar: 0.0252 \n",
      "l0: 0.029120, l1: 0.030332, l2: 0.039732, l3: 0.062618, l4: 0.113131, l5: 0.216948, l6: 0.458505\n",
      "\n",
      "[epoch: 359/400, batch: 896/1000, ite: 47738] train loss: 1.1731, accuracy: 94.1778%, tar: 0.0252 \n",
      "l0: 0.028264, l1: 0.029250, l2: 0.038047, l3: 0.057262, l4: 0.104863, l5: 0.251670, l6: 0.490945\n",
      "\n",
      "[epoch: 359/400, batch: 904/1000, ite: 47739] train loss: 1.1733, accuracy: 92.3238%, tar: 0.0252 \n",
      "l0: 0.023082, l1: 0.023972, l2: 0.031567, l3: 0.044726, l4: 0.088828, l5: 0.219713, l6: 0.376742\n",
      "\n",
      "[epoch: 359/400, batch: 912/1000, ite: 47740] train loss: 1.1733, accuracy: 94.4648%, tar: 0.0252 \n",
      "l0: 0.024799, l1: 0.026188, l2: 0.033601, l3: 0.049890, l4: 0.096130, l5: 0.170096, l6: 0.321257\n",
      "\n",
      "[epoch: 359/400, batch: 920/1000, ite: 47741] train loss: 1.1733, accuracy: 94.9825%, tar: 0.0252 \n",
      "l0: 0.017359, l1: 0.017976, l2: 0.024355, l3: 0.035356, l4: 0.057645, l5: 0.098739, l6: 0.205975\n",
      "\n",
      "[epoch: 359/400, batch: 928/1000, ite: 47742] train loss: 1.1730, accuracy: 96.8810%, tar: 0.0252 \n",
      "l0: 0.016102, l1: 0.016752, l2: 0.021832, l3: 0.029994, l4: 0.053874, l5: 0.094125, l6: 0.187619\n",
      "\n",
      "[epoch: 359/400, batch: 936/1000, ite: 47743] train loss: 1.1726, accuracy: 97.2455%, tar: 0.0252 \n",
      "l0: 0.020402, l1: 0.021102, l2: 0.027136, l3: 0.036838, l4: 0.061771, l5: 0.119332, l6: 0.257726\n",
      "\n",
      "[epoch: 359/400, batch: 944/1000, ite: 47744] train loss: 1.1724, accuracy: 95.7624%, tar: 0.0252 \n",
      "l0: 0.022121, l1: 0.022630, l2: 0.028856, l3: 0.037169, l4: 0.060813, l5: 0.111870, l6: 0.265501\n",
      "\n",
      "[epoch: 359/400, batch: 952/1000, ite: 47745] train loss: 1.1722, accuracy: 96.1041%, tar: 0.0252 \n",
      "l0: 0.019795, l1: 0.021062, l2: 0.028035, l3: 0.048318, l4: 0.090553, l5: 0.171309, l6: 0.348351\n",
      "\n",
      "[epoch: 359/400, batch: 960/1000, ite: 47746] train loss: 1.1722, accuracy: 95.0146%, tar: 0.0252 \n",
      "l0: 0.022206, l1: 0.023135, l2: 0.029171, l3: 0.040411, l4: 0.072304, l5: 0.142752, l6: 0.326518\n",
      "\n",
      "[epoch: 359/400, batch: 968/1000, ite: 47747] train loss: 1.1721, accuracy: 95.7966%, tar: 0.0252 \n",
      "l0: 0.025043, l1: 0.026091, l2: 0.034947, l3: 0.051601, l4: 0.086751, l5: 0.164774, l6: 0.346448\n",
      "\n",
      "[epoch: 359/400, batch: 976/1000, ite: 47748] train loss: 1.1720, accuracy: 94.6865%, tar: 0.0252 \n",
      "l0: 0.030520, l1: 0.032110, l2: 0.042492, l3: 0.058938, l4: 0.103540, l5: 0.202257, l6: 0.479203\n",
      "\n",
      "[epoch: 359/400, batch: 984/1000, ite: 47749] train loss: 1.1722, accuracy: 93.7975%, tar: 0.0252 \n",
      "l0: 0.022429, l1: 0.023988, l2: 0.031137, l3: 0.042457, l4: 0.071455, l5: 0.152480, l6: 0.335940\n",
      "\n",
      "[epoch: 359/400, batch: 992/1000, ite: 47750] train loss: 1.1721, accuracy: 95.4313%, tar: 0.0252 \n",
      "l0: 0.019747, l1: 0.020834, l2: 0.028148, l3: 0.040421, l4: 0.064910, l5: 0.110166, l6: 0.248728\n",
      "\n",
      "[epoch: 359/400, batch: 1000/1000, ite: 47751] train loss: 1.1719, accuracy: 96.2219%, tar: 0.0252 \n",
      "l0: 0.020261, l1: 0.022105, l2: 0.030825, l3: 0.048767, l4: 0.091575, l5: 0.192315, l6: 0.464631\n",
      "\n",
      "[epoch: 360/400, batch: 8/1000, ite: 47752] train loss: 1.1720, accuracy: 94.3298%, tar: 0.0252 \n",
      "l0: 0.019893, l1: 0.021522, l2: 0.030397, l3: 0.050160, l4: 0.091495, l5: 0.181237, l6: 0.361523\n",
      "\n",
      "[epoch: 360/400, batch: 16/1000, ite: 47753] train loss: 1.1719, accuracy: 95.3615%, tar: 0.0252 \n",
      "l0: 0.029945, l1: 0.031327, l2: 0.040343, l3: 0.057213, l4: 0.096484, l5: 0.183375, l6: 0.398978\n",
      "\n",
      "[epoch: 360/400, batch: 24/1000, ite: 47754] train loss: 1.1720, accuracy: 93.5502%, tar: 0.0252 \n",
      "l0: 0.020383, l1: 0.021998, l2: 0.030459, l3: 0.048280, l4: 0.097183, l5: 0.186362, l6: 0.384111\n",
      "\n",
      "[epoch: 360/400, batch: 32/1000, ite: 47755] train loss: 1.1720, accuracy: 94.8937%, tar: 0.0252 \n",
      "l0: 0.019891, l1: 0.021633, l2: 0.030442, l3: 0.049738, l4: 0.127653, l5: 0.287070, l6: 0.458760\n",
      "\n",
      "[epoch: 360/400, batch: 40/1000, ite: 47756] train loss: 1.1721, accuracy: 93.6727%, tar: 0.0252 \n",
      "l0: 0.019983, l1: 0.021242, l2: 0.029450, l3: 0.043241, l4: 0.081954, l5: 0.151348, l6: 0.322848\n",
      "\n",
      "[epoch: 360/400, batch: 48/1000, ite: 47757] train loss: 1.1720, accuracy: 95.4775%, tar: 0.0252 \n",
      "l0: 0.021250, l1: 0.022079, l2: 0.030116, l3: 0.045398, l4: 0.085214, l5: 0.178171, l6: 0.389922\n",
      "\n",
      "[epoch: 360/400, batch: 56/1000, ite: 47758] train loss: 1.1720, accuracy: 95.1723%, tar: 0.0252 \n",
      "l0: 0.019246, l1: 0.020744, l2: 0.027211, l3: 0.043079, l4: 0.075268, l5: 0.137443, l6: 0.272545\n",
      "\n",
      "[epoch: 360/400, batch: 64/1000, ite: 47759] train loss: 1.1719, accuracy: 96.2972%, tar: 0.0252 \n",
      "l0: 0.022189, l1: 0.023440, l2: 0.030934, l3: 0.041757, l4: 0.067488, l5: 0.116081, l6: 0.282959\n",
      "\n",
      "[epoch: 360/400, batch: 72/1000, ite: 47760] train loss: 1.1717, accuracy: 96.3921%, tar: 0.0252 \n",
      "l0: 0.024560, l1: 0.025404, l2: 0.033519, l3: 0.048325, l4: 0.087957, l5: 0.189460, l6: 0.541033\n",
      "\n",
      "[epoch: 360/400, batch: 80/1000, ite: 47761] train loss: 1.1719, accuracy: 94.8330%, tar: 0.0252 \n",
      "l0: 0.016381, l1: 0.017858, l2: 0.026153, l3: 0.036679, l4: 0.067596, l5: 0.133723, l6: 0.244119\n",
      "\n",
      "[epoch: 360/400, batch: 88/1000, ite: 47762] train loss: 1.1717, accuracy: 96.6980%, tar: 0.0252 \n",
      "l0: 0.029134, l1: 0.031643, l2: 0.042088, l3: 0.068530, l4: 0.128703, l5: 0.253291, l6: 0.498970\n",
      "\n",
      "[epoch: 360/400, batch: 96/1000, ite: 47763] train loss: 1.1719, accuracy: 93.4242%, tar: 0.0252 \n",
      "l0: 0.021940, l1: 0.023085, l2: 0.029115, l3: 0.041892, l4: 0.090253, l5: 0.162024, l6: 0.350325\n",
      "\n",
      "[epoch: 360/400, batch: 104/1000, ite: 47764] train loss: 1.1718, accuracy: 95.1906%, tar: 0.0252 \n",
      "l0: 0.017162, l1: 0.019299, l2: 0.028312, l3: 0.046336, l4: 0.089492, l5: 0.162241, l6: 0.344117\n",
      "\n",
      "[epoch: 360/400, batch: 112/1000, ite: 47765] train loss: 1.1717, accuracy: 95.6248%, tar: 0.0252 \n",
      "l0: 0.020843, l1: 0.021878, l2: 0.027535, l3: 0.040731, l4: 0.067776, l5: 0.128543, l6: 0.276811\n",
      "\n",
      "[epoch: 360/400, batch: 120/1000, ite: 47766] train loss: 1.1716, accuracy: 95.1596%, tar: 0.0252 \n",
      "l0: 0.019591, l1: 0.020968, l2: 0.026970, l3: 0.040017, l4: 0.078115, l5: 0.154941, l6: 0.292300\n",
      "\n",
      "[epoch: 360/400, batch: 128/1000, ite: 47767] train loss: 1.1714, accuracy: 96.0904%, tar: 0.0252 \n",
      "l0: 0.024589, l1: 0.026600, l2: 0.035859, l3: 0.052112, l4: 0.100837, l5: 0.222115, l6: 0.441400\n",
      "\n",
      "[epoch: 360/400, batch: 136/1000, ite: 47768] train loss: 1.1715, accuracy: 93.4670%, tar: 0.0252 \n",
      "l0: 0.025016, l1: 0.025828, l2: 0.032389, l3: 0.046190, l4: 0.081898, l5: 0.159078, l6: 0.308932\n",
      "\n",
      "[epoch: 360/400, batch: 144/1000, ite: 47769] train loss: 1.1714, accuracy: 94.8301%, tar: 0.0252 \n",
      "l0: 0.024673, l1: 0.025553, l2: 0.033289, l3: 0.044271, l4: 0.073795, l5: 0.167770, l6: 0.377250\n",
      "\n",
      "[epoch: 360/400, batch: 152/1000, ite: 47770] train loss: 1.1714, accuracy: 94.5108%, tar: 0.0252 \n",
      "l0: 0.023863, l1: 0.025217, l2: 0.033546, l3: 0.052673, l4: 0.101618, l5: 0.225426, l6: 0.414595\n",
      "\n",
      "[epoch: 360/400, batch: 160/1000, ite: 47771] train loss: 1.1715, accuracy: 93.7893%, tar: 0.0252 \n",
      "l0: 0.030522, l1: 0.031778, l2: 0.040178, l3: 0.055110, l4: 0.098535, l5: 0.240255, l6: 0.416517\n",
      "\n",
      "[epoch: 360/400, batch: 168/1000, ite: 47772] train loss: 1.1716, accuracy: 94.1771%, tar: 0.0252 \n",
      "l0: 0.022191, l1: 0.023983, l2: 0.033045, l3: 0.049598, l4: 0.096992, l5: 0.191210, l6: 0.404345\n",
      "\n",
      "[epoch: 360/400, batch: 176/1000, ite: 47773] train loss: 1.1716, accuracy: 95.0904%, tar: 0.0252 \n",
      "l0: 0.023387, l1: 0.024567, l2: 0.033305, l3: 0.049891, l4: 0.095609, l5: 0.213444, l6: 0.451703\n",
      "\n",
      "[epoch: 360/400, batch: 184/1000, ite: 47774] train loss: 1.1717, accuracy: 94.5078%, tar: 0.0252 \n",
      "l0: 0.021900, l1: 0.023237, l2: 0.031903, l3: 0.050450, l4: 0.102257, l5: 0.209574, l6: 0.460142\n",
      "\n",
      "[epoch: 360/400, batch: 192/1000, ite: 47775] train loss: 1.1718, accuracy: 94.4587%, tar: 0.0252 \n",
      "l0: 0.026919, l1: 0.028969, l2: 0.040279, l3: 0.058737, l4: 0.106431, l5: 0.215248, l6: 0.470842\n",
      "\n",
      "[epoch: 360/400, batch: 200/1000, ite: 47776] train loss: 1.1719, accuracy: 94.0426%, tar: 0.0252 \n",
      "l0: 0.025390, l1: 0.026538, l2: 0.035333, l3: 0.052765, l4: 0.107417, l5: 0.184110, l6: 0.358757\n",
      "\n",
      "[epoch: 360/400, batch: 208/1000, ite: 47777] train loss: 1.1719, accuracy: 94.7526%, tar: 0.0252 \n",
      "l0: 0.022117, l1: 0.023977, l2: 0.033332, l3: 0.054446, l4: 0.127312, l5: 0.231513, l6: 0.469400\n",
      "\n",
      "[epoch: 360/400, batch: 216/1000, ite: 47778] train loss: 1.1721, accuracy: 94.0744%, tar: 0.0252 \n",
      "l0: 0.017270, l1: 0.018851, l2: 0.025124, l3: 0.040894, l4: 0.084940, l5: 0.195445, l6: 0.395888\n",
      "\n",
      "[epoch: 360/400, batch: 224/1000, ite: 47779] train loss: 1.1721, accuracy: 94.6285%, tar: 0.0252 \n",
      "l0: 0.017239, l1: 0.018293, l2: 0.024873, l3: 0.035292, l4: 0.064435, l5: 0.125492, l6: 0.260467\n",
      "\n",
      "[epoch: 360/400, batch: 232/1000, ite: 47780] train loss: 1.1719, accuracy: 96.2118%, tar: 0.0252 \n",
      "l0: 0.022823, l1: 0.024431, l2: 0.032237, l3: 0.050211, l4: 0.109628, l5: 0.216848, l6: 0.434092\n",
      "\n",
      "[epoch: 360/400, batch: 240/1000, ite: 47781] train loss: 1.1720, accuracy: 94.4875%, tar: 0.0252 \n",
      "l0: 0.019219, l1: 0.021018, l2: 0.031677, l3: 0.050949, l4: 0.096534, l5: 0.183634, l6: 0.364529\n",
      "\n",
      "[epoch: 360/400, batch: 248/1000, ite: 47782] train loss: 1.1720, accuracy: 95.3366%, tar: 0.0251 \n",
      "l0: 0.019283, l1: 0.019905, l2: 0.027449, l3: 0.039672, l4: 0.076141, l5: 0.144622, l6: 0.294384\n",
      "\n",
      "[epoch: 360/400, batch: 256/1000, ite: 47783] train loss: 1.1718, accuracy: 95.5586%, tar: 0.0251 \n",
      "l0: 0.030183, l1: 0.031767, l2: 0.040286, l3: 0.061326, l4: 0.104286, l5: 0.248681, l6: 0.499858\n",
      "\n",
      "[epoch: 360/400, batch: 264/1000, ite: 47784] train loss: 1.1720, accuracy: 93.1411%, tar: 0.0251 \n",
      "l0: 0.021887, l1: 0.023808, l2: 0.034507, l3: 0.055675, l4: 0.108398, l5: 0.209907, l6: 0.391329\n",
      "\n",
      "[epoch: 360/400, batch: 272/1000, ite: 47785] train loss: 1.1720, accuracy: 94.9986%, tar: 0.0251 \n",
      "l0: 0.017591, l1: 0.019039, l2: 0.026465, l3: 0.040675, l4: 0.067622, l5: 0.110009, l6: 0.235665\n",
      "\n",
      "[epoch: 360/400, batch: 280/1000, ite: 47786] train loss: 1.1718, accuracy: 96.9176%, tar: 0.0251 \n",
      "l0: 0.018440, l1: 0.019121, l2: 0.026686, l3: 0.037984, l4: 0.078825, l5: 0.177684, l6: 0.360962\n",
      "\n",
      "[epoch: 360/400, batch: 288/1000, ite: 47787] train loss: 1.1718, accuracy: 95.3642%, tar: 0.0251 \n",
      "l0: 0.019075, l1: 0.020052, l2: 0.025895, l3: 0.039286, l4: 0.070273, l5: 0.156144, l6: 0.300692\n",
      "\n",
      "[epoch: 360/400, batch: 296/1000, ite: 47788] train loss: 1.1716, accuracy: 95.5910%, tar: 0.0251 \n",
      "l0: 0.025005, l1: 0.026726, l2: 0.036268, l3: 0.053316, l4: 0.102739, l5: 0.216554, l6: 0.388988\n",
      "\n",
      "[epoch: 360/400, batch: 304/1000, ite: 47789] train loss: 1.1717, accuracy: 94.4534%, tar: 0.0251 \n",
      "l0: 0.022159, l1: 0.023814, l2: 0.034262, l3: 0.057275, l4: 0.112380, l5: 0.237558, l6: 0.537335\n",
      "\n",
      "[epoch: 360/400, batch: 312/1000, ite: 47790] train loss: 1.1719, accuracy: 93.7161%, tar: 0.0251 \n",
      "l0: 0.022209, l1: 0.023191, l2: 0.029602, l3: 0.042327, l4: 0.074578, l5: 0.142229, l6: 0.329965\n",
      "\n",
      "[epoch: 360/400, batch: 320/1000, ite: 47791] train loss: 1.1718, accuracy: 95.0871%, tar: 0.0251 \n",
      "l0: 0.022829, l1: 0.024488, l2: 0.031590, l3: 0.051504, l4: 0.111747, l5: 0.201650, l6: 0.369544\n",
      "\n",
      "[epoch: 360/400, batch: 328/1000, ite: 47792] train loss: 1.1718, accuracy: 95.0001%, tar: 0.0251 \n",
      "l0: 0.017365, l1: 0.018589, l2: 0.023554, l3: 0.036692, l4: 0.074388, l5: 0.140559, l6: 0.285895\n",
      "\n",
      "[epoch: 360/400, batch: 336/1000, ite: 47793] train loss: 1.1716, accuracy: 95.4686%, tar: 0.0251 \n",
      "l0: 0.028426, l1: 0.029940, l2: 0.037404, l3: 0.053872, l4: 0.093441, l5: 0.201173, l6: 0.459328\n",
      "\n",
      "[epoch: 360/400, batch: 344/1000, ite: 47794] train loss: 1.1718, accuracy: 93.4237%, tar: 0.0251 \n",
      "l0: 0.027938, l1: 0.029650, l2: 0.039340, l3: 0.057340, l4: 0.111760, l5: 0.242208, l6: 0.486111\n",
      "\n",
      "[epoch: 360/400, batch: 352/1000, ite: 47795] train loss: 1.1719, accuracy: 93.0539%, tar: 0.0251 \n",
      "l0: 0.023316, l1: 0.025493, l2: 0.036488, l3: 0.059910, l4: 0.109889, l5: 0.220569, l6: 0.413110\n",
      "\n",
      "[epoch: 360/400, batch: 360/1000, ite: 47796] train loss: 1.1720, accuracy: 95.6026%, tar: 0.0251 \n",
      "l0: 0.025052, l1: 0.027079, l2: 0.038176, l3: 0.057195, l4: 0.127979, l5: 0.299537, l6: 0.540113\n",
      "\n",
      "[epoch: 360/400, batch: 368/1000, ite: 47797] train loss: 1.1723, accuracy: 94.2486%, tar: 0.0251 \n",
      "l0: 0.024778, l1: 0.025937, l2: 0.032193, l3: 0.043375, l4: 0.067949, l5: 0.132483, l6: 0.269548\n",
      "\n",
      "[epoch: 360/400, batch: 376/1000, ite: 47798] train loss: 1.1721, accuracy: 95.0294%, tar: 0.0251 \n",
      "l0: 0.025563, l1: 0.027045, l2: 0.035387, l3: 0.055363, l4: 0.103065, l5: 0.213616, l6: 0.442625\n",
      "\n",
      "[epoch: 360/400, batch: 384/1000, ite: 47799] train loss: 1.1722, accuracy: 93.6474%, tar: 0.0251 \n",
      "l0: 0.019835, l1: 0.021891, l2: 0.031319, l3: 0.051137, l4: 0.097743, l5: 0.188954, l6: 0.403571\n",
      "\n",
      "[epoch: 360/400, batch: 392/1000, ite: 47800] train loss: 1.1722, accuracy: 95.2828%, tar: 0.0251 \n",
      "l0: 0.023568, l1: 0.024943, l2: 0.032117, l3: 0.048415, l4: 0.098445, l5: 0.200368, l6: 0.404728\n",
      "\n",
      "[epoch: 360/400, batch: 400/1000, ite: 47801] train loss: 1.1723, accuracy: 94.2272%, tar: 0.0251 \n",
      "l0: 0.025428, l1: 0.027551, l2: 0.036520, l3: 0.056871, l4: 0.097575, l5: 0.194781, l6: 0.383883\n",
      "\n",
      "[epoch: 360/400, batch: 408/1000, ite: 47802] train loss: 1.1723, accuracy: 94.8670%, tar: 0.0251 \n",
      "l0: 0.020065, l1: 0.021358, l2: 0.026798, l3: 0.039274, l4: 0.067980, l5: 0.134008, l6: 0.244240\n",
      "\n",
      "[epoch: 360/400, batch: 416/1000, ite: 47803] train loss: 1.1721, accuracy: 95.7802%, tar: 0.0251 \n",
      "l0: 0.022400, l1: 0.023542, l2: 0.030779, l3: 0.041817, l4: 0.072278, l5: 0.140202, l6: 0.429147\n",
      "\n",
      "[epoch: 360/400, batch: 424/1000, ite: 47804] train loss: 1.1721, accuracy: 93.9455%, tar: 0.0251 \n",
      "l0: 0.025182, l1: 0.026078, l2: 0.033599, l3: 0.045536, l4: 0.085250, l5: 0.160447, l6: 0.352980\n",
      "\n",
      "[epoch: 360/400, batch: 432/1000, ite: 47805] train loss: 1.1721, accuracy: 95.1105%, tar: 0.0251 \n",
      "l0: 0.016940, l1: 0.017988, l2: 0.023804, l3: 0.034470, l4: 0.059842, l5: 0.122303, l6: 0.253900\n",
      "\n",
      "[epoch: 360/400, batch: 440/1000, ite: 47806] train loss: 1.1719, accuracy: 96.1492%, tar: 0.0251 \n",
      "l0: 0.020644, l1: 0.022015, l2: 0.028321, l3: 0.044202, l4: 0.091272, l5: 0.167248, l6: 0.363156\n",
      "\n",
      "[epoch: 360/400, batch: 448/1000, ite: 47807] train loss: 1.1718, accuracy: 95.3665%, tar: 0.0251 \n",
      "l0: 0.018731, l1: 0.019267, l2: 0.025198, l3: 0.035874, l4: 0.064889, l5: 0.144684, l6: 0.321802\n",
      "\n",
      "[epoch: 360/400, batch: 456/1000, ite: 47808] train loss: 1.1717, accuracy: 95.5889%, tar: 0.0251 \n",
      "l0: 0.020790, l1: 0.021920, l2: 0.030466, l3: 0.046900, l4: 0.107389, l5: 0.189827, l6: 0.367942\n",
      "\n",
      "[epoch: 360/400, batch: 464/1000, ite: 47809] train loss: 1.1717, accuracy: 95.0920%, tar: 0.0251 \n",
      "l0: 0.018064, l1: 0.019418, l2: 0.027968, l3: 0.045535, l4: 0.093123, l5: 0.197241, l6: 0.375700\n",
      "\n",
      "[epoch: 360/400, batch: 472/1000, ite: 47810] train loss: 1.1717, accuracy: 95.3607%, tar: 0.0251 \n",
      "l0: 0.022956, l1: 0.024135, l2: 0.032133, l3: 0.047805, l4: 0.086464, l5: 0.159573, l6: 0.309096\n",
      "\n",
      "[epoch: 360/400, batch: 480/1000, ite: 47811] train loss: 1.1716, accuracy: 95.6197%, tar: 0.0251 \n",
      "l0: 0.020347, l1: 0.021293, l2: 0.028099, l3: 0.043375, l4: 0.083418, l5: 0.170775, l6: 0.366066\n",
      "\n",
      "[epoch: 360/400, batch: 488/1000, ite: 47812] train loss: 1.1715, accuracy: 95.3678%, tar: 0.0251 \n",
      "l0: 0.018589, l1: 0.019638, l2: 0.026306, l3: 0.038486, l4: 0.072382, l5: 0.150165, l6: 0.331704\n",
      "\n",
      "[epoch: 360/400, batch: 496/1000, ite: 47813] train loss: 1.1714, accuracy: 95.3388%, tar: 0.0251 \n",
      "l0: 0.024572, l1: 0.026605, l2: 0.033995, l3: 0.051625, l4: 0.101554, l5: 0.206114, l6: 0.404596\n",
      "\n",
      "[epoch: 360/400, batch: 504/1000, ite: 47814] train loss: 1.1715, accuracy: 94.2412%, tar: 0.0251 \n",
      "l0: 0.020338, l1: 0.021388, l2: 0.026776, l3: 0.039888, l4: 0.071722, l5: 0.148418, l6: 0.327686\n",
      "\n",
      "[epoch: 360/400, batch: 512/1000, ite: 47815] train loss: 1.1714, accuracy: 95.7146%, tar: 0.0251 \n",
      "l0: 0.034015, l1: 0.035892, l2: 0.045763, l3: 0.071785, l4: 0.139211, l5: 0.309659, l6: 0.574211\n",
      "\n",
      "[epoch: 360/400, batch: 520/1000, ite: 47816] train loss: 1.1717, accuracy: 92.0190%, tar: 0.0251 \n",
      "l0: 0.017718, l1: 0.018683, l2: 0.024157, l3: 0.037469, l4: 0.067045, l5: 0.130373, l6: 0.313760\n",
      "\n",
      "[epoch: 360/400, batch: 528/1000, ite: 47817] train loss: 1.1716, accuracy: 95.6274%, tar: 0.0251 \n",
      "l0: 0.019440, l1: 0.020812, l2: 0.028041, l3: 0.042008, l4: 0.075923, l5: 0.155289, l6: 0.346890\n",
      "\n",
      "[epoch: 360/400, batch: 536/1000, ite: 47818] train loss: 1.1715, accuracy: 95.6108%, tar: 0.0251 \n",
      "l0: 0.022357, l1: 0.024109, l2: 0.031859, l3: 0.046664, l4: 0.085886, l5: 0.206676, l6: 0.435854\n",
      "\n",
      "[epoch: 360/400, batch: 544/1000, ite: 47819] train loss: 1.1716, accuracy: 94.1850%, tar: 0.0251 \n",
      "l0: 0.016635, l1: 0.017319, l2: 0.023540, l3: 0.034460, l4: 0.062237, l5: 0.128124, l6: 0.291872\n",
      "\n",
      "[epoch: 360/400, batch: 552/1000, ite: 47820] train loss: 1.1714, accuracy: 95.9586%, tar: 0.0251 \n",
      "l0: 0.023766, l1: 0.025385, l2: 0.036175, l3: 0.062642, l4: 0.113974, l5: 0.231556, l6: 0.473495\n",
      "\n",
      "[epoch: 360/400, batch: 560/1000, ite: 47821] train loss: 1.1716, accuracy: 93.9989%, tar: 0.0251 \n",
      "l0: 0.027111, l1: 0.028605, l2: 0.036971, l3: 0.052011, l4: 0.097486, l5: 0.204127, l6: 0.425286\n",
      "\n",
      "[epoch: 360/400, batch: 568/1000, ite: 47822] train loss: 1.1716, accuracy: 93.7502%, tar: 0.0251 \n",
      "l0: 0.028901, l1: 0.031596, l2: 0.043425, l3: 0.077480, l4: 0.155925, l5: 0.266296, l6: 0.511898\n",
      "\n",
      "[epoch: 360/400, batch: 576/1000, ite: 47823] train loss: 1.1719, accuracy: 94.1189%, tar: 0.0251 \n",
      "l0: 0.022872, l1: 0.024395, l2: 0.032936, l3: 0.052392, l4: 0.093907, l5: 0.173656, l6: 0.358917\n",
      "\n",
      "[epoch: 360/400, batch: 584/1000, ite: 47824] train loss: 1.1719, accuracy: 94.9390%, tar: 0.0251 \n",
      "l0: 0.016755, l1: 0.017787, l2: 0.025499, l3: 0.043492, l4: 0.083067, l5: 0.141560, l6: 0.323056\n",
      "\n",
      "[epoch: 360/400, batch: 592/1000, ite: 47825] train loss: 1.1718, accuracy: 95.0345%, tar: 0.0251 \n",
      "l0: 0.027451, l1: 0.030304, l2: 0.041279, l3: 0.065909, l4: 0.145879, l5: 0.253504, l6: 0.424818\n",
      "\n",
      "[epoch: 360/400, batch: 600/1000, ite: 47826] train loss: 1.1719, accuracy: 94.8162%, tar: 0.0251 \n",
      "l0: 0.020510, l1: 0.022382, l2: 0.032769, l3: 0.051076, l4: 0.086466, l5: 0.160136, l6: 0.292610\n",
      "\n",
      "[epoch: 360/400, batch: 608/1000, ite: 47827] train loss: 1.1718, accuracy: 95.7403%, tar: 0.0251 \n",
      "l0: 0.027101, l1: 0.028261, l2: 0.036780, l3: 0.058777, l4: 0.115315, l5: 0.217346, l6: 0.367986\n",
      "\n",
      "[epoch: 360/400, batch: 616/1000, ite: 47828] train loss: 1.1718, accuracy: 94.3755%, tar: 0.0251 \n",
      "l0: 0.020194, l1: 0.022053, l2: 0.030115, l3: 0.047293, l4: 0.095569, l5: 0.207209, l6: 0.427410\n",
      "\n",
      "[epoch: 360/400, batch: 624/1000, ite: 47829] train loss: 1.1719, accuracy: 94.8403%, tar: 0.0251 \n",
      "l0: 0.017548, l1: 0.018515, l2: 0.024434, l3: 0.037214, l4: 0.071890, l5: 0.147257, l6: 0.319571\n",
      "\n",
      "[epoch: 360/400, batch: 632/1000, ite: 47830] train loss: 1.1718, accuracy: 95.4329%, tar: 0.0251 \n",
      "l0: 0.021597, l1: 0.023616, l2: 0.032964, l3: 0.054228, l4: 0.109631, l5: 0.204302, l6: 0.342635\n",
      "\n",
      "[epoch: 360/400, batch: 640/1000, ite: 47831] train loss: 1.1717, accuracy: 95.8748%, tar: 0.0251 \n",
      "l0: 0.019889, l1: 0.021064, l2: 0.028545, l3: 0.043500, l4: 0.081052, l5: 0.146251, l6: 0.321223\n",
      "\n",
      "[epoch: 360/400, batch: 648/1000, ite: 47832] train loss: 1.1716, accuracy: 95.1901%, tar: 0.0251 \n",
      "l0: 0.020335, l1: 0.021573, l2: 0.029712, l3: 0.040497, l4: 0.068170, l5: 0.156237, l6: 0.290157\n",
      "\n",
      "[epoch: 360/400, batch: 656/1000, ite: 47833] train loss: 1.1715, accuracy: 95.9015%, tar: 0.0251 \n",
      "l0: 0.023408, l1: 0.025347, l2: 0.033610, l3: 0.050052, l4: 0.093693, l5: 0.191928, l6: 0.394064\n",
      "\n",
      "[epoch: 360/400, batch: 664/1000, ite: 47834] train loss: 1.1715, accuracy: 95.1587%, tar: 0.0251 \n",
      "l0: 0.021606, l1: 0.022574, l2: 0.029440, l3: 0.042210, l4: 0.074270, l5: 0.170252, l6: 0.327793\n",
      "\n",
      "[epoch: 360/400, batch: 672/1000, ite: 47835] train loss: 1.1714, accuracy: 95.2351%, tar: 0.0251 \n",
      "l0: 0.022087, l1: 0.024358, l2: 0.033992, l3: 0.060723, l4: 0.132115, l5: 0.204769, l6: 0.423209\n",
      "\n",
      "[epoch: 360/400, batch: 680/1000, ite: 47836] train loss: 1.1715, accuracy: 95.1028%, tar: 0.0251 \n",
      "l0: 0.019121, l1: 0.021039, l2: 0.029378, l3: 0.044877, l4: 0.079413, l5: 0.176666, l6: 0.455552\n",
      "\n",
      "[epoch: 360/400, batch: 688/1000, ite: 47837] train loss: 1.1716, accuracy: 94.9404%, tar: 0.0251 \n",
      "l0: 0.020332, l1: 0.021068, l2: 0.028736, l3: 0.040386, l4: 0.080580, l5: 0.152460, l6: 0.307971\n",
      "\n",
      "[epoch: 360/400, batch: 696/1000, ite: 47838] train loss: 1.1715, accuracy: 95.1271%, tar: 0.0251 \n",
      "l0: 0.018304, l1: 0.019466, l2: 0.025427, l3: 0.039395, l4: 0.073338, l5: 0.146192, l6: 0.336084\n",
      "\n",
      "[epoch: 360/400, batch: 704/1000, ite: 47839] train loss: 1.1714, accuracy: 95.0373%, tar: 0.0251 \n",
      "l0: 0.028798, l1: 0.031022, l2: 0.040857, l3: 0.066535, l4: 0.133781, l5: 0.242468, l6: 0.450687\n",
      "\n",
      "[epoch: 360/400, batch: 712/1000, ite: 47840] train loss: 1.1715, accuracy: 93.6672%, tar: 0.0251 \n",
      "l0: 0.020266, l1: 0.021651, l2: 0.029083, l3: 0.042951, l4: 0.079135, l5: 0.171861, l6: 0.362568\n",
      "\n",
      "[epoch: 360/400, batch: 720/1000, ite: 47841] train loss: 1.1715, accuracy: 95.7944%, tar: 0.0251 \n",
      "l0: 0.020394, l1: 0.021277, l2: 0.028488, l3: 0.042158, l4: 0.075106, l5: 0.162656, l6: 0.348365\n",
      "\n",
      "[epoch: 360/400, batch: 728/1000, ite: 47842] train loss: 1.1714, accuracy: 95.3416%, tar: 0.0251 \n",
      "l0: 0.026640, l1: 0.027636, l2: 0.035646, l3: 0.052246, l4: 0.091304, l5: 0.189798, l6: 0.343095\n",
      "\n",
      "[epoch: 360/400, batch: 736/1000, ite: 47843] train loss: 1.1714, accuracy: 94.2357%, tar: 0.0251 \n",
      "l0: 0.025949, l1: 0.026992, l2: 0.034807, l3: 0.052047, l4: 0.100842, l5: 0.199129, l6: 0.416543\n",
      "\n",
      "[epoch: 360/400, batch: 744/1000, ite: 47844] train loss: 1.1714, accuracy: 93.9610%, tar: 0.0251 \n",
      "l0: 0.020971, l1: 0.021712, l2: 0.029754, l3: 0.043150, l4: 0.076611, l5: 0.158356, l6: 0.347082\n",
      "\n",
      "[epoch: 360/400, batch: 752/1000, ite: 47845] train loss: 1.1714, accuracy: 95.1021%, tar: 0.0250 \n",
      "l0: 0.016406, l1: 0.017345, l2: 0.024579, l3: 0.036516, l4: 0.064876, l5: 0.116469, l6: 0.267038\n",
      "\n",
      "[epoch: 360/400, batch: 760/1000, ite: 47846] train loss: 1.1712, accuracy: 96.3324%, tar: 0.0250 \n",
      "l0: 0.019856, l1: 0.021695, l2: 0.030811, l3: 0.048962, l4: 0.092284, l5: 0.194218, l6: 0.358428\n",
      "\n",
      "[epoch: 360/400, batch: 768/1000, ite: 47847] train loss: 1.1712, accuracy: 95.6076%, tar: 0.0250 \n",
      "l0: 0.026744, l1: 0.028495, l2: 0.037440, l3: 0.050888, l4: 0.081572, l5: 0.155379, l6: 0.333233\n",
      "\n",
      "[epoch: 360/400, batch: 776/1000, ite: 47848] train loss: 1.1711, accuracy: 95.5965%, tar: 0.0250 \n",
      "l0: 0.029592, l1: 0.031877, l2: 0.044701, l3: 0.070101, l4: 0.132334, l5: 0.275063, l6: 0.565695\n",
      "\n",
      "[epoch: 360/400, batch: 784/1000, ite: 47849] train loss: 1.1714, accuracy: 93.6221%, tar: 0.0250 \n",
      "l0: 0.018124, l1: 0.018947, l2: 0.025928, l3: 0.039123, l4: 0.071861, l5: 0.132607, l6: 0.274808\n",
      "\n",
      "[epoch: 360/400, batch: 792/1000, ite: 47850] train loss: 1.1712, accuracy: 95.4546%, tar: 0.0250 \n",
      "l0: 0.016509, l1: 0.018042, l2: 0.026423, l3: 0.039451, l4: 0.068053, l5: 0.139215, l6: 0.309938\n",
      "\n",
      "[epoch: 360/400, batch: 800/1000, ite: 47851] train loss: 1.1711, accuracy: 96.5593%, tar: 0.0250 \n",
      "l0: 0.015600, l1: 0.016848, l2: 0.023435, l3: 0.037999, l4: 0.069077, l5: 0.123000, l6: 0.247479\n",
      "\n",
      "[epoch: 360/400, batch: 808/1000, ite: 47852] train loss: 1.1709, accuracy: 96.4132%, tar: 0.0250 \n",
      "l0: 0.019602, l1: 0.020821, l2: 0.028235, l3: 0.043536, l4: 0.072948, l5: 0.135347, l6: 0.284905\n",
      "\n",
      "[epoch: 360/400, batch: 816/1000, ite: 47853] train loss: 1.1707, accuracy: 95.7708%, tar: 0.0250 \n",
      "l0: 0.022463, l1: 0.023470, l2: 0.030363, l3: 0.049098, l4: 0.092767, l5: 0.171699, l6: 0.344138\n",
      "\n",
      "[epoch: 360/400, batch: 824/1000, ite: 47854] train loss: 1.1707, accuracy: 94.8492%, tar: 0.0250 \n",
      "l0: 0.024082, l1: 0.024793, l2: 0.029709, l3: 0.037096, l4: 0.053966, l5: 0.102865, l6: 0.248866\n",
      "\n",
      "[epoch: 360/400, batch: 832/1000, ite: 47855] train loss: 1.1705, accuracy: 96.3906%, tar: 0.0250 \n",
      "l0: 0.023668, l1: 0.024777, l2: 0.030732, l3: 0.045609, l4: 0.079651, l5: 0.156117, l6: 0.318450\n",
      "\n",
      "[epoch: 360/400, batch: 840/1000, ite: 47856] train loss: 1.1704, accuracy: 94.8753%, tar: 0.0250 \n",
      "l0: 0.020638, l1: 0.021237, l2: 0.027371, l3: 0.037162, l4: 0.063822, l5: 0.117953, l6: 0.256545\n",
      "\n",
      "[epoch: 360/400, batch: 848/1000, ite: 47857] train loss: 1.1702, accuracy: 95.8561%, tar: 0.0250 \n",
      "l0: 0.025173, l1: 0.025879, l2: 0.030597, l3: 0.041686, l4: 0.069753, l5: 0.162542, l6: 0.332418\n",
      "\n",
      "[epoch: 360/400, batch: 856/1000, ite: 47858] train loss: 1.1701, accuracy: 94.9234%, tar: 0.0250 \n",
      "l0: 0.025721, l1: 0.026713, l2: 0.034158, l3: 0.050133, l4: 0.085748, l5: 0.193739, l6: 0.416845\n",
      "\n",
      "[epoch: 360/400, batch: 864/1000, ite: 47859] train loss: 1.1702, accuracy: 93.8567%, tar: 0.0250 \n",
      "l0: 0.019282, l1: 0.020468, l2: 0.027348, l3: 0.039355, l4: 0.068462, l5: 0.127168, l6: 0.331682\n",
      "\n",
      "[epoch: 360/400, batch: 872/1000, ite: 47860] train loss: 1.1701, accuracy: 95.5299%, tar: 0.0250 \n",
      "l0: 0.022246, l1: 0.023264, l2: 0.031260, l3: 0.045148, l4: 0.082290, l5: 0.158743, l6: 0.400263\n",
      "\n",
      "[epoch: 360/400, batch: 880/1000, ite: 47861] train loss: 1.1701, accuracy: 94.8762%, tar: 0.0250 \n",
      "l0: 0.025563, l1: 0.026565, l2: 0.035600, l3: 0.051082, l4: 0.096604, l5: 0.217141, l6: 0.477129\n",
      "\n",
      "[epoch: 360/400, batch: 888/1000, ite: 47862] train loss: 1.1702, accuracy: 92.9236%, tar: 0.0250 \n",
      "l0: 0.016873, l1: 0.017568, l2: 0.024902, l3: 0.036989, l4: 0.062998, l5: 0.117667, l6: 0.237607\n",
      "\n",
      "[epoch: 360/400, batch: 896/1000, ite: 47863] train loss: 1.1700, accuracy: 96.4835%, tar: 0.0250 \n",
      "l0: 0.019122, l1: 0.020024, l2: 0.024632, l3: 0.034842, l4: 0.059031, l5: 0.102116, l6: 0.224235\n",
      "\n",
      "[epoch: 360/400, batch: 904/1000, ite: 47864] train loss: 1.1697, accuracy: 96.3732%, tar: 0.0250 \n",
      "l0: 0.025486, l1: 0.026988, l2: 0.033749, l3: 0.050651, l4: 0.091982, l5: 0.194525, l6: 0.425540\n",
      "\n",
      "[epoch: 360/400, batch: 912/1000, ite: 47865] train loss: 1.1698, accuracy: 93.9574%, tar: 0.0250 \n",
      "l0: 0.021612, l1: 0.022995, l2: 0.030287, l3: 0.043065, l4: 0.078902, l5: 0.186441, l6: 0.426242\n",
      "\n",
      "[epoch: 360/400, batch: 920/1000, ite: 47866] train loss: 1.1698, accuracy: 93.9905%, tar: 0.0250 \n",
      "l0: 0.022479, l1: 0.023795, l2: 0.031558, l3: 0.046312, l4: 0.081798, l5: 0.172745, l6: 0.510877\n",
      "\n",
      "[epoch: 360/400, batch: 928/1000, ite: 47867] train loss: 1.1699, accuracy: 94.4429%, tar: 0.0250 \n",
      "l0: 0.024383, l1: 0.026607, l2: 0.036655, l3: 0.056154, l4: 0.103988, l5: 0.245977, l6: 0.508328\n",
      "\n",
      "[epoch: 360/400, batch: 936/1000, ite: 47868] train loss: 1.1701, accuracy: 94.0128%, tar: 0.0250 \n",
      "l0: 0.024021, l1: 0.025910, l2: 0.036184, l3: 0.057014, l4: 0.098224, l5: 0.196482, l6: 0.399896\n",
      "\n",
      "[epoch: 360/400, batch: 944/1000, ite: 47869] train loss: 1.1702, accuracy: 94.4787%, tar: 0.0250 \n",
      "l0: 0.022198, l1: 0.023490, l2: 0.032316, l3: 0.050185, l4: 0.094494, l5: 0.190161, l6: 0.389427\n",
      "\n",
      "[epoch: 360/400, batch: 952/1000, ite: 47870] train loss: 1.1702, accuracy: 94.6780%, tar: 0.0250 \n",
      "l0: 0.026378, l1: 0.027451, l2: 0.034927, l3: 0.050224, l4: 0.090480, l5: 0.211690, l6: 0.411144\n",
      "\n",
      "[epoch: 360/400, batch: 960/1000, ite: 47871] train loss: 1.1702, accuracy: 93.7741%, tar: 0.0250 \n",
      "l0: 0.027845, l1: 0.028612, l2: 0.036589, l3: 0.054855, l4: 0.097123, l5: 0.170250, l6: 0.310653\n",
      "\n",
      "[epoch: 360/400, batch: 968/1000, ite: 47872] train loss: 1.1702, accuracy: 94.5932%, tar: 0.0250 \n",
      "l0: 0.024326, l1: 0.026085, l2: 0.034240, l3: 0.051138, l4: 0.099153, l5: 0.219263, l6: 0.426462\n",
      "\n",
      "[epoch: 360/400, batch: 976/1000, ite: 47873] train loss: 1.1702, accuracy: 94.4449%, tar: 0.0250 \n",
      "l0: 0.019382, l1: 0.020359, l2: 0.028731, l3: 0.043286, l4: 0.069256, l5: 0.127452, l6: 0.268567\n",
      "\n",
      "[epoch: 360/400, batch: 984/1000, ite: 47874] train loss: 1.1701, accuracy: 95.5870%, tar: 0.0250 \n",
      "l0: 0.018663, l1: 0.019503, l2: 0.027223, l3: 0.042152, l4: 0.069707, l5: 0.123276, l6: 0.247538\n",
      "\n",
      "[epoch: 360/400, batch: 992/1000, ite: 47875] train loss: 1.1699, accuracy: 96.1138%, tar: 0.0250 \n",
      "l0: 0.017736, l1: 0.019640, l2: 0.026656, l3: 0.042683, l4: 0.078149, l5: 0.195864, l6: 0.436674\n",
      "\n",
      "[epoch: 360/400, batch: 1000/1000, ite: 47876] train loss: 1.1699, accuracy: 95.6985%, tar: 0.0250 \n",
      "l0: 0.018428, l1: 0.019633, l2: 0.027762, l3: 0.044915, l4: 0.085523, l5: 0.179370, l6: 0.376605\n",
      "\n",
      "[epoch: 361/400, batch: 8/1000, ite: 47877] train loss: 1.1699, accuracy: 95.0886%, tar: 0.0250 \n",
      "l0: 0.017036, l1: 0.018582, l2: 0.026101, l3: 0.046229, l4: 0.087513, l5: 0.153866, l6: 0.343327\n",
      "\n",
      "[epoch: 361/400, batch: 16/1000, ite: 47878] train loss: 1.1698, accuracy: 95.8524%, tar: 0.0250 \n",
      "l0: 0.018930, l1: 0.020426, l2: 0.029765, l3: 0.044156, l4: 0.080196, l5: 0.157555, l6: 0.341667\n",
      "\n",
      "[epoch: 361/400, batch: 24/1000, ite: 47879] train loss: 1.1697, accuracy: 95.6279%, tar: 0.0250 \n",
      "l0: 0.021576, l1: 0.023142, l2: 0.031169, l3: 0.047498, l4: 0.108522, l5: 0.191544, l6: 0.333126\n",
      "\n",
      "[epoch: 361/400, batch: 32/1000, ite: 47880] train loss: 1.1697, accuracy: 95.4736%, tar: 0.0250 \n",
      "l0: 0.028777, l1: 0.030444, l2: 0.039522, l3: 0.064286, l4: 0.121439, l5: 0.244849, l6: 0.425799\n",
      "\n",
      "[epoch: 361/400, batch: 40/1000, ite: 47881] train loss: 1.1698, accuracy: 94.6471%, tar: 0.0250 \n",
      "l0: 0.022657, l1: 0.024008, l2: 0.031823, l3: 0.047720, l4: 0.084617, l5: 0.182377, l6: 0.337724\n",
      "\n",
      "[epoch: 361/400, batch: 48/1000, ite: 47882] train loss: 1.1698, accuracy: 95.6837%, tar: 0.0250 \n",
      "l0: 0.022111, l1: 0.023589, l2: 0.030922, l3: 0.046879, l4: 0.087327, l5: 0.181123, l6: 0.382700\n",
      "\n",
      "[epoch: 361/400, batch: 56/1000, ite: 47883] train loss: 1.1698, accuracy: 94.8714%, tar: 0.0250 \n",
      "l0: 0.018933, l1: 0.020284, l2: 0.029614, l3: 0.047819, l4: 0.083512, l5: 0.172005, l6: 0.354745\n",
      "\n",
      "[epoch: 361/400, batch: 64/1000, ite: 47884] train loss: 1.1697, accuracy: 95.2578%, tar: 0.0250 \n",
      "l0: 0.023457, l1: 0.024350, l2: 0.030224, l3: 0.043514, l4: 0.085991, l5: 0.182460, l6: 0.389596\n",
      "\n",
      "[epoch: 361/400, batch: 72/1000, ite: 47885] train loss: 1.1697, accuracy: 94.2723%, tar: 0.0250 \n",
      "l0: 0.024223, l1: 0.025181, l2: 0.033663, l3: 0.049930, l4: 0.094411, l5: 0.172556, l6: 0.341988\n",
      "\n",
      "[epoch: 361/400, batch: 80/1000, ite: 47886] train loss: 1.1697, accuracy: 94.7972%, tar: 0.0250 \n",
      "l0: 0.018536, l1: 0.019331, l2: 0.025591, l3: 0.036828, l4: 0.058568, l5: 0.112613, l6: 0.224785\n",
      "\n",
      "[epoch: 361/400, batch: 88/1000, ite: 47887] train loss: 1.1694, accuracy: 96.4407%, tar: 0.0250 \n",
      "l0: 0.028926, l1: 0.030794, l2: 0.040390, l3: 0.058967, l4: 0.112254, l5: 0.246814, l6: 0.513488\n",
      "\n",
      "[epoch: 361/400, batch: 96/1000, ite: 47888] train loss: 1.1696, accuracy: 93.6791%, tar: 0.0250 \n",
      "l0: 0.025482, l1: 0.026558, l2: 0.036716, l3: 0.054070, l4: 0.096876, l5: 0.192044, l6: 0.469071\n",
      "\n",
      "[epoch: 361/400, batch: 104/1000, ite: 47889] train loss: 1.1697, accuracy: 94.3880%, tar: 0.0250 \n",
      "l0: 0.024809, l1: 0.025885, l2: 0.036657, l3: 0.055463, l4: 0.104418, l5: 0.249794, l6: 0.440763\n",
      "\n",
      "[epoch: 361/400, batch: 112/1000, ite: 47890] train loss: 1.1699, accuracy: 94.0563%, tar: 0.0250 \n",
      "l0: 0.021442, l1: 0.023035, l2: 0.030863, l3: 0.046347, l4: 0.093243, l5: 0.211486, l6: 0.446283\n",
      "\n",
      "[epoch: 361/400, batch: 120/1000, ite: 47891] train loss: 1.1699, accuracy: 94.2819%, tar: 0.0250 \n",
      "l0: 0.018514, l1: 0.019887, l2: 0.027462, l3: 0.040919, l4: 0.076985, l5: 0.166203, l6: 0.401918\n",
      "\n",
      "[epoch: 361/400, batch: 128/1000, ite: 47892] train loss: 1.1699, accuracy: 95.2514%, tar: 0.0250 \n",
      "l0: 0.025494, l1: 0.028342, l2: 0.038501, l3: 0.066165, l4: 0.136393, l5: 0.229345, l6: 0.421103\n",
      "\n",
      "[epoch: 361/400, batch: 136/1000, ite: 47893] train loss: 1.1700, accuracy: 94.5652%, tar: 0.0250 \n",
      "l0: 0.018419, l1: 0.020069, l2: 0.028919, l3: 0.047407, l4: 0.105060, l5: 0.202403, l6: 0.380504\n",
      "\n",
      "[epoch: 361/400, batch: 144/1000, ite: 47894] train loss: 1.1701, accuracy: 95.3256%, tar: 0.0250 \n",
      "l0: 0.025867, l1: 0.027702, l2: 0.035764, l3: 0.054178, l4: 0.097716, l5: 0.201716, l6: 0.400743\n",
      "\n",
      "[epoch: 361/400, batch: 152/1000, ite: 47895] train loss: 1.1701, accuracy: 94.7648%, tar: 0.0250 \n",
      "l0: 0.018447, l1: 0.019769, l2: 0.027629, l3: 0.044305, l4: 0.107450, l5: 0.217341, l6: 0.410812\n",
      "\n",
      "[epoch: 361/400, batch: 160/1000, ite: 47896] train loss: 1.1701, accuracy: 94.7905%, tar: 0.0250 \n",
      "l0: 0.020153, l1: 0.021516, l2: 0.030277, l3: 0.048614, l4: 0.107636, l5: 0.201754, l6: 0.447453\n",
      "\n",
      "[epoch: 361/400, batch: 168/1000, ite: 47897] train loss: 1.1702, accuracy: 94.4903%, tar: 0.0250 \n",
      "l0: 0.027070, l1: 0.028228, l2: 0.035822, l3: 0.050506, l4: 0.080220, l5: 0.147197, l6: 0.350218\n",
      "\n",
      "[epoch: 361/400, batch: 176/1000, ite: 47898] train loss: 1.1702, accuracy: 94.4323%, tar: 0.0250 \n",
      "l0: 0.021789, l1: 0.023174, l2: 0.034050, l3: 0.056383, l4: 0.117697, l5: 0.239111, l6: 0.446169\n",
      "\n",
      "[epoch: 361/400, batch: 184/1000, ite: 47899] train loss: 1.1703, accuracy: 94.0570%, tar: 0.0250 \n",
      "l0: 0.014601, l1: 0.015829, l2: 0.020932, l3: 0.032533, l4: 0.064048, l5: 0.141929, l6: 0.338300\n",
      "\n",
      "[epoch: 361/400, batch: 192/1000, ite: 47900] train loss: 1.1702, accuracy: 96.4295%, tar: 0.0250 \n",
      "l0: 0.023049, l1: 0.024274, l2: 0.031688, l3: 0.045137, l4: 0.086319, l5: 0.165243, l6: 0.352866\n",
      "\n",
      "[epoch: 361/400, batch: 200/1000, ite: 47901] train loss: 1.1701, accuracy: 94.8316%, tar: 0.0250 \n",
      "l0: 0.021799, l1: 0.022829, l2: 0.028750, l3: 0.040845, l4: 0.071792, l5: 0.145447, l6: 0.291810\n",
      "\n",
      "[epoch: 361/400, batch: 208/1000, ite: 47902] train loss: 1.1700, accuracy: 95.2702%, tar: 0.0250 \n",
      "l0: 0.017545, l1: 0.018442, l2: 0.025946, l3: 0.036462, l4: 0.061833, l5: 0.108089, l6: 0.205780\n",
      "\n",
      "[epoch: 361/400, batch: 216/1000, ite: 47903] train loss: 1.1698, accuracy: 96.4997%, tar: 0.0250 \n",
      "l0: 0.023237, l1: 0.024825, l2: 0.030860, l3: 0.049255, l4: 0.099188, l5: 0.205504, l6: 0.493742\n",
      "\n",
      "[epoch: 361/400, batch: 224/1000, ite: 47904] train loss: 1.1699, accuracy: 93.6217%, tar: 0.0250 \n",
      "l0: 0.018607, l1: 0.020239, l2: 0.028886, l3: 0.045839, l4: 0.097824, l5: 0.229758, l6: 0.407592\n",
      "\n",
      "[epoch: 361/400, batch: 232/1000, ite: 47905] train loss: 1.1700, accuracy: 94.7659%, tar: 0.0249 \n",
      "l0: 0.021817, l1: 0.022861, l2: 0.029470, l3: 0.044703, l4: 0.089613, l5: 0.190344, l6: 0.424130\n",
      "\n",
      "[epoch: 361/400, batch: 240/1000, ite: 47906] train loss: 1.1700, accuracy: 94.1331%, tar: 0.0249 \n",
      "l0: 0.022538, l1: 0.024648, l2: 0.033110, l3: 0.049156, l4: 0.093847, l5: 0.206807, l6: 0.359011\n",
      "\n",
      "[epoch: 361/400, batch: 248/1000, ite: 47907] train loss: 1.1700, accuracy: 95.1446%, tar: 0.0249 \n",
      "l0: 0.020489, l1: 0.021630, l2: 0.028323, l3: 0.039659, l4: 0.064384, l5: 0.121028, l6: 0.265420\n",
      "\n",
      "[epoch: 361/400, batch: 256/1000, ite: 47908] train loss: 1.1698, accuracy: 95.8026%, tar: 0.0249 \n",
      "l0: 0.019351, l1: 0.020279, l2: 0.027263, l3: 0.042196, l4: 0.074523, l5: 0.144672, l6: 0.338725\n",
      "\n",
      "[epoch: 361/400, batch: 264/1000, ite: 47909] train loss: 1.1697, accuracy: 95.4562%, tar: 0.0249 \n",
      "l0: 0.020812, l1: 0.021921, l2: 0.029913, l3: 0.042298, l4: 0.075556, l5: 0.209836, l6: 0.357274\n",
      "\n",
      "[epoch: 361/400, batch: 272/1000, ite: 47910] train loss: 1.1697, accuracy: 94.4098%, tar: 0.0249 \n",
      "l0: 0.022784, l1: 0.024375, l2: 0.032549, l3: 0.051267, l4: 0.087019, l5: 0.169345, l6: 0.333354\n",
      "\n",
      "[epoch: 361/400, batch: 280/1000, ite: 47911] train loss: 1.1696, accuracy: 95.1789%, tar: 0.0249 \n",
      "l0: 0.019508, l1: 0.020821, l2: 0.027190, l3: 0.038769, l4: 0.073225, l5: 0.148393, l6: 0.299658\n",
      "\n",
      "[epoch: 361/400, batch: 288/1000, ite: 47912] train loss: 1.1695, accuracy: 96.2032%, tar: 0.0249 \n",
      "l0: 0.023737, l1: 0.024583, l2: 0.032316, l3: 0.049639, l4: 0.097621, l5: 0.216396, l6: 0.433418\n",
      "\n",
      "[epoch: 361/400, batch: 296/1000, ite: 47913] train loss: 1.1696, accuracy: 93.6215%, tar: 0.0249 \n",
      "l0: 0.016230, l1: 0.017328, l2: 0.025006, l3: 0.038732, l4: 0.070179, l5: 0.143113, l6: 0.288777\n",
      "\n",
      "[epoch: 361/400, batch: 304/1000, ite: 47914] train loss: 1.1694, accuracy: 96.3020%, tar: 0.0249 \n",
      "l0: 0.022725, l1: 0.024500, l2: 0.034250, l3: 0.053116, l4: 0.096336, l5: 0.207478, l6: 0.402321\n",
      "\n",
      "[epoch: 361/400, batch: 312/1000, ite: 47915] train loss: 1.1695, accuracy: 95.0181%, tar: 0.0249 \n",
      "l0: 0.023226, l1: 0.024808, l2: 0.032764, l3: 0.051616, l4: 0.109840, l5: 0.224851, l6: 0.469597\n",
      "\n",
      "[epoch: 361/400, batch: 320/1000, ite: 47916] train loss: 1.1696, accuracy: 94.6010%, tar: 0.0249 \n",
      "l0: 0.019433, l1: 0.020208, l2: 0.026773, l3: 0.037187, l4: 0.063089, l5: 0.125058, l6: 0.287009\n",
      "\n",
      "[epoch: 361/400, batch: 328/1000, ite: 47917] train loss: 1.1695, accuracy: 95.4154%, tar: 0.0249 \n",
      "l0: 0.024226, l1: 0.025313, l2: 0.031477, l3: 0.041273, l4: 0.063771, l5: 0.139237, l6: 0.237362\n",
      "\n",
      "[epoch: 361/400, batch: 336/1000, ite: 47918] train loss: 1.1693, accuracy: 96.0609%, tar: 0.0249 \n",
      "l0: 0.022991, l1: 0.024442, l2: 0.034228, l3: 0.059894, l4: 0.113716, l5: 0.233391, l6: 0.422008\n",
      "\n",
      "[epoch: 361/400, batch: 344/1000, ite: 47919] train loss: 1.1694, accuracy: 94.1180%, tar: 0.0249 \n",
      "l0: 0.025199, l1: 0.026454, l2: 0.035319, l3: 0.050099, l4: 0.091774, l5: 0.222502, l6: 0.470043\n",
      "\n",
      "[epoch: 361/400, batch: 352/1000, ite: 47920] train loss: 1.1695, accuracy: 93.7956%, tar: 0.0249 \n",
      "l0: 0.023488, l1: 0.025544, l2: 0.035076, l3: 0.063406, l4: 0.125905, l5: 0.201039, l6: 0.371701\n",
      "\n",
      "[epoch: 361/400, batch: 360/1000, ite: 47921] train loss: 1.1695, accuracy: 94.8765%, tar: 0.0249 \n",
      "l0: 0.016376, l1: 0.017256, l2: 0.022682, l3: 0.033079, l4: 0.057085, l5: 0.120091, l6: 0.265137\n",
      "\n",
      "[epoch: 361/400, batch: 368/1000, ite: 47922] train loss: 1.1693, accuracy: 96.0266%, tar: 0.0249 \n",
      "l0: 0.020326, l1: 0.021475, l2: 0.029371, l3: 0.042657, l4: 0.073399, l5: 0.132019, l6: 0.341362\n",
      "\n",
      "[epoch: 361/400, batch: 376/1000, ite: 47923] train loss: 1.1692, accuracy: 95.1490%, tar: 0.0249 \n",
      "l0: 0.023318, l1: 0.024908, l2: 0.033978, l3: 0.049542, l4: 0.087212, l5: 0.156304, l6: 0.308266\n",
      "\n",
      "[epoch: 361/400, batch: 384/1000, ite: 47924] train loss: 1.1691, accuracy: 95.1102%, tar: 0.0249 \n",
      "l0: 0.022450, l1: 0.024193, l2: 0.033891, l3: 0.055644, l4: 0.102045, l5: 0.192578, l6: 0.414545\n",
      "\n",
      "[epoch: 361/400, batch: 392/1000, ite: 47925] train loss: 1.1692, accuracy: 94.7133%, tar: 0.0249 \n",
      "l0: 0.020065, l1: 0.020857, l2: 0.027106, l3: 0.039450, l4: 0.068643, l5: 0.139405, l6: 0.348935\n",
      "\n",
      "[epoch: 361/400, batch: 400/1000, ite: 47926] train loss: 1.1691, accuracy: 95.0326%, tar: 0.0249 \n",
      "l0: 0.017186, l1: 0.017566, l2: 0.023026, l3: 0.034890, l4: 0.065973, l5: 0.130072, l6: 0.305975\n",
      "\n",
      "[epoch: 361/400, batch: 408/1000, ite: 47927] train loss: 1.1690, accuracy: 95.3631%, tar: 0.0249 \n",
      "l0: 0.018418, l1: 0.020421, l2: 0.028065, l3: 0.046434, l4: 0.097215, l5: 0.222044, l6: 0.547312\n",
      "\n",
      "[epoch: 361/400, batch: 416/1000, ite: 47928] train loss: 1.1691, accuracy: 93.5380%, tar: 0.0249 \n",
      "l0: 0.031394, l1: 0.034071, l2: 0.049279, l3: 0.077183, l4: 0.130738, l5: 0.266461, l6: 0.515136\n",
      "\n",
      "[epoch: 361/400, batch: 424/1000, ite: 47929] train loss: 1.1694, accuracy: 93.7437%, tar: 0.0249 \n",
      "l0: 0.027980, l1: 0.029777, l2: 0.039132, l3: 0.062358, l4: 0.116771, l5: 0.254773, l6: 0.446242\n",
      "\n",
      "[epoch: 361/400, batch: 432/1000, ite: 47930] train loss: 1.1695, accuracy: 94.0536%, tar: 0.0249 \n",
      "l0: 0.019731, l1: 0.020720, l2: 0.028442, l3: 0.039934, l4: 0.066623, l5: 0.112586, l6: 0.219760\n",
      "\n",
      "[epoch: 361/400, batch: 440/1000, ite: 47931] train loss: 1.1693, accuracy: 96.4806%, tar: 0.0249 \n",
      "l0: 0.028642, l1: 0.029639, l2: 0.038440, l3: 0.053662, l4: 0.102654, l5: 0.234195, l6: 0.523547\n",
      "\n",
      "[epoch: 361/400, batch: 448/1000, ite: 47932] train loss: 1.1695, accuracy: 93.2617%, tar: 0.0249 \n",
      "l0: 0.026342, l1: 0.028561, l2: 0.037620, l3: 0.054692, l4: 0.102598, l5: 0.212552, l6: 0.448632\n",
      "\n",
      "[epoch: 361/400, batch: 456/1000, ite: 47933] train loss: 1.1696, accuracy: 94.7146%, tar: 0.0249 \n",
      "l0: 0.015956, l1: 0.017045, l2: 0.023614, l3: 0.038048, l4: 0.073798, l5: 0.159010, l6: 0.301108\n",
      "\n",
      "[epoch: 361/400, batch: 464/1000, ite: 47934] train loss: 1.1695, accuracy: 96.1503%, tar: 0.0249 \n",
      "l0: 0.016278, l1: 0.016900, l2: 0.022902, l3: 0.033338, l4: 0.055398, l5: 0.111231, l6: 0.252508\n",
      "\n",
      "[epoch: 361/400, batch: 472/1000, ite: 47935] train loss: 1.1692, accuracy: 96.1687%, tar: 0.0249 \n",
      "l0: 0.020614, l1: 0.021723, l2: 0.028755, l3: 0.040246, l4: 0.068502, l5: 0.142243, l6: 0.329347\n",
      "\n",
      "[epoch: 361/400, batch: 480/1000, ite: 47936] train loss: 1.1692, accuracy: 95.4590%, tar: 0.0249 \n",
      "l0: 0.018868, l1: 0.020509, l2: 0.029148, l3: 0.045850, l4: 0.090536, l5: 0.165418, l6: 0.358672\n",
      "\n",
      "[epoch: 361/400, batch: 488/1000, ite: 47937] train loss: 1.1691, accuracy: 95.5607%, tar: 0.0249 \n",
      "l0: 0.021697, l1: 0.022697, l2: 0.030307, l3: 0.047518, l4: 0.091195, l5: 0.197594, l6: 0.354347\n",
      "\n",
      "[epoch: 361/400, batch: 496/1000, ite: 47938] train loss: 1.1691, accuracy: 94.1413%, tar: 0.0249 \n",
      "l0: 0.018437, l1: 0.019355, l2: 0.028098, l3: 0.044696, l4: 0.074383, l5: 0.162020, l6: 0.303283\n",
      "\n",
      "[epoch: 361/400, batch: 504/1000, ite: 47939] train loss: 1.1690, accuracy: 95.6231%, tar: 0.0249 \n",
      "l0: 0.021721, l1: 0.022579, l2: 0.028437, l3: 0.041830, l4: 0.070396, l5: 0.132663, l6: 0.288019\n",
      "\n",
      "[epoch: 361/400, batch: 512/1000, ite: 47940] train loss: 1.1688, accuracy: 95.6164%, tar: 0.0249 \n",
      "l0: 0.017903, l1: 0.018588, l2: 0.023207, l3: 0.031027, l4: 0.050048, l5: 0.099248, l6: 0.224675\n",
      "\n",
      "[epoch: 361/400, batch: 520/1000, ite: 47941] train loss: 1.1686, accuracy: 96.5830%, tar: 0.0249 \n",
      "l0: 0.020050, l1: 0.021961, l2: 0.029547, l3: 0.049160, l4: 0.100883, l5: 0.186794, l6: 0.371619\n",
      "\n",
      "[epoch: 361/400, batch: 528/1000, ite: 47942] train loss: 1.1686, accuracy: 95.1370%, tar: 0.0249 \n",
      "l0: 0.030089, l1: 0.031759, l2: 0.042930, l3: 0.061533, l4: 0.111612, l5: 0.233290, l6: 0.450613\n",
      "\n",
      "[epoch: 361/400, batch: 536/1000, ite: 47943] train loss: 1.1687, accuracy: 93.7046%, tar: 0.0249 \n",
      "l0: 0.018741, l1: 0.019665, l2: 0.026610, l3: 0.040422, l4: 0.071627, l5: 0.139834, l6: 0.288005\n",
      "\n",
      "[epoch: 361/400, batch: 544/1000, ite: 47944] train loss: 1.1686, accuracy: 95.5465%, tar: 0.0249 \n",
      "l0: 0.020978, l1: 0.022079, l2: 0.030913, l3: 0.047698, l4: 0.093282, l5: 0.212907, l6: 0.467903\n",
      "\n",
      "[epoch: 361/400, batch: 552/1000, ite: 47945] train loss: 1.1687, accuracy: 93.5662%, tar: 0.0249 \n",
      "l0: 0.026259, l1: 0.028121, l2: 0.036265, l3: 0.054591, l4: 0.107228, l5: 0.240573, l6: 0.421337\n",
      "\n",
      "[epoch: 361/400, batch: 560/1000, ite: 47946] train loss: 1.1688, accuracy: 94.0707%, tar: 0.0249 \n",
      "l0: 0.018860, l1: 0.019938, l2: 0.026392, l3: 0.039497, l4: 0.078865, l5: 0.175483, l6: 0.350717\n",
      "\n",
      "[epoch: 361/400, batch: 568/1000, ite: 47947] train loss: 1.1687, accuracy: 95.0182%, tar: 0.0249 \n",
      "l0: 0.025358, l1: 0.026871, l2: 0.034677, l3: 0.051049, l4: 0.091838, l5: 0.234378, l6: 0.439165\n",
      "\n",
      "[epoch: 361/400, batch: 576/1000, ite: 47948] train loss: 1.1688, accuracy: 94.2261%, tar: 0.0249 \n",
      "l0: 0.016346, l1: 0.017484, l2: 0.024354, l3: 0.034683, l4: 0.060844, l5: 0.116091, l6: 0.236414\n",
      "\n",
      "[epoch: 361/400, batch: 584/1000, ite: 47949] train loss: 1.1686, accuracy: 96.2811%, tar: 0.0249 \n",
      "l0: 0.031852, l1: 0.034068, l2: 0.046550, l3: 0.069679, l4: 0.121295, l5: 0.233275, l6: 0.445679\n",
      "\n",
      "[epoch: 361/400, batch: 592/1000, ite: 47950] train loss: 1.1687, accuracy: 94.1287%, tar: 0.0249 \n",
      "l0: 0.022326, l1: 0.023709, l2: 0.030996, l3: 0.047435, l4: 0.082281, l5: 0.157005, l6: 0.304874\n",
      "\n",
      "[epoch: 361/400, batch: 600/1000, ite: 47951] train loss: 1.1686, accuracy: 95.2757%, tar: 0.0249 \n",
      "l0: 0.023310, l1: 0.024884, l2: 0.034349, l3: 0.056575, l4: 0.107249, l5: 0.194970, l6: 0.385996\n",
      "\n",
      "[epoch: 361/400, batch: 608/1000, ite: 47952] train loss: 1.1686, accuracy: 94.1608%, tar: 0.0249 \n",
      "l0: 0.023718, l1: 0.024963, l2: 0.031621, l3: 0.048411, l4: 0.119458, l5: 0.239378, l6: 0.454149\n",
      "\n",
      "[epoch: 361/400, batch: 616/1000, ite: 47953] train loss: 1.1688, accuracy: 93.9228%, tar: 0.0249 \n",
      "l0: 0.025760, l1: 0.026985, l2: 0.034487, l3: 0.052377, l4: 0.093585, l5: 0.191945, l6: 0.376345\n",
      "\n",
      "[epoch: 361/400, batch: 624/1000, ite: 47954] train loss: 1.1688, accuracy: 93.9846%, tar: 0.0249 \n",
      "l0: 0.021026, l1: 0.021342, l2: 0.027761, l3: 0.041686, l4: 0.075632, l5: 0.150469, l6: 0.313696\n",
      "\n",
      "[epoch: 361/400, batch: 632/1000, ite: 47955] train loss: 1.1687, accuracy: 94.9983%, tar: 0.0249 \n",
      "l0: 0.021435, l1: 0.022882, l2: 0.033295, l3: 0.048832, l4: 0.081509, l5: 0.180637, l6: 0.332022\n",
      "\n",
      "[epoch: 361/400, batch: 640/1000, ite: 47956] train loss: 1.1686, accuracy: 95.4731%, tar: 0.0249 \n",
      "l0: 0.020184, l1: 0.021944, l2: 0.031361, l3: 0.052709, l4: 0.100987, l5: 0.193665, l6: 0.379808\n",
      "\n",
      "[epoch: 361/400, batch: 648/1000, ite: 47957] train loss: 1.1686, accuracy: 94.8039%, tar: 0.0249 \n",
      "l0: 0.019171, l1: 0.020571, l2: 0.028713, l3: 0.048608, l4: 0.092669, l5: 0.189646, l6: 0.402017\n",
      "\n",
      "[epoch: 361/400, batch: 656/1000, ite: 47958] train loss: 1.1686, accuracy: 95.3381%, tar: 0.0249 \n",
      "l0: 0.018789, l1: 0.020591, l2: 0.029814, l3: 0.045240, l4: 0.076049, l5: 0.148198, l6: 0.291900\n",
      "\n",
      "[epoch: 361/400, batch: 664/1000, ite: 47959] train loss: 1.1685, accuracy: 96.4167%, tar: 0.0249 \n",
      "l0: 0.018522, l1: 0.019054, l2: 0.026248, l3: 0.039628, l4: 0.066020, l5: 0.114011, l6: 0.208772\n",
      "\n",
      "[epoch: 361/400, batch: 672/1000, ite: 47960] train loss: 1.1683, accuracy: 96.6983%, tar: 0.0249 \n",
      "l0: 0.020746, l1: 0.023223, l2: 0.032993, l3: 0.050600, l4: 0.087427, l5: 0.198992, l6: 0.386028\n",
      "\n",
      "[epoch: 361/400, batch: 680/1000, ite: 47961] train loss: 1.1683, accuracy: 95.0876%, tar: 0.0249 \n",
      "l0: 0.019305, l1: 0.019894, l2: 0.027026, l3: 0.039736, l4: 0.067403, l5: 0.128933, l6: 0.297212\n",
      "\n",
      "[epoch: 361/400, batch: 688/1000, ite: 47962] train loss: 1.1682, accuracy: 95.4298%, tar: 0.0249 \n",
      "l0: 0.021830, l1: 0.023142, l2: 0.030031, l3: 0.044852, l4: 0.083085, l5: 0.215090, l6: 0.542822\n",
      "\n",
      "[epoch: 361/400, batch: 696/1000, ite: 47963] train loss: 1.1683, accuracy: 93.0567%, tar: 0.0249 \n",
      "l0: 0.023259, l1: 0.024120, l2: 0.031799, l3: 0.048071, l4: 0.082493, l5: 0.160544, l6: 0.277296\n",
      "\n",
      "[epoch: 361/400, batch: 704/1000, ite: 47964] train loss: 1.1682, accuracy: 95.4090%, tar: 0.0249 \n",
      "l0: 0.027593, l1: 0.028873, l2: 0.035174, l3: 0.049480, l4: 0.086943, l5: 0.161439, l6: 0.305670\n",
      "\n",
      "[epoch: 361/400, batch: 712/1000, ite: 47965] train loss: 1.1681, accuracy: 95.1658%, tar: 0.0249 \n",
      "l0: 0.023768, l1: 0.025224, l2: 0.034749, l3: 0.053564, l4: 0.110234, l5: 0.236655, l6: 0.475313\n",
      "\n",
      "[epoch: 361/400, batch: 720/1000, ite: 47966] train loss: 1.1683, accuracy: 93.3687%, tar: 0.0249 \n",
      "l0: 0.013179, l1: 0.014905, l2: 0.021885, l3: 0.033038, l4: 0.061461, l5: 0.127637, l6: 0.250715\n",
      "\n",
      "[epoch: 361/400, batch: 728/1000, ite: 47967] train loss: 1.1681, accuracy: 96.9807%, tar: 0.0248 \n",
      "l0: 0.021069, l1: 0.021905, l2: 0.030455, l3: 0.045454, l4: 0.076657, l5: 0.155874, l6: 0.344693\n",
      "\n",
      "[epoch: 361/400, batch: 736/1000, ite: 47968] train loss: 1.1680, accuracy: 94.7478%, tar: 0.0248 \n",
      "l0: 0.021423, l1: 0.022732, l2: 0.029262, l3: 0.042729, l4: 0.078469, l5: 0.177305, l6: 0.368888\n",
      "\n",
      "[epoch: 361/400, batch: 744/1000, ite: 47969] train loss: 1.1680, accuracy: 94.8949%, tar: 0.0248 \n",
      "l0: 0.016932, l1: 0.018014, l2: 0.023238, l3: 0.034403, l4: 0.068771, l5: 0.139589, l6: 0.242086\n",
      "\n",
      "[epoch: 361/400, batch: 752/1000, ite: 47970] train loss: 1.1678, accuracy: 96.1832%, tar: 0.0248 \n",
      "l0: 0.018735, l1: 0.019624, l2: 0.024766, l3: 0.036334, l4: 0.062534, l5: 0.141872, l6: 0.289515\n",
      "\n",
      "[epoch: 361/400, batch: 760/1000, ite: 47971] train loss: 1.1676, accuracy: 95.7923%, tar: 0.0248 \n",
      "l0: 0.029929, l1: 0.030937, l2: 0.039426, l3: 0.054395, l4: 0.098150, l5: 0.209478, l6: 0.488570\n",
      "\n",
      "[epoch: 361/400, batch: 768/1000, ite: 47972] train loss: 1.1678, accuracy: 92.6606%, tar: 0.0248 \n",
      "l0: 0.024577, l1: 0.025832, l2: 0.034279, l3: 0.045810, l4: 0.076495, l5: 0.168310, l6: 0.342396\n",
      "\n",
      "[epoch: 361/400, batch: 776/1000, ite: 47973] train loss: 1.1677, accuracy: 94.6461%, tar: 0.0248 \n",
      "l0: 0.023279, l1: 0.024883, l2: 0.033253, l3: 0.049352, l4: 0.082068, l5: 0.143724, l6: 0.278058\n",
      "\n",
      "[epoch: 361/400, batch: 784/1000, ite: 47974] train loss: 1.1676, accuracy: 95.3906%, tar: 0.0248 \n",
      "l0: 0.019823, l1: 0.021282, l2: 0.028807, l3: 0.041702, l4: 0.070790, l5: 0.140012, l6: 0.254362\n",
      "\n",
      "[epoch: 361/400, batch: 792/1000, ite: 47975] train loss: 1.1674, accuracy: 96.5329%, tar: 0.0248 \n",
      "l0: 0.019747, l1: 0.020971, l2: 0.028586, l3: 0.043240, l4: 0.087060, l5: 0.187634, l6: 0.384651\n",
      "\n",
      "[epoch: 361/400, batch: 800/1000, ite: 47976] train loss: 1.1674, accuracy: 94.6953%, tar: 0.0248 \n",
      "l0: 0.016931, l1: 0.018011, l2: 0.023664, l3: 0.035278, l4: 0.063055, l5: 0.119606, l6: 0.229372\n",
      "\n",
      "[epoch: 361/400, batch: 808/1000, ite: 47977] train loss: 1.1672, accuracy: 96.4518%, tar: 0.0248 \n",
      "l0: 0.018179, l1: 0.019822, l2: 0.026823, l3: 0.045223, l4: 0.104096, l5: 0.216296, l6: 0.370768\n",
      "\n",
      "[epoch: 361/400, batch: 816/1000, ite: 47978] train loss: 1.1672, accuracy: 95.5047%, tar: 0.0248 \n",
      "l0: 0.024296, l1: 0.025600, l2: 0.034252, l3: 0.052829, l4: 0.096464, l5: 0.196915, l6: 0.344174\n",
      "\n",
      "[epoch: 361/400, batch: 824/1000, ite: 47979] train loss: 1.1672, accuracy: 94.9348%, tar: 0.0248 \n",
      "l0: 0.027967, l1: 0.028987, l2: 0.037583, l3: 0.053758, l4: 0.096445, l5: 0.171899, l6: 0.340530\n",
      "\n",
      "[epoch: 361/400, batch: 832/1000, ite: 47980] train loss: 1.1672, accuracy: 94.8621%, tar: 0.0248 \n",
      "l0: 0.024366, l1: 0.026212, l2: 0.036932, l3: 0.054344, l4: 0.117268, l5: 0.241562, l6: 0.471197\n",
      "\n",
      "[epoch: 361/400, batch: 840/1000, ite: 47981] train loss: 1.1673, accuracy: 93.9822%, tar: 0.0248 \n",
      "l0: 0.020977, l1: 0.021848, l2: 0.029052, l3: 0.043563, l4: 0.072849, l5: 0.134970, l6: 0.288419\n",
      "\n",
      "[epoch: 361/400, batch: 848/1000, ite: 47982] train loss: 1.1672, accuracy: 95.4999%, tar: 0.0248 \n",
      "l0: 0.023691, l1: 0.025331, l2: 0.034520, l3: 0.057016, l4: 0.123126, l5: 0.226189, l6: 0.363279\n",
      "\n",
      "[epoch: 361/400, batch: 856/1000, ite: 47983] train loss: 1.1672, accuracy: 94.5820%, tar: 0.0248 \n",
      "l0: 0.018436, l1: 0.019826, l2: 0.026515, l3: 0.043082, l4: 0.080083, l5: 0.165279, l6: 0.309283\n",
      "\n",
      "[epoch: 361/400, batch: 864/1000, ite: 47984] train loss: 1.1671, accuracy: 96.3245%, tar: 0.0248 \n",
      "l0: 0.017342, l1: 0.018326, l2: 0.025793, l3: 0.039038, l4: 0.069667, l5: 0.139028, l6: 0.342416\n",
      "\n",
      "[epoch: 361/400, batch: 872/1000, ite: 47985] train loss: 1.1670, accuracy: 95.4286%, tar: 0.0248 \n",
      "l0: 0.025371, l1: 0.026421, l2: 0.035353, l3: 0.056671, l4: 0.106160, l5: 0.225319, l6: 0.517532\n",
      "\n",
      "[epoch: 361/400, batch: 880/1000, ite: 47986] train loss: 1.1672, accuracy: 94.0915%, tar: 0.0248 \n",
      "l0: 0.025394, l1: 0.028288, l2: 0.040772, l3: 0.075045, l4: 0.149787, l5: 0.344252, l6: 0.606004\n",
      "\n",
      "[epoch: 361/400, batch: 888/1000, ite: 47987] train loss: 1.1676, accuracy: 93.4143%, tar: 0.0248 \n",
      "l0: 0.021596, l1: 0.023111, l2: 0.032637, l3: 0.049897, l4: 0.100210, l5: 0.215284, l6: 0.474217\n",
      "\n",
      "[epoch: 361/400, batch: 896/1000, ite: 47988] train loss: 1.1677, accuracy: 94.5965%, tar: 0.0248 \n",
      "l0: 0.018371, l1: 0.018986, l2: 0.025562, l3: 0.035110, l4: 0.063206, l5: 0.125137, l6: 0.281398\n",
      "\n",
      "l0: 0.021262, l1: 0.022814, l2: 0.030464, l3: 0.046797, l4: 0.087186, l5: 0.180356, l6: 0.379137\n",
      "\n",
      "[epoch: 361/400, batch: 928/1000, ite: 47992] train loss: 1.1676, accuracy: 95.1376%, tar: 0.0248 \n",
      "l0: 0.023062, l1: 0.023671, l2: 0.030217, l3: 0.043343, l4: 0.076690, l5: 0.151530, l6: 0.353947\n",
      "\n",
      "[epoch: 361/400, batch: 936/1000, ite: 47993] train loss: 1.1675, accuracy: 95.2602%, tar: 0.0248 \n",
      "l0: 0.022825, l1: 0.023903, l2: 0.030798, l3: 0.043704, l4: 0.084529, l5: 0.170860, l6: 0.354611\n",
      "\n",
      "[epoch: 361/400, batch: 944/1000, ite: 47994] train loss: 1.1675, accuracy: 94.3918%, tar: 0.0248 \n",
      "l0: 0.017772, l1: 0.019518, l2: 0.026287, l3: 0.041239, l4: 0.106520, l5: 0.217910, l6: 0.309812\n",
      "\n",
      "[epoch: 361/400, batch: 952/1000, ite: 47995] train loss: 1.1674, accuracy: 95.8214%, tar: 0.0248 \n",
      "l0: 0.020776, l1: 0.021609, l2: 0.026718, l3: 0.037334, l4: 0.072130, l5: 0.166093, l6: 0.331937\n",
      "\n",
      "[epoch: 361/400, batch: 960/1000, ite: 47996] train loss: 1.1673, accuracy: 95.6103%, tar: 0.0248 \n",
      "l0: 0.020370, l1: 0.021381, l2: 0.026277, l3: 0.033792, l4: 0.057442, l5: 0.123814, l6: 0.313715\n",
      "\n",
      "[epoch: 361/400, batch: 968/1000, ite: 47997] train loss: 1.1672, accuracy: 96.2084%, tar: 0.0248 \n",
      "l0: 0.018139, l1: 0.019295, l2: 0.027454, l3: 0.044377, l4: 0.088635, l5: 0.202394, l6: 0.436323\n",
      "\n",
      "[epoch: 361/400, batch: 976/1000, ite: 47998] train loss: 1.1673, accuracy: 95.6613%, tar: 0.0248 \n",
      "l0: 0.028619, l1: 0.030260, l2: 0.039932, l3: 0.060965, l4: 0.102875, l5: 0.195167, l6: 0.474264\n",
      "\n",
      "[epoch: 361/400, batch: 984/1000, ite: 47999] train loss: 1.1674, accuracy: 93.2835%, tar: 0.0248 \n",
      "l0: 0.022649, l1: 0.023633, l2: 0.031275, l3: 0.048083, l4: 0.095429, l5: 0.192739, l6: 0.423266\n",
      "\n",
      "[epoch: 361/400, batch: 992/1000, ite: 48000] train loss: 1.1674, accuracy: 94.9802%, tar: 0.0248 \n",
      "l0: 0.018260, l1: 0.019496, l2: 0.025909, l3: 0.041233, l4: 0.077067, l5: 0.156437, l6: 0.344312\n",
      "\n",
      "[epoch: 361/400, batch: 1000/1000, ite: 48001] train loss: 1.0313, accuracy: 94.7116%, tar: 0.0183 \n",
      "l0: 0.024440, l1: 0.025360, l2: 0.032108, l3: 0.045538, l4: 0.081950, l5: 0.153160, l6: 0.331838\n",
      "\n",
      "[epoch: 362/400, batch: 8/1000, ite: 48002] train loss: 1.0301, accuracy: 94.7735%, tar: 0.0213 \n",
      "l0: 0.014892, l1: 0.016166, l2: 0.023460, l3: 0.040617, l4: 0.078568, l5: 0.159171, l6: 0.305067\n",
      "\n",
      "[epoch: 362/400, batch: 16/1000, ite: 48003] train loss: 1.0033, accuracy: 95.8760%, tar: 0.0192 \n",
      "l0: 0.022266, l1: 0.024044, l2: 0.033148, l3: 0.046674, l4: 0.082663, l5: 0.149162, l6: 0.337142\n",
      "\n",
      "[epoch: 362/400, batch: 24/1000, ite: 48004] train loss: 1.0109, accuracy: 96.2903%, tar: 0.0200 \n",
      "l0: 0.027183, l1: 0.028248, l2: 0.037372, l3: 0.052243, l4: 0.091844, l5: 0.163071, l6: 0.521063\n",
      "\n",
      "[epoch: 362/400, batch: 32/1000, ite: 48005] train loss: 1.0956, accuracy: 93.1820%, tar: 0.0214 \n",
      "l0: 0.022274, l1: 0.023267, l2: 0.029411, l3: 0.042207, l4: 0.076035, l5: 0.141784, l6: 0.286469\n",
      "\n",
      "[epoch: 362/400, batch: 40/1000, ite: 48006] train loss: 1.0642, accuracy: 95.4332%, tar: 0.0216 \n",
      "l0: 0.019489, l1: 0.020026, l2: 0.027972, l3: 0.043399, l4: 0.087535, l5: 0.161030, l6: 0.373303\n",
      "\n",
      "[epoch: 362/400, batch: 48/1000, ite: 48007] train loss: 1.0712, accuracy: 95.0257%, tar: 0.0213 \n",
      "l0: 0.019558, l1: 0.020493, l2: 0.029794, l3: 0.046291, l4: 0.089237, l5: 0.199016, l6: 0.417120\n",
      "\n",
      "[epoch: 362/400, batch: 56/1000, ite: 48008] train loss: 1.0925, accuracy: 94.7874%, tar: 0.0210 \n",
      "l0: 0.022146, l1: 0.023372, l2: 0.029959, l3: 0.044804, l4: 0.091541, l5: 0.167715, l6: 0.358388\n",
      "\n",
      "[epoch: 362/400, batch: 64/1000, ite: 48009] train loss: 1.0935, accuracy: 95.3761%, tar: 0.0212 \n",
      "l0: 0.025326, l1: 0.026545, l2: 0.032942, l3: 0.048042, l4: 0.093433, l5: 0.205200, l6: 0.501415\n",
      "\n",
      "[epoch: 362/400, batch: 72/1000, ite: 48010] train loss: 1.1278, accuracy: 93.0245%, tar: 0.0216 \n",
      "l0: 0.023498, l1: 0.024973, l2: 0.033524, l3: 0.052709, l4: 0.108244, l5: 0.213443, l6: 0.441289\n",
      "\n",
      "[epoch: 362/400, batch: 80/1000, ite: 48011] train loss: 1.1476, accuracy: 94.2950%, tar: 0.0218 \n",
      "l0: 0.016949, l1: 0.017949, l2: 0.023950, l3: 0.034508, l4: 0.061606, l5: 0.121850, l6: 0.294079\n",
      "\n",
      "[epoch: 362/400, batch: 88/1000, ite: 48012] train loss: 1.1239, accuracy: 95.7448%, tar: 0.0214 \n",
      "l0: 0.022270, l1: 0.023976, l2: 0.033153, l3: 0.050446, l4: 0.102029, l5: 0.182977, l6: 0.356584\n",
      "\n",
      "[epoch: 362/400, batch: 96/1000, ite: 48013] train loss: 1.1243, accuracy: 95.4612%, tar: 0.0214 \n",
      "l0: 0.023917, l1: 0.025915, l2: 0.035146, l3: 0.049855, l4: 0.097282, l5: 0.245201, l6: 0.553031\n",
      "\n",
      "[epoch: 362/400, batch: 104/1000, ite: 48014] train loss: 1.1570, accuracy: 93.6899%, tar: 0.0216 \n",
      "l0: 0.030783, l1: 0.032979, l2: 0.042195, l3: 0.063410, l4: 0.118407, l5: 0.232576, l6: 0.575958\n",
      "\n",
      "[epoch: 362/400, batch: 112/1000, ite: 48015] train loss: 1.1918, accuracy: 93.4371%, tar: 0.0222 \n",
      "l0: 0.018443, l1: 0.019354, l2: 0.026325, l3: 0.039813, l4: 0.072691, l5: 0.147957, l6: 0.282430\n",
      "\n",
      "[epoch: 362/400, batch: 120/1000, ite: 48016] train loss: 1.1733, accuracy: 95.3966%, tar: 0.0220 \n",
      "l0: 0.019695, l1: 0.020654, l2: 0.028160, l3: 0.045891, l4: 0.081085, l5: 0.135295, l6: 0.283183\n",
      "\n",
      "[epoch: 362/400, batch: 128/1000, ite: 48017] train loss: 1.1573, accuracy: 95.3290%, tar: 0.0218 \n",
      "l0: 0.022130, l1: 0.023811, l2: 0.033376, l3: 0.049299, l4: 0.080443, l5: 0.146524, l6: 0.271426\n",
      "\n",
      "[epoch: 362/400, batch: 136/1000, ite: 48018] train loss: 1.1431, accuracy: 95.9749%, tar: 0.0219 \n",
      "l0: 0.025703, l1: 0.027270, l2: 0.035115, l3: 0.055010, l4: 0.099968, l5: 0.202692, l6: 0.336218\n",
      "\n",
      "[epoch: 362/400, batch: 144/1000, ite: 48019] train loss: 1.1417, accuracy: 95.4890%, tar: 0.0221 \n",
      "l0: 0.020269, l1: 0.020907, l2: 0.027409, l3: 0.039171, l4: 0.064624, l5: 0.114939, l6: 0.265499\n",
      "\n",
      "[epoch: 362/400, batch: 152/1000, ite: 48020] train loss: 1.1254, accuracy: 95.7956%, tar: 0.0220 \n",
      "l0: 0.032161, l1: 0.033946, l2: 0.043681, l3: 0.063413, l4: 0.125280, l5: 0.270170, l6: 0.612577\n",
      "\n",
      "[epoch: 362/400, batch: 160/1000, ite: 48021] train loss: 1.1576, accuracy: 91.3669%, tar: 0.0225 \n",
      "l0: 0.018088, l1: 0.019504, l2: 0.029177, l3: 0.045098, l4: 0.087054, l5: 0.158057, l6: 0.280799\n",
      "\n",
      "[epoch: 362/400, batch: 168/1000, ite: 48022] train loss: 1.1469, accuracy: 95.7681%, tar: 0.0223 \n",
      "l0: 0.017612, l1: 0.018840, l2: 0.027068, l3: 0.040680, l4: 0.071697, l5: 0.177699, l6: 0.319523\n",
      "\n",
      "[epoch: 362/400, batch: 176/1000, ite: 48023] train loss: 1.1403, accuracy: 95.9483%, tar: 0.0221 \n",
      "l0: 0.022028, l1: 0.024320, l2: 0.033815, l3: 0.050818, l4: 0.101220, l5: 0.209129, l6: 0.441970\n",
      "\n",
      "[epoch: 362/400, batch: 184/1000, ite: 48024] train loss: 1.1487, accuracy: 94.6010%, tar: 0.0221 \n",
      "l0: 0.027385, l1: 0.029014, l2: 0.037267, l3: 0.055820, l4: 0.098811, l5: 0.204325, l6: 0.467022\n",
      "\n",
      "[epoch: 362/400, batch: 192/1000, ite: 48025] train loss: 1.1583, accuracy: 93.5322%, tar: 0.0223 \n",
      "l0: 0.019296, l1: 0.020572, l2: 0.028243, l3: 0.044573, l4: 0.087718, l5: 0.201043, l6: 0.392372\n",
      "\n",
      "[epoch: 362/400, batch: 200/1000, ite: 48026] train loss: 1.1595, accuracy: 95.2771%, tar: 0.0222 \n",
      "l0: 0.015361, l1: 0.016128, l2: 0.021248, l3: 0.031604, l4: 0.052637, l5: 0.119022, l6: 0.271182\n",
      "\n",
      "[epoch: 362/400, batch: 208/1000, ite: 48027] train loss: 1.1465, accuracy: 96.2798%, tar: 0.0219 \n",
      "l0: 0.027500, l1: 0.029735, l2: 0.039239, l3: 0.063200, l4: 0.146137, l5: 0.342228, l6: 0.578215\n",
      "\n",
      "[epoch: 362/400, batch: 216/1000, ite: 48028] train loss: 1.1700, accuracy: 93.0446%, tar: 0.0221 \n",
      "l0: 0.022712, l1: 0.024136, l2: 0.031749, l3: 0.050336, l4: 0.096865, l5: 0.209658, l6: 0.430032\n",
      "\n",
      "[epoch: 362/400, batch: 224/1000, ite: 48029] train loss: 1.1744, accuracy: 94.3073%, tar: 0.0221 \n",
      "l0: 0.021242, l1: 0.022609, l2: 0.032047, l3: 0.047324, l4: 0.089422, l5: 0.189304, l6: 0.405893\n",
      "\n",
      "[epoch: 362/400, batch: 232/1000, ite: 48030] train loss: 1.1758, accuracy: 94.8539%, tar: 0.0221 \n",
      "l0: 0.023539, l1: 0.024923, l2: 0.034009, l3: 0.050987, l4: 0.101144, l5: 0.203788, l6: 0.383133\n",
      "\n",
      "[epoch: 362/400, batch: 240/1000, ite: 48031] train loss: 1.1768, accuracy: 94.4402%, tar: 0.0221 \n",
      "l0: 0.020161, l1: 0.021546, l2: 0.029695, l3: 0.047511, l4: 0.089143, l5: 0.170269, l6: 0.372579\n",
      "\n",
      "[epoch: 362/400, batch: 248/1000, ite: 48032] train loss: 1.1753, accuracy: 95.0286%, tar: 0.0221 \n",
      "l0: 0.022694, l1: 0.025180, l2: 0.034472, l3: 0.054662, l4: 0.122297, l5: 0.254640, l6: 0.435061\n",
      "\n",
      "[epoch: 362/400, batch: 256/1000, ite: 48033] train loss: 1.1816, accuracy: 95.8335%, tar: 0.0221 \n",
      "l0: 0.018693, l1: 0.019963, l2: 0.025572, l3: 0.040114, l4: 0.073871, l5: 0.164059, l6: 0.439017\n",
      "\n",
      "[epoch: 362/400, batch: 264/1000, ite: 48034] train loss: 1.1828, accuracy: 94.0404%, tar: 0.0220 \n",
      "l0: 0.020043, l1: 0.021014, l2: 0.030062, l3: 0.047847, l4: 0.087132, l5: 0.193769, l6: 0.362686\n",
      "\n",
      "[epoch: 362/400, batch: 272/1000, ite: 48035] train loss: 1.1812, accuracy: 95.3106%, tar: 0.0219 \n",
      "l0: 0.021443, l1: 0.022568, l2: 0.031978, l3: 0.050786, l4: 0.082474, l5: 0.135329, l6: 0.306587\n",
      "\n",
      "[epoch: 362/400, batch: 280/1000, ite: 48036] train loss: 1.1749, accuracy: 95.7819%, tar: 0.0219 \n",
      "l0: 0.023569, l1: 0.026215, l2: 0.037444, l3: 0.064265, l4: 0.136545, l5: 0.263732, l6: 0.464363\n",
      "\n",
      "[epoch: 362/400, batch: 288/1000, ite: 48037] train loss: 1.1833, accuracy: 94.2232%, tar: 0.0220 \n",
      "l0: 0.021952, l1: 0.022423, l2: 0.028360, l3: 0.037687, l4: 0.058154, l5: 0.105423, l6: 0.203154\n",
      "\n",
      "[epoch: 362/400, batch: 296/1000, ite: 48038] train loss: 1.1701, accuracy: 96.1415%, tar: 0.0220 \n",
      "l0: 0.020915, l1: 0.022070, l2: 0.029217, l3: 0.043447, l4: 0.073810, l5: 0.186522, l6: 0.340602\n",
      "\n",
      "[epoch: 362/400, batch: 304/1000, ite: 48039] train loss: 1.1674, accuracy: 95.1114%, tar: 0.0219 \n",
      "l0: 0.023317, l1: 0.024646, l2: 0.032928, l3: 0.049516, l4: 0.086895, l5: 0.189894, l6: 0.446939\n",
      "\n",
      "[epoch: 362/400, batch: 312/1000, ite: 48040] train loss: 1.1709, accuracy: 93.5505%, tar: 0.0220 \n",
      "l0: 0.019705, l1: 0.021006, l2: 0.028737, l3: 0.041607, l4: 0.069889, l5: 0.125562, l6: 0.262767\n",
      "\n",
      "[epoch: 362/400, batch: 320/1000, ite: 48041] train loss: 1.1627, accuracy: 95.7474%, tar: 0.0219 \n",
      "l0: 0.025121, l1: 0.026223, l2: 0.033729, l3: 0.052977, l4: 0.100908, l5: 0.190777, l6: 0.366333\n",
      "\n",
      "[epoch: 362/400, batch: 328/1000, ite: 48042] train loss: 1.1628, accuracy: 94.5604%, tar: 0.0220 \n",
      "l0: 0.018673, l1: 0.019413, l2: 0.025667, l3: 0.037173, l4: 0.071637, l5: 0.138225, l6: 0.326143\n",
      "\n",
      "[epoch: 362/400, batch: 336/1000, ite: 48043] train loss: 1.1582, accuracy: 95.4842%, tar: 0.0219 \n",
      "l0: 0.017535, l1: 0.018236, l2: 0.023358, l3: 0.037403, l4: 0.065320, l5: 0.126180, l6: 0.251405\n",
      "\n",
      "[epoch: 362/400, batch: 344/1000, ite: 48044] train loss: 1.1498, accuracy: 96.3059%, tar: 0.0218 \n",
      "l0: 0.020383, l1: 0.021869, l2: 0.029291, l3: 0.041486, l4: 0.075838, l5: 0.143080, l6: 0.299664\n",
      "\n",
      "[epoch: 362/400, batch: 352/1000, ite: 48045] train loss: 1.1451, accuracy: 95.7160%, tar: 0.0218 \n",
      "l0: 0.022683, l1: 0.023861, l2: 0.032726, l3: 0.047398, l4: 0.082226, l5: 0.189271, l6: 0.408789\n",
      "\n",
      "[epoch: 362/400, batch: 360/1000, ite: 48046] train loss: 1.1467, accuracy: 94.8971%, tar: 0.0218 \n",
      "l0: 0.026162, l1: 0.027712, l2: 0.037130, l3: 0.053845, l4: 0.097106, l5: 0.210017, l6: 0.422827\n",
      "\n",
      "[epoch: 362/400, batch: 368/1000, ite: 48047] train loss: 1.1500, accuracy: 94.4279%, tar: 0.0219 \n",
      "l0: 0.020968, l1: 0.022573, l2: 0.029938, l3: 0.046288, l4: 0.084025, l5: 0.140310, l6: 0.371667\n",
      "\n",
      "[epoch: 362/400, batch: 376/1000, ite: 48048] train loss: 1.1488, accuracy: 95.1734%, tar: 0.0219 \n",
      "l0: 0.020504, l1: 0.021627, l2: 0.028951, l3: 0.040628, l4: 0.071940, l5: 0.142167, l6: 0.319881\n",
      "\n",
      "[epoch: 362/400, batch: 384/1000, ite: 48049] train loss: 1.1453, accuracy: 94.7719%, tar: 0.0219 \n",
      "l0: 0.022304, l1: 0.023867, l2: 0.032405, l3: 0.052551, l4: 0.099046, l5: 0.194155, l6: 0.382625\n",
      "\n",
      "[epoch: 362/400, batch: 392/1000, ite: 48050] train loss: 1.1462, accuracy: 94.6063%, tar: 0.0219 \n",
      "l0: 0.020936, l1: 0.022590, l2: 0.031237, l3: 0.051725, l4: 0.105456, l5: 0.218139, l6: 0.422417\n",
      "\n",
      "[epoch: 362/400, batch: 400/1000, ite: 48051] train loss: 1.1492, accuracy: 94.9599%, tar: 0.0218 \n",
      "l0: 0.025711, l1: 0.026892, l2: 0.034899, l3: 0.052442, l4: 0.102156, l5: 0.208168, l6: 0.385606\n",
      "\n",
      "[epoch: 362/400, batch: 408/1000, ite: 48052] train loss: 1.1506, accuracy: 93.9933%, tar: 0.0219 \n",
      "l0: 0.017755, l1: 0.018672, l2: 0.024460, l3: 0.038899, l4: 0.072629, l5: 0.152465, l6: 0.383831\n",
      "\n",
      "[epoch: 362/400, batch: 416/1000, ite: 48053] train loss: 1.1496, accuracy: 95.0403%, tar: 0.0218 \n",
      "l0: 0.022733, l1: 0.024180, l2: 0.033590, l3: 0.051580, l4: 0.098405, l5: 0.228242, l6: 0.455139\n",
      "\n",
      "[epoch: 362/400, batch: 424/1000, ite: 48054] train loss: 1.1537, accuracy: 93.5987%, tar: 0.0219 \n",
      "l0: 0.022880, l1: 0.023762, l2: 0.031748, l3: 0.044820, l4: 0.074992, l5: 0.147595, l6: 0.295241\n",
      "\n",
      "[epoch: 362/400, batch: 432/1000, ite: 48055] train loss: 1.1499, accuracy: 94.9401%, tar: 0.0219 \n",
      "l0: 0.023890, l1: 0.026279, l2: 0.034843, l3: 0.048849, l4: 0.083138, l5: 0.186017, l6: 0.392422\n",
      "\n",
      "[epoch: 362/400, batch: 440/1000, ite: 48056] train loss: 1.1505, accuracy: 95.4329%, tar: 0.0219 \n",
      "l0: 0.020417, l1: 0.021547, l2: 0.028303, l3: 0.041374, l4: 0.075029, l5: 0.149084, l6: 0.348314\n",
      "\n",
      "[epoch: 362/400, batch: 448/1000, ite: 48057] train loss: 1.1485, accuracy: 94.8830%, tar: 0.0219 \n",
      "l0: 0.024747, l1: 0.026802, l2: 0.037727, l3: 0.059411, l4: 0.124829, l5: 0.272523, l6: 0.543976\n",
      "\n",
      "[epoch: 362/400, batch: 456/1000, ite: 48058] train loss: 1.1568, accuracy: 94.5375%, tar: 0.0219 \n",
      "l0: 0.018374, l1: 0.019540, l2: 0.027594, l3: 0.045328, l4: 0.079927, l5: 0.135653, l6: 0.276709\n",
      "\n",
      "[epoch: 362/400, batch: 464/1000, ite: 48059] train loss: 1.1522, accuracy: 96.2493%, tar: 0.0219 \n",
      "l0: 0.022102, l1: 0.023594, l2: 0.029990, l3: 0.047453, l4: 0.094771, l5: 0.204982, l6: 0.426588\n",
      "\n",
      "[epoch: 362/400, batch: 472/1000, ite: 48060] train loss: 1.1544, accuracy: 94.0379%, tar: 0.0219 \n",
      "l0: 0.024323, l1: 0.026310, l2: 0.033416, l3: 0.049666, l4: 0.113024, l5: 0.238865, l6: 0.429176\n",
      "\n",
      "[epoch: 362/400, batch: 480/1000, ite: 48061] train loss: 1.1575, accuracy: 94.7263%, tar: 0.0219 \n",
      "l0: 0.017611, l1: 0.018885, l2: 0.026656, l3: 0.040288, l4: 0.079861, l5: 0.163595, l6: 0.324828\n",
      "\n",
      "[epoch: 362/400, batch: 488/1000, ite: 48062] train loss: 1.1551, accuracy: 95.9450%, tar: 0.0219 \n",
      "l0: 0.017842, l1: 0.018815, l2: 0.024919, l3: 0.036017, l4: 0.060628, l5: 0.112886, l6: 0.286042\n",
      "\n",
      "[epoch: 362/400, batch: 496/1000, ite: 48063] train loss: 1.1502, accuracy: 95.5214%, tar: 0.0218 \n",
      "l0: 0.020645, l1: 0.022050, l2: 0.029525, l3: 0.045321, l4: 0.085800, l5: 0.192356, l6: 0.395533\n",
      "\n",
      "[epoch: 362/400, batch: 504/1000, ite: 48064] train loss: 1.1508, accuracy: 95.0455%, tar: 0.0218 \n",
      "l0: 0.018144, l1: 0.019225, l2: 0.027975, l3: 0.044762, l4: 0.091572, l5: 0.165610, l6: 0.287840\n",
      "\n",
      "[epoch: 362/400, batch: 512/1000, ite: 48065] train loss: 1.1476, accuracy: 95.9708%, tar: 0.0217 \n",
      "l0: 0.027351, l1: 0.028732, l2: 0.039774, l3: 0.061278, l4: 0.111611, l5: 0.214815, l6: 0.533473\n",
      "\n",
      "[epoch: 362/400, batch: 520/1000, ite: 48066] train loss: 1.1538, accuracy: 93.4250%, tar: 0.0218 \n",
      "l0: 0.025804, l1: 0.027183, l2: 0.035464, l3: 0.051654, l4: 0.099923, l5: 0.224668, l6: 0.508535\n",
      "\n",
      "[epoch: 362/400, batch: 528/1000, ite: 48067] train loss: 1.1587, accuracy: 92.8844%, tar: 0.0219 \n",
      "l0: 0.021406, l1: 0.022635, l2: 0.029817, l3: 0.043603, l4: 0.082771, l5: 0.183046, l6: 0.348772\n",
      "\n",
      "[epoch: 362/400, batch: 536/1000, ite: 48068] train loss: 1.1576, accuracy: 95.2496%, tar: 0.0219 \n",
      "l0: 0.021653, l1: 0.022877, l2: 0.030778, l3: 0.044607, l4: 0.087484, l5: 0.189717, l6: 0.364247\n",
      "\n",
      "[epoch: 362/400, batch: 544/1000, ite: 48069] train loss: 1.1571, accuracy: 95.2299%, tar: 0.0218 \n",
      "l0: 0.021648, l1: 0.022572, l2: 0.029400, l3: 0.041544, l4: 0.072377, l5: 0.140525, l6: 0.288247\n",
      "\n",
      "[epoch: 362/400, batch: 552/1000, ite: 48070] train loss: 1.1536, accuracy: 95.7779%, tar: 0.0218 \n",
      "l0: 0.027208, l1: 0.029851, l2: 0.041006, l3: 0.066864, l4: 0.129572, l5: 0.263485, l6: 0.531242\n",
      "\n",
      "[epoch: 362/400, batch: 560/1000, ite: 48071] train loss: 1.1602, accuracy: 93.6179%, tar: 0.0219 \n",
      "l0: 0.025536, l1: 0.027358, l2: 0.036992, l3: 0.056679, l4: 0.110136, l5: 0.241498, l6: 0.519077\n",
      "\n",
      "[epoch: 362/400, batch: 568/1000, ite: 48072] train loss: 1.1654, accuracy: 93.5557%, tar: 0.0220 \n",
      "l0: 0.020434, l1: 0.021050, l2: 0.028041, l3: 0.040129, l4: 0.066150, l5: 0.136634, l6: 0.265388\n",
      "\n",
      "[epoch: 362/400, batch: 576/1000, ite: 48073] train loss: 1.1610, accuracy: 95.9775%, tar: 0.0220 \n",
      "l0: 0.024560, l1: 0.025655, l2: 0.034317, l3: 0.050465, l4: 0.095257, l5: 0.228091, l6: 0.493333\n",
      "\n",
      "[epoch: 362/400, batch: 584/1000, ite: 48074] train loss: 1.1648, accuracy: 94.0381%, tar: 0.0220 \n",
      "l0: 0.025638, l1: 0.028183, l2: 0.038562, l3: 0.060373, l4: 0.104691, l5: 0.193079, l6: 0.359697\n",
      "\n",
      "[epoch: 362/400, batch: 592/1000, ite: 48075] train loss: 1.1650, accuracy: 94.6048%, tar: 0.0220 \n",
      "l0: 0.014659, l1: 0.016103, l2: 0.021536, l3: 0.031710, l4: 0.063868, l5: 0.122003, l6: 0.296059\n",
      "\n",
      "[epoch: 362/400, batch: 600/1000, ite: 48076] train loss: 1.1611, accuracy: 96.1659%, tar: 0.0219 \n",
      "l0: 0.022245, l1: 0.023401, l2: 0.030801, l3: 0.048770, l4: 0.096725, l5: 0.179568, l6: 0.361458\n",
      "\n",
      "[epoch: 362/400, batch: 608/1000, ite: 48077] train loss: 1.1606, accuracy: 94.6784%, tar: 0.0219 \n",
      "l0: 0.016281, l1: 0.017134, l2: 0.022297, l3: 0.035755, l4: 0.069689, l5: 0.137694, l6: 0.291916\n",
      "\n",
      "[epoch: 362/400, batch: 616/1000, ite: 48078] train loss: 1.1571, accuracy: 95.7495%, tar: 0.0219 \n",
      "l0: 0.016640, l1: 0.018166, l2: 0.025135, l3: 0.036793, l4: 0.067831, l5: 0.120519, l6: 0.251958\n",
      "\n",
      "[epoch: 362/400, batch: 624/1000, ite: 48079] train loss: 1.1525, accuracy: 96.8196%, tar: 0.0218 \n",
      "l0: 0.020220, l1: 0.022568, l2: 0.033657, l3: 0.058960, l4: 0.124291, l5: 0.282161, l6: 0.470238\n",
      "\n",
      "[epoch: 362/400, batch: 632/1000, ite: 48080] train loss: 1.1566, accuracy: 94.5655%, tar: 0.0218 \n",
      "l0: 0.023829, l1: 0.025267, l2: 0.033765, l3: 0.050421, l4: 0.088271, l5: 0.187654, l6: 0.406340\n",
      "\n",
      "[epoch: 362/400, batch: 640/1000, ite: 48081] train loss: 1.1575, accuracy: 94.8617%, tar: 0.0218 \n",
      "l0: 0.024705, l1: 0.026766, l2: 0.035440, l3: 0.053689, l4: 0.107027, l5: 0.217367, l6: 0.466046\n",
      "\n",
      "[epoch: 362/400, batch: 648/1000, ite: 48082] train loss: 1.1605, accuracy: 93.5653%, tar: 0.0218 \n",
      "l0: 0.014240, l1: 0.014963, l2: 0.021365, l3: 0.031679, l4: 0.057117, l5: 0.110006, l6: 0.214799\n",
      "\n",
      "[epoch: 362/400, batch: 656/1000, ite: 48083] train loss: 1.1547, accuracy: 97.0040%, tar: 0.0218 \n",
      "l0: 0.021253, l1: 0.021974, l2: 0.028256, l3: 0.037499, l4: 0.068080, l5: 0.130753, l6: 0.274920\n",
      "\n",
      "[epoch: 362/400, batch: 664/1000, ite: 48084] train loss: 1.1513, accuracy: 95.1209%, tar: 0.0217 \n",
      "l0: 0.020907, l1: 0.022697, l2: 0.031929, l3: 0.049320, l4: 0.089021, l5: 0.146117, l6: 0.289798\n",
      "\n",
      "[epoch: 362/400, batch: 672/1000, ite: 48085] train loss: 1.1488, accuracy: 95.5068%, tar: 0.0217 \n",
      "l0: 0.018563, l1: 0.019614, l2: 0.028076, l3: 0.042474, l4: 0.071793, l5: 0.131009, l6: 0.295736\n",
      "\n",
      "[epoch: 362/400, batch: 680/1000, ite: 48086] train loss: 1.1460, accuracy: 95.8803%, tar: 0.0217 \n",
      "l0: 0.017595, l1: 0.019765, l2: 0.028571, l3: 0.047643, l4: 0.083466, l5: 0.173918, l6: 0.293414\n",
      "\n",
      "[epoch: 362/400, batch: 688/1000, ite: 48087] train loss: 1.1439, accuracy: 96.5482%, tar: 0.0217 \n",
      "l0: 0.028687, l1: 0.029697, l2: 0.037382, l3: 0.050396, l4: 0.082434, l5: 0.169181, l6: 0.361806\n",
      "\n",
      "[epoch: 362/400, batch: 696/1000, ite: 48088] train loss: 1.1437, accuracy: 94.0274%, tar: 0.0217 \n",
      "l0: 0.025450, l1: 0.026319, l2: 0.032421, l3: 0.046162, l4: 0.082421, l5: 0.168599, l6: 0.402390\n",
      "\n",
      "[epoch: 362/400, batch: 704/1000, ite: 48089] train loss: 1.1443, accuracy: 94.2357%, tar: 0.0218 \n",
      "l0: 0.022537, l1: 0.023631, l2: 0.032277, l3: 0.048026, l4: 0.092678, l5: 0.206315, l6: 0.416722\n",
      "\n",
      "[epoch: 362/400, batch: 712/1000, ite: 48090] train loss: 1.1456, accuracy: 93.9509%, tar: 0.0218 \n",
      "l0: 0.025379, l1: 0.026875, l2: 0.035603, l3: 0.047936, l4: 0.076352, l5: 0.152897, l6: 0.324921\n",
      "\n",
      "[epoch: 362/400, batch: 720/1000, ite: 48091] train loss: 1.1442, accuracy: 95.3692%, tar: 0.0218 \n",
      "l0: 0.020648, l1: 0.021684, l2: 0.029057, l3: 0.049837, l4: 0.104763, l5: 0.218336, l6: 0.442648\n",
      "\n",
      "[epoch: 362/400, batch: 728/1000, ite: 48092] train loss: 1.1463, accuracy: 93.9806%, tar: 0.0218 \n",
      "l0: 0.025791, l1: 0.026993, l2: 0.034466, l3: 0.052400, l4: 0.099827, l5: 0.199546, l6: 0.420932\n",
      "\n",
      "[epoch: 362/400, batch: 736/1000, ite: 48093] train loss: 1.1478, accuracy: 93.9259%, tar: 0.0219 \n",
      "l0: 0.021643, l1: 0.022362, l2: 0.029777, l3: 0.044838, l4: 0.082236, l5: 0.150723, l6: 0.355518\n",
      "\n",
      "[epoch: 362/400, batch: 744/1000, ite: 48094] train loss: 1.1469, accuracy: 95.2738%, tar: 0.0218 \n",
      "l0: 0.019110, l1: 0.020343, l2: 0.029005, l3: 0.049002, l4: 0.099977, l5: 0.220497, l6: 0.450545\n",
      "\n",
      "[epoch: 362/400, batch: 752/1000, ite: 48095] train loss: 1.1490, accuracy: 94.6459%, tar: 0.0218 \n",
      "l0: 0.026365, l1: 0.027312, l2: 0.035339, l3: 0.052773, l4: 0.096640, l5: 0.228572, l6: 0.470170\n",
      "\n",
      "[epoch: 362/400, batch: 760/1000, ite: 48096] train loss: 1.1518, accuracy: 93.5751%, tar: 0.0219 \n",
      "l0: 0.023679, l1: 0.024974, l2: 0.033595, l3: 0.050537, l4: 0.089038, l5: 0.185928, l6: 0.341759\n",
      "\n",
      "[epoch: 362/400, batch: 768/1000, ite: 48097] train loss: 1.1512, accuracy: 95.3406%, tar: 0.0219 \n",
      "l0: 0.027178, l1: 0.028445, l2: 0.036327, l3: 0.054184, l4: 0.103802, l5: 0.225857, l6: 0.431697\n",
      "\n",
      "[epoch: 362/400, batch: 776/1000, ite: 48098] train loss: 1.1532, accuracy: 93.4127%, tar: 0.0219 \n",
      "l0: 0.020801, l1: 0.023564, l2: 0.031110, l3: 0.048838, l4: 0.088029, l5: 0.168671, l6: 0.348424\n",
      "\n",
      "[epoch: 362/400, batch: 784/1000, ite: 48099] train loss: 1.1524, accuracy: 95.3907%, tar: 0.0219 \n",
      "l0: 0.021748, l1: 0.022590, l2: 0.030984, l3: 0.053462, l4: 0.093252, l5: 0.172863, l6: 0.372047\n",
      "\n",
      "[epoch: 362/400, batch: 792/1000, ite: 48100] train loss: 1.1524, accuracy: 94.7149%, tar: 0.0219 \n",
      "l0: 0.019731, l1: 0.021262, l2: 0.027625, l3: 0.040080, l4: 0.074008, l5: 0.150631, l6: 0.284307\n",
      "\n",
      "[epoch: 362/400, batch: 800/1000, ite: 48101] train loss: 1.1499, accuracy: 96.0244%, tar: 0.0219 \n",
      "l0: 0.023792, l1: 0.025533, l2: 0.036081, l3: 0.056579, l4: 0.099897, l5: 0.155833, l6: 0.323890\n",
      "\n",
      "[epoch: 362/400, batch: 808/1000, ite: 48102] train loss: 1.1490, accuracy: 95.6507%, tar: 0.0219 \n",
      "l0: 0.018076, l1: 0.019054, l2: 0.027319, l3: 0.048572, l4: 0.088405, l5: 0.150940, l6: 0.324967\n",
      "\n",
      "[epoch: 362/400, batch: 816/1000, ite: 48103] train loss: 1.1476, accuracy: 95.5382%, tar: 0.0219 \n",
      "l0: 0.017624, l1: 0.018743, l2: 0.028359, l3: 0.049309, l4: 0.105907, l5: 0.180387, l6: 0.344368\n",
      "\n",
      "[epoch: 362/400, batch: 824/1000, ite: 48104] train loss: 1.1471, accuracy: 95.0887%, tar: 0.0218 \n",
      "l0: 0.023501, l1: 0.024945, l2: 0.030273, l3: 0.045676, l4: 0.100788, l5: 0.185996, l6: 0.317544\n",
      "\n",
      "[epoch: 362/400, batch: 832/1000, ite: 48105] train loss: 1.1462, accuracy: 95.1283%, tar: 0.0219 \n",
      "l0: 0.021230, l1: 0.022248, l2: 0.028248, l3: 0.040055, l4: 0.069633, l5: 0.140801, l6: 0.295076\n",
      "\n",
      "[epoch: 362/400, batch: 840/1000, ite: 48106] train loss: 1.1441, accuracy: 95.6077%, tar: 0.0219 \n",
      "l0: 0.012298, l1: 0.013319, l2: 0.020341, l3: 0.029703, l4: 0.054206, l5: 0.103654, l6: 0.205258\n",
      "\n",
      "[epoch: 362/400, batch: 848/1000, ite: 48107] train loss: 1.1394, accuracy: 97.2300%, tar: 0.0218 \n",
      "l0: 0.021026, l1: 0.022597, l2: 0.028450, l3: 0.042296, l4: 0.075888, l5: 0.140655, l6: 0.296783\n",
      "\n",
      "[epoch: 362/400, batch: 856/1000, ite: 48108] train loss: 1.1375, accuracy: 95.2914%, tar: 0.0218 \n",
      "l0: 0.025282, l1: 0.026694, l2: 0.034267, l3: 0.049357, l4: 0.085245, l5: 0.163595, l6: 0.329644\n",
      "\n",
      "[epoch: 362/400, batch: 864/1000, ite: 48109] train loss: 1.1367, accuracy: 94.8682%, tar: 0.0218 \n",
      "l0: 0.019556, l1: 0.020268, l2: 0.028624, l3: 0.042165, l4: 0.074528, l5: 0.155023, l6: 0.306745\n",
      "\n",
      "[epoch: 362/400, batch: 872/1000, ite: 48110] train loss: 1.1350, accuracy: 95.7515%, tar: 0.0218 \n",
      "l0: 0.013809, l1: 0.015097, l2: 0.022334, l3: 0.033376, l4: 0.070522, l5: 0.128804, l6: 0.407602\n",
      "\n",
      "[epoch: 362/400, batch: 880/1000, ite: 48111] train loss: 1.1347, accuracy: 95.4751%, tar: 0.0217 \n",
      "l0: 0.014768, l1: 0.016267, l2: 0.022040, l3: 0.033843, l4: 0.064290, l5: 0.145445, l6: 0.298683\n",
      "\n",
      "[epoch: 362/400, batch: 888/1000, ite: 48112] train loss: 1.1326, accuracy: 96.3412%, tar: 0.0216 \n",
      "l0: 0.016675, l1: 0.016937, l2: 0.020774, l3: 0.027718, l4: 0.048831, l5: 0.087996, l6: 0.187788\n",
      "\n",
      "[epoch: 362/400, batch: 896/1000, ite: 48113] train loss: 1.1279, accuracy: 96.4464%, tar: 0.0216 \n",
      "l0: 0.018540, l1: 0.019690, l2: 0.027914, l3: 0.045295, l4: 0.089803, l5: 0.172006, l6: 0.402540\n",
      "\n",
      "[epoch: 362/400, batch: 904/1000, ite: 48114] train loss: 1.1284, accuracy: 95.4832%, tar: 0.0216 \n",
      "l0: 0.026515, l1: 0.028327, l2: 0.037413, l3: 0.060971, l4: 0.120241, l5: 0.221755, l6: 0.505342\n",
      "\n",
      "[epoch: 362/400, batch: 912/1000, ite: 48115] train loss: 1.1317, accuracy: 93.6276%, tar: 0.0216 \n",
      "l0: 0.022576, l1: 0.024904, l2: 0.035512, l3: 0.053110, l4: 0.095708, l5: 0.192763, l6: 0.416766\n",
      "\n",
      "[epoch: 362/400, batch: 920/1000, ite: 48116] train loss: 1.1328, accuracy: 95.2649%, tar: 0.0216 \n",
      "l0: 0.022606, l1: 0.024616, l2: 0.034201, l3: 0.051538, l4: 0.109570, l5: 0.211727, l6: 0.409585\n",
      "\n",
      "[epoch: 362/400, batch: 928/1000, ite: 48117] train loss: 1.1340, accuracy: 94.7788%, tar: 0.0216 \n",
      "l0: 0.029396, l1: 0.033746, l2: 0.042886, l3: 0.058858, l4: 0.101618, l5: 0.215261, l6: 0.419863\n",
      "\n",
      "[epoch: 362/400, batch: 936/1000, ite: 48118] train loss: 1.1357, accuracy: 94.0671%, tar: 0.0217 \n",
      "l0: 0.022152, l1: 0.023199, l2: 0.030306, l3: 0.044287, l4: 0.087899, l5: 0.153859, l6: 0.298448\n",
      "\n",
      "[epoch: 362/400, batch: 944/1000, ite: 48119] train loss: 1.1342, accuracy: 95.7494%, tar: 0.0217 \n",
      "l0: 0.024842, l1: 0.025988, l2: 0.033576, l3: 0.047441, l4: 0.080109, l5: 0.156062, l6: 0.314610\n",
      "\n",
      "[epoch: 362/400, batch: 952/1000, ite: 48120] train loss: 1.1331, accuracy: 94.9638%, tar: 0.0217 \n",
      "l0: 0.023178, l1: 0.024410, l2: 0.031775, l3: 0.045367, l4: 0.082550, l5: 0.169623, l6: 0.420276\n",
      "\n",
      "[epoch: 362/400, batch: 960/1000, ite: 48121] train loss: 1.1338, accuracy: 94.4545%, tar: 0.0217 \n",
      "l0: 0.023701, l1: 0.025535, l2: 0.033750, l3: 0.053127, l4: 0.118457, l5: 0.233187, l6: 0.484426\n",
      "\n",
      "[epoch: 362/400, batch: 968/1000, ite: 48122] train loss: 1.1364, accuracy: 93.7685%, tar: 0.0218 \n",
      "l0: 0.019633, l1: 0.021227, l2: 0.029813, l3: 0.046130, l4: 0.082846, l5: 0.141074, l6: 0.286471\n",
      "\n",
      "[epoch: 362/400, batch: 976/1000, ite: 48123] train loss: 1.1347, accuracy: 95.8058%, tar: 0.0217 \n",
      "l0: 0.019723, l1: 0.021646, l2: 0.031411, l3: 0.050909, l4: 0.100872, l5: 0.215059, l6: 0.374853\n",
      "\n",
      "[epoch: 362/400, batch: 984/1000, ite: 48124] train loss: 1.1352, accuracy: 95.5893%, tar: 0.0217 \n",
      "l0: 0.025341, l1: 0.027290, l2: 0.035880, l3: 0.057187, l4: 0.101547, l5: 0.208237, l6: 0.367011\n",
      "\n",
      "[epoch: 362/400, batch: 992/1000, ite: 48125] train loss: 1.1356, accuracy: 95.3530%, tar: 0.0217 \n",
      "l0: 0.021374, l1: 0.022148, l2: 0.027532, l3: 0.040463, l4: 0.068476, l5: 0.148522, l6: 0.317414\n",
      "\n",
      "[epoch: 362/400, batch: 1000/1000, ite: 48126] train loss: 1.1343, accuracy: 95.1440%, tar: 0.0217 \n",
      "l0: 0.018349, l1: 0.018648, l2: 0.025203, l3: 0.037400, l4: 0.074947, l5: 0.144527, l6: 0.343952\n",
      "\n",
      "[epoch: 363/400, batch: 8/1000, ite: 48127] train loss: 1.1333, accuracy: 96.0053%, tar: 0.0217 \n",
      "l0: 0.019804, l1: 0.021087, l2: 0.028076, l3: 0.043595, l4: 0.088712, l5: 0.156110, l6: 0.311694\n",
      "\n",
      "[epoch: 363/400, batch: 16/1000, ite: 48128] train loss: 1.1322, accuracy: 95.4046%, tar: 0.0217 \n",
      "l0: 0.026261, l1: 0.027280, l2: 0.035588, l3: 0.052053, l4: 0.093929, l5: 0.188789, l6: 0.404692\n",
      "\n",
      "[epoch: 363/400, batch: 24/1000, ite: 48129] train loss: 1.1330, accuracy: 94.3351%, tar: 0.0217 \n",
      "l0: 0.020671, l1: 0.021774, l2: 0.029448, l3: 0.040709, l4: 0.068332, l5: 0.114325, l6: 0.254926\n",
      "\n",
      "[epoch: 363/400, batch: 32/1000, ite: 48130] train loss: 1.1305, accuracy: 95.8152%, tar: 0.0217 \n",
      "l0: 0.020825, l1: 0.023910, l2: 0.035851, l3: 0.065131, l4: 0.140422, l5: 0.274354, l6: 0.420582\n",
      "\n",
      "[epoch: 363/400, batch: 40/1000, ite: 48131] train loss: 1.1326, accuracy: 95.5032%, tar: 0.0217 \n",
      "l0: 0.023658, l1: 0.024695, l2: 0.032502, l3: 0.048947, l4: 0.092470, l5: 0.223455, l6: 0.437279\n",
      "\n",
      "[epoch: 363/400, batch: 48/1000, ite: 48132] train loss: 1.1339, accuracy: 94.0340%, tar: 0.0217 \n",
      "l0: 0.023231, l1: 0.024655, l2: 0.033988, l3: 0.050771, l4: 0.104401, l5: 0.233123, l6: 0.455328\n",
      "\n",
      "[epoch: 363/400, batch: 56/1000, ite: 48133] train loss: 1.1358, accuracy: 94.2089%, tar: 0.0217 \n",
      "l0: 0.015600, l1: 0.016447, l2: 0.022386, l3: 0.037167, l4: 0.085414, l5: 0.176354, l6: 0.334421\n",
      "\n",
      "[epoch: 363/400, batch: 64/1000, ite: 48134] train loss: 1.1350, accuracy: 95.1376%, tar: 0.0217 \n",
      "l0: 0.021711, l1: 0.022720, l2: 0.029002, l3: 0.044734, l4: 0.082739, l5: 0.151057, l6: 0.313490\n",
      "\n",
      "[epoch: 363/400, batch: 72/1000, ite: 48135] train loss: 1.1339, accuracy: 95.2847%, tar: 0.0217 \n",
      "l0: 0.015388, l1: 0.016167, l2: 0.024046, l3: 0.039273, l4: 0.074023, l5: 0.140003, l6: 0.244685\n",
      "\n",
      "[epoch: 363/400, batch: 80/1000, ite: 48136] train loss: 1.1315, accuracy: 96.5772%, tar: 0.0217 \n",
      "l0: 0.023830, l1: 0.026277, l2: 0.032749, l3: 0.047916, l4: 0.091853, l5: 0.194318, l6: 0.357376\n",
      "\n",
      "[epoch: 363/400, batch: 88/1000, ite: 48137] train loss: 1.1315, accuracy: 95.3404%, tar: 0.0217 \n",
      "l0: 0.021836, l1: 0.023177, l2: 0.031145, l3: 0.048964, l4: 0.093075, l5: 0.161297, l6: 0.339746\n",
      "\n",
      "[epoch: 363/400, batch: 96/1000, ite: 48138] train loss: 1.1310, accuracy: 95.5325%, tar: 0.0217 \n",
      "l0: 0.027411, l1: 0.030701, l2: 0.042448, l3: 0.067998, l4: 0.122646, l5: 0.244220, l6: 0.433405\n",
      "\n",
      "[epoch: 363/400, batch: 104/1000, ite: 48139] train loss: 1.1330, accuracy: 95.0443%, tar: 0.0217 \n",
      "l0: 0.019498, l1: 0.020487, l2: 0.027969, l3: 0.042198, l4: 0.075703, l5: 0.170049, l6: 0.365849\n",
      "\n",
      "[epoch: 363/400, batch: 112/1000, ite: 48140] train loss: 1.1327, accuracy: 95.1510%, tar: 0.0217 \n",
      "l0: 0.025447, l1: 0.027175, l2: 0.035607, l3: 0.051416, l4: 0.095903, l5: 0.192839, l6: 0.409989\n",
      "\n",
      "[epoch: 363/400, batch: 120/1000, ite: 48141] train loss: 1.1336, accuracy: 94.5919%, tar: 0.0217 \n",
      "l0: 0.019346, l1: 0.020361, l2: 0.027290, l3: 0.042916, l4: 0.085322, l5: 0.164907, l6: 0.342311\n",
      "\n",
      "[epoch: 363/400, batch: 128/1000, ite: 48142] train loss: 1.1330, accuracy: 95.3306%, tar: 0.0217 \n",
      "l0: 0.016837, l1: 0.017965, l2: 0.024275, l3: 0.032556, l4: 0.053965, l5: 0.131540, l6: 0.297602\n",
      "\n",
      "[epoch: 363/400, batch: 136/1000, ite: 48143] train loss: 1.1313, accuracy: 96.9491%, tar: 0.0217 \n",
      "l0: 0.019433, l1: 0.020595, l2: 0.028646, l3: 0.045771, l4: 0.092427, l5: 0.182937, l6: 0.346886\n",
      "\n",
      "[epoch: 363/400, batch: 144/1000, ite: 48144] train loss: 1.1310, accuracy: 95.5550%, tar: 0.0217 \n",
      "l0: 0.017417, l1: 0.018190, l2: 0.025468, l3: 0.036578, l4: 0.063353, l5: 0.120213, l6: 0.261742\n",
      "\n",
      "[epoch: 363/400, batch: 152/1000, ite: 48145] train loss: 1.1288, accuracy: 96.6270%, tar: 0.0216 \n",
      "l0: 0.020354, l1: 0.022241, l2: 0.026545, l3: 0.045206, l4: 0.069476, l5: 0.136407, l6: 0.248755\n",
      "\n",
      "[epoch: 363/400, batch: 160/1000, ite: 48146] train loss: 1.1267, accuracy: 96.4549%, tar: 0.0216 \n",
      "l0: 0.021543, l1: 0.022580, l2: 0.029457, l3: 0.042335, l4: 0.075300, l5: 0.158574, l6: 0.419888\n",
      "\n",
      "[epoch: 363/400, batch: 168/1000, ite: 48147] train loss: 1.1271, accuracy: 94.8913%, tar: 0.0216 \n",
      "l0: 0.022725, l1: 0.023848, l2: 0.031025, l3: 0.044317, l4: 0.076509, l5: 0.149005, l6: 0.331907\n",
      "\n",
      "[epoch: 363/400, batch: 176/1000, ite: 48148] train loss: 1.1264, accuracy: 95.0392%, tar: 0.0216 \n",
      "l0: 0.017785, l1: 0.018856, l2: 0.026058, l3: 0.039830, l4: 0.075565, l5: 0.155658, l6: 0.354208\n",
      "\n",
      "[epoch: 363/400, batch: 184/1000, ite: 48149] train loss: 1.1259, accuracy: 95.2806%, tar: 0.0216 \n",
      "l0: 0.021079, l1: 0.022756, l2: 0.031700, l3: 0.050879, l4: 0.089745, l5: 0.171198, l6: 0.318701\n",
      "\n",
      "[epoch: 363/400, batch: 192/1000, ite: 48150] train loss: 1.1252, accuracy: 95.2708%, tar: 0.0216 \n",
      "l0: 0.020024, l1: 0.022956, l2: 0.034594, l3: 0.058798, l4: 0.117021, l5: 0.209668, l6: 0.344103\n",
      "\n",
      "[epoch: 363/400, batch: 200/1000, ite: 48151] train loss: 1.1254, accuracy: 95.5845%, tar: 0.0216 \n",
      "l0: 0.019395, l1: 0.020546, l2: 0.027879, l3: 0.039013, l4: 0.071519, l5: 0.146190, l6: 0.334222\n",
      "\n",
      "[epoch: 363/400, batch: 208/1000, ite: 48152] train loss: 1.1246, accuracy: 94.8797%, tar: 0.0216 \n",
      "l0: 0.017203, l1: 0.018807, l2: 0.026175, l3: 0.040257, l4: 0.075943, l5: 0.155520, l6: 0.332706\n",
      "\n",
      "[epoch: 363/400, batch: 216/1000, ite: 48153] train loss: 1.1238, accuracy: 95.2711%, tar: 0.0215 \n",
      "l0: 0.023140, l1: 0.025009, l2: 0.034460, l3: 0.056022, l4: 0.111517, l5: 0.244246, l6: 0.430085\n",
      "\n",
      "[epoch: 363/400, batch: 224/1000, ite: 48154] train loss: 1.1253, accuracy: 93.9667%, tar: 0.0216 \n",
      "l0: 0.020176, l1: 0.021106, l2: 0.028762, l3: 0.044587, l4: 0.080403, l5: 0.152178, l6: 0.335591\n",
      "\n",
      "[epoch: 363/400, batch: 232/1000, ite: 48155] train loss: 1.1246, accuracy: 95.2548%, tar: 0.0215 \n",
      "l0: 0.012091, l1: 0.012711, l2: 0.017394, l3: 0.024379, l4: 0.042889, l5: 0.093458, l6: 0.238336\n",
      "\n",
      "[epoch: 363/400, batch: 240/1000, ite: 48156] train loss: 1.1218, accuracy: 96.9709%, tar: 0.0215 \n",
      "l0: 0.019380, l1: 0.021379, l2: 0.030575, l3: 0.050693, l4: 0.102577, l5: 0.197686, l6: 0.435439\n",
      "\n",
      "[epoch: 363/400, batch: 248/1000, ite: 48157] train loss: 1.1229, accuracy: 95.3165%, tar: 0.0215 \n",
      "l0: 0.021246, l1: 0.022011, l2: 0.029019, l3: 0.041757, l4: 0.068721, l5: 0.127325, l6: 0.259135\n",
      "\n",
      "[epoch: 363/400, batch: 256/1000, ite: 48158] train loss: 1.1210, accuracy: 95.6336%, tar: 0.0215 \n",
      "l0: 0.029750, l1: 0.032111, l2: 0.041521, l3: 0.062470, l4: 0.131286, l5: 0.285552, l6: 0.532367\n",
      "\n",
      "[epoch: 363/400, batch: 264/1000, ite: 48159] train loss: 1.1244, accuracy: 93.0900%, tar: 0.0215 \n",
      "l0: 0.021074, l1: 0.021979, l2: 0.029397, l3: 0.045231, l4: 0.082161, l5: 0.142237, l6: 0.289739\n",
      "\n",
      "[epoch: 363/400, batch: 272/1000, ite: 48160] train loss: 1.1231, accuracy: 95.3242%, tar: 0.0215 \n",
      "l0: 0.023325, l1: 0.024551, l2: 0.031767, l3: 0.043326, l4: 0.070388, l5: 0.135502, l6: 0.312191\n",
      "\n",
      "[epoch: 363/400, batch: 280/1000, ite: 48161] train loss: 1.1221, accuracy: 95.1041%, tar: 0.0215 \n",
      "l0: 0.023915, l1: 0.026188, l2: 0.034817, l3: 0.052496, l4: 0.088467, l5: 0.180395, l6: 0.377313\n",
      "\n",
      "[epoch: 363/400, batch: 288/1000, ite: 48162] train loss: 1.1224, accuracy: 95.5345%, tar: 0.0215 \n",
      "l0: 0.024298, l1: 0.025638, l2: 0.034616, l3: 0.051515, l4: 0.106983, l5: 0.210348, l6: 0.404576\n",
      "\n",
      "[epoch: 363/400, batch: 296/1000, ite: 48163] train loss: 1.1233, accuracy: 94.4682%, tar: 0.0216 \n",
      "l0: 0.024824, l1: 0.025929, l2: 0.033975, l3: 0.050686, l4: 0.087088, l5: 0.191988, l6: 0.399121\n",
      "\n",
      "[epoch: 363/400, batch: 304/1000, ite: 48164] train loss: 1.1238, accuracy: 94.2940%, tar: 0.0216 \n",
      "l0: 0.025725, l1: 0.026955, l2: 0.034563, l3: 0.052190, l4: 0.102459, l5: 0.199371, l6: 0.441423\n",
      "\n",
      "[epoch: 363/400, batch: 312/1000, ite: 48165] train loss: 1.1251, accuracy: 93.7673%, tar: 0.0216 \n",
      "l0: 0.024356, l1: 0.025973, l2: 0.034600, l3: 0.054019, l4: 0.106313, l5: 0.223186, l6: 0.511301\n",
      "\n",
      "[epoch: 363/400, batch: 320/1000, ite: 48166] train loss: 1.1273, accuracy: 92.8350%, tar: 0.0216 \n",
      "l0: 0.016680, l1: 0.017751, l2: 0.024731, l3: 0.040231, l4: 0.087330, l5: 0.173484, l6: 0.363883\n",
      "\n",
      "[epoch: 363/400, batch: 328/1000, ite: 48167] train loss: 1.1271, accuracy: 95.1537%, tar: 0.0216 \n",
      "l0: 0.021078, l1: 0.022285, l2: 0.028721, l3: 0.044763, l4: 0.083371, l5: 0.163033, l6: 0.298725\n",
      "\n",
      "[epoch: 363/400, batch: 336/1000, ite: 48168] train loss: 1.1261, accuracy: 95.2422%, tar: 0.0216 \n",
      "l0: 0.019935, l1: 0.021223, l2: 0.029994, l3: 0.049677, l4: 0.093978, l5: 0.203228, l6: 0.428547\n",
      "\n",
      "[epoch: 363/400, batch: 344/1000, ite: 48169] train loss: 1.1270, accuracy: 94.5559%, tar: 0.0216 \n",
      "l0: 0.025900, l1: 0.027152, l2: 0.034653, l3: 0.050741, l4: 0.089617, l5: 0.183368, l6: 0.369333\n",
      "\n",
      "[epoch: 363/400, batch: 352/1000, ite: 48170] train loss: 1.1272, accuracy: 94.3365%, tar: 0.0216 \n",
      "l0: 0.025751, l1: 0.027829, l2: 0.038930, l3: 0.058938, l4: 0.118781, l5: 0.262223, l6: 0.475172\n",
      "\n",
      "[epoch: 363/400, batch: 360/1000, ite: 48171] train loss: 1.1293, accuracy: 93.6265%, tar: 0.0216 \n",
      "l0: 0.022878, l1: 0.024833, l2: 0.032855, l3: 0.051976, l4: 0.101616, l5: 0.232878, l6: 0.473170\n",
      "\n",
      "[epoch: 363/400, batch: 368/1000, ite: 48172] train loss: 1.1310, accuracy: 94.7959%, tar: 0.0216 \n",
      "l0: 0.017166, l1: 0.017799, l2: 0.023282, l3: 0.033965, l4: 0.061478, l5: 0.136838, l6: 0.262423\n",
      "\n",
      "[epoch: 363/400, batch: 376/1000, ite: 48173] train loss: 1.1292, accuracy: 96.1698%, tar: 0.0216 \n",
      "l0: 0.020406, l1: 0.021550, l2: 0.030005, l3: 0.047235, l4: 0.086562, l5: 0.174066, l6: 0.284912\n",
      "\n",
      "[epoch: 363/400, batch: 384/1000, ite: 48174] train loss: 1.1281, accuracy: 95.4049%, tar: 0.0216 \n",
      "l0: 0.018453, l1: 0.019606, l2: 0.026119, l3: 0.036584, l4: 0.061409, l5: 0.116268, l6: 0.259778\n",
      "\n",
      "[epoch: 363/400, batch: 392/1000, ite: 48175] train loss: 1.1263, accuracy: 96.2531%, tar: 0.0216 \n",
      "l0: 0.021184, l1: 0.022448, l2: 0.031279, l3: 0.052678, l4: 0.115712, l5: 0.199055, l6: 0.400534\n",
      "\n",
      "[epoch: 363/400, batch: 400/1000, ite: 48176] train loss: 1.1269, accuracy: 95.0379%, tar: 0.0216 \n",
      "l0: 0.017435, l1: 0.019043, l2: 0.027533, l3: 0.043727, l4: 0.101599, l5: 0.195129, l6: 0.377893\n",
      "\n",
      "[epoch: 363/400, batch: 408/1000, ite: 48177] train loss: 1.1271, accuracy: 95.0291%, tar: 0.0216 \n",
      "l0: 0.013779, l1: 0.014353, l2: 0.018272, l3: 0.025140, l4: 0.043900, l5: 0.081037, l6: 0.174091\n",
      "\n",
      "[epoch: 363/400, batch: 416/1000, ite: 48178] train loss: 1.1239, accuracy: 97.0822%, tar: 0.0215 \n",
      "l0: 0.023980, l1: 0.026060, l2: 0.034497, l3: 0.052429, l4: 0.101404, l5: 0.214678, l6: 0.506554\n",
      "\n",
      "[epoch: 363/400, batch: 424/1000, ite: 48179] train loss: 1.1258, accuracy: 94.3813%, tar: 0.0215 \n",
      "l0: 0.030706, l1: 0.032215, l2: 0.042789, l3: 0.061532, l4: 0.114001, l5: 0.246769, l6: 0.496357\n",
      "\n",
      "[epoch: 363/400, batch: 432/1000, ite: 48180] train loss: 1.1280, accuracy: 93.5296%, tar: 0.0216 \n",
      "l0: 0.022035, l1: 0.023487, l2: 0.029776, l3: 0.045033, l4: 0.087646, l5: 0.195579, l6: 0.397727\n",
      "\n",
      "[epoch: 363/400, batch: 440/1000, ite: 48181] train loss: 1.1284, accuracy: 94.8643%, tar: 0.0216 \n",
      "l0: 0.025261, l1: 0.027131, l2: 0.037842, l3: 0.056116, l4: 0.096442, l5: 0.192026, l6: 0.425404\n",
      "\n",
      "[epoch: 363/400, batch: 448/1000, ite: 48182] train loss: 1.1293, accuracy: 94.0716%, tar: 0.0216 \n",
      "l0: 0.022465, l1: 0.022956, l2: 0.029276, l3: 0.041243, l4: 0.067679, l5: 0.128751, l6: 0.260632\n",
      "\n",
      "[epoch: 363/400, batch: 456/1000, ite: 48183] train loss: 1.1277, accuracy: 95.4779%, tar: 0.0216 \n",
      "l0: 0.021178, l1: 0.022324, l2: 0.028748, l3: 0.041991, l4: 0.080479, l5: 0.160102, l6: 0.312722\n",
      "\n",
      "[epoch: 363/400, batch: 464/1000, ite: 48184] train loss: 1.1269, accuracy: 95.4134%, tar: 0.0216 \n",
      "l0: 0.019407, l1: 0.020939, l2: 0.028463, l3: 0.040013, l4: 0.072402, l5: 0.147468, l6: 0.289596\n",
      "\n",
      "[epoch: 363/400, batch: 472/1000, ite: 48185] train loss: 1.1258, accuracy: 95.7402%, tar: 0.0216 \n",
      "l0: 0.024361, l1: 0.025638, l2: 0.033152, l3: 0.052622, l4: 0.100918, l5: 0.202803, l6: 0.429839\n",
      "\n",
      "[epoch: 363/400, batch: 480/1000, ite: 48186] train loss: 1.1267, accuracy: 94.2131%, tar: 0.0216 \n",
      "l0: 0.020878, l1: 0.022217, l2: 0.030351, l3: 0.043767, l4: 0.078062, l5: 0.169321, l6: 0.324732\n",
      "\n",
      "[epoch: 363/400, batch: 488/1000, ite: 48187] train loss: 1.1261, accuracy: 95.3235%, tar: 0.0216 \n",
      "l0: 0.021076, l1: 0.022331, l2: 0.030769, l3: 0.046390, l4: 0.082126, l5: 0.150119, l6: 0.317730\n",
      "\n",
      "[epoch: 363/400, batch: 496/1000, ite: 48188] train loss: 1.1254, accuracy: 95.8290%, tar: 0.0216 \n",
      "l0: 0.016565, l1: 0.017835, l2: 0.024764, l3: 0.037803, l4: 0.062210, l5: 0.117816, l6: 0.245110\n",
      "\n",
      "[epoch: 363/400, batch: 504/1000, ite: 48189] train loss: 1.1235, accuracy: 96.3236%, tar: 0.0216 \n",
      "l0: 0.023050, l1: 0.023995, l2: 0.031056, l3: 0.047051, l4: 0.082510, l5: 0.175622, l6: 0.333698\n",
      "\n",
      "[epoch: 363/400, batch: 512/1000, ite: 48190] train loss: 1.1232, accuracy: 94.8704%, tar: 0.0216 \n",
      "l0: 0.020911, l1: 0.022407, l2: 0.030993, l3: 0.048069, l4: 0.095276, l5: 0.172003, l6: 0.369609\n",
      "\n",
      "[epoch: 363/400, batch: 520/1000, ite: 48191] train loss: 1.1232, accuracy: 95.1684%, tar: 0.0216 \n",
      "l0: 0.017929, l1: 0.019044, l2: 0.025669, l3: 0.036806, l4: 0.065225, l5: 0.148671, l6: 0.316982\n",
      "\n",
      "[epoch: 363/400, batch: 528/1000, ite: 48192] train loss: 1.1223, accuracy: 95.0910%, tar: 0.0216 \n",
      "l0: 0.028235, l1: 0.029818, l2: 0.038216, l3: 0.055169, l4: 0.102938, l5: 0.202307, l6: 0.450662\n",
      "\n",
      "[epoch: 363/400, batch: 536/1000, ite: 48193] train loss: 1.1236, accuracy: 93.4630%, tar: 0.0216 \n",
      "l0: 0.021450, l1: 0.022596, l2: 0.029901, l3: 0.041486, l4: 0.069245, l5: 0.132632, l6: 0.280958\n",
      "\n",
      "[epoch: 363/400, batch: 544/1000, ite: 48194] train loss: 1.1223, accuracy: 95.6507%, tar: 0.0216 \n",
      "l0: 0.030375, l1: 0.033585, l2: 0.049314, l3: 0.077293, l4: 0.143646, l5: 0.269733, l6: 0.494243\n",
      "\n",
      "[epoch: 363/400, batch: 552/1000, ite: 48195] train loss: 1.1248, accuracy: 93.2974%, tar: 0.0216 \n",
      "l0: 0.024472, l1: 0.026446, l2: 0.035842, l3: 0.059008, l4: 0.122311, l5: 0.226720, l6: 0.428721\n",
      "\n",
      "[epoch: 363/400, batch: 560/1000, ite: 48196] train loss: 1.1259, accuracy: 94.2454%, tar: 0.0217 \n",
      "l0: 0.024740, l1: 0.026262, l2: 0.035554, l3: 0.052239, l4: 0.091748, l5: 0.207623, l6: 0.392464\n",
      "\n",
      "[epoch: 363/400, batch: 568/1000, ite: 48197] train loss: 1.1264, accuracy: 93.9460%, tar: 0.0217 \n",
      "l0: 0.020391, l1: 0.021078, l2: 0.028270, l3: 0.042739, l4: 0.082927, l5: 0.183504, l6: 0.357234\n",
      "\n",
      "[epoch: 363/400, batch: 576/1000, ite: 48198] train loss: 1.1262, accuracy: 95.6000%, tar: 0.0217 \n",
      "l0: 0.019889, l1: 0.021153, l2: 0.030610, l3: 0.048328, l4: 0.090859, l5: 0.182942, l6: 0.361152\n",
      "\n",
      "[epoch: 363/400, batch: 584/1000, ite: 48199] train loss: 1.1262, accuracy: 95.0586%, tar: 0.0217 \n",
      "l0: 0.021104, l1: 0.022920, l2: 0.032014, l3: 0.049047, l4: 0.086805, l5: 0.200367, l6: 0.402048\n",
      "\n",
      "[epoch: 363/400, batch: 592/1000, ite: 48200] train loss: 1.1267, accuracy: 94.4010%, tar: 0.0217 \n",
      "l0: 0.020878, l1: 0.021632, l2: 0.027429, l3: 0.037175, l4: 0.063819, l5: 0.128082, l6: 0.311397\n",
      "\n",
      "[epoch: 363/400, batch: 600/1000, ite: 48201] train loss: 1.1257, accuracy: 95.4589%, tar: 0.0216 \n",
      "l0: 0.032627, l1: 0.034378, l2: 0.043936, l3: 0.068953, l4: 0.141917, l5: 0.268020, l6: 0.523482\n",
      "\n",
      "[epoch: 363/400, batch: 608/1000, ite: 48202] train loss: 1.1282, accuracy: 93.0061%, tar: 0.0217 \n",
      "l0: 0.028099, l1: 0.029338, l2: 0.039477, l3: 0.057080, l4: 0.099460, l5: 0.205215, l6: 0.472934\n",
      "\n",
      "[epoch: 363/400, batch: 616/1000, ite: 48203] train loss: 1.1296, accuracy: 93.3515%, tar: 0.0217 \n",
      "l0: 0.027205, l1: 0.028816, l2: 0.037737, l3: 0.054610, l4: 0.116707, l5: 0.267132, l6: 0.527104\n",
      "\n",
      "[epoch: 363/400, batch: 624/1000, ite: 48204] train loss: 1.1319, accuracy: 92.4918%, tar: 0.0218 \n",
      "l0: 0.022040, l1: 0.023212, l2: 0.031270, l3: 0.047919, l4: 0.089795, l5: 0.179199, l6: 0.399248\n",
      "\n",
      "[epoch: 363/400, batch: 632/1000, ite: 48205] train loss: 1.1322, accuracy: 94.9019%, tar: 0.0218 \n",
      "l0: 0.020606, l1: 0.021540, l2: 0.028695, l3: 0.041881, l4: 0.072814, l5: 0.143575, l6: 0.331139\n",
      "\n",
      "[epoch: 363/400, batch: 640/1000, ite: 48206] train loss: 1.1315, accuracy: 95.5582%, tar: 0.0218 \n",
      "l0: 0.020497, l1: 0.021606, l2: 0.028259, l3: 0.044559, l4: 0.089528, l5: 0.180556, l6: 0.423089\n",
      "\n",
      "[epoch: 363/400, batch: 648/1000, ite: 48207] train loss: 1.1320, accuracy: 94.8291%, tar: 0.0218 \n",
      "l0: 0.023687, l1: 0.024277, l2: 0.031134, l3: 0.045437, l4: 0.077201, l5: 0.155747, l6: 0.319949\n",
      "\n",
      "[epoch: 363/400, batch: 656/1000, ite: 48208] train loss: 1.1314, accuracy: 95.0840%, tar: 0.0218 \n",
      "l0: 0.021565, l1: 0.022051, l2: 0.030559, l3: 0.045168, l4: 0.079039, l5: 0.145024, l6: 0.339965\n",
      "\n",
      "[epoch: 363/400, batch: 664/1000, ite: 48209] train loss: 1.1309, accuracy: 95.2720%, tar: 0.0218 \n",
      "l0: 0.023978, l1: 0.025858, l2: 0.032905, l3: 0.050217, l4: 0.097579, l5: 0.199814, l6: 0.442082\n",
      "\n",
      "[epoch: 363/400, batch: 672/1000, ite: 48210] train loss: 1.1318, accuracy: 94.3320%, tar: 0.0218 \n",
      "l0: 0.024314, l1: 0.026132, l2: 0.034870, l3: 0.054941, l4: 0.100278, l5: 0.184764, l6: 0.372143\n",
      "\n",
      "[epoch: 363/400, batch: 680/1000, ite: 48211] train loss: 1.1320, accuracy: 94.6388%, tar: 0.0218 \n",
      "l0: 0.023418, l1: 0.024583, l2: 0.033151, l3: 0.051642, l4: 0.088125, l5: 0.148669, l6: 0.319198\n",
      "\n",
      "[epoch: 363/400, batch: 688/1000, ite: 48212] train loss: 1.1315, accuracy: 95.2925%, tar: 0.0218 \n",
      "l0: 0.020591, l1: 0.021930, l2: 0.027959, l3: 0.044058, l4: 0.077095, l5: 0.135731, l6: 0.255323\n",
      "\n",
      "[epoch: 363/400, batch: 696/1000, ite: 48213] train loss: 1.1301, accuracy: 95.7946%, tar: 0.0218 \n",
      "l0: 0.015054, l1: 0.015859, l2: 0.022637, l3: 0.033068, l4: 0.062507, l5: 0.127163, l6: 0.247405\n",
      "\n",
      "[epoch: 363/400, batch: 704/1000, ite: 48214] train loss: 1.1285, accuracy: 96.2858%, tar: 0.0218 \n",
      "l0: 0.019931, l1: 0.021292, l2: 0.029540, l3: 0.041027, l4: 0.076388, l5: 0.177924, l6: 0.435934\n",
      "\n",
      "[epoch: 363/400, batch: 712/1000, ite: 48215] train loss: 1.1290, accuracy: 94.8629%, tar: 0.0217 \n",
      "l0: 0.021537, l1: 0.023746, l2: 0.033064, l3: 0.053962, l4: 0.113778, l5: 0.226848, l6: 0.426718\n",
      "\n",
      "[epoch: 363/400, batch: 720/1000, ite: 48216] train loss: 1.1299, accuracy: 94.3390%, tar: 0.0217 \n",
      "l0: 0.027726, l1: 0.031250, l2: 0.042808, l3: 0.071911, l4: 0.144140, l5: 0.296995, l6: 0.506595\n",
      "\n",
      "[epoch: 363/400, batch: 728/1000, ite: 48217] train loss: 1.1322, accuracy: 93.5307%, tar: 0.0218 \n",
      "l0: 0.018957, l1: 0.020402, l2: 0.027888, l3: 0.045638, l4: 0.098293, l5: 0.237047, l6: 0.502861\n",
      "\n",
      "[epoch: 363/400, batch: 736/1000, ite: 48218] train loss: 1.1337, accuracy: 94.1064%, tar: 0.0218 \n",
      "l0: 0.022250, l1: 0.023276, l2: 0.030164, l3: 0.046288, l4: 0.084587, l5: 0.178293, l6: 0.409685\n",
      "\n",
      "[epoch: 363/400, batch: 744/1000, ite: 48219] train loss: 1.1340, accuracy: 94.1645%, tar: 0.0218 \n",
      "l0: 0.021540, l1: 0.022310, l2: 0.026686, l3: 0.035939, l4: 0.063493, l5: 0.129410, l6: 0.342361\n",
      "\n",
      "[epoch: 363/400, batch: 752/1000, ite: 48220] train loss: 1.1334, accuracy: 94.7828%, tar: 0.0218 \n",
      "l0: 0.025032, l1: 0.026377, l2: 0.032989, l3: 0.050509, l4: 0.106559, l5: 0.231081, l6: 0.446202\n",
      "\n",
      "[epoch: 363/400, batch: 760/1000, ite: 48221] train loss: 1.1345, accuracy: 93.9202%, tar: 0.0218 \n",
      "l0: 0.016605, l1: 0.017748, l2: 0.025240, l3: 0.040535, l4: 0.082637, l5: 0.161804, l6: 0.295364\n",
      "\n",
      "[epoch: 363/400, batch: 768/1000, ite: 48222] train loss: 1.1336, accuracy: 95.8764%, tar: 0.0218 \n",
      "l0: 0.023754, l1: 0.025561, l2: 0.036160, l3: 0.054804, l4: 0.098514, l5: 0.226371, l6: 0.453207\n",
      "\n",
      "[epoch: 363/400, batch: 776/1000, ite: 48223] train loss: 1.1347, accuracy: 94.4391%, tar: 0.0218 \n",
      "l0: 0.018946, l1: 0.020847, l2: 0.030142, l3: 0.048407, l4: 0.092617, l5: 0.181207, l6: 0.340477\n",
      "\n",
      "[epoch: 363/400, batch: 784/1000, ite: 48224] train loss: 1.1344, accuracy: 95.7302%, tar: 0.0217 \n",
      "l0: 0.013920, l1: 0.014819, l2: 0.020191, l3: 0.030008, l4: 0.051105, l5: 0.086483, l6: 0.204560\n",
      "\n",
      "[epoch: 363/400, batch: 792/1000, ite: 48225] train loss: 1.1322, accuracy: 96.9865%, tar: 0.0217 \n",
      "l0: 0.020847, l1: 0.022354, l2: 0.029316, l3: 0.045798, l4: 0.106872, l5: 0.205896, l6: 0.405529\n",
      "\n",
      "[epoch: 363/400, batch: 800/1000, ite: 48226] train loss: 1.1327, accuracy: 94.3200%, tar: 0.0217 \n",
      "l0: 0.022018, l1: 0.022657, l2: 0.029863, l3: 0.040999, l4: 0.071056, l5: 0.166303, l6: 0.343837\n",
      "\n",
      "[epoch: 363/400, batch: 808/1000, ite: 48227] train loss: 1.1323, accuracy: 94.7916%, tar: 0.0217 \n",
      "l0: 0.022290, l1: 0.023713, l2: 0.030975, l3: 0.048896, l4: 0.086243, l5: 0.168559, l6: 0.390943\n",
      "\n",
      "[epoch: 363/400, batch: 816/1000, ite: 48228] train loss: 1.1324, accuracy: 94.8284%, tar: 0.0217 \n",
      "l0: 0.020818, l1: 0.022510, l2: 0.029961, l3: 0.047254, l4: 0.110935, l5: 0.218604, l6: 0.406653\n",
      "\n",
      "[epoch: 363/400, batch: 824/1000, ite: 48229] train loss: 1.1330, accuracy: 95.1090%, tar: 0.0217 \n",
      "l0: 0.017820, l1: 0.019121, l2: 0.026072, l3: 0.039741, l4: 0.085040, l5: 0.221462, l6: 0.420364\n",
      "\n",
      "[epoch: 363/400, batch: 832/1000, ite: 48230] train loss: 1.1335, accuracy: 94.3322%, tar: 0.0217 \n",
      "l0: 0.021532, l1: 0.022618, l2: 0.030573, l3: 0.043328, l4: 0.082019, l5: 0.163638, l6: 0.330452\n",
      "\n",
      "[epoch: 363/400, batch: 840/1000, ite: 48231] train loss: 1.1331, accuracy: 94.8915%, tar: 0.0217 \n",
      "l0: 0.020355, l1: 0.021462, l2: 0.029772, l3: 0.046146, l4: 0.088369, l5: 0.174279, l6: 0.374458\n",
      "\n",
      "[epoch: 363/400, batch: 848/1000, ite: 48232] train loss: 1.1331, accuracy: 95.6097%, tar: 0.0217 \n",
      "l0: 0.020190, l1: 0.021744, l2: 0.030406, l3: 0.047792, l4: 0.091521, l5: 0.218202, l6: 0.511086\n",
      "\n",
      "[epoch: 363/400, batch: 856/1000, ite: 48233] train loss: 1.1345, accuracy: 94.4896%, tar: 0.0217 \n",
      "l0: 0.016262, l1: 0.018083, l2: 0.027256, l3: 0.043076, l4: 0.085867, l5: 0.154228, l6: 0.290397\n",
      "\n",
      "[epoch: 363/400, batch: 864/1000, ite: 48234] train loss: 1.1336, accuracy: 96.7147%, tar: 0.0217 \n",
      "l0: 0.020193, l1: 0.021507, l2: 0.029524, l3: 0.046005, l4: 0.085773, l5: 0.196583, l6: 0.422776\n",
      "\n",
      "[epoch: 363/400, batch: 872/1000, ite: 48235] train loss: 1.1341, accuracy: 94.4284%, tar: 0.0217 \n",
      "l0: 0.018645, l1: 0.020265, l2: 0.028721, l3: 0.042817, l4: 0.078615, l5: 0.147823, l6: 0.396909\n",
      "\n",
      "[epoch: 363/400, batch: 880/1000, ite: 48236] train loss: 1.1341, accuracy: 95.2586%, tar: 0.0216 \n",
      "l0: 0.015841, l1: 0.016879, l2: 0.024501, l3: 0.036275, l4: 0.059147, l5: 0.114908, l6: 0.274860\n",
      "\n",
      "[epoch: 363/400, batch: 888/1000, ite: 48237] train loss: 1.1327, accuracy: 96.3320%, tar: 0.0216 \n",
      "l0: 0.019273, l1: 0.020686, l2: 0.026864, l3: 0.040582, l4: 0.064428, l5: 0.112073, l6: 0.246644\n",
      "\n",
      "[epoch: 363/400, batch: 896/1000, ite: 48238] train loss: 1.1313, accuracy: 96.4150%, tar: 0.0216 \n",
      "l0: 0.025030, l1: 0.026041, l2: 0.035178, l3: 0.050505, l4: 0.085553, l5: 0.205640, l6: 0.453173\n",
      "\n",
      "[epoch: 363/400, batch: 904/1000, ite: 48239] train loss: 1.1322, accuracy: 93.8392%, tar: 0.0216 \n",
      "l0: 0.019252, l1: 0.020636, l2: 0.028919, l3: 0.042335, l4: 0.077914, l5: 0.156927, l6: 0.390500\n",
      "\n",
      "[epoch: 363/400, batch: 912/1000, ite: 48240] train loss: 1.1322, accuracy: 95.3344%, tar: 0.0216 \n",
      "l0: 0.034257, l1: 0.036781, l2: 0.049422, l3: 0.076057, l4: 0.140248, l5: 0.302432, l6: 0.544862\n",
      "\n",
      "[epoch: 363/400, batch: 920/1000, ite: 48241] train loss: 1.1347, accuracy: 92.3482%, tar: 0.0217 \n",
      "l0: 0.023296, l1: 0.025107, l2: 0.031181, l3: 0.045320, l4: 0.074990, l5: 0.133661, l6: 0.296613\n",
      "\n",
      "[epoch: 363/400, batch: 928/1000, ite: 48242] train loss: 1.1339, accuracy: 95.1121%, tar: 0.0217 \n",
      "l0: 0.021938, l1: 0.023125, l2: 0.031983, l3: 0.046781, l4: 0.072196, l5: 0.130595, l6: 0.259685\n",
      "\n",
      "[epoch: 363/400, batch: 936/1000, ite: 48243] train loss: 1.1327, accuracy: 95.7716%, tar: 0.0217 \n",
      "l0: 0.022690, l1: 0.023525, l2: 0.030840, l3: 0.051539, l4: 0.092549, l5: 0.210585, l6: 0.392376\n",
      "\n",
      "[epoch: 363/400, batch: 944/1000, ite: 48244] train loss: 1.1331, accuracy: 94.6475%, tar: 0.0217 \n",
      "l0: 0.023861, l1: 0.025259, l2: 0.032597, l3: 0.047591, l4: 0.088155, l5: 0.218028, l6: 0.485571\n",
      "\n",
      "[epoch: 363/400, batch: 952/1000, ite: 48245] train loss: 1.1342, accuracy: 93.9075%, tar: 0.0217 \n",
      "l0: 0.024353, l1: 0.026175, l2: 0.035144, l3: 0.050555, l4: 0.088676, l5: 0.159604, l6: 0.331008\n",
      "\n",
      "[epoch: 363/400, batch: 960/1000, ite: 48246] train loss: 1.1339, accuracy: 95.8891%, tar: 0.0217 \n",
      "l0: 0.020663, l1: 0.021690, l2: 0.028772, l3: 0.043478, l4: 0.086007, l5: 0.185694, l6: 0.349628\n",
      "\n",
      "[epoch: 363/400, batch: 968/1000, ite: 48247] train loss: 1.1337, accuracy: 94.4001%, tar: 0.0217 \n",
      "l0: 0.019706, l1: 0.020196, l2: 0.027169, l3: 0.039458, l4: 0.068718, l5: 0.153927, l6: 0.328609\n",
      "\n",
      "[epoch: 363/400, batch: 976/1000, ite: 48248] train loss: 1.1331, accuracy: 95.4299%, tar: 0.0217 \n",
      "l0: 0.023112, l1: 0.023689, l2: 0.030531, l3: 0.043262, l4: 0.072531, l5: 0.128244, l6: 0.306228\n",
      "\n",
      "[epoch: 363/400, batch: 984/1000, ite: 48249] train loss: 1.1323, accuracy: 95.3011%, tar: 0.0217 \n",
      "l0: 0.018829, l1: 0.019707, l2: 0.025230, l3: 0.036969, l4: 0.084633, l5: 0.157843, l6: 0.281772\n",
      "\n",
      "[epoch: 363/400, batch: 992/1000, ite: 48250] train loss: 1.1314, accuracy: 96.3018%, tar: 0.0217 \n",
      "l0: 0.020982, l1: 0.022711, l2: 0.030105, l3: 0.044675, l4: 0.082779, l5: 0.168973, l6: 0.407584\n",
      "\n",
      "[epoch: 363/400, batch: 1000/1000, ite: 48251] train loss: 1.1317, accuracy: 94.5401%, tar: 0.0217 \n",
      "l0: 0.025174, l1: 0.026780, l2: 0.036080, l3: 0.049593, l4: 0.092998, l5: 0.196852, l6: 0.407658\n",
      "\n",
      "[epoch: 364/400, batch: 8/1000, ite: 48252] train loss: 1.1322, accuracy: 93.8780%, tar: 0.0217 \n",
      "l0: 0.020261, l1: 0.021394, l2: 0.029144, l3: 0.042064, l4: 0.067486, l5: 0.126452, l6: 0.260486\n",
      "\n",
      "[epoch: 364/400, batch: 16/1000, ite: 48253] train loss: 1.1310, accuracy: 95.8737%, tar: 0.0217 \n",
      "l0: 0.019404, l1: 0.020336, l2: 0.025297, l3: 0.036334, l4: 0.061737, l5: 0.115249, l6: 0.271258\n",
      "\n",
      "[epoch: 364/400, batch: 24/1000, ite: 48254] train loss: 1.1298, accuracy: 95.7824%, tar: 0.0217 \n",
      "l0: 0.021229, l1: 0.022328, l2: 0.028927, l3: 0.042986, l4: 0.076565, l5: 0.134510, l6: 0.290523\n",
      "\n",
      "[epoch: 364/400, batch: 32/1000, ite: 48255] train loss: 1.1289, accuracy: 95.8841%, tar: 0.0217 \n",
      "l0: 0.021091, l1: 0.022266, l2: 0.032642, l3: 0.054726, l4: 0.113762, l5: 0.221747, l6: 0.459113\n",
      "\n",
      "[epoch: 364/400, batch: 40/1000, ite: 48256] train loss: 1.1299, accuracy: 94.4401%, tar: 0.0217 \n",
      "l0: 0.028225, l1: 0.030272, l2: 0.039781, l3: 0.057230, l4: 0.115739, l5: 0.264212, l6: 0.547961\n",
      "\n",
      "[epoch: 364/400, batch: 48/1000, ite: 48257] train loss: 1.1319, accuracy: 93.6015%, tar: 0.0217 \n",
      "l0: 0.019555, l1: 0.021121, l2: 0.029357, l3: 0.044915, l4: 0.091495, l5: 0.181042, l6: 0.316335\n",
      "\n",
      "[epoch: 364/400, batch: 56/1000, ite: 48258] train loss: 1.1315, accuracy: 95.5566%, tar: 0.0217 \n",
      "l0: 0.018699, l1: 0.020945, l2: 0.030241, l3: 0.044961, l4: 0.086684, l5: 0.170442, l6: 0.331285\n",
      "\n",
      "[epoch: 364/400, batch: 64/1000, ite: 48259] train loss: 1.1311, accuracy: 95.9258%, tar: 0.0217 \n",
      "l0: 0.019434, l1: 0.021429, l2: 0.031267, l3: 0.059818, l4: 0.123321, l5: 0.219622, l6: 0.411321\n",
      "\n",
      "[epoch: 364/400, batch: 72/1000, ite: 48260] train loss: 1.1318, accuracy: 94.9331%, tar: 0.0217 \n",
      "l0: 0.021338, l1: 0.022719, l2: 0.029779, l3: 0.043623, l4: 0.084715, l5: 0.168339, l6: 0.369906\n",
      "\n",
      "[epoch: 364/400, batch: 80/1000, ite: 48261] train loss: 1.1317, accuracy: 95.1514%, tar: 0.0217 \n",
      "l0: 0.016509, l1: 0.017763, l2: 0.024742, l3: 0.035695, l4: 0.063370, l5: 0.114965, l6: 0.254189\n",
      "\n",
      "[epoch: 364/400, batch: 88/1000, ite: 48262] train loss: 1.1304, accuracy: 96.9104%, tar: 0.0216 \n",
      "l0: 0.029951, l1: 0.032248, l2: 0.044999, l3: 0.068959, l4: 0.128847, l5: 0.263664, l6: 0.526314\n",
      "\n",
      "[epoch: 364/400, batch: 96/1000, ite: 48263] train loss: 1.1323, accuracy: 92.9818%, tar: 0.0217 \n",
      "l0: 0.015247, l1: 0.016238, l2: 0.024092, l3: 0.039789, l4: 0.080403, l5: 0.160364, l6: 0.368035\n",
      "\n",
      "[epoch: 364/400, batch: 104/1000, ite: 48264] train loss: 1.1320, accuracy: 95.5858%, tar: 0.0217 \n",
      "l0: 0.025385, l1: 0.027134, l2: 0.036663, l3: 0.055410, l4: 0.121827, l5: 0.232336, l6: 0.509143\n",
      "\n",
      "[epoch: 364/400, batch: 112/1000, ite: 48265] train loss: 1.1335, accuracy: 93.1690%, tar: 0.0217 \n",
      "l0: 0.019004, l1: 0.020486, l2: 0.029110, l3: 0.043133, l4: 0.083823, l5: 0.185982, l6: 0.378055\n",
      "\n",
      "[epoch: 364/400, batch: 120/1000, ite: 48266] train loss: 1.1336, accuracy: 94.9869%, tar: 0.0217 \n",
      "l0: 0.016180, l1: 0.017281, l2: 0.022368, l3: 0.033993, l4: 0.055134, l5: 0.118712, l6: 0.276340\n",
      "\n",
      "[epoch: 364/400, batch: 128/1000, ite: 48267] train loss: 1.1324, accuracy: 95.9128%, tar: 0.0216 \n",
      "l0: 0.021869, l1: 0.023335, l2: 0.029868, l3: 0.043537, l4: 0.085454, l5: 0.174256, l6: 0.377042\n",
      "\n",
      "[epoch: 364/400, batch: 136/1000, ite: 48268] train loss: 1.1324, accuracy: 94.8172%, tar: 0.0216 \n",
      "l0: 0.017654, l1: 0.019185, l2: 0.027192, l3: 0.040118, l4: 0.069581, l5: 0.148302, l6: 0.310138\n",
      "\n",
      "[epoch: 364/400, batch: 144/1000, ite: 48269] train loss: 1.1317, accuracy: 95.6363%, tar: 0.0216 \n",
      "l0: 0.018516, l1: 0.020022, l2: 0.027150, l3: 0.042418, l4: 0.080534, l5: 0.176928, l6: 0.305630\n",
      "\n",
      "[epoch: 364/400, batch: 152/1000, ite: 48270] train loss: 1.1312, accuracy: 95.9373%, tar: 0.0216 \n",
      "l0: 0.020582, l1: 0.022446, l2: 0.029649, l3: 0.046830, l4: 0.092062, l5: 0.187871, l6: 0.374946\n",
      "\n",
      "[epoch: 364/400, batch: 160/1000, ite: 48271] train loss: 1.1313, accuracy: 95.1063%, tar: 0.0216 \n",
      "l0: 0.016942, l1: 0.018779, l2: 0.028323, l3: 0.048902, l4: 0.096011, l5: 0.155475, l6: 0.298331\n",
      "\n",
      "[epoch: 364/400, batch: 168/1000, ite: 48272] train loss: 1.1307, accuracy: 96.1389%, tar: 0.0216 \n",
      "l0: 0.021364, l1: 0.022638, l2: 0.031571, l3: 0.048623, l4: 0.100263, l5: 0.187321, l6: 0.419822\n",
      "\n",
      "[epoch: 364/400, batch: 176/1000, ite: 48273] train loss: 1.1311, accuracy: 94.2973%, tar: 0.0216 \n",
      "l0: 0.021467, l1: 0.022521, l2: 0.030606, l3: 0.044468, l4: 0.075604, l5: 0.165210, l6: 0.429892\n",
      "\n",
      "[epoch: 364/400, batch: 184/1000, ite: 48274] train loss: 1.1314, accuracy: 95.0457%, tar: 0.0216 \n",
      "l0: 0.018170, l1: 0.019177, l2: 0.027369, l3: 0.040726, l4: 0.071091, l5: 0.132528, l6: 0.246230\n",
      "\n",
      "[epoch: 364/400, batch: 192/1000, ite: 48275] train loss: 1.1302, accuracy: 96.3012%, tar: 0.0216 \n",
      "l0: 0.023832, l1: 0.024639, l2: 0.032042, l3: 0.046647, l4: 0.079863, l5: 0.134342, l6: 0.324304\n",
      "\n",
      "[epoch: 364/400, batch: 200/1000, ite: 48276] train loss: 1.1297, accuracy: 95.2013%, tar: 0.0216 \n",
      "l0: 0.019302, l1: 0.019891, l2: 0.026231, l3: 0.037282, l4: 0.066672, l5: 0.153248, l6: 0.336324\n",
      "\n",
      "[epoch: 364/400, batch: 208/1000, ite: 48277] train loss: 1.1292, accuracy: 95.0455%, tar: 0.0216 \n",
      "l0: 0.024883, l1: 0.025940, l2: 0.035397, l3: 0.051354, l4: 0.088546, l5: 0.183680, l6: 0.381300\n",
      "\n",
      "[epoch: 364/400, batch: 216/1000, ite: 48278] train loss: 1.1294, accuracy: 94.5861%, tar: 0.0216 \n",
      "l0: 0.019675, l1: 0.020843, l2: 0.028038, l3: 0.042418, l4: 0.073728, l5: 0.176021, l6: 0.360438\n",
      "\n",
      "[epoch: 364/400, batch: 224/1000, ite: 48279] train loss: 1.1292, accuracy: 95.2949%, tar: 0.0216 \n",
      "l0: 0.019811, l1: 0.021567, l2: 0.029951, l3: 0.047462, l4: 0.090155, l5: 0.179273, l6: 0.362688\n",
      "\n",
      "[epoch: 364/400, batch: 232/1000, ite: 48280] train loss: 1.1292, accuracy: 95.3234%, tar: 0.0216 \n",
      "l0: 0.017630, l1: 0.018279, l2: 0.024464, l3: 0.038248, l4: 0.069981, l5: 0.116354, l6: 0.227239\n",
      "\n",
      "[epoch: 364/400, batch: 240/1000, ite: 48281] train loss: 1.1278, accuracy: 96.2122%, tar: 0.0216 \n",
      "l0: 0.018606, l1: 0.019471, l2: 0.026025, l3: 0.038704, l4: 0.073187, l5: 0.176678, l6: 0.304048\n",
      "\n",
      "[epoch: 364/400, batch: 248/1000, ite: 48282] train loss: 1.1273, accuracy: 95.7436%, tar: 0.0215 \n",
      "l0: 0.020565, l1: 0.022037, l2: 0.028688, l3: 0.043050, l4: 0.078076, l5: 0.158864, l6: 0.408167\n",
      "\n",
      "[epoch: 364/400, batch: 256/1000, ite: 48283] train loss: 1.1274, accuracy: 94.7439%, tar: 0.0215 \n",
      "l0: 0.027508, l1: 0.029327, l2: 0.039611, l3: 0.060257, l4: 0.111582, l5: 0.248618, l6: 0.564886\n",
      "\n",
      "[epoch: 364/400, batch: 264/1000, ite: 48284] train loss: 1.1292, accuracy: 92.7693%, tar: 0.0216 \n",
      "l0: 0.015803, l1: 0.017793, l2: 0.023929, l3: 0.036482, l4: 0.057040, l5: 0.107569, l6: 0.275392\n",
      "\n",
      "[epoch: 364/400, batch: 272/1000, ite: 48285] train loss: 1.1281, accuracy: 96.6437%, tar: 0.0215 \n",
      "l0: 0.019088, l1: 0.019812, l2: 0.025773, l3: 0.039090, l4: 0.067083, l5: 0.115554, l6: 0.272976\n",
      "\n",
      "[epoch: 364/400, batch: 280/1000, ite: 48286] train loss: 1.1271, accuracy: 95.4058%, tar: 0.0215 \n",
      "l0: 0.017536, l1: 0.018530, l2: 0.025690, l3: 0.039216, l4: 0.073717, l5: 0.151182, l6: 0.309114\n",
      "\n",
      "[epoch: 364/400, batch: 288/1000, ite: 48287] train loss: 1.1265, accuracy: 95.4059%, tar: 0.0215 \n",
      "l0: 0.020675, l1: 0.021760, l2: 0.030380, l3: 0.045156, l4: 0.090826, l5: 0.188451, l6: 0.371805\n",
      "\n",
      "[epoch: 364/400, batch: 296/1000, ite: 48288] train loss: 1.1266, accuracy: 95.1304%, tar: 0.0215 \n",
      "l0: 0.018286, l1: 0.019462, l2: 0.025187, l3: 0.038353, l4: 0.064891, l5: 0.130738, l6: 0.277785\n",
      "\n",
      "[epoch: 364/400, batch: 304/1000, ite: 48289] train loss: 1.1256, accuracy: 95.8610%, tar: 0.0215 \n",
      "l0: 0.023924, l1: 0.025807, l2: 0.036778, l3: 0.053934, l4: 0.095125, l5: 0.190700, l6: 0.367207\n",
      "\n",
      "[epoch: 364/400, batch: 312/1000, ite: 48290] train loss: 1.1258, accuracy: 95.1827%, tar: 0.0215 \n",
      "l0: 0.017093, l1: 0.018481, l2: 0.025846, l3: 0.038774, l4: 0.088553, l5: 0.200734, l6: 0.414147\n",
      "\n",
      "[epoch: 364/400, batch: 320/1000, ite: 48291] train loss: 1.1261, accuracy: 95.1095%, tar: 0.0215 \n",
      "l0: 0.025052, l1: 0.026021, l2: 0.031706, l3: 0.044145, l4: 0.072928, l5: 0.143948, l6: 0.362935\n",
      "\n",
      "[epoch: 364/400, batch: 328/1000, ite: 48292] train loss: 1.1259, accuracy: 94.3856%, tar: 0.0215 \n",
      "l0: 0.019653, l1: 0.020773, l2: 0.028140, l3: 0.040444, l4: 0.075844, l5: 0.163156, l6: 0.396349\n",
      "\n",
      "[epoch: 364/400, batch: 336/1000, ite: 48293] train loss: 1.1260, accuracy: 94.7696%, tar: 0.0215 \n",
      "l0: 0.016136, l1: 0.016747, l2: 0.022075, l3: 0.032303, l4: 0.057332, l5: 0.117770, l6: 0.244805\n",
      "\n",
      "[epoch: 364/400, batch: 344/1000, ite: 48294] train loss: 1.1247, accuracy: 96.2023%, tar: 0.0215 \n",
      "l0: 0.021932, l1: 0.023346, l2: 0.030110, l3: 0.044219, l4: 0.091420, l5: 0.159624, l6: 0.343054\n",
      "\n",
      "[epoch: 364/400, batch: 352/1000, ite: 48295] train loss: 1.1245, accuracy: 94.9761%, tar: 0.0215 \n",
      "l0: 0.019910, l1: 0.021344, l2: 0.029213, l3: 0.048590, l4: 0.097957, l5: 0.151506, l6: 0.256169\n",
      "\n",
      "[epoch: 364/400, batch: 360/1000, ite: 48296] train loss: 1.1237, accuracy: 96.1902%, tar: 0.0215 \n",
      "l0: 0.025264, l1: 0.027057, l2: 0.036158, l3: 0.052747, l4: 0.104556, l5: 0.188523, l6: 0.381030\n",
      "\n",
      "[epoch: 364/400, batch: 368/1000, ite: 48297] train loss: 1.1239, accuracy: 94.9541%, tar: 0.0215 \n",
      "l0: 0.019701, l1: 0.020518, l2: 0.027542, l3: 0.040756, l4: 0.072782, l5: 0.154477, l6: 0.307251\n",
      "\n",
      "[epoch: 364/400, batch: 376/1000, ite: 48298] train loss: 1.1234, accuracy: 95.5206%, tar: 0.0215 \n",
      "l0: 0.022109, l1: 0.023566, l2: 0.031830, l3: 0.047660, l4: 0.100657, l5: 0.257174, l6: 0.439191\n",
      "\n",
      "[epoch: 364/400, batch: 384/1000, ite: 48299] train loss: 1.1242, accuracy: 94.8696%, tar: 0.0215 \n",
      "l0: 0.020253, l1: 0.021403, l2: 0.029588, l3: 0.043643, l4: 0.079558, l5: 0.183581, l6: 0.336298\n",
      "\n",
      "[epoch: 364/400, batch: 392/1000, ite: 48300] train loss: 1.1239, accuracy: 95.0255%, tar: 0.0215 \n",
      "l0: 0.021661, l1: 0.022708, l2: 0.030213, l3: 0.047675, l4: 0.090995, l5: 0.184556, l6: 0.345710\n",
      "\n",
      "[epoch: 364/400, batch: 400/1000, ite: 48301] train loss: 1.1238, accuracy: 95.0230%, tar: 0.0215 \n",
      "l0: 0.022258, l1: 0.023281, l2: 0.031711, l3: 0.043573, l4: 0.073881, l5: 0.138067, l6: 0.309944\n",
      "\n",
      "[epoch: 364/400, batch: 408/1000, ite: 48302] train loss: 1.1233, accuracy: 95.8932%, tar: 0.0215 \n",
      "l0: 0.017351, l1: 0.018498, l2: 0.025398, l3: 0.039705, l4: 0.077946, l5: 0.150193, l6: 0.297765\n",
      "\n",
      "[epoch: 364/400, batch: 416/1000, ite: 48303] train loss: 1.1226, accuracy: 95.8145%, tar: 0.0215 \n",
      "l0: 0.017798, l1: 0.018453, l2: 0.025080, l3: 0.037289, l4: 0.068367, l5: 0.157343, l6: 0.337119\n",
      "\n",
      "[epoch: 364/400, batch: 424/1000, ite: 48304] train loss: 1.1223, accuracy: 95.2207%, tar: 0.0215 \n",
      "l0: 0.016899, l1: 0.018036, l2: 0.026465, l3: 0.041206, l4: 0.083955, l5: 0.174949, l6: 0.373892\n",
      "\n",
      "[epoch: 364/400, batch: 432/1000, ite: 48305] train loss: 1.1222, accuracy: 95.5865%, tar: 0.0215 \n",
      "l0: 0.021825, l1: 0.023124, l2: 0.031860, l3: 0.048267, l4: 0.097605, l5: 0.200976, l6: 0.379959\n",
      "\n",
      "[epoch: 364/400, batch: 440/1000, ite: 48306] train loss: 1.1224, accuracy: 94.2235%, tar: 0.0215 \n",
      "l0: 0.026324, l1: 0.028275, l2: 0.037213, l3: 0.055178, l4: 0.096928, l5: 0.215555, l6: 0.455994\n",
      "\n",
      "[epoch: 364/400, batch: 448/1000, ite: 48307] train loss: 1.1232, accuracy: 93.6106%, tar: 0.0215 \n",
      "l0: 0.020038, l1: 0.021023, l2: 0.028990, l3: 0.043598, l4: 0.074946, l5: 0.151936, l6: 0.368134\n",
      "\n",
      "[epoch: 364/400, batch: 456/1000, ite: 48308] train loss: 1.1231, accuracy: 95.6160%, tar: 0.0215 \n",
      "l0: 0.033008, l1: 0.034950, l2: 0.046309, l3: 0.076239, l4: 0.168220, l5: 0.368703, l6: 0.683992\n",
      "\n",
      "[epoch: 364/400, batch: 464/1000, ite: 48309] train loss: 1.1262, accuracy: 90.9631%, tar: 0.0215 \n",
      "l0: 0.023823, l1: 0.024825, l2: 0.030572, l3: 0.044780, l4: 0.071718, l5: 0.132873, l6: 0.327655\n",
      "\n",
      "[epoch: 364/400, batch: 472/1000, ite: 48310] train loss: 1.1258, accuracy: 94.6040%, tar: 0.0215 \n",
      "l0: 0.020661, l1: 0.021935, l2: 0.028926, l3: 0.042172, l4: 0.083068, l5: 0.184736, l6: 0.402608\n",
      "\n",
      "[epoch: 364/400, batch: 480/1000, ite: 48311] train loss: 1.1260, accuracy: 95.3779%, tar: 0.0215 \n",
      "l0: 0.020413, l1: 0.021482, l2: 0.028744, l3: 0.040424, l4: 0.074205, l5: 0.137942, l6: 0.353033\n",
      "\n",
      "[epoch: 364/400, batch: 488/1000, ite: 48312] train loss: 1.1257, accuracy: 95.5507%, tar: 0.0215 \n",
      "l0: 0.021124, l1: 0.022814, l2: 0.031116, l3: 0.044410, l4: 0.101340, l5: 0.166190, l6: 0.326249\n",
      "\n",
      "[epoch: 364/400, batch: 496/1000, ite: 48313] train loss: 1.1254, accuracy: 95.6222%, tar: 0.0215 \n",
      "l0: 0.021439, l1: 0.022377, l2: 0.029510, l3: 0.049447, l4: 0.098262, l5: 0.195753, l6: 0.337688\n",
      "\n",
      "[epoch: 364/400, batch: 504/1000, ite: 48314] train loss: 1.1253, accuracy: 95.5995%, tar: 0.0215 \n",
      "l0: 0.021563, l1: 0.023679, l2: 0.034945, l3: 0.059136, l4: 0.118828, l5: 0.187344, l6: 0.325258\n",
      "\n",
      "[epoch: 364/400, batch: 512/1000, ite: 48315] train loss: 1.1253, accuracy: 95.4543%, tar: 0.0215 \n",
      "l0: 0.022898, l1: 0.024122, l2: 0.030939, l3: 0.044324, l4: 0.086931, l5: 0.201695, l6: 0.420018\n",
      "\n",
      "[epoch: 364/400, batch: 520/1000, ite: 48316] train loss: 1.1257, accuracy: 94.5696%, tar: 0.0215 \n",
      "l0: 0.018175, l1: 0.019137, l2: 0.026285, l3: 0.037867, l4: 0.066980, l5: 0.115660, l6: 0.216726\n",
      "\n",
      "[epoch: 364/400, batch: 528/1000, ite: 48317] train loss: 1.1244, accuracy: 96.6257%, tar: 0.0215 \n",
      "l0: 0.029321, l1: 0.031024, l2: 0.041773, l3: 0.057306, l4: 0.099571, l5: 0.216025, l6: 0.467810\n",
      "\n",
      "[epoch: 364/400, batch: 536/1000, ite: 48318] train loss: 1.1253, accuracy: 93.5579%, tar: 0.0215 \n",
      "l0: 0.023888, l1: 0.025757, l2: 0.036218, l3: 0.061451, l4: 0.118071, l5: 0.236960, l6: 0.406238\n",
      "\n",
      "[epoch: 364/400, batch: 544/1000, ite: 48319] train loss: 1.1259, accuracy: 94.2937%, tar: 0.0215 \n",
      "l0: 0.020776, l1: 0.021313, l2: 0.029019, l3: 0.039581, l4: 0.062362, l5: 0.121960, l6: 0.297810\n",
      "\n",
      "[epoch: 364/400, batch: 552/1000, ite: 48320] train loss: 1.1252, accuracy: 96.2008%, tar: 0.0215 \n",
      "l0: 0.027697, l1: 0.028641, l2: 0.037324, l3: 0.053562, l4: 0.089566, l5: 0.169092, l6: 0.371259\n",
      "\n",
      "[epoch: 364/400, batch: 560/1000, ite: 48321] train loss: 1.1252, accuracy: 93.9981%, tar: 0.0215 \n",
      "l0: 0.028976, l1: 0.030268, l2: 0.038755, l3: 0.058183, l4: 0.107400, l5: 0.239800, l6: 0.513826\n",
      "\n",
      "[epoch: 364/400, batch: 568/1000, ite: 48322] train loss: 1.1265, accuracy: 93.2490%, tar: 0.0216 \n",
      "l0: 0.021506, l1: 0.022812, l2: 0.029976, l3: 0.047788, l4: 0.135968, l5: 0.214762, l6: 0.378040\n",
      "\n",
      "[epoch: 364/400, batch: 576/1000, ite: 48323] train loss: 1.1268, accuracy: 94.5912%, tar: 0.0216 \n",
      "l0: 0.019424, l1: 0.021449, l2: 0.030637, l3: 0.049752, l4: 0.085404, l5: 0.186266, l6: 0.437073\n",
      "\n",
      "[epoch: 364/400, batch: 584/1000, ite: 48324] train loss: 1.1272, accuracy: 95.3950%, tar: 0.0216 \n",
      "l0: 0.025545, l1: 0.026754, l2: 0.036635, l3: 0.059960, l4: 0.115683, l5: 0.257505, l6: 0.503859\n",
      "\n",
      "[epoch: 364/400, batch: 592/1000, ite: 48325] train loss: 1.1285, accuracy: 92.7539%, tar: 0.0216 \n",
      "l0: 0.017239, l1: 0.018845, l2: 0.025983, l3: 0.044857, l4: 0.084121, l5: 0.166467, l6: 0.416221\n",
      "\n",
      "[epoch: 364/400, batch: 600/1000, ite: 48326] train loss: 1.1287, accuracy: 94.9369%, tar: 0.0216 \n",
      "l0: 0.017778, l1: 0.018556, l2: 0.025625, l3: 0.038538, l4: 0.075520, l5: 0.166476, l6: 0.310089\n",
      "\n",
      "[epoch: 364/400, batch: 608/1000, ite: 48327] train loss: 1.1282, accuracy: 95.6021%, tar: 0.0215 \n",
      "l0: 0.017327, l1: 0.018961, l2: 0.025996, l3: 0.037371, l4: 0.065196, l5: 0.132212, l6: 0.273998\n",
      "\n",
      "[epoch: 364/400, batch: 616/1000, ite: 48328] train loss: 1.1273, accuracy: 96.7732%, tar: 0.0215 \n",
      "l0: 0.017000, l1: 0.018009, l2: 0.025045, l3: 0.043371, l4: 0.080575, l5: 0.156060, l6: 0.321676\n",
      "\n",
      "[epoch: 364/400, batch: 624/1000, ite: 48329] train loss: 1.1269, accuracy: 95.8520%, tar: 0.0215 \n",
      "l0: 0.025358, l1: 0.026611, l2: 0.033713, l3: 0.052640, l4: 0.109532, l5: 0.219608, l6: 0.432233\n",
      "\n",
      "[epoch: 364/400, batch: 632/1000, ite: 48330] train loss: 1.1276, accuracy: 94.2355%, tar: 0.0215 \n",
      "l0: 0.021287, l1: 0.022493, l2: 0.031346, l3: 0.047610, l4: 0.078318, l5: 0.172741, l6: 0.372407\n",
      "\n",
      "[epoch: 364/400, batch: 640/1000, ite: 48331] train loss: 1.1276, accuracy: 94.9014%, tar: 0.0215 \n",
      "l0: 0.019881, l1: 0.021288, l2: 0.029074, l3: 0.044723, l4: 0.079674, l5: 0.158014, l6: 0.332677\n",
      "\n",
      "[epoch: 364/400, batch: 648/1000, ite: 48332] train loss: 1.1273, accuracy: 95.4375%, tar: 0.0215 \n",
      "l0: 0.016474, l1: 0.017411, l2: 0.023473, l3: 0.035173, l4: 0.066919, l5: 0.123110, l6: 0.294593\n",
      "\n",
      "[epoch: 364/400, batch: 656/1000, ite: 48333] train loss: 1.1265, accuracy: 95.4018%, tar: 0.0215 \n",
      "l0: 0.027709, l1: 0.030138, l2: 0.041098, l3: 0.058416, l4: 0.119654, l5: 0.317370, l6: 0.586249\n",
      "\n",
      "[epoch: 364/400, batch: 664/1000, ite: 48334] train loss: 1.1284, accuracy: 92.4878%, tar: 0.0215 \n",
      "l0: 0.017218, l1: 0.018089, l2: 0.023987, l3: 0.035747, l4: 0.062912, l5: 0.139395, l6: 0.393332\n",
      "\n",
      "[epoch: 364/400, batch: 672/1000, ite: 48335] train loss: 1.1283, accuracy: 95.2552%, tar: 0.0215 \n",
      "l0: 0.019278, l1: 0.020829, l2: 0.029351, l3: 0.048436, l4: 0.098007, l5: 0.184391, l6: 0.425884\n",
      "\n",
      "[epoch: 364/400, batch: 680/1000, ite: 48336] train loss: 1.1287, accuracy: 94.7370%, tar: 0.0215 \n",
      "l0: 0.014403, l1: 0.015091, l2: 0.020361, l3: 0.033335, l4: 0.057035, l5: 0.131872, l6: 0.263277\n",
      "\n",
      "[epoch: 364/400, batch: 688/1000, ite: 48337] train loss: 1.1277, accuracy: 95.8084%, tar: 0.0215 \n",
      "l0: 0.022482, l1: 0.024173, l2: 0.033171, l3: 0.050802, l4: 0.098472, l5: 0.198393, l6: 0.381682\n",
      "\n",
      "[epoch: 364/400, batch: 696/1000, ite: 48338] train loss: 1.1279, accuracy: 94.9747%, tar: 0.0215 \n",
      "l0: 0.025028, l1: 0.026310, l2: 0.033922, l3: 0.050933, l4: 0.097682, l5: 0.235934, l6: 0.422902\n",
      "\n",
      "[epoch: 364/400, batch: 704/1000, ite: 48339] train loss: 1.1285, accuracy: 94.1509%, tar: 0.0215 \n",
      "l0: 0.017961, l1: 0.019375, l2: 0.027617, l3: 0.053076, l4: 0.109167, l5: 0.184987, l6: 0.376855\n",
      "\n",
      "[epoch: 364/400, batch: 712/1000, ite: 48340] train loss: 1.1286, accuracy: 95.1791%, tar: 0.0215 \n",
      "l0: 0.016334, l1: 0.017891, l2: 0.024827, l3: 0.041362, l4: 0.074264, l5: 0.138859, l6: 0.314890\n",
      "\n",
      "[epoch: 364/400, batch: 720/1000, ite: 48341] train loss: 1.1281, accuracy: 95.8382%, tar: 0.0215 \n",
      "l0: 0.022779, l1: 0.024344, l2: 0.031523, l3: 0.049119, l4: 0.108988, l5: 0.226669, l6: 0.388818\n",
      "\n",
      "[epoch: 364/400, batch: 728/1000, ite: 48342] train loss: 1.1284, accuracy: 94.7894%, tar: 0.0215 \n",
      "l0: 0.015784, l1: 0.016425, l2: 0.021986, l3: 0.032917, l4: 0.059484, l5: 0.139017, l6: 0.270968\n",
      "\n",
      "[epoch: 364/400, batch: 736/1000, ite: 48343] train loss: 1.1276, accuracy: 96.3069%, tar: 0.0215 \n",
      "l0: 0.030491, l1: 0.032485, l2: 0.044169, l3: 0.072185, l4: 0.136570, l5: 0.270398, l6: 0.526431\n",
      "\n",
      "[epoch: 364/400, batch: 744/1000, ite: 48344] train loss: 1.1291, accuracy: 92.7309%, tar: 0.0215 \n",
      "l0: 0.019735, l1: 0.021315, l2: 0.028849, l3: 0.046008, l4: 0.094859, l5: 0.185035, l6: 0.387437\n",
      "\n",
      "[epoch: 364/400, batch: 752/1000, ite: 48345] train loss: 1.1292, accuracy: 95.4596%, tar: 0.0215 \n",
      "l0: 0.022165, l1: 0.022918, l2: 0.030034, l3: 0.040919, l4: 0.068250, l5: 0.133947, l6: 0.261742\n",
      "\n",
      "[epoch: 364/400, batch: 760/1000, ite: 48346] train loss: 1.1284, accuracy: 95.5400%, tar: 0.0215 \n",
      "l0: 0.017124, l1: 0.018581, l2: 0.025281, l3: 0.036965, l4: 0.068375, l5: 0.136189, l6: 0.262566\n",
      "\n",
      "[epoch: 364/400, batch: 768/1000, ite: 48347] train loss: 1.1275, accuracy: 96.1374%, tar: 0.0215 \n",
      "l0: 0.027789, l1: 0.029829, l2: 0.040682, l3: 0.064301, l4: 0.121573, l5: 0.220431, l6: 0.437821\n",
      "\n",
      "[epoch: 364/400, batch: 776/1000, ite: 48348] train loss: 1.1283, accuracy: 93.9290%, tar: 0.0215 \n",
      "l0: 0.017864, l1: 0.018810, l2: 0.024815, l3: 0.036677, l4: 0.062819, l5: 0.117971, l6: 0.250666\n",
      "\n",
      "[epoch: 364/400, batch: 784/1000, ite: 48349] train loss: 1.1273, accuracy: 95.8271%, tar: 0.0215 \n",
      "l0: 0.020601, l1: 0.022269, l2: 0.030348, l3: 0.042680, l4: 0.077100, l5: 0.169025, l6: 0.376865\n",
      "\n",
      "[epoch: 364/400, batch: 792/1000, ite: 48350] train loss: 1.1273, accuracy: 95.3832%, tar: 0.0215 \n",
      "l0: 0.021166, l1: 0.022069, l2: 0.029047, l3: 0.045545, l4: 0.085611, l5: 0.199610, l6: 0.392394\n",
      "\n",
      "[epoch: 364/400, batch: 800/1000, ite: 48351] train loss: 1.1274, accuracy: 94.3503%, tar: 0.0215 \n",
      "l0: 0.020014, l1: 0.021900, l2: 0.028811, l3: 0.042990, l4: 0.085823, l5: 0.186029, l6: 0.367379\n",
      "\n",
      "[epoch: 364/400, batch: 808/1000, ite: 48352] train loss: 1.1274, accuracy: 95.2109%, tar: 0.0215 \n",
      "l0: 0.019228, l1: 0.020666, l2: 0.028779, l3: 0.046075, l4: 0.092947, l5: 0.203712, l6: 0.436306\n",
      "\n",
      "[epoch: 364/400, batch: 816/1000, ite: 48353] train loss: 1.1279, accuracy: 95.0441%, tar: 0.0215 \n",
      "l0: 0.025258, l1: 0.026427, l2: 0.035057, l3: 0.050589, l4: 0.090076, l5: 0.219754, l6: 0.409461\n",
      "\n",
      "[epoch: 364/400, batch: 824/1000, ite: 48354] train loss: 1.1283, accuracy: 93.6024%, tar: 0.0215 \n",
      "l0: 0.021807, l1: 0.023751, l2: 0.035217, l3: 0.066976, l4: 0.125236, l5: 0.280879, l6: 0.565354\n",
      "\n",
      "[epoch: 364/400, batch: 832/1000, ite: 48355] train loss: 1.1298, accuracy: 94.0306%, tar: 0.0215 \n",
      "l0: 0.022343, l1: 0.023541, l2: 0.032005, l3: 0.044137, l4: 0.076703, l5: 0.171729, l6: 0.327001\n",
      "\n",
      "[epoch: 364/400, batch: 840/1000, ite: 48356] train loss: 1.1295, accuracy: 94.8540%, tar: 0.0215 \n",
      "l0: 0.018821, l1: 0.019953, l2: 0.027137, l3: 0.040174, l4: 0.074096, l5: 0.151828, l6: 0.293572\n",
      "\n",
      "[epoch: 364/400, batch: 848/1000, ite: 48357] train loss: 1.1290, accuracy: 95.4000%, tar: 0.0215 \n",
      "l0: 0.023602, l1: 0.025070, l2: 0.032457, l3: 0.051052, l4: 0.105265, l5: 0.196446, l6: 0.373450\n",
      "\n",
      "[epoch: 364/400, batch: 856/1000, ite: 48358] train loss: 1.1291, accuracy: 94.6323%, tar: 0.0215 \n",
      "l0: 0.018413, l1: 0.020381, l2: 0.030964, l3: 0.054665, l4: 0.103631, l5: 0.167042, l6: 0.321075\n",
      "\n",
      "[epoch: 364/400, batch: 864/1000, ite: 48359] train loss: 1.1289, accuracy: 96.1297%, tar: 0.0215 \n",
      "l0: 0.020571, l1: 0.021807, l2: 0.031134, l3: 0.049396, l4: 0.091515, l5: 0.194546, l6: 0.395566\n",
      "\n",
      "[epoch: 364/400, batch: 872/1000, ite: 48360] train loss: 1.1291, accuracy: 95.5415%, tar: 0.0215 \n",
      "l0: 0.020941, l1: 0.022112, l2: 0.029776, l3: 0.045966, l4: 0.078151, l5: 0.142535, l6: 0.298118\n",
      "\n",
      "[epoch: 364/400, batch: 880/1000, ite: 48361] train loss: 1.1285, accuracy: 96.0209%, tar: 0.0215 \n",
      "l0: 0.024391, l1: 0.025995, l2: 0.033057, l3: 0.051408, l4: 0.101990, l5: 0.212634, l6: 0.393742\n",
      "\n",
      "[epoch: 364/400, batch: 888/1000, ite: 48362] train loss: 1.1289, accuracy: 94.6389%, tar: 0.0215 \n",
      "l0: 0.023643, l1: 0.024502, l2: 0.031833, l3: 0.048994, l4: 0.084287, l5: 0.194577, l6: 0.395256\n",
      "\n",
      "[epoch: 364/400, batch: 896/1000, ite: 48363] train loss: 1.1291, accuracy: 95.0381%, tar: 0.0215 \n",
      "l0: 0.026397, l1: 0.027884, l2: 0.036305, l3: 0.053906, l4: 0.096414, l5: 0.226385, l6: 0.446740\n",
      "\n",
      "[epoch: 364/400, batch: 904/1000, ite: 48364] train loss: 1.1297, accuracy: 94.3115%, tar: 0.0215 \n",
      "l0: 0.022803, l1: 0.023567, l2: 0.030864, l3: 0.045261, l4: 0.082962, l5: 0.185728, l6: 0.358397\n",
      "\n",
      "[epoch: 364/400, batch: 912/1000, ite: 48365] train loss: 1.1297, accuracy: 94.3856%, tar: 0.0215 \n",
      "l0: 0.019216, l1: 0.020035, l2: 0.027364, l3: 0.041883, l4: 0.076822, l5: 0.165565, l6: 0.339251\n",
      "\n",
      "[epoch: 364/400, batch: 920/1000, ite: 48366] train loss: 1.1294, accuracy: 95.2448%, tar: 0.0215 \n",
      "l0: 0.016936, l1: 0.019041, l2: 0.027098, l3: 0.044907, l4: 0.090009, l5: 0.179641, l6: 0.348316\n",
      "\n",
      "[epoch: 364/400, batch: 928/1000, ite: 48367] train loss: 1.1292, accuracy: 95.9837%, tar: 0.0215 \n",
      "l0: 0.026455, l1: 0.027713, l2: 0.034867, l3: 0.051069, l4: 0.094058, l5: 0.212423, l6: 0.430650\n",
      "\n",
      "[epoch: 364/400, batch: 936/1000, ite: 48368] train loss: 1.1297, accuracy: 93.2398%, tar: 0.0215 \n",
      "l0: 0.020113, l1: 0.021379, l2: 0.028975, l3: 0.046711, l4: 0.074088, l5: 0.131573, l6: 0.308478\n",
      "\n",
      "[epoch: 364/400, batch: 944/1000, ite: 48369] train loss: 1.1292, accuracy: 95.8980%, tar: 0.0215 \n",
      "l0: 0.019151, l1: 0.020199, l2: 0.027780, l3: 0.047134, l4: 0.103169, l5: 0.200116, l6: 0.352527\n",
      "\n",
      "[epoch: 364/400, batch: 952/1000, ite: 48370] train loss: 1.1292, accuracy: 94.7455%, tar: 0.0215 \n",
      "l0: 0.019798, l1: 0.020742, l2: 0.027207, l3: 0.042054, l4: 0.079370, l5: 0.141278, l6: 0.300149\n",
      "\n",
      "[epoch: 364/400, batch: 960/1000, ite: 48371] train loss: 1.1287, accuracy: 95.4531%, tar: 0.0215 \n",
      "l0: 0.025321, l1: 0.026737, l2: 0.033336, l3: 0.048758, l4: 0.087938, l5: 0.157250, l6: 0.319728\n",
      "\n",
      "[epoch: 364/400, batch: 968/1000, ite: 48372] train loss: 1.1284, accuracy: 95.2579%, tar: 0.0215 \n",
      "l0: 0.021786, l1: 0.022694, l2: 0.030265, l3: 0.042236, l4: 0.074739, l5: 0.164035, l6: 0.356297\n",
      "\n",
      "[epoch: 364/400, batch: 976/1000, ite: 48373] train loss: 1.1283, accuracy: 94.5495%, tar: 0.0215 \n",
      "l0: 0.018867, l1: 0.019611, l2: 0.025742, l3: 0.038414, l4: 0.068049, l5: 0.137240, l6: 0.262587\n",
      "\n",
      "[epoch: 364/400, batch: 984/1000, ite: 48374] train loss: 1.1275, accuracy: 96.0123%, tar: 0.0215 \n",
      "l0: 0.024341, l1: 0.026115, l2: 0.035507, l3: 0.055406, l4: 0.104243, l5: 0.268609, l6: 0.527271\n",
      "\n",
      "[epoch: 364/400, batch: 992/1000, ite: 48375] train loss: 1.1287, accuracy: 93.2761%, tar: 0.0215 \n",
      "l0: 0.018936, l1: 0.020386, l2: 0.027327, l3: 0.041745, l4: 0.076889, l5: 0.177564, l6: 0.366887\n",
      "\n",
      "[epoch: 364/400, batch: 1000/1000, ite: 48376] train loss: 1.1286, accuracy: 95.4873%, tar: 0.0215 \n",
      "l0: 0.014627, l1: 0.015747, l2: 0.020838, l3: 0.031187, l4: 0.052039, l5: 0.104115, l6: 0.290178\n",
      "\n",
      "[epoch: 365/400, batch: 8/1000, ite: 48377] train loss: 1.1278, accuracy: 96.0799%, tar: 0.0215 \n",
      "l0: 0.018575, l1: 0.019380, l2: 0.026283, l3: 0.038517, l4: 0.072183, l5: 0.158302, l6: 0.353113\n",
      "\n",
      "[epoch: 365/400, batch: 16/1000, ite: 48378] train loss: 1.1276, accuracy: 95.3299%, tar: 0.0215 \n",
      "l0: 0.024573, l1: 0.026067, l2: 0.035013, l3: 0.058166, l4: 0.127634, l5: 0.228117, l6: 0.419094\n",
      "\n",
      "[epoch: 365/400, batch: 24/1000, ite: 48379] train loss: 1.1282, accuracy: 94.6531%, tar: 0.0215 \n",
      "l0: 0.017486, l1: 0.019399, l2: 0.030183, l3: 0.054173, l4: 0.092747, l5: 0.199681, l6: 0.461034\n",
      "\n",
      "[epoch: 365/400, batch: 32/1000, ite: 48380] train loss: 1.1287, accuracy: 95.0442%, tar: 0.0215 \n",
      "l0: 0.024943, l1: 0.026847, l2: 0.036439, l3: 0.056066, l4: 0.103819, l5: 0.233640, l6: 0.419685\n",
      "\n",
      "[epoch: 365/400, batch: 40/1000, ite: 48381] train loss: 1.1292, accuracy: 93.8748%, tar: 0.0215 \n",
      "l0: 0.022324, l1: 0.023436, l2: 0.031058, l3: 0.050840, l4: 0.131558, l5: 0.250324, l6: 0.442341\n",
      "\n",
      "[epoch: 365/400, batch: 48/1000, ite: 48382] train loss: 1.1300, accuracy: 93.6497%, tar: 0.0215 \n",
      "l0: 0.017500, l1: 0.018690, l2: 0.027057, l3: 0.041521, l4: 0.076377, l5: 0.146497, l6: 0.280939\n",
      "\n",
      "[epoch: 365/400, batch: 56/1000, ite: 48383] train loss: 1.1294, accuracy: 95.8720%, tar: 0.0215 \n",
      "l0: 0.016949, l1: 0.018314, l2: 0.027901, l3: 0.043967, l4: 0.083699, l5: 0.173130, l6: 0.324070\n",
      "\n",
      "[epoch: 365/400, batch: 64/1000, ite: 48384] train loss: 1.1290, accuracy: 95.9177%, tar: 0.0214 \n",
      "l0: 0.021817, l1: 0.023485, l2: 0.033811, l3: 0.053824, l4: 0.105223, l5: 0.185274, l6: 0.347659\n",
      "\n",
      "[epoch: 365/400, batch: 72/1000, ite: 48385] train loss: 1.1290, accuracy: 95.0407%, tar: 0.0214 \n",
      "l0: 0.020725, l1: 0.021681, l2: 0.028303, l3: 0.039613, l4: 0.064369, l5: 0.123524, l6: 0.238933\n",
      "\n",
      "[epoch: 365/400, batch: 80/1000, ite: 48386] train loss: 1.1281, accuracy: 96.0787%, tar: 0.0214 \n",
      "l0: 0.020314, l1: 0.021241, l2: 0.028052, l3: 0.039802, l4: 0.079957, l5: 0.138106, l6: 0.282193\n",
      "\n",
      "[epoch: 365/400, batch: 88/1000, ite: 48387] train loss: 1.1275, accuracy: 95.8408%, tar: 0.0214 \n",
      "l0: 0.021897, l1: 0.024219, l2: 0.035831, l3: 0.059958, l4: 0.130159, l5: 0.225922, l6: 0.414185\n",
      "\n",
      "[epoch: 365/400, batch: 96/1000, ite: 48388] train loss: 1.1280, accuracy: 94.9058%, tar: 0.0214 \n",
      "l0: 0.025019, l1: 0.026293, l2: 0.033976, l3: 0.055153, l4: 0.108486, l5: 0.223449, l6: 0.450399\n",
      "\n",
      "[epoch: 365/400, batch: 104/1000, ite: 48389] train loss: 1.1287, accuracy: 94.0836%, tar: 0.0215 \n",
      "l0: 0.018180, l1: 0.019487, l2: 0.028224, l3: 0.045407, l4: 0.077012, l5: 0.140100, l6: 0.280181\n",
      "\n",
      "[epoch: 365/400, batch: 112/1000, ite: 48390] train loss: 1.1281, accuracy: 96.2533%, tar: 0.0214 \n",
      "l0: 0.025030, l1: 0.026793, l2: 0.035907, l3: 0.055781, l4: 0.105391, l5: 0.209857, l6: 0.426093\n",
      "\n",
      "[epoch: 365/400, batch: 120/1000, ite: 48391] train loss: 1.1286, accuracy: 94.6458%, tar: 0.0215 \n",
      "l0: 0.029219, l1: 0.030680, l2: 0.039884, l3: 0.061292, l4: 0.130949, l5: 0.328936, l6: 0.693948\n",
      "\n",
      "[epoch: 365/400, batch: 128/1000, ite: 48392] train loss: 1.1308, accuracy: 90.6822%, tar: 0.0215 \n",
      "l0: 0.016668, l1: 0.017375, l2: 0.021093, l3: 0.029158, l4: 0.048938, l5: 0.083906, l6: 0.173578\n",
      "\n",
      "[epoch: 365/400, batch: 136/1000, ite: 48393] train loss: 1.1294, accuracy: 96.8645%, tar: 0.0215 \n",
      "l0: 0.018989, l1: 0.019914, l2: 0.024563, l3: 0.034905, l4: 0.061714, l5: 0.138698, l6: 0.323184\n",
      "\n",
      "[epoch: 365/400, batch: 144/1000, ite: 48394] train loss: 1.1289, accuracy: 95.0313%, tar: 0.0215 \n",
      "l0: 0.020635, l1: 0.021790, l2: 0.028649, l3: 0.043566, l4: 0.081953, l5: 0.170671, l6: 0.367996\n",
      "\n",
      "[epoch: 365/400, batch: 152/1000, ite: 48395] train loss: 1.1289, accuracy: 95.1517%, tar: 0.0215 \n",
      "l0: 0.020551, l1: 0.021680, l2: 0.031496, l3: 0.045467, l4: 0.078874, l5: 0.143229, l6: 0.281104\n",
      "\n",
      "[epoch: 365/400, batch: 160/1000, ite: 48396] train loss: 1.1283, accuracy: 95.6748%, tar: 0.0215 \n",
      "l0: 0.015889, l1: 0.016988, l2: 0.022407, l3: 0.037919, l4: 0.083511, l5: 0.185329, l6: 0.362485\n",
      "\n",
      "[epoch: 365/400, batch: 168/1000, ite: 48397] train loss: 1.1282, accuracy: 95.4248%, tar: 0.0214 \n",
      "l0: 0.018412, l1: 0.019965, l2: 0.027379, l3: 0.041710, l4: 0.088230, l5: 0.182711, l6: 0.304580\n",
      "\n",
      "[epoch: 365/400, batch: 176/1000, ite: 48398] train loss: 1.1279, accuracy: 95.5842%, tar: 0.0214 \n",
      "l0: 0.020281, l1: 0.021648, l2: 0.029170, l3: 0.045368, l4: 0.091079, l5: 0.201473, l6: 0.348333\n",
      "\n",
      "[epoch: 365/400, batch: 184/1000, ite: 48399] train loss: 1.1278, accuracy: 95.0329%, tar: 0.0214 \n",
      "l0: 0.015880, l1: 0.017034, l2: 0.023370, l3: 0.034706, l4: 0.060808, l5: 0.111221, l6: 0.271010\n",
      "\n",
      "[epoch: 365/400, batch: 192/1000, ite: 48400] train loss: 1.1270, accuracy: 96.0504%, tar: 0.0214 \n",
      "l0: 0.020358, l1: 0.021381, l2: 0.029261, l3: 0.046186, l4: 0.085325, l5: 0.176077, l6: 0.435364\n",
      "\n",
      "[epoch: 365/400, batch: 200/1000, ite: 48401] train loss: 1.1274, accuracy: 94.7426%, tar: 0.0214 \n",
      "l0: 0.026826, l1: 0.028306, l2: 0.037145, l3: 0.052071, l4: 0.097706, l5: 0.231776, l6: 0.456363\n",
      "\n",
      "[epoch: 365/400, batch: 208/1000, ite: 48402] train loss: 1.1280, accuracy: 93.3981%, tar: 0.0214 \n",
      "l0: 0.021285, l1: 0.022022, l2: 0.031726, l3: 0.048859, l4: 0.096805, l5: 0.196775, l6: 0.400764\n",
      "\n",
      "[epoch: 365/400, batch: 216/1000, ite: 48403] train loss: 1.1282, accuracy: 94.3096%, tar: 0.0214 \n",
      "l0: 0.029275, l1: 0.030682, l2: 0.041552, l3: 0.063433, l4: 0.125997, l5: 0.306960, l6: 0.601609\n",
      "\n",
      "[epoch: 365/400, batch: 224/1000, ite: 48404] train loss: 1.1299, accuracy: 91.7358%, tar: 0.0214 \n",
      "l0: 0.024202, l1: 0.025290, l2: 0.032864, l3: 0.050198, l4: 0.082392, l5: 0.156312, l6: 0.368774\n",
      "\n",
      "[epoch: 365/400, batch: 232/1000, ite: 48405] train loss: 1.1299, accuracy: 95.0483%, tar: 0.0215 \n",
      "l0: 0.020215, l1: 0.021212, l2: 0.028630, l3: 0.042574, l4: 0.066441, l5: 0.118857, l6: 0.247573\n",
      "\n",
      "[epoch: 365/400, batch: 240/1000, ite: 48406] train loss: 1.1291, accuracy: 96.1445%, tar: 0.0214 \n",
      "l0: 0.017163, l1: 0.018704, l2: 0.026626, l3: 0.040819, l4: 0.073187, l5: 0.161561, l6: 0.359226\n",
      "\n",
      "[epoch: 365/400, batch: 248/1000, ite: 48407] train loss: 1.1289, accuracy: 96.0900%, tar: 0.0214 \n",
      "l0: 0.021506, l1: 0.023597, l2: 0.033259, l3: 0.056643, l4: 0.110712, l5: 0.214675, l6: 0.416205\n",
      "\n",
      "[epoch: 365/400, batch: 256/1000, ite: 48408] train loss: 1.1294, accuracy: 95.0671%, tar: 0.0214 \n",
      "l0: 0.019095, l1: 0.020114, l2: 0.026342, l3: 0.040554, l4: 0.080180, l5: 0.153515, l6: 0.342125\n",
      "\n",
      "[epoch: 365/400, batch: 264/1000, ite: 48409] train loss: 1.1291, accuracy: 95.2563%, tar: 0.0214 \n",
      "l0: 0.024695, l1: 0.026375, l2: 0.038003, l3: 0.061533, l4: 0.104642, l5: 0.207284, l6: 0.465710\n",
      "\n",
      "[epoch: 365/400, batch: 272/1000, ite: 48410] train loss: 1.1298, accuracy: 93.8194%, tar: 0.0214 \n",
      "l0: 0.020712, l1: 0.022073, l2: 0.029812, l3: 0.049275, l4: 0.097334, l5: 0.197208, l6: 0.381289\n",
      "\n",
      "[epoch: 365/400, batch: 280/1000, ite: 48411] train loss: 1.1299, accuracy: 94.6559%, tar: 0.0214 \n",
      "l0: 0.020324, l1: 0.021241, l2: 0.026699, l3: 0.036469, l4: 0.065076, l5: 0.128445, l6: 0.281214\n",
      "\n",
      "[epoch: 365/400, batch: 288/1000, ite: 48412] train loss: 1.1292, accuracy: 95.5238%, tar: 0.0214 \n",
      "l0: 0.023595, l1: 0.025091, l2: 0.035469, l3: 0.052211, l4: 0.092863, l5: 0.176013, l6: 0.413864\n",
      "\n",
      "[epoch: 365/400, batch: 296/1000, ite: 48413] train loss: 1.1295, accuracy: 94.4307%, tar: 0.0214 \n",
      "l0: 0.016256, l1: 0.018142, l2: 0.026130, l3: 0.041308, l4: 0.081481, l5: 0.175491, l6: 0.327757\n",
      "\n",
      "[epoch: 365/400, batch: 304/1000, ite: 48414] train loss: 1.1292, accuracy: 96.3940%, tar: 0.0214 \n",
      "l0: 0.022533, l1: 0.023673, l2: 0.031808, l3: 0.048551, l4: 0.088271, l5: 0.192901, l6: 0.425010\n",
      "\n",
      "[epoch: 365/400, batch: 312/1000, ite: 48415] train loss: 1.1295, accuracy: 93.9299%, tar: 0.0214 \n",
      "l0: 0.021460, l1: 0.022955, l2: 0.032066, l3: 0.047926, l4: 0.081338, l5: 0.140880, l6: 0.337730\n",
      "\n",
      "[epoch: 365/400, batch: 320/1000, ite: 48416] train loss: 1.1293, accuracy: 95.5260%, tar: 0.0214 \n",
      "l0: 0.019061, l1: 0.019885, l2: 0.027893, l3: 0.041449, l4: 0.078772, l5: 0.157302, l6: 0.324277\n",
      "\n",
      "[epoch: 365/400, batch: 328/1000, ite: 48417] train loss: 1.1290, accuracy: 95.3056%, tar: 0.0214 \n",
      "l0: 0.022822, l1: 0.024537, l2: 0.032740, l3: 0.055537, l4: 0.131610, l5: 0.201430, l6: 0.369274\n",
      "\n",
      "[epoch: 365/400, batch: 336/1000, ite: 48418] train loss: 1.1292, accuracy: 94.9814%, tar: 0.0214 \n",
      "l0: 0.024979, l1: 0.026479, l2: 0.035621, l3: 0.050826, l4: 0.115761, l5: 0.218069, l6: 0.459288\n",
      "\n",
      "[epoch: 365/400, batch: 344/1000, ite: 48419] train loss: 1.1298, accuracy: 93.7390%, tar: 0.0214 \n",
      "l0: 0.020760, l1: 0.021899, l2: 0.027400, l3: 0.038210, l4: 0.073348, l5: 0.146898, l6: 0.365625\n",
      "\n",
      "[epoch: 365/400, batch: 352/1000, ite: 48420] train loss: 1.1296, accuracy: 95.1883%, tar: 0.0214 \n",
      "l0: 0.020497, l1: 0.021839, l2: 0.028065, l3: 0.041090, l4: 0.073829, l5: 0.156487, l6: 0.390853\n",
      "\n",
      "[epoch: 365/400, batch: 360/1000, ite: 48421] train loss: 1.1296, accuracy: 94.4205%, tar: 0.0214 \n",
      "l0: 0.026887, l1: 0.028330, l2: 0.037397, l3: 0.054230, l4: 0.102147, l5: 0.204179, l6: 0.374075\n",
      "\n",
      "[epoch: 365/400, batch: 368/1000, ite: 48422] train loss: 1.1298, accuracy: 94.8583%, tar: 0.0214 \n",
      "l0: 0.020285, l1: 0.021594, l2: 0.029193, l3: 0.043971, l4: 0.086825, l5: 0.171914, l6: 0.390949\n",
      "\n",
      "[epoch: 365/400, batch: 376/1000, ite: 48423] train loss: 1.1299, accuracy: 95.1293%, tar: 0.0214 \n",
      "l0: 0.025465, l1: 0.026447, l2: 0.034073, l3: 0.048595, l4: 0.079714, l5: 0.169635, l6: 0.405438\n",
      "\n",
      "[epoch: 365/400, batch: 384/1000, ite: 48424] train loss: 1.1300, accuracy: 94.6687%, tar: 0.0215 \n",
      "l0: 0.020441, l1: 0.021516, l2: 0.029514, l3: 0.042788, l4: 0.075623, l5: 0.160667, l6: 0.326884\n",
      "\n",
      "[epoch: 365/400, batch: 392/1000, ite: 48425] train loss: 1.1297, accuracy: 95.1957%, tar: 0.0214 \n",
      "l0: 0.023228, l1: 0.024639, l2: 0.033567, l3: 0.054057, l4: 0.099616, l5: 0.236486, l6: 0.450183\n",
      "\n",
      "[epoch: 365/400, batch: 400/1000, ite: 48426] train loss: 1.1303, accuracy: 93.6057%, tar: 0.0215 \n",
      "l0: 0.024511, l1: 0.026215, l2: 0.034278, l3: 0.051955, l4: 0.101247, l5: 0.204514, l6: 0.439658\n",
      "\n",
      "[epoch: 365/400, batch: 408/1000, ite: 48427] train loss: 1.1308, accuracy: 94.0797%, tar: 0.0215 \n",
      "l0: 0.020684, l1: 0.021957, l2: 0.030213, l3: 0.043433, l4: 0.079496, l5: 0.145168, l6: 0.298618\n",
      "\n",
      "[epoch: 365/400, batch: 416/1000, ite: 48428] train loss: 1.1303, accuracy: 95.8070%, tar: 0.0215 \n",
      "l0: 0.024434, l1: 0.025770, l2: 0.034526, l3: 0.049657, l4: 0.089768, l5: 0.175601, l6: 0.404169\n",
      "\n",
      "[epoch: 365/400, batch: 424/1000, ite: 48429] train loss: 1.1305, accuracy: 94.0817%, tar: 0.0215 \n",
      "l0: 0.018437, l1: 0.019283, l2: 0.026913, l3: 0.038519, l4: 0.076826, l5: 0.158777, l6: 0.319005\n",
      "\n",
      "[epoch: 365/400, batch: 432/1000, ite: 48430] train loss: 1.1302, accuracy: 94.8176%, tar: 0.0215 \n",
      "l0: 0.020676, l1: 0.022223, l2: 0.029336, l3: 0.045888, l4: 0.091212, l5: 0.170152, l6: 0.392170\n",
      "\n",
      "[epoch: 365/400, batch: 440/1000, ite: 48431] train loss: 1.1302, accuracy: 95.0131%, tar: 0.0215 \n",
      "l0: 0.015781, l1: 0.016999, l2: 0.024569, l3: 0.037271, l4: 0.062593, l5: 0.121963, l6: 0.288566\n",
      "\n",
      "[epoch: 365/400, batch: 448/1000, ite: 48432] train loss: 1.1296, accuracy: 95.6390%, tar: 0.0214 \n",
      "l0: 0.016587, l1: 0.017603, l2: 0.023225, l3: 0.034620, l4: 0.061500, l5: 0.120386, l6: 0.273593\n",
      "\n",
      "[epoch: 365/400, batch: 456/1000, ite: 48433] train loss: 1.1289, accuracy: 96.1425%, tar: 0.0214 \n",
      "l0: 0.022650, l1: 0.023826, l2: 0.032820, l3: 0.048679, l4: 0.088032, l5: 0.183415, l6: 0.374437\n",
      "\n",
      "[epoch: 365/400, batch: 464/1000, ite: 48434] train loss: 1.1289, accuracy: 94.8275%, tar: 0.0214 \n",
      "l0: 0.019676, l1: 0.021748, l2: 0.031777, l3: 0.046804, l4: 0.087640, l5: 0.161058, l6: 0.343845\n",
      "\n",
      "[epoch: 365/400, batch: 472/1000, ite: 48435] train loss: 1.1288, accuracy: 95.8446%, tar: 0.0214 \n",
      "l0: 0.020802, l1: 0.022631, l2: 0.030780, l3: 0.045842, l4: 0.091956, l5: 0.190257, l6: 0.383637\n",
      "\n",
      "[epoch: 365/400, batch: 480/1000, ite: 48436] train loss: 1.1289, accuracy: 95.4079%, tar: 0.0214 \n",
      "l0: 0.023167, l1: 0.025084, l2: 0.034386, l3: 0.054102, l4: 0.088873, l5: 0.169051, l6: 0.365676\n",
      "\n",
      "[epoch: 365/400, batch: 488/1000, ite: 48437] train loss: 1.1289, accuracy: 94.8869%, tar: 0.0214 \n",
      "l0: 0.021647, l1: 0.023349, l2: 0.033767, l3: 0.053503, l4: 0.095592, l5: 0.209174, l6: 0.391078\n",
      "\n",
      "[epoch: 365/400, batch: 496/1000, ite: 48438] train loss: 1.1291, accuracy: 94.8028%, tar: 0.0214 \n",
      "l0: 0.022256, l1: 0.023628, l2: 0.030973, l3: 0.047501, l4: 0.090139, l5: 0.186991, l6: 0.375047\n",
      "\n",
      "[epoch: 365/400, batch: 504/1000, ite: 48439] train loss: 1.1292, accuracy: 95.6749%, tar: 0.0214 \n",
      "l0: 0.019480, l1: 0.020895, l2: 0.029894, l3: 0.047285, l4: 0.098001, l5: 0.218044, l6: 0.438392\n",
      "\n",
      "[epoch: 365/400, batch: 512/1000, ite: 48440] train loss: 1.1296, accuracy: 94.5827%, tar: 0.0214 \n",
      "l0: 0.034982, l1: 0.037117, l2: 0.047886, l3: 0.069912, l4: 0.145734, l5: 0.330836, l6: 0.604951\n",
      "\n",
      "[epoch: 365/400, batch: 520/1000, ite: 48441] train loss: 1.1313, accuracy: 91.7113%, tar: 0.0215 \n",
      "l0: 0.015148, l1: 0.016878, l2: 0.025419, l3: 0.040829, l4: 0.074176, l5: 0.140685, l6: 0.278062\n",
      "\n",
      "[epoch: 365/400, batch: 528/1000, ite: 48442] train loss: 1.1307, accuracy: 96.4449%, tar: 0.0214 \n",
      "l0: 0.019893, l1: 0.021570, l2: 0.029746, l3: 0.045100, l4: 0.081194, l5: 0.176449, l6: 0.322420\n",
      "\n",
      "[epoch: 365/400, batch: 536/1000, ite: 48443] train loss: 1.1304, accuracy: 95.5524%, tar: 0.0214 \n",
      "l0: 0.027801, l1: 0.029227, l2: 0.038072, l3: 0.055349, l4: 0.104630, l5: 0.207628, l6: 0.388780\n",
      "\n",
      "[epoch: 365/400, batch: 544/1000, ite: 48444] train loss: 1.1307, accuracy: 94.6086%, tar: 0.0215 \n",
      "l0: 0.021234, l1: 0.022865, l2: 0.030952, l3: 0.045886, l4: 0.094487, l5: 0.210296, l6: 0.389108\n",
      "\n",
      "[epoch: 365/400, batch: 552/1000, ite: 48445] train loss: 1.1309, accuracy: 95.0642%, tar: 0.0215 \n",
      "l0: 0.020378, l1: 0.021508, l2: 0.029495, l3: 0.044339, l4: 0.082540, l5: 0.170943, l6: 0.385997\n",
      "\n",
      "[epoch: 365/400, batch: 560/1000, ite: 48446] train loss: 1.1309, accuracy: 94.8497%, tar: 0.0215 \n",
      "l0: 0.021707, l1: 0.022718, l2: 0.028179, l3: 0.039883, l4: 0.068668, l5: 0.157258, l6: 0.272929\n",
      "\n",
      "[epoch: 365/400, batch: 568/1000, ite: 48447] train loss: 1.1304, accuracy: 95.0887%, tar: 0.0215 \n",
      "l0: 0.023713, l1: 0.025341, l2: 0.034028, l3: 0.047630, l4: 0.091103, l5: 0.179255, l6: 0.399562\n",
      "\n",
      "[epoch: 365/400, batch: 576/1000, ite: 48448] train loss: 1.1305, accuracy: 94.3561%, tar: 0.0215 \n",
      "l0: 0.024912, l1: 0.026030, l2: 0.034442, l3: 0.049496, l4: 0.085287, l5: 0.197214, l6: 0.404947\n",
      "\n",
      "[epoch: 365/400, batch: 584/1000, ite: 48449] train loss: 1.1308, accuracy: 94.6123%, tar: 0.0215 \n",
      "l0: 0.021728, l1: 0.023030, l2: 0.031229, l3: 0.047753, l4: 0.103233, l5: 0.184431, l6: 0.352795\n",
      "\n",
      "[epoch: 365/400, batch: 592/1000, ite: 48450] train loss: 1.1307, accuracy: 95.4121%, tar: 0.0215 \n",
      "l0: 0.016488, l1: 0.017821, l2: 0.026485, l3: 0.041785, l4: 0.079352, l5: 0.162783, l6: 0.333059\n",
      "\n",
      "[epoch: 365/400, batch: 600/1000, ite: 48451] train loss: 1.1305, accuracy: 96.2591%, tar: 0.0215 \n",
      "l0: 0.014020, l1: 0.015045, l2: 0.021023, l3: 0.030741, l4: 0.051300, l5: 0.104923, l6: 0.243220\n",
      "\n",
      "[epoch: 365/400, batch: 608/1000, ite: 48452] train loss: 1.1296, accuracy: 97.0413%, tar: 0.0214 \n",
      "l0: 0.020656, l1: 0.021652, l2: 0.029503, l3: 0.044809, l4: 0.082918, l5: 0.173499, l6: 0.393098\n",
      "\n",
      "[epoch: 365/400, batch: 616/1000, ite: 48453] train loss: 1.1297, accuracy: 94.4560%, tar: 0.0214 \n",
      "l0: 0.021609, l1: 0.023039, l2: 0.032038, l3: 0.049436, l4: 0.085671, l5: 0.164572, l6: 0.411218\n",
      "\n",
      "[epoch: 365/400, batch: 624/1000, ite: 48454] train loss: 1.1298, accuracy: 94.3555%, tar: 0.0214 \n",
      "l0: 0.018985, l1: 0.020201, l2: 0.026857, l3: 0.043937, l4: 0.092408, l5: 0.164353, l6: 0.319909\n",
      "\n",
      "[epoch: 365/400, batch: 632/1000, ite: 48455] train loss: 1.1296, accuracy: 95.2984%, tar: 0.0214 \n",
      "l0: 0.014738, l1: 0.015757, l2: 0.021480, l3: 0.030357, l4: 0.056160, l5: 0.146553, l6: 0.329664\n",
      "\n",
      "[epoch: 365/400, batch: 640/1000, ite: 48456] train loss: 1.1291, accuracy: 96.0343%, tar: 0.0214 \n",
      "l0: 0.014942, l1: 0.016028, l2: 0.023349, l3: 0.039581, l4: 0.080574, l5: 0.182917, l6: 0.353237\n",
      "\n",
      "[epoch: 365/400, batch: 648/1000, ite: 48457] train loss: 1.1290, accuracy: 95.4835%, tar: 0.0214 \n",
      "l0: 0.024392, l1: 0.026995, l2: 0.036336, l3: 0.058771, l4: 0.103826, l5: 0.219351, l6: 0.492284\n",
      "\n",
      "[epoch: 365/400, batch: 656/1000, ite: 48458] train loss: 1.1297, accuracy: 93.9051%, tar: 0.0214 \n",
      "l0: 0.017172, l1: 0.018168, l2: 0.025022, l3: 0.038294, l4: 0.068071, l5: 0.136434, l6: 0.270008\n",
      "\n",
      "[epoch: 365/400, batch: 664/1000, ite: 48459] train loss: 1.1291, accuracy: 95.8442%, tar: 0.0214 \n",
      "l0: 0.014717, l1: 0.015971, l2: 0.022930, l3: 0.033752, l4: 0.061631, l5: 0.137242, l6: 0.264778\n",
      "\n",
      "[epoch: 365/400, batch: 672/1000, ite: 48460] train loss: 1.1284, accuracy: 96.5957%, tar: 0.0214 \n",
      "l0: 0.026863, l1: 0.028732, l2: 0.038877, l3: 0.063392, l4: 0.124638, l5: 0.234558, l6: 0.548319\n",
      "\n",
      "[epoch: 365/400, batch: 680/1000, ite: 48461] train loss: 1.1295, accuracy: 93.3499%, tar: 0.0214 \n",
      "l0: 0.019753, l1: 0.022740, l2: 0.035476, l3: 0.059703, l4: 0.112513, l5: 0.204061, l6: 0.356911\n",
      "\n",
      "[epoch: 365/400, batch: 688/1000, ite: 48462] train loss: 1.1296, accuracy: 95.5415%, tar: 0.0214 \n",
      "l0: 0.021134, l1: 0.022785, l2: 0.031100, l3: 0.049639, l4: 0.090497, l5: 0.191403, l6: 0.422698\n",
      "\n",
      "[epoch: 365/400, batch: 696/1000, ite: 48463] train loss: 1.1298, accuracy: 94.9701%, tar: 0.0214 \n",
      "l0: 0.018046, l1: 0.019262, l2: 0.024465, l3: 0.034854, l4: 0.068835, l5: 0.122820, l6: 0.277521\n",
      "\n",
      "[epoch: 365/400, batch: 704/1000, ite: 48464] train loss: 1.1292, accuracy: 96.1153%, tar: 0.0214 \n",
      "l0: 0.019408, l1: 0.020419, l2: 0.028062, l3: 0.041501, l4: 0.073453, l5: 0.148861, l6: 0.364147\n",
      "\n",
      "[epoch: 365/400, batch: 712/1000, ite: 48465] train loss: 1.1291, accuracy: 95.2164%, tar: 0.0214 \n",
      "l0: 0.018398, l1: 0.018962, l2: 0.024038, l3: 0.034446, l4: 0.058766, l5: 0.132311, l6: 0.260943\n",
      "\n",
      "[epoch: 365/400, batch: 720/1000, ite: 48466] train loss: 1.1284, accuracy: 95.9417%, tar: 0.0214 \n",
      "l0: 0.022908, l1: 0.024567, l2: 0.032649, l3: 0.052250, l4: 0.101575, l5: 0.213758, l6: 0.410371\n",
      "\n",
      "[epoch: 365/400, batch: 728/1000, ite: 48467] train loss: 1.1287, accuracy: 94.3451%, tar: 0.0214 \n",
      "l0: 0.018415, l1: 0.019607, l2: 0.027030, l3: 0.037599, l4: 0.064401, l5: 0.117258, l6: 0.262798\n",
      "\n",
      "[epoch: 365/400, batch: 736/1000, ite: 48468] train loss: 1.1280, accuracy: 95.9063%, tar: 0.0214 \n",
      "l0: 0.025318, l1: 0.027453, l2: 0.036050, l3: 0.052514, l4: 0.096529, l5: 0.195265, l6: 0.334611\n",
      "\n",
      "[epoch: 365/400, batch: 744/1000, ite: 48469] train loss: 1.1280, accuracy: 95.4548%, tar: 0.0214 \n",
      "l0: 0.020709, l1: 0.021735, l2: 0.029850, l3: 0.044311, l4: 0.082184, l5: 0.167527, l6: 0.316918\n",
      "\n",
      "[epoch: 365/400, batch: 752/1000, ite: 48470] train loss: 1.1277, accuracy: 95.6698%, tar: 0.0214 \n",
      "l0: 0.025021, l1: 0.026284, l2: 0.033211, l3: 0.043893, l4: 0.072279, l5: 0.134098, l6: 0.303235\n",
      "\n",
      "[epoch: 365/400, batch: 760/1000, ite: 48471] train loss: 1.1273, accuracy: 95.4040%, tar: 0.0214 \n",
      "l0: 0.025950, l1: 0.028246, l2: 0.035925, l3: 0.055854, l4: 0.108318, l5: 0.224037, l6: 0.375579\n",
      "\n",
      "[epoch: 365/400, batch: 768/1000, ite: 48472] train loss: 1.1276, accuracy: 94.6342%, tar: 0.0214 \n",
      "l0: 0.018170, l1: 0.019250, l2: 0.026225, l3: 0.039527, l4: 0.073175, l5: 0.156382, l6: 0.346501\n",
      "\n",
      "[epoch: 365/400, batch: 776/1000, ite: 48473] train loss: 1.1274, accuracy: 95.3561%, tar: 0.0214 \n",
      "l0: 0.020832, l1: 0.022497, l2: 0.030356, l3: 0.048526, l4: 0.094896, l5: 0.206494, l6: 0.429775\n",
      "\n",
      "[epoch: 365/400, batch: 784/1000, ite: 48474] train loss: 1.1277, accuracy: 93.8358%, tar: 0.0214 \n",
      "l0: 0.018877, l1: 0.020777, l2: 0.028330, l3: 0.043085, l4: 0.079473, l5: 0.147943, l6: 0.301480\n",
      "\n",
      "[epoch: 365/400, batch: 792/1000, ite: 48475] train loss: 1.1273, accuracy: 95.8731%, tar: 0.0214 \n",
      "l0: 0.019301, l1: 0.020972, l2: 0.029544, l3: 0.044713, l4: 0.086031, l5: 0.195910, l6: 0.409663\n",
      "\n",
      "[epoch: 365/400, batch: 800/1000, ite: 48476] train loss: 1.1275, accuracy: 95.2295%, tar: 0.0214 \n",
      "l0: 0.014422, l1: 0.015316, l2: 0.019900, l3: 0.030343, l4: 0.059884, l5: 0.132794, l6: 0.258020\n",
      "\n",
      "[epoch: 365/400, batch: 808/1000, ite: 48477] train loss: 1.1268, accuracy: 96.3096%, tar: 0.0214 \n",
      "l0: 0.024813, l1: 0.025562, l2: 0.033238, l3: 0.048460, l4: 0.081386, l5: 0.163326, l6: 0.354086\n",
      "\n",
      "[epoch: 365/400, batch: 816/1000, ite: 48478] train loss: 1.1267, accuracy: 94.5473%, tar: 0.0214 \n",
      "l0: 0.022169, l1: 0.023352, l2: 0.032893, l3: 0.048916, l4: 0.087025, l5: 0.166267, l6: 0.373909\n",
      "\n",
      "[epoch: 365/400, batch: 824/1000, ite: 48479] train loss: 1.1267, accuracy: 95.3206%, tar: 0.0214 \n",
      "l0: 0.020535, l1: 0.022290, l2: 0.030270, l3: 0.043870, l4: 0.077091, l5: 0.179771, l6: 0.340784\n",
      "\n",
      "[epoch: 365/400, batch: 832/1000, ite: 48480] train loss: 1.1266, accuracy: 95.3720%, tar: 0.0214 \n",
      "l0: 0.022472, l1: 0.023843, l2: 0.032202, l3: 0.049429, l4: 0.094960, l5: 0.228545, l6: 0.482268\n",
      "\n",
      "[epoch: 365/400, batch: 840/1000, ite: 48481] train loss: 1.1272, accuracy: 93.5431%, tar: 0.0214 \n",
      "l0: 0.019220, l1: 0.020303, l2: 0.027734, l3: 0.041506, l4: 0.071817, l5: 0.134375, l6: 0.312094\n",
      "\n",
      "[epoch: 365/400, batch: 848/1000, ite: 48482] train loss: 1.1268, accuracy: 95.6247%, tar: 0.0214 \n",
      "l0: 0.024046, l1: 0.025632, l2: 0.036486, l3: 0.057221, l4: 0.106466, l5: 0.211701, l6: 0.402883\n",
      "\n",
      "[epoch: 365/400, batch: 856/1000, ite: 48483] train loss: 1.1271, accuracy: 94.6014%, tar: 0.0214 \n",
      "l0: 0.015712, l1: 0.016948, l2: 0.023871, l3: 0.038210, l4: 0.068101, l5: 0.151902, l6: 0.311594\n",
      "\n",
      "[epoch: 365/400, batch: 864/1000, ite: 48484] train loss: 1.1268, accuracy: 96.0568%, tar: 0.0214 \n",
      "l0: 0.024281, l1: 0.025468, l2: 0.033156, l3: 0.047931, l4: 0.080993, l5: 0.175380, l6: 0.361877\n",
      "\n",
      "[epoch: 365/400, batch: 872/1000, ite: 48485] train loss: 1.1267, accuracy: 94.6365%, tar: 0.0214 \n",
      "l0: 0.020464, l1: 0.021370, l2: 0.029284, l3: 0.043670, l4: 0.076109, l5: 0.156288, l6: 0.341744\n",
      "\n",
      "[epoch: 365/400, batch: 880/1000, ite: 48486] train loss: 1.1265, accuracy: 95.4070%, tar: 0.0214 \n",
      "l0: 0.021255, l1: 0.021893, l2: 0.029987, l3: 0.044806, l4: 0.076393, l5: 0.135010, l6: 0.281518\n",
      "\n",
      "[epoch: 365/400, batch: 888/1000, ite: 48487] train loss: 1.1261, accuracy: 95.7746%, tar: 0.0214 \n",
      "l0: 0.018509, l1: 0.019154, l2: 0.024196, l3: 0.035017, l4: 0.060293, l5: 0.130503, l6: 0.269537\n",
      "\n",
      "[epoch: 365/400, batch: 896/1000, ite: 48488] train loss: 1.1255, accuracy: 95.7938%, tar: 0.0214 \n",
      "l0: 0.023748, l1: 0.026099, l2: 0.035933, l3: 0.055775, l4: 0.133007, l5: 0.242846, l6: 0.446007\n",
      "\n",
      "[epoch: 365/400, batch: 904/1000, ite: 48489] train loss: 1.1261, accuracy: 94.2106%, tar: 0.0214 \n",
      "l0: 0.021336, l1: 0.023324, l2: 0.031416, l3: 0.048928, l4: 0.091188, l5: 0.173741, l6: 0.318756\n",
      "\n",
      "[epoch: 365/400, batch: 912/1000, ite: 48490] train loss: 1.1259, accuracy: 95.5026%, tar: 0.0214 \n",
      "l0: 0.018985, l1: 0.019824, l2: 0.026152, l3: 0.036778, l4: 0.058082, l5: 0.111822, l6: 0.247671\n",
      "\n",
      "[epoch: 365/400, batch: 920/1000, ite: 48491] train loss: 1.1251, accuracy: 95.9162%, tar: 0.0214 \n",
      "l0: 0.019904, l1: 0.021071, l2: 0.028195, l3: 0.040494, l4: 0.068798, l5: 0.117818, l6: 0.243528\n",
      "\n",
      "[epoch: 365/400, batch: 928/1000, ite: 48492] train loss: 1.1244, accuracy: 96.3878%, tar: 0.0214 \n",
      "l0: 0.020618, l1: 0.021479, l2: 0.028214, l3: 0.046153, l4: 0.118262, l5: 0.228338, l6: 0.458924\n",
      "\n",
      "[epoch: 365/400, batch: 936/1000, ite: 48493] train loss: 1.1250, accuracy: 93.9539%, tar: 0.0214 \n",
      "l0: 0.021010, l1: 0.022259, l2: 0.028844, l3: 0.044979, l4: 0.087803, l5: 0.184129, l6: 0.396583\n",
      "\n",
      "[epoch: 365/400, batch: 944/1000, ite: 48494] train loss: 1.1251, accuracy: 94.5589%, tar: 0.0214 \n",
      "l0: 0.018098, l1: 0.019113, l2: 0.024427, l3: 0.037018, l4: 0.079895, l5: 0.145826, l6: 0.293013\n",
      "\n",
      "[epoch: 365/400, batch: 952/1000, ite: 48495] train loss: 1.1247, accuracy: 96.1182%, tar: 0.0214 \n",
      "l0: 0.020161, l1: 0.021317, l2: 0.027958, l3: 0.041523, l4: 0.077611, l5: 0.184564, l6: 0.367983\n",
      "\n",
      "[epoch: 365/400, batch: 960/1000, ite: 48496] train loss: 1.1247, accuracy: 95.5569%, tar: 0.0214 \n",
      "l0: 0.016534, l1: 0.017507, l2: 0.023477, l3: 0.034726, l4: 0.066519, l5: 0.138432, l6: 0.280585\n",
      "\n",
      "[epoch: 365/400, batch: 968/1000, ite: 48497] train loss: 1.1241, accuracy: 95.8917%, tar: 0.0213 \n",
      "l0: 0.022303, l1: 0.023181, l2: 0.029969, l3: 0.041709, l4: 0.073526, l5: 0.151828, l6: 0.310419\n",
      "\n",
      "[epoch: 365/400, batch: 976/1000, ite: 48498] train loss: 1.1238, accuracy: 95.2211%, tar: 0.0213 \n",
      "l0: 0.019738, l1: 0.020682, l2: 0.027278, l3: 0.039908, l4: 0.072455, l5: 0.133785, l6: 0.295150\n",
      "\n",
      "[epoch: 365/400, batch: 984/1000, ite: 48499] train loss: 1.1234, accuracy: 94.9447%, tar: 0.0213 \n",
      "l0: 0.023082, l1: 0.024861, l2: 0.032307, l3: 0.049762, l4: 0.105360, l5: 0.217627, l6: 0.455781\n",
      "\n",
      "[epoch: 365/400, batch: 992/1000, ite: 48500] train loss: 1.1239, accuracy: 94.1709%, tar: 0.0213 \n",
      "l0: 0.025913, l1: 0.028234, l2: 0.039081, l3: 0.063306, l4: 0.132470, l5: 0.272220, l6: 0.555466\n",
      "\n",
      "[epoch: 365/400, batch: 1000/1000, ite: 48501] train loss: 1.1250, accuracy: 93.6882%, tar: 0.0214 \n",
      "l0: 0.025166, l1: 0.028453, l2: 0.041529, l3: 0.068100, l4: 0.145811, l5: 0.276037, l6: 0.459331\n",
      "\n",
      "[epoch: 366/400, batch: 8/1000, ite: 48502] train loss: 1.1257, accuracy: 94.7594%, tar: 0.0214 \n",
      "l0: 0.023183, l1: 0.025133, l2: 0.035685, l3: 0.056066, l4: 0.112574, l5: 0.211325, l6: 0.391038\n",
      "\n",
      "[epoch: 366/400, batch: 16/1000, ite: 48503] train loss: 1.1260, accuracy: 94.7619%, tar: 0.0214 \n",
      "l0: 0.020290, l1: 0.021229, l2: 0.028429, l3: 0.044120, l4: 0.080985, l5: 0.157811, l6: 0.326758\n",
      "\n",
      "[epoch: 366/400, batch: 24/1000, ite: 48504] train loss: 1.1257, accuracy: 95.5225%, tar: 0.0214 \n",
      "l0: 0.017882, l1: 0.018987, l2: 0.026816, l3: 0.041461, l4: 0.073752, l5: 0.144056, l6: 0.328730\n",
      "\n",
      "[epoch: 366/400, batch: 32/1000, ite: 48505] train loss: 1.1255, accuracy: 94.9063%, tar: 0.0214 \n",
      "l0: 0.017073, l1: 0.018258, l2: 0.024935, l3: 0.040030, l4: 0.076857, l5: 0.178397, l6: 0.336489\n",
      "\n",
      "[epoch: 366/400, batch: 40/1000, ite: 48506] train loss: 1.1253, accuracy: 95.3649%, tar: 0.0213 \n",
      "l0: 0.019412, l1: 0.020340, l2: 0.026977, l3: 0.037094, l4: 0.057912, l5: 0.116579, l6: 0.249377\n",
      "\n",
      "[epoch: 366/400, batch: 48/1000, ite: 48507] train loss: 1.1246, accuracy: 95.9751%, tar: 0.0213 \n",
      "l0: 0.024624, l1: 0.025784, l2: 0.035127, l3: 0.050380, l4: 0.086474, l5: 0.173429, l6: 0.346121\n",
      "\n",
      "[epoch: 366/400, batch: 56/1000, ite: 48508] train loss: 1.1245, accuracy: 95.1215%, tar: 0.0213 \n",
      "l0: 0.019892, l1: 0.020865, l2: 0.027492, l3: 0.042635, l4: 0.078661, l5: 0.183934, l6: 0.329529\n",
      "\n",
      "[epoch: 366/400, batch: 64/1000, ite: 48509] train loss: 1.1244, accuracy: 95.0569%, tar: 0.0213 \n",
      "l0: 0.021500, l1: 0.023079, l2: 0.032567, l3: 0.049303, l4: 0.086546, l5: 0.170465, l6: 0.449526\n",
      "\n",
      "[epoch: 366/400, batch: 72/1000, ite: 48510] train loss: 1.1247, accuracy: 94.2755%, tar: 0.0213 \n",
      "l0: 0.018882, l1: 0.020162, l2: 0.026995, l3: 0.042151, l4: 0.078131, l5: 0.160106, l6: 0.305770\n",
      "\n",
      "[epoch: 366/400, batch: 80/1000, ite: 48511] train loss: 1.1244, accuracy: 95.8236%, tar: 0.0213 \n",
      "l0: 0.021819, l1: 0.023255, l2: 0.031635, l3: 0.048057, l4: 0.092191, l5: 0.202400, l6: 0.381727\n",
      "\n",
      "[epoch: 366/400, batch: 88/1000, ite: 48512] train loss: 1.1245, accuracy: 94.8524%, tar: 0.0213 \n",
      "l0: 0.026207, l1: 0.028253, l2: 0.038131, l3: 0.060439, l4: 0.116333, l5: 0.303850, l6: 0.585537\n",
      "\n",
      "[epoch: 366/400, batch: 96/1000, ite: 48513] train loss: 1.1257, accuracy: 92.0275%, tar: 0.0214 \n",
      "l0: 0.022026, l1: 0.023217, l2: 0.031198, l3: 0.045491, l4: 0.085385, l5: 0.182516, l6: 0.369991\n",
      "\n",
      "[epoch: 366/400, batch: 104/1000, ite: 48514] train loss: 1.1257, accuracy: 94.5300%, tar: 0.0214 \n",
      "l0: 0.018279, l1: 0.019717, l2: 0.027767, l3: 0.047180, l4: 0.095070, l5: 0.201997, l6: 0.360445\n",
      "\n",
      "[epoch: 366/400, batch: 112/1000, ite: 48515] train loss: 1.1257, accuracy: 94.5933%, tar: 0.0213 \n",
      "l0: 0.022566, l1: 0.023764, l2: 0.030578, l3: 0.044458, l4: 0.083329, l5: 0.146364, l6: 0.316885\n",
      "\n",
      "[epoch: 366/400, batch: 120/1000, ite: 48516] train loss: 1.1255, accuracy: 95.0376%, tar: 0.0213 \n",
      "l0: 0.022601, l1: 0.024338, l2: 0.033905, l3: 0.052268, l4: 0.107960, l5: 0.222662, l6: 0.378837\n",
      "\n",
      "[epoch: 366/400, batch: 128/1000, ite: 48517] train loss: 1.1256, accuracy: 94.3870%, tar: 0.0214 \n",
      "l0: 0.026795, l1: 0.028818, l2: 0.039378, l3: 0.059294, l4: 0.119807, l5: 0.278497, l6: 0.588479\n",
      "\n",
      "[epoch: 366/400, batch: 136/1000, ite: 48518] train loss: 1.1268, accuracy: 92.0586%, tar: 0.0214 \n",
      "l0: 0.019364, l1: 0.021456, l2: 0.029728, l3: 0.043321, l4: 0.080289, l5: 0.154600, l6: 0.308165\n",
      "\n",
      "[epoch: 366/400, batch: 144/1000, ite: 48519] train loss: 1.1265, accuracy: 96.2372%, tar: 0.0214 \n",
      "l0: 0.020897, l1: 0.022243, l2: 0.028541, l3: 0.042392, l4: 0.080293, l5: 0.171861, l6: 0.354177\n",
      "\n",
      "[epoch: 366/400, batch: 152/1000, ite: 48520] train loss: 1.1264, accuracy: 95.1208%, tar: 0.0214 \n",
      "l0: 0.018941, l1: 0.020310, l2: 0.028405, l3: 0.045173, l4: 0.087601, l5: 0.202512, l6: 0.498675\n",
      "\n",
      "[epoch: 366/400, batch: 160/1000, ite: 48521] train loss: 1.1270, accuracy: 94.4848%, tar: 0.0214 \n",
      "l0: 0.015256, l1: 0.016029, l2: 0.022957, l3: 0.035446, l4: 0.075571, l5: 0.146624, l6: 0.283686\n",
      "\n",
      "[epoch: 366/400, batch: 168/1000, ite: 48522] train loss: 1.1265, accuracy: 95.9575%, tar: 0.0213 \n",
      "l0: 0.028497, l1: 0.030084, l2: 0.040359, l3: 0.060954, l4: 0.108929, l5: 0.254901, l6: 0.480214\n",
      "\n",
      "[epoch: 366/400, batch: 176/1000, ite: 48523] train loss: 1.1272, accuracy: 93.3147%, tar: 0.0214 \n",
      "l0: 0.020089, l1: 0.021458, l2: 0.029727, l3: 0.043425, l4: 0.085671, l5: 0.185745, l6: 0.385357\n",
      "\n",
      "[epoch: 366/400, batch: 184/1000, ite: 48524] train loss: 1.1273, accuracy: 95.3110%, tar: 0.0214 \n",
      "l0: 0.020121, l1: 0.020867, l2: 0.026792, l3: 0.039940, l4: 0.077218, l5: 0.158134, l6: 0.364633\n",
      "\n",
      "[epoch: 366/400, batch: 192/1000, ite: 48525] train loss: 1.1272, accuracy: 94.8106%, tar: 0.0214 \n",
      "l0: 0.018869, l1: 0.020098, l2: 0.027294, l3: 0.040360, l4: 0.075550, l5: 0.139613, l6: 0.308370\n",
      "\n",
      "[epoch: 366/400, batch: 200/1000, ite: 48526] train loss: 1.1268, accuracy: 95.6618%, tar: 0.0213 \n",
      "l0: 0.016795, l1: 0.018280, l2: 0.025542, l3: 0.044250, l4: 0.084756, l5: 0.163419, l6: 0.301573\n",
      "\n",
      "[epoch: 366/400, batch: 208/1000, ite: 48527] train loss: 1.1265, accuracy: 96.4860%, tar: 0.0213 \n",
      "l0: 0.027131, l1: 0.028844, l2: 0.041773, l3: 0.064605, l4: 0.130773, l5: 0.281755, l6: 0.521367\n",
      "\n",
      "[epoch: 366/400, batch: 216/1000, ite: 48528] train loss: 1.1274, accuracy: 93.8055%, tar: 0.0213 \n",
      "l0: 0.017516, l1: 0.018705, l2: 0.026749, l3: 0.041817, l4: 0.076156, l5: 0.186171, l6: 0.354444\n",
      "\n",
      "[epoch: 366/400, batch: 224/1000, ite: 48529] train loss: 1.1273, accuracy: 95.0159%, tar: 0.0213 \n",
      "l0: 0.020229, l1: 0.021340, l2: 0.026112, l3: 0.037658, l4: 0.073323, l5: 0.157667, l6: 0.366524\n",
      "\n",
      "[epoch: 366/400, batch: 232/1000, ite: 48530] train loss: 1.1272, accuracy: 95.0707%, tar: 0.0213 \n",
      "l0: 0.027371, l1: 0.028987, l2: 0.038346, l3: 0.064871, l4: 0.111129, l5: 0.197334, l6: 0.418920\n",
      "\n",
      "[epoch: 366/400, batch: 240/1000, ite: 48531] train loss: 1.1276, accuracy: 93.6124%, tar: 0.0214 \n",
      "l0: 0.021035, l1: 0.022559, l2: 0.029133, l3: 0.043567, l4: 0.078271, l5: 0.154578, l6: 0.338240\n",
      "\n",
      "[epoch: 366/400, batch: 248/1000, ite: 48532] train loss: 1.1274, accuracy: 95.2413%, tar: 0.0213 \n",
      "l0: 0.018115, l1: 0.018885, l2: 0.024895, l3: 0.036518, l4: 0.063342, l5: 0.132793, l6: 0.305407\n",
      "\n",
      "[epoch: 366/400, batch: 256/1000, ite: 48533] train loss: 1.1270, accuracy: 95.9570%, tar: 0.0213 \n",
      "l0: 0.021837, l1: 0.023278, l2: 0.031159, l3: 0.046035, l4: 0.088668, l5: 0.165849, l6: 0.355988\n",
      "\n",
      "[epoch: 366/400, batch: 264/1000, ite: 48534] train loss: 1.1269, accuracy: 95.5214%, tar: 0.0213 \n",
      "l0: 0.021390, l1: 0.023313, l2: 0.031877, l3: 0.048842, l4: 0.093532, l5: 0.188930, l6: 0.411640\n",
      "\n",
      "[epoch: 366/400, batch: 272/1000, ite: 48535] train loss: 1.1271, accuracy: 94.3409%, tar: 0.0213 \n",
      "l0: 0.022756, l1: 0.024753, l2: 0.036565, l3: 0.057533, l4: 0.121256, l5: 0.229843, l6: 0.486180\n",
      "\n",
      "[epoch: 366/400, batch: 280/1000, ite: 48536] train loss: 1.1278, accuracy: 94.3862%, tar: 0.0213 \n",
      "l0: 0.017247, l1: 0.018870, l2: 0.027393, l3: 0.043113, l4: 0.078087, l5: 0.146580, l6: 0.272916\n",
      "\n",
      "[epoch: 366/400, batch: 288/1000, ite: 48537] train loss: 1.1273, accuracy: 96.7072%, tar: 0.0213 \n",
      "l0: 0.019563, l1: 0.020849, l2: 0.027511, l3: 0.039027, l4: 0.068057, l5: 0.148145, l6: 0.309406\n",
      "\n",
      "[epoch: 366/400, batch: 296/1000, ite: 48538] train loss: 1.1270, accuracy: 95.5838%, tar: 0.0213 \n",
      "l0: 0.021926, l1: 0.023350, l2: 0.030687, l3: 0.049685, l4: 0.109371, l5: 0.214811, l6: 0.402304\n",
      "\n",
      "[epoch: 366/400, batch: 304/1000, ite: 48539] train loss: 1.1272, accuracy: 94.5277%, tar: 0.0213 \n",
      "l0: 0.021976, l1: 0.023217, l2: 0.031680, l3: 0.049318, l4: 0.091007, l5: 0.207868, l6: 0.569238\n",
      "\n",
      "[epoch: 366/400, batch: 312/1000, ite: 48540] train loss: 1.1280, accuracy: 92.6753%, tar: 0.0213 \n",
      "l0: 0.015776, l1: 0.016361, l2: 0.021963, l3: 0.033063, l4: 0.066890, l5: 0.141869, l6: 0.302438\n",
      "\n",
      "[epoch: 366/400, batch: 320/1000, ite: 48541] train loss: 1.1276, accuracy: 95.7417%, tar: 0.0213 \n",
      "l0: 0.014971, l1: 0.015903, l2: 0.022527, l3: 0.033453, l4: 0.059832, l5: 0.135256, l6: 0.318711\n",
      "\n",
      "[epoch: 366/400, batch: 328/1000, ite: 48542] train loss: 1.1273, accuracy: 95.9140%, tar: 0.0213 \n",
      "l0: 0.025626, l1: 0.027044, l2: 0.036118, l3: 0.058318, l4: 0.108870, l5: 0.236904, l6: 0.497335\n",
      "\n",
      "[epoch: 366/400, batch: 336/1000, ite: 48543] train loss: 1.1279, accuracy: 93.8370%, tar: 0.0213 \n",
      "l0: 0.023695, l1: 0.024440, l2: 0.033104, l3: 0.056036, l4: 0.106304, l5: 0.250448, l6: 0.523065\n",
      "\n",
      "[epoch: 366/400, batch: 344/1000, ite: 48544] train loss: 1.1287, accuracy: 93.3897%, tar: 0.0213 \n",
      "l0: 0.020531, l1: 0.021572, l2: 0.030590, l3: 0.047252, l4: 0.084092, l5: 0.156121, l6: 0.304380\n",
      "\n",
      "[epoch: 366/400, batch: 352/1000, ite: 48545] train loss: 1.1284, accuracy: 95.8710%, tar: 0.0213 \n",
      "l0: 0.020439, l1: 0.021756, l2: 0.029412, l3: 0.046087, l4: 0.097423, l5: 0.190069, l6: 0.344828\n",
      "\n",
      "[epoch: 366/400, batch: 360/1000, ite: 48546] train loss: 1.1283, accuracy: 95.3844%, tar: 0.0213 \n",
      "l0: 0.024392, l1: 0.025664, l2: 0.034458, l3: 0.056808, l4: 0.122986, l5: 0.258767, l6: 0.562549\n",
      "\n",
      "[epoch: 366/400, batch: 368/1000, ite: 48547] train loss: 1.1293, accuracy: 93.6180%, tar: 0.0213 \n",
      "l0: 0.020343, l1: 0.021169, l2: 0.027671, l3: 0.043317, l4: 0.088511, l5: 0.165052, l6: 0.347591\n",
      "\n",
      "[epoch: 366/400, batch: 376/1000, ite: 48548] train loss: 1.1292, accuracy: 95.1583%, tar: 0.0213 \n",
      "l0: 0.021649, l1: 0.023208, l2: 0.030852, l3: 0.047248, l4: 0.086563, l5: 0.195104, l6: 0.454891\n",
      "\n",
      "[epoch: 366/400, batch: 384/1000, ite: 48549] train loss: 1.1295, accuracy: 94.0345%, tar: 0.0213 \n",
      "l0: 0.023552, l1: 0.024988, l2: 0.032021, l3: 0.042771, l4: 0.072094, l5: 0.136983, l6: 0.283597\n",
      "\n",
      "[epoch: 366/400, batch: 392/1000, ite: 48550] train loss: 1.1291, accuracy: 95.3767%, tar: 0.0213 \n",
      "l0: 0.013476, l1: 0.014616, l2: 0.020843, l3: 0.033504, l4: 0.078841, l5: 0.140465, l6: 0.305035\n",
      "\n",
      "[epoch: 366/400, batch: 400/1000, ite: 48551] train loss: 1.1287, accuracy: 96.4708%, tar: 0.0213 \n",
      "l0: 0.028838, l1: 0.029968, l2: 0.040637, l3: 0.068068, l4: 0.125572, l5: 0.231306, l6: 0.413238\n",
      "\n",
      "[epoch: 366/400, batch: 408/1000, ite: 48552] train loss: 1.1291, accuracy: 94.8579%, tar: 0.0213 \n",
      "l0: 0.025430, l1: 0.026534, l2: 0.035028, l3: 0.051191, l4: 0.085322, l5: 0.165468, l6: 0.378098\n",
      "\n",
      "[epoch: 366/400, batch: 416/1000, ite: 48553] train loss: 1.1292, accuracy: 94.2041%, tar: 0.0213 \n",
      "l0: 0.022077, l1: 0.023746, l2: 0.032677, l3: 0.050218, l4: 0.093149, l5: 0.180430, l6: 0.371862\n",
      "\n",
      "[epoch: 366/400, batch: 424/1000, ite: 48554] train loss: 1.1292, accuracy: 95.1615%, tar: 0.0213 \n",
      "l0: 0.019262, l1: 0.020208, l2: 0.026370, l3: 0.042073, l4: 0.087092, l5: 0.173704, l6: 0.392819\n",
      "\n",
      "[epoch: 366/400, batch: 432/1000, ite: 48555] train loss: 1.1293, accuracy: 94.6895%, tar: 0.0213 \n",
      "l0: 0.020940, l1: 0.022140, l2: 0.029368, l3: 0.042401, l4: 0.075636, l5: 0.159926, l6: 0.353599\n",
      "\n",
      "[epoch: 366/400, batch: 440/1000, ite: 48556] train loss: 1.1291, accuracy: 95.1312%, tar: 0.0213 \n",
      "l0: 0.014653, l1: 0.015965, l2: 0.022645, l3: 0.033818, l4: 0.061134, l5: 0.113111, l6: 0.246685\n",
      "\n",
      "[epoch: 366/400, batch: 448/1000, ite: 48557] train loss: 1.1285, accuracy: 96.8739%, tar: 0.0213 \n",
      "l0: 0.021996, l1: 0.023016, l2: 0.031681, l3: 0.045731, l4: 0.083326, l5: 0.167785, l6: 0.359972\n",
      "\n",
      "[epoch: 366/400, batch: 456/1000, ite: 48558] train loss: 1.1284, accuracy: 94.9132%, tar: 0.0213 \n",
      "l0: 0.022760, l1: 0.024516, l2: 0.033116, l3: 0.055996, l4: 0.097662, l5: 0.190426, l6: 0.380852\n",
      "\n",
      "[epoch: 366/400, batch: 464/1000, ite: 48559] train loss: 1.1285, accuracy: 94.8697%, tar: 0.0213 \n",
      "l0: 0.020093, l1: 0.021039, l2: 0.026382, l3: 0.038569, l4: 0.077247, l5: 0.145758, l6: 0.268617\n",
      "\n",
      "[epoch: 366/400, batch: 472/1000, ite: 48560] train loss: 1.1281, accuracy: 95.0874%, tar: 0.0213 \n",
      "l0: 0.019795, l1: 0.020959, l2: 0.027689, l3: 0.047961, l4: 0.093587, l5: 0.191624, l6: 0.355884\n",
      "\n",
      "[epoch: 366/400, batch: 480/1000, ite: 48561] train loss: 1.1281, accuracy: 95.1648%, tar: 0.0213 \n",
      "l0: 0.018617, l1: 0.019381, l2: 0.025350, l3: 0.038411, l4: 0.066214, l5: 0.133504, l6: 0.334331\n",
      "\n",
      "[epoch: 366/400, batch: 488/1000, ite: 48562] train loss: 1.1278, accuracy: 95.4697%, tar: 0.0213 \n",
      "l0: 0.017371, l1: 0.018687, l2: 0.025455, l3: 0.037642, l4: 0.066690, l5: 0.135592, l6: 0.343492\n",
      "\n",
      "[epoch: 366/400, batch: 496/1000, ite: 48563] train loss: 1.1276, accuracy: 96.1042%, tar: 0.0213 \n",
      "l0: 0.019675, l1: 0.020653, l2: 0.028127, l3: 0.042631, l4: 0.074774, l5: 0.141336, l6: 0.311055\n",
      "\n",
      "[epoch: 366/400, batch: 504/1000, ite: 48564] train loss: 1.1272, accuracy: 95.3819%, tar: 0.0213 \n",
      "l0: 0.022092, l1: 0.025015, l2: 0.038018, l3: 0.067692, l4: 0.121991, l5: 0.221573, l6: 0.391970\n",
      "\n",
      "[epoch: 366/400, batch: 512/1000, ite: 48565] train loss: 1.1275, accuracy: 95.1864%, tar: 0.0213 \n",
      "l0: 0.027261, l1: 0.029200, l2: 0.037328, l3: 0.055841, l4: 0.095844, l5: 0.205446, l6: 0.385446\n",
      "\n",
      "[epoch: 366/400, batch: 520/1000, ite: 48566] train loss: 1.1277, accuracy: 94.4063%, tar: 0.0213 \n",
      "l0: 0.022715, l1: 0.023997, l2: 0.031148, l3: 0.045256, l4: 0.084631, l5: 0.203263, l6: 0.347928\n",
      "\n",
      "[epoch: 366/400, batch: 528/1000, ite: 48567] train loss: 1.1277, accuracy: 94.7021%, tar: 0.0213 \n",
      "l0: 0.025705, l1: 0.026751, l2: 0.035967, l3: 0.055280, l4: 0.099208, l5: 0.229313, l6: 0.467073\n",
      "\n",
      "[epoch: 366/400, batch: 536/1000, ite: 48568] train loss: 1.1282, accuracy: 93.5503%, tar: 0.0213 \n",
      "l0: 0.023261, l1: 0.024522, l2: 0.033476, l3: 0.049697, l4: 0.098033, l5: 0.211007, l6: 0.436302\n",
      "\n",
      "[epoch: 366/400, batch: 544/1000, ite: 48569] train loss: 1.1285, accuracy: 94.7998%, tar: 0.0213 \n",
      "l0: 0.020843, l1: 0.022522, l2: 0.031447, l3: 0.050025, l4: 0.097250, l5: 0.215499, l6: 0.463036\n",
      "\n",
      "[epoch: 366/400, batch: 552/1000, ite: 48570] train loss: 1.1289, accuracy: 94.3675%, tar: 0.0213 \n",
      "l0: 0.019833, l1: 0.020468, l2: 0.027377, l3: 0.038831, l4: 0.061655, l5: 0.116483, l6: 0.319905\n",
      "\n",
      "[epoch: 366/400, batch: 560/1000, ite: 48571] train loss: 1.1286, accuracy: 95.2557%, tar: 0.0213 \n",
      "l0: 0.027677, l1: 0.028943, l2: 0.037890, l3: 0.053052, l4: 0.094302, l5: 0.171606, l6: 0.489432\n",
      "\n",
      "[epoch: 366/400, batch: 568/1000, ite: 48572] train loss: 1.1290, accuracy: 94.2503%, tar: 0.0213 \n",
      "l0: 0.017840, l1: 0.018537, l2: 0.023872, l3: 0.035742, l4: 0.068858, l5: 0.149504, l6: 0.360989\n",
      "\n",
      "[epoch: 366/400, batch: 576/1000, ite: 48573] train loss: 1.1289, accuracy: 95.1607%, tar: 0.0213 \n",
      "l0: 0.019014, l1: 0.020365, l2: 0.026484, l3: 0.042998, l4: 0.073709, l5: 0.171875, l6: 0.340014\n",
      "\n",
      "[epoch: 366/400, batch: 584/1000, ite: 48574] train loss: 1.1287, accuracy: 95.5271%, tar: 0.0213 \n",
      "l0: 0.022269, l1: 0.023619, l2: 0.033958, l3: 0.050968, l4: 0.099158, l5: 0.221353, l6: 0.445763\n",
      "\n",
      "[epoch: 366/400, batch: 592/1000, ite: 48575] train loss: 1.1291, accuracy: 94.4967%, tar: 0.0213 \n",
      "l0: 0.024113, l1: 0.026349, l2: 0.036167, l3: 0.056661, l4: 0.137989, l5: 0.283136, l6: 0.532299\n",
      "\n",
      "[epoch: 366/400, batch: 600/1000, ite: 48576] train loss: 1.1300, accuracy: 93.6103%, tar: 0.0213 \n",
      "l0: 0.021792, l1: 0.023009, l2: 0.030043, l3: 0.048374, l4: 0.090226, l5: 0.178559, l6: 0.370834\n",
      "\n",
      "[epoch: 366/400, batch: 608/1000, ite: 48577] train loss: 1.1300, accuracy: 94.9042%, tar: 0.0213 \n",
      "l0: 0.020934, l1: 0.021735, l2: 0.027846, l3: 0.037601, l4: 0.059089, l5: 0.108536, l6: 0.256706\n",
      "\n",
      "[epoch: 366/400, batch: 616/1000, ite: 48578] train loss: 1.1294, accuracy: 95.6006%, tar: 0.0213 \n",
      "l0: 0.019696, l1: 0.021021, l2: 0.028004, l3: 0.041882, l4: 0.082856, l5: 0.176031, l6: 0.305148\n",
      "\n",
      "[epoch: 366/400, batch: 624/1000, ite: 48579] train loss: 1.1292, accuracy: 95.7886%, tar: 0.0213 \n",
      "l0: 0.021257, l1: 0.022546, l2: 0.029337, l3: 0.046052, l4: 0.090639, l5: 0.181253, l6: 0.400800\n",
      "\n",
      "[epoch: 366/400, batch: 632/1000, ite: 48580] train loss: 1.1293, accuracy: 94.5475%, tar: 0.0213 \n",
      "l0: 0.020302, l1: 0.021854, l2: 0.029144, l3: 0.043127, l4: 0.072554, l5: 0.166572, l6: 0.356404\n",
      "\n",
      "[epoch: 366/400, batch: 640/1000, ite: 48581] train loss: 1.1292, accuracy: 94.7828%, tar: 0.0213 \n",
      "l0: 0.018933, l1: 0.020925, l2: 0.029835, l3: 0.046506, l4: 0.085183, l5: 0.180219, l6: 0.336428\n",
      "\n",
      "[epoch: 366/400, batch: 648/1000, ite: 48582] train loss: 1.1291, accuracy: 96.0273%, tar: 0.0213 \n",
      "l0: 0.019635, l1: 0.020378, l2: 0.027359, l3: 0.044732, l4: 0.086664, l5: 0.174658, l6: 0.330628\n",
      "\n",
      "[epoch: 366/400, batch: 656/1000, ite: 48583] train loss: 1.1289, accuracy: 95.3679%, tar: 0.0213 \n",
      "l0: 0.021156, l1: 0.021752, l2: 0.026183, l3: 0.038427, l4: 0.065711, l5: 0.127122, l6: 0.322971\n",
      "\n",
      "[epoch: 366/400, batch: 664/1000, ite: 48584] train loss: 1.1286, accuracy: 95.0372%, tar: 0.0213 \n",
      "l0: 0.021256, l1: 0.021944, l2: 0.030647, l3: 0.046981, l4: 0.080535, l5: 0.173198, l6: 0.386913\n",
      "\n",
      "[epoch: 366/400, batch: 672/1000, ite: 48585] train loss: 1.1286, accuracy: 95.1265%, tar: 0.0213 \n",
      "l0: 0.013957, l1: 0.015654, l2: 0.023224, l3: 0.045119, l4: 0.080537, l5: 0.172053, l6: 0.372850\n",
      "\n",
      "[epoch: 366/400, batch: 680/1000, ite: 48586] train loss: 1.1286, accuracy: 96.1755%, tar: 0.0213 \n",
      "l0: 0.020482, l1: 0.021798, l2: 0.031577, l3: 0.050951, l4: 0.118577, l5: 0.217155, l6: 0.400493\n",
      "\n",
      "[epoch: 366/400, batch: 688/1000, ite: 48587] train loss: 1.1288, accuracy: 94.6156%, tar: 0.0213 \n",
      "l0: 0.024302, l1: 0.025235, l2: 0.031607, l3: 0.046053, l4: 0.077019, l5: 0.124712, l6: 0.238815\n",
      "\n",
      "[epoch: 366/400, batch: 696/1000, ite: 48588] train loss: 1.1283, accuracy: 95.8514%, tar: 0.0213 \n",
      "l0: 0.022993, l1: 0.024536, l2: 0.031042, l3: 0.047439, l4: 0.088958, l5: 0.158504, l6: 0.330182\n",
      "\n",
      "[epoch: 366/400, batch: 704/1000, ite: 48589] train loss: 1.1281, accuracy: 95.0152%, tar: 0.0213 \n",
      "l0: 0.017538, l1: 0.018453, l2: 0.025466, l3: 0.040139, l4: 0.070787, l5: 0.169561, l6: 0.316094\n",
      "\n",
      "[epoch: 366/400, batch: 712/1000, ite: 48590] train loss: 1.1279, accuracy: 95.3934%, tar: 0.0213 \n",
      "l0: 0.018862, l1: 0.020285, l2: 0.031013, l3: 0.050409, l4: 0.093325, l5: 0.169856, l6: 0.344425\n",
      "\n",
      "[epoch: 366/400, batch: 720/1000, ite: 48591] train loss: 1.1278, accuracy: 95.8079%, tar: 0.0213 \n",
      "l0: 0.023650, l1: 0.025501, l2: 0.031434, l3: 0.046037, l4: 0.078279, l5: 0.156045, l6: 0.320480\n",
      "\n",
      "[epoch: 366/400, batch: 728/1000, ite: 48592] train loss: 1.1276, accuracy: 95.7443%, tar: 0.0213 \n",
      "l0: 0.022397, l1: 0.023872, l2: 0.032013, l3: 0.046833, l4: 0.084160, l5: 0.202669, l6: 0.481039\n",
      "\n",
      "[epoch: 366/400, batch: 736/1000, ite: 48593] train loss: 1.1280, accuracy: 93.8953%, tar: 0.0213 \n",
      "l0: 0.020504, l1: 0.021819, l2: 0.029980, l3: 0.048035, l4: 0.098751, l5: 0.203513, l6: 0.419316\n",
      "\n",
      "[epoch: 366/400, batch: 744/1000, ite: 48594] train loss: 1.1282, accuracy: 94.5099%, tar: 0.0213 \n",
      "l0: 0.016513, l1: 0.017854, l2: 0.024939, l3: 0.041013, l4: 0.077189, l5: 0.136469, l6: 0.323316\n",
      "\n",
      "[epoch: 366/400, batch: 752/1000, ite: 48595] train loss: 1.1280, accuracy: 95.7575%, tar: 0.0213 \n",
      "l0: 0.024839, l1: 0.026462, l2: 0.035778, l3: 0.054035, l4: 0.108541, l5: 0.221839, l6: 0.465306\n",
      "\n",
      "[epoch: 366/400, batch: 760/1000, ite: 48596] train loss: 1.1284, accuracy: 93.6213%, tar: 0.0213 \n",
      "l0: 0.015616, l1: 0.016336, l2: 0.021225, l3: 0.032695, l4: 0.062572, l5: 0.134000, l6: 0.257093\n",
      "\n",
      "[epoch: 366/400, batch: 768/1000, ite: 48597] train loss: 1.1279, accuracy: 96.5611%, tar: 0.0213 \n",
      "l0: 0.019202, l1: 0.020405, l2: 0.030509, l3: 0.046973, l4: 0.089459, l5: 0.173584, l6: 0.332406\n",
      "\n",
      "[epoch: 366/400, batch: 776/1000, ite: 48598] train loss: 1.1277, accuracy: 95.4194%, tar: 0.0213 \n",
      "l0: 0.016629, l1: 0.017385, l2: 0.024126, l3: 0.034030, l4: 0.060339, l5: 0.109715, l6: 0.261268\n",
      "\n",
      "[epoch: 366/400, batch: 784/1000, ite: 48599] train loss: 1.1272, accuracy: 96.0880%, tar: 0.0213 \n",
      "l0: 0.019756, l1: 0.021154, l2: 0.028907, l3: 0.047332, l4: 0.091118, l5: 0.173782, l6: 0.346155\n",
      "\n",
      "[epoch: 366/400, batch: 792/1000, ite: 48600] train loss: 1.1271, accuracy: 95.8330%, tar: 0.0213 \n",
      "l0: 0.020953, l1: 0.022016, l2: 0.030391, l3: 0.047519, l4: 0.084130, l5: 0.159248, l6: 0.319589\n",
      "\n",
      "[epoch: 366/400, batch: 800/1000, ite: 48601] train loss: 1.1269, accuracy: 95.1675%, tar: 0.0213 \n",
      "l0: 0.018843, l1: 0.019738, l2: 0.024853, l3: 0.035087, l4: 0.060660, l5: 0.121443, l6: 0.234182\n",
      "\n",
      "[epoch: 366/400, batch: 808/1000, ite: 48602] train loss: 1.1263, accuracy: 96.1720%, tar: 0.0213 \n",
      "l0: 0.018733, l1: 0.019328, l2: 0.025259, l3: 0.040451, l4: 0.075682, l5: 0.156889, l6: 0.317862\n",
      "\n",
      "[epoch: 366/400, batch: 816/1000, ite: 48603] train loss: 1.1260, accuracy: 95.0579%, tar: 0.0213 \n",
      "l0: 0.019844, l1: 0.021354, l2: 0.029315, l3: 0.043647, l4: 0.079078, l5: 0.175410, l6: 0.392905\n",
      "\n",
      "[epoch: 366/400, batch: 824/1000, ite: 48604] train loss: 1.1261, accuracy: 94.7914%, tar: 0.0213 \n",
      "l0: 0.021757, l1: 0.024141, l2: 0.033267, l3: 0.046610, l4: 0.086198, l5: 0.178630, l6: 0.398444\n",
      "\n",
      "[epoch: 366/400, batch: 832/1000, ite: 48605] train loss: 1.1262, accuracy: 95.0161%, tar: 0.0213 \n",
      "l0: 0.020487, l1: 0.021805, l2: 0.029881, l3: 0.046223, l4: 0.082245, l5: 0.165819, l6: 0.419272\n",
      "\n",
      "[epoch: 366/400, batch: 840/1000, ite: 48606] train loss: 1.1263, accuracy: 94.1693%, tar: 0.0213 \n",
      "l0: 0.023059, l1: 0.025073, l2: 0.032543, l3: 0.049035, l4: 0.090667, l5: 0.188691, l6: 0.369810\n",
      "\n",
      "[epoch: 366/400, batch: 848/1000, ite: 48607] train loss: 1.1264, accuracy: 95.2931%, tar: 0.0213 \n",
      "l0: 0.023440, l1: 0.024784, l2: 0.033082, l3: 0.051845, l4: 0.098210, l5: 0.213378, l6: 0.440373\n",
      "\n",
      "[epoch: 366/400, batch: 856/1000, ite: 48608] train loss: 1.1267, accuracy: 94.3350%, tar: 0.0213 \n",
      "l0: 0.014575, l1: 0.015574, l2: 0.021467, l3: 0.036784, l4: 0.076464, l5: 0.157812, l6: 0.316474\n",
      "\n",
      "[epoch: 366/400, batch: 864/1000, ite: 48609] train loss: 1.1264, accuracy: 95.7885%, tar: 0.0213 \n",
      "l0: 0.025962, l1: 0.027375, l2: 0.037218, l3: 0.056229, l4: 0.102059, l5: 0.196267, l6: 0.450796\n",
      "\n",
      "[epoch: 366/400, batch: 872/1000, ite: 48610] train loss: 1.1268, accuracy: 93.8578%, tar: 0.0213 \n",
      "l0: 0.027316, l1: 0.029162, l2: 0.038639, l3: 0.053754, l4: 0.104725, l5: 0.206767, l6: 0.409745\n",
      "\n",
      "[epoch: 366/400, batch: 880/1000, ite: 48611] train loss: 1.1270, accuracy: 94.5616%, tar: 0.0213 \n",
      "l0: 0.017374, l1: 0.018173, l2: 0.023061, l3: 0.033457, l4: 0.056947, l5: 0.112549, l6: 0.287870\n",
      "\n",
      "[epoch: 366/400, batch: 888/1000, ite: 48612] train loss: 1.1266, accuracy: 95.7166%, tar: 0.0213 \n",
      "l0: 0.015884, l1: 0.016883, l2: 0.021644, l3: 0.033828, l4: 0.072992, l5: 0.184873, l6: 0.330426\n",
      "\n",
      "[epoch: 366/400, batch: 896/1000, ite: 48613] train loss: 1.1264, accuracy: 94.9815%, tar: 0.0213 \n",
      "l0: 0.023038, l1: 0.024203, l2: 0.032277, l3: 0.047404, l4: 0.083565, l5: 0.178749, l6: 0.377737\n",
      "\n",
      "[epoch: 366/400, batch: 904/1000, ite: 48614] train loss: 1.1264, accuracy: 94.3263%, tar: 0.0213 \n",
      "l0: 0.019970, l1: 0.021895, l2: 0.031777, l3: 0.048939, l4: 0.085691, l5: 0.166798, l6: 0.371860\n",
      "\n",
      "[epoch: 366/400, batch: 912/1000, ite: 48615] train loss: 1.1264, accuracy: 95.2648%, tar: 0.0213 \n",
      "l0: 0.015566, l1: 0.016483, l2: 0.020926, l3: 0.037554, l4: 0.079991, l5: 0.138925, l6: 0.259026\n",
      "\n",
      "[epoch: 366/400, batch: 920/1000, ite: 48616] train loss: 1.1260, accuracy: 96.4598%, tar: 0.0213 \n",
      "l0: 0.015525, l1: 0.016607, l2: 0.022442, l3: 0.033397, l4: 0.057404, l5: 0.097309, l6: 0.227921\n",
      "\n",
      "[epoch: 366/400, batch: 928/1000, ite: 48617] train loss: 1.1253, accuracy: 96.7016%, tar: 0.0213 \n",
      "l0: 0.024289, l1: 0.025457, l2: 0.034713, l3: 0.050217, l4: 0.081621, l5: 0.181976, l6: 0.350107\n",
      "\n",
      "[epoch: 366/400, batch: 936/1000, ite: 48618] train loss: 1.1252, accuracy: 95.0843%, tar: 0.0213 \n",
      "l0: 0.014621, l1: 0.016146, l2: 0.022665, l3: 0.032438, l4: 0.060188, l5: 0.146026, l6: 0.328712\n",
      "\n",
      "[epoch: 366/400, batch: 944/1000, ite: 48619] train loss: 1.1250, accuracy: 96.1113%, tar: 0.0213 \n",
      "l0: 0.027305, l1: 0.028646, l2: 0.036558, l3: 0.050772, l4: 0.102640, l5: 0.227656, l6: 0.440093\n",
      "\n",
      "[epoch: 366/400, batch: 952/1000, ite: 48620] train loss: 1.1253, accuracy: 94.2873%, tar: 0.0213 \n",
      "l0: 0.016480, l1: 0.017174, l2: 0.023367, l3: 0.030853, l4: 0.049402, l5: 0.086319, l6: 0.190424\n",
      "\n",
      "[epoch: 366/400, batch: 960/1000, ite: 48621] train loss: 1.1245, accuracy: 97.0097%, tar: 0.0213 \n",
      "l0: 0.019250, l1: 0.020183, l2: 0.026393, l3: 0.039954, l4: 0.072399, l5: 0.155145, l6: 0.341678\n",
      "\n",
      "[epoch: 366/400, batch: 968/1000, ite: 48622] train loss: 1.1243, accuracy: 94.8152%, tar: 0.0213 \n",
      "l0: 0.019023, l1: 0.019651, l2: 0.025674, l3: 0.036726, l4: 0.064735, l5: 0.131866, l6: 0.283042\n",
      "\n",
      "[epoch: 366/400, batch: 976/1000, ite: 48623] train loss: 1.1239, accuracy: 95.9225%, tar: 0.0212 \n",
      "l0: 0.023318, l1: 0.024599, l2: 0.033870, l3: 0.050324, l4: 0.091896, l5: 0.194893, l6: 0.406891\n",
      "\n",
      "[epoch: 366/400, batch: 984/1000, ite: 48624] train loss: 1.1241, accuracy: 94.5371%, tar: 0.0213 \n",
      "l0: 0.018556, l1: 0.019624, l2: 0.027802, l3: 0.041886, l4: 0.071243, l5: 0.153530, l6: 0.379049\n",
      "\n",
      "[epoch: 366/400, batch: 992/1000, ite: 48625] train loss: 1.1241, accuracy: 94.9157%, tar: 0.0212 \n",
      "l0: 0.023302, l1: 0.026241, l2: 0.038182, l3: 0.065506, l4: 0.116304, l5: 0.220234, l6: 0.422945\n",
      "\n",
      "[epoch: 366/400, batch: 1000/1000, ite: 48626] train loss: 1.1244, accuracy: 95.2115%, tar: 0.0212 \n",
      "l0: 0.027672, l1: 0.029089, l2: 0.038597, l3: 0.055944, l4: 0.103888, l5: 0.220701, l6: 0.460625\n",
      "\n",
      "[epoch: 367/400, batch: 8/1000, ite: 48627] train loss: 1.1248, accuracy: 93.2094%, tar: 0.0213 \n",
      "l0: 0.021084, l1: 0.022404, l2: 0.030668, l3: 0.046084, l4: 0.089119, l5: 0.241848, l6: 0.470726\n",
      "\n",
      "[epoch: 367/400, batch: 16/1000, ite: 48628] train loss: 1.1253, accuracy: 94.2338%, tar: 0.0213 \n",
      "l0: 0.015405, l1: 0.016420, l2: 0.023196, l3: 0.032738, l4: 0.054286, l5: 0.101739, l6: 0.234007\n",
      "\n",
      "[epoch: 367/400, batch: 24/1000, ite: 48629] train loss: 1.1246, accuracy: 96.4037%, tar: 0.0212 \n",
      "l0: 0.015645, l1: 0.016869, l2: 0.025257, l3: 0.041978, l4: 0.082997, l5: 0.162469, l6: 0.417959\n",
      "\n",
      "[epoch: 367/400, batch: 32/1000, ite: 48630] train loss: 1.1247, accuracy: 95.4869%, tar: 0.0212 \n",
      "l0: 0.018037, l1: 0.019180, l2: 0.025790, l3: 0.038245, l4: 0.069116, l5: 0.134967, l6: 0.320352\n",
      "\n",
      "[epoch: 367/400, batch: 40/1000, ite: 48631] train loss: 1.1244, accuracy: 95.6725%, tar: 0.0212 \n",
      "l0: 0.021068, l1: 0.022430, l2: 0.031479, l3: 0.046972, l4: 0.082886, l5: 0.193112, l6: 0.441409\n",
      "\n",
      "[epoch: 367/400, batch: 48/1000, ite: 48632] train loss: 1.1247, accuracy: 94.6176%, tar: 0.0212 \n",
      "l0: 0.019489, l1: 0.020633, l2: 0.029355, l3: 0.044701, l4: 0.082294, l5: 0.170048, l6: 0.327294\n",
      "\n",
      "[epoch: 367/400, batch: 56/1000, ite: 48633] train loss: 1.1245, accuracy: 95.3136%, tar: 0.0212 \n",
      "l0: 0.019027, l1: 0.020273, l2: 0.029496, l3: 0.050865, l4: 0.087156, l5: 0.175858, l6: 0.352623\n",
      "\n",
      "[epoch: 367/400, batch: 64/1000, ite: 48634] train loss: 1.1245, accuracy: 95.3048%, tar: 0.0212 \n",
      "l0: 0.019846, l1: 0.021077, l2: 0.028708, l3: 0.044708, l4: 0.085584, l5: 0.172881, l6: 0.428065\n",
      "\n",
      "[epoch: 367/400, batch: 72/1000, ite: 48635] train loss: 1.1246, accuracy: 94.4760%, tar: 0.0212 \n",
      "l0: 0.014300, l1: 0.015538, l2: 0.024691, l3: 0.037340, l4: 0.058964, l5: 0.128716, l6: 0.250950\n",
      "\n",
      "[epoch: 367/400, batch: 80/1000, ite: 48636] train loss: 1.1241, accuracy: 96.9755%, tar: 0.0212 \n",
      "l0: 0.026349, l1: 0.028093, l2: 0.039791, l3: 0.058142, l4: 0.118930, l5: 0.227921, l6: 0.476044\n",
      "\n",
      "[epoch: 367/400, batch: 88/1000, ite: 48637] train loss: 1.1246, accuracy: 94.0211%, tar: 0.0212 \n",
      "l0: 0.023322, l1: 0.025336, l2: 0.035290, l3: 0.054509, l4: 0.097890, l5: 0.185496, l6: 0.344313\n",
      "\n",
      "[epoch: 367/400, batch: 96/1000, ite: 48638] train loss: 1.1246, accuracy: 96.0152%, tar: 0.0212 \n",
      "l0: 0.020117, l1: 0.021242, l2: 0.028169, l3: 0.040711, l4: 0.076735, l5: 0.142909, l6: 0.311969\n",
      "\n",
      "[epoch: 367/400, batch: 104/1000, ite: 48639] train loss: 1.1243, accuracy: 95.6084%, tar: 0.0212 \n",
      "l0: 0.021411, l1: 0.022176, l2: 0.029341, l3: 0.045534, l4: 0.087230, l5: 0.198481, l6: 0.416744\n",
      "\n",
      "[epoch: 367/400, batch: 112/1000, ite: 48640] train loss: 1.1245, accuracy: 94.2611%, tar: 0.0212 \n",
      "l0: 0.025972, l1: 0.028374, l2: 0.039212, l3: 0.060380, l4: 0.114524, l5: 0.214554, l6: 0.401643\n",
      "\n",
      "[epoch: 367/400, batch: 120/1000, ite: 48641] train loss: 1.1248, accuracy: 94.7510%, tar: 0.0212 \n",
      "[epoch: 367/400, batch: 136/1000, ite: 48643] train loss: 1.1248, accuracy: 95.1882%, tar: 0.0212 \n",
      "l0: 0.020781, l1: 0.021854, l2: 0.029844, l3: 0.041570, l4: 0.070636, l5: 0.135263, l6: 0.267473\n",
      "\n",
      "[epoch: 367/400, batch: 144/1000, ite: 48644] train loss: 1.1244, accuracy: 95.7577%, tar: 0.0212 \n",
      "l0: 0.022038, l1: 0.023975, l2: 0.031701, l3: 0.046073, l4: 0.082144, l5: 0.192197, l6: 0.368735\n",
      "\n",
      "[epoch: 367/400, batch: 152/1000, ite: 48645] train loss: 1.1244, accuracy: 94.9458%, tar: 0.0212 \n",
      "l0: 0.023164, l1: 0.024628, l2: 0.033416, l3: 0.053231, l4: 0.100212, l5: 0.227335, l6: 0.528964\n",
      "\n",
      "[epoch: 367/400, batch: 160/1000, ite: 48646] train loss: 1.1250, accuracy: 93.1390%, tar: 0.0212 \n",
      "l0: 0.022339, l1: 0.023973, l2: 0.033452, l3: 0.051521, l4: 0.093868, l5: 0.181339, l6: 0.379502\n",
      "\n",
      "[epoch: 367/400, batch: 168/1000, ite: 48647] train loss: 1.1251, accuracy: 94.8640%, tar: 0.0212 \n",
      "l0: 0.021985, l1: 0.023019, l2: 0.028201, l3: 0.039929, l4: 0.064906, l5: 0.145341, l6: 0.326681\n",
      "\n",
      "[epoch: 367/400, batch: 176/1000, ite: 48648] train loss: 1.1249, accuracy: 94.6928%, tar: 0.0212 \n",
      "l0: 0.014045, l1: 0.014669, l2: 0.019285, l3: 0.028405, l4: 0.053332, l5: 0.112623, l6: 0.261835\n",
      "\n",
      "[epoch: 367/400, batch: 184/1000, ite: 48649] train loss: 1.1243, accuracy: 96.1052%, tar: 0.0212 \n",
      "l0: 0.022277, l1: 0.023218, l2: 0.031527, l3: 0.048106, l4: 0.084494, l5: 0.164090, l6: 0.358624\n",
      "\n",
      "[epoch: 367/400, batch: 192/1000, ite: 48650] train loss: 1.1243, accuracy: 94.5648%, tar: 0.0212 \n",
      "l0: 0.016880, l1: 0.018508, l2: 0.027860, l3: 0.049921, l4: 0.109869, l5: 0.185345, l6: 0.368128\n",
      "\n",
      "[epoch: 367/400, batch: 200/1000, ite: 48651] train loss: 1.1243, accuracy: 95.3773%, tar: 0.0212 \n",
      "l0: 0.020473, l1: 0.021627, l2: 0.029616, l3: 0.045484, l4: 0.106607, l5: 0.227450, l6: 0.426752\n",
      "\n",
      "[epoch: 367/400, batch: 208/1000, ite: 48652] train loss: 1.1246, accuracy: 94.4460%, tar: 0.0212 \n",
      "l0: 0.018072, l1: 0.020539, l2: 0.031574, l3: 0.050375, l4: 0.095584, l5: 0.203770, l6: 0.387893\n",
      "\n",
      "[epoch: 367/400, batch: 216/1000, ite: 48653] train loss: 1.1247, accuracy: 95.4846%, tar: 0.0212 \n",
      "l0: 0.014280, l1: 0.015223, l2: 0.020443, l3: 0.030733, l4: 0.051174, l5: 0.099429, l6: 0.222258\n",
      "\n",
      "[epoch: 367/400, batch: 224/1000, ite: 48654] train loss: 1.1240, accuracy: 96.6772%, tar: 0.0212 \n",
      "l0: 0.028104, l1: 0.029742, l2: 0.038849, l3: 0.061988, l4: 0.119299, l5: 0.244396, l6: 0.522354\n",
      "\n",
      "[epoch: 367/400, batch: 232/1000, ite: 48655] train loss: 1.1247, accuracy: 92.9246%, tar: 0.0212 \n",
      "l0: 0.019077, l1: 0.020003, l2: 0.026435, l3: 0.037833, l4: 0.067113, l5: 0.136094, l6: 0.290734\n",
      "\n",
      "[epoch: 367/400, batch: 240/1000, ite: 48656] train loss: 1.1243, accuracy: 95.5793%, tar: 0.0212 \n",
      "l0: 0.020601, l1: 0.021896, l2: 0.030068, l3: 0.047645, l4: 0.082194, l5: 0.153782, l6: 0.278263\n",
      "\n",
      "[epoch: 367/400, batch: 248/1000, ite: 48657] train loss: 1.1240, accuracy: 95.7896%, tar: 0.0212 \n",
      "l0: 0.022650, l1: 0.023988, l2: 0.030463, l3: 0.044480, l4: 0.090062, l5: 0.177309, l6: 0.420974\n",
      "\n",
      "[epoch: 367/400, batch: 256/1000, ite: 48658] train loss: 1.1242, accuracy: 95.1477%, tar: 0.0212 \n",
      "l0: 0.024263, l1: 0.025131, l2: 0.032553, l3: 0.046705, l4: 0.083232, l5: 0.203953, l6: 0.447320\n",
      "\n",
      "[epoch: 367/400, batch: 264/1000, ite: 48659] train loss: 1.1245, accuracy: 93.4603%, tar: 0.0212 \n",
      "l0: 0.021088, l1: 0.022437, l2: 0.032076, l3: 0.047793, l4: 0.089525, l5: 0.196119, l6: 0.376327\n",
      "\n",
      "[epoch: 367/400, batch: 272/1000, ite: 48660] train loss: 1.1246, accuracy: 95.5038%, tar: 0.0212 \n",
      "l0: 0.019442, l1: 0.020660, l2: 0.026356, l3: 0.037391, l4: 0.066866, l5: 0.142447, l6: 0.336343\n",
      "\n",
      "[epoch: 367/400, batch: 280/1000, ite: 48661] train loss: 1.1244, accuracy: 95.3368%, tar: 0.0212 \n",
      "l0: 0.018324, l1: 0.020215, l2: 0.027297, l3: 0.043297, l4: 0.085476, l5: 0.170378, l6: 0.368858\n",
      "\n",
      "[epoch: 367/400, batch: 288/1000, ite: 48662] train loss: 1.1243, accuracy: 95.2166%, tar: 0.0212 \n",
      "l0: 0.021113, l1: 0.022581, l2: 0.030280, l3: 0.042629, l4: 0.070152, l5: 0.154813, l6: 0.332989\n",
      "\n",
      "[epoch: 367/400, batch: 296/1000, ite: 48663] train loss: 1.1241, accuracy: 95.7199%, tar: 0.0212 \n",
      "l0: 0.021880, l1: 0.022912, l2: 0.031174, l3: 0.048005, l4: 0.091322, l5: 0.203526, l6: 0.413897\n",
      "\n",
      "[epoch: 367/400, batch: 304/1000, ite: 48664] train loss: 1.1243, accuracy: 94.4012%, tar: 0.0212 \n",
      "l0: 0.024397, l1: 0.025886, l2: 0.034474, l3: 0.051659, l4: 0.087511, l5: 0.172106, l6: 0.420139\n",
      "\n",
      "[epoch: 367/400, batch: 312/1000, ite: 48665] train loss: 1.1245, accuracy: 94.0316%, tar: 0.0212 \n",
      "l0: 0.019807, l1: 0.021285, l2: 0.029767, l3: 0.053137, l4: 0.115859, l5: 0.242964, l6: 0.426845\n",
      "\n",
      "[epoch: 367/400, batch: 320/1000, ite: 48666] train loss: 1.1248, accuracy: 94.3266%, tar: 0.0212 \n",
      "l0: 0.019591, l1: 0.021353, l2: 0.027437, l3: 0.043596, l4: 0.075092, l5: 0.166995, l6: 0.344264\n",
      "\n",
      "[epoch: 367/400, batch: 328/1000, ite: 48667] train loss: 1.1247, accuracy: 95.9000%, tar: 0.0212 \n",
      "l0: 0.026520, l1: 0.028536, l2: 0.039185, l3: 0.060916, l4: 0.137781, l5: 0.287861, l6: 0.511712\n",
      "\n",
      "[epoch: 367/400, batch: 336/1000, ite: 48668] train loss: 1.1254, accuracy: 92.7710%, tar: 0.0212 \n",
      "l0: 0.017836, l1: 0.018799, l2: 0.025952, l3: 0.038313, l4: 0.063336, l5: 0.124726, l6: 0.271252\n",
      "\n",
      "[epoch: 367/400, batch: 344/1000, ite: 48669] train loss: 1.1250, accuracy: 96.0141%, tar: 0.0212 \n",
      "l0: 0.019165, l1: 0.020607, l2: 0.029491, l3: 0.045996, l4: 0.087924, l5: 0.185293, l6: 0.378053\n",
      "\n",
      "[epoch: 367/400, batch: 352/1000, ite: 48670] train loss: 1.1250, accuracy: 94.5863%, tar: 0.0212 \n",
      "l0: 0.024148, l1: 0.026182, l2: 0.037047, l3: 0.062874, l4: 0.137286, l5: 0.282856, l6: 0.512046\n",
      "\n",
      "[epoch: 367/400, batch: 360/1000, ite: 48671] train loss: 1.1257, accuracy: 93.6478%, tar: 0.0212 \n",
      "l0: 0.021015, l1: 0.022165, l2: 0.029954, l3: 0.045858, l4: 0.083423, l5: 0.181915, l6: 0.391132\n",
      "\n",
      "[epoch: 367/400, batch: 368/1000, ite: 48672] train loss: 1.1258, accuracy: 94.6675%, tar: 0.0212 \n",
      "l0: 0.023002, l1: 0.025078, l2: 0.035606, l3: 0.055434, l4: 0.116251, l5: 0.269696, l6: 0.547125\n",
      "\n",
      "[epoch: 367/400, batch: 376/1000, ite: 48673] train loss: 1.1265, accuracy: 93.4293%, tar: 0.0212 \n",
      "l0: 0.019215, l1: 0.021191, l2: 0.031491, l3: 0.051718, l4: 0.093314, l5: 0.151738, l6: 0.352089\n",
      "\n",
      "[epoch: 367/400, batch: 384/1000, ite: 48674] train loss: 1.1265, accuracy: 95.8288%, tar: 0.0212 \n",
      "l0: 0.013717, l1: 0.014452, l2: 0.020261, l3: 0.031337, l4: 0.056102, l5: 0.107418, l6: 0.262418\n",
      "\n",
      "[epoch: 367/400, batch: 392/1000, ite: 48675] train loss: 1.1259, accuracy: 96.8341%, tar: 0.0212 \n",
      "l0: 0.025024, l1: 0.026801, l2: 0.035370, l3: 0.060569, l4: 0.132187, l5: 0.291740, l6: 0.510878\n",
      "\n",
      "[epoch: 367/400, batch: 400/1000, ite: 48676] train loss: 1.1266, accuracy: 94.1346%, tar: 0.0212 \n",
      "l0: 0.026056, l1: 0.026963, l2: 0.034500, l3: 0.047901, l4: 0.074872, l5: 0.132057, l6: 0.392730\n",
      "\n",
      "[epoch: 367/400, batch: 408/1000, ite: 48677] train loss: 1.1266, accuracy: 93.5779%, tar: 0.0212 \n",
      "l0: 0.014312, l1: 0.015521, l2: 0.022204, l3: 0.035282, l4: 0.071081, l5: 0.186538, l6: 0.318789\n",
      "\n",
      "[epoch: 367/400, batch: 416/1000, ite: 48678] train loss: 1.1264, accuracy: 95.0429%, tar: 0.0212 \n",
      "l0: 0.024093, l1: 0.025776, l2: 0.034332, l3: 0.052504, l4: 0.098651, l5: 0.201056, l6: 0.385211\n",
      "\n",
      "[epoch: 367/400, batch: 424/1000, ite: 48679] train loss: 1.1266, accuracy: 94.6408%, tar: 0.0212 \n",
      "l0: 0.021343, l1: 0.023094, l2: 0.031865, l3: 0.050667, l4: 0.105442, l5: 0.232417, l6: 0.405871\n",
      "\n",
      "[epoch: 367/400, batch: 432/1000, ite: 48680] train loss: 1.1268, accuracy: 94.6382%, tar: 0.0212 \n",
      "l0: 0.023068, l1: 0.023925, l2: 0.031736, l3: 0.046101, l4: 0.082715, l5: 0.153571, l6: 0.351110\n",
      "\n",
      "[epoch: 367/400, batch: 440/1000, ite: 48681] train loss: 1.1267, accuracy: 94.5368%, tar: 0.0212 \n",
      "l0: 0.020086, l1: 0.021864, l2: 0.029250, l3: 0.045981, l4: 0.087634, l5: 0.182221, l6: 0.340472\n",
      "\n",
      "[epoch: 367/400, batch: 448/1000, ite: 48682] train loss: 1.1266, accuracy: 94.7877%, tar: 0.0212 \n",
      "l0: 0.024185, l1: 0.026552, l2: 0.035358, l3: 0.054923, l4: 0.112004, l5: 0.196300, l6: 0.447734\n",
      "\n",
      "[epoch: 367/400, batch: 456/1000, ite: 48683] train loss: 1.1269, accuracy: 95.0987%, tar: 0.0212 \n",
      "l0: 0.018657, l1: 0.020197, l2: 0.027646, l3: 0.041849, l4: 0.088611, l5: 0.182818, l6: 0.333270\n",
      "\n",
      "[epoch: 367/400, batch: 464/1000, ite: 48684] train loss: 1.1268, accuracy: 95.8233%, tar: 0.0212 \n",
      "l0: 0.028022, l1: 0.030390, l2: 0.040305, l3: 0.061921, l4: 0.133534, l5: 0.309299, l6: 0.545294\n",
      "\n",
      "[epoch: 367/400, batch: 472/1000, ite: 48685] train loss: 1.1276, accuracy: 93.1331%, tar: 0.0212 \n",
      "l0: 0.024123, l1: 0.025512, l2: 0.032466, l3: 0.044783, l4: 0.079149, l5: 0.165140, l6: 0.412259\n",
      "\n",
      "[epoch: 367/400, batch: 480/1000, ite: 48686] train loss: 1.1277, accuracy: 94.5697%, tar: 0.0212 \n",
      "l0: 0.019426, l1: 0.020362, l2: 0.026813, l3: 0.035621, l4: 0.060103, l5: 0.120810, l6: 0.269151\n",
      "\n",
      "[epoch: 367/400, batch: 488/1000, ite: 48687] train loss: 1.1273, accuracy: 95.8868%, tar: 0.0212 \n",
      "l0: 0.020796, l1: 0.021922, l2: 0.029113, l3: 0.042753, l4: 0.083003, l5: 0.163732, l6: 0.339897\n",
      "\n",
      "[epoch: 367/400, batch: 496/1000, ite: 48688] train loss: 1.1272, accuracy: 95.2986%, tar: 0.0212 \n",
      "l0: 0.028320, l1: 0.029986, l2: 0.038079, l3: 0.057107, l4: 0.112447, l5: 0.229619, l6: 0.483152\n",
      "\n",
      "[epoch: 367/400, batch: 504/1000, ite: 48689] train loss: 1.1277, accuracy: 92.6256%, tar: 0.0212 \n",
      "l0: 0.021862, l1: 0.022887, l2: 0.031131, l3: 0.046092, l4: 0.085054, l5: 0.173800, l6: 0.359909\n",
      "\n",
      "[epoch: 367/400, batch: 512/1000, ite: 48690] train loss: 1.1276, accuracy: 95.1333%, tar: 0.0212 \n",
      "l0: 0.022690, l1: 0.023695, l2: 0.029738, l3: 0.041886, l4: 0.081411, l5: 0.186763, l6: 0.370507\n",
      "\n",
      "[epoch: 367/400, batch: 520/1000, ite: 48691] train loss: 1.1276, accuracy: 94.6014%, tar: 0.0212 \n",
      "l0: 0.018656, l1: 0.020312, l2: 0.028409, l3: 0.042863, l4: 0.086797, l5: 0.197482, l6: 0.365365\n",
      "\n",
      "[epoch: 367/400, batch: 528/1000, ite: 48692] train loss: 1.1276, accuracy: 95.3141%, tar: 0.0212 \n",
      "l0: 0.023922, l1: 0.024618, l2: 0.034005, l3: 0.051052, l4: 0.095655, l5: 0.213310, l6: 0.433592\n",
      "\n",
      "[epoch: 367/400, batch: 536/1000, ite: 48693] train loss: 1.1279, accuracy: 94.0453%, tar: 0.0212 \n",
      "l0: 0.022531, l1: 0.023953, l2: 0.031375, l3: 0.047006, l4: 0.089164, l5: 0.189831, l6: 0.411615\n",
      "\n",
      "[epoch: 367/400, batch: 544/1000, ite: 48694] train loss: 1.1281, accuracy: 94.4993%, tar: 0.0212 \n",
      "l0: 0.017763, l1: 0.019307, l2: 0.026308, l3: 0.040999, l4: 0.070602, l5: 0.138787, l6: 0.293832\n",
      "\n",
      "[epoch: 367/400, batch: 552/1000, ite: 48695] train loss: 1.1277, accuracy: 96.5676%, tar: 0.0212 \n",
      "l0: 0.017315, l1: 0.018532, l2: 0.026133, l3: 0.044535, l4: 0.103915, l5: 0.212838, l6: 0.384554\n",
      "\n",
      "[epoch: 367/400, batch: 560/1000, ite: 48696] train loss: 1.1278, accuracy: 95.0628%, tar: 0.0212 \n",
      "l0: 0.018804, l1: 0.020271, l2: 0.028506, l3: 0.044043, l4: 0.080607, l5: 0.162424, l6: 0.342729\n",
      "\n",
      "[epoch: 367/400, batch: 568/1000, ite: 48697] train loss: 1.1277, accuracy: 95.6134%, tar: 0.0212 \n",
      "l0: 0.020986, l1: 0.021789, l2: 0.029666, l3: 0.041251, l4: 0.065829, l5: 0.130012, l6: 0.271246\n",
      "\n",
      "[epoch: 367/400, batch: 576/1000, ite: 48698] train loss: 1.1273, accuracy: 95.8812%, tar: 0.0212 \n",
      "l0: 0.019416, l1: 0.020816, l2: 0.030244, l3: 0.048165, l4: 0.092997, l5: 0.196902, l6: 0.408919\n",
      "\n",
      "[epoch: 367/400, batch: 584/1000, ite: 48699] train loss: 1.1275, accuracy: 95.0906%, tar: 0.0212 \n",
      "l0: 0.018394, l1: 0.020474, l2: 0.028311, l3: 0.040838, l4: 0.072660, l5: 0.134294, l6: 0.248596\n",
      "\n",
      "[epoch: 367/400, batch: 592/1000, ite: 48700] train loss: 1.1270, accuracy: 96.7705%, tar: 0.0212 \n",
      "l0: 0.019233, l1: 0.020673, l2: 0.029361, l3: 0.049417, l4: 0.098275, l5: 0.184923, l6: 0.353931\n",
      "\n",
      "[epoch: 367/400, batch: 600/1000, ite: 48701] train loss: 1.1270, accuracy: 95.2538%, tar: 0.0212 \n",
      "l0: 0.016087, l1: 0.017829, l2: 0.028173, l3: 0.046866, l4: 0.086126, l5: 0.158606, l6: 0.316544\n",
      "\n",
      "[epoch: 367/400, batch: 608/1000, ite: 48702] train loss: 1.1268, accuracy: 96.1419%, tar: 0.0212 \n",
      "l0: 0.016977, l1: 0.018017, l2: 0.024056, l3: 0.036723, l4: 0.076001, l5: 0.141350, l6: 0.308156\n",
      "\n",
      "[epoch: 367/400, batch: 616/1000, ite: 48703] train loss: 1.1265, accuracy: 95.8060%, tar: 0.0212 \n",
      "l0: 0.018214, l1: 0.019871, l2: 0.028075, l3: 0.049904, l4: 0.107481, l5: 0.207245, l6: 0.482893\n",
      "\n",
      "[epoch: 367/400, batch: 624/1000, ite: 48704] train loss: 1.1269, accuracy: 95.2898%, tar: 0.0212 \n",
      "l0: 0.023401, l1: 0.024777, l2: 0.033466, l3: 0.049169, l4: 0.091972, l5: 0.205992, l6: 0.386409\n",
      "\n",
      "[epoch: 367/400, batch: 632/1000, ite: 48705] train loss: 1.1270, accuracy: 93.8749%, tar: 0.0212 \n",
      "l0: 0.025366, l1: 0.027138, l2: 0.037050, l3: 0.064004, l4: 0.123324, l5: 0.233440, l6: 0.487279\n",
      "\n",
      "[epoch: 367/400, batch: 640/1000, ite: 48706] train loss: 1.1275, accuracy: 93.9791%, tar: 0.0212 \n",
      "l0: 0.020161, l1: 0.020918, l2: 0.025860, l3: 0.034926, l4: 0.060900, l5: 0.138697, l6: 0.286616\n",
      "\n",
      "[epoch: 367/400, batch: 648/1000, ite: 48707] train loss: 1.1272, accuracy: 95.3265%, tar: 0.0212 \n",
      "l0: 0.018412, l1: 0.018963, l2: 0.023721, l3: 0.033117, l4: 0.052321, l5: 0.098941, l6: 0.240775\n",
      "\n",
      "[epoch: 367/400, batch: 656/1000, ite: 48708] train loss: 1.1266, accuracy: 95.8524%, tar: 0.0212 \n",
      "l0: 0.020848, l1: 0.022151, l2: 0.028017, l3: 0.040975, l4: 0.072047, l5: 0.146201, l6: 0.356349\n",
      "\n",
      "[epoch: 367/400, batch: 664/1000, ite: 48709] train loss: 1.1265, accuracy: 95.0010%, tar: 0.0212 \n",
      "l0: 0.015249, l1: 0.015846, l2: 0.021373, l3: 0.030162, l4: 0.049027, l5: 0.083555, l6: 0.225678\n",
      "\n",
      "[epoch: 367/400, batch: 672/1000, ite: 48710] train loss: 1.1259, accuracy: 96.6380%, tar: 0.0212 \n",
      "l0: 0.025922, l1: 0.026974, l2: 0.034425, l3: 0.051807, l4: 0.098545, l5: 0.231757, l6: 0.471242\n",
      "\n",
      "[epoch: 367/400, batch: 680/1000, ite: 48711] train loss: 1.1263, accuracy: 93.4165%, tar: 0.0212 \n",
      "l0: 0.017238, l1: 0.017942, l2: 0.022636, l3: 0.031852, l4: 0.052964, l5: 0.095273, l6: 0.272060\n",
      "\n",
      "[epoch: 367/400, batch: 688/1000, ite: 48712] train loss: 1.1258, accuracy: 95.8414%, tar: 0.0212 \n",
      "l0: 0.020105, l1: 0.021264, l2: 0.028562, l3: 0.043710, l4: 0.081654, l5: 0.155775, l6: 0.312762\n",
      "\n",
      "[epoch: 367/400, batch: 696/1000, ite: 48713] train loss: 1.1256, accuracy: 95.7467%, tar: 0.0212 \n",
      "l0: 0.021630, l1: 0.023436, l2: 0.033740, l3: 0.052416, l4: 0.099788, l5: 0.212696, l6: 0.431977\n",
      "\n",
      "[epoch: 367/400, batch: 704/1000, ite: 48714] train loss: 1.1258, accuracy: 94.9304%, tar: 0.0212 \n",
      "l0: 0.019112, l1: 0.020364, l2: 0.027677, l3: 0.043279, l4: 0.115461, l5: 0.172663, l6: 0.405991\n",
      "\n",
      "[epoch: 367/400, batch: 712/1000, ite: 48715] train loss: 1.1260, accuracy: 95.1350%, tar: 0.0212 \n",
      "l0: 0.024698, l1: 0.026547, l2: 0.036181, l3: 0.058887, l4: 0.112112, l5: 0.236962, l6: 0.518106\n",
      "\n",
      "[epoch: 367/400, batch: 720/1000, ite: 48716] train loss: 1.1265, accuracy: 93.8234%, tar: 0.0212 \n",
      "l0: 0.017436, l1: 0.018611, l2: 0.026904, l3: 0.044927, l4: 0.073437, l5: 0.136074, l6: 0.259175\n",
      "\n",
      "[epoch: 367/400, batch: 728/1000, ite: 48717] train loss: 1.1261, accuracy: 96.4157%, tar: 0.0212 \n",
      "l0: 0.021379, l1: 0.022891, l2: 0.033010, l3: 0.049328, l4: 0.085309, l5: 0.167540, l6: 0.333471\n",
      "\n",
      "[epoch: 367/400, batch: 736/1000, ite: 48718] train loss: 1.1260, accuracy: 95.1355%, tar: 0.0212 \n",
      "l0: 0.023009, l1: 0.024819, l2: 0.033367, l3: 0.053066, l4: 0.102578, l5: 0.208165, l6: 0.406730\n",
      "\n",
      "[epoch: 367/400, batch: 744/1000, ite: 48719] train loss: 1.1262, accuracy: 94.5877%, tar: 0.0212 \n",
      "l0: 0.019568, l1: 0.020578, l2: 0.027235, l3: 0.039387, l4: 0.070183, l5: 0.195188, l6: 0.392449\n",
      "\n",
      "[epoch: 367/400, batch: 752/1000, ite: 48720] train loss: 1.1263, accuracy: 94.9206%, tar: 0.0212 \n",
      "l0: 0.014302, l1: 0.014862, l2: 0.020286, l3: 0.029140, l4: 0.049048, l5: 0.106837, l6: 0.248438\n",
      "\n",
      "[epoch: 367/400, batch: 760/1000, ite: 48721] train loss: 1.1257, accuracy: 96.3849%, tar: 0.0212 \n",
      "l0: 0.020939, l1: 0.022279, l2: 0.031932, l3: 0.048596, l4: 0.098739, l5: 0.233706, l6: 0.466691\n",
      "\n",
      "[epoch: 367/400, batch: 768/1000, ite: 48722] train loss: 1.1261, accuracy: 95.1418%, tar: 0.0212 \n",
      "l0: 0.022442, l1: 0.023412, l2: 0.030406, l3: 0.043898, l4: 0.075447, l5: 0.145326, l6: 0.343855\n",
      "\n",
      "[epoch: 367/400, batch: 776/1000, ite: 48723] train loss: 1.1260, accuracy: 94.9920%, tar: 0.0212 \n",
      "l0: 0.024657, l1: 0.025581, l2: 0.033676, l3: 0.050443, l4: 0.099699, l5: 0.269426, l6: 0.483338\n",
      "\n",
      "[epoch: 367/400, batch: 784/1000, ite: 48724] train loss: 1.1264, accuracy: 93.4146%, tar: 0.0212 \n",
      "l0: 0.022641, l1: 0.023774, l2: 0.029756, l3: 0.043126, l4: 0.074022, l5: 0.170744, l6: 0.341132\n",
      "\n",
      "[epoch: 367/400, batch: 792/1000, ite: 48725] train loss: 1.1263, accuracy: 95.2368%, tar: 0.0212 \n",
      "l0: 0.019359, l1: 0.020248, l2: 0.028482, l3: 0.041361, l4: 0.067263, l5: 0.126773, l6: 0.338762\n",
      "\n",
      "[epoch: 367/400, batch: 800/1000, ite: 48726] train loss: 1.1261, accuracy: 95.4624%, tar: 0.0212 \n",
      "l0: 0.021914, l1: 0.023472, l2: 0.032144, l3: 0.048010, l4: 0.075730, l5: 0.132848, l6: 0.355289\n",
      "\n",
      "[epoch: 367/400, batch: 808/1000, ite: 48727] train loss: 1.1260, accuracy: 95.1177%, tar: 0.0212 \n",
      "l0: 0.017984, l1: 0.018797, l2: 0.024784, l3: 0.039646, l4: 0.067163, l5: 0.135555, l6: 0.282917\n",
      "\n",
      "[epoch: 367/400, batch: 816/1000, ite: 48728] train loss: 1.1257, accuracy: 95.8587%, tar: 0.0212 \n",
      "l0: 0.026090, l1: 0.027257, l2: 0.036983, l3: 0.052984, l4: 0.086565, l5: 0.184140, l6: 0.399165\n",
      "\n",
      "[epoch: 367/400, batch: 824/1000, ite: 48729] train loss: 1.1258, accuracy: 94.7411%, tar: 0.0212 \n",
      "l0: 0.019265, l1: 0.020263, l2: 0.026410, l3: 0.038536, l4: 0.078194, l5: 0.173207, l6: 0.357986\n",
      "\n",
      "[epoch: 367/400, batch: 832/1000, ite: 48730] train loss: 1.1257, accuracy: 95.5192%, tar: 0.0212 \n",
      "l0: 0.033462, l1: 0.034569, l2: 0.046166, l3: 0.066038, l4: 0.112176, l5: 0.224158, l6: 0.435081\n",
      "\n",
      "[epoch: 367/400, batch: 840/1000, ite: 48731] train loss: 1.1261, accuracy: 93.3611%, tar: 0.0212 \n",
      "l0: 0.017905, l1: 0.018638, l2: 0.023916, l3: 0.033056, l4: 0.054167, l5: 0.098718, l6: 0.219294\n",
      "\n",
      "[epoch: 367/400, batch: 848/1000, ite: 48732] train loss: 1.1255, accuracy: 96.4296%, tar: 0.0212 \n",
      "l0: 0.026854, l1: 0.027761, l2: 0.035324, l3: 0.051678, l4: 0.093046, l5: 0.203116, l6: 0.407951\n",
      "\n",
      "[epoch: 367/400, batch: 856/1000, ite: 48733] train loss: 1.1257, accuracy: 94.0424%, tar: 0.0212 \n",
      "l0: 0.018639, l1: 0.019770, l2: 0.027490, l3: 0.039587, l4: 0.071411, l5: 0.167922, l6: 0.339073\n",
      "\n",
      "[epoch: 367/400, batch: 864/1000, ite: 48734] train loss: 1.1255, accuracy: 95.5634%, tar: 0.0212 \n",
      "l0: 0.017807, l1: 0.018658, l2: 0.025435, l3: 0.037594, l4: 0.070303, l5: 0.149225, l6: 0.372421\n",
      "\n",
      "[epoch: 367/400, batch: 872/1000, ite: 48735] train loss: 1.1255, accuracy: 95.2479%, tar: 0.0212 \n",
      "l0: 0.019044, l1: 0.020657, l2: 0.029178, l3: 0.043972, l4: 0.090310, l5: 0.192707, l6: 0.383529\n",
      "\n",
      "[epoch: 367/400, batch: 880/1000, ite: 48736] train loss: 1.1256, accuracy: 95.3887%, tar: 0.0212 \n",
      "l0: 0.021456, l1: 0.022377, l2: 0.028288, l3: 0.041135, l4: 0.079164, l5: 0.154811, l6: 0.299516\n",
      "\n",
      "[epoch: 367/400, batch: 888/1000, ite: 48737] train loss: 1.1253, accuracy: 94.8801%, tar: 0.0212 \n",
      "l0: 0.015543, l1: 0.016811, l2: 0.024715, l3: 0.036330, l4: 0.065985, l5: 0.137112, l6: 0.277125\n",
      "\n",
      "[epoch: 367/400, batch: 896/1000, ite: 48738] train loss: 1.1249, accuracy: 96.3242%, tar: 0.0212 \n",
      "l0: 0.017359, l1: 0.019320, l2: 0.028689, l3: 0.051109, l4: 0.105780, l5: 0.189078, l6: 0.338539\n",
      "\n",
      "[epoch: 367/400, batch: 904/1000, ite: 48739] train loss: 1.1249, accuracy: 96.0427%, tar: 0.0212 \n",
      "l0: 0.020817, l1: 0.022196, l2: 0.030508, l3: 0.046996, l4: 0.084924, l5: 0.169387, l6: 0.274148\n",
      "\n",
      "[epoch: 367/400, batch: 912/1000, ite: 48740] train loss: 1.1246, accuracy: 95.1695%, tar: 0.0212 \n",
      "l0: 0.021453, l1: 0.022836, l2: 0.033101, l3: 0.048102, l4: 0.096968, l5: 0.187142, l6: 0.358450\n",
      "\n",
      "[epoch: 367/400, batch: 920/1000, ite: 48741] train loss: 1.1246, accuracy: 95.8313%, tar: 0.0212 \n",
      "l0: 0.018542, l1: 0.019778, l2: 0.025339, l3: 0.037151, l4: 0.062848, l5: 0.129105, l6: 0.281902\n",
      "\n",
      "[epoch: 367/400, batch: 928/1000, ite: 48742] train loss: 1.1243, accuracy: 95.6219%, tar: 0.0212 \n",
      "l0: 0.020422, l1: 0.021241, l2: 0.026644, l3: 0.036753, l4: 0.069571, l5: 0.141241, l6: 0.298442\n",
      "\n",
      "[epoch: 367/400, batch: 936/1000, ite: 48743] train loss: 1.1240, accuracy: 95.3668%, tar: 0.0212 \n",
      "l0: 0.021870, l1: 0.023663, l2: 0.032025, l3: 0.045841, l4: 0.083344, l5: 0.163827, l6: 0.301278\n",
      "\n",
      "[epoch: 367/400, batch: 944/1000, ite: 48744] train loss: 1.1238, accuracy: 96.1120%, tar: 0.0212 \n",
      "l0: 0.027818, l1: 0.029257, l2: 0.038657, l3: 0.059507, l4: 0.111960, l5: 0.233519, l6: 0.530668\n",
      "\n",
      "[epoch: 367/400, batch: 952/1000, ite: 48745] train loss: 1.1244, accuracy: 92.7839%, tar: 0.0212 \n",
      "l0: 0.019689, l1: 0.020365, l2: 0.026760, l3: 0.038200, l4: 0.062347, l5: 0.115365, l6: 0.289550\n",
      "\n",
      "[epoch: 367/400, batch: 960/1000, ite: 48746] train loss: 1.1241, accuracy: 95.6737%, tar: 0.0212 \n",
      "l0: 0.019246, l1: 0.021387, l2: 0.030982, l3: 0.051687, l4: 0.101749, l5: 0.193725, l6: 0.327775\n",
      "\n",
      "[epoch: 367/400, batch: 968/1000, ite: 48747] train loss: 1.1240, accuracy: 95.6966%, tar: 0.0212 \n",
      "l0: 0.022415, l1: 0.023341, l2: 0.030216, l3: 0.044117, l4: 0.077764, l5: 0.205933, l6: 0.319244\n",
      "\n",
      "[epoch: 367/400, batch: 976/1000, ite: 48748] train loss: 1.1239, accuracy: 94.9574%, tar: 0.0212 \n",
      "l0: 0.025355, l1: 0.026463, l2: 0.035001, l3: 0.052177, l4: 0.089388, l5: 0.180393, l6: 0.305280\n",
      "\n",
      "[epoch: 367/400, batch: 984/1000, ite: 48749] train loss: 1.1238, accuracy: 94.9316%, tar: 0.0212 \n",
      "l0: 0.021927, l1: 0.022920, l2: 0.030543, l3: 0.049558, l4: 0.095522, l5: 0.187822, l6: 0.365088\n",
      "\n",
      "[epoch: 367/400, batch: 992/1000, ite: 48750] train loss: 1.1238, accuracy: 94.5432%, tar: 0.0212 \n",
      "l0: 0.019646, l1: 0.021085, l2: 0.030067, l3: 0.048291, l4: 0.096293, l5: 0.175215, l6: 0.345082\n",
      "\n",
      "[epoch: 367/400, batch: 1000/1000, ite: 48751] train loss: 1.1237, accuracy: 95.2961%, tar: 0.0212 \n",
      "l0: 0.020740, l1: 0.022394, l2: 0.031400, l3: 0.047500, l4: 0.093434, l5: 0.217033, l6: 0.389242\n",
      "\n",
      "[epoch: 368/400, batch: 8/1000, ite: 48752] train loss: 1.1239, accuracy: 94.4038%, tar: 0.0212 \n",
      "l0: 0.019867, l1: 0.021077, l2: 0.029204, l3: 0.041087, l4: 0.075237, l5: 0.158090, l6: 0.293562\n",
      "\n",
      "[epoch: 368/400, batch: 16/1000, ite: 48753] train loss: 1.1236, accuracy: 95.4895%, tar: 0.0212 \n",
      "l0: 0.021311, l1: 0.023386, l2: 0.032279, l3: 0.052699, l4: 0.115802, l5: 0.248942, l6: 0.454201\n",
      "\n",
      "[epoch: 368/400, batch: 24/1000, ite: 48754] train loss: 1.1240, accuracy: 94.5593%, tar: 0.0212 \n",
      "l0: 0.022211, l1: 0.023323, l2: 0.030473, l3: 0.044097, l4: 0.073348, l5: 0.171275, l6: 0.356747\n",
      "\n",
      "[epoch: 368/400, batch: 32/1000, ite: 48755] train loss: 1.1239, accuracy: 95.0426%, tar: 0.0212 \n",
      "l0: 0.024045, l1: 0.026948, l2: 0.038695, l3: 0.069508, l4: 0.157977, l5: 0.332962, l6: 0.618003\n",
      "\n",
      "[epoch: 368/400, batch: 40/1000, ite: 48756] train loss: 1.1249, accuracy: 92.8319%, tar: 0.0212 \n",
      "l0: 0.021250, l1: 0.023531, l2: 0.033073, l3: 0.051474, l4: 0.109041, l5: 0.244857, l6: 0.453994\n",
      "\n",
      "[epoch: 368/400, batch: 48/1000, ite: 48757] train loss: 1.1253, accuracy: 94.8363%, tar: 0.0212 \n",
      "l0: 0.016695, l1: 0.018414, l2: 0.026137, l3: 0.039740, l4: 0.081713, l5: 0.167518, l6: 0.338731\n",
      "\n",
      "[epoch: 368/400, batch: 56/1000, ite: 48758] train loss: 1.1252, accuracy: 96.0231%, tar: 0.0212 \n",
      "l0: 0.023446, l1: 0.025663, l2: 0.034921, l3: 0.056427, l4: 0.114537, l5: 0.219193, l6: 0.493742\n",
      "\n",
      "[epoch: 368/400, batch: 64/1000, ite: 48759] train loss: 1.1256, accuracy: 93.9989%, tar: 0.0212 \n",
      "l0: 0.021161, l1: 0.022536, l2: 0.030741, l3: 0.048396, l4: 0.103786, l5: 0.200318, l6: 0.399093\n",
      "\n",
      "[epoch: 368/400, batch: 72/1000, ite: 48760] train loss: 1.1257, accuracy: 94.9281%, tar: 0.0212 \n",
      "l0: 0.018444, l1: 0.019652, l2: 0.026010, l3: 0.039437, l4: 0.074498, l5: 0.156582, l6: 0.363555\n",
      "\n",
      "[epoch: 368/400, batch: 80/1000, ite: 48761] train loss: 1.1257, accuracy: 94.9868%, tar: 0.0212 \n",
      "l0: 0.014124, l1: 0.014869, l2: 0.020387, l3: 0.030692, l4: 0.054965, l5: 0.112355, l6: 0.236772\n",
      "\n",
      "[epoch: 368/400, batch: 88/1000, ite: 48762] train loss: 1.1251, accuracy: 96.7670%, tar: 0.0212 \n",
      "l0: 0.021895, l1: 0.023009, l2: 0.030485, l3: 0.046500, l4: 0.080237, l5: 0.142674, l6: 0.315662\n",
      "\n",
      "[epoch: 368/400, batch: 96/1000, ite: 48763] train loss: 1.1250, accuracy: 95.1649%, tar: 0.0212 \n",
      "l0: 0.015977, l1: 0.017112, l2: 0.023346, l3: 0.036025, l4: 0.070164, l5: 0.178774, l6: 0.316054\n",
      "\n",
      "[epoch: 368/400, batch: 104/1000, ite: 48764] train loss: 1.1248, accuracy: 95.8750%, tar: 0.0212 \n",
      "l0: 0.014036, l1: 0.016457, l2: 0.024761, l3: 0.047848, l4: 0.096384, l5: 0.156260, l6: 0.283485\n",
      "\n",
      "[epoch: 368/400, batch: 112/1000, ite: 48765] train loss: 1.1245, accuracy: 96.5673%, tar: 0.0212 \n",
      "l0: 0.021042, l1: 0.022667, l2: 0.031393, l3: 0.046537, l4: 0.085806, l5: 0.207541, l6: 0.437795\n",
      "\n",
      "[epoch: 368/400, batch: 120/1000, ite: 48766] train loss: 1.1247, accuracy: 93.8892%, tar: 0.0212 \n",
      "l0: 0.018486, l1: 0.018852, l2: 0.023168, l3: 0.031633, l4: 0.054684, l5: 0.114098, l6: 0.246405\n",
      "\n",
      "[epoch: 368/400, batch: 128/1000, ite: 48767] train loss: 1.1242, accuracy: 95.7727%, tar: 0.0212 \n",
      "l0: 0.017849, l1: 0.018667, l2: 0.024574, l3: 0.039942, l4: 0.074033, l5: 0.156233, l6: 0.331951\n",
      "\n",
      "[epoch: 368/400, batch: 136/1000, ite: 48768] train loss: 1.1241, accuracy: 94.7474%, tar: 0.0212 \n",
      "l0: 0.029151, l1: 0.031541, l2: 0.041710, l3: 0.064135, l4: 0.144202, l5: 0.348219, l6: 0.617087\n",
      "\n",
      "[epoch: 368/400, batch: 144/1000, ite: 48769] train loss: 1.1251, accuracy: 91.9167%, tar: 0.0212 \n",
      "l0: 0.021999, l1: 0.023595, l2: 0.031302, l3: 0.046547, l4: 0.083660, l5: 0.176713, l6: 0.336369\n",
      "\n",
      "[epoch: 368/400, batch: 152/1000, ite: 48770] train loss: 1.1250, accuracy: 95.3123%, tar: 0.0212 \n",
      "l0: 0.019255, l1: 0.020572, l2: 0.026879, l3: 0.046222, l4: 0.092020, l5: 0.161693, l6: 0.293026\n",
      "\n",
      "[epoch: 368/400, batch: 160/1000, ite: 48771] train loss: 1.1248, accuracy: 95.5487%, tar: 0.0212 \n",
      "l0: 0.016025, l1: 0.017468, l2: 0.024868, l3: 0.042694, l4: 0.086408, l5: 0.160298, l6: 0.311273\n",
      "\n",
      "[epoch: 368/400, batch: 168/1000, ite: 48772] train loss: 1.1246, accuracy: 95.9387%, tar: 0.0212 \n",
      "l0: 0.024196, l1: 0.025560, l2: 0.032820, l3: 0.046659, l4: 0.080806, l5: 0.158068, l6: 0.326713\n",
      "\n",
      "[epoch: 368/400, batch: 176/1000, ite: 48773] train loss: 1.1244, accuracy: 95.2991%, tar: 0.0212 \n",
      "l0: 0.020085, l1: 0.021631, l2: 0.030052, l3: 0.054064, l4: 0.099893, l5: 0.202372, l6: 0.367157\n",
      "\n",
      "[epoch: 368/400, batch: 184/1000, ite: 48774] train loss: 1.1245, accuracy: 95.3820%, tar: 0.0212 \n",
      "l0: 0.018228, l1: 0.019479, l2: 0.024841, l3: 0.034369, l4: 0.060517, l5: 0.142030, l6: 0.274954\n",
      "\n",
      "[epoch: 368/400, batch: 192/1000, ite: 48775] train loss: 1.1241, accuracy: 96.2340%, tar: 0.0212 \n",
      "l0: 0.022058, l1: 0.023098, l2: 0.032985, l3: 0.047630, l4: 0.081575, l5: 0.164963, l6: 0.349181\n",
      "\n",
      "[epoch: 368/400, batch: 200/1000, ite: 48776] train loss: 1.1241, accuracy: 94.4655%, tar: 0.0212 \n",
      "l0: 0.020790, l1: 0.021868, l2: 0.029724, l3: 0.043123, l4: 0.076946, l5: 0.165334, l6: 0.318569\n",
      "\n",
      "[epoch: 368/400, batch: 208/1000, ite: 48777] train loss: 1.1239, accuracy: 95.3788%, tar: 0.0212 \n",
      "l0: 0.015448, l1: 0.017289, l2: 0.024205, l3: 0.046650, l4: 0.094091, l5: 0.172917, l6: 0.324701\n",
      "\n",
      "[epoch: 368/400, batch: 216/1000, ite: 48778] train loss: 1.1238, accuracy: 96.1833%, tar: 0.0211 \n",
      "l0: 0.021068, l1: 0.022783, l2: 0.029803, l3: 0.044445, l4: 0.078046, l5: 0.153213, l6: 0.305173\n",
      "\n",
      "[epoch: 368/400, batch: 224/1000, ite: 48779] train loss: 1.1236, accuracy: 95.7833%, tar: 0.0211 \n",
      "l0: 0.027197, l1: 0.028331, l2: 0.036151, l3: 0.053856, l4: 0.093045, l5: 0.195715, l6: 0.517038\n",
      "\n",
      "[epoch: 368/400, batch: 232/1000, ite: 48780] train loss: 1.1240, accuracy: 92.8234%, tar: 0.0212 \n",
      "l0: 0.021255, l1: 0.022808, l2: 0.031322, l3: 0.051242, l4: 0.095823, l5: 0.204740, l6: 0.459230\n",
      "\n",
      "[epoch: 368/400, batch: 240/1000, ite: 48781] train loss: 1.1243, accuracy: 95.3803%, tar: 0.0212 \n",
      "l0: 0.019284, l1: 0.020595, l2: 0.028055, l3: 0.043031, l4: 0.072958, l5: 0.133368, l6: 0.310625\n",
      "\n",
      "[epoch: 368/400, batch: 248/1000, ite: 48782] train loss: 1.1241, accuracy: 95.5135%, tar: 0.0212 \n",
      "l0: 0.025869, l1: 0.027050, l2: 0.034309, l3: 0.048228, l4: 0.088190, l5: 0.171665, l6: 0.333535\n",
      "\n",
      "[epoch: 368/400, batch: 256/1000, ite: 48783] train loss: 1.1240, accuracy: 94.9141%, tar: 0.0212 \n",
      "l0: 0.017502, l1: 0.018205, l2: 0.024192, l3: 0.035576, l4: 0.063635, l5: 0.120014, l6: 0.291543\n",
      "\n",
      "[epoch: 368/400, batch: 264/1000, ite: 48784] train loss: 1.1237, accuracy: 95.8832%, tar: 0.0212 \n",
      "l0: 0.021573, l1: 0.022937, l2: 0.031353, l3: 0.047704, l4: 0.090251, l5: 0.168555, l6: 0.396154\n",
      "\n",
      "[epoch: 368/400, batch: 272/1000, ite: 48785] train loss: 1.1237, accuracy: 94.7815%, tar: 0.0212 \n",
      "l0: 0.025646, l1: 0.027466, l2: 0.035071, l3: 0.052025, l4: 0.088701, l5: 0.171013, l6: 0.350334\n",
      "\n",
      "[epoch: 368/400, batch: 280/1000, ite: 48786] train loss: 1.1237, accuracy: 95.6749%, tar: 0.0212 \n",
      "l0: 0.020102, l1: 0.021163, l2: 0.027527, l3: 0.037493, l4: 0.058421, l5: 0.114859, l6: 0.255074\n",
      "\n",
      "[epoch: 368/400, batch: 288/1000, ite: 48787] train loss: 1.1233, accuracy: 95.8786%, tar: 0.0212 \n",
      "l0: 0.025120, l1: 0.026993, l2: 0.036112, l3: 0.058773, l4: 0.114237, l5: 0.253026, l6: 0.516926\n",
      "\n",
      "[epoch: 368/400, batch: 296/1000, ite: 48788] train loss: 1.1238, accuracy: 93.7716%, tar: 0.0212 \n",
      "l0: 0.022942, l1: 0.024770, l2: 0.034760, l3: 0.057739, l4: 0.108803, l5: 0.221395, l6: 0.404455\n",
      "\n",
      "[epoch: 368/400, batch: 304/1000, ite: 48789] train loss: 1.1240, accuracy: 94.5036%, tar: 0.0212 \n",
      "l0: 0.025583, l1: 0.027241, l2: 0.037903, l3: 0.059349, l4: 0.131236, l5: 0.320416, l6: 0.567852\n",
      "\n",
      "[epoch: 368/400, batch: 312/1000, ite: 48790] train loss: 1.1248, accuracy: 92.2862%, tar: 0.0212 \n",
      "l0: 0.017984, l1: 0.019459, l2: 0.026751, l3: 0.042809, l4: 0.083996, l5: 0.158062, l6: 0.301680\n",
      "\n",
      "[epoch: 368/400, batch: 320/1000, ite: 48791] train loss: 1.1246, accuracy: 95.9868%, tar: 0.0212 \n",
      "l0: 0.023719, l1: 0.025014, l2: 0.035262, l3: 0.055531, l4: 0.115813, l5: 0.252656, l6: 0.463312\n",
      "\n",
      "[epoch: 368/400, batch: 328/1000, ite: 48792] train loss: 1.1250, accuracy: 94.4086%, tar: 0.0212 \n",
      "l0: 0.013264, l1: 0.014592, l2: 0.021028, l3: 0.036139, l4: 0.066840, l5: 0.141255, l6: 0.277543\n",
      "\n",
      "[epoch: 368/400, batch: 336/1000, ite: 48793] train loss: 1.1247, accuracy: 97.0852%, tar: 0.0212 \n",
      "l0: 0.021698, l1: 0.022973, l2: 0.031352, l3: 0.048372, l4: 0.089086, l5: 0.160439, l6: 0.326348\n",
      "\n",
      "[epoch: 368/400, batch: 344/1000, ite: 48794] train loss: 1.1245, accuracy: 95.3966%, tar: 0.0212 \n",
      "l0: 0.018675, l1: 0.019607, l2: 0.028277, l3: 0.047092, l4: 0.093269, l5: 0.184342, l6: 0.329663\n",
      "\n",
      "[epoch: 368/400, batch: 352/1000, ite: 48795] train loss: 1.1245, accuracy: 94.9340%, tar: 0.0212 \n",
      "l0: 0.019101, l1: 0.020164, l2: 0.026850, l3: 0.044256, l4: 0.089040, l5: 0.176945, l6: 0.364152\n",
      "\n",
      "[epoch: 368/400, batch: 360/1000, ite: 48796] train loss: 1.1244, accuracy: 94.2134%, tar: 0.0212 \n",
      "l0: 0.025524, l1: 0.027524, l2: 0.036403, l3: 0.051454, l4: 0.087368, l5: 0.159640, l6: 0.325667\n",
      "\n",
      "[epoch: 368/400, batch: 368/1000, ite: 48797] train loss: 1.1243, accuracy: 94.7476%, tar: 0.0212 \n",
      "l0: 0.022999, l1: 0.024577, l2: 0.033430, l3: 0.048988, l4: 0.089661, l5: 0.179599, l6: 0.425906\n",
      "\n",
      "[epoch: 368/400, batch: 376/1000, ite: 48798] train loss: 1.1245, accuracy: 94.3896%, tar: 0.0212 \n",
      "l0: 0.029654, l1: 0.030848, l2: 0.040224, l3: 0.063482, l4: 0.125859, l5: 0.244775, l6: 0.424708\n",
      "\n",
      "[epoch: 368/400, batch: 384/1000, ite: 48799] train loss: 1.1248, accuracy: 94.0278%, tar: 0.0212 \n",
      "l0: 0.020394, l1: 0.021495, l2: 0.030914, l3: 0.047049, l4: 0.090422, l5: 0.191032, l6: 0.387800\n",
      "\n",
      "[epoch: 368/400, batch: 392/1000, ite: 48800] train loss: 1.1249, accuracy: 95.3295%, tar: 0.0212 \n",
      "l0: 0.019272, l1: 0.020321, l2: 0.027728, l3: 0.039697, l4: 0.065137, l5: 0.130803, l6: 0.281328\n",
      "\n",
      "[epoch: 368/400, batch: 400/1000, ite: 48801] train loss: 1.1246, accuracy: 95.6411%, tar: 0.0212 \n",
      "l0: 0.017671, l1: 0.019043, l2: 0.027500, l3: 0.044617, l4: 0.068161, l5: 0.129306, l6: 0.270589\n",
      "\n",
      "[epoch: 368/400, batch: 408/1000, ite: 48802] train loss: 1.1243, accuracy: 96.0935%, tar: 0.0212 \n",
      "l0: 0.017065, l1: 0.019122, l2: 0.028838, l3: 0.047439, l4: 0.099417, l5: 0.187574, l6: 0.311100\n",
      "\n",
      "[epoch: 368/400, batch: 416/1000, ite: 48803] train loss: 1.1241, accuracy: 96.4429%, tar: 0.0212 \n",
      "l0: 0.027198, l1: 0.029279, l2: 0.040554, l3: 0.066895, l4: 0.114539, l5: 0.225979, l6: 0.475076\n",
      "\n",
      "[epoch: 368/400, batch: 424/1000, ite: 48804] train loss: 1.1246, accuracy: 93.3415%, tar: 0.0212 \n",
      "l0: 0.017816, l1: 0.019742, l2: 0.029180, l3: 0.045574, l4: 0.085866, l5: 0.180434, l6: 0.336482\n",
      "\n",
      "[epoch: 368/400, batch: 432/1000, ite: 48805] train loss: 1.1245, accuracy: 95.6085%, tar: 0.0212 \n",
      "l0: 0.025075, l1: 0.026214, l2: 0.035129, l3: 0.057973, l4: 0.102167, l5: 0.234721, l6: 0.458859\n",
      "\n",
      "[epoch: 368/400, batch: 440/1000, ite: 48806] train loss: 1.1248, accuracy: 93.0530%, tar: 0.0212 \n",
      "l0: 0.022410, l1: 0.023659, l2: 0.030716, l3: 0.042400, l4: 0.071628, l5: 0.156231, l6: 0.349996\n",
      "\n",
      "[epoch: 368/400, batch: 448/1000, ite: 48807] train loss: 1.1247, accuracy: 94.6217%, tar: 0.0212 \n",
      "l0: 0.016583, l1: 0.017395, l2: 0.024264, l3: 0.034298, l4: 0.054979, l5: 0.098921, l6: 0.324398\n",
      "\n",
      "[epoch: 368/400, batch: 456/1000, ite: 48808] train loss: 1.1244, accuracy: 96.3087%, tar: 0.0212 \n",
      "l0: 0.023357, l1: 0.024920, l2: 0.033488, l3: 0.047713, l4: 0.080336, l5: 0.156695, l6: 0.411986\n",
      "\n",
      "[epoch: 368/400, batch: 464/1000, ite: 48809] train loss: 1.1245, accuracy: 94.5492%, tar: 0.0212 \n",
      "l0: 0.018003, l1: 0.019087, l2: 0.025824, l3: 0.037472, l4: 0.068699, l5: 0.156226, l6: 0.346805\n",
      "\n",
      "[epoch: 368/400, batch: 472/1000, ite: 48810] train loss: 1.1244, accuracy: 95.2783%, tar: 0.0212 \n",
      "l0: 0.015950, l1: 0.016728, l2: 0.021330, l3: 0.030699, l4: 0.055955, l5: 0.101996, l6: 0.205550\n",
      "\n",
      "[epoch: 368/400, batch: 480/1000, ite: 48811] train loss: 1.1238, accuracy: 96.2366%, tar: 0.0212 \n",
      "l0: 0.019966, l1: 0.021059, l2: 0.029321, l3: 0.045305, l4: 0.088114, l5: 0.188989, l6: 0.381097\n",
      "\n",
      "[epoch: 368/400, batch: 488/1000, ite: 48812] train loss: 1.1239, accuracy: 94.9208%, tar: 0.0212 \n",
      "l0: 0.018862, l1: 0.020081, l2: 0.027652, l3: 0.041251, l4: 0.070490, l5: 0.146671, l6: 0.303357\n",
      "\n",
      "[epoch: 368/400, batch: 496/1000, ite: 48813] train loss: 1.1237, accuracy: 95.3718%, tar: 0.0212 \n",
      "l0: 0.022990, l1: 0.024586, l2: 0.033677, l3: 0.049722, l4: 0.084919, l5: 0.168594, l6: 0.355978\n",
      "\n",
      "[epoch: 368/400, batch: 504/1000, ite: 48814] train loss: 1.1236, accuracy: 94.4703%, tar: 0.0212 \n",
      "l0: 0.019091, l1: 0.020257, l2: 0.026608, l3: 0.037815, l4: 0.067802, l5: 0.136188, l6: 0.301066\n",
      "\n",
      "[epoch: 368/400, batch: 512/1000, ite: 48815] train loss: 1.1234, accuracy: 95.7844%, tar: 0.0212 \n",
      "l0: 0.021319, l1: 0.022696, l2: 0.030491, l3: 0.047397, l4: 0.077224, l5: 0.152853, l6: 0.282987\n",
      "\n",
      "[epoch: 368/400, batch: 520/1000, ite: 48816] train loss: 1.1231, accuracy: 95.4554%, tar: 0.0212 \n",
      "l0: 0.022981, l1: 0.024022, l2: 0.032217, l3: 0.044830, l4: 0.079995, l5: 0.173158, l6: 0.320847\n",
      "\n",
      "[epoch: 368/400, batch: 528/1000, ite: 48817] train loss: 1.1230, accuracy: 94.9061%, tar: 0.0212 \n",
      "l0: 0.022625, l1: 0.023836, l2: 0.031252, l3: 0.049506, l4: 0.099907, l5: 0.188207, l6: 0.371626\n",
      "\n",
      "[epoch: 368/400, batch: 536/1000, ite: 48818] train loss: 1.1230, accuracy: 94.5259%, tar: 0.0212 \n",
      "l0: 0.017006, l1: 0.018025, l2: 0.024611, l3: 0.038342, l4: 0.061616, l5: 0.129056, l6: 0.321920\n",
      "\n",
      "[epoch: 368/400, batch: 544/1000, ite: 48819] train loss: 1.1228, accuracy: 95.7787%, tar: 0.0212 \n",
      "l0: 0.021681, l1: 0.023965, l2: 0.032525, l3: 0.051980, l4: 0.102280, l5: 0.240501, l6: 0.477161\n",
      "\n",
      "[epoch: 368/400, batch: 552/1000, ite: 48820] train loss: 1.1232, accuracy: 94.2378%, tar: 0.0212 \n",
      "l0: 0.025817, l1: 0.027572, l2: 0.038342, l3: 0.059307, l4: 0.105720, l5: 0.179981, l6: 0.316925\n",
      "\n",
      "[epoch: 368/400, batch: 560/1000, ite: 48821] train loss: 1.1231, accuracy: 95.2792%, tar: 0.0212 \n",
      "l0: 0.023987, l1: 0.025444, l2: 0.034469, l3: 0.054291, l4: 0.105153, l5: 0.202254, l6: 0.402614\n",
      "\n",
      "[epoch: 368/400, batch: 568/1000, ite: 48822] train loss: 1.1233, accuracy: 94.8156%, tar: 0.0212 \n",
      "l0: 0.020353, l1: 0.021434, l2: 0.031283, l3: 0.047043, l4: 0.080564, l5: 0.175712, l6: 0.363926\n",
      "\n",
      "[epoch: 368/400, batch: 576/1000, ite: 48823] train loss: 1.1233, accuracy: 95.3192%, tar: 0.0212 \n",
      "l0: 0.023044, l1: 0.024836, l2: 0.033338, l3: 0.050346, l4: 0.094210, l5: 0.203075, l6: 0.424760\n",
      "\n",
      "[epoch: 368/400, batch: 584/1000, ite: 48824] train loss: 1.1235, accuracy: 94.3829%, tar: 0.0212 \n",
      "l0: 0.024518, l1: 0.025678, l2: 0.033576, l3: 0.051207, l4: 0.113272, l5: 0.230474, l6: 0.400978\n",
      "\n",
      "[epoch: 368/400, batch: 592/1000, ite: 48825] train loss: 1.1237, accuracy: 94.7153%, tar: 0.0212 \n",
      "l0: 0.023048, l1: 0.024383, l2: 0.031046, l3: 0.042616, l4: 0.072818, l5: 0.123256, l6: 0.294924\n",
      "\n",
      "[epoch: 368/400, batch: 600/1000, ite: 48826] train loss: 1.1234, accuracy: 95.1152%, tar: 0.0212 \n",
      "l0: 0.026256, l1: 0.027904, l2: 0.037962, l3: 0.058350, l4: 0.097999, l5: 0.218656, l6: 0.518096\n",
      "\n",
      "[epoch: 368/400, batch: 608/1000, ite: 48827] train loss: 1.1239, accuracy: 92.8953%, tar: 0.0212 \n",
      "l0: 0.020776, l1: 0.022293, l2: 0.031881, l3: 0.045915, l4: 0.087116, l5: 0.171137, l6: 0.406323\n",
      "\n",
      "[epoch: 368/400, batch: 616/1000, ite: 48828] train loss: 1.1239, accuracy: 94.6797%, tar: 0.0212 \n",
      "l0: 0.018560, l1: 0.020065, l2: 0.025983, l3: 0.041511, l4: 0.077052, l5: 0.133297, l6: 0.272779\n",
      "\n",
      "[epoch: 368/400, batch: 624/1000, ite: 48829] train loss: 1.1236, accuracy: 95.8209%, tar: 0.0212 \n",
      "l0: 0.021891, l1: 0.023346, l2: 0.032529, l3: 0.047253, l4: 0.091295, l5: 0.232567, l6: 0.457603\n",
      "\n",
      "[epoch: 368/400, batch: 632/1000, ite: 48830] train loss: 1.1239, accuracy: 94.5745%, tar: 0.0212 \n",
      "l0: 0.021074, l1: 0.021782, l2: 0.029767, l3: 0.046523, l4: 0.079680, l5: 0.150255, l6: 0.307552\n",
      "\n",
      "[epoch: 368/400, batch: 640/1000, ite: 48831] train loss: 1.1237, accuracy: 95.5826%, tar: 0.0212 \n",
      "l0: 0.022382, l1: 0.023722, l2: 0.031585, l3: 0.046577, l4: 0.089648, l5: 0.202444, l6: 0.420228\n",
      "\n",
      "[epoch: 368/400, batch: 648/1000, ite: 48832] train loss: 1.1239, accuracy: 94.2398%, tar: 0.0212 \n",
      "l0: 0.021736, l1: 0.023005, l2: 0.030724, l3: 0.046425, l4: 0.086985, l5: 0.169240, l6: 0.342503\n",
      "\n",
      "[epoch: 368/400, batch: 656/1000, ite: 48833] train loss: 1.1238, accuracy: 94.9311%, tar: 0.0212 \n",
      "l0: 0.026440, l1: 0.027912, l2: 0.037344, l3: 0.050291, l4: 0.089771, l5: 0.212374, l6: 0.420864\n",
      "\n",
      "[epoch: 368/400, batch: 664/1000, ite: 48834] train loss: 1.1240, accuracy: 94.5843%, tar: 0.0212 \n",
      "l0: 0.026897, l1: 0.028523, l2: 0.039005, l3: 0.056376, l4: 0.094018, l5: 0.196089, l6: 0.391880\n",
      "\n",
      "[epoch: 368/400, batch: 672/1000, ite: 48835] train loss: 1.1241, accuracy: 94.7217%, tar: 0.0212 \n",
      "l0: 0.018821, l1: 0.019556, l2: 0.026409, l3: 0.039217, l4: 0.069340, l5: 0.157580, l6: 0.327145\n",
      "\n",
      "[epoch: 368/400, batch: 680/1000, ite: 48836] train loss: 1.1240, accuracy: 95.0920%, tar: 0.0212 \n",
      "l0: 0.023005, l1: 0.025445, l2: 0.036090, l3: 0.061510, l4: 0.132335, l5: 0.279478, l6: 0.554519\n",
      "\n",
      "[epoch: 368/400, batch: 688/1000, ite: 48837] train loss: 1.1246, accuracy: 94.3325%, tar: 0.0212 \n",
      "l0: 0.016216, l1: 0.017170, l2: 0.023675, l3: 0.033820, l4: 0.059010, l5: 0.116112, l6: 0.298170\n",
      "\n",
      "[epoch: 368/400, batch: 696/1000, ite: 48838] train loss: 1.1243, accuracy: 96.1074%, tar: 0.0212 \n",
      "l0: 0.020880, l1: 0.022941, l2: 0.032805, l3: 0.048986, l4: 0.101217, l5: 0.211620, l6: 0.379674\n",
      "\n",
      "[epoch: 368/400, batch: 704/1000, ite: 48839] train loss: 1.1244, accuracy: 95.6296%, tar: 0.0212 \n",
      "l0: 0.017642, l1: 0.018831, l2: 0.026280, l3: 0.041314, l4: 0.074084, l5: 0.152055, l6: 0.270114\n",
      "\n",
      "[epoch: 368/400, batch: 712/1000, ite: 48840] train loss: 1.1241, accuracy: 95.8815%, tar: 0.0212 \n",
      "l0: 0.020561, l1: 0.021600, l2: 0.029287, l3: 0.045412, l4: 0.083486, l5: 0.155692, l6: 0.316784\n",
      "\n",
      "[epoch: 368/400, batch: 720/1000, ite: 48841] train loss: 1.1239, accuracy: 95.3919%, tar: 0.0212 \n",
      "l0: 0.024533, l1: 0.025530, l2: 0.034745, l3: 0.051354, l4: 0.090124, l5: 0.203279, l6: 0.406538\n",
      "\n",
      "[epoch: 368/400, batch: 728/1000, ite: 48842] train loss: 1.1241, accuracy: 93.9878%, tar: 0.0212 \n",
      "l0: 0.018407, l1: 0.019893, l2: 0.027815, l3: 0.044032, l4: 0.086248, l5: 0.180195, l6: 0.404335\n",
      "\n",
      "[epoch: 368/400, batch: 736/1000, ite: 48843] train loss: 1.1242, accuracy: 94.8921%, tar: 0.0212 \n",
      "l0: 0.018797, l1: 0.019518, l2: 0.026263, l3: 0.039569, l4: 0.079569, l5: 0.178129, l6: 0.363253\n",
      "\n",
      "[epoch: 368/400, batch: 744/1000, ite: 48844] train loss: 1.1241, accuracy: 95.0697%, tar: 0.0212 \n",
      "l0: 0.019841, l1: 0.020731, l2: 0.030747, l3: 0.048213, l4: 0.084349, l5: 0.184725, l6: 0.353771\n",
      "\n",
      "[epoch: 368/400, batch: 752/1000, ite: 48845] train loss: 1.1241, accuracy: 95.2918%, tar: 0.0212 \n",
      "l0: 0.017880, l1: 0.018567, l2: 0.023698, l3: 0.034415, l4: 0.056373, l5: 0.111647, l6: 0.244159\n",
      "\n",
      "[epoch: 368/400, batch: 760/1000, ite: 48846] train loss: 1.1237, accuracy: 96.3797%, tar: 0.0212 \n",
      "l0: 0.024151, l1: 0.026248, l2: 0.035013, l3: 0.054586, l4: 0.107901, l5: 0.216182, l6: 0.460184\n",
      "\n",
      "[epoch: 368/400, batch: 768/1000, ite: 48847] train loss: 1.1240, accuracy: 94.0432%, tar: 0.0212 \n",
      "l0: 0.018481, l1: 0.019526, l2: 0.027230, l3: 0.039177, l4: 0.067892, l5: 0.151722, l6: 0.340569\n",
      "\n",
      "[epoch: 368/400, batch: 776/1000, ite: 48848] train loss: 1.1238, accuracy: 95.2555%, tar: 0.0212 \n",
      "l0: 0.017572, l1: 0.018978, l2: 0.026463, l3: 0.044307, l4: 0.099664, l5: 0.192453, l6: 0.367602\n",
      "\n",
      "[epoch: 368/400, batch: 784/1000, ite: 48849] train loss: 1.1238, accuracy: 95.5972%, tar: 0.0212 \n",
      "l0: 0.018663, l1: 0.019626, l2: 0.028403, l3: 0.041390, l4: 0.075872, l5: 0.167759, l6: 0.413628\n",
      "\n",
      "[epoch: 368/400, batch: 792/1000, ite: 48850] train loss: 1.1239, accuracy: 94.7678%, tar: 0.0212 \n",
      "l0: 0.020235, l1: 0.021067, l2: 0.026846, l3: 0.038906, l4: 0.063997, l5: 0.120842, l6: 0.297900\n",
      "\n",
      "[epoch: 368/400, batch: 800/1000, ite: 48851] train loss: 1.1236, accuracy: 95.6968%, tar: 0.0212 \n",
      "l0: 0.017282, l1: 0.018182, l2: 0.024297, l3: 0.036215, l4: 0.064148, l5: 0.126270, l6: 0.261978\n",
      "\n",
      "[epoch: 368/400, batch: 808/1000, ite: 48852] train loss: 1.1233, accuracy: 95.7463%, tar: 0.0212 \n",
      "l0: 0.022120, l1: 0.024125, l2: 0.034209, l3: 0.051646, l4: 0.095818, l5: 0.180192, l6: 0.400462\n",
      "\n",
      "[epoch: 368/400, batch: 816/1000, ite: 48853] train loss: 1.1234, accuracy: 95.1098%, tar: 0.0212 \n",
      "l0: 0.016150, l1: 0.017375, l2: 0.022297, l3: 0.034632, l4: 0.089518, l5: 0.162080, l6: 0.281852\n",
      "\n",
      "[epoch: 368/400, batch: 824/1000, ite: 48854] train loss: 1.1231, accuracy: 96.3526%, tar: 0.0212 \n",
      "l0: 0.023203, l1: 0.024090, l2: 0.032029, l3: 0.047259, l4: 0.088531, l5: 0.199763, l6: 0.377264\n",
      "\n",
      "[epoch: 368/400, batch: 832/1000, ite: 48855] train loss: 1.1232, accuracy: 94.7426%, tar: 0.0212 \n",
      "l0: 0.020315, l1: 0.021065, l2: 0.027636, l3: 0.040362, l4: 0.077305, l5: 0.146852, l6: 0.297917\n",
      "\n",
      "[epoch: 368/400, batch: 840/1000, ite: 48856] train loss: 1.1230, accuracy: 94.9804%, tar: 0.0212 \n",
      "l0: 0.018961, l1: 0.020418, l2: 0.027858, l3: 0.045571, l4: 0.081665, l5: 0.152817, l6: 0.336295\n",
      "\n",
      "[epoch: 368/400, batch: 848/1000, ite: 48857] train loss: 1.1228, accuracy: 95.8895%, tar: 0.0212 \n",
      "l0: 0.020939, l1: 0.023299, l2: 0.031828, l3: 0.048745, l4: 0.096196, l5: 0.190214, l6: 0.387036\n",
      "\n",
      "[epoch: 368/400, batch: 856/1000, ite: 48858] train loss: 1.1229, accuracy: 95.0216%, tar: 0.0212 \n",
      "l0: 0.019439, l1: 0.020640, l2: 0.029071, l3: 0.045004, l4: 0.080533, l5: 0.155106, l6: 0.360166\n",
      "\n",
      "[epoch: 368/400, batch: 864/1000, ite: 48859] train loss: 1.1229, accuracy: 94.6679%, tar: 0.0211 \n",
      "l0: 0.020575, l1: 0.021803, l2: 0.026322, l3: 0.036698, l4: 0.058330, l5: 0.114624, l6: 0.260090\n",
      "\n",
      "[epoch: 368/400, batch: 872/1000, ite: 48860] train loss: 1.1225, accuracy: 95.9125%, tar: 0.0211 \n",
      "l0: 0.018419, l1: 0.019226, l2: 0.026197, l3: 0.038678, l4: 0.080510, l5: 0.165478, l6: 0.366439\n",
      "\n",
      "[epoch: 368/400, batch: 880/1000, ite: 48861] train loss: 1.1225, accuracy: 95.0537%, tar: 0.0211 \n",
      "l0: 0.022517, l1: 0.023625, l2: 0.032783, l3: 0.050697, l4: 0.089114, l5: 0.182597, l6: 0.383155\n",
      "\n",
      "[epoch: 368/400, batch: 888/1000, ite: 48862] train loss: 1.1225, accuracy: 94.6038%, tar: 0.0211 \n",
      "l0: 0.017961, l1: 0.018857, l2: 0.024245, l3: 0.035352, l4: 0.059567, l5: 0.113672, l6: 0.226435\n",
      "\n",
      "[epoch: 368/400, batch: 896/1000, ite: 48863] train loss: 1.1220, accuracy: 96.8063%, tar: 0.0211 \n",
      "l0: 0.024738, l1: 0.026279, l2: 0.033742, l3: 0.048510, l4: 0.092434, l5: 0.191761, l6: 0.421880\n",
      "\n",
      "[epoch: 368/400, batch: 904/1000, ite: 48864] train loss: 1.1222, accuracy: 94.3649%, tar: 0.0211 \n",
      "l0: 0.020209, l1: 0.021136, l2: 0.027942, l3: 0.041158, l4: 0.074192, l5: 0.174004, l6: 0.408405\n",
      "\n",
      "[epoch: 368/400, batch: 912/1000, ite: 48865] train loss: 1.1223, accuracy: 94.5393%, tar: 0.0211 \n",
      "l0: 0.022735, l1: 0.023979, l2: 0.031625, l3: 0.046311, l4: 0.086527, l5: 0.202253, l6: 0.398200\n",
      "\n",
      "[epoch: 368/400, batch: 920/1000, ite: 48866] train loss: 1.1224, accuracy: 94.4303%, tar: 0.0211 \n",
      "l0: 0.017549, l1: 0.018949, l2: 0.025071, l3: 0.036723, l4: 0.069882, l5: 0.148448, l6: 0.298702\n",
      "\n",
      "[epoch: 368/400, batch: 928/1000, ite: 48867] train loss: 1.1221, accuracy: 96.2040%, tar: 0.0211 \n",
      "l0: 0.015879, l1: 0.017801, l2: 0.025386, l3: 0.041368, l4: 0.085530, l5: 0.203326, l6: 0.399065\n",
      "\n",
      "[epoch: 368/400, batch: 936/1000, ite: 48868] train loss: 1.1222, accuracy: 95.6216%, tar: 0.0211 \n",
      "l0: 0.020221, l1: 0.022337, l2: 0.030839, l3: 0.048421, l4: 0.095583, l5: 0.208721, l6: 0.457223\n",
      "\n",
      "[epoch: 368/400, batch: 944/1000, ite: 48869] train loss: 1.1225, accuracy: 94.3799%, tar: 0.0211 \n",
      "l0: 0.017524, l1: 0.018642, l2: 0.026040, l3: 0.042163, l4: 0.097186, l5: 0.196844, l6: 0.355255\n",
      "\n",
      "[epoch: 368/400, batch: 952/1000, ite: 48870] train loss: 1.1225, accuracy: 95.5125%, tar: 0.0211 \n",
      "l0: 0.022278, l1: 0.023190, l2: 0.029410, l3: 0.041839, l4: 0.070514, l5: 0.132695, l6: 0.344543\n",
      "\n",
      "[epoch: 368/400, batch: 960/1000, ite: 48871] train loss: 1.1223, accuracy: 94.7811%, tar: 0.0211 \n",
      "l0: 0.023578, l1: 0.024497, l2: 0.030397, l3: 0.042117, l4: 0.080424, l5: 0.176854, l6: 0.456582\n",
      "\n",
      "[epoch: 368/400, batch: 968/1000, ite: 48872] train loss: 1.1225, accuracy: 93.9245%, tar: 0.0211 \n",
      "l0: 0.016383, l1: 0.017750, l2: 0.026991, l3: 0.043317, l4: 0.086649, l5: 0.193849, l6: 0.410690\n",
      "\n",
      "[epoch: 368/400, batch: 976/1000, ite: 48873] train loss: 1.1226, accuracy: 95.4925%, tar: 0.0211 \n",
      "l0: 0.017100, l1: 0.018329, l2: 0.026168, l3: 0.039702, l4: 0.073939, l5: 0.155410, l6: 0.304564\n",
      "\n",
      "[epoch: 368/400, batch: 984/1000, ite: 48874] train loss: 1.1224, accuracy: 95.8665%, tar: 0.0211 \n",
      "l0: 0.016770, l1: 0.018102, l2: 0.024961, l3: 0.040747, l4: 0.091345, l5: 0.175748, l6: 0.318996\n",
      "\n",
      "[epoch: 368/400, batch: 992/1000, ite: 48875] train loss: 1.1223, accuracy: 95.6661%, tar: 0.0211 \n",
      "l0: 0.022420, l1: 0.023282, l2: 0.031581, l3: 0.044741, l4: 0.077325, l5: 0.169009, l6: 0.356283\n",
      "\n",
      "[epoch: 368/400, batch: 1000/1000, ite: 48876] train loss: 1.1223, accuracy: 94.5944%, tar: 0.0211 \n",
      "l0: 0.024631, l1: 0.026324, l2: 0.035570, l3: 0.050632, l4: 0.088812, l5: 0.206097, l6: 0.447357\n",
      "\n",
      "[epoch: 369/400, batch: 8/1000, ite: 48877] train loss: 1.1225, accuracy: 93.4745%, tar: 0.0211 \n",
      "l0: 0.020270, l1: 0.021767, l2: 0.029166, l3: 0.044396, l4: 0.083016, l5: 0.189632, l6: 0.422571\n",
      "\n",
      "[epoch: 369/400, batch: 16/1000, ite: 48878] train loss: 1.1226, accuracy: 94.8347%, tar: 0.0211 \n",
      "l0: 0.025812, l1: 0.028254, l2: 0.039266, l3: 0.063655, l4: 0.117471, l5: 0.201014, l6: 0.372153\n",
      "\n",
      "[epoch: 369/400, batch: 24/1000, ite: 48879] train loss: 1.1227, accuracy: 94.9820%, tar: 0.0211 \n",
      "l0: 0.020682, l1: 0.021957, l2: 0.029638, l3: 0.043111, l4: 0.080632, l5: 0.157871, l6: 0.336559\n",
      "\n",
      "[epoch: 369/400, batch: 32/1000, ite: 48880] train loss: 1.1226, accuracy: 95.0021%, tar: 0.0211 \n",
      "l0: 0.021685, l1: 0.022895, l2: 0.030702, l3: 0.044967, l4: 0.091534, l5: 0.182741, l6: 0.406820\n",
      "\n",
      "[epoch: 369/400, batch: 40/1000, ite: 48881] train loss: 1.1227, accuracy: 94.9141%, tar: 0.0211 \n",
      "l0: 0.016891, l1: 0.017633, l2: 0.021002, l3: 0.029828, l4: 0.047515, l5: 0.104556, l6: 0.236477\n",
      "\n",
      "[epoch: 369/400, batch: 48/1000, ite: 48882] train loss: 1.1223, accuracy: 96.1833%, tar: 0.0211 \n",
      "l0: 0.021131, l1: 0.022527, l2: 0.030662, l3: 0.049037, l4: 0.083880, l5: 0.160508, l6: 0.339926\n",
      "\n",
      "[epoch: 369/400, batch: 56/1000, ite: 48883] train loss: 1.1222, accuracy: 95.6517%, tar: 0.0211 \n",
      "l0: 0.029108, l1: 0.030617, l2: 0.040223, l3: 0.054877, l4: 0.093038, l5: 0.186123, l6: 0.470113\n",
      "\n",
      "[epoch: 369/400, batch: 64/1000, ite: 48884] train loss: 1.1225, accuracy: 93.7788%, tar: 0.0211 \n",
      "l0: 0.019796, l1: 0.020971, l2: 0.028478, l3: 0.043018, l4: 0.077283, l5: 0.166182, l6: 0.347025\n",
      "\n",
      "[epoch: 369/400, batch: 72/1000, ite: 48885] train loss: 1.1224, accuracy: 95.0320%, tar: 0.0211 \n",
      "l0: 0.016346, l1: 0.017230, l2: 0.024259, l3: 0.036776, l4: 0.067079, l5: 0.130483, l6: 0.309551\n",
      "\n",
      "[epoch: 369/400, batch: 80/1000, ite: 48886] train loss: 1.1222, accuracy: 95.9280%, tar: 0.0211 \n",
      "l0: 0.016063, l1: 0.017154, l2: 0.023535, l3: 0.042160, l4: 0.088887, l5: 0.158867, l6: 0.310074\n",
      "\n",
      "l0: 0.018747, l1: 0.019668, l2: 0.026869, l3: 0.041701, l4: 0.073273, l5: 0.131989, l6: 0.270611\n",
      "\n",
      "[epoch: 369/400, batch: 104/1000, ite: 48889] train loss: 1.1213, accuracy: 96.0589%, tar: 0.0211 \n",
      "l0: 0.013301, l1: 0.013975, l2: 0.019042, l3: 0.027949, l4: 0.048673, l5: 0.108224, l6: 0.235820\n",
      "\n",
      "[epoch: 369/400, batch: 112/1000, ite: 48890] train loss: 1.1208, accuracy: 96.7104%, tar: 0.0211 \n",
      "l0: 0.026685, l1: 0.027971, l2: 0.038336, l3: 0.055115, l4: 0.097664, l5: 0.223898, l6: 0.483762\n",
      "\n",
      "[epoch: 369/400, batch: 120/1000, ite: 48891] train loss: 1.1211, accuracy: 94.0317%, tar: 0.0211 \n",
      "l0: 0.019234, l1: 0.020058, l2: 0.028352, l3: 0.040860, l4: 0.071157, l5: 0.143834, l6: 0.306257\n",
      "\n",
      "[epoch: 369/400, batch: 128/1000, ite: 48892] train loss: 1.1209, accuracy: 96.0307%, tar: 0.0211 \n",
      "l0: 0.019069, l1: 0.019968, l2: 0.026861, l3: 0.043405, l4: 0.073661, l5: 0.150271, l6: 0.317632\n",
      "\n",
      "[epoch: 369/400, batch: 136/1000, ite: 48893] train loss: 1.1208, accuracy: 95.7597%, tar: 0.0211 \n",
      "l0: 0.023906, l1: 0.025399, l2: 0.034290, l3: 0.050535, l4: 0.100185, l5: 0.224269, l6: 0.446327\n",
      "\n",
      "[epoch: 369/400, batch: 144/1000, ite: 48894] train loss: 1.1210, accuracy: 93.9489%, tar: 0.0211 \n",
      "l0: 0.016284, l1: 0.017563, l2: 0.023444, l3: 0.039319, l4: 0.083591, l5: 0.168993, l6: 0.337077\n",
      "\n",
      "[epoch: 369/400, batch: 152/1000, ite: 48895] train loss: 1.1209, accuracy: 95.6344%, tar: 0.0211 \n",
      "l0: 0.018175, l1: 0.019410, l2: 0.026360, l3: 0.038153, l4: 0.067978, l5: 0.146241, l6: 0.296227\n",
      "\n",
      "[epoch: 369/400, batch: 160/1000, ite: 48896] train loss: 1.1207, accuracy: 95.4092%, tar: 0.0211 \n",
      "l0: 0.022498, l1: 0.024295, l2: 0.033767, l3: 0.050243, l4: 0.089892, l5: 0.193097, l6: 0.443292\n",
      "\n",
      "[epoch: 369/400, batch: 168/1000, ite: 48897] train loss: 1.1209, accuracy: 93.9822%, tar: 0.0211 \n",
      "l0: 0.026568, l1: 0.027917, l2: 0.036056, l3: 0.051993, l4: 0.107246, l5: 0.229978, l6: 0.494571\n",
      "\n",
      "[epoch: 369/400, batch: 176/1000, ite: 48898] train loss: 1.1213, accuracy: 93.2065%, tar: 0.0211 \n",
      "l0: 0.022829, l1: 0.024940, l2: 0.031915, l3: 0.048644, l4: 0.095942, l5: 0.212951, l6: 0.432215\n",
      "\n",
      "[epoch: 369/400, batch: 184/1000, ite: 48899] train loss: 1.1215, accuracy: 94.2148%, tar: 0.0211 \n",
      "l0: 0.015410, l1: 0.016624, l2: 0.021980, l3: 0.033910, l4: 0.078693, l5: 0.142183, l6: 0.279036\n",
      "\n",
      "[epoch: 369/400, batch: 192/1000, ite: 48900] train loss: 1.1212, accuracy: 96.7923%, tar: 0.0211 \n",
      "l0: 0.015840, l1: 0.017325, l2: 0.024978, l3: 0.038465, l4: 0.072176, l5: 0.136880, l6: 0.336026\n",
      "\n",
      "[epoch: 369/400, batch: 200/1000, ite: 48901] train loss: 1.1211, accuracy: 96.1545%, tar: 0.0211 \n",
      "l0: 0.023297, l1: 0.024700, l2: 0.031742, l3: 0.052351, l4: 0.090914, l5: 0.186550, l6: 0.410368\n",
      "\n",
      "[epoch: 369/400, batch: 208/1000, ite: 48902] train loss: 1.1212, accuracy: 94.7143%, tar: 0.0211 \n",
      "l0: 0.018782, l1: 0.019498, l2: 0.025125, l3: 0.039349, l4: 0.071822, l5: 0.129649, l6: 0.262383\n",
      "\n",
      "[epoch: 369/400, batch: 216/1000, ite: 48903] train loss: 1.1209, accuracy: 95.4095%, tar: 0.0211 \n",
      "l0: 0.027771, l1: 0.029691, l2: 0.041303, l3: 0.061342, l4: 0.103273, l5: 0.208831, l6: 0.460714\n",
      "\n",
      "[epoch: 369/400, batch: 224/1000, ite: 48904] train loss: 1.1212, accuracy: 93.7074%, tar: 0.0211 \n",
      "l0: 0.023683, l1: 0.025443, l2: 0.033298, l3: 0.050292, l4: 0.091266, l5: 0.217652, l6: 0.403904\n",
      "\n",
      "[epoch: 369/400, batch: 232/1000, ite: 48905] train loss: 1.1213, accuracy: 93.9313%, tar: 0.0211 \n",
      "l0: 0.019130, l1: 0.020648, l2: 0.027726, l3: 0.041174, l4: 0.071892, l5: 0.140990, l6: 0.293646\n",
      "\n",
      "[epoch: 369/400, batch: 240/1000, ite: 48906] train loss: 1.1211, accuracy: 96.1436%, tar: 0.0211 \n",
      "l0: 0.018028, l1: 0.019455, l2: 0.027344, l3: 0.042491, l4: 0.070968, l5: 0.155317, l6: 0.312947\n",
      "\n",
      "[epoch: 369/400, batch: 248/1000, ite: 48907] train loss: 1.1209, accuracy: 95.1373%, tar: 0.0211 \n",
      "l0: 0.018444, l1: 0.019102, l2: 0.026779, l3: 0.039552, l4: 0.069449, l5: 0.143455, l6: 0.288239\n",
      "\n",
      "[epoch: 369/400, batch: 256/1000, ite: 48908] train loss: 1.1207, accuracy: 95.7302%, tar: 0.0211 \n",
      "l0: 0.016510, l1: 0.017270, l2: 0.022642, l3: 0.033484, l4: 0.057856, l5: 0.113788, l6: 0.230115\n",
      "\n",
      "[epoch: 369/400, batch: 264/1000, ite: 48909] train loss: 1.1202, accuracy: 96.1590%, tar: 0.0211 \n",
      "l0: 0.024485, l1: 0.026201, l2: 0.036940, l3: 0.053988, l4: 0.102120, l5: 0.210630, l6: 0.403823\n",
      "\n",
      "[epoch: 369/400, batch: 272/1000, ite: 48910] train loss: 1.1204, accuracy: 94.8622%, tar: 0.0211 \n",
      "l0: 0.019596, l1: 0.020976, l2: 0.028046, l3: 0.045379, l4: 0.085609, l5: 0.164549, l6: 0.324372\n",
      "\n",
      "[epoch: 369/400, batch: 280/1000, ite: 48911] train loss: 1.1203, accuracy: 95.4142%, tar: 0.0211 \n",
      "l0: 0.017908, l1: 0.019366, l2: 0.026875, l3: 0.043730, l4: 0.078601, l5: 0.172114, l6: 0.321162\n",
      "\n",
      "[epoch: 369/400, batch: 288/1000, ite: 48912] train loss: 1.1202, accuracy: 96.0935%, tar: 0.0211 \n",
      "l0: 0.030295, l1: 0.032307, l2: 0.044639, l3: 0.066359, l4: 0.117988, l5: 0.219290, l6: 0.460012\n",
      "\n",
      "[epoch: 369/400, batch: 296/1000, ite: 48913] train loss: 1.1205, accuracy: 94.0174%, tar: 0.0211 \n",
      "l0: 0.019163, l1: 0.019801, l2: 0.026316, l3: 0.038473, l4: 0.070396, l5: 0.137189, l6: 0.265282\n",
      "\n",
      "[epoch: 369/400, batch: 304/1000, ite: 48914] train loss: 1.1202, accuracy: 95.7918%, tar: 0.0211 \n",
      "l0: 0.017875, l1: 0.018765, l2: 0.026080, l3: 0.040129, l4: 0.080259, l5: 0.153825, l6: 0.302251\n",
      "\n",
      "[epoch: 369/400, batch: 312/1000, ite: 48915] train loss: 1.1200, accuracy: 95.5771%, tar: 0.0211 \n",
      "l0: 0.019853, l1: 0.020742, l2: 0.027777, l3: 0.041530, l4: 0.075536, l5: 0.150466, l6: 0.337314\n",
      "\n",
      "[epoch: 369/400, batch: 320/1000, ite: 48916] train loss: 1.1199, accuracy: 95.2175%, tar: 0.0211 \n",
      "l0: 0.021912, l1: 0.023248, l2: 0.033532, l3: 0.050903, l4: 0.102514, l5: 0.216710, l6: 0.432582\n",
      "\n",
      "[epoch: 369/400, batch: 328/1000, ite: 48917] train loss: 1.1201, accuracy: 93.7929%, tar: 0.0211 \n",
      "l0: 0.020191, l1: 0.021941, l2: 0.029822, l3: 0.047156, l4: 0.106284, l5: 0.165709, l6: 0.391416\n",
      "\n",
      "[epoch: 369/400, batch: 336/1000, ite: 48918] train loss: 1.1202, accuracy: 95.3588%, tar: 0.0211 \n",
      "l0: 0.023400, l1: 0.024604, l2: 0.032839, l3: 0.050063, l4: 0.096510, l5: 0.214011, l6: 0.461511\n",
      "\n",
      "[epoch: 369/400, batch: 344/1000, ite: 48919] train loss: 1.1204, accuracy: 94.0173%, tar: 0.0211 \n",
      "l0: 0.021338, l1: 0.022671, l2: 0.031696, l3: 0.050389, l4: 0.091644, l5: 0.190120, l6: 0.491819\n",
      "\n",
      "[epoch: 369/400, batch: 352/1000, ite: 48920] train loss: 1.1208, accuracy: 93.6739%, tar: 0.0211 \n",
      "l0: 0.022606, l1: 0.024233, l2: 0.032263, l3: 0.046567, l4: 0.086684, l5: 0.187630, l6: 0.319002\n",
      "\n",
      "[epoch: 369/400, batch: 360/1000, ite: 48921] train loss: 1.1207, accuracy: 95.3779%, tar: 0.0211 \n",
      "l0: 0.021099, l1: 0.022218, l2: 0.031120, l3: 0.045096, l4: 0.080592, l5: 0.160247, l6: 0.312988\n",
      "\n",
      "[epoch: 369/400, batch: 368/1000, ite: 48922] train loss: 1.1205, accuracy: 95.5251%, tar: 0.0211 \n",
      "l0: 0.020525, l1: 0.021898, l2: 0.029102, l3: 0.042086, l4: 0.074310, l5: 0.138789, l6: 0.347391\n",
      "\n",
      "[epoch: 369/400, batch: 376/1000, ite: 48923] train loss: 1.1204, accuracy: 95.6321%, tar: 0.0211 \n",
      "l0: 0.015542, l1: 0.016790, l2: 0.024930, l3: 0.039421, l4: 0.074680, l5: 0.165358, l6: 0.325850\n",
      "\n",
      "[epoch: 369/400, batch: 384/1000, ite: 48924] train loss: 1.1203, accuracy: 95.9522%, tar: 0.0211 \n",
      "l0: 0.018142, l1: 0.019403, l2: 0.029166, l3: 0.056536, l4: 0.108966, l5: 0.200415, l6: 0.391769\n",
      "\n",
      "[epoch: 369/400, batch: 392/1000, ite: 48925] train loss: 1.1204, accuracy: 95.1078%, tar: 0.0211 \n",
      "l0: 0.018082, l1: 0.019135, l2: 0.026525, l3: 0.040747, l4: 0.073365, l5: 0.173025, l6: 0.458019\n",
      "\n",
      "[epoch: 369/400, batch: 400/1000, ite: 48926] train loss: 1.1206, accuracy: 94.6281%, tar: 0.0211 \n",
      "l0: 0.018834, l1: 0.020339, l2: 0.029093, l3: 0.045125, l4: 0.084387, l5: 0.168047, l6: 0.357414\n",
      "\n",
      "[epoch: 369/400, batch: 408/1000, ite: 48927] train loss: 1.1205, accuracy: 95.3646%, tar: 0.0211 \n",
      "l0: 0.021089, l1: 0.022031, l2: 0.029455, l3: 0.044208, l4: 0.080233, l5: 0.157096, l6: 0.331043\n",
      "\n",
      "[epoch: 369/400, batch: 416/1000, ite: 48928] train loss: 1.1204, accuracy: 94.7846%, tar: 0.0211 \n",
      "l0: 0.017655, l1: 0.018754, l2: 0.024825, l3: 0.039295, l4: 0.069961, l5: 0.139489, l6: 0.289667\n",
      "\n",
      "[epoch: 369/400, batch: 424/1000, ite: 48929] train loss: 1.1202, accuracy: 95.9107%, tar: 0.0211 \n",
      "l0: 0.021626, l1: 0.022992, l2: 0.029238, l3: 0.042532, l4: 0.074277, l5: 0.165850, l6: 0.315231\n",
      "\n",
      "[epoch: 369/400, batch: 432/1000, ite: 48930] train loss: 1.1200, accuracy: 95.5710%, tar: 0.0211 \n",
      "l0: 0.018031, l1: 0.018991, l2: 0.025819, l3: 0.039238, l4: 0.069026, l5: 0.139450, l6: 0.285073\n",
      "\n",
      "[epoch: 369/400, batch: 440/1000, ite: 48931] train loss: 1.1198, accuracy: 95.8825%, tar: 0.0211 \n",
      "l0: 0.019392, l1: 0.020963, l2: 0.028993, l3: 0.041440, l4: 0.086750, l5: 0.212162, l6: 0.414416\n",
      "\n",
      "[epoch: 369/400, batch: 448/1000, ite: 48932] train loss: 1.1199, accuracy: 95.1766%, tar: 0.0211 \n",
      "l0: 0.020502, l1: 0.021687, l2: 0.028289, l3: 0.041567, l4: 0.071952, l5: 0.127988, l6: 0.267468\n",
      "\n",
      "[epoch: 369/400, batch: 456/1000, ite: 48933] train loss: 1.1196, accuracy: 95.9261%, tar: 0.0211 \n",
      "l0: 0.015671, l1: 0.017227, l2: 0.024791, l3: 0.038267, l4: 0.076159, l5: 0.150738, l6: 0.266173\n",
      "\n",
      "[epoch: 369/400, batch: 464/1000, ite: 48934] train loss: 1.1193, accuracy: 96.6900%, tar: 0.0211 \n",
      "l0: 0.015862, l1: 0.016884, l2: 0.023551, l3: 0.034933, l4: 0.079755, l5: 0.132116, l6: 0.251461\n",
      "\n",
      "[epoch: 369/400, batch: 472/1000, ite: 48935] train loss: 1.1190, accuracy: 96.4751%, tar: 0.0211 \n",
      "l0: 0.018242, l1: 0.018856, l2: 0.026413, l3: 0.038773, l4: 0.067530, l5: 0.125548, l6: 0.365797\n",
      "\n",
      "[epoch: 369/400, batch: 480/1000, ite: 48936] train loss: 1.1189, accuracy: 95.6688%, tar: 0.0211 \n",
      "l0: 0.022277, l1: 0.023530, l2: 0.030809, l3: 0.048161, l4: 0.113665, l5: 0.217407, l6: 0.406850\n",
      "\n",
      "[epoch: 369/400, batch: 488/1000, ite: 48937] train loss: 1.1191, accuracy: 94.1341%, tar: 0.0211 \n",
      "l0: 0.024346, l1: 0.025419, l2: 0.033830, l3: 0.050053, l4: 0.088022, l5: 0.161532, l6: 0.337661\n",
      "\n",
      "[epoch: 369/400, batch: 496/1000, ite: 48938] train loss: 1.1190, accuracy: 94.0821%, tar: 0.0211 \n",
      "l0: 0.022266, l1: 0.024507, l2: 0.034241, l3: 0.061342, l4: 0.126053, l5: 0.244396, l6: 0.434740\n",
      "\n",
      "[epoch: 369/400, batch: 504/1000, ite: 48939] train loss: 1.1193, accuracy: 95.4199%, tar: 0.0211 \n",
      "l0: 0.021324, l1: 0.023073, l2: 0.032365, l3: 0.052339, l4: 0.100509, l5: 0.214987, l6: 0.403925\n",
      "\n",
      "[epoch: 369/400, batch: 512/1000, ite: 48940] train loss: 1.1194, accuracy: 94.3980%, tar: 0.0211 \n",
      "l0: 0.020047, l1: 0.021342, l2: 0.029875, l3: 0.048211, l4: 0.094774, l5: 0.192907, l6: 0.410029\n",
      "\n",
      "[epoch: 369/400, batch: 520/1000, ite: 48941] train loss: 1.1196, accuracy: 94.9891%, tar: 0.0211 \n",
      "l0: 0.017028, l1: 0.018381, l2: 0.025603, l3: 0.037163, l4: 0.062077, l5: 0.120427, l6: 0.253842\n",
      "\n",
      "[epoch: 369/400, batch: 528/1000, ite: 48942] train loss: 1.1192, accuracy: 96.2924%, tar: 0.0211 \n",
      "l0: 0.018533, l1: 0.020346, l2: 0.028347, l3: 0.046188, l4: 0.083526, l5: 0.173957, l6: 0.360719\n",
      "\n",
      "[epoch: 369/400, batch: 536/1000, ite: 48943] train loss: 1.1192, accuracy: 95.0558%, tar: 0.0211 \n",
      "l0: 0.014119, l1: 0.015326, l2: 0.022387, l3: 0.035308, l4: 0.071618, l5: 0.128222, l6: 0.320130\n",
      "\n",
      "[epoch: 369/400, batch: 544/1000, ite: 48944] train loss: 1.1190, accuracy: 96.3223%, tar: 0.0211 \n",
      "l0: 0.025065, l1: 0.026781, l2: 0.037693, l3: 0.059447, l4: 0.120966, l5: 0.245471, l6: 0.407939\n",
      "\n",
      "[epoch: 369/400, batch: 552/1000, ite: 48945] train loss: 1.1192, accuracy: 93.7643%, tar: 0.0211 \n",
      "l0: 0.022422, l1: 0.023344, l2: 0.029757, l3: 0.044347, l4: 0.094018, l5: 0.193458, l6: 0.393071\n",
      "\n",
      "[epoch: 369/400, batch: 560/1000, ite: 48946] train loss: 1.1193, accuracy: 94.1286%, tar: 0.0211 \n",
      "l0: 0.023384, l1: 0.024454, l2: 0.035162, l3: 0.057681, l4: 0.100866, l5: 0.210975, l6: 0.477582\n",
      "\n",
      "[epoch: 369/400, batch: 568/1000, ite: 48947] train loss: 1.1196, accuracy: 93.6180%, tar: 0.0211 \n",
      "l0: 0.015486, l1: 0.016773, l2: 0.022268, l3: 0.032494, l4: 0.050038, l5: 0.102920, l6: 0.219979\n",
      "\n",
      "[epoch: 369/400, batch: 576/1000, ite: 48948] train loss: 1.1192, accuracy: 97.0088%, tar: 0.0211 \n",
      "l0: 0.024624, l1: 0.027815, l2: 0.040616, l3: 0.064227, l4: 0.138775, l5: 0.315236, l6: 0.561782\n",
      "\n",
      "[epoch: 369/400, batch: 584/1000, ite: 48949] train loss: 1.1198, accuracy: 93.4119%, tar: 0.0211 \n",
      "l0: 0.022045, l1: 0.023770, l2: 0.033056, l3: 0.055867, l4: 0.116643, l5: 0.276669, l6: 0.557269\n",
      "\n",
      "[epoch: 369/400, batch: 592/1000, ite: 48950] train loss: 1.1203, accuracy: 93.0934%, tar: 0.0211 \n",
      "l0: 0.017091, l1: 0.017827, l2: 0.023405, l3: 0.031746, l4: 0.059969, l5: 0.138884, l6: 0.267908\n",
      "\n",
      "[epoch: 369/400, batch: 600/1000, ite: 48951] train loss: 1.1200, accuracy: 96.0545%, tar: 0.0211 \n",
      "l0: 0.023611, l1: 0.025104, l2: 0.033259, l3: 0.052545, l4: 0.104366, l5: 0.238049, l6: 0.492676\n",
      "\n",
      "[epoch: 369/400, batch: 608/1000, ite: 48952] train loss: 1.1204, accuracy: 93.8477%, tar: 0.0211 \n",
      "l0: 0.016681, l1: 0.017321, l2: 0.022714, l3: 0.036350, l4: 0.068472, l5: 0.130767, l6: 0.267153\n",
      "\n",
      "[epoch: 369/400, batch: 616/1000, ite: 48953] train loss: 1.1201, accuracy: 96.1015%, tar: 0.0211 \n",
      "l0: 0.022235, l1: 0.023938, l2: 0.033339, l3: 0.049922, l4: 0.091137, l5: 0.194393, l6: 0.380735\n",
      "\n",
      "[epoch: 369/400, batch: 624/1000, ite: 48954] train loss: 1.1202, accuracy: 94.4017%, tar: 0.0211 \n",
      "l0: 0.019523, l1: 0.020919, l2: 0.028357, l3: 0.046487, l4: 0.097808, l5: 0.193164, l6: 0.390718\n",
      "\n",
      "[epoch: 369/400, batch: 632/1000, ite: 48955] train loss: 1.1202, accuracy: 94.7371%, tar: 0.0211 \n",
      "l0: 0.015777, l1: 0.017141, l2: 0.024899, l3: 0.041360, l4: 0.071191, l5: 0.165523, l6: 0.305357\n",
      "\n",
      "[epoch: 369/400, batch: 640/1000, ite: 48956] train loss: 1.1201, accuracy: 96.0020%, tar: 0.0211 \n",
      "l0: 0.025165, l1: 0.026797, l2: 0.037839, l3: 0.064162, l4: 0.138251, l5: 0.282418, l6: 0.557860\n",
      "\n",
      "[epoch: 369/400, batch: 648/1000, ite: 48957] train loss: 1.1207, accuracy: 93.0715%, tar: 0.0211 \n",
      "l0: 0.021864, l1: 0.023136, l2: 0.031984, l3: 0.047838, l4: 0.093259, l5: 0.210455, l6: 0.452541\n",
      "\n",
      "[epoch: 369/400, batch: 656/1000, ite: 48958] train loss: 1.1209, accuracy: 94.4696%, tar: 0.0211 \n",
      "l0: 0.031089, l1: 0.032118, l2: 0.039696, l3: 0.053374, l4: 0.091865, l5: 0.184463, l6: 0.380286\n",
      "\n",
      "[epoch: 369/400, batch: 664/1000, ite: 48959] train loss: 1.1209, accuracy: 94.5706%, tar: 0.0211 \n",
      "l0: 0.029580, l1: 0.030863, l2: 0.041719, l3: 0.064161, l4: 0.112406, l5: 0.256718, l6: 0.625905\n",
      "\n",
      "[epoch: 369/400, batch: 672/1000, ite: 48960] train loss: 1.1217, accuracy: 91.9824%, tar: 0.0211 \n",
      "l0: 0.013396, l1: 0.014279, l2: 0.019866, l3: 0.033111, l4: 0.059108, l5: 0.109079, l6: 0.240292\n",
      "\n",
      "[epoch: 369/400, batch: 680/1000, ite: 48961] train loss: 1.1213, accuracy: 96.4131%, tar: 0.0211 \n",
      "l0: 0.022394, l1: 0.023619, l2: 0.031319, l3: 0.048463, l4: 0.087039, l5: 0.194601, l6: 0.396900\n",
      "\n",
      "[epoch: 369/400, batch: 688/1000, ite: 48962] train loss: 1.1214, accuracy: 94.2774%, tar: 0.0211 \n",
      "l0: 0.022258, l1: 0.023439, l2: 0.030882, l3: 0.046889, l4: 0.086093, l5: 0.179053, l6: 0.368923\n",
      "\n",
      "[epoch: 369/400, batch: 696/1000, ite: 48963] train loss: 1.1214, accuracy: 94.5381%, tar: 0.0211 \n",
      "l0: 0.022877, l1: 0.024245, l2: 0.029870, l3: 0.044432, l4: 0.095084, l5: 0.180395, l6: 0.408477\n",
      "\n",
      "[epoch: 369/400, batch: 704/1000, ite: 48964] train loss: 1.1215, accuracy: 93.9984%, tar: 0.0211 \n",
      "l0: 0.017904, l1: 0.018470, l2: 0.023407, l3: 0.033455, l4: 0.054852, l5: 0.107002, l6: 0.269317\n",
      "\n",
      "[epoch: 369/400, batch: 712/1000, ite: 48965] train loss: 1.1211, accuracy: 96.0971%, tar: 0.0211 \n",
      "l0: 0.021130, l1: 0.022175, l2: 0.027835, l3: 0.043633, l4: 0.080139, l5: 0.171694, l6: 0.382651\n",
      "\n",
      "[epoch: 369/400, batch: 720/1000, ite: 48966] train loss: 1.1212, accuracy: 94.2285%, tar: 0.0211 \n",
      "l0: 0.023373, l1: 0.025280, l2: 0.034752, l3: 0.054477, l4: 0.102922, l5: 0.197822, l6: 0.407930\n",
      "\n",
      "[epoch: 369/400, batch: 728/1000, ite: 48967] train loss: 1.1213, accuracy: 94.8711%, tar: 0.0211 \n",
      "l0: 0.015319, l1: 0.017028, l2: 0.026365, l3: 0.049261, l4: 0.087629, l5: 0.134836, l6: 0.271244\n",
      "\n",
      "[epoch: 369/400, batch: 736/1000, ite: 48968] train loss: 1.1210, accuracy: 96.1628%, tar: 0.0211 \n",
      "l0: 0.022980, l1: 0.024600, l2: 0.033236, l3: 0.052339, l4: 0.104652, l5: 0.246561, l6: 0.478681\n",
      "\n",
      "[epoch: 369/400, batch: 744/1000, ite: 48969] train loss: 1.1214, accuracy: 94.4851%, tar: 0.0211 \n",
      "l0: 0.017082, l1: 0.018542, l2: 0.026993, l3: 0.040542, l4: 0.076710, l5: 0.157561, l6: 0.327163\n",
      "\n",
      "[epoch: 369/400, batch: 752/1000, ite: 48970] train loss: 1.1212, accuracy: 95.7887%, tar: 0.0211 \n",
      "l0: 0.021225, l1: 0.022538, l2: 0.030324, l3: 0.044581, l4: 0.082540, l5: 0.170992, l6: 0.418037\n",
      "\n",
      "[epoch: 369/400, batch: 760/1000, ite: 48971] train loss: 1.1213, accuracy: 94.6009%, tar: 0.0211 \n",
      "l0: 0.021230, l1: 0.022889, l2: 0.031440, l3: 0.050554, l4: 0.115219, l5: 0.213898, l6: 0.361103\n",
      "\n",
      "[epoch: 369/400, batch: 768/1000, ite: 48972] train loss: 1.1214, accuracy: 95.0257%, tar: 0.0211 \n",
      "l0: 0.017767, l1: 0.018802, l2: 0.025533, l3: 0.037928, l4: 0.065678, l5: 0.136413, l6: 0.278629\n",
      "\n",
      "[epoch: 369/400, batch: 776/1000, ite: 48973] train loss: 1.1211, accuracy: 95.6684%, tar: 0.0211 \n",
      "l0: 0.022527, l1: 0.023583, l2: 0.032820, l3: 0.050516, l4: 0.086825, l5: 0.171006, l6: 0.388393\n",
      "\n",
      "[epoch: 369/400, batch: 784/1000, ite: 48974] train loss: 1.1212, accuracy: 94.6504%, tar: 0.0211 \n",
      "l0: 0.019165, l1: 0.020505, l2: 0.028863, l3: 0.041366, l4: 0.088325, l5: 0.196300, l6: 0.382862\n",
      "\n",
      "[epoch: 369/400, batch: 792/1000, ite: 48975] train loss: 1.1212, accuracy: 94.6469%, tar: 0.0211 \n",
      "l0: 0.020978, l1: 0.021833, l2: 0.029749, l3: 0.043584, l4: 0.074586, l5: 0.168881, l6: 0.331378\n",
      "\n",
      "[epoch: 369/400, batch: 800/1000, ite: 48976] train loss: 1.1211, accuracy: 95.0069%, tar: 0.0211 \n",
      "l0: 0.017461, l1: 0.020117, l2: 0.030688, l3: 0.050346, l4: 0.091307, l5: 0.177294, l6: 0.362624\n",
      "\n",
      "[epoch: 369/400, batch: 808/1000, ite: 48977] train loss: 1.1211, accuracy: 95.9421%, tar: 0.0211 \n",
      "l0: 0.017924, l1: 0.019360, l2: 0.026062, l3: 0.041090, l4: 0.072085, l5: 0.146072, l6: 0.305864\n",
      "\n",
      "[epoch: 369/400, batch: 816/1000, ite: 48978] train loss: 1.1209, accuracy: 95.6921%, tar: 0.0211 \n",
      "l0: 0.020604, l1: 0.023012, l2: 0.032964, l3: 0.054254, l4: 0.112726, l5: 0.246929, l6: 0.505905\n",
      "\n",
      "[epoch: 369/400, batch: 824/1000, ite: 48979] train loss: 1.1213, accuracy: 94.5944%, tar: 0.0211 \n",
      "l0: 0.017762, l1: 0.020162, l2: 0.030333, l3: 0.047863, l4: 0.094412, l5: 0.193930, l6: 0.396756\n",
      "\n",
      "[epoch: 369/400, batch: 832/1000, ite: 48980] train loss: 1.1214, accuracy: 95.5684%, tar: 0.0210 \n",
      "l0: 0.022118, l1: 0.023435, l2: 0.031156, l3: 0.043060, l4: 0.073236, l5: 0.155127, l6: 0.404016\n",
      "\n",
      "[epoch: 369/400, batch: 840/1000, ite: 48981] train loss: 1.1214, accuracy: 94.2678%, tar: 0.0210 \n",
      "l0: 0.016397, l1: 0.017867, l2: 0.025084, l3: 0.038421, l4: 0.083372, l5: 0.195733, l6: 0.392225\n",
      "\n",
      "[epoch: 369/400, batch: 848/1000, ite: 48982] train loss: 1.1215, accuracy: 95.4288%, tar: 0.0210 \n",
      "l0: 0.024627, l1: 0.026423, l2: 0.034325, l3: 0.052656, l4: 0.106250, l5: 0.171531, l6: 0.331435\n",
      "\n",
      "[epoch: 369/400, batch: 856/1000, ite: 48983] train loss: 1.1214, accuracy: 95.0822%, tar: 0.0210 \n",
      "l0: 0.014038, l1: 0.015134, l2: 0.022852, l3: 0.036550, l4: 0.069984, l5: 0.148985, l6: 0.320849\n",
      "\n",
      "[epoch: 369/400, batch: 864/1000, ite: 48984] train loss: 1.1213, accuracy: 95.8440%, tar: 0.0210 \n",
      "l0: 0.018255, l1: 0.019669, l2: 0.026601, l3: 0.038492, l4: 0.074026, l5: 0.161405, l6: 0.365327\n",
      "\n",
      "[epoch: 369/400, batch: 872/1000, ite: 48985] train loss: 1.1212, accuracy: 94.8525%, tar: 0.0210 \n",
      "l0: 0.019216, l1: 0.021437, l2: 0.027754, l3: 0.044966, l4: 0.084691, l5: 0.179515, l6: 0.376617\n",
      "\n",
      "[epoch: 369/400, batch: 880/1000, ite: 48986] train loss: 1.1212, accuracy: 95.4094%, tar: 0.0210 \n",
      "l0: 0.024050, l1: 0.025390, l2: 0.031720, l3: 0.045926, l4: 0.110582, l5: 0.216845, l6: 0.377881\n",
      "\n",
      "[epoch: 369/400, batch: 888/1000, ite: 48987] train loss: 1.1213, accuracy: 94.4682%, tar: 0.0210 \n",
      "l0: 0.028471, l1: 0.029766, l2: 0.038816, l3: 0.057874, l4: 0.101609, l5: 0.181845, l6: 0.381342\n",
      "\n",
      "[epoch: 369/400, batch: 896/1000, ite: 48988] train loss: 1.1214, accuracy: 94.0386%, tar: 0.0210 \n",
      "l0: 0.024760, l1: 0.026009, l2: 0.034274, l3: 0.050365, l4: 0.101386, l5: 0.228356, l6: 0.429645\n",
      "\n",
      "[epoch: 369/400, batch: 904/1000, ite: 48989] train loss: 1.1216, accuracy: 93.3915%, tar: 0.0211 \n",
      "l0: 0.023232, l1: 0.024283, l2: 0.031066, l3: 0.044975, l4: 0.076280, l5: 0.151124, l6: 0.345386\n",
      "\n",
      "[epoch: 369/400, batch: 912/1000, ite: 48990] train loss: 1.1216, accuracy: 94.6730%, tar: 0.0211 \n",
      "l0: 0.019448, l1: 0.020622, l2: 0.028141, l3: 0.044680, l4: 0.082874, l5: 0.146964, l6: 0.304744\n",
      "\n",
      "[epoch: 369/400, batch: 920/1000, ite: 48991] train loss: 1.1214, accuracy: 95.7168%, tar: 0.0211 \n",
      "l0: 0.029518, l1: 0.031933, l2: 0.043687, l3: 0.067454, l4: 0.118150, l5: 0.199243, l6: 0.360089\n",
      "\n",
      "[epoch: 369/400, batch: 928/1000, ite: 48992] train loss: 1.1215, accuracy: 95.1105%, tar: 0.0211 \n",
      "l0: 0.022119, l1: 0.023624, l2: 0.031665, l3: 0.049470, l4: 0.107580, l5: 0.205128, l6: 0.390527\n",
      "\n",
      "[epoch: 369/400, batch: 936/1000, ite: 48993] train loss: 1.1216, accuracy: 94.5149%, tar: 0.0211 \n",
      "l0: 0.022217, l1: 0.023398, l2: 0.032593, l3: 0.047637, l4: 0.086277, l5: 0.188069, l6: 0.376744\n",
      "\n",
      "[epoch: 369/400, batch: 944/1000, ite: 48994] train loss: 1.1216, accuracy: 94.6577%, tar: 0.0211 \n",
      "l0: 0.015998, l1: 0.017114, l2: 0.022929, l3: 0.041815, l4: 0.090717, l5: 0.189295, l6: 0.343292\n",
      "\n",
      "[epoch: 369/400, batch: 952/1000, ite: 48995] train loss: 1.1216, accuracy: 96.2531%, tar: 0.0211 \n",
      "l0: 0.016520, l1: 0.017406, l2: 0.023661, l3: 0.034092, l4: 0.055596, l5: 0.104781, l6: 0.249058\n",
      "\n",
      "[epoch: 369/400, batch: 960/1000, ite: 48996] train loss: 1.1212, accuracy: 96.1900%, tar: 0.0211 \n",
      "l0: 0.018208, l1: 0.019495, l2: 0.026963, l3: 0.043758, l4: 0.084360, l5: 0.178947, l6: 0.413334\n",
      "\n",
      "[epoch: 369/400, batch: 968/1000, ite: 48997] train loss: 1.1213, accuracy: 95.2121%, tar: 0.0211 \n",
      "l0: 0.022904, l1: 0.023870, l2: 0.031717, l3: 0.046723, l4: 0.096219, l5: 0.247447, l6: 0.456048\n",
      "\n",
      "[epoch: 369/400, batch: 976/1000, ite: 48998] train loss: 1.1216, accuracy: 93.3394%, tar: 0.0211 \n",
      "l0: 0.017501, l1: 0.018736, l2: 0.026337, l3: 0.043752, l4: 0.082292, l5: 0.178974, l6: 0.343368\n",
      "\n",
      "[epoch: 369/400, batch: 984/1000, ite: 48999] train loss: 1.1215, accuracy: 95.2395%, tar: 0.0210 \n",
      "l0: 0.021598, l1: 0.022312, l2: 0.028406, l3: 0.039555, l4: 0.070307, l5: 0.151462, l6: 0.306716\n",
      "\n",
      "[epoch: 369/400, batch: 992/1000, ite: 49000] train loss: 1.1213, accuracy: 95.3402%, tar: 0.0210 \n",
      "l0: 0.018999, l1: 0.020284, l2: 0.027170, l3: 0.047275, l4: 0.092719, l5: 0.162575, l6: 0.308866\n",
      "\n",
      "[epoch: 369/400, batch: 1000/1000, ite: 49001] train loss: 1.1212, accuracy: 95.8228%, tar: 0.0210 \n",
      "l0: 0.016844, l1: 0.018001, l2: 0.024934, l3: 0.039431, l4: 0.080366, l5: 0.162193, l6: 0.331543\n",
      "\n",
      "[epoch: 370/400, batch: 8/1000, ite: 49002] train loss: 1.1211, accuracy: 95.5262%, tar: 0.0210 \n",
      "l0: 0.015035, l1: 0.015909, l2: 0.020276, l3: 0.031117, l4: 0.056559, l5: 0.109441, l6: 0.213013\n",
      "\n",
      "[epoch: 370/400, batch: 16/1000, ite: 49003] train loss: 1.1206, accuracy: 96.7271%, tar: 0.0210 \n",
      "l0: 0.023049, l1: 0.024436, l2: 0.031562, l3: 0.046791, l4: 0.076871, l5: 0.153117, l6: 0.333623\n",
      "\n",
      "[epoch: 370/400, batch: 24/1000, ite: 49004] train loss: 1.1205, accuracy: 95.4942%, tar: 0.0210 \n",
      "l0: 0.022616, l1: 0.023687, l2: 0.031561, l3: 0.045512, l4: 0.081917, l5: 0.193959, l6: 0.389316\n",
      "\n",
      "[epoch: 370/400, batch: 32/1000, ite: 49005] train loss: 1.1206, accuracy: 94.4543%, tar: 0.0210 \n",
      "l0: 0.018107, l1: 0.019550, l2: 0.026759, l3: 0.042433, l4: 0.084682, l5: 0.172418, l6: 0.352416\n",
      "\n",
      "[epoch: 370/400, batch: 40/1000, ite: 49006] train loss: 1.1205, accuracy: 94.8805%, tar: 0.0210 \n",
      "l0: 0.024508, l1: 0.026422, l2: 0.036285, l3: 0.052441, l4: 0.101367, l5: 0.234244, l6: 0.389064\n",
      "\n",
      "[epoch: 370/400, batch: 48/1000, ite: 49007] train loss: 1.1207, accuracy: 94.5715%, tar: 0.0210 \n",
      "l0: 0.026172, l1: 0.028624, l2: 0.038980, l3: 0.058056, l4: 0.112317, l5: 0.255812, l6: 0.568961\n",
      "\n",
      "[epoch: 370/400, batch: 56/1000, ite: 49008] train loss: 1.1212, accuracy: 92.6772%, tar: 0.0210 \n",
      "l0: 0.017247, l1: 0.018790, l2: 0.026327, l3: 0.044747, l4: 0.092179, l5: 0.178225, l6: 0.349822\n",
      "\n",
      "[epoch: 370/400, batch: 64/1000, ite: 49009] train loss: 1.1212, accuracy: 95.5920%, tar: 0.0210 \n",
      "l0: 0.018055, l1: 0.019580, l2: 0.027711, l3: 0.043211, l4: 0.088621, l5: 0.190539, l6: 0.344663\n",
      "\n",
      "[epoch: 370/400, batch: 72/1000, ite: 49010] train loss: 1.1211, accuracy: 95.2035%, tar: 0.0210 \n",
      "l0: 0.021802, l1: 0.023894, l2: 0.035373, l3: 0.059841, l4: 0.126247, l5: 0.248473, l6: 0.439826\n",
      "\n",
      "[epoch: 370/400, batch: 80/1000, ite: 49011] train loss: 1.1214, accuracy: 94.2631%, tar: 0.0210 \n",
      "l0: 0.020073, l1: 0.020908, l2: 0.026289, l3: 0.035950, l4: 0.064176, l5: 0.135723, l6: 0.282685\n",
      "\n",
      "[epoch: 370/400, batch: 88/1000, ite: 49012] train loss: 1.1212, accuracy: 95.4731%, tar: 0.0210 \n",
      "l0: 0.024562, l1: 0.025761, l2: 0.033160, l3: 0.048932, l4: 0.089130, l5: 0.198214, l6: 0.441656\n",
      "\n",
      "[epoch: 370/400, batch: 96/1000, ite: 49013] train loss: 1.1214, accuracy: 94.0610%, tar: 0.0210 \n",
      "l0: 0.023350, l1: 0.025238, l2: 0.034531, l3: 0.050055, l4: 0.092865, l5: 0.175472, l6: 0.339738\n",
      "\n",
      "[epoch: 370/400, batch: 104/1000, ite: 49014] train loss: 1.1213, accuracy: 95.4012%, tar: 0.0210 \n",
      "l0: 0.018871, l1: 0.019472, l2: 0.025807, l3: 0.038442, l4: 0.069134, l5: 0.137017, l6: 0.297004\n",
      "\n",
      "[epoch: 370/400, batch: 112/1000, ite: 49015] train loss: 1.1211, accuracy: 95.7449%, tar: 0.0210 \n",
      "l0: 0.018501, l1: 0.020321, l2: 0.028078, l3: 0.047364, l4: 0.109028, l5: 0.230029, l6: 0.439396\n",
      "\n",
      "[epoch: 370/400, batch: 120/1000, ite: 49016] train loss: 1.1213, accuracy: 95.0608%, tar: 0.0210 \n",
      "l0: 0.015756, l1: 0.017008, l2: 0.023617, l3: 0.033560, l4: 0.056730, l5: 0.109655, l6: 0.241007\n",
      "\n",
      "[epoch: 370/400, batch: 128/1000, ite: 49017] train loss: 1.1209, accuracy: 96.6032%, tar: 0.0210 \n",
      "l0: 0.018710, l1: 0.019641, l2: 0.028757, l3: 0.046398, l4: 0.080238, l5: 0.139821, l6: 0.303180\n",
      "\n",
      "[epoch: 370/400, batch: 136/1000, ite: 49018] train loss: 1.1208, accuracy: 95.5986%, tar: 0.0210 \n",
      "l0: 0.016261, l1: 0.017052, l2: 0.023658, l3: 0.035861, l4: 0.060377, l5: 0.128583, l6: 0.274446\n",
      "\n",
      "[epoch: 370/400, batch: 144/1000, ite: 49019] train loss: 1.1205, accuracy: 95.6477%, tar: 0.0210 \n",
      "l0: 0.017919, l1: 0.019037, l2: 0.027748, l3: 0.040428, l4: 0.064498, l5: 0.123559, l6: 0.240179\n",
      "\n",
      "[epoch: 370/400, batch: 152/1000, ite: 49020] train loss: 1.1202, accuracy: 96.2606%, tar: 0.0210 \n",
      "l0: 0.025567, l1: 0.028989, l2: 0.041724, l3: 0.067924, l4: 0.130861, l5: 0.242768, l6: 0.392854\n",
      "\n",
      "[epoch: 370/400, batch: 160/1000, ite: 49021] train loss: 1.1204, accuracy: 94.9501%, tar: 0.0210 \n",
      "l0: 0.020665, l1: 0.021698, l2: 0.028422, l3: 0.038539, l4: 0.062807, l5: 0.121005, l6: 0.273709\n",
      "\n",
      "[epoch: 370/400, batch: 168/1000, ite: 49022] train loss: 1.1201, accuracy: 95.3741%, tar: 0.0210 \n",
      "l0: 0.015475, l1: 0.016511, l2: 0.022154, l3: 0.034763, l4: 0.063654, l5: 0.129816, l6: 0.348837\n",
      "\n",
      "[epoch: 370/400, batch: 176/1000, ite: 49023] train loss: 1.1200, accuracy: 96.2895%, tar: 0.0210 \n",
      "l0: 0.016608, l1: 0.017621, l2: 0.024663, l3: 0.036656, l4: 0.070279, l5: 0.139924, l6: 0.307826\n",
      "\n",
      "[epoch: 370/400, batch: 184/1000, ite: 49024] train loss: 1.1198, accuracy: 95.6639%, tar: 0.0210 \n",
      "l0: 0.017576, l1: 0.018370, l2: 0.023953, l3: 0.033868, l4: 0.062702, l5: 0.117988, l6: 0.246084\n",
      "\n",
      "[epoch: 370/400, batch: 192/1000, ite: 49025] train loss: 1.1194, accuracy: 96.0045%, tar: 0.0210 \n",
      "l0: 0.015120, l1: 0.015816, l2: 0.021987, l3: 0.032892, l4: 0.059724, l5: 0.120860, l6: 0.277030\n",
      "\n",
      "[epoch: 370/400, batch: 200/1000, ite: 49026] train loss: 1.1192, accuracy: 96.2342%, tar: 0.0210 \n",
      "l0: 0.018073, l1: 0.019044, l2: 0.025265, l3: 0.036010, l4: 0.065367, l5: 0.112400, l6: 0.227619\n",
      "\n",
      "[epoch: 370/400, batch: 208/1000, ite: 49027] train loss: 1.1188, accuracy: 96.3256%, tar: 0.0210 \n",
      "l0: 0.026483, l1: 0.028620, l2: 0.039534, l3: 0.060202, l4: 0.115542, l5: 0.236603, l6: 0.456659\n",
      "\n",
      "[epoch: 370/400, batch: 216/1000, ite: 49028] train loss: 1.1191, accuracy: 93.0622%, tar: 0.0210 \n",
      "l0: 0.027164, l1: 0.028374, l2: 0.037464, l3: 0.064535, l4: 0.135213, l5: 0.258828, l6: 0.517401\n",
      "\n",
      "[epoch: 370/400, batch: 224/1000, ite: 49029] train loss: 1.1195, accuracy: 93.1479%, tar: 0.0210 \n",
      "l0: 0.019331, l1: 0.019626, l2: 0.026308, l3: 0.039295, l4: 0.071661, l5: 0.135115, l6: 0.338510\n",
      "\n",
      "[epoch: 370/400, batch: 232/1000, ite: 49030] train loss: 1.1194, accuracy: 95.7449%, tar: 0.0210 \n",
      "l0: 0.028510, l1: 0.030867, l2: 0.039148, l3: 0.060355, l4: 0.120664, l5: 0.238156, l6: 0.473109\n",
      "\n",
      "[epoch: 370/400, batch: 240/1000, ite: 49031] train loss: 1.1198, accuracy: 93.8400%, tar: 0.0210 \n",
      "l0: 0.022049, l1: 0.023098, l2: 0.031179, l3: 0.044730, l4: 0.088355, l5: 0.203292, l6: 0.449336\n",
      "\n",
      "[epoch: 370/400, batch: 248/1000, ite: 49032] train loss: 1.1199, accuracy: 94.6098%, tar: 0.0210 \n",
      "l0: 0.021505, l1: 0.022635, l2: 0.028986, l3: 0.043040, l4: 0.088830, l5: 0.201914, l6: 0.401285\n",
      "\n",
      "[epoch: 370/400, batch: 256/1000, ite: 49033] train loss: 1.1200, accuracy: 94.3186%, tar: 0.0210 \n",
      "l0: 0.015303, l1: 0.016356, l2: 0.021596, l3: 0.034460, l4: 0.061369, l5: 0.130059, l6: 0.326682\n",
      "\n",
      "[epoch: 370/400, batch: 264/1000, ite: 49034] train loss: 1.1198, accuracy: 96.0131%, tar: 0.0210 \n",
      "l0: 0.019972, l1: 0.021084, l2: 0.029318, l3: 0.046005, l4: 0.090294, l5: 0.188478, l6: 0.397627\n",
      "\n",
      "[epoch: 370/400, batch: 272/1000, ite: 49035] train loss: 1.1199, accuracy: 95.2755%, tar: 0.0210 \n",
      "l0: 0.021991, l1: 0.023666, l2: 0.032569, l3: 0.052006, l4: 0.104595, l5: 0.225350, l6: 0.404615\n",
      "\n",
      "[epoch: 370/400, batch: 280/1000, ite: 49036] train loss: 1.1201, accuracy: 94.4860%, tar: 0.0210 \n",
      "l0: 0.018816, l1: 0.019427, l2: 0.025460, l3: 0.036656, l4: 0.063059, l5: 0.131000, l6: 0.338898\n",
      "\n",
      "[epoch: 370/400, batch: 288/1000, ite: 49037] train loss: 1.1199, accuracy: 94.9383%, tar: 0.0210 \n",
      "l0: 0.023443, l1: 0.024702, l2: 0.033180, l3: 0.051289, l4: 0.095471, l5: 0.177581, l6: 0.388166\n",
      "\n",
      "[epoch: 370/400, batch: 296/1000, ite: 49038] train loss: 1.1200, accuracy: 94.4053%, tar: 0.0210 \n",
      "l0: 0.026861, l1: 0.029165, l2: 0.042049, l3: 0.065012, l4: 0.134952, l5: 0.306235, l6: 0.583825\n",
      "\n",
      "[epoch: 370/400, batch: 304/1000, ite: 49039] train loss: 1.1206, accuracy: 93.2941%, tar: 0.0210 \n",
      "l0: 0.017842, l1: 0.019573, l2: 0.028300, l3: 0.043916, l4: 0.079336, l5: 0.161246, l6: 0.330418\n",
      "\n",
      "[epoch: 370/400, batch: 312/1000, ite: 49040] train loss: 1.1205, accuracy: 95.5732%, tar: 0.0210 \n",
      "l0: 0.021743, l1: 0.023905, l2: 0.031607, l3: 0.049482, l4: 0.094733, l5: 0.190576, l6: 0.382106\n",
      "\n",
      "[epoch: 370/400, batch: 320/1000, ite: 49041] train loss: 1.1206, accuracy: 96.0117%, tar: 0.0210 \n",
      "l0: 0.020161, l1: 0.021327, l2: 0.027367, l3: 0.039677, l4: 0.061246, l5: 0.113641, l6: 0.285323\n",
      "\n",
      "[epoch: 370/400, batch: 328/1000, ite: 49042] train loss: 1.1203, accuracy: 96.3785%, tar: 0.0210 \n",
      "l0: 0.020592, l1: 0.022146, l2: 0.030096, l3: 0.047995, l4: 0.096887, l5: 0.192016, l6: 0.420126\n",
      "\n",
      "[epoch: 370/400, batch: 336/1000, ite: 49043] train loss: 1.1204, accuracy: 94.3357%, tar: 0.0210 \n",
      "l0: 0.017571, l1: 0.018519, l2: 0.024846, l3: 0.034630, l4: 0.058120, l5: 0.112995, l6: 0.248772\n",
      "\n",
      "[epoch: 370/400, batch: 344/1000, ite: 49044] train loss: 1.1201, accuracy: 96.3331%, tar: 0.0210 \n",
      "l0: 0.026222, l1: 0.027560, l2: 0.036949, l3: 0.051336, l4: 0.088895, l5: 0.194533, l6: 0.417243\n",
      "\n",
      "[epoch: 370/400, batch: 352/1000, ite: 49045] train loss: 1.1202, accuracy: 94.7060%, tar: 0.0210 \n",
      "l0: 0.022019, l1: 0.022658, l2: 0.028396, l3: 0.040273, l4: 0.065918, l5: 0.127020, l6: 0.312742\n",
      "\n",
      "[epoch: 370/400, batch: 360/1000, ite: 49046] train loss: 1.1201, accuracy: 95.0357%, tar: 0.0210 \n",
      "l0: 0.024135, l1: 0.025659, l2: 0.035484, l3: 0.054720, l4: 0.091349, l5: 0.164901, l6: 0.328498\n",
      "\n",
      "[epoch: 370/400, batch: 368/1000, ite: 49047] train loss: 1.1200, accuracy: 94.5966%, tar: 0.0210 \n",
      "l0: 0.017825, l1: 0.018918, l2: 0.025158, l3: 0.036539, l4: 0.066741, l5: 0.124832, l6: 0.237915\n",
      "\n",
      "[epoch: 370/400, batch: 376/1000, ite: 49048] train loss: 1.1197, accuracy: 96.4176%, tar: 0.0210 \n",
      "l0: 0.022882, l1: 0.023988, l2: 0.031066, l3: 0.049877, l4: 0.091964, l5: 0.168848, l6: 0.305595\n",
      "\n",
      "[epoch: 370/400, batch: 384/1000, ite: 49049] train loss: 1.1196, accuracy: 95.1564%, tar: 0.0210 \n",
      "l0: 0.018931, l1: 0.020624, l2: 0.028556, l3: 0.042532, l4: 0.082199, l5: 0.170009, l6: 0.375163\n",
      "\n",
      "[epoch: 370/400, batch: 392/1000, ite: 49050] train loss: 1.1196, accuracy: 95.4882%, tar: 0.0210 \n",
      "l0: 0.025843, l1: 0.027831, l2: 0.039460, l3: 0.062384, l4: 0.122557, l5: 0.245096, l6: 0.532404\n",
      "\n",
      "[epoch: 370/400, batch: 400/1000, ite: 49051] train loss: 1.1200, accuracy: 92.9459%, tar: 0.0210 \n",
      "l0: 0.023725, l1: 0.025128, l2: 0.034661, l3: 0.050562, l4: 0.090581, l5: 0.174615, l6: 0.360050\n",
      "\n",
      "[epoch: 370/400, batch: 408/1000, ite: 49052] train loss: 1.1200, accuracy: 94.5129%, tar: 0.0210 \n",
      "l0: 0.019086, l1: 0.020183, l2: 0.027215, l3: 0.039345, l4: 0.062998, l5: 0.126446, l6: 0.306558\n",
      "\n",
      "[epoch: 370/400, batch: 416/1000, ite: 49053] train loss: 1.1198, accuracy: 95.9071%, tar: 0.0210 \n",
      "l0: 0.021866, l1: 0.023130, l2: 0.031746, l3: 0.051211, l4: 0.102291, l5: 0.213006, l6: 0.431361\n",
      "\n",
      "[epoch: 370/400, batch: 424/1000, ite: 49054] train loss: 1.1200, accuracy: 94.2845%, tar: 0.0210 \n",
      "l0: 0.020069, l1: 0.021018, l2: 0.029578, l3: 0.045909, l4: 0.095950, l5: 0.205600, l6: 0.376151\n",
      "\n",
      "[epoch: 370/400, batch: 432/1000, ite: 49055] train loss: 1.1200, accuracy: 94.7131%, tar: 0.0210 \n",
      "l0: 0.022514, l1: 0.024035, l2: 0.033501, l3: 0.049826, l4: 0.092118, l5: 0.187803, l6: 0.369202\n",
      "\n",
      "[epoch: 370/400, batch: 440/1000, ite: 49056] train loss: 1.1201, accuracy: 94.8641%, tar: 0.0210 \n",
      "l0: 0.018631, l1: 0.019785, l2: 0.027313, l3: 0.041887, l4: 0.082228, l5: 0.190781, l6: 0.466008\n",
      "\n",
      "[epoch: 370/400, batch: 448/1000, ite: 49057] train loss: 1.1203, accuracy: 93.8885%, tar: 0.0210 \n",
      "l0: 0.022638, l1: 0.024330, l2: 0.033524, l3: 0.048568, l4: 0.096587, l5: 0.199600, l6: 0.379237\n",
      "\n",
      "[epoch: 370/400, batch: 456/1000, ite: 49058] train loss: 1.1203, accuracy: 94.6625%, tar: 0.0210 \n",
      "l0: 0.018743, l1: 0.020694, l2: 0.027650, l3: 0.039372, l4: 0.075671, l5: 0.130317, l6: 0.289822\n",
      "\n",
      "[epoch: 370/400, batch: 464/1000, ite: 49059] train loss: 1.1201, accuracy: 96.0757%, tar: 0.0210 \n",
      "l0: 0.016393, l1: 0.017823, l2: 0.024434, l3: 0.038631, l4: 0.080542, l5: 0.190994, l6: 0.385497\n",
      "\n",
      "[epoch: 370/400, batch: 472/1000, ite: 49060] train loss: 1.1201, accuracy: 95.0908%, tar: 0.0210 \n",
      "l0: 0.021804, l1: 0.022769, l2: 0.030875, l3: 0.043570, l4: 0.069297, l5: 0.135570, l6: 0.352144\n",
      "\n",
      "[epoch: 370/400, batch: 480/1000, ite: 49061] train loss: 1.1201, accuracy: 94.9014%, tar: 0.0210 \n",
      "l0: 0.016736, l1: 0.017674, l2: 0.022288, l3: 0.032397, l4: 0.058362, l5: 0.113498, l6: 0.263285\n",
      "\n",
      "[epoch: 370/400, batch: 488/1000, ite: 49062] train loss: 1.1197, accuracy: 96.2928%, tar: 0.0210 \n",
      "l0: 0.017841, l1: 0.019215, l2: 0.026988, l3: 0.040825, l4: 0.078032, l5: 0.153472, l6: 0.319019\n",
      "\n",
      "[epoch: 370/400, batch: 496/1000, ite: 49063] train loss: 1.1196, accuracy: 95.6159%, tar: 0.0210 \n",
      "l0: 0.014861, l1: 0.016661, l2: 0.027156, l3: 0.051733, l4: 0.094360, l5: 0.161057, l6: 0.277119\n",
      "\n",
      "[epoch: 370/400, batch: 504/1000, ite: 49064] train loss: 1.1194, accuracy: 96.4053%, tar: 0.0210 \n",
      "l0: 0.029326, l1: 0.031023, l2: 0.041621, l3: 0.068050, l4: 0.125106, l5: 0.248813, l6: 0.557980\n",
      "\n",
      "[epoch: 370/400, batch: 512/1000, ite: 49065] train loss: 1.1199, accuracy: 92.5045%, tar: 0.0210 \n",
      "l0: 0.022866, l1: 0.023679, l2: 0.031606, l3: 0.045696, l4: 0.072965, l5: 0.166830, l6: 0.352435\n",
      "\n",
      "[epoch: 370/400, batch: 520/1000, ite: 49066] train loss: 1.1199, accuracy: 94.5019%, tar: 0.0210 \n",
      "l0: 0.024746, l1: 0.025544, l2: 0.033941, l3: 0.049953, l4: 0.088236, l5: 0.209001, l6: 0.434533\n",
      "\n",
      "[epoch: 370/400, batch: 528/1000, ite: 49067] train loss: 1.1201, accuracy: 93.5449%, tar: 0.0210 \n",
      "l0: 0.023837, l1: 0.025469, l2: 0.033085, l3: 0.052584, l4: 0.094733, l5: 0.179597, l6: 0.336877\n",
      "\n",
      "[epoch: 370/400, batch: 536/1000, ite: 49068] train loss: 1.1200, accuracy: 94.4165%, tar: 0.0210 \n",
      "l0: 0.014206, l1: 0.015360, l2: 0.023220, l3: 0.038163, l4: 0.072548, l5: 0.140742, l6: 0.260967\n",
      "\n",
      "[epoch: 370/400, batch: 544/1000, ite: 49069] train loss: 1.1198, accuracy: 96.7761%, tar: 0.0210 \n",
      "l0: 0.022018, l1: 0.023848, l2: 0.033276, l3: 0.051754, l4: 0.105815, l5: 0.253939, l6: 0.467233\n",
      "\n",
      "[epoch: 370/400, batch: 552/1000, ite: 49070] train loss: 1.1201, accuracy: 94.6488%, tar: 0.0210 \n",
      "l0: 0.022947, l1: 0.024862, l2: 0.032227, l3: 0.047471, l4: 0.081918, l5: 0.162473, l6: 0.368136\n",
      "\n",
      "[epoch: 370/400, batch: 560/1000, ite: 49071] train loss: 1.1200, accuracy: 95.0859%, tar: 0.0210 \n",
      "l0: 0.013678, l1: 0.014320, l2: 0.018266, l3: 0.027247, l4: 0.052074, l5: 0.093050, l6: 0.199888\n",
      "\n",
      "[epoch: 370/400, batch: 568/1000, ite: 49072] train loss: 1.1196, accuracy: 96.5674%, tar: 0.0210 \n",
      "l0: 0.015362, l1: 0.016500, l2: 0.023122, l3: 0.036252, l4: 0.067064, l5: 0.138496, l6: 0.322106\n",
      "\n",
      "[epoch: 370/400, batch: 576/1000, ite: 49073] train loss: 1.1194, accuracy: 96.1093%, tar: 0.0210 \n",
      "l0: 0.015829, l1: 0.016756, l2: 0.021980, l3: 0.032114, l4: 0.066806, l5: 0.133619, l6: 0.265618\n",
      "\n",
      "[epoch: 370/400, batch: 584/1000, ite: 49074] train loss: 1.1191, accuracy: 95.9155%, tar: 0.0210 \n",
      "l0: 0.021537, l1: 0.023103, l2: 0.030880, l3: 0.047070, l4: 0.102113, l5: 0.183854, l6: 0.402360\n",
      "\n",
      "[epoch: 370/400, batch: 592/1000, ite: 49075] train loss: 1.1192, accuracy: 94.4826%, tar: 0.0210 \n",
      "l0: 0.023586, l1: 0.024808, l2: 0.034143, l3: 0.052376, l4: 0.094360, l5: 0.196679, l6: 0.534379\n",
      "\n",
      "[epoch: 370/400, batch: 600/1000, ite: 49076] train loss: 1.1196, accuracy: 93.5478%, tar: 0.0210 \n",
      "l0: 0.021517, l1: 0.022437, l2: 0.028912, l3: 0.041463, l4: 0.078418, l5: 0.147852, l6: 0.337914\n",
      "\n",
      "[epoch: 370/400, batch: 608/1000, ite: 49077] train loss: 1.1195, accuracy: 94.8458%, tar: 0.0210 \n",
      "l0: 0.018687, l1: 0.019634, l2: 0.025351, l3: 0.038839, l4: 0.067811, l5: 0.129914, l6: 0.295503\n",
      "\n",
      "[epoch: 370/400, batch: 616/1000, ite: 49078] train loss: 1.1193, accuracy: 95.3320%, tar: 0.0210 \n",
      "l0: 0.019649, l1: 0.020130, l2: 0.026934, l3: 0.039363, l4: 0.067312, l5: 0.127129, l6: 0.311878\n",
      "\n",
      "[epoch: 370/400, batch: 624/1000, ite: 49079] train loss: 1.1191, accuracy: 95.6872%, tar: 0.0210 \n",
      "l0: 0.021743, l1: 0.023440, l2: 0.034980, l3: 0.052065, l4: 0.101463, l5: 0.285218, l6: 0.504460\n",
      "\n",
      "[epoch: 370/400, batch: 632/1000, ite: 49080] train loss: 1.1195, accuracy: 93.4213%, tar: 0.0210 \n",
      "l0: 0.019470, l1: 0.020122, l2: 0.025784, l3: 0.036473, l4: 0.060462, l5: 0.107207, l6: 0.279316\n",
      "\n",
      "[epoch: 370/400, batch: 640/1000, ite: 49081] train loss: 1.1192, accuracy: 95.6525%, tar: 0.0210 \n",
      "l0: 0.019098, l1: 0.019987, l2: 0.028415, l3: 0.044234, l4: 0.083873, l5: 0.163880, l6: 0.413186\n",
      "\n",
      "[epoch: 370/400, batch: 648/1000, ite: 49082] train loss: 1.1193, accuracy: 94.9684%, tar: 0.0210 \n",
      "l0: 0.022707, l1: 0.024497, l2: 0.033034, l3: 0.053555, l4: 0.099324, l5: 0.191519, l6: 0.384650\n",
      "\n",
      "[epoch: 370/400, batch: 656/1000, ite: 49083] train loss: 1.1194, accuracy: 94.4205%, tar: 0.0210 \n",
      "l0: 0.016221, l1: 0.017377, l2: 0.022274, l3: 0.035386, l4: 0.070509, l5: 0.146918, l6: 0.345531\n",
      "\n",
      "[epoch: 370/400, batch: 664/1000, ite: 49084] train loss: 1.1193, accuracy: 96.0612%, tar: 0.0210 \n",
      "l0: 0.019641, l1: 0.021178, l2: 0.030178, l3: 0.050564, l4: 0.097144, l5: 0.210786, l6: 0.428338\n",
      "\n",
      "[epoch: 370/400, batch: 672/1000, ite: 49085] train loss: 1.1194, accuracy: 94.9780%, tar: 0.0210 \n",
      "l0: 0.020002, l1: 0.021820, l2: 0.031072, l3: 0.049483, l4: 0.092142, l5: 0.185522, l6: 0.391955\n",
      "\n",
      "[epoch: 370/400, batch: 680/1000, ite: 49086] train loss: 1.1195, accuracy: 94.4645%, tar: 0.0210 \n",
      "l0: 0.016747, l1: 0.018413, l2: 0.026928, l3: 0.040449, l4: 0.083790, l5: 0.170927, l6: 0.324492\n",
      "\n",
      "[epoch: 370/400, batch: 688/1000, ite: 49087] train loss: 1.1194, accuracy: 96.1621%, tar: 0.0210 \n",
      "l0: 0.020369, l1: 0.021490, l2: 0.029257, l3: 0.041878, l4: 0.073653, l5: 0.174360, l6: 0.348926\n",
      "\n",
      "[epoch: 370/400, batch: 696/1000, ite: 49088] train loss: 1.1193, accuracy: 95.1373%, tar: 0.0210 \n",
      "l0: 0.024528, l1: 0.025850, l2: 0.034026, l3: 0.050322, l4: 0.096731, l5: 0.187044, l6: 0.364340\n",
      "\n",
      "[epoch: 370/400, batch: 704/1000, ite: 49089] train loss: 1.1193, accuracy: 94.7255%, tar: 0.0210 \n",
      "l0: 0.019172, l1: 0.020196, l2: 0.028036, l3: 0.046541, l4: 0.092408, l5: 0.182357, l6: 0.345659\n",
      "\n",
      "[epoch: 370/400, batch: 712/1000, ite: 49090] train loss: 1.1193, accuracy: 95.0155%, tar: 0.0210 \n",
      "l0: 0.015882, l1: 0.017253, l2: 0.024980, l3: 0.041727, l4: 0.092408, l5: 0.193531, l6: 0.376957\n",
      "\n",
      "[epoch: 370/400, batch: 720/1000, ite: 49091] train loss: 1.1193, accuracy: 95.2695%, tar: 0.0210 \n",
      "l0: 0.023656, l1: 0.025496, l2: 0.035788, l3: 0.056096, l4: 0.101075, l5: 0.184884, l6: 0.388992\n",
      "\n",
      "[epoch: 370/400, batch: 728/1000, ite: 49092] train loss: 1.1194, accuracy: 94.5874%, tar: 0.0210 \n",
      "l0: 0.016944, l1: 0.018405, l2: 0.026035, l3: 0.039585, l4: 0.075829, l5: 0.135459, l6: 0.297848\n",
      "\n",
      "[epoch: 370/400, batch: 736/1000, ite: 49093] train loss: 1.1192, accuracy: 95.8955%, tar: 0.0210 \n",
      "l0: 0.018188, l1: 0.018975, l2: 0.025529, l3: 0.037940, l4: 0.076569, l5: 0.196459, l6: 0.402642\n",
      "\n",
      "[epoch: 370/400, batch: 744/1000, ite: 49094] train loss: 1.1193, accuracy: 94.7677%, tar: 0.0210 \n",
      "l0: 0.021905, l1: 0.023443, l2: 0.033355, l3: 0.053181, l4: 0.092627, l5: 0.146014, l6: 0.294603\n",
      "\n",
      "[epoch: 370/400, batch: 752/1000, ite: 49095] train loss: 1.1191, accuracy: 95.8269%, tar: 0.0210 \n",
      "l0: 0.024292, l1: 0.025494, l2: 0.033416, l3: 0.048767, l4: 0.088123, l5: 0.162647, l6: 0.345464\n",
      "\n",
      "[epoch: 370/400, batch: 760/1000, ite: 49096] train loss: 1.1191, accuracy: 95.8346%, tar: 0.0210 \n",
      "l0: 0.023077, l1: 0.026540, l2: 0.038492, l3: 0.068673, l4: 0.134676, l5: 0.275670, l6: 0.557979\n",
      "\n",
      "[epoch: 370/400, batch: 768/1000, ite: 49097] train loss: 1.1196, accuracy: 93.4245%, tar: 0.0210 \n",
      "l0: 0.024091, l1: 0.026194, l2: 0.034905, l3: 0.057222, l4: 0.106579, l5: 0.244653, l6: 0.480469\n",
      "\n",
      "[epoch: 370/400, batch: 776/1000, ite: 49098] train loss: 1.1199, accuracy: 93.7041%, tar: 0.0210 \n",
      "l0: 0.022581, l1: 0.023707, l2: 0.033583, l3: 0.046375, l4: 0.081254, l5: 0.154584, l6: 0.339437\n",
      "\n",
      "[epoch: 370/400, batch: 784/1000, ite: 49099] train loss: 1.1199, accuracy: 95.0800%, tar: 0.0210 \n",
      "l0: 0.023248, l1: 0.024597, l2: 0.033641, l3: 0.050979, l4: 0.103478, l5: 0.223687, l6: 0.359830\n",
      "\n",
      "[epoch: 370/400, batch: 792/1000, ite: 49100] train loss: 1.1199, accuracy: 94.3847%, tar: 0.0210 \n",
      "l0: 0.022035, l1: 0.023155, l2: 0.030996, l3: 0.046375, l4: 0.074479, l5: 0.146638, l6: 0.329155\n",
      "\n",
      "[epoch: 370/400, batch: 800/1000, ite: 49101] train loss: 1.1198, accuracy: 95.4511%, tar: 0.0210 \n",
      "l0: 0.018511, l1: 0.019729, l2: 0.027480, l3: 0.040876, l4: 0.075377, l5: 0.160851, l6: 0.341818\n",
      "\n",
      "[epoch: 370/400, batch: 808/1000, ite: 49102] train loss: 1.1197, accuracy: 95.6106%, tar: 0.0210 \n",
      "l0: 0.020329, l1: 0.021939, l2: 0.030643, l3: 0.046491, l4: 0.091467, l5: 0.169746, l6: 0.346540\n",
      "\n",
      "[epoch: 370/400, batch: 816/1000, ite: 49103] train loss: 1.1197, accuracy: 95.2913%, tar: 0.0210 \n",
      "l0: 0.020120, l1: 0.021219, l2: 0.028640, l3: 0.043053, l4: 0.088429, l5: 0.212243, l6: 0.459765\n",
      "\n",
      "[epoch: 370/400, batch: 824/1000, ite: 49104] train loss: 1.1199, accuracy: 94.6913%, tar: 0.0210 \n",
      "l0: 0.014043, l1: 0.014819, l2: 0.020747, l3: 0.033373, l4: 0.060489, l5: 0.111540, l6: 0.225887\n",
      "\n",
      "[epoch: 370/400, batch: 832/1000, ite: 49105] train loss: 1.1195, accuracy: 96.1973%, tar: 0.0210 \n",
      "l0: 0.023081, l1: 0.024930, l2: 0.035374, l3: 0.061098, l4: 0.107032, l5: 0.244665, l6: 0.448831\n",
      "\n",
      "[epoch: 370/400, batch: 840/1000, ite: 49106] train loss: 1.1198, accuracy: 94.1857%, tar: 0.0210 \n",
      "l0: 0.021960, l1: 0.023299, l2: 0.029630, l3: 0.045004, l4: 0.082775, l5: 0.196359, l6: 0.402859\n",
      "\n",
      "[epoch: 370/400, batch: 848/1000, ite: 49107] train loss: 1.1199, accuracy: 94.6777%, tar: 0.0210 \n",
      "l0: 0.020852, l1: 0.021745, l2: 0.029116, l3: 0.044548, l4: 0.077476, l5: 0.149616, l6: 0.329523\n",
      "\n",
      "[epoch: 370/400, batch: 856/1000, ite: 49108] train loss: 1.1198, accuracy: 95.2542%, tar: 0.0210 \n",
      "l0: 0.023450, l1: 0.024423, l2: 0.030366, l3: 0.039988, l4: 0.071537, l5: 0.154226, l6: 0.344658\n",
      "\n",
      "[epoch: 370/400, batch: 864/1000, ite: 49109] train loss: 1.1197, accuracy: 94.9072%, tar: 0.0210 \n",
      "l0: 0.021322, l1: 0.023246, l2: 0.030466, l3: 0.049537, l4: 0.080117, l5: 0.151880, l6: 0.289900\n",
      "\n",
      "[epoch: 370/400, batch: 872/1000, ite: 49110] train loss: 1.1195, accuracy: 95.9520%, tar: 0.0210 \n",
      "l0: 0.020684, l1: 0.021664, l2: 0.028819, l3: 0.044242, l4: 0.092149, l5: 0.198793, l6: 0.307577\n",
      "\n",
      "[epoch: 370/400, batch: 880/1000, ite: 49111] train loss: 1.1194, accuracy: 95.7894%, tar: 0.0210 \n",
      "l0: 0.017098, l1: 0.018728, l2: 0.028705, l3: 0.046269, l4: 0.091681, l5: 0.199481, l6: 0.352566\n",
      "\n",
      "[epoch: 370/400, batch: 888/1000, ite: 49112] train loss: 1.1194, accuracy: 95.6522%, tar: 0.0210 \n",
      "l0: 0.019772, l1: 0.021226, l2: 0.030799, l3: 0.047181, l4: 0.083666, l5: 0.184492, l6: 0.337798\n",
      "\n",
      "[epoch: 370/400, batch: 896/1000, ite: 49113] train loss: 1.1194, accuracy: 95.8492%, tar: 0.0210 \n",
      "l0: 0.026090, l1: 0.028124, l2: 0.037620, l3: 0.056621, l4: 0.100389, l5: 0.244954, l6: 0.467802\n",
      "\n",
      "[epoch: 370/400, batch: 904/1000, ite: 49114] train loss: 1.1197, accuracy: 93.8110%, tar: 0.0210 \n",
      "l0: 0.019165, l1: 0.020044, l2: 0.027598, l3: 0.041010, l4: 0.066056, l5: 0.129481, l6: 0.284135\n",
      "\n",
      "[epoch: 370/400, batch: 912/1000, ite: 49115] train loss: 1.1194, accuracy: 95.8591%, tar: 0.0210 \n",
      "l0: 0.028400, l1: 0.030035, l2: 0.038215, l3: 0.057032, l4: 0.109337, l5: 0.229020, l6: 0.424905\n",
      "\n",
      "[epoch: 370/400, batch: 920/1000, ite: 49116] train loss: 1.1196, accuracy: 93.7454%, tar: 0.0210 \n",
      "l0: 0.019876, l1: 0.020977, l2: 0.028342, l3: 0.042961, l4: 0.085618, l5: 0.182931, l6: 0.472417\n",
      "\n",
      "[epoch: 370/400, batch: 928/1000, ite: 49117] train loss: 1.1198, accuracy: 94.6390%, tar: 0.0210 \n",
      "l0: 0.020598, l1: 0.022165, l2: 0.031328, l3: 0.052437, l4: 0.118175, l5: 0.251609, l6: 0.550975\n",
      "\n",
      "[epoch: 370/400, batch: 936/1000, ite: 49118] train loss: 1.1203, accuracy: 93.6068%, tar: 0.0210 \n",
      "l0: 0.024785, l1: 0.025983, l2: 0.034450, l3: 0.055124, l4: 0.108699, l5: 0.183706, l6: 0.354721\n",
      "\n",
      "[epoch: 370/400, batch: 944/1000, ite: 49119] train loss: 1.1203, accuracy: 94.9364%, tar: 0.0210 \n",
      "l0: 0.020015, l1: 0.020671, l2: 0.026653, l3: 0.036243, l4: 0.069790, l5: 0.148875, l6: 0.309547\n",
      "\n",
      "[epoch: 370/400, batch: 952/1000, ite: 49120] train loss: 1.1201, accuracy: 95.6508%, tar: 0.0210 \n",
      "l0: 0.015339, l1: 0.016383, l2: 0.022975, l3: 0.035173, l4: 0.067577, l5: 0.129464, l6: 0.309599\n",
      "\n",
      "[epoch: 370/400, batch: 960/1000, ite: 49121] train loss: 1.1199, accuracy: 95.9517%, tar: 0.0210 \n",
      "l0: 0.021695, l1: 0.023045, l2: 0.032182, l3: 0.055668, l4: 0.120295, l5: 0.245365, l6: 0.456358\n",
      "\n",
      "[epoch: 370/400, batch: 968/1000, ite: 49122] train loss: 1.1202, accuracy: 94.1423%, tar: 0.0210 \n",
      "l0: 0.015614, l1: 0.017011, l2: 0.023955, l3: 0.036147, l4: 0.064451, l5: 0.149209, l6: 0.296863\n",
      "\n",
      "[epoch: 370/400, batch: 976/1000, ite: 49123] train loss: 1.1200, accuracy: 96.3374%, tar: 0.0210 \n",
      "l0: 0.015540, l1: 0.017142, l2: 0.024147, l3: 0.038333, l4: 0.093060, l5: 0.195390, l6: 0.367910\n",
      "\n",
      "[epoch: 370/400, batch: 984/1000, ite: 49124] train loss: 1.1200, accuracy: 95.6095%, tar: 0.0210 \n",
      "l0: 0.017055, l1: 0.017925, l2: 0.022332, l3: 0.036453, l4: 0.083901, l5: 0.168192, l6: 0.321287\n",
      "\n",
      "[epoch: 370/400, batch: 992/1000, ite: 49125] train loss: 1.1199, accuracy: 95.5701%, tar: 0.0210 \n",
      "l0: 0.023146, l1: 0.024463, l2: 0.032620, l3: 0.050848, l4: 0.092682, l5: 0.190540, l6: 0.366070\n",
      "\n",
      "[epoch: 370/400, batch: 1000/1000, ite: 49126] train loss: 1.1199, accuracy: 94.4717%, tar: 0.0210 \n",
      "l0: 0.018328, l1: 0.019791, l2: 0.027894, l3: 0.041842, l4: 0.080785, l5: 0.155759, l6: 0.326033\n",
      "\n",
      "[epoch: 371/400, batch: 8/1000, ite: 49127] train loss: 1.1198, accuracy: 95.2826%, tar: 0.0210 \n",
      "l0: 0.017281, l1: 0.018560, l2: 0.026252, l3: 0.039979, l4: 0.069948, l5: 0.134715, l6: 0.258945\n",
      "\n",
      "[epoch: 371/400, batch: 16/1000, ite: 49128] train loss: 1.1196, accuracy: 96.1777%, tar: 0.0210 \n",
      "l0: 0.018587, l1: 0.019630, l2: 0.025729, l3: 0.038147, l4: 0.076854, l5: 0.152048, l6: 0.374259\n",
      "\n",
      "[epoch: 371/400, batch: 40/1000, ite: 49131] train loss: 1.1195, accuracy: 95.1602%, tar: 0.0210 \n",
      "l0: 0.017300, l1: 0.018747, l2: 0.025419, l3: 0.044933, l4: 0.084045, l5: 0.158725, l6: 0.371905\n",
      "\n",
      "[epoch: 371/400, batch: 48/1000, ite: 49132] train loss: 1.1195, accuracy: 95.2701%, tar: 0.0210 \n",
      "l0: 0.019146, l1: 0.020306, l2: 0.025879, l3: 0.038421, l4: 0.074430, l5: 0.170569, l6: 0.344191\n",
      "\n",
      "[epoch: 371/400, batch: 56/1000, ite: 49133] train loss: 1.1194, accuracy: 95.2676%, tar: 0.0210 \n",
      "l0: 0.025141, l1: 0.026835, l2: 0.034683, l3: 0.052315, l4: 0.101574, l5: 0.204501, l6: 0.432378\n",
      "\n",
      "[epoch: 371/400, batch: 64/1000, ite: 49134] train loss: 1.1196, accuracy: 94.1637%, tar: 0.0210 \n",
      "l0: 0.015280, l1: 0.016636, l2: 0.024131, l3: 0.039668, l4: 0.070567, l5: 0.136082, l6: 0.269575\n",
      "\n",
      "[epoch: 371/400, batch: 72/1000, ite: 49135] train loss: 1.1194, accuracy: 96.3624%, tar: 0.0210 \n",
      "l0: 0.013600, l1: 0.014839, l2: 0.022347, l3: 0.036820, l4: 0.068569, l5: 0.187970, l6: 0.341493\n",
      "\n",
      "[epoch: 371/400, batch: 80/1000, ite: 49136] train loss: 1.1193, accuracy: 95.6645%, tar: 0.0210 \n",
      "l0: 0.015447, l1: 0.016559, l2: 0.025136, l3: 0.043236, l4: 0.079043, l5: 0.166198, l6: 0.335067\n",
      "\n",
      "[epoch: 371/400, batch: 88/1000, ite: 49137] train loss: 1.1192, accuracy: 95.7566%, tar: 0.0210 \n",
      "l0: 0.022952, l1: 0.024053, l2: 0.032080, l3: 0.049441, l4: 0.081707, l5: 0.142321, l6: 0.297020\n",
      "\n",
      "[epoch: 371/400, batch: 96/1000, ite: 49138] train loss: 1.1191, accuracy: 95.1650%, tar: 0.0210 \n",
      "l0: 0.022074, l1: 0.023884, l2: 0.032640, l3: 0.049541, l4: 0.095467, l5: 0.178485, l6: 0.413711\n",
      "\n",
      "[epoch: 371/400, batch: 104/1000, ite: 49139] train loss: 1.1192, accuracy: 94.4269%, tar: 0.0210 \n",
      "l0: 0.022204, l1: 0.024724, l2: 0.031198, l3: 0.052396, l4: 0.097093, l5: 0.168309, l6: 0.308253\n",
      "\n",
      "[epoch: 371/400, batch: 112/1000, ite: 49140] train loss: 1.1191, accuracy: 96.0885%, tar: 0.0210 \n",
      "l0: 0.016678, l1: 0.017411, l2: 0.023224, l3: 0.033541, l4: 0.064811, l5: 0.140962, l6: 0.270886\n",
      "\n",
      "[epoch: 371/400, batch: 120/1000, ite: 49141] train loss: 1.1188, accuracy: 96.3363%, tar: 0.0210 \n",
      "l0: 0.025961, l1: 0.027974, l2: 0.038500, l3: 0.056005, l4: 0.099099, l5: 0.224850, l6: 0.451362\n",
      "\n",
      "[epoch: 371/400, batch: 128/1000, ite: 49142] train loss: 1.1191, accuracy: 94.0869%, tar: 0.0210 \n",
      "l0: 0.021778, l1: 0.023020, l2: 0.031930, l3: 0.047685, l4: 0.089812, l5: 0.174733, l6: 0.368018\n",
      "\n",
      "[epoch: 371/400, batch: 136/1000, ite: 49143] train loss: 1.1191, accuracy: 95.2288%, tar: 0.0210 \n",
      "l0: 0.024218, l1: 0.025589, l2: 0.033821, l3: 0.049152, l4: 0.088453, l5: 0.192952, l6: 0.427099\n",
      "\n",
      "[epoch: 371/400, batch: 144/1000, ite: 49144] train loss: 1.1192, accuracy: 94.9352%, tar: 0.0210 \n",
      "l0: 0.016966, l1: 0.018767, l2: 0.028128, l3: 0.049414, l4: 0.091913, l5: 0.210537, l6: 0.410647\n",
      "\n",
      "[epoch: 371/400, batch: 152/1000, ite: 49145] train loss: 1.1193, accuracy: 95.2472%, tar: 0.0210 \n",
      "l0: 0.018339, l1: 0.019937, l2: 0.028553, l3: 0.050448, l4: 0.097104, l5: 0.195572, l6: 0.429423\n",
      "\n",
      "[epoch: 371/400, batch: 160/1000, ite: 49146] train loss: 1.1194, accuracy: 94.8231%, tar: 0.0210 \n",
      "l0: 0.019176, l1: 0.020263, l2: 0.028334, l3: 0.044138, l4: 0.083271, l5: 0.203844, l6: 0.428805\n",
      "\n",
      "[epoch: 371/400, batch: 168/1000, ite: 49147] train loss: 1.1195, accuracy: 94.5950%, tar: 0.0210 \n",
      "l0: 0.020329, l1: 0.021672, l2: 0.028480, l3: 0.043196, l4: 0.088886, l5: 0.183621, l6: 0.388338\n",
      "\n",
      "[epoch: 371/400, batch: 176/1000, ite: 49148] train loss: 1.1196, accuracy: 94.4956%, tar: 0.0210 \n",
      "l0: 0.021406, l1: 0.024170, l2: 0.036261, l3: 0.067931, l4: 0.130764, l5: 0.270128, l6: 0.551481\n",
      "\n",
      "[epoch: 371/400, batch: 184/1000, ite: 49149] train loss: 1.1200, accuracy: 94.1982%, tar: 0.0210 \n",
      "l0: 0.029101, l1: 0.031932, l2: 0.043099, l3: 0.065034, l4: 0.124364, l5: 0.242002, l6: 0.410781\n",
      "\n",
      "[epoch: 371/400, batch: 192/1000, ite: 49150] train loss: 1.1202, accuracy: 93.7570%, tar: 0.0210 \n",
      "l0: 0.017592, l1: 0.018569, l2: 0.025221, l3: 0.039489, l4: 0.069728, l5: 0.149382, l6: 0.355266\n",
      "\n",
      "[epoch: 371/400, batch: 200/1000, ite: 49151] train loss: 1.1202, accuracy: 95.3758%, tar: 0.0210 \n",
      "l0: 0.019264, l1: 0.020360, l2: 0.026691, l3: 0.037562, l4: 0.070653, l5: 0.113388, l6: 0.231037\n",
      "\n",
      "[epoch: 371/400, batch: 208/1000, ite: 49152] train loss: 1.1199, accuracy: 96.6986%, tar: 0.0210 \n",
      "l0: 0.023507, l1: 0.024819, l2: 0.032195, l3: 0.050753, l4: 0.092061, l5: 0.185268, l6: 0.383386\n",
      "\n",
      "[epoch: 371/400, batch: 216/1000, ite: 49153] train loss: 1.1199, accuracy: 94.6984%, tar: 0.0210 \n",
      "l0: 0.024143, l1: 0.025608, l2: 0.034297, l3: 0.057477, l4: 0.122482, l5: 0.231522, l6: 0.469136\n",
      "\n",
      "[epoch: 371/400, batch: 224/1000, ite: 49154] train loss: 1.1202, accuracy: 93.9584%, tar: 0.0210 \n",
      "l0: 0.021956, l1: 0.023564, l2: 0.032650, l3: 0.049190, l4: 0.096484, l5: 0.208972, l6: 0.419090\n",
      "\n",
      "[epoch: 371/400, batch: 232/1000, ite: 49155] train loss: 1.1203, accuracy: 94.1708%, tar: 0.0210 \n",
      "l0: 0.030084, l1: 0.032160, l2: 0.043398, l3: 0.066320, l4: 0.127939, l5: 0.269583, l6: 0.534864\n",
      "\n",
      "[epoch: 371/400, batch: 240/1000, ite: 49156] train loss: 1.1208, accuracy: 92.7895%, tar: 0.0210 \n",
      "l0: 0.018257, l1: 0.019956, l2: 0.028306, l3: 0.044671, l4: 0.099049, l5: 0.171355, l6: 0.351580\n",
      "\n",
      "[epoch: 371/400, batch: 248/1000, ite: 49157] train loss: 1.1207, accuracy: 95.5568%, tar: 0.0210 \n",
      "l0: 0.025491, l1: 0.027071, l2: 0.036635, l3: 0.053822, l4: 0.088189, l5: 0.185970, l6: 0.373028\n",
      "\n",
      "[epoch: 371/400, batch: 256/1000, ite: 49158] train loss: 1.1208, accuracy: 94.9329%, tar: 0.0210 \n",
      "l0: 0.019925, l1: 0.021232, l2: 0.028019, l3: 0.044095, l4: 0.072801, l5: 0.161335, l6: 0.322179\n",
      "\n",
      "[epoch: 371/400, batch: 264/1000, ite: 49159] train loss: 1.1207, accuracy: 95.3372%, tar: 0.0210 \n",
      "l0: 0.016263, l1: 0.017508, l2: 0.025865, l3: 0.038994, l4: 0.070994, l5: 0.154679, l6: 0.349474\n",
      "\n",
      "[epoch: 371/400, batch: 272/1000, ite: 49160] train loss: 1.1206, accuracy: 95.5938%, tar: 0.0210 \n",
      "l0: 0.024832, l1: 0.026331, l2: 0.034630, l3: 0.051712, l4: 0.091296, l5: 0.206606, l6: 0.471968\n",
      "\n",
      "[epoch: 371/400, batch: 280/1000, ite: 49161] train loss: 1.1208, accuracy: 93.2817%, tar: 0.0210 \n",
      "l0: 0.020183, l1: 0.020877, l2: 0.029656, l3: 0.045244, l4: 0.073463, l5: 0.138711, l6: 0.300698\n",
      "\n",
      "[epoch: 371/400, batch: 288/1000, ite: 49162] train loss: 1.1206, accuracy: 94.9641%, tar: 0.0210 \n",
      "l0: 0.013186, l1: 0.014316, l2: 0.020062, l3: 0.029538, l4: 0.048031, l5: 0.083078, l6: 0.168685\n",
      "\n",
      "[epoch: 371/400, batch: 296/1000, ite: 49163] train loss: 1.1201, accuracy: 97.3997%, tar: 0.0210 \n",
      "l0: 0.015018, l1: 0.016776, l2: 0.025800, l3: 0.043191, l4: 0.076035, l5: 0.159792, l6: 0.279027\n",
      "\n",
      "[epoch: 371/400, batch: 304/1000, ite: 49164] train loss: 1.1200, accuracy: 96.5011%, tar: 0.0210 \n",
      "l0: 0.020997, l1: 0.022976, l2: 0.034178, l3: 0.058963, l4: 0.129019, l5: 0.241946, l6: 0.479192\n",
      "\n",
      "[epoch: 371/400, batch: 312/1000, ite: 49165] train loss: 1.1203, accuracy: 95.3213%, tar: 0.0210 \n",
      "l0: 0.018011, l1: 0.018967, l2: 0.024690, l3: 0.037872, l4: 0.066313, l5: 0.136076, l6: 0.302378\n",
      "\n",
      "[epoch: 371/400, batch: 320/1000, ite: 49166] train loss: 1.1201, accuracy: 96.1310%, tar: 0.0210 \n",
      "l0: 0.021390, l1: 0.022517, l2: 0.031204, l3: 0.047644, l4: 0.088619, l5: 0.161344, l6: 0.319098\n",
      "\n",
      "[epoch: 371/400, batch: 328/1000, ite: 49167] train loss: 1.1200, accuracy: 95.2220%, tar: 0.0210 \n",
      "l0: 0.016478, l1: 0.017825, l2: 0.026630, l3: 0.042842, l4: 0.086515, l5: 0.185689, l6: 0.353813\n",
      "\n",
      "[epoch: 371/400, batch: 336/1000, ite: 49168] train loss: 1.1199, accuracy: 95.4455%, tar: 0.0210 \n",
      "l0: 0.014095, l1: 0.015320, l2: 0.021354, l3: 0.033684, l4: 0.059489, l5: 0.125085, l6: 0.284402\n",
      "\n",
      "[epoch: 371/400, batch: 344/1000, ite: 49169] train loss: 1.1197, accuracy: 95.9487%, tar: 0.0210 \n",
      "l0: 0.019274, l1: 0.021471, l2: 0.029600, l3: 0.047400, l4: 0.086128, l5: 0.168467, l6: 0.320434\n",
      "\n",
      "[epoch: 371/400, batch: 352/1000, ite: 49170] train loss: 1.1196, accuracy: 96.4119%, tar: 0.0209 \n",
      "l0: 0.018222, l1: 0.019154, l2: 0.027894, l3: 0.046206, l4: 0.089229, l5: 0.165376, l6: 0.378479\n",
      "\n",
      "[epoch: 371/400, batch: 360/1000, ite: 49171] train loss: 1.1196, accuracy: 95.4341%, tar: 0.0209 \n",
      "l0: 0.015538, l1: 0.016857, l2: 0.022263, l3: 0.035216, l4: 0.064435, l5: 0.137497, l6: 0.243533\n",
      "\n",
      "[epoch: 371/400, batch: 368/1000, ite: 49172] train loss: 1.1193, accuracy: 96.1075%, tar: 0.0209 \n",
      "l0: 0.018230, l1: 0.019222, l2: 0.026623, l3: 0.044113, l4: 0.075441, l5: 0.139239, l6: 0.284076\n",
      "\n",
      "[epoch: 371/400, batch: 376/1000, ite: 49173] train loss: 1.1192, accuracy: 96.0197%, tar: 0.0209 \n",
      "l0: 0.020644, l1: 0.021767, l2: 0.029191, l3: 0.042397, l4: 0.077085, l5: 0.166745, l6: 0.416312\n",
      "\n",
      "[epoch: 371/400, batch: 384/1000, ite: 49174] train loss: 1.1192, accuracy: 94.2502%, tar: 0.0209 \n",
      "l0: 0.017176, l1: 0.018404, l2: 0.025345, l3: 0.037041, l4: 0.067674, l5: 0.144888, l6: 0.249700\n",
      "\n",
      "[epoch: 371/400, batch: 392/1000, ite: 49175] train loss: 1.1190, accuracy: 96.4796%, tar: 0.0209 \n",
      "l0: 0.020389, l1: 0.021755, l2: 0.029257, l3: 0.045371, l4: 0.080954, l5: 0.159781, l6: 0.359748\n",
      "\n",
      "[epoch: 371/400, batch: 400/1000, ite: 49176] train loss: 1.1189, accuracy: 94.3724%, tar: 0.0209 \n",
      "l0: 0.024766, l1: 0.025804, l2: 0.035306, l3: 0.052102, l4: 0.098327, l5: 0.204562, l6: 0.449599\n",
      "\n",
      "[epoch: 371/400, batch: 408/1000, ite: 49177] train loss: 1.1191, accuracy: 93.4244%, tar: 0.0209 \n",
      "l0: 0.021591, l1: 0.023840, l2: 0.033384, l3: 0.051863, l4: 0.106215, l5: 0.226938, l6: 0.438090\n",
      "\n",
      "[epoch: 371/400, batch: 416/1000, ite: 49178] train loss: 1.1193, accuracy: 94.6669%, tar: 0.0209 \n",
      "l0: 0.021359, l1: 0.022658, l2: 0.029996, l3: 0.044725, l4: 0.078824, l5: 0.174938, l6: 0.416225\n",
      "\n",
      "[epoch: 371/400, batch: 424/1000, ite: 49179] train loss: 1.1194, accuracy: 95.0051%, tar: 0.0209 \n",
      "l0: 0.021451, l1: 0.022635, l2: 0.030746, l3: 0.045276, l4: 0.084586, l5: 0.197010, l6: 0.365672\n",
      "\n",
      "[epoch: 371/400, batch: 432/1000, ite: 49180] train loss: 1.1194, accuracy: 94.8194%, tar: 0.0209 \n",
      "l0: 0.028791, l1: 0.029892, l2: 0.038254, l3: 0.056955, l4: 0.100364, l5: 0.230303, l6: 0.495392\n",
      "\n",
      "[epoch: 371/400, batch: 440/1000, ite: 49181] train loss: 1.1197, accuracy: 93.2380%, tar: 0.0209 \n",
      "l0: 0.016448, l1: 0.017762, l2: 0.027134, l3: 0.045876, l4: 0.078724, l5: 0.137916, l6: 0.259188\n",
      "\n",
      "[epoch: 371/400, batch: 448/1000, ite: 49182] train loss: 1.1195, accuracy: 96.5867%, tar: 0.0209 \n",
      "l0: 0.022092, l1: 0.022971, l2: 0.027663, l3: 0.044604, l4: 0.079994, l5: 0.158022, l6: 0.308755\n",
      "\n",
      "[epoch: 371/400, batch: 456/1000, ite: 49183] train loss: 1.1194, accuracy: 95.4403%, tar: 0.0209 \n",
      "l0: 0.014989, l1: 0.015792, l2: 0.021754, l3: 0.032523, l4: 0.058206, l5: 0.119088, l6: 0.256944\n",
      "\n",
      "[epoch: 371/400, batch: 464/1000, ite: 49184] train loss: 1.1191, accuracy: 96.5342%, tar: 0.0209 \n",
      "l0: 0.026671, l1: 0.027729, l2: 0.035051, l3: 0.053640, l4: 0.099085, l5: 0.182502, l6: 0.354312\n",
      "\n",
      "[epoch: 371/400, batch: 472/1000, ite: 49185] train loss: 1.1191, accuracy: 94.9012%, tar: 0.0209 \n",
      "l0: 0.020085, l1: 0.022753, l2: 0.032666, l3: 0.051340, l4: 0.108747, l5: 0.266573, l6: 0.493663\n",
      "\n",
      "[epoch: 371/400, batch: 480/1000, ite: 49186] train loss: 1.1194, accuracy: 95.0359%, tar: 0.0209 \n",
      "l0: 0.020420, l1: 0.022395, l2: 0.030894, l3: 0.048271, l4: 0.102118, l5: 0.237683, l6: 0.464456\n",
      "\n",
      "[epoch: 371/400, batch: 488/1000, ite: 49187] train loss: 1.1196, accuracy: 95.0679%, tar: 0.0209 \n",
      "l0: 0.020464, l1: 0.021833, l2: 0.030563, l3: 0.047966, l4: 0.091789, l5: 0.231850, l6: 0.529024\n",
      "\n",
      "[epoch: 371/400, batch: 496/1000, ite: 49188] train loss: 1.1199, accuracy: 93.9366%, tar: 0.0209 \n",
      "l0: 0.020776, l1: 0.022561, l2: 0.031101, l3: 0.044962, l4: 0.079798, l5: 0.162976, l6: 0.322924\n",
      "\n",
      "[epoch: 371/400, batch: 504/1000, ite: 49189] train loss: 1.1199, accuracy: 95.5312%, tar: 0.0209 \n",
      "l0: 0.024720, l1: 0.025940, l2: 0.032980, l3: 0.044628, l4: 0.079789, l5: 0.183201, l6: 0.427685\n",
      "\n",
      "[epoch: 371/400, batch: 512/1000, ite: 49190] train loss: 1.1200, accuracy: 93.7043%, tar: 0.0209 \n",
      "l0: 0.025422, l1: 0.026636, l2: 0.035482, l3: 0.055001, l4: 0.111967, l5: 0.218479, l6: 0.456013\n",
      "\n",
      "[epoch: 371/400, batch: 520/1000, ite: 49191] train loss: 1.1202, accuracy: 93.2104%, tar: 0.0209 \n",
      "l0: 0.020868, l1: 0.021348, l2: 0.029020, l3: 0.041894, l4: 0.071874, l5: 0.153707, l6: 0.343730\n",
      "\n",
      "[epoch: 371/400, batch: 528/1000, ite: 49192] train loss: 1.1201, accuracy: 94.6232%, tar: 0.0209 \n",
      "l0: 0.020381, l1: 0.021263, l2: 0.029070, l3: 0.042950, l4: 0.075597, l5: 0.157908, l6: 0.330103\n",
      "\n",
      "[epoch: 371/400, batch: 536/1000, ite: 49193] train loss: 1.1200, accuracy: 95.1789%, tar: 0.0209 \n",
      "l0: 0.013964, l1: 0.014979, l2: 0.019841, l3: 0.030422, l4: 0.050245, l5: 0.092520, l6: 0.245151\n",
      "\n",
      "[epoch: 371/400, batch: 544/1000, ite: 49194] train loss: 1.1197, accuracy: 96.3938%, tar: 0.0209 \n",
      "l0: 0.020974, l1: 0.022285, l2: 0.027661, l3: 0.041972, l4: 0.079539, l5: 0.163919, l6: 0.341489\n",
      "\n",
      "[epoch: 371/400, batch: 552/1000, ite: 49195] train loss: 1.1196, accuracy: 95.4513%, tar: 0.0209 \n",
      "l0: 0.016784, l1: 0.017410, l2: 0.021382, l3: 0.031850, l4: 0.056288, l5: 0.105229, l6: 0.250441\n",
      "\n",
      "[epoch: 371/400, batch: 560/1000, ite: 49196] train loss: 1.1193, accuracy: 95.9324%, tar: 0.0209 \n",
      "l0: 0.020995, l1: 0.022142, l2: 0.030858, l3: 0.043973, l4: 0.077730, l5: 0.154269, l6: 0.335364\n",
      "\n",
      "[epoch: 371/400, batch: 568/1000, ite: 49197] train loss: 1.1192, accuracy: 95.0162%, tar: 0.0209 \n",
      "l0: 0.019783, l1: 0.020875, l2: 0.027008, l3: 0.040065, l4: 0.074982, l5: 0.148553, l6: 0.312630\n",
      "\n",
      "[epoch: 371/400, batch: 576/1000, ite: 49198] train loss: 1.1191, accuracy: 95.3684%, tar: 0.0209 \n",
      "l0: 0.022035, l1: 0.023100, l2: 0.030344, l3: 0.045968, l4: 0.103020, l5: 0.185662, l6: 0.343644\n",
      "\n",
      "[epoch: 371/400, batch: 584/1000, ite: 49199] train loss: 1.1191, accuracy: 94.8220%, tar: 0.0209 \n",
      "l0: 0.020262, l1: 0.021460, l2: 0.028968, l3: 0.043808, l4: 0.082504, l5: 0.179955, l6: 0.323938\n",
      "\n",
      "[epoch: 371/400, batch: 592/1000, ite: 49200] train loss: 1.1190, accuracy: 94.9646%, tar: 0.0209 \n",
      "l0: 0.019845, l1: 0.021107, l2: 0.027211, l3: 0.042674, l4: 0.084451, l5: 0.187814, l6: 0.292759\n",
      "\n",
      "[epoch: 371/400, batch: 600/1000, ite: 49201] train loss: 1.1189, accuracy: 95.6637%, tar: 0.0209 \n",
      "l0: 0.018329, l1: 0.019069, l2: 0.025433, l3: 0.035474, l4: 0.063478, l5: 0.112283, l6: 0.228880\n",
      "\n",
      "[epoch: 371/400, batch: 608/1000, ite: 49202] train loss: 1.1186, accuracy: 95.9337%, tar: 0.0209 \n",
      "l0: 0.023114, l1: 0.024829, l2: 0.033402, l3: 0.055256, l4: 0.106539, l5: 0.225137, l6: 0.446757\n",
      "\n",
      "[epoch: 371/400, batch: 616/1000, ite: 49203] train loss: 1.1188, accuracy: 93.9241%, tar: 0.0209 \n",
      "l0: 0.020004, l1: 0.021172, l2: 0.028073, l3: 0.041737, l4: 0.084887, l5: 0.155768, l6: 0.334570\n",
      "\n",
      "[epoch: 371/400, batch: 624/1000, ite: 49204] train loss: 1.1187, accuracy: 94.7131%, tar: 0.0209 \n",
      "l0: 0.014888, l1: 0.016733, l2: 0.024083, l3: 0.036731, l4: 0.071497, l5: 0.152921, l6: 0.279793\n",
      "\n",
      "[epoch: 371/400, batch: 632/1000, ite: 49205] train loss: 1.1185, accuracy: 96.2908%, tar: 0.0209 \n",
      "l0: 0.028931, l1: 0.030776, l2: 0.040747, l3: 0.057786, l4: 0.107658, l5: 0.258548, l6: 0.488949\n",
      "\n",
      "[epoch: 371/400, batch: 640/1000, ite: 49206] train loss: 1.1188, accuracy: 93.8419%, tar: 0.0209 \n",
      "l0: 0.020038, l1: 0.021438, l2: 0.029350, l3: 0.043090, l4: 0.080778, l5: 0.147906, l6: 0.321312\n",
      "\n",
      "[epoch: 371/400, batch: 648/1000, ite: 49207] train loss: 1.1187, accuracy: 95.3016%, tar: 0.0209 \n",
      "l0: 0.022193, l1: 0.023253, l2: 0.033408, l3: 0.050704, l4: 0.091094, l5: 0.186423, l6: 0.410832\n",
      "\n",
      "[epoch: 371/400, batch: 656/1000, ite: 49208] train loss: 1.1188, accuracy: 94.0364%, tar: 0.0209 \n",
      "l0: 0.023257, l1: 0.024403, l2: 0.033739, l3: 0.049507, l4: 0.090132, l5: 0.190019, l6: 0.424164\n",
      "\n",
      "[epoch: 371/400, batch: 664/1000, ite: 49209] train loss: 1.1189, accuracy: 93.8201%, tar: 0.0209 \n",
      "l0: 0.020786, l1: 0.021932, l2: 0.028928, l3: 0.044294, l4: 0.096391, l5: 0.231457, l6: 0.451070\n",
      "\n",
      "[epoch: 371/400, batch: 672/1000, ite: 49210] train loss: 1.1191, accuracy: 94.0091%, tar: 0.0209 \n",
      "l0: 0.020527, l1: 0.021851, l2: 0.029186, l3: 0.045333, l4: 0.081756, l5: 0.148735, l6: 0.370552\n",
      "\n",
      "[epoch: 371/400, batch: 680/1000, ite: 49211] train loss: 1.1191, accuracy: 94.8109%, tar: 0.0209 \n",
      "l0: 0.017110, l1: 0.018424, l2: 0.025591, l3: 0.036345, l4: 0.074707, l5: 0.131746, l6: 0.293925\n",
      "\n",
      "[epoch: 371/400, batch: 688/1000, ite: 49212] train loss: 1.1189, accuracy: 95.8091%, tar: 0.0209 \n",
      "l0: 0.018131, l1: 0.019527, l2: 0.026397, l3: 0.036628, l4: 0.060998, l5: 0.143142, l6: 0.328512\n",
      "\n",
      "[epoch: 371/400, batch: 696/1000, ite: 49213] train loss: 1.1188, accuracy: 95.7589%, tar: 0.0209 \n",
      "l0: 0.023753, l1: 0.026131, l2: 0.037655, l3: 0.054824, l4: 0.100935, l5: 0.210595, l6: 0.411537\n",
      "\n",
      "[epoch: 371/400, batch: 704/1000, ite: 49214] train loss: 1.1189, accuracy: 94.8840%, tar: 0.0209 \n",
      "l0: 0.023779, l1: 0.024775, l2: 0.033398, l3: 0.048201, l4: 0.082671, l5: 0.176175, l6: 0.346273\n",
      "\n",
      "[epoch: 371/400, batch: 712/1000, ite: 49215] train loss: 1.1189, accuracy: 94.7957%, tar: 0.0209 \n",
      "l0: 0.022440, l1: 0.023450, l2: 0.029941, l3: 0.044775, l4: 0.079986, l5: 0.162224, l6: 0.333887\n",
      "\n",
      "[epoch: 371/400, batch: 720/1000, ite: 49216] train loss: 1.1188, accuracy: 95.3447%, tar: 0.0209 \n",
      "l0: 0.018272, l1: 0.020930, l2: 0.033059, l3: 0.060699, l4: 0.130299, l5: 0.280146, l6: 0.453785\n",
      "\n",
      "[epoch: 371/400, batch: 728/1000, ite: 49217] train loss: 1.1191, accuracy: 93.9380%, tar: 0.0209 \n",
      "l0: 0.021425, l1: 0.023023, l2: 0.030005, l3: 0.042651, l4: 0.072600, l5: 0.161704, l6: 0.346016\n",
      "\n",
      "[epoch: 371/400, batch: 736/1000, ite: 49218] train loss: 1.1190, accuracy: 94.9547%, tar: 0.0209 \n",
      "l0: 0.019785, l1: 0.021021, l2: 0.030604, l3: 0.047483, l4: 0.085502, l5: 0.163553, l6: 0.306488\n",
      "\n",
      "[epoch: 371/400, batch: 744/1000, ite: 49219] train loss: 1.1189, accuracy: 95.8383%, tar: 0.0209 \n",
      "l0: 0.014466, l1: 0.015420, l2: 0.021543, l3: 0.031142, l4: 0.061063, l5: 0.146051, l6: 0.278393\n",
      "\n",
      "[epoch: 371/400, batch: 752/1000, ite: 49220] train loss: 1.1187, accuracy: 95.9144%, tar: 0.0209 \n",
      "l0: 0.018066, l1: 0.019523, l2: 0.028196, l3: 0.048063, l4: 0.103626, l5: 0.215610, l6: 0.326787\n",
      "\n",
      "[epoch: 371/400, batch: 760/1000, ite: 49221] train loss: 1.1187, accuracy: 95.3814%, tar: 0.0209 \n",
      "l0: 0.022999, l1: 0.024470, l2: 0.034490, l3: 0.051244, l4: 0.088845, l5: 0.176722, l6: 0.336786\n",
      "\n",
      "[epoch: 371/400, batch: 768/1000, ite: 49222] train loss: 1.1186, accuracy: 95.2332%, tar: 0.0209 \n",
      "l0: 0.023366, l1: 0.024319, l2: 0.032791, l3: 0.045540, l4: 0.081894, l5: 0.148959, l6: 0.305222\n",
      "\n",
      "[epoch: 371/400, batch: 776/1000, ite: 49223] train loss: 1.1185, accuracy: 95.4858%, tar: 0.0209 \n",
      "l0: 0.023275, l1: 0.024668, l2: 0.033470, l3: 0.051771, l4: 0.111070, l5: 0.247565, l6: 0.544248\n",
      "\n",
      "[epoch: 371/400, batch: 784/1000, ite: 49224] train loss: 1.1189, accuracy: 92.5071%, tar: 0.0209 \n",
      "l0: 0.019658, l1: 0.020063, l2: 0.025847, l3: 0.034156, l4: 0.060478, l5: 0.122023, l6: 0.288696\n",
      "\n",
      "[epoch: 371/400, batch: 792/1000, ite: 49225] train loss: 1.1187, accuracy: 95.8896%, tar: 0.0209 \n",
      "l0: 0.014703, l1: 0.016080, l2: 0.021934, l3: 0.031082, l4: 0.055642, l5: 0.119750, l6: 0.270216\n",
      "\n",
      "[epoch: 371/400, batch: 800/1000, ite: 49226] train loss: 1.1184, accuracy: 96.1848%, tar: 0.0209 \n",
      "l0: 0.019821, l1: 0.020795, l2: 0.029425, l3: 0.045737, l4: 0.081519, l5: 0.160258, l6: 0.352145\n",
      "\n",
      "[epoch: 371/400, batch: 808/1000, ite: 49227] train loss: 1.1184, accuracy: 95.5451%, tar: 0.0209 \n",
      "l0: 0.019335, l1: 0.020560, l2: 0.027785, l3: 0.040745, l4: 0.068955, l5: 0.134541, l6: 0.291206\n",
      "\n",
      "[epoch: 371/400, batch: 816/1000, ite: 49228] train loss: 1.1182, accuracy: 95.7064%, tar: 0.0209 \n",
      "l0: 0.019128, l1: 0.019935, l2: 0.027020, l3: 0.040818, l4: 0.080358, l5: 0.162257, l6: 0.334298\n",
      "\n",
      "[epoch: 371/400, batch: 824/1000, ite: 49229] train loss: 1.1181, accuracy: 95.0575%, tar: 0.0209 \n",
      "l0: 0.021877, l1: 0.022719, l2: 0.031535, l3: 0.046421, l4: 0.081975, l5: 0.214726, l6: 0.409624\n",
      "\n",
      "[epoch: 371/400, batch: 832/1000, ite: 49230] train loss: 1.1182, accuracy: 95.4841%, tar: 0.0209 \n",
      "l0: 0.021085, l1: 0.022447, l2: 0.030786, l3: 0.052213, l4: 0.101316, l5: 0.201318, l6: 0.357013\n",
      "\n",
      "[epoch: 371/400, batch: 840/1000, ite: 49231] train loss: 1.1183, accuracy: 95.5208%, tar: 0.0209 \n",
      "l0: 0.021364, l1: 0.023354, l2: 0.031444, l3: 0.047175, l4: 0.090807, l5: 0.204927, l6: 0.458631\n",
      "\n",
      "[epoch: 371/400, batch: 848/1000, ite: 49232] train loss: 1.1184, accuracy: 94.1848%, tar: 0.0209 \n",
      "l0: 0.023150, l1: 0.024913, l2: 0.034267, l3: 0.048704, l4: 0.083124, l5: 0.179877, l6: 0.364627\n",
      "\n",
      "[epoch: 371/400, batch: 856/1000, ite: 49233] train loss: 1.1184, accuracy: 94.5930%, tar: 0.0209 \n",
      "l0: 0.017278, l1: 0.018261, l2: 0.025674, l3: 0.037623, l4: 0.070391, l5: 0.182707, l6: 0.296857\n",
      "\n",
      "[epoch: 371/400, batch: 864/1000, ite: 49234] train loss: 1.1183, accuracy: 96.5800%, tar: 0.0209 \n",
      "l0: 0.021848, l1: 0.023044, l2: 0.029375, l3: 0.041107, l4: 0.069627, l5: 0.161999, l6: 0.385977\n",
      "\n",
      "[epoch: 371/400, batch: 872/1000, ite: 49235] train loss: 1.1183, accuracy: 94.9529%, tar: 0.0209 \n",
      "l0: 0.019555, l1: 0.021174, l2: 0.029640, l3: 0.046218, l4: 0.092041, l5: 0.176893, l6: 0.357390\n",
      "\n",
      "[epoch: 371/400, batch: 880/1000, ite: 49236] train loss: 1.1183, accuracy: 94.7819%, tar: 0.0209 \n",
      "l0: 0.023948, l1: 0.025906, l2: 0.035774, l3: 0.057674, l4: 0.113706, l5: 0.230390, l6: 0.459380\n",
      "\n",
      "[epoch: 371/400, batch: 888/1000, ite: 49237] train loss: 1.1185, accuracy: 93.9741%, tar: 0.0209 \n",
      "l0: 0.022594, l1: 0.023191, l2: 0.030853, l3: 0.043331, l4: 0.073808, l5: 0.158015, l6: 0.331269\n",
      "\n",
      "[epoch: 371/400, batch: 896/1000, ite: 49238] train loss: 1.1185, accuracy: 95.9198%, tar: 0.0209 \n",
      "l0: 0.017943, l1: 0.018912, l2: 0.026554, l3: 0.039551, l4: 0.086240, l5: 0.139010, l6: 0.276156\n",
      "\n",
      "[epoch: 371/400, batch: 904/1000, ite: 49239] train loss: 1.1183, accuracy: 96.1606%, tar: 0.0209 \n",
      "l0: 0.021351, l1: 0.022265, l2: 0.030618, l3: 0.049439, l4: 0.095471, l5: 0.183516, l6: 0.398772\n",
      "\n",
      "[epoch: 371/400, batch: 912/1000, ite: 49240] train loss: 1.1183, accuracy: 93.9537%, tar: 0.0209 \n",
      "l0: 0.023863, l1: 0.025951, l2: 0.034527, l3: 0.056497, l4: 0.122116, l5: 0.305811, l6: 0.603495\n",
      "\n",
      "[epoch: 371/400, batch: 920/1000, ite: 49241] train loss: 1.1189, accuracy: 92.7038%, tar: 0.0209 \n",
      "l0: 0.019378, l1: 0.021936, l2: 0.032792, l3: 0.051840, l4: 0.103207, l5: 0.252036, l6: 0.452978\n",
      "\n",
      "[epoch: 371/400, batch: 928/1000, ite: 49242] train loss: 1.1191, accuracy: 94.6381%, tar: 0.0209 \n",
      "l0: 0.012799, l1: 0.013535, l2: 0.020164, l3: 0.033177, l4: 0.062854, l5: 0.118355, l6: 0.240599\n",
      "\n",
      "[epoch: 371/400, batch: 936/1000, ite: 49243] train loss: 1.1188, accuracy: 96.5908%, tar: 0.0209 \n",
      "l0: 0.020848, l1: 0.021828, l2: 0.027274, l3: 0.038295, l4: 0.063514, l5: 0.123738, l6: 0.274179\n",
      "\n",
      "[epoch: 371/400, batch: 944/1000, ite: 49244] train loss: 1.1186, accuracy: 95.4570%, tar: 0.0209 \n",
      "l0: 0.018509, l1: 0.019709, l2: 0.027229, l3: 0.045149, l4: 0.088125, l5: 0.148321, l6: 0.266172\n",
      "\n",
      "[epoch: 371/400, batch: 952/1000, ite: 49245] train loss: 1.1184, accuracy: 96.3229%, tar: 0.0209 \n",
      "l0: 0.025718, l1: 0.027023, l2: 0.036202, l3: 0.054961, l4: 0.102253, l5: 0.214393, l6: 0.421957\n",
      "\n",
      "[epoch: 371/400, batch: 960/1000, ite: 49246] train loss: 1.1185, accuracy: 93.3535%, tar: 0.0209 \n",
      "l0: 0.019433, l1: 0.020429, l2: 0.026973, l3: 0.041227, l4: 0.074965, l5: 0.142430, l6: 0.397867\n",
      "\n",
      "[epoch: 371/400, batch: 968/1000, ite: 49247] train loss: 1.1185, accuracy: 94.6875%, tar: 0.0209 \n",
      "l0: 0.019427, l1: 0.021094, l2: 0.028385, l3: 0.047095, l4: 0.081867, l5: 0.151129, l6: 0.296260\n",
      "\n",
      "[epoch: 371/400, batch: 976/1000, ite: 49248] train loss: 1.1184, accuracy: 95.9836%, tar: 0.0209 \n",
      "l0: 0.019678, l1: 0.020520, l2: 0.027144, l3: 0.040615, l4: 0.073662, l5: 0.146737, l6: 0.322260\n",
      "\n",
      "[epoch: 371/400, batch: 984/1000, ite: 49249] train loss: 1.1183, accuracy: 95.3566%, tar: 0.0209 \n",
      "l0: 0.023763, l1: 0.026005, l2: 0.036521, l3: 0.058481, l4: 0.119417, l5: 0.272972, l6: 0.510500\n",
      "\n",
      "[epoch: 371/400, batch: 992/1000, ite: 49250] train loss: 1.1186, accuracy: 93.7301%, tar: 0.0209 \n",
      "l0: 0.019404, l1: 0.021382, l2: 0.029170, l3: 0.043248, l4: 0.084312, l5: 0.215061, l6: 0.456196\n",
      "\n",
      "[epoch: 371/400, batch: 1000/1000, ite: 49251] train loss: 1.1188, accuracy: 94.5479%, tar: 0.0209 \n",
      "l0: 0.018562, l1: 0.019227, l2: 0.026347, l3: 0.038821, l4: 0.064886, l5: 0.115606, l6: 0.215535\n",
      "\n",
      "[epoch: 372/400, batch: 8/1000, ite: 49252] train loss: 1.1185, accuracy: 96.3249%, tar: 0.0209 \n",
      "l0: 0.021086, l1: 0.022731, l2: 0.031488, l3: 0.048426, l4: 0.096569, l5: 0.220412, l6: 0.474646\n",
      "\n",
      "[epoch: 372/400, batch: 16/1000, ite: 49253] train loss: 1.1187, accuracy: 94.1709%, tar: 0.0209 \n",
      "l0: 0.021436, l1: 0.023266, l2: 0.033461, l3: 0.055281, l4: 0.144847, l5: 0.316132, l6: 0.478686\n",
      "\n",
      "[epoch: 372/400, batch: 24/1000, ite: 49254] train loss: 1.1191, accuracy: 93.2855%, tar: 0.0209 \n",
      "l0: 0.021334, l1: 0.022100, l2: 0.028492, l3: 0.038979, l4: 0.069933, l5: 0.174969, l6: 0.398435\n",
      "\n",
      "[epoch: 372/400, batch: 32/1000, ite: 49255] train loss: 1.1191, accuracy: 94.5708%, tar: 0.0209 \n",
      "l0: 0.023600, l1: 0.025017, l2: 0.033722, l3: 0.052958, l4: 0.107860, l5: 0.212456, l6: 0.445085\n",
      "\n",
      "[epoch: 372/400, batch: 40/1000, ite: 49256] train loss: 1.1193, accuracy: 93.6614%, tar: 0.0209 \n",
      "l0: 0.018024, l1: 0.019178, l2: 0.024217, l3: 0.038724, l4: 0.071981, l5: 0.148730, l6: 0.289710\n",
      "\n",
      "[epoch: 372/400, batch: 48/1000, ite: 49257] train loss: 1.1191, accuracy: 95.6539%, tar: 0.0209 \n",
      "l0: 0.021974, l1: 0.023276, l2: 0.030353, l3: 0.041253, l4: 0.070057, l5: 0.130547, l6: 0.333786\n",
      "\n",
      "[epoch: 372/400, batch: 56/1000, ite: 49258] train loss: 1.1190, accuracy: 95.0798%, tar: 0.0209 \n",
      "l0: 0.015735, l1: 0.017336, l2: 0.023836, l3: 0.039936, l4: 0.074027, l5: 0.142249, l6: 0.389760\n",
      "\n",
      "[epoch: 372/400, batch: 64/1000, ite: 49259] train loss: 1.1190, accuracy: 95.1793%, tar: 0.0209 \n",
      "l0: 0.019637, l1: 0.021302, l2: 0.027238, l3: 0.039245, l4: 0.079067, l5: 0.173207, l6: 0.313574\n",
      "\n",
      "[epoch: 372/400, batch: 72/1000, ite: 49260] train loss: 1.1189, accuracy: 95.5122%, tar: 0.0209 \n",
      "l0: 0.018190, l1: 0.019177, l2: 0.024547, l3: 0.037184, l4: 0.063543, l5: 0.117877, l6: 0.247686\n",
      "\n",
      "[epoch: 372/400, batch: 80/1000, ite: 49261] train loss: 1.1186, accuracy: 96.0456%, tar: 0.0209 \n",
      "l0: 0.018166, l1: 0.019401, l2: 0.027613, l3: 0.041444, l4: 0.080786, l5: 0.165400, l6: 0.359245\n",
      "\n",
      "[epoch: 372/400, batch: 88/1000, ite: 49262] train loss: 1.1186, accuracy: 95.5962%, tar: 0.0209 \n",
      "l0: 0.021983, l1: 0.024095, l2: 0.034253, l3: 0.057644, l4: 0.125743, l5: 0.267884, l6: 0.519849\n",
      "\n",
      "[epoch: 372/400, batch: 96/1000, ite: 49263] train loss: 1.1189, accuracy: 93.3547%, tar: 0.0209 \n",
      "l0: 0.020282, l1: 0.021823, l2: 0.030745, l3: 0.053352, l4: 0.104869, l5: 0.215171, l6: 0.400722\n",
      "\n",
      "[epoch: 372/400, batch: 104/1000, ite: 49264] train loss: 1.1190, accuracy: 95.3303%, tar: 0.0209 \n",
      "l0: 0.017957, l1: 0.019570, l2: 0.027678, l3: 0.042808, l4: 0.071271, l5: 0.169766, l6: 0.427201\n",
      "\n",
      "[epoch: 372/400, batch: 112/1000, ite: 49265] train loss: 1.1191, accuracy: 94.6199%, tar: 0.0209 \n",
      "l0: 0.016860, l1: 0.017945, l2: 0.024039, l3: 0.034201, l4: 0.058548, l5: 0.122703, l6: 0.238225\n",
      "\n",
      "[epoch: 372/400, batch: 120/1000, ite: 49266] train loss: 1.1188, accuracy: 96.1093%, tar: 0.0209 \n",
      "l0: 0.020692, l1: 0.021528, l2: 0.027432, l3: 0.042058, l4: 0.076629, l5: 0.144207, l6: 0.308090\n",
      "\n",
      "[epoch: 372/400, batch: 128/1000, ite: 49267] train loss: 1.1187, accuracy: 95.4681%, tar: 0.0209 \n",
      "l0: 0.018727, l1: 0.020141, l2: 0.028224, l3: 0.043116, l4: 0.081398, l5: 0.176215, l6: 0.379630\n",
      "\n",
      "[epoch: 372/400, batch: 136/1000, ite: 49268] train loss: 1.1187, accuracy: 95.1068%, tar: 0.0209 \n",
      "l0: 0.020853, l1: 0.022507, l2: 0.031866, l3: 0.048165, l4: 0.101460, l5: 0.204279, l6: 0.415715\n",
      "\n",
      "[epoch: 372/400, batch: 144/1000, ite: 49269] train loss: 1.1188, accuracy: 95.0273%, tar: 0.0209 \n",
      "l0: 0.023842, l1: 0.024861, l2: 0.032823, l3: 0.046889, l4: 0.086392, l5: 0.168093, l6: 0.377898\n",
      "\n",
      "[epoch: 372/400, batch: 152/1000, ite: 49270] train loss: 1.1188, accuracy: 94.6211%, tar: 0.0209 \n",
      "l0: 0.023175, l1: 0.024710, l2: 0.034914, l3: 0.052365, l4: 0.106265, l5: 0.206690, l6: 0.427672\n",
      "\n",
      "[epoch: 372/400, batch: 160/1000, ite: 49271] train loss: 1.1190, accuracy: 94.0683%, tar: 0.0209 \n",
      "l0: 0.018515, l1: 0.020409, l2: 0.027855, l3: 0.047128, l4: 0.084628, l5: 0.162892, l6: 0.343148\n",
      "\n",
      "[epoch: 372/400, batch: 168/1000, ite: 49272] train loss: 1.1189, accuracy: 95.7714%, tar: 0.0209 \n",
      "l0: 0.018720, l1: 0.019855, l2: 0.027054, l3: 0.043193, l4: 0.088290, l5: 0.190230, l6: 0.416108\n",
      "\n",
      "[epoch: 372/400, batch: 176/1000, ite: 49273] train loss: 1.1190, accuracy: 94.2082%, tar: 0.0209 \n",
      "l0: 0.018742, l1: 0.020367, l2: 0.028857, l3: 0.042575, l4: 0.071824, l5: 0.141978, l6: 0.324063\n",
      "\n",
      "[epoch: 372/400, batch: 184/1000, ite: 49274] train loss: 1.1189, accuracy: 95.4621%, tar: 0.0209 \n",
      "l0: 0.021409, l1: 0.023105, l2: 0.031896, l3: 0.048277, l4: 0.092350, l5: 0.170360, l6: 0.399562\n",
      "\n",
      "[epoch: 372/400, batch: 192/1000, ite: 49275] train loss: 1.1189, accuracy: 95.2696%, tar: 0.0209 \n",
      "l0: 0.023687, l1: 0.025427, l2: 0.034266, l3: 0.050190, l4: 0.105166, l5: 0.238973, l6: 0.453728\n",
      "\n",
      "[epoch: 372/400, batch: 200/1000, ite: 49276] train loss: 1.1192, accuracy: 93.9361%, tar: 0.0209 \n",
      "l0: 0.026275, l1: 0.027605, l2: 0.038150, l3: 0.057952, l4: 0.108098, l5: 0.215985, l6: 0.515163\n",
      "\n",
      "[epoch: 372/400, batch: 208/1000, ite: 49277] train loss: 1.1195, accuracy: 92.3062%, tar: 0.0209 \n",
      "l0: 0.020497, l1: 0.021626, l2: 0.029008, l3: 0.047342, l4: 0.084409, l5: 0.163985, l6: 0.338877\n",
      "\n",
      "[epoch: 372/400, batch: 216/1000, ite: 49278] train loss: 1.1194, accuracy: 95.0931%, tar: 0.0209 \n",
      "l0: 0.024622, l1: 0.026036, l2: 0.034269, l3: 0.051153, l4: 0.100172, l5: 0.208926, l6: 0.418957\n",
      "\n",
      "[epoch: 372/400, batch: 224/1000, ite: 49279] train loss: 1.1195, accuracy: 93.8193%, tar: 0.0209 \n",
      "l0: 0.014374, l1: 0.014807, l2: 0.019279, l3: 0.028464, l4: 0.045513, l5: 0.080125, l6: 0.199035\n",
      "\n",
      "[epoch: 372/400, batch: 232/1000, ite: 49280] train loss: 1.1191, accuracy: 96.9712%, tar: 0.0209 \n",
      "l0: 0.020042, l1: 0.021107, l2: 0.028491, l3: 0.040833, l4: 0.071631, l5: 0.139008, l6: 0.328095\n",
      "\n",
      "[epoch: 372/400, batch: 240/1000, ite: 49281] train loss: 1.1190, accuracy: 95.4272%, tar: 0.0209 \n",
      "l0: 0.024377, l1: 0.026888, l2: 0.036990, l3: 0.056809, l4: 0.112576, l5: 0.255593, l6: 0.422077\n",
      "\n",
      "[epoch: 372/400, batch: 248/1000, ite: 49282] train loss: 1.1192, accuracy: 95.1313%, tar: 0.0209 \n",
      "l0: 0.020949, l1: 0.022052, l2: 0.030035, l3: 0.045471, l4: 0.079816, l5: 0.175843, l6: 0.422066\n",
      "\n",
      "[epoch: 372/400, batch: 256/1000, ite: 49283] train loss: 1.1193, accuracy: 94.4234%, tar: 0.0209 \n",
      "l0: 0.019649, l1: 0.020618, l2: 0.028372, l3: 0.043553, l4: 0.075077, l5: 0.174703, l6: 0.321098\n",
      "\n",
      "[epoch: 372/400, batch: 264/1000, ite: 49284] train loss: 1.1192, accuracy: 95.3742%, tar: 0.0209 \n",
      "l0: 0.024471, l1: 0.025430, l2: 0.033645, l3: 0.050662, l4: 0.095204, l5: 0.196099, l6: 0.400372\n",
      "\n",
      "[epoch: 372/400, batch: 272/1000, ite: 49285] train loss: 1.1193, accuracy: 94.0631%, tar: 0.0209 \n",
      "l0: 0.017684, l1: 0.018814, l2: 0.024281, l3: 0.039383, l4: 0.074124, l5: 0.145667, l6: 0.319398\n",
      "\n",
      "[epoch: 372/400, batch: 280/1000, ite: 49286] train loss: 1.1192, accuracy: 95.3928%, tar: 0.0209 \n",
      "l0: 0.024566, l1: 0.025289, l2: 0.034026, l3: 0.053883, l4: 0.100084, l5: 0.222681, l6: 0.446787\n",
      "\n",
      "[epoch: 372/400, batch: 288/1000, ite: 49287] train loss: 1.1193, accuracy: 93.5314%, tar: 0.0209 \n",
      "l0: 0.019128, l1: 0.020004, l2: 0.025596, l3: 0.037940, l4: 0.072042, l5: 0.136740, l6: 0.301018\n",
      "\n",
      "[epoch: 372/400, batch: 296/1000, ite: 49288] train loss: 1.1192, accuracy: 95.8500%, tar: 0.0209 \n",
      "l0: 0.021522, l1: 0.022633, l2: 0.031619, l3: 0.048427, l4: 0.087823, l5: 0.158241, l6: 0.357748\n",
      "\n",
      "[epoch: 372/400, batch: 304/1000, ite: 49289] train loss: 1.1192, accuracy: 95.0309%, tar: 0.0209 \n",
      "l0: 0.023870, l1: 0.025633, l2: 0.034480, l3: 0.053841, l4: 0.106639, l5: 0.228443, l6: 0.528675\n",
      "\n",
      "[epoch: 372/400, batch: 312/1000, ite: 49290] train loss: 1.1195, accuracy: 93.8693%, tar: 0.0209 \n",
      "l0: 0.018314, l1: 0.019808, l2: 0.028624, l3: 0.046735, l4: 0.088629, l5: 0.187914, l6: 0.380435\n",
      "\n",
      "[epoch: 372/400, batch: 320/1000, ite: 49291] train loss: 1.1195, accuracy: 95.4534%, tar: 0.0209 \n",
      "l0: 0.017549, l1: 0.018673, l2: 0.028188, l3: 0.041143, l4: 0.067374, l5: 0.114735, l6: 0.258890\n",
      "\n",
      "[epoch: 372/400, batch: 328/1000, ite: 49292] train loss: 1.1193, accuracy: 96.0294%, tar: 0.0209 \n",
      "l0: 0.025954, l1: 0.027493, l2: 0.035657, l3: 0.049809, l4: 0.096955, l5: 0.188243, l6: 0.382181\n",
      "\n",
      "[epoch: 372/400, batch: 336/1000, ite: 49293] train loss: 1.1193, accuracy: 94.3444%, tar: 0.0209 \n",
      "l0: 0.020055, l1: 0.021218, l2: 0.029567, l3: 0.046396, l4: 0.097400, l5: 0.224143, l6: 0.426560\n",
      "\n",
      "[epoch: 372/400, batch: 344/1000, ite: 49294] train loss: 1.1195, accuracy: 94.3667%, tar: 0.0209 \n",
      "l0: 0.020792, l1: 0.022780, l2: 0.032641, l3: 0.053993, l4: 0.128981, l5: 0.229866, l6: 0.487605\n",
      "\n",
      "[epoch: 372/400, batch: 352/1000, ite: 49295] train loss: 1.1197, accuracy: 94.2924%, tar: 0.0209 \n",
      "l0: 0.023326, l1: 0.023982, l2: 0.031235, l3: 0.043401, l4: 0.072717, l5: 0.158310, l6: 0.320865\n",
      "\n",
      "[epoch: 372/400, batch: 360/1000, ite: 49296] train loss: 1.1196, accuracy: 95.0336%, tar: 0.0209 \n",
      "l0: 0.021763, l1: 0.023383, l2: 0.030372, l3: 0.045542, l4: 0.082666, l5: 0.199724, l6: 0.422974\n",
      "\n",
      "[epoch: 372/400, batch: 368/1000, ite: 49297] train loss: 1.1197, accuracy: 94.1544%, tar: 0.0209 \n",
      "l0: 0.019547, l1: 0.020611, l2: 0.026330, l3: 0.037777, l4: 0.060865, l5: 0.122138, l6: 0.283171\n",
      "\n",
      "[epoch: 372/400, batch: 376/1000, ite: 49298] train loss: 1.1195, accuracy: 96.1296%, tar: 0.0209 \n",
      "l0: 0.016758, l1: 0.018408, l2: 0.027632, l3: 0.049166, l4: 0.085478, l5: 0.182347, l6: 0.392018\n",
      "\n",
      "[epoch: 372/400, batch: 384/1000, ite: 49299] train loss: 1.1196, accuracy: 95.2743%, tar: 0.0209 \n",
      "l0: 0.023179, l1: 0.024676, l2: 0.034412, l3: 0.052023, l4: 0.100789, l5: 0.224337, l6: 0.432248\n",
      "\n",
      "[epoch: 372/400, batch: 392/1000, ite: 49300] train loss: 1.1197, accuracy: 93.4296%, tar: 0.0209 \n",
      "l0: 0.015782, l1: 0.016826, l2: 0.023291, l3: 0.038544, l4: 0.069648, l5: 0.142792, l6: 0.388951\n",
      "\n",
      "[epoch: 372/400, batch: 400/1000, ite: 49301] train loss: 1.1197, accuracy: 95.4022%, tar: 0.0209 \n",
      "l0: 0.019963, l1: 0.020951, l2: 0.028328, l3: 0.042198, l4: 0.077393, l5: 0.167878, l6: 0.314137\n",
      "\n",
      "[epoch: 372/400, batch: 408/1000, ite: 49302] train loss: 1.1196, accuracy: 95.8321%, tar: 0.0209 \n",
      "l0: 0.021440, l1: 0.023279, l2: 0.031170, l3: 0.047438, l4: 0.091475, l5: 0.194450, l6: 0.365962\n",
      "\n",
      "[epoch: 372/400, batch: 416/1000, ite: 49303] train loss: 1.1196, accuracy: 95.5077%, tar: 0.0209 \n",
      "l0: 0.025412, l1: 0.026770, l2: 0.035412, l3: 0.051203, l4: 0.094640, l5: 0.217205, l6: 0.463316\n",
      "\n",
      "[epoch: 372/400, batch: 424/1000, ite: 49304] train loss: 1.1198, accuracy: 93.8944%, tar: 0.0209 \n",
      "l0: 0.021116, l1: 0.024034, l2: 0.034988, l3: 0.059405, l4: 0.121750, l5: 0.241821, l6: 0.478716\n",
      "\n",
      "[epoch: 372/400, batch: 432/1000, ite: 49305] train loss: 1.1201, accuracy: 94.2011%, tar: 0.0209 \n",
      "l0: 0.015836, l1: 0.016962, l2: 0.022738, l3: 0.035205, l4: 0.066670, l5: 0.156964, l6: 0.318063\n",
      "\n",
      "[epoch: 372/400, batch: 440/1000, ite: 49306] train loss: 1.1200, accuracy: 95.4465%, tar: 0.0209 \n",
      "l0: 0.019165, l1: 0.020724, l2: 0.029923, l3: 0.049868, l4: 0.104418, l5: 0.215218, l6: 0.403855\n",
      "\n",
      "[epoch: 372/400, batch: 448/1000, ite: 49307] train loss: 1.1201, accuracy: 94.7708%, tar: 0.0209 \n",
      "l0: 0.015751, l1: 0.017341, l2: 0.024516, l3: 0.039114, l4: 0.084019, l5: 0.169880, l6: 0.351075\n",
      "\n",
      "[epoch: 372/400, batch: 456/1000, ite: 49308] train loss: 1.1200, accuracy: 95.7137%, tar: 0.0209 \n",
      "l0: 0.021786, l1: 0.023009, l2: 0.031451, l3: 0.047028, l4: 0.093724, l5: 0.162385, l6: 0.327388\n",
      "\n",
      "[epoch: 372/400, batch: 464/1000, ite: 49309] train loss: 1.1200, accuracy: 94.9948%, tar: 0.0209 \n",
      "l0: 0.019441, l1: 0.020940, l2: 0.029752, l3: 0.047503, l4: 0.087921, l5: 0.158039, l6: 0.327233\n",
      "\n",
      "[epoch: 372/400, batch: 472/1000, ite: 49310] train loss: 1.1199, accuracy: 95.1780%, tar: 0.0209 \n",
      "l0: 0.024221, l1: 0.025194, l2: 0.032612, l3: 0.047052, l4: 0.082034, l5: 0.160200, l6: 0.297306\n",
      "\n",
      "[epoch: 372/400, batch: 480/1000, ite: 49311] train loss: 1.1198, accuracy: 95.1359%, tar: 0.0209 \n",
      "l0: 0.019929, l1: 0.021773, l2: 0.028918, l3: 0.045238, l4: 0.086335, l5: 0.189324, l6: 0.423432\n",
      "\n",
      "[epoch: 372/400, batch: 488/1000, ite: 49312] train loss: 1.1199, accuracy: 95.2111%, tar: 0.0209 \n",
      "l0: 0.013791, l1: 0.015290, l2: 0.021989, l3: 0.038163, l4: 0.083677, l5: 0.188394, l6: 0.370675\n",
      "\n",
      "[epoch: 372/400, batch: 496/1000, ite: 49313] train loss: 1.1198, accuracy: 96.5348%, tar: 0.0209 \n",
      "l0: 0.012807, l1: 0.014574, l2: 0.022432, l3: 0.037332, l4: 0.068555, l5: 0.151642, l6: 0.304768\n",
      "\n",
      "[epoch: 372/400, batch: 504/1000, ite: 49314] train loss: 1.1197, accuracy: 96.4170%, tar: 0.0209 \n",
      "l0: 0.017610, l1: 0.018683, l2: 0.027185, l3: 0.045116, l4: 0.092126, l5: 0.187854, l6: 0.408297\n",
      "\n",
      "[epoch: 372/400, batch: 512/1000, ite: 49315] train loss: 1.1198, accuracy: 95.0606%, tar: 0.0209 \n",
      "l0: 0.018096, l1: 0.020119, l2: 0.028734, l3: 0.045650, l4: 0.095023, l5: 0.172594, l6: 0.312786\n",
      "\n",
      "[epoch: 372/400, batch: 520/1000, ite: 49316] train loss: 1.1197, accuracy: 95.7087%, tar: 0.0209 \n",
      "l0: 0.019749, l1: 0.020622, l2: 0.026836, l3: 0.040054, l4: 0.068365, l5: 0.145769, l6: 0.306743\n",
      "\n",
      "[epoch: 372/400, batch: 528/1000, ite: 49317] train loss: 1.1195, accuracy: 95.5073%, tar: 0.0209 \n",
      "l0: 0.019527, l1: 0.020691, l2: 0.026882, l3: 0.041030, l4: 0.070465, l5: 0.127265, l6: 0.247416\n",
      "\n",
      "[epoch: 372/400, batch: 536/1000, ite: 49318] train loss: 1.1193, accuracy: 96.0830%, tar: 0.0209 \n",
      "l0: 0.017008, l1: 0.018645, l2: 0.026688, l3: 0.045024, l4: 0.090476, l5: 0.158222, l6: 0.335599\n",
      "\n",
      "[epoch: 372/400, batch: 544/1000, ite: 49319] train loss: 1.1192, accuracy: 95.1563%, tar: 0.0209 \n",
      "l0: 0.019498, l1: 0.021266, l2: 0.033450, l3: 0.052603, l4: 0.094778, l5: 0.190389, l6: 0.379103\n",
      "\n",
      "[epoch: 372/400, batch: 552/1000, ite: 49320] train loss: 1.1193, accuracy: 95.8952%, tar: 0.0209 \n",
      "l0: 0.022929, l1: 0.024749, l2: 0.032412, l3: 0.048910, l4: 0.097533, l5: 0.231496, l6: 0.406406\n",
      "\n",
      "[epoch: 372/400, batch: 560/1000, ite: 49321] train loss: 1.1194, accuracy: 94.2151%, tar: 0.0209 \n",
      "l0: 0.021438, l1: 0.022388, l2: 0.031875, l3: 0.048313, l4: 0.084232, l5: 0.165284, l6: 0.322414\n",
      "\n",
      "[epoch: 372/400, batch: 568/1000, ite: 49322] train loss: 1.1193, accuracy: 95.4349%, tar: 0.0209 \n",
      "l0: 0.022253, l1: 0.024752, l2: 0.036209, l3: 0.061172, l4: 0.132897, l5: 0.268620, l6: 0.461559\n",
      "\n",
      "[epoch: 372/400, batch: 576/1000, ite: 49323] train loss: 1.1196, accuracy: 94.5776%, tar: 0.0209 \n",
      "l0: 0.018163, l1: 0.018946, l2: 0.025315, l3: 0.036733, l4: 0.059209, l5: 0.126068, l6: 0.287966\n",
      "\n",
      "[epoch: 372/400, batch: 584/1000, ite: 49324] train loss: 1.1194, accuracy: 95.8190%, tar: 0.0209 \n",
      "l0: 0.023088, l1: 0.024240, l2: 0.032317, l3: 0.056105, l4: 0.117474, l5: 0.239509, l6: 0.484293\n",
      "\n",
      "[epoch: 372/400, batch: 592/1000, ite: 49325] train loss: 1.1197, accuracy: 93.5082%, tar: 0.0209 \n",
      "l0: 0.017226, l1: 0.018376, l2: 0.026638, l3: 0.038380, l4: 0.066016, l5: 0.139303, l6: 0.300783\n",
      "\n",
      "[epoch: 372/400, batch: 600/1000, ite: 49326] train loss: 1.1195, accuracy: 95.5100%, tar: 0.0209 \n",
      "l0: 0.021858, l1: 0.023385, l2: 0.031350, l3: 0.047573, l4: 0.086007, l5: 0.198106, l6: 0.446264\n",
      "\n",
      "[epoch: 372/400, batch: 608/1000, ite: 49327] train loss: 1.1197, accuracy: 93.3641%, tar: 0.0209 \n",
      "l0: 0.019087, l1: 0.020025, l2: 0.027596, l3: 0.042709, l4: 0.077224, l5: 0.150583, l6: 0.286639\n",
      "\n",
      "[epoch: 372/400, batch: 616/1000, ite: 49328] train loss: 1.1195, accuracy: 95.5868%, tar: 0.0209 \n",
      "l0: 0.015662, l1: 0.016242, l2: 0.021078, l3: 0.029982, l4: 0.047101, l5: 0.084761, l6: 0.220479\n",
      "\n",
      "[epoch: 372/400, batch: 624/1000, ite: 49329] train loss: 1.1192, accuracy: 96.4918%, tar: 0.0209 \n",
      "l0: 0.020395, l1: 0.021615, l2: 0.029012, l3: 0.045245, l4: 0.085193, l5: 0.188598, l6: 0.447184\n",
      "\n",
      "[epoch: 372/400, batch: 632/1000, ite: 49330] train loss: 1.1193, accuracy: 94.1239%, tar: 0.0209 \n",
      "l0: 0.020759, l1: 0.023059, l2: 0.034089, l3: 0.061957, l4: 0.133204, l5: 0.243195, l6: 0.399076\n",
      "\n",
      "[epoch: 372/400, batch: 640/1000, ite: 49331] train loss: 1.1194, accuracy: 95.5685%, tar: 0.0209 \n",
      "l0: 0.019684, l1: 0.020753, l2: 0.027096, l3: 0.040495, l4: 0.066726, l5: 0.161095, l6: 0.336667\n",
      "\n",
      "[epoch: 372/400, batch: 648/1000, ite: 49332] train loss: 1.1193, accuracy: 95.1167%, tar: 0.0209 \n",
      "l0: 0.023816, l1: 0.025075, l2: 0.032251, l3: 0.048175, l4: 0.097941, l5: 0.221858, l6: 0.425728\n",
      "\n",
      "[epoch: 372/400, batch: 656/1000, ite: 49333] train loss: 1.1195, accuracy: 93.3955%, tar: 0.0209 \n",
      "l0: 0.021252, l1: 0.022436, l2: 0.031576, l3: 0.042751, l4: 0.075510, l5: 0.143156, l6: 0.344055\n",
      "\n",
      "[epoch: 372/400, batch: 664/1000, ite: 49334] train loss: 1.1194, accuracy: 95.2123%, tar: 0.0209 \n",
      "l0: 0.017959, l1: 0.019221, l2: 0.026675, l3: 0.044486, l4: 0.082320, l5: 0.167866, l6: 0.350373\n",
      "\n",
      "[epoch: 372/400, batch: 672/1000, ite: 49335] train loss: 1.1194, accuracy: 95.6944%, tar: 0.0209 \n",
      "l0: 0.020823, l1: 0.022113, l2: 0.030598, l3: 0.048843, l4: 0.086956, l5: 0.185162, l6: 0.343499\n",
      "\n",
      "[epoch: 372/400, batch: 680/1000, ite: 49336] train loss: 1.1193, accuracy: 95.8608%, tar: 0.0209 \n",
      "l0: 0.017712, l1: 0.019358, l2: 0.026360, l3: 0.041003, l4: 0.084984, l5: 0.171332, l6: 0.378307\n",
      "\n",
      "[epoch: 372/400, batch: 688/1000, ite: 49337] train loss: 1.1193, accuracy: 95.2233%, tar: 0.0209 \n",
      "l0: 0.016763, l1: 0.017916, l2: 0.023219, l3: 0.035500, l4: 0.071755, l5: 0.145114, l6: 0.379692\n",
      "\n",
      "[epoch: 372/400, batch: 696/1000, ite: 49338] train loss: 1.1193, accuracy: 95.0401%, tar: 0.0209 \n",
      "l0: 0.020623, l1: 0.021702, l2: 0.029107, l3: 0.044343, l4: 0.081091, l5: 0.204808, l6: 0.524272\n",
      "\n",
      "[epoch: 372/400, batch: 704/1000, ite: 49339] train loss: 1.1196, accuracy: 94.4151%, tar: 0.0209 \n",
      "l0: 0.017874, l1: 0.019059, l2: 0.027359, l3: 0.041063, l4: 0.081480, l5: 0.174300, l6: 0.321507\n",
      "\n",
      "[epoch: 372/400, batch: 712/1000, ite: 49340] train loss: 1.1195, accuracy: 95.8372%, tar: 0.0209 \n",
      "l0: 0.020015, l1: 0.021215, l2: 0.028081, l3: 0.040989, l4: 0.074472, l5: 0.168408, l6: 0.348155\n",
      "\n",
      "[epoch: 372/400, batch: 720/1000, ite: 49341] train loss: 1.1194, accuracy: 94.4867%, tar: 0.0209 \n",
      "l0: 0.014271, l1: 0.015098, l2: 0.020789, l3: 0.032252, l4: 0.056871, l5: 0.106730, l6: 0.217917\n",
      "\n",
      "[epoch: 372/400, batch: 728/1000, ite: 49342] train loss: 1.1191, accuracy: 96.7523%, tar: 0.0209 \n",
      "l0: 0.021248, l1: 0.022825, l2: 0.031991, l3: 0.051042, l4: 0.091894, l5: 0.182942, l6: 0.376128\n",
      "\n",
      "[epoch: 372/400, batch: 736/1000, ite: 49343] train loss: 1.1191, accuracy: 95.3111%, tar: 0.0209 \n",
      "l0: 0.021669, l1: 0.023301, l2: 0.033328, l3: 0.049572, l4: 0.089642, l5: 0.169420, l6: 0.345899\n",
      "\n",
      "[epoch: 372/400, batch: 744/1000, ite: 49344] train loss: 1.1191, accuracy: 95.1081%, tar: 0.0209 \n",
      "l0: 0.016326, l1: 0.017199, l2: 0.022648, l3: 0.035486, l4: 0.064929, l5: 0.138611, l6: 0.404907\n",
      "\n",
      "[epoch: 372/400, batch: 752/1000, ite: 49345] train loss: 1.1191, accuracy: 94.9056%, tar: 0.0209 \n",
      "l0: 0.023257, l1: 0.024744, l2: 0.032404, l3: 0.057149, l4: 0.102185, l5: 0.201365, l6: 0.414529\n",
      "\n",
      "[epoch: 372/400, batch: 760/1000, ite: 49346] train loss: 1.1192, accuracy: 94.7694%, tar: 0.0209 \n",
      "l0: 0.021729, l1: 0.022842, l2: 0.032108, l3: 0.049960, l4: 0.091900, l5: 0.197225, l6: 0.385877\n",
      "\n",
      "[epoch: 372/400, batch: 768/1000, ite: 49347] train loss: 1.1193, accuracy: 94.8806%, tar: 0.0209 \n",
      "l0: 0.018868, l1: 0.020069, l2: 0.026848, l3: 0.038069, l4: 0.064690, l5: 0.130245, l6: 0.304736\n",
      "\n",
      "[epoch: 372/400, batch: 776/1000, ite: 49348] train loss: 1.1191, accuracy: 95.6831%, tar: 0.0209 \n",
      "l0: 0.021856, l1: 0.022837, l2: 0.031312, l3: 0.045671, l4: 0.076543, l5: 0.134506, l6: 0.288519\n",
      "\n",
      "[epoch: 372/400, batch: 784/1000, ite: 49349] train loss: 1.1190, accuracy: 95.5812%, tar: 0.0209 \n",
      "l0: 0.012842, l1: 0.013966, l2: 0.019881, l3: 0.034036, l4: 0.078708, l5: 0.149049, l6: 0.315744\n",
      "\n",
      "[epoch: 372/400, batch: 792/1000, ite: 49350] train loss: 1.1188, accuracy: 96.1677%, tar: 0.0209 \n",
      "l0: 0.020680, l1: 0.022408, l2: 0.030604, l3: 0.046510, l4: 0.090730, l5: 0.179222, l6: 0.413743\n",
      "\n",
      "[epoch: 372/400, batch: 800/1000, ite: 49351] train loss: 1.1189, accuracy: 94.4372%, tar: 0.0209 \n",
      "l0: 0.015970, l1: 0.017222, l2: 0.022874, l3: 0.034532, l4: 0.061597, l5: 0.129042, l6: 0.299531\n",
      "\n",
      "[epoch: 372/400, batch: 808/1000, ite: 49352] train loss: 1.1187, accuracy: 96.0706%, tar: 0.0209 \n",
      "l0: 0.014613, l1: 0.015207, l2: 0.019268, l3: 0.028963, l4: 0.049833, l5: 0.075937, l6: 0.163352\n",
      "\n",
      "[epoch: 372/400, batch: 816/1000, ite: 49353] train loss: 1.1183, accuracy: 97.2901%, tar: 0.0208 \n",
      "l0: 0.020929, l1: 0.022667, l2: 0.031143, l3: 0.046021, l4: 0.078772, l5: 0.181456, l6: 0.358886\n",
      "\n",
      "[epoch: 372/400, batch: 824/1000, ite: 49354] train loss: 1.1183, accuracy: 94.9926%, tar: 0.0208 \n",
      "l0: 0.019283, l1: 0.020563, l2: 0.027257, l3: 0.050667, l4: 0.089827, l5: 0.199325, l6: 0.388613\n",
      "\n",
      "[epoch: 372/400, batch: 832/1000, ite: 49355] train loss: 1.1183, accuracy: 95.0311%, tar: 0.0208 \n",
      "l0: 0.020335, l1: 0.020981, l2: 0.027415, l3: 0.040653, l4: 0.067152, l5: 0.122441, l6: 0.238904\n",
      "\n",
      "[epoch: 372/400, batch: 840/1000, ite: 49356] train loss: 1.1181, accuracy: 95.9933%, tar: 0.0208 \n",
      "l0: 0.022006, l1: 0.023303, l2: 0.032548, l3: 0.046938, l4: 0.080443, l5: 0.158354, l6: 0.280944\n",
      "\n",
      "[epoch: 372/400, batch: 848/1000, ite: 49357] train loss: 1.1180, accuracy: 95.3801%, tar: 0.0208 \n",
      "l0: 0.021920, l1: 0.022967, l2: 0.030423, l3: 0.045760, l4: 0.080182, l5: 0.162120, l6: 0.343192\n",
      "\n",
      "[epoch: 372/400, batch: 856/1000, ite: 49358] train loss: 1.1179, accuracy: 94.9145%, tar: 0.0208 \n",
      "l0: 0.016270, l1: 0.017635, l2: 0.027099, l3: 0.048717, l4: 0.097961, l5: 0.206081, l6: 0.383045\n",
      "\n",
      "[epoch: 372/400, batch: 864/1000, ite: 49359] train loss: 1.1179, accuracy: 95.4488%, tar: 0.0208 \n",
      "l0: 0.022601, l1: 0.024007, l2: 0.033272, l3: 0.049023, l4: 0.097628, l5: 0.251583, l6: 0.459040\n",
      "\n",
      "[epoch: 372/400, batch: 872/1000, ite: 49360] train loss: 1.1182, accuracy: 93.7904%, tar: 0.0208 \n",
      "l0: 0.021385, l1: 0.022135, l2: 0.028814, l3: 0.044333, l4: 0.087658, l5: 0.204509, l6: 0.393314\n",
      "\n",
      "[epoch: 372/400, batch: 880/1000, ite: 49361] train loss: 1.1182, accuracy: 94.7782%, tar: 0.0208 \n",
      "l0: 0.019177, l1: 0.019985, l2: 0.028557, l3: 0.043893, l4: 0.083028, l5: 0.175049, l6: 0.383361\n",
      "\n",
      "[epoch: 372/400, batch: 888/1000, ite: 49362] train loss: 1.1182, accuracy: 95.0183%, tar: 0.0208 \n",
      "l0: 0.020039, l1: 0.021057, l2: 0.029527, l3: 0.045283, l4: 0.086677, l5: 0.158445, l6: 0.301923\n",
      "\n",
      "[epoch: 372/400, batch: 896/1000, ite: 49363] train loss: 1.1181, accuracy: 95.6918%, tar: 0.0208 \n",
      "l0: 0.018626, l1: 0.019902, l2: 0.028732, l3: 0.045092, l4: 0.079221, l5: 0.134934, l6: 0.286426\n",
      "\n",
      "[epoch: 372/400, batch: 904/1000, ite: 49364] train loss: 1.1180, accuracy: 96.0873%, tar: 0.0208 \n",
      "l0: 0.028311, l1: 0.030529, l2: 0.040013, l3: 0.061315, l4: 0.113636, l5: 0.229262, l6: 0.438123\n",
      "\n",
      "[epoch: 372/400, batch: 912/1000, ite: 49365] train loss: 1.1182, accuracy: 93.8283%, tar: 0.0208 \n",
      "l0: 0.021236, l1: 0.022265, l2: 0.030160, l3: 0.043249, l4: 0.072022, l5: 0.161008, l6: 0.274465\n",
      "\n",
      "[epoch: 372/400, batch: 920/1000, ite: 49366] train loss: 1.1180, accuracy: 96.0757%, tar: 0.0208 \n",
      "l0: 0.017426, l1: 0.018440, l2: 0.024686, l3: 0.035984, l4: 0.063794, l5: 0.128113, l6: 0.271828\n",
      "\n",
      "[epoch: 372/400, batch: 928/1000, ite: 49367] train loss: 1.1178, accuracy: 95.6708%, tar: 0.0208 \n",
      "l0: 0.021225, l1: 0.022734, l2: 0.030797, l3: 0.043339, l4: 0.080809, l5: 0.220650, l6: 0.440497\n",
      "\n",
      "[epoch: 372/400, batch: 936/1000, ite: 49368] train loss: 1.1179, accuracy: 94.2692%, tar: 0.0208 \n",
      "l0: 0.021931, l1: 0.023130, l2: 0.031059, l3: 0.046386, l4: 0.073506, l5: 0.145577, l6: 0.288773\n",
      "\n",
      "[epoch: 372/400, batch: 944/1000, ite: 49369] train loss: 1.1178, accuracy: 95.2468%, tar: 0.0208 \n",
      "l0: 0.017916, l1: 0.019262, l2: 0.027398, l3: 0.042713, l4: 0.076535, l5: 0.144177, l6: 0.331924\n",
      "\n",
      "[epoch: 372/400, batch: 952/1000, ite: 49370] train loss: 1.1177, accuracy: 95.5233%, tar: 0.0208 \n",
      "l0: 0.016490, l1: 0.017685, l2: 0.023704, l3: 0.038809, l4: 0.081709, l5: 0.154261, l6: 0.336403\n",
      "\n",
      "[epoch: 372/400, batch: 960/1000, ite: 49371] train loss: 1.1176, accuracy: 95.6210%, tar: 0.0208 \n",
      "l0: 0.016265, l1: 0.017864, l2: 0.025149, l3: 0.037800, l4: 0.079816, l5: 0.173918, l6: 0.379570\n",
      "\n",
      "[epoch: 372/400, batch: 968/1000, ite: 49372] train loss: 1.1176, accuracy: 96.0572%, tar: 0.0208 \n",
      "l0: 0.021879, l1: 0.024390, l2: 0.032010, l3: 0.047688, l4: 0.090289, l5: 0.180043, l6: 0.451788\n",
      "\n",
      "[epoch: 372/400, batch: 976/1000, ite: 49373] train loss: 1.1177, accuracy: 95.0165%, tar: 0.0208 \n",
      "l0: 0.029946, l1: 0.031827, l2: 0.042578, l3: 0.065964, l4: 0.116067, l5: 0.238074, l6: 0.481469\n",
      "\n",
      "[epoch: 372/400, batch: 984/1000, ite: 49374] train loss: 1.1180, accuracy: 93.6155%, tar: 0.0208 \n",
      "l0: 0.027901, l1: 0.030163, l2: 0.039006, l3: 0.061000, l4: 0.115686, l5: 0.208771, l6: 0.417043\n",
      "\n",
      "[epoch: 372/400, batch: 992/1000, ite: 49375] train loss: 1.1182, accuracy: 94.1857%, tar: 0.0208 \n",
      "l0: 0.028520, l1: 0.030269, l2: 0.038781, l3: 0.057954, l4: 0.124358, l5: 0.221181, l6: 0.426972\n",
      "\n",
      "[epoch: 372/400, batch: 1000/1000, ite: 49376] train loss: 1.1183, accuracy: 94.4579%, tar: 0.0209 \n",
      "l0: 0.020295, l1: 0.021092, l2: 0.029179, l3: 0.045710, l4: 0.081560, l5: 0.187791, l6: 0.364418\n",
      "\n",
      "[epoch: 373/400, batch: 8/1000, ite: 49377] train loss: 1.1183, accuracy: 94.7102%, tar: 0.0209 \n",
      "l0: 0.024217, l1: 0.025834, l2: 0.034215, l3: 0.050906, l4: 0.100997, l5: 0.238482, l6: 0.626607\n",
      "\n",
      "[epoch: 373/400, batch: 16/1000, ite: 49378] train loss: 1.1188, accuracy: 92.8348%, tar: 0.0209 \n",
      "l0: 0.023520, l1: 0.025304, l2: 0.034594, l3: 0.054058, l4: 0.099997, l5: 0.229209, l6: 0.515696\n",
      "\n",
      "[epoch: 373/400, batch: 24/1000, ite: 49379] train loss: 1.1191, accuracy: 93.8083%, tar: 0.0209 \n",
      "l0: 0.016853, l1: 0.017458, l2: 0.023442, l3: 0.033060, l4: 0.054146, l5: 0.098463, l6: 0.239811\n",
      "\n",
      "[epoch: 373/400, batch: 32/1000, ite: 49380] train loss: 1.1188, accuracy: 95.8941%, tar: 0.0209 \n",
      "l0: 0.018584, l1: 0.020392, l2: 0.027612, l3: 0.040766, l4: 0.078151, l5: 0.156274, l6: 0.300451\n",
      "\n",
      "[epoch: 373/400, batch: 40/1000, ite: 49381] train loss: 1.1187, accuracy: 95.8543%, tar: 0.0209 \n",
      "l0: 0.023547, l1: 0.024794, l2: 0.032152, l3: 0.052863, l4: 0.105903, l5: 0.223439, l6: 0.497613\n",
      "\n",
      "[epoch: 373/400, batch: 48/1000, ite: 49382] train loss: 1.1189, accuracy: 93.3363%, tar: 0.0209 \n",
      "l0: 0.021963, l1: 0.023404, l2: 0.033936, l3: 0.050231, l4: 0.090570, l5: 0.226094, l6: 0.441370\n",
      "\n",
      "[epoch: 373/400, batch: 56/1000, ite: 49383] train loss: 1.1191, accuracy: 94.2568%, tar: 0.0209 \n",
      "l0: 0.020621, l1: 0.021810, l2: 0.029063, l3: 0.047356, l4: 0.083832, l5: 0.188161, l6: 0.398155\n",
      "\n",
      "[epoch: 373/400, batch: 64/1000, ite: 49384] train loss: 1.1191, accuracy: 93.9343%, tar: 0.0209 \n",
      "l0: 0.018506, l1: 0.020079, l2: 0.029271, l3: 0.043987, l4: 0.084957, l5: 0.178517, l6: 0.335702\n",
      "\n",
      "[epoch: 373/400, batch: 72/1000, ite: 49385] train loss: 1.1191, accuracy: 95.6129%, tar: 0.0209 \n",
      "l0: 0.022772, l1: 0.024694, l2: 0.032280, l3: 0.045364, l4: 0.075361, l5: 0.140810, l6: 0.274094\n",
      "\n",
      "[epoch: 373/400, batch: 80/1000, ite: 49386] train loss: 1.1189, accuracy: 95.7786%, tar: 0.0209 \n",
      "l0: 0.017105, l1: 0.018372, l2: 0.025160, l3: 0.040301, l4: 0.072159, l5: 0.128211, l6: 0.264658\n",
      "\n",
      "[epoch: 373/400, batch: 88/1000, ite: 49387] train loss: 1.1187, accuracy: 96.0486%, tar: 0.0209 \n",
      "l0: 0.017580, l1: 0.018659, l2: 0.024736, l3: 0.035934, l4: 0.069341, l5: 0.139231, l6: 0.360832\n",
      "\n",
      "[epoch: 373/400, batch: 96/1000, ite: 49388] train loss: 1.1186, accuracy: 95.4351%, tar: 0.0209 \n",
      "l0: 0.024082, l1: 0.026003, l2: 0.037703, l3: 0.056387, l4: 0.113843, l5: 0.270233, l6: 0.523321\n",
      "\n",
      "[epoch: 373/400, batch: 104/1000, ite: 49389] train loss: 1.1190, accuracy: 93.1038%, tar: 0.0209 \n",
      "l0: 0.018794, l1: 0.020139, l2: 0.027584, l3: 0.041686, l4: 0.069904, l5: 0.146409, l6: 0.325807\n",
      "\n",
      "[epoch: 373/400, batch: 112/1000, ite: 49390] train loss: 1.1189, accuracy: 95.1718%, tar: 0.0209 \n",
      "l0: 0.020472, l1: 0.021860, l2: 0.029853, l3: 0.040392, l4: 0.071184, l5: 0.163261, l6: 0.337941\n",
      "\n",
      "[epoch: 373/400, batch: 120/1000, ite: 49391] train loss: 1.1188, accuracy: 95.0537%, tar: 0.0209 \n",
      "l0: 0.020895, l1: 0.022185, l2: 0.031760, l3: 0.048805, l4: 0.091034, l5: 0.219974, l6: 0.401432\n",
      "\n",
      "[epoch: 373/400, batch: 128/1000, ite: 49392] train loss: 1.1189, accuracy: 94.2767%, tar: 0.0209 \n",
      "l0: 0.018898, l1: 0.020909, l2: 0.030543, l3: 0.047739, l4: 0.080355, l5: 0.146327, l6: 0.336881\n",
      "\n",
      "[epoch: 373/400, batch: 136/1000, ite: 49393] train loss: 1.1188, accuracy: 95.6866%, tar: 0.0209 \n",
      "l0: 0.015513, l1: 0.016491, l2: 0.022951, l3: 0.035432, l4: 0.068985, l5: 0.114532, l6: 0.222178\n",
      "\n",
      "[epoch: 373/400, batch: 144/1000, ite: 49394] train loss: 1.1185, accuracy: 96.4794%, tar: 0.0208 \n",
      "l0: 0.018315, l1: 0.020551, l2: 0.032716, l3: 0.056668, l4: 0.103871, l5: 0.191306, l6: 0.349862\n",
      "\n",
      "[epoch: 373/400, batch: 152/1000, ite: 49395] train loss: 1.1185, accuracy: 95.7648%, tar: 0.0208 \n",
      "l0: 0.022036, l1: 0.023565, l2: 0.031595, l3: 0.047785, l4: 0.091794, l5: 0.203330, l6: 0.364039\n",
      "\n",
      "[epoch: 373/400, batch: 160/1000, ite: 49396] train loss: 1.1186, accuracy: 95.0649%, tar: 0.0208 \n",
      "l0: 0.018625, l1: 0.019969, l2: 0.027274, l3: 0.043683, l4: 0.083290, l5: 0.161628, l6: 0.326123\n",
      "\n",
      "[epoch: 373/400, batch: 168/1000, ite: 49397] train loss: 1.1185, accuracy: 95.6746%, tar: 0.0208 \n",
      "l0: 0.017813, l1: 0.019095, l2: 0.026079, l3: 0.036969, l4: 0.071790, l5: 0.123950, l6: 0.246928\n",
      "\n",
      "[epoch: 373/400, batch: 176/1000, ite: 49398] train loss: 1.1182, accuracy: 96.4767%, tar: 0.0208 \n",
      "l0: 0.019662, l1: 0.021134, l2: 0.028683, l3: 0.042888, l4: 0.076455, l5: 0.154066, l6: 0.384699\n",
      "\n",
      "[epoch: 373/400, batch: 184/1000, ite: 49399] train loss: 1.1182, accuracy: 94.8569%, tar: 0.0208 \n",
      "l0: 0.017213, l1: 0.018843, l2: 0.028556, l3: 0.044010, l4: 0.088196, l5: 0.191077, l6: 0.370027\n",
      "\n",
      "[epoch: 373/400, batch: 192/1000, ite: 49400] train loss: 1.1183, accuracy: 94.6899%, tar: 0.0208 \n",
      "l0: 0.019600, l1: 0.021658, l2: 0.031513, l3: 0.052958, l4: 0.103383, l5: 0.242851, l6: 0.504008\n",
      "\n",
      "[epoch: 373/400, batch: 200/1000, ite: 49401] train loss: 1.1185, accuracy: 93.4765%, tar: 0.0208 \n",
      "l0: 0.014855, l1: 0.016869, l2: 0.026350, l3: 0.044631, l4: 0.114346, l5: 0.223944, l6: 0.383273\n",
      "\n",
      "[epoch: 373/400, batch: 208/1000, ite: 49402] train loss: 1.1186, accuracy: 95.7983%, tar: 0.0208 \n",
      "l0: 0.019065, l1: 0.020922, l2: 0.029706, l3: 0.048062, l4: 0.084510, l5: 0.170017, l6: 0.358501\n",
      "\n",
      "[epoch: 373/400, batch: 216/1000, ite: 49403] train loss: 1.1186, accuracy: 95.5708%, tar: 0.0208 \n",
      "l0: 0.021924, l1: 0.023829, l2: 0.034281, l3: 0.052971, l4: 0.091130, l5: 0.207972, l6: 0.429484\n",
      "\n",
      "[epoch: 373/400, batch: 224/1000, ite: 49404] train loss: 1.1187, accuracy: 94.8466%, tar: 0.0208 \n",
      "l0: 0.021210, l1: 0.022460, l2: 0.029495, l3: 0.043132, l4: 0.073932, l5: 0.132244, l6: 0.302726\n",
      "\n",
      "[epoch: 373/400, batch: 232/1000, ite: 49405] train loss: 1.1186, accuracy: 95.4193%, tar: 0.0208 \n",
      "l0: 0.015875, l1: 0.016886, l2: 0.024291, l3: 0.035901, l4: 0.057168, l5: 0.105771, l6: 0.244108\n",
      "\n",
      "[epoch: 373/400, batch: 240/1000, ite: 49406] train loss: 1.1183, accuracy: 96.3683%, tar: 0.0208 \n",
      "l0: 0.019782, l1: 0.021499, l2: 0.028040, l3: 0.041036, l4: 0.071725, l5: 0.144621, l6: 0.315608\n",
      "\n",
      "[epoch: 373/400, batch: 248/1000, ite: 49407] train loss: 1.1182, accuracy: 95.4651%, tar: 0.0208 \n",
      "l0: 0.015230, l1: 0.016438, l2: 0.022035, l3: 0.035334, l4: 0.068347, l5: 0.134866, l6: 0.327900\n",
      "\n",
      "[epoch: 373/400, batch: 256/1000, ite: 49408] train loss: 1.1181, accuracy: 95.8780%, tar: 0.0208 \n",
      "l0: 0.025253, l1: 0.026474, l2: 0.034180, l3: 0.051353, l4: 0.096311, l5: 0.195537, l6: 0.436068\n",
      "\n",
      "[epoch: 373/400, batch: 264/1000, ite: 49409] train loss: 1.1182, accuracy: 94.1241%, tar: 0.0208 \n",
      "l0: 0.024334, l1: 0.027071, l2: 0.039790, l3: 0.060009, l4: 0.103090, l5: 0.198161, l6: 0.422889\n",
      "\n",
      "[epoch: 373/400, batch: 272/1000, ite: 49410] train loss: 1.1183, accuracy: 95.2521%, tar: 0.0208 \n",
      "l0: 0.017496, l1: 0.019545, l2: 0.027129, l3: 0.042604, l4: 0.092582, l5: 0.205224, l6: 0.400742\n",
      "\n",
      "[epoch: 373/400, batch: 280/1000, ite: 49411] train loss: 1.1184, accuracy: 95.0745%, tar: 0.0208 \n",
      "l0: 0.013965, l1: 0.014960, l2: 0.020714, l3: 0.034255, l4: 0.078985, l5: 0.169008, l6: 0.326475\n",
      "\n",
      "[epoch: 373/400, batch: 288/1000, ite: 49412] train loss: 1.1183, accuracy: 95.6361%, tar: 0.0208 \n",
      "l0: 0.018250, l1: 0.019933, l2: 0.029855, l3: 0.050921, l4: 0.103936, l5: 0.195385, l6: 0.400842\n",
      "\n",
      "[epoch: 373/400, batch: 296/1000, ite: 49413] train loss: 1.1184, accuracy: 95.3057%, tar: 0.0208 \n",
      "l0: 0.016267, l1: 0.017295, l2: 0.023346, l3: 0.037605, l4: 0.085645, l5: 0.139793, l6: 0.276735\n",
      "\n",
      "[epoch: 373/400, batch: 304/1000, ite: 49414] train loss: 1.1182, accuracy: 96.2920%, tar: 0.0208 \n",
      "l0: 0.026555, l1: 0.027548, l2: 0.036018, l3: 0.050351, l4: 0.077911, l5: 0.141317, l6: 0.304588\n",
      "\n",
      "[epoch: 373/400, batch: 312/1000, ite: 49415] train loss: 1.1181, accuracy: 94.9259%, tar: 0.0208 \n",
      "l0: 0.031839, l1: 0.034345, l2: 0.044162, l3: 0.066516, l4: 0.133937, l5: 0.310087, l6: 0.542488\n",
      "\n",
      "[epoch: 373/400, batch: 320/1000, ite: 49416] train loss: 1.1185, accuracy: 93.1230%, tar: 0.0208 \n",
      "l0: 0.025753, l1: 0.026704, l2: 0.033485, l3: 0.047580, l4: 0.081405, l5: 0.174810, l6: 0.384371\n",
      "\n",
      "[epoch: 373/400, batch: 328/1000, ite: 49417] train loss: 1.1185, accuracy: 94.5812%, tar: 0.0208 \n",
      "l0: 0.026996, l1: 0.028176, l2: 0.036209, l3: 0.052662, l4: 0.093939, l5: 0.191779, l6: 0.381274\n",
      "\n",
      "[epoch: 373/400, batch: 336/1000, ite: 49418] train loss: 1.1186, accuracy: 93.5115%, tar: 0.0208 \n",
      "l0: 0.018888, l1: 0.019759, l2: 0.025539, l3: 0.039065, l4: 0.069469, l5: 0.154212, l6: 0.363732\n",
      "\n",
      "[epoch: 373/400, batch: 344/1000, ite: 49419] train loss: 1.1186, accuracy: 95.2973%, tar: 0.0208 \n",
      "l0: 0.018282, l1: 0.019010, l2: 0.025850, l3: 0.037022, l4: 0.061758, l5: 0.103643, l6: 0.221152\n",
      "\n",
      "[epoch: 373/400, batch: 352/1000, ite: 49420] train loss: 1.1183, accuracy: 96.2002%, tar: 0.0208 \n",
      "l0: 0.018110, l1: 0.018974, l2: 0.024262, l3: 0.034569, l4: 0.062228, l5: 0.125598, l6: 0.265174\n",
      "\n",
      "[epoch: 373/400, batch: 360/1000, ite: 49421] train loss: 1.1181, accuracy: 95.9105%, tar: 0.0208 \n",
      "l0: 0.017940, l1: 0.019199, l2: 0.026493, l3: 0.037929, l4: 0.072327, l5: 0.136863, l6: 0.253700\n",
      "\n",
      "[epoch: 373/400, batch: 368/1000, ite: 49422] train loss: 1.1178, accuracy: 95.9363%, tar: 0.0208 \n",
      "l0: 0.018236, l1: 0.019584, l2: 0.030045, l3: 0.046258, l4: 0.081687, l5: 0.158567, l6: 0.350000\n",
      "\n",
      "[epoch: 373/400, batch: 376/1000, ite: 49423] train loss: 1.1178, accuracy: 95.8326%, tar: 0.0208 \n",
      "l0: 0.019077, l1: 0.020285, l2: 0.028727, l3: 0.051924, l4: 0.093808, l5: 0.162294, l6: 0.322852\n",
      "\n",
      "[epoch: 373/400, batch: 384/1000, ite: 49424] train loss: 1.1177, accuracy: 95.3256%, tar: 0.0208 \n",
      "l0: 0.017479, l1: 0.019608, l2: 0.026611, l3: 0.038051, l4: 0.073830, l5: 0.153621, l6: 0.366948\n",
      "\n",
      "[epoch: 373/400, batch: 392/1000, ite: 49425] train loss: 1.1177, accuracy: 94.9505%, tar: 0.0208 \n",
      "l0: 0.020025, l1: 0.020861, l2: 0.026563, l3: 0.036573, l4: 0.064227, l5: 0.121404, l6: 0.274858\n",
      "\n",
      "[epoch: 373/400, batch: 400/1000, ite: 49426] train loss: 1.1175, accuracy: 95.4641%, tar: 0.0208 \n",
      "l0: 0.019698, l1: 0.020569, l2: 0.029537, l3: 0.043493, l4: 0.070532, l5: 0.144458, l6: 0.321386\n",
      "\n",
      "[epoch: 373/400, batch: 408/1000, ite: 49427] train loss: 1.1174, accuracy: 95.2118%, tar: 0.0208 \n",
      "l0: 0.016205, l1: 0.017490, l2: 0.024896, l3: 0.045064, l4: 0.081682, l5: 0.170278, l6: 0.342955\n",
      "\n",
      "[epoch: 373/400, batch: 416/1000, ite: 49428] train loss: 1.1174, accuracy: 95.7425%, tar: 0.0208 \n",
      "l0: 0.017385, l1: 0.018211, l2: 0.023562, l3: 0.035734, l4: 0.060313, l5: 0.124906, l6: 0.271197\n",
      "\n",
      "[epoch: 373/400, batch: 424/1000, ite: 49429] train loss: 1.1171, accuracy: 96.0278%, tar: 0.0208 \n",
      "l0: 0.021872, l1: 0.022342, l2: 0.026951, l3: 0.035656, l4: 0.053040, l5: 0.095645, l6: 0.262553\n",
      "\n",
      "[epoch: 373/400, batch: 432/1000, ite: 49430] train loss: 1.1169, accuracy: 95.4002%, tar: 0.0208 \n",
      "l0: 0.019492, l1: 0.020428, l2: 0.027727, l3: 0.042084, l4: 0.082049, l5: 0.192360, l6: 0.343392\n",
      "\n",
      "[epoch: 373/400, batch: 440/1000, ite: 49431] train loss: 1.1169, accuracy: 94.6646%, tar: 0.0208 \n",
      "l0: 0.016012, l1: 0.016774, l2: 0.023052, l3: 0.034937, l4: 0.074504, l5: 0.146247, l6: 0.310167\n",
      "\n",
      "[epoch: 373/400, batch: 448/1000, ite: 49432] train loss: 1.1168, accuracy: 96.1140%, tar: 0.0208 \n",
      "l0: 0.023084, l1: 0.025412, l2: 0.035213, l3: 0.059560, l4: 0.121351, l5: 0.234887, l6: 0.398380\n",
      "\n",
      "[epoch: 373/400, batch: 456/1000, ite: 49433] train loss: 1.1169, accuracy: 95.6536%, tar: 0.0208 \n",
      "l0: 0.026644, l1: 0.027835, l2: 0.036222, l3: 0.052116, l4: 0.094213, l5: 0.214768, l6: 0.504498\n",
      "\n",
      "[epoch: 373/400, batch: 464/1000, ite: 49434] train loss: 1.1171, accuracy: 93.2188%, tar: 0.0208 \n",
      "l0: 0.021448, l1: 0.022603, l2: 0.030181, l3: 0.048507, l4: 0.094638, l5: 0.196797, l6: 0.371448\n",
      "\n",
      "[epoch: 373/400, batch: 472/1000, ite: 49435] train loss: 1.1172, accuracy: 94.8772%, tar: 0.0208 \n",
      "l0: 0.021029, l1: 0.022018, l2: 0.029740, l3: 0.043072, l4: 0.081880, l5: 0.166502, l6: 0.327253\n",
      "\n",
      "[epoch: 373/400, batch: 480/1000, ite: 49436] train loss: 1.1171, accuracy: 95.1215%, tar: 0.0208 \n",
      "l0: 0.020983, l1: 0.022600, l2: 0.029920, l3: 0.049326, l4: 0.118958, l5: 0.250391, l6: 0.450754\n",
      "\n",
      "[epoch: 373/400, batch: 488/1000, ite: 49437] train loss: 1.1173, accuracy: 93.8639%, tar: 0.0208 \n",
      "l0: 0.025485, l1: 0.027343, l2: 0.038623, l3: 0.058347, l4: 0.108211, l5: 0.230635, l6: 0.496773\n",
      "\n",
      "[epoch: 373/400, batch: 496/1000, ite: 49438] train loss: 1.1175, accuracy: 93.7655%, tar: 0.0208 \n",
      "l0: 0.014419, l1: 0.015136, l2: 0.019558, l3: 0.028909, l4: 0.051030, l5: 0.113118, l6: 0.248370\n",
      "\n",
      "[epoch: 373/400, batch: 504/1000, ite: 49439] train loss: 1.1173, accuracy: 96.1995%, tar: 0.0208 \n",
      "l0: 0.023525, l1: 0.024959, l2: 0.034535, l3: 0.052753, l4: 0.106599, l5: 0.226916, l6: 0.439359\n",
      "\n",
      "[epoch: 373/400, batch: 512/1000, ite: 49440] train loss: 1.1174, accuracy: 93.7664%, tar: 0.0208 \n",
      "l0: 0.028026, l1: 0.029871, l2: 0.038749, l3: 0.057213, l4: 0.110270, l5: 0.243991, l6: 0.500646\n",
      "\n",
      "[epoch: 373/400, batch: 520/1000, ite: 49441] train loss: 1.1177, accuracy: 93.9790%, tar: 0.0208 \n",
      "l0: 0.016452, l1: 0.017691, l2: 0.024763, l3: 0.041933, l4: 0.097858, l5: 0.189137, l6: 0.415077\n",
      "\n",
      "[epoch: 373/400, batch: 528/1000, ite: 49442] train loss: 1.1178, accuracy: 94.8599%, tar: 0.0208 \n",
      "l0: 0.016805, l1: 0.017868, l2: 0.025141, l3: 0.039358, l4: 0.095156, l5: 0.167582, l6: 0.318682\n",
      "\n",
      "[epoch: 373/400, batch: 536/1000, ite: 49443] train loss: 1.1177, accuracy: 95.6291%, tar: 0.0208 \n",
      "l0: 0.020248, l1: 0.021294, l2: 0.027864, l3: 0.042717, l4: 0.084493, l5: 0.213464, l6: 0.416959\n",
      "\n",
      "[epoch: 373/400, batch: 544/1000, ite: 49444] train loss: 1.1178, accuracy: 94.5573%, tar: 0.0208 \n",
      "l0: 0.021842, l1: 0.023560, l2: 0.032131, l3: 0.049263, l4: 0.085654, l5: 0.198728, l6: 0.446275\n",
      "\n",
      "[epoch: 373/400, batch: 552/1000, ite: 49445] train loss: 1.1179, accuracy: 94.2986%, tar: 0.0208 \n",
      "l0: 0.019659, l1: 0.021272, l2: 0.029906, l3: 0.049976, l4: 0.090444, l5: 0.164446, l6: 0.311474\n",
      "\n",
      "[epoch: 373/400, batch: 560/1000, ite: 49446] train loss: 1.1178, accuracy: 95.3017%, tar: 0.0208 \n",
      "l0: 0.027251, l1: 0.028565, l2: 0.038994, l3: 0.059324, l4: 0.104992, l5: 0.250770, l6: 0.574742\n",
      "\n",
      "[epoch: 373/400, batch: 568/1000, ite: 49447] train loss: 1.1182, accuracy: 91.8059%, tar: 0.0208 \n",
      "l0: 0.018867, l1: 0.019469, l2: 0.026739, l3: 0.039235, l4: 0.077262, l5: 0.161455, l6: 0.331779\n",
      "\n",
      "[epoch: 373/400, batch: 576/1000, ite: 49448] train loss: 1.1181, accuracy: 95.5011%, tar: 0.0208 \n",
      "l0: 0.020739, l1: 0.021586, l2: 0.027349, l3: 0.042062, l4: 0.082248, l5: 0.166882, l6: 0.343240\n",
      "\n",
      "[epoch: 373/400, batch: 584/1000, ite: 49449] train loss: 1.1181, accuracy: 95.0508%, tar: 0.0208 \n",
      "l0: 0.014502, l1: 0.016429, l2: 0.023192, l3: 0.034283, l4: 0.057342, l5: 0.122567, l6: 0.287253\n",
      "\n",
      "[epoch: 373/400, batch: 592/1000, ite: 49450] train loss: 1.1179, accuracy: 95.8767%, tar: 0.0208 \n",
      "l0: 0.017885, l1: 0.019125, l2: 0.026080, l3: 0.040392, l4: 0.075372, l5: 0.148910, l6: 0.264072\n",
      "\n",
      "[epoch: 373/400, batch: 600/1000, ite: 49451] train loss: 1.1177, accuracy: 96.1700%, tar: 0.0208 \n",
      "l0: 0.015276, l1: 0.016440, l2: 0.023961, l3: 0.039149, l4: 0.084301, l5: 0.191050, l6: 0.406965\n",
      "\n",
      "[epoch: 373/400, batch: 608/1000, ite: 49452] train loss: 1.1178, accuracy: 95.3964%, tar: 0.0208 \n",
      "l0: 0.024998, l1: 0.027663, l2: 0.037116, l3: 0.055553, l4: 0.099350, l5: 0.204165, l6: 0.448374\n",
      "\n",
      "[epoch: 373/400, batch: 616/1000, ite: 49453] train loss: 1.1179, accuracy: 94.5459%, tar: 0.0208 \n",
      "l0: 0.019565, l1: 0.020977, l2: 0.028000, l3: 0.042697, l4: 0.100873, l5: 0.178685, l6: 0.336000\n",
      "\n",
      "[epoch: 373/400, batch: 624/1000, ite: 49454] train loss: 1.1179, accuracy: 95.8430%, tar: 0.0208 \n",
      "l0: 0.020799, l1: 0.021880, l2: 0.029024, l3: 0.040349, l4: 0.081133, l5: 0.145319, l6: 0.268590\n",
      "\n",
      "[epoch: 373/400, batch: 632/1000, ite: 49455] train loss: 1.1177, accuracy: 95.6177%, tar: 0.0208 \n",
      "l0: 0.021721, l1: 0.022520, l2: 0.028340, l3: 0.041617, l4: 0.076538, l5: 0.158066, l6: 0.380082\n",
      "\n",
      "[epoch: 373/400, batch: 640/1000, ite: 49456] train loss: 1.1177, accuracy: 94.7616%, tar: 0.0208 \n",
      "l0: 0.017577, l1: 0.019318, l2: 0.026353, l3: 0.038245, l4: 0.078451, l5: 0.186918, l6: 0.381458\n",
      "\n",
      "[epoch: 373/400, batch: 648/1000, ite: 49457] train loss: 1.1177, accuracy: 95.0190%, tar: 0.0208 \n",
      "l0: 0.026580, l1: 0.027807, l2: 0.038310, l3: 0.055090, l4: 0.098195, l5: 0.207156, l6: 0.438392\n",
      "\n",
      "[epoch: 373/400, batch: 656/1000, ite: 49458] train loss: 1.1179, accuracy: 93.8253%, tar: 0.0208 \n",
      "l0: 0.022516, l1: 0.024429, l2: 0.034213, l3: 0.059455, l4: 0.122581, l5: 0.250345, l6: 0.493805\n",
      "\n",
      "[epoch: 373/400, batch: 664/1000, ite: 49459] train loss: 1.1182, accuracy: 94.1934%, tar: 0.0208 \n",
      "l0: 0.022486, l1: 0.024280, l2: 0.033149, l3: 0.051295, l4: 0.113812, l5: 0.227353, l6: 0.449058\n",
      "\n",
      "[epoch: 373/400, batch: 672/1000, ite: 49460] train loss: 1.1183, accuracy: 94.2426%, tar: 0.0208 \n",
      "l0: 0.017042, l1: 0.017890, l2: 0.024154, l3: 0.036285, l4: 0.063115, l5: 0.126781, l6: 0.339938\n",
      "\n",
      "[epoch: 373/400, batch: 680/1000, ite: 49461] train loss: 1.1182, accuracy: 95.4940%, tar: 0.0208 \n",
      "l0: 0.017652, l1: 0.018573, l2: 0.025787, l3: 0.037404, l4: 0.067172, l5: 0.129468, l6: 0.332486\n",
      "\n",
      "[epoch: 373/400, batch: 688/1000, ite: 49462] train loss: 1.1181, accuracy: 95.4221%, tar: 0.0208 \n",
      "l0: 0.020010, l1: 0.021111, l2: 0.027511, l3: 0.042277, l4: 0.075385, l5: 0.135318, l6: 0.325320\n",
      "\n",
      "[epoch: 373/400, batch: 696/1000, ite: 49463] train loss: 1.1180, accuracy: 95.6093%, tar: 0.0208 \n",
      "l0: 0.020411, l1: 0.021456, l2: 0.028033, l3: 0.038861, l4: 0.064889, l5: 0.119111, l6: 0.271758\n",
      "\n",
      "[epoch: 373/400, batch: 704/1000, ite: 49464] train loss: 1.1178, accuracy: 96.0881%, tar: 0.0208 \n",
      "l0: 0.023715, l1: 0.026489, l2: 0.039086, l3: 0.066191, l4: 0.140743, l5: 0.267214, l6: 0.462959\n",
      "\n",
      "[epoch: 373/400, batch: 712/1000, ite: 49465] train loss: 1.1181, accuracy: 94.1546%, tar: 0.0208 \n",
      "l0: 0.017863, l1: 0.018548, l2: 0.023673, l3: 0.033397, l4: 0.061839, l5: 0.126526, l6: 0.339926\n",
      "\n",
      "[epoch: 373/400, batch: 720/1000, ite: 49466] train loss: 1.1180, accuracy: 95.8359%, tar: 0.0208 \n",
      "l0: 0.023608, l1: 0.024387, l2: 0.031786, l3: 0.045357, l4: 0.080550, l5: 0.166313, l6: 0.332121\n",
      "\n",
      "[epoch: 373/400, batch: 728/1000, ite: 49467] train loss: 1.1179, accuracy: 94.8729%, tar: 0.0208 \n",
      "l0: 0.023334, l1: 0.024690, l2: 0.031229, l3: 0.048227, l4: 0.090292, l5: 0.207450, l6: 0.526605\n",
      "\n",
      "[epoch: 373/400, batch: 736/1000, ite: 49468] train loss: 1.1182, accuracy: 93.2664%, tar: 0.0208 \n",
      "l0: 0.020935, l1: 0.021736, l2: 0.027965, l3: 0.039138, l4: 0.064572, l5: 0.130155, l6: 0.364602\n",
      "\n",
      "[epoch: 373/400, batch: 744/1000, ite: 49469] train loss: 1.1181, accuracy: 95.3183%, tar: 0.0208 \n",
      "l0: 0.019330, l1: 0.020541, l2: 0.026877, l3: 0.044462, l4: 0.092768, l5: 0.195713, l6: 0.436691\n",
      "\n",
      "[epoch: 373/400, batch: 752/1000, ite: 49470] train loss: 1.1182, accuracy: 94.7114%, tar: 0.0208 \n",
      "l0: 0.017609, l1: 0.019160, l2: 0.027618, l3: 0.049680, l4: 0.093719, l5: 0.195141, l6: 0.448545\n",
      "\n",
      "[epoch: 373/400, batch: 760/1000, ite: 49471] train loss: 1.1184, accuracy: 95.0945%, tar: 0.0208 \n",
      "l0: 0.019382, l1: 0.021069, l2: 0.027800, l3: 0.044515, l4: 0.093967, l5: 0.181262, l6: 0.407313\n",
      "\n",
      "[epoch: 373/400, batch: 768/1000, ite: 49472] train loss: 1.1184, accuracy: 95.0651%, tar: 0.0208 \n",
      "l0: 0.017254, l1: 0.018418, l2: 0.025325, l3: 0.037370, l4: 0.065958, l5: 0.155140, l6: 0.323137\n",
      "\n",
      "[epoch: 373/400, batch: 776/1000, ite: 49473] train loss: 1.1183, accuracy: 95.7503%, tar: 0.0208 \n",
      "l0: 0.018522, l1: 0.020121, l2: 0.028552, l3: 0.041708, l4: 0.074224, l5: 0.171517, l6: 0.336075\n",
      "\n",
      "[epoch: 373/400, batch: 784/1000, ite: 49474] train loss: 1.1183, accuracy: 95.6681%, tar: 0.0208 \n",
      "l0: 0.022993, l1: 0.024546, l2: 0.034281, l3: 0.053442, l4: 0.100341, l5: 0.228576, l6: 0.462426\n",
      "\n",
      "[epoch: 373/400, batch: 792/1000, ite: 49475] train loss: 1.1184, accuracy: 94.7189%, tar: 0.0208 \n",
      "l0: 0.020359, l1: 0.022221, l2: 0.029750, l3: 0.049205, l4: 0.106599, l5: 0.210047, l6: 0.407418\n",
      "\n",
      "[epoch: 373/400, batch: 800/1000, ite: 49476] train loss: 1.1185, accuracy: 94.6479%, tar: 0.0208 \n",
      "l0: 0.017347, l1: 0.019102, l2: 0.027343, l3: 0.042936, l4: 0.080912, l5: 0.154836, l6: 0.285330\n",
      "\n",
      "[epoch: 373/400, batch: 808/1000, ite: 49477] train loss: 1.1184, accuracy: 96.2769%, tar: 0.0208 \n",
      "l0: 0.019330, l1: 0.020252, l2: 0.027833, l3: 0.042677, l4: 0.079504, l5: 0.149385, l6: 0.309991\n",
      "\n",
      "[epoch: 373/400, batch: 816/1000, ite: 49478] train loss: 1.1183, accuracy: 95.1762%, tar: 0.0208 \n",
      "l0: 0.018530, l1: 0.019602, l2: 0.025895, l3: 0.038773, l4: 0.065907, l5: 0.131303, l6: 0.261284\n",
      "\n",
      "[epoch: 373/400, batch: 824/1000, ite: 49479] train loss: 1.1181, accuracy: 96.0856%, tar: 0.0208 \n",
      "l0: 0.025498, l1: 0.026384, l2: 0.033965, l3: 0.050020, l4: 0.094576, l5: 0.219242, l6: 0.469022\n",
      "\n",
      "[epoch: 373/400, batch: 832/1000, ite: 49480] train loss: 1.1183, accuracy: 93.5597%, tar: 0.0208 \n",
      "l0: 0.016905, l1: 0.017992, l2: 0.024610, l3: 0.036477, l4: 0.062686, l5: 0.111450, l6: 0.259941\n",
      "\n",
      "[epoch: 373/400, batch: 840/1000, ite: 49481] train loss: 1.1180, accuracy: 96.6818%, tar: 0.0208 \n",
      "l0: 0.015197, l1: 0.016960, l2: 0.026240, l3: 0.047023, l4: 0.102599, l5: 0.199637, l6: 0.362988\n",
      "\n",
      "[epoch: 373/400, batch: 848/1000, ite: 49482] train loss: 1.1181, accuracy: 96.1422%, tar: 0.0208 \n",
      "l0: 0.022899, l1: 0.024337, l2: 0.032956, l3: 0.049691, l4: 0.095512, l5: 0.190854, l6: 0.436873\n",
      "\n",
      "[epoch: 373/400, batch: 856/1000, ite: 49483] train loss: 1.1182, accuracy: 94.4396%, tar: 0.0208 \n",
      "l0: 0.023774, l1: 0.026325, l2: 0.035309, l3: 0.060440, l4: 0.124901, l5: 0.252202, l6: 0.511930\n",
      "\n",
      "[epoch: 373/400, batch: 864/1000, ite: 49484] train loss: 1.1185, accuracy: 94.2717%, tar: 0.0208 \n",
      "l0: 0.022544, l1: 0.023632, l2: 0.032404, l3: 0.045760, l4: 0.080309, l5: 0.173292, l6: 0.369363\n",
      "\n",
      "[epoch: 373/400, batch: 872/1000, ite: 49485] train loss: 1.1185, accuracy: 94.8034%, tar: 0.0208 \n",
      "l0: 0.020141, l1: 0.021546, l2: 0.028759, l3: 0.044665, l4: 0.080781, l5: 0.185986, l6: 0.380698\n",
      "\n",
      "[epoch: 373/400, batch: 880/1000, ite: 49486] train loss: 1.1185, accuracy: 95.1771%, tar: 0.0208 \n",
      "l0: 0.016123, l1: 0.017499, l2: 0.023514, l3: 0.036035, l4: 0.087470, l5: 0.155739, l6: 0.329725\n",
      "\n",
      "[epoch: 373/400, batch: 888/1000, ite: 49487] train loss: 1.1184, accuracy: 95.8801%, tar: 0.0208 \n",
      "l0: 0.024900, l1: 0.026343, l2: 0.035281, l3: 0.053545, l4: 0.095665, l5: 0.199922, l6: 0.448884\n",
      "\n",
      "[epoch: 373/400, batch: 896/1000, ite: 49488] train loss: 1.1186, accuracy: 93.5934%, tar: 0.0208 \n",
      "l0: 0.021384, l1: 0.022188, l2: 0.029456, l3: 0.041596, l4: 0.067891, l5: 0.127196, l6: 0.247294\n",
      "\n",
      "[epoch: 373/400, batch: 904/1000, ite: 49489] train loss: 1.1183, accuracy: 95.8320%, tar: 0.0208 \n",
      "l0: 0.019534, l1: 0.020789, l2: 0.027687, l3: 0.046971, l4: 0.096591, l5: 0.177079, l6: 0.324931\n",
      "\n",
      "[epoch: 373/400, batch: 912/1000, ite: 49490] train loss: 1.1183, accuracy: 94.9246%, tar: 0.0208 \n",
      "l0: 0.021634, l1: 0.023151, l2: 0.030078, l3: 0.043610, l4: 0.084548, l5: 0.183207, l6: 0.341886\n",
      "\n",
      "[epoch: 373/400, batch: 920/1000, ite: 49491] train loss: 1.1183, accuracy: 95.0082%, tar: 0.0208 \n",
      "l0: 0.018893, l1: 0.020016, l2: 0.026346, l3: 0.038456, l4: 0.068238, l5: 0.139119, l6: 0.286727\n",
      "\n",
      "[epoch: 373/400, batch: 928/1000, ite: 49492] train loss: 1.1181, accuracy: 96.0120%, tar: 0.0208 \n",
      "l0: 0.023664, l1: 0.025023, l2: 0.033420, l3: 0.047014, l4: 0.081450, l5: 0.172868, l6: 0.352621\n",
      "\n",
      "[epoch: 373/400, batch: 936/1000, ite: 49493] train loss: 1.1181, accuracy: 95.2781%, tar: 0.0208 \n",
      "l0: 0.022059, l1: 0.023048, l2: 0.032204, l3: 0.051191, l4: 0.092326, l5: 0.234116, l6: 0.446038\n",
      "\n",
      "[epoch: 373/400, batch: 944/1000, ite: 49494] train loss: 1.1182, accuracy: 94.3350%, tar: 0.0208 \n",
      "l0: 0.020143, l1: 0.021521, l2: 0.029443, l3: 0.049535, l4: 0.089180, l5: 0.191911, l6: 0.483231\n",
      "\n",
      "[epoch: 373/400, batch: 952/1000, ite: 49495] train loss: 1.1184, accuracy: 94.7386%, tar: 0.0208 \n",
      "l0: 0.025160, l1: 0.027533, l2: 0.038226, l3: 0.058244, l4: 0.105169, l5: 0.211568, l6: 0.458173\n",
      "\n",
      "[epoch: 373/400, batch: 960/1000, ite: 49496] train loss: 1.1186, accuracy: 94.1428%, tar: 0.0208 \n",
      "l0: 0.013949, l1: 0.014840, l2: 0.020500, l3: 0.031714, l4: 0.059909, l5: 0.124937, l6: 0.264449\n",
      "\n",
      "[epoch: 373/400, batch: 968/1000, ite: 49497] train loss: 1.1184, accuracy: 96.3572%, tar: 0.0208 \n",
      "l0: 0.019941, l1: 0.021271, l2: 0.029493, l3: 0.045706, l4: 0.082232, l5: 0.137585, l6: 0.294559\n",
      "\n",
      "[epoch: 373/400, batch: 976/1000, ite: 49498] train loss: 1.1183, accuracy: 96.0420%, tar: 0.0208 \n",
      "l0: 0.020221, l1: 0.021539, l2: 0.029483, l3: 0.046837, l4: 0.074336, l5: 0.146737, l6: 0.303962\n",
      "\n",
      "[epoch: 373/400, batch: 984/1000, ite: 49499] train loss: 1.1182, accuracy: 95.7063%, tar: 0.0208 \n",
      "l0: 0.024451, l1: 0.026066, l2: 0.036159, l3: 0.049856, l4: 0.089156, l5: 0.181842, l6: 0.414431\n",
      "\n",
      "[epoch: 373/400, batch: 992/1000, ite: 49500] train loss: 1.1182, accuracy: 94.4204%, tar: 0.0208 \n",
      "l0: 0.021245, l1: 0.022307, l2: 0.030361, l3: 0.043917, l4: 0.077781, l5: 0.169870, l6: 0.359214\n",
      "\n",
      "[epoch: 373/400, batch: 1000/1000, ite: 49501] train loss: 1.1182, accuracy: 94.6537%, tar: 0.0208 \n",
      "l0: 0.024757, l1: 0.025740, l2: 0.034475, l3: 0.049064, l4: 0.084573, l5: 0.195958, l6: 0.425572\n",
      "\n",
      "[epoch: 374/400, batch: 8/1000, ite: 49502] train loss: 1.1183, accuracy: 93.8968%, tar: 0.0208 \n",
      "l0: 0.022475, l1: 0.023597, l2: 0.031132, l3: 0.046409, l4: 0.081607, l5: 0.156123, l6: 0.323529\n",
      "\n",
      "[epoch: 374/400, batch: 16/1000, ite: 49503] train loss: 1.1183, accuracy: 95.8763%, tar: 0.0208 \n",
      "l0: 0.022225, l1: 0.024034, l2: 0.033249, l3: 0.049286, l4: 0.083356, l5: 0.150026, l6: 0.330634\n",
      "\n",
      "[epoch: 374/400, batch: 24/1000, ite: 49504] train loss: 1.1182, accuracy: 95.4958%, tar: 0.0208 \n",
      "l0: 0.021436, l1: 0.023098, l2: 0.032984, l3: 0.051332, l4: 0.092098, l5: 0.219616, l6: 0.462438\n",
      "\n",
      "[epoch: 374/400, batch: 32/1000, ite: 49505] train loss: 1.1184, accuracy: 94.4953%, tar: 0.0208 \n",
      "l0: 0.015893, l1: 0.017155, l2: 0.025242, l3: 0.041339, l4: 0.076143, l5: 0.168393, l6: 0.335451\n",
      "\n",
      "[epoch: 374/400, batch: 40/1000, ite: 49506] train loss: 1.1183, accuracy: 95.7161%, tar: 0.0208 \n",
      "l0: 0.018384, l1: 0.019689, l2: 0.028158, l3: 0.045058, l4: 0.083633, l5: 0.152977, l6: 0.302658\n",
      "\n",
      "[epoch: 374/400, batch: 48/1000, ite: 49507] train loss: 1.1182, accuracy: 95.3756%, tar: 0.0208 \n",
      "l0: 0.021231, l1: 0.022052, l2: 0.027710, l3: 0.039310, l4: 0.068559, l5: 0.135790, l6: 0.303881\n",
      "\n",
      "[epoch: 374/400, batch: 56/1000, ite: 49508] train loss: 1.1181, accuracy: 95.3672%, tar: 0.0208 \n",
      "l0: 0.023774, l1: 0.024674, l2: 0.033389, l3: 0.048369, l4: 0.081381, l5: 0.196349, l6: 0.399131\n",
      "\n",
      "[epoch: 374/400, batch: 64/1000, ite: 49509] train loss: 1.1181, accuracy: 94.4066%, tar: 0.0208 \n",
      "l0: 0.020758, l1: 0.022225, l2: 0.029364, l3: 0.044665, l4: 0.083516, l5: 0.176973, l6: 0.418327\n",
      "\n",
      "[epoch: 374/400, batch: 72/1000, ite: 49510] train loss: 1.1182, accuracy: 94.9088%, tar: 0.0208 \n",
      "l0: 0.019145, l1: 0.020654, l2: 0.028159, l3: 0.046480, l4: 0.096732, l5: 0.201510, l6: 0.383376\n",
      "\n",
      "[epoch: 374/400, batch: 80/1000, ite: 49511] train loss: 1.1182, accuracy: 95.3786%, tar: 0.0208 \n",
      "l0: 0.011438, l1: 0.012855, l2: 0.019106, l3: 0.028425, l4: 0.049266, l5: 0.090690, l6: 0.160236\n",
      "\n",
      "[epoch: 374/400, batch: 88/1000, ite: 49512] train loss: 1.1179, accuracy: 98.1787%, tar: 0.0208 \n",
      "l0: 0.018745, l1: 0.019847, l2: 0.027353, l3: 0.045807, l4: 0.087471, l5: 0.185590, l6: 0.342013\n",
      "\n",
      "[epoch: 374/400, batch: 96/1000, ite: 49513] train loss: 1.1178, accuracy: 94.9007%, tar: 0.0208 \n",
      "l0: 0.016813, l1: 0.018220, l2: 0.024742, l3: 0.035303, l4: 0.066183, l5: 0.145919, l6: 0.300036\n",
      "\n",
      "[epoch: 374/400, batch: 104/1000, ite: 49514] train loss: 1.1177, accuracy: 95.6557%, tar: 0.0208 \n",
      "l0: 0.025718, l1: 0.027462, l2: 0.035835, l3: 0.049580, l4: 0.092976, l5: 0.220524, l6: 0.552053\n",
      "\n",
      "[epoch: 374/400, batch: 112/1000, ite: 49515] train loss: 1.1180, accuracy: 93.1601%, tar: 0.0208 \n",
      "l0: 0.017798, l1: 0.019136, l2: 0.027215, l3: 0.043009, l4: 0.080087, l5: 0.167782, l6: 0.365902\n",
      "\n",
      "[epoch: 374/400, batch: 120/1000, ite: 49516] train loss: 1.1180, accuracy: 95.6976%, tar: 0.0208 \n",
      "l0: 0.019895, l1: 0.022029, l2: 0.031202, l3: 0.050823, l4: 0.104005, l5: 0.273338, l6: 0.539028\n",
      "\n",
      "[epoch: 374/400, batch: 128/1000, ite: 49517] train loss: 1.1183, accuracy: 92.9125%, tar: 0.0208 \n",
      "l0: 0.018777, l1: 0.019903, l2: 0.027786, l3: 0.042859, l4: 0.076875, l5: 0.144932, l6: 0.318025\n",
      "\n",
      "[epoch: 374/400, batch: 136/1000, ite: 49518] train loss: 1.1182, accuracy: 95.5224%, tar: 0.0208 \n",
      "l0: 0.018709, l1: 0.020426, l2: 0.030484, l3: 0.048814, l4: 0.096846, l5: 0.219595, l6: 0.466875\n",
      "\n",
      "[epoch: 374/400, batch: 144/1000, ite: 49519] train loss: 1.1183, accuracy: 94.3409%, tar: 0.0208 \n",
      "l0: 0.023375, l1: 0.024046, l2: 0.031460, l3: 0.046340, l4: 0.082048, l5: 0.178523, l6: 0.389978\n",
      "\n",
      "[epoch: 374/400, batch: 152/1000, ite: 49520] train loss: 1.1184, accuracy: 94.7557%, tar: 0.0208 \n",
      "l0: 0.021116, l1: 0.022355, l2: 0.030153, l3: 0.041855, l4: 0.070062, l5: 0.122676, l6: 0.245289\n",
      "\n",
      "[epoch: 374/400, batch: 160/1000, ite: 49521] train loss: 1.1182, accuracy: 95.9876%, tar: 0.0208 \n",
      "l0: 0.017392, l1: 0.019695, l2: 0.029285, l3: 0.048293, l4: 0.092266, l5: 0.177489, l6: 0.365619\n",
      "\n",
      "[epoch: 374/400, batch: 168/1000, ite: 49522] train loss: 1.1182, accuracy: 95.6466%, tar: 0.0208 \n",
      "l0: 0.019003, l1: 0.020196, l2: 0.027118, l3: 0.041106, l4: 0.074802, l5: 0.159913, l6: 0.336533\n",
      "\n",
      "[epoch: 374/400, batch: 176/1000, ite: 49523] train loss: 1.1181, accuracy: 95.3606%, tar: 0.0208 \n",
      "l0: 0.018566, l1: 0.019950, l2: 0.027365, l3: 0.044549, l4: 0.083189, l5: 0.172519, l6: 0.431962\n",
      "\n",
      "[epoch: 374/400, batch: 184/1000, ite: 49524] train loss: 1.1182, accuracy: 95.1117%, tar: 0.0208 \n",
      "l0: 0.019933, l1: 0.021337, l2: 0.029191, l3: 0.047060, l4: 0.084565, l5: 0.154516, l6: 0.317761\n",
      "\n",
      "[epoch: 374/400, batch: 192/1000, ite: 49525] train loss: 1.1181, accuracy: 95.0457%, tar: 0.0208 \n",
      "l0: 0.023884, l1: 0.025272, l2: 0.033208, l3: 0.049498, l4: 0.097059, l5: 0.200398, l6: 0.431638\n",
      "\n",
      "[epoch: 374/400, batch: 200/1000, ite: 49526] train loss: 1.1182, accuracy: 94.5757%, tar: 0.0208 \n",
      "l0: 0.021449, l1: 0.022362, l2: 0.028834, l3: 0.043063, l4: 0.084433, l5: 0.197417, l6: 0.372885\n",
      "\n",
      "[epoch: 374/400, batch: 208/1000, ite: 49527] train loss: 1.1182, accuracy: 94.3482%, tar: 0.0208 \n",
      "l0: 0.015941, l1: 0.017083, l2: 0.022871, l3: 0.034236, l4: 0.087543, l5: 0.167438, l6: 0.297293\n",
      "\n",
      "[epoch: 374/400, batch: 216/1000, ite: 49528] train loss: 1.1181, accuracy: 95.8780%, tar: 0.0208 \n",
      "l0: 0.019468, l1: 0.020764, l2: 0.026059, l3: 0.042469, l4: 0.105414, l5: 0.226226, l6: 0.446440\n",
      "\n",
      "[epoch: 374/400, batch: 224/1000, ite: 49529] train loss: 1.1183, accuracy: 94.6770%, tar: 0.0208 \n",
      "l0: 0.014822, l1: 0.015823, l2: 0.022224, l3: 0.033316, l4: 0.059521, l5: 0.108340, l6: 0.255777\n",
      "\n",
      "[epoch: 374/400, batch: 232/1000, ite: 49530] train loss: 1.1180, accuracy: 96.4434%, tar: 0.0208 \n",
      "l0: 0.027237, l1: 0.028184, l2: 0.035447, l3: 0.050931, l4: 0.091214, l5: 0.144773, l6: 0.353566\n",
      "\n",
      "[epoch: 374/400, batch: 240/1000, ite: 49531] train loss: 1.1180, accuracy: 94.7057%, tar: 0.0208 \n",
      "l0: 0.022747, l1: 0.024171, l2: 0.033461, l3: 0.051429, l4: 0.092276, l5: 0.182201, l6: 0.354522\n",
      "\n",
      "[epoch: 374/400, batch: 248/1000, ite: 49532] train loss: 1.1180, accuracy: 95.4300%, tar: 0.0208 \n",
      "l0: 0.019711, l1: 0.020682, l2: 0.026228, l3: 0.039406, l4: 0.073984, l5: 0.178497, l6: 0.386871\n",
      "\n",
      "[epoch: 374/400, batch: 256/1000, ite: 49533] train loss: 1.1180, accuracy: 94.1857%, tar: 0.0208 \n",
      "l0: 0.018392, l1: 0.019380, l2: 0.028328, l3: 0.041569, l4: 0.076142, l5: 0.133907, l6: 0.276771\n",
      "\n",
      "[epoch: 374/400, batch: 264/1000, ite: 49534] train loss: 1.1179, accuracy: 95.8694%, tar: 0.0208 \n",
      "l0: 0.019513, l1: 0.020705, l2: 0.027204, l3: 0.039070, l4: 0.069413, l5: 0.133481, l6: 0.304521\n",
      "\n",
      "[epoch: 374/400, batch: 272/1000, ite: 49535] train loss: 1.1177, accuracy: 95.4069%, tar: 0.0208 \n",
      "l0: 0.018765, l1: 0.020154, l2: 0.028608, l3: 0.044212, l4: 0.081885, l5: 0.170556, l6: 0.346571\n",
      "\n",
      "[epoch: 374/400, batch: 280/1000, ite: 49536] train loss: 1.1177, accuracy: 95.4349%, tar: 0.0208 \n",
      "l0: 0.017470, l1: 0.018367, l2: 0.023873, l3: 0.036401, l4: 0.073172, l5: 0.145391, l6: 0.282447\n",
      "\n",
      "[epoch: 374/400, batch: 288/1000, ite: 49537] train loss: 1.1175, accuracy: 95.5978%, tar: 0.0208 \n",
      "l0: 0.016585, l1: 0.017462, l2: 0.023114, l3: 0.033315, l4: 0.067720, l5: 0.131136, l6: 0.261421\n",
      "\n",
      "[epoch: 374/400, batch: 296/1000, ite: 49538] train loss: 1.1173, accuracy: 96.5104%, tar: 0.0208 \n",
      "l0: 0.022341, l1: 0.023302, l2: 0.029887, l3: 0.044009, l4: 0.078670, l5: 0.171338, l6: 0.372665\n",
      "\n",
      "[epoch: 374/400, batch: 304/1000, ite: 49539] train loss: 1.1173, accuracy: 94.9414%, tar: 0.0208 \n",
      "l0: 0.024668, l1: 0.026075, l2: 0.034450, l3: 0.053376, l4: 0.107154, l5: 0.206298, l6: 0.450113\n",
      "\n",
      "[epoch: 374/400, batch: 312/1000, ite: 49540] train loss: 1.1175, accuracy: 93.1328%, tar: 0.0208 \n",
      "l0: 0.019225, l1: 0.021397, l2: 0.031671, l3: 0.057985, l4: 0.141550, l5: 0.265777, l6: 0.462720\n",
      "\n",
      "[epoch: 374/400, batch: 320/1000, ite: 49541] train loss: 1.1177, accuracy: 94.6183%, tar: 0.0208 \n",
      "l0: 0.024688, l1: 0.026316, l2: 0.036014, l3: 0.058118, l4: 0.120251, l5: 0.249725, l6: 0.461128\n",
      "\n",
      "[epoch: 374/400, batch: 328/1000, ite: 49542] train loss: 1.1179, accuracy: 93.3997%, tar: 0.0208 \n",
      "l0: 0.022950, l1: 0.024804, l2: 0.035741, l3: 0.055190, l4: 0.110861, l5: 0.256461, l6: 0.492598\n",
      "\n",
      "[epoch: 374/400, batch: 336/1000, ite: 49543] train loss: 1.1182, accuracy: 93.8449%, tar: 0.0208 \n",
      "l0: 0.019084, l1: 0.020524, l2: 0.028069, l3: 0.044493, l4: 0.095323, l5: 0.224503, l6: 0.441468\n",
      "\n",
      "[epoch: 374/400, batch: 344/1000, ite: 49544] train loss: 1.1183, accuracy: 95.2671%, tar: 0.0208 \n",
      "l0: 0.022307, l1: 0.023843, l2: 0.030433, l3: 0.043235, l4: 0.077515, l5: 0.171679, l6: 0.377587\n",
      "\n",
      "[epoch: 374/400, batch: 352/1000, ite: 49545] train loss: 1.1183, accuracy: 94.2362%, tar: 0.0208 \n",
      "l0: 0.017159, l1: 0.018169, l2: 0.025574, l3: 0.046333, l4: 0.078899, l5: 0.143467, l6: 0.380729\n",
      "\n",
      "[epoch: 374/400, batch: 360/1000, ite: 49546] train loss: 1.1183, accuracy: 94.8244%, tar: 0.0208 \n",
      "l0: 0.022206, l1: 0.024504, l2: 0.034490, l3: 0.052019, l4: 0.100705, l5: 0.245275, l6: 0.432204\n",
      "\n",
      "[epoch: 374/400, batch: 368/1000, ite: 49547] train loss: 1.1184, accuracy: 94.3659%, tar: 0.0208 \n",
      "l0: 0.017478, l1: 0.018688, l2: 0.027569, l3: 0.046413, l4: 0.087813, l5: 0.160610, l6: 0.287557\n",
      "\n",
      "[epoch: 374/400, batch: 376/1000, ite: 49548] train loss: 1.1183, accuracy: 95.3032%, tar: 0.0208 \n",
      "l0: 0.017655, l1: 0.019037, l2: 0.025819, l3: 0.039358, l4: 0.079816, l5: 0.166199, l6: 0.283441\n",
      "\n",
      "[epoch: 374/400, batch: 384/1000, ite: 49549] train loss: 1.1182, accuracy: 95.7237%, tar: 0.0208 \n",
      "l0: 0.019967, l1: 0.021138, l2: 0.028213, l3: 0.043706, l4: 0.066938, l5: 0.119252, l6: 0.244099\n",
      "\n",
      "[epoch: 374/400, batch: 392/1000, ite: 49550] train loss: 1.1180, accuracy: 96.7644%, tar: 0.0208 \n",
      "l0: 0.023558, l1: 0.024775, l2: 0.032311, l3: 0.048278, l4: 0.093569, l5: 0.167732, l6: 0.365333\n",
      "\n",
      "[epoch: 374/400, batch: 400/1000, ite: 49551] train loss: 1.1180, accuracy: 94.8650%, tar: 0.0208 \n",
      "l0: 0.020769, l1: 0.021885, l2: 0.028012, l3: 0.040723, l4: 0.085165, l5: 0.181374, l6: 0.365688\n",
      "\n",
      "[epoch: 374/400, batch: 408/1000, ite: 49552] train loss: 1.1180, accuracy: 94.3310%, tar: 0.0208 \n",
      "l0: 0.029228, l1: 0.031004, l2: 0.041276, l3: 0.060093, l4: 0.114527, l5: 0.218591, l6: 0.414043\n",
      "\n",
      "[epoch: 374/400, batch: 416/1000, ite: 49553] train loss: 1.1181, accuracy: 93.7847%, tar: 0.0208 \n",
      "l0: 0.018471, l1: 0.019487, l2: 0.025614, l3: 0.040873, l4: 0.087063, l5: 0.217526, l6: 0.420775\n",
      "\n",
      "[epoch: 374/400, batch: 424/1000, ite: 49554] train loss: 1.1182, accuracy: 94.6117%, tar: 0.0208 \n",
      "l0: 0.021200, l1: 0.022563, l2: 0.029689, l3: 0.042275, l4: 0.089457, l5: 0.171897, l6: 0.369722\n",
      "\n",
      "[epoch: 374/400, batch: 432/1000, ite: 49555] train loss: 1.1182, accuracy: 94.8921%, tar: 0.0208 \n",
      "l0: 0.020357, l1: 0.022413, l2: 0.032610, l3: 0.048062, l4: 0.079139, l5: 0.154306, l6: 0.366263\n",
      "\n",
      "[epoch: 374/400, batch: 440/1000, ite: 49556] train loss: 1.1182, accuracy: 95.7830%, tar: 0.0208 \n",
      "l0: 0.019588, l1: 0.020933, l2: 0.029748, l3: 0.051627, l4: 0.109081, l5: 0.202510, l6: 0.396043\n",
      "\n",
      "[epoch: 374/400, batch: 448/1000, ite: 49557] train loss: 1.1183, accuracy: 95.1009%, tar: 0.0208 \n",
      "l0: 0.018558, l1: 0.019999, l2: 0.028792, l3: 0.048001, l4: 0.090627, l5: 0.201065, l6: 0.359273\n",
      "\n",
      "[epoch: 374/400, batch: 456/1000, ite: 49558] train loss: 1.1183, accuracy: 95.4497%, tar: 0.0208 \n",
      "l0: 0.016952, l1: 0.019425, l2: 0.030450, l3: 0.051038, l4: 0.100684, l5: 0.172109, l6: 0.334385\n",
      "\n",
      "[epoch: 374/400, batch: 464/1000, ite: 49559] train loss: 1.1182, accuracy: 95.7003%, tar: 0.0208 \n",
      "l0: 0.020211, l1: 0.021652, l2: 0.028970, l3: 0.044380, l4: 0.079456, l5: 0.172937, l6: 0.354776\n",
      "\n",
      "[epoch: 374/400, batch: 472/1000, ite: 49560] train loss: 1.1182, accuracy: 95.3381%, tar: 0.0208 \n",
      "l0: 0.024132, l1: 0.026281, l2: 0.034717, l3: 0.056496, l4: 0.113901, l5: 0.227109, l6: 0.454562\n",
      "\n",
      "[epoch: 374/400, batch: 480/1000, ite: 49561] train loss: 1.1184, accuracy: 95.0864%, tar: 0.0208 \n",
      "l0: 0.022033, l1: 0.022973, l2: 0.030008, l3: 0.046208, l4: 0.076901, l5: 0.186587, l6: 0.404738\n",
      "\n",
      "[epoch: 374/400, batch: 488/1000, ite: 49562] train loss: 1.1184, accuracy: 94.9292%, tar: 0.0208 \n",
      "l0: 0.021865, l1: 0.023748, l2: 0.032119, l3: 0.047904, l4: 0.083496, l5: 0.170339, l6: 0.334786\n",
      "\n",
      "[epoch: 374/400, batch: 496/1000, ite: 49563] train loss: 1.1184, accuracy: 95.2412%, tar: 0.0208 \n",
      "l0: 0.014803, l1: 0.015894, l2: 0.022039, l3: 0.032292, l4: 0.063661, l5: 0.127532, l6: 0.241987\n",
      "\n",
      "[epoch: 374/400, batch: 504/1000, ite: 49564] train loss: 1.1182, accuracy: 96.5427%, tar: 0.0208 \n",
      "l0: 0.017423, l1: 0.018676, l2: 0.023932, l3: 0.034823, l4: 0.063949, l5: 0.138251, l6: 0.289181\n",
      "\n",
      "[epoch: 374/400, batch: 512/1000, ite: 49565] train loss: 1.1180, accuracy: 95.9455%, tar: 0.0208 \n",
      "l0: 0.025033, l1: 0.026706, l2: 0.037413, l3: 0.059486, l4: 0.113627, l5: 0.232085, l6: 0.506705\n",
      "\n",
      "[epoch: 374/400, batch: 520/1000, ite: 49566] train loss: 1.1183, accuracy: 93.7452%, tar: 0.0208 \n",
      "l0: 0.020720, l1: 0.022112, l2: 0.028992, l3: 0.045295, l4: 0.079051, l5: 0.134215, l6: 0.305154\n",
      "\n",
      "[epoch: 374/400, batch: 528/1000, ite: 49567] train loss: 1.1181, accuracy: 95.9028%, tar: 0.0208 \n",
      "l0: 0.027668, l1: 0.028651, l2: 0.039588, l3: 0.060039, l4: 0.107440, l5: 0.219238, l6: 0.419122\n",
      "\n",
      "[epoch: 374/400, batch: 536/1000, ite: 49568] train loss: 1.1183, accuracy: 93.1574%, tar: 0.0208 \n",
      "l0: 0.017382, l1: 0.018238, l2: 0.025442, l3: 0.040122, l4: 0.074889, l5: 0.137012, l6: 0.282331\n",
      "\n",
      "[epoch: 374/400, batch: 544/1000, ite: 49569] train loss: 1.1181, accuracy: 96.1842%, tar: 0.0208 \n",
      "l0: 0.016862, l1: 0.017659, l2: 0.023808, l3: 0.034520, l4: 0.062295, l5: 0.137954, l6: 0.294807\n",
      "\n",
      "[epoch: 374/400, batch: 552/1000, ite: 49570] train loss: 1.1180, accuracy: 95.5884%, tar: 0.0208 \n",
      "l0: 0.021012, l1: 0.022164, l2: 0.029074, l3: 0.041113, l4: 0.070884, l5: 0.151461, l6: 0.274649\n",
      "\n",
      "[epoch: 374/400, batch: 560/1000, ite: 49571] train loss: 1.1178, accuracy: 96.0364%, tar: 0.0208 \n",
      "l0: 0.017031, l1: 0.017847, l2: 0.024193, l3: 0.038501, l4: 0.076111, l5: 0.174897, l6: 0.320102\n",
      "\n",
      "[epoch: 374/400, batch: 568/1000, ite: 49572] train loss: 1.1178, accuracy: 95.1473%, tar: 0.0208 \n",
      "l0: 0.021556, l1: 0.023855, l2: 0.035875, l3: 0.062012, l4: 0.122515, l5: 0.261433, l6: 0.492634\n",
      "\n",
      "[epoch: 374/400, batch: 576/1000, ite: 49573] train loss: 1.1180, accuracy: 93.9806%, tar: 0.0208 \n",
      "l0: 0.018856, l1: 0.020347, l2: 0.028395, l3: 0.045610, l4: 0.113518, l5: 0.236381, l6: 0.439501\n",
      "\n",
      "[epoch: 374/400, batch: 584/1000, ite: 49574] train loss: 1.1182, accuracy: 94.7179%, tar: 0.0208 \n",
      "l0: 0.023767, l1: 0.025447, l2: 0.033974, l3: 0.050941, l4: 0.119269, l5: 0.264585, l6: 0.428606\n",
      "\n",
      "[epoch: 374/400, batch: 592/1000, ite: 49575] train loss: 1.1183, accuracy: 94.1328%, tar: 0.0208 \n",
      "l0: 0.021865, l1: 0.022553, l2: 0.029815, l3: 0.038870, l4: 0.061654, l5: 0.119495, l6: 0.267888\n",
      "\n",
      "[epoch: 374/400, batch: 600/1000, ite: 49576] train loss: 1.1181, accuracy: 95.3342%, tar: 0.0208 \n",
      "l0: 0.018142, l1: 0.018933, l2: 0.024358, l3: 0.036325, l4: 0.062732, l5: 0.119083, l6: 0.253600\n",
      "\n",
      "[epoch: 374/400, batch: 608/1000, ite: 49577] train loss: 1.1179, accuracy: 96.0783%, tar: 0.0208 \n",
      "l0: 0.025248, l1: 0.026731, l2: 0.036887, l3: 0.058247, l4: 0.101902, l5: 0.233510, l6: 0.562186\n",
      "\n",
      "[epoch: 374/400, batch: 616/1000, ite: 49578] train loss: 1.1182, accuracy: 92.3457%, tar: 0.0208 \n",
      "l0: 0.026068, l1: 0.029430, l2: 0.040881, l3: 0.064024, l4: 0.109425, l5: 0.214347, l6: 0.392574\n",
      "\n",
      "[epoch: 374/400, batch: 624/1000, ite: 49579] train loss: 1.1183, accuracy: 95.3297%, tar: 0.0208 \n",
      "l0: 0.018919, l1: 0.020337, l2: 0.029346, l3: 0.048028, l4: 0.097327, l5: 0.170214, l6: 0.288760\n",
      "\n",
      "[epoch: 374/400, batch: 632/1000, ite: 49580] train loss: 1.1182, accuracy: 96.0605%, tar: 0.0208 \n",
      "l0: 0.019814, l1: 0.020769, l2: 0.027793, l3: 0.040151, l4: 0.076437, l5: 0.154467, l6: 0.333825\n",
      "\n",
      "[epoch: 374/400, batch: 640/1000, ite: 49581] train loss: 1.1182, accuracy: 94.9988%, tar: 0.0208 \n",
      "l0: 0.015323, l1: 0.016865, l2: 0.023561, l3: 0.038504, l4: 0.070226, l5: 0.165963, l6: 0.462386\n",
      "\n",
      "[epoch: 374/400, batch: 648/1000, ite: 49582] train loss: 1.1183, accuracy: 94.9982%, tar: 0.0208 \n",
      "l0: 0.025853, l1: 0.027337, l2: 0.037174, l3: 0.057045, l4: 0.097974, l5: 0.202755, l6: 0.506279\n",
      "\n",
      "[epoch: 374/400, batch: 656/1000, ite: 49583] train loss: 1.1185, accuracy: 93.6512%, tar: 0.0208 \n",
      "l0: 0.022204, l1: 0.023467, l2: 0.033417, l3: 0.052459, l4: 0.096257, l5: 0.216192, l6: 0.400183\n",
      "\n",
      "[epoch: 374/400, batch: 664/1000, ite: 49584] train loss: 1.1186, accuracy: 94.7168%, tar: 0.0208 \n",
      "l0: 0.018160, l1: 0.018873, l2: 0.026019, l3: 0.039579, l4: 0.069112, l5: 0.124221, l6: 0.262393\n",
      "\n",
      "[epoch: 374/400, batch: 672/1000, ite: 49585] train loss: 1.1184, accuracy: 95.6240%, tar: 0.0208 \n",
      "l0: 0.019145, l1: 0.020877, l2: 0.029253, l3: 0.044030, l4: 0.072770, l5: 0.130969, l6: 0.317478\n",
      "\n",
      "[epoch: 374/400, batch: 680/1000, ite: 49586] train loss: 1.1183, accuracy: 95.8668%, tar: 0.0208 \n",
      "l0: 0.018162, l1: 0.019059, l2: 0.024833, l3: 0.036357, l4: 0.061432, l5: 0.108894, l6: 0.249415\n",
      "\n",
      "[epoch: 374/400, batch: 688/1000, ite: 49587] train loss: 1.1181, accuracy: 95.8658%, tar: 0.0208 \n",
      "l0: 0.016648, l1: 0.017870, l2: 0.025476, l3: 0.036313, l4: 0.054795, l5: 0.105476, l6: 0.240416\n",
      "\n",
      "[epoch: 374/400, batch: 696/1000, ite: 49588] train loss: 1.1178, accuracy: 96.8833%, tar: 0.0208 \n",
      "l0: 0.021411, l1: 0.022495, l2: 0.029810, l3: 0.047987, l4: 0.097951, l5: 0.211944, l6: 0.444273\n",
      "\n",
      "[epoch: 374/400, batch: 712/1000, ite: 49590] train loss: 1.1180, accuracy: 94.5074%, tar: 0.0208 \n",
      "l0: 0.016938, l1: 0.018114, l2: 0.025318, l3: 0.038553, l4: 0.068589, l5: 0.121997, l6: 0.275531\n",
      "\n",
      "[epoch: 374/400, batch: 720/1000, ite: 49591] train loss: 1.1178, accuracy: 96.5027%, tar: 0.0208 \n",
      "l0: 0.017932, l1: 0.019021, l2: 0.025523, l3: 0.037368, l4: 0.069134, l5: 0.149239, l6: 0.327604\n",
      "\n",
      "[epoch: 374/400, batch: 728/1000, ite: 49592] train loss: 1.1177, accuracy: 95.0816%, tar: 0.0208 \n",
      "l0: 0.023381, l1: 0.024342, l2: 0.031600, l3: 0.049455, l4: 0.087121, l5: 0.202445, l6: 0.419307\n",
      "\n",
      "[epoch: 374/400, batch: 736/1000, ite: 49593] train loss: 1.1178, accuracy: 94.2793%, tar: 0.0208 \n",
      "l0: 0.020802, l1: 0.022685, l2: 0.031093, l3: 0.047248, l4: 0.085353, l5: 0.176209, l6: 0.336438\n",
      "\n",
      "[epoch: 374/400, batch: 744/1000, ite: 49594] train loss: 1.1178, accuracy: 94.9171%, tar: 0.0208 \n",
      "l0: 0.023776, l1: 0.026007, l2: 0.035648, l3: 0.052925, l4: 0.095910, l5: 0.168952, l6: 0.309655\n",
      "\n",
      "[epoch: 374/400, batch: 752/1000, ite: 49595] train loss: 1.1177, accuracy: 95.2196%, tar: 0.0208 \n",
      "l0: 0.021135, l1: 0.022209, l2: 0.030591, l3: 0.048741, l4: 0.103482, l5: 0.204225, l6: 0.428027\n",
      "\n",
      "[epoch: 374/400, batch: 760/1000, ite: 49596] train loss: 1.1178, accuracy: 95.0339%, tar: 0.0208 \n",
      "l0: 0.022489, l1: 0.023612, l2: 0.030392, l3: 0.040890, l4: 0.070561, l5: 0.137291, l6: 0.400653\n",
      "\n",
      "[epoch: 374/400, batch: 768/1000, ite: 49597] train loss: 1.1178, accuracy: 95.6005%, tar: 0.0208 \n",
      "l0: 0.019030, l1: 0.020285, l2: 0.027879, l3: 0.039698, l4: 0.077693, l5: 0.167336, l6: 0.360838\n",
      "\n",
      "[epoch: 374/400, batch: 776/1000, ite: 49598] train loss: 1.1178, accuracy: 95.4091%, tar: 0.0208 \n",
      "l0: 0.018490, l1: 0.019866, l2: 0.027792, l3: 0.041075, l4: 0.070667, l5: 0.149787, l6: 0.292304\n",
      "\n",
      "[epoch: 374/400, batch: 784/1000, ite: 49599] train loss: 1.1177, accuracy: 95.4287%, tar: 0.0208 \n",
      "l0: 0.019071, l1: 0.020641, l2: 0.026385, l3: 0.040325, l4: 0.081612, l5: 0.124531, l6: 0.294180\n",
      "\n",
      "[epoch: 374/400, batch: 792/1000, ite: 49600] train loss: 1.1176, accuracy: 95.9134%, tar: 0.0208 \n",
      "l0: 0.025764, l1: 0.027128, l2: 0.034529, l3: 0.052041, l4: 0.092128, l5: 0.168497, l6: 0.372193\n",
      "\n",
      "[epoch: 374/400, batch: 800/1000, ite: 49601] train loss: 1.1176, accuracy: 94.6536%, tar: 0.0208 \n",
      "l0: 0.018382, l1: 0.019398, l2: 0.024630, l3: 0.034443, l4: 0.063489, l5: 0.143799, l6: 0.314237\n",
      "\n",
      "[epoch: 374/400, batch: 808/1000, ite: 49602] train loss: 1.1175, accuracy: 95.7689%, tar: 0.0208 \n",
      "l0: 0.020065, l1: 0.021417, l2: 0.030004, l3: 0.045521, l4: 0.077764, l5: 0.143806, l6: 0.324830\n",
      "\n",
      "[epoch: 374/400, batch: 816/1000, ite: 49603] train loss: 1.1174, accuracy: 95.5982%, tar: 0.0208 \n",
      "l0: 0.022288, l1: 0.024326, l2: 0.033652, l3: 0.051054, l4: 0.097209, l5: 0.204357, l6: 0.464533\n",
      "\n",
      "[epoch: 374/400, batch: 824/1000, ite: 49604] train loss: 1.1175, accuracy: 93.9127%, tar: 0.0208 \n",
      "l0: 0.032327, l1: 0.033579, l2: 0.045918, l3: 0.075059, l4: 0.152601, l5: 0.307517, l6: 0.837208\n",
      "\n",
      "[epoch: 374/400, batch: 832/1000, ite: 49605] train loss: 1.1183, accuracy: 90.2935%, tar: 0.0208 \n",
      "l0: 0.018038, l1: 0.019904, l2: 0.028097, l3: 0.044364, l4: 0.085002, l5: 0.206476, l6: 0.486568\n",
      "\n",
      "[epoch: 374/400, batch: 840/1000, ite: 49606] train loss: 1.1184, accuracy: 95.3151%, tar: 0.0208 \n",
      "l0: 0.022382, l1: 0.023938, l2: 0.032746, l3: 0.049802, l4: 0.107324, l5: 0.259574, l6: 0.489784\n",
      "\n",
      "[epoch: 374/400, batch: 848/1000, ite: 49607] train loss: 1.1187, accuracy: 93.7718%, tar: 0.0208 \n",
      "l0: 0.020028, l1: 0.022145, l2: 0.032493, l3: 0.052258, l4: 0.109985, l5: 0.210151, l6: 0.416271\n",
      "\n",
      "[epoch: 374/400, batch: 856/1000, ite: 49608] train loss: 1.1188, accuracy: 95.2118%, tar: 0.0208 \n",
      "l0: 0.018101, l1: 0.019082, l2: 0.027284, l3: 0.038640, l4: 0.069755, l5: 0.139004, l6: 0.285075\n",
      "\n",
      "[epoch: 374/400, batch: 864/1000, ite: 49609] train loss: 1.1186, accuracy: 96.0082%, tar: 0.0208 \n",
      "l0: 0.022367, l1: 0.023627, l2: 0.032027, l3: 0.049298, l4: 0.092235, l5: 0.185061, l6: 0.408035\n",
      "\n",
      "[epoch: 374/400, batch: 872/1000, ite: 49610] train loss: 1.1187, accuracy: 93.9660%, tar: 0.0208 \n",
      "l0: 0.019862, l1: 0.021221, l2: 0.026889, l3: 0.044687, l4: 0.090181, l5: 0.176905, l6: 0.377895\n",
      "\n",
      "[epoch: 374/400, batch: 880/1000, ite: 49611] train loss: 1.1187, accuracy: 95.0800%, tar: 0.0208 \n",
      "l0: 0.017691, l1: 0.018978, l2: 0.025847, l3: 0.038339, l4: 0.071647, l5: 0.128952, l6: 0.252183\n",
      "\n",
      "[epoch: 374/400, batch: 888/1000, ite: 49612] train loss: 1.1185, accuracy: 96.2762%, tar: 0.0208 \n",
      "l0: 0.016846, l1: 0.018103, l2: 0.025186, l3: 0.036147, l4: 0.066962, l5: 0.136947, l6: 0.304840\n",
      "\n",
      "[epoch: 374/400, batch: 896/1000, ite: 49613] train loss: 1.1184, accuracy: 96.1370%, tar: 0.0208 \n",
      "l0: 0.022731, l1: 0.024316, l2: 0.033498, l3: 0.051262, l4: 0.092893, l5: 0.183336, l6: 0.410887\n",
      "\n",
      "[epoch: 374/400, batch: 904/1000, ite: 49614] train loss: 1.1184, accuracy: 94.8435%, tar: 0.0208 \n",
      "l0: 0.025736, l1: 0.027138, l2: 0.036651, l3: 0.055929, l4: 0.096029, l5: 0.182074, l6: 0.424492\n",
      "\n",
      "[epoch: 374/400, batch: 912/1000, ite: 49615] train loss: 1.1185, accuracy: 94.2916%, tar: 0.0208 \n",
      "l0: 0.021176, l1: 0.022105, l2: 0.028908, l3: 0.044806, l4: 0.079974, l5: 0.172252, l6: 0.330672\n",
      "\n",
      "[epoch: 374/400, batch: 920/1000, ite: 49616] train loss: 1.1185, accuracy: 95.1184%, tar: 0.0208 \n",
      "l0: 0.015398, l1: 0.016198, l2: 0.021281, l3: 0.035037, l4: 0.115547, l5: 0.166208, l6: 0.336857\n",
      "\n",
      "[epoch: 374/400, batch: 928/1000, ite: 49617] train loss: 1.1184, accuracy: 95.8225%, tar: 0.0208 \n",
      "l0: 0.024334, l1: 0.025674, l2: 0.034649, l3: 0.052453, l4: 0.104847, l5: 0.232540, l6: 0.431701\n",
      "\n",
      "[epoch: 374/400, batch: 936/1000, ite: 49618] train loss: 1.1186, accuracy: 94.1427%, tar: 0.0208 \n",
      "l0: 0.024447, l1: 0.025536, l2: 0.032513, l3: 0.044514, l4: 0.078678, l5: 0.131395, l6: 0.293978\n",
      "\n",
      "[epoch: 374/400, batch: 944/1000, ite: 49619] train loss: 1.1185, accuracy: 95.1452%, tar: 0.0208 \n",
      "l0: 0.027198, l1: 0.028720, l2: 0.037499, l3: 0.056136, l4: 0.105144, l5: 0.221088, l6: 0.403854\n",
      "\n",
      "[epoch: 374/400, batch: 952/1000, ite: 49620] train loss: 1.1186, accuracy: 93.8006%, tar: 0.0208 \n",
      "l0: 0.017101, l1: 0.018903, l2: 0.026519, l3: 0.047300, l4: 0.098734, l5: 0.214872, l6: 0.373295\n",
      "\n",
      "[epoch: 374/400, batch: 960/1000, ite: 49621] train loss: 1.1186, accuracy: 95.0177%, tar: 0.0208 \n",
      "l0: 0.022258, l1: 0.023041, l2: 0.030040, l3: 0.043792, l4: 0.073936, l5: 0.151361, l6: 0.343417\n",
      "\n",
      "[epoch: 374/400, batch: 968/1000, ite: 49622] train loss: 1.1186, accuracy: 94.7286%, tar: 0.0208 \n",
      "l0: 0.011659, l1: 0.013036, l2: 0.020953, l3: 0.035773, l4: 0.066206, l5: 0.120335, l6: 0.265055\n",
      "\n",
      "[epoch: 374/400, batch: 976/1000, ite: 49623] train loss: 1.1184, accuracy: 96.9683%, tar: 0.0208 \n",
      "l0: 0.018155, l1: 0.019311, l2: 0.025383, l3: 0.042063, l4: 0.071659, l5: 0.137446, l6: 0.333817\n",
      "\n",
      "[epoch: 374/400, batch: 984/1000, ite: 49624] train loss: 1.1183, accuracy: 95.4818%, tar: 0.0208 \n",
      "l0: 0.021989, l1: 0.023131, l2: 0.031638, l3: 0.042110, l4: 0.072153, l5: 0.140956, l6: 0.338680\n",
      "\n",
      "[epoch: 374/400, batch: 992/1000, ite: 49625] train loss: 1.1182, accuracy: 95.4504%, tar: 0.0208 \n",
      "l0: 0.019924, l1: 0.021342, l2: 0.029664, l3: 0.044879, l4: 0.082185, l5: 0.197815, l6: 0.357594\n",
      "\n",
      "[epoch: 374/400, batch: 1000/1000, ite: 49626] train loss: 1.1182, accuracy: 95.1076%, tar: 0.0208 \n",
      "l0: 0.019221, l1: 0.021618, l2: 0.030850, l3: 0.048039, l4: 0.087269, l5: 0.167910, l6: 0.371289\n",
      "\n",
      "[epoch: 375/400, batch: 8/1000, ite: 49627] train loss: 1.1182, accuracy: 95.6877%, tar: 0.0208 \n",
      "l0: 0.023568, l1: 0.026214, l2: 0.035935, l3: 0.054731, l4: 0.107652, l5: 0.187253, l6: 0.332153\n",
      "\n",
      "[epoch: 375/400, batch: 16/1000, ite: 49628] train loss: 1.1182, accuracy: 96.1144%, tar: 0.0208 \n",
      "l0: 0.023526, l1: 0.025085, l2: 0.036338, l3: 0.053778, l4: 0.099479, l5: 0.245062, l6: 0.542096\n",
      "\n",
      "[epoch: 375/400, batch: 24/1000, ite: 49629] train loss: 1.1185, accuracy: 92.4523%, tar: 0.0208 \n",
      "l0: 0.019405, l1: 0.020280, l2: 0.027151, l3: 0.042743, l4: 0.090593, l5: 0.184590, l6: 0.421469\n",
      "\n",
      "[epoch: 375/400, batch: 32/1000, ite: 49630] train loss: 1.1186, accuracy: 94.5572%, tar: 0.0208 \n",
      "l0: 0.019361, l1: 0.020047, l2: 0.026890, l3: 0.037292, l4: 0.067323, l5: 0.139253, l6: 0.316141\n",
      "\n",
      "[epoch: 375/400, batch: 40/1000, ite: 49631] train loss: 1.1184, accuracy: 95.0471%, tar: 0.0208 \n",
      "l0: 0.016605, l1: 0.017795, l2: 0.025781, l3: 0.039994, l4: 0.066766, l5: 0.129254, l6: 0.212456\n",
      "\n",
      "[epoch: 375/400, batch: 48/1000, ite: 49632] train loss: 1.1182, accuracy: 96.9048%, tar: 0.0208 \n",
      "l0: 0.028789, l1: 0.029852, l2: 0.038664, l3: 0.055461, l4: 0.102265, l5: 0.181212, l6: 0.357128\n",
      "\n",
      "[epoch: 375/400, batch: 56/1000, ite: 49633] train loss: 1.1182, accuracy: 93.9070%, tar: 0.0208 \n",
      "l0: 0.016577, l1: 0.017831, l2: 0.024202, l3: 0.035153, l4: 0.064054, l5: 0.129706, l6: 0.292628\n",
      "\n",
      "[epoch: 375/400, batch: 64/1000, ite: 49634] train loss: 1.1181, accuracy: 96.2329%, tar: 0.0208 \n",
      "l0: 0.027431, l1: 0.029543, l2: 0.040949, l3: 0.063533, l4: 0.118618, l5: 0.267123, l6: 0.485178\n",
      "\n",
      "[epoch: 375/400, batch: 72/1000, ite: 49635] train loss: 1.1183, accuracy: 93.6407%, tar: 0.0208 \n",
      "l0: 0.020010, l1: 0.021423, l2: 0.029991, l3: 0.048183, l4: 0.086136, l5: 0.193184, l6: 0.486432\n",
      "\n",
      "[epoch: 375/400, batch: 80/1000, ite: 49636] train loss: 1.1185, accuracy: 94.3454%, tar: 0.0208 \n",
      "l0: 0.014163, l1: 0.015333, l2: 0.021280, l3: 0.031797, l4: 0.053231, l5: 0.099169, l6: 0.239255\n",
      "\n",
      "[epoch: 375/400, batch: 88/1000, ite: 49637] train loss: 1.1182, accuracy: 96.6956%, tar: 0.0208 \n",
      "l0: 0.026958, l1: 0.028092, l2: 0.035381, l3: 0.055555, l4: 0.099842, l5: 0.197422, l6: 0.431239\n",
      "\n",
      "[epoch: 375/400, batch: 96/1000, ite: 49638] train loss: 1.1183, accuracy: 94.3112%, tar: 0.0208 \n",
      "l0: 0.019235, l1: 0.021941, l2: 0.033592, l3: 0.059583, l4: 0.116172, l5: 0.210009, l6: 0.391357\n",
      "\n",
      "[epoch: 375/400, batch: 104/1000, ite: 49639] train loss: 1.1184, accuracy: 95.6576%, tar: 0.0208 \n",
      "l0: 0.021894, l1: 0.023139, l2: 0.029425, l3: 0.042394, l4: 0.074009, l5: 0.143537, l6: 0.322177\n",
      "\n",
      "[epoch: 375/400, batch: 112/1000, ite: 49640] train loss: 1.1183, accuracy: 95.3562%, tar: 0.0208 \n",
      "l0: 0.031013, l1: 0.033260, l2: 0.043380, l3: 0.065699, l4: 0.130442, l5: 0.281467, l6: 0.506855\n",
      "\n",
      "[epoch: 375/400, batch: 120/1000, ite: 49641] train loss: 1.1186, accuracy: 92.8836%, tar: 0.0208 \n",
      "l0: 0.018597, l1: 0.020110, l2: 0.027752, l3: 0.041183, l4: 0.080888, l5: 0.133921, l6: 0.287243\n",
      "\n",
      "[epoch: 375/400, batch: 128/1000, ite: 49642] train loss: 1.1185, accuracy: 95.9739%, tar: 0.0208 \n",
      "l0: 0.014545, l1: 0.015985, l2: 0.023035, l3: 0.037721, l4: 0.073590, l5: 0.147568, l6: 0.315285\n",
      "\n",
      "[epoch: 375/400, batch: 136/1000, ite: 49643] train loss: 1.1184, accuracy: 96.9339%, tar: 0.0208 \n",
      "l0: 0.023709, l1: 0.025351, l2: 0.034876, l3: 0.054922, l4: 0.104908, l5: 0.228149, l6: 0.438884\n",
      "\n",
      "[epoch: 375/400, batch: 144/1000, ite: 49644] train loss: 1.1185, accuracy: 94.6538%, tar: 0.0208 \n",
      "l0: 0.021237, l1: 0.022115, l2: 0.029400, l3: 0.041354, l4: 0.073102, l5: 0.159061, l6: 0.316773\n",
      "\n",
      "[epoch: 375/400, batch: 152/1000, ite: 49645] train loss: 1.1185, accuracy: 95.6351%, tar: 0.0208 \n",
      "l0: 0.015779, l1: 0.016995, l2: 0.025026, l3: 0.040382, l4: 0.075534, l5: 0.158452, l6: 0.354085\n",
      "\n",
      "[epoch: 375/400, batch: 160/1000, ite: 49646] train loss: 1.1184, accuracy: 96.0253%, tar: 0.0208 \n",
      "l0: 0.022511, l1: 0.023772, l2: 0.032519, l3: 0.054231, l4: 0.116300, l5: 0.251626, l6: 0.460518\n",
      "\n",
      "[epoch: 375/400, batch: 168/1000, ite: 49647] train loss: 1.1186, accuracy: 94.0098%, tar: 0.0208 \n",
      "l0: 0.019391, l1: 0.020439, l2: 0.028536, l3: 0.041679, l4: 0.071882, l5: 0.147360, l6: 0.278528\n",
      "\n",
      "[epoch: 375/400, batch: 176/1000, ite: 49648] train loss: 1.1185, accuracy: 95.4647%, tar: 0.0208 \n",
      "l0: 0.026165, l1: 0.028063, l2: 0.039077, l3: 0.068344, l4: 0.133779, l5: 0.308183, l6: 0.522876\n",
      "\n",
      "[epoch: 375/400, batch: 184/1000, ite: 49649] train loss: 1.1188, accuracy: 92.8591%, tar: 0.0208 \n",
      "l0: 0.014985, l1: 0.015598, l2: 0.021265, l3: 0.029931, l4: 0.051833, l5: 0.099952, l6: 0.214811\n",
      "\n",
      "[epoch: 375/400, batch: 192/1000, ite: 49650] train loss: 1.1185, accuracy: 97.0510%, tar: 0.0208 \n",
      "l0: 0.019950, l1: 0.021266, l2: 0.028877, l3: 0.045256, l4: 0.087064, l5: 0.180980, l6: 0.384529\n",
      "\n",
      "[epoch: 375/400, batch: 200/1000, ite: 49651] train loss: 1.1185, accuracy: 94.6333%, tar: 0.0208 \n",
      "l0: 0.021265, l1: 0.023239, l2: 0.031306, l3: 0.046374, l4: 0.085134, l5: 0.225562, l6: 0.463708\n",
      "\n",
      "[epoch: 375/400, batch: 208/1000, ite: 49652] train loss: 1.1187, accuracy: 94.8660%, tar: 0.0208 \n",
      "l0: 0.020731, l1: 0.021764, l2: 0.027859, l3: 0.041448, l4: 0.085018, l5: 0.217884, l6: 0.398876\n",
      "\n",
      "[epoch: 375/400, batch: 216/1000, ite: 49653] train loss: 1.1187, accuracy: 93.7328%, tar: 0.0208 \n",
      "l0: 0.019940, l1: 0.021924, l2: 0.031970, l3: 0.058555, l4: 0.118085, l5: 0.230673, l6: 0.461474\n",
      "\n",
      "[epoch: 375/400, batch: 224/1000, ite: 49654] train loss: 1.1189, accuracy: 95.5576%, tar: 0.0208 \n",
      "l0: 0.019005, l1: 0.020136, l2: 0.026031, l3: 0.039478, l4: 0.084281, l5: 0.205945, l6: 0.409939\n",
      "\n",
      "[epoch: 375/400, batch: 232/1000, ite: 49655] train loss: 1.1190, accuracy: 94.8782%, tar: 0.0208 \n",
      "l0: 0.016010, l1: 0.017896, l2: 0.025544, l3: 0.045403, l4: 0.095528, l5: 0.186174, l6: 0.379686\n",
      "\n",
      "[epoch: 375/400, batch: 240/1000, ite: 49656] train loss: 1.1190, accuracy: 95.6205%, tar: 0.0208 \n",
      "l0: 0.032080, l1: 0.034763, l2: 0.049007, l3: 0.071720, l4: 0.137661, l5: 0.294737, l6: 0.528666\n",
      "\n",
      "[epoch: 375/400, batch: 248/1000, ite: 49657] train loss: 1.1193, accuracy: 92.7345%, tar: 0.0208 \n",
      "l0: 0.014825, l1: 0.016198, l2: 0.022908, l3: 0.035511, l4: 0.060960, l5: 0.141677, l6: 0.241890\n",
      "\n",
      "[epoch: 375/400, batch: 256/1000, ite: 49658] train loss: 1.1191, accuracy: 96.7174%, tar: 0.0208 \n",
      "l0: 0.028204, l1: 0.029801, l2: 0.039742, l3: 0.064638, l4: 0.132515, l5: 0.286450, l6: 0.587520\n",
      "\n",
      "[epoch: 375/400, batch: 264/1000, ite: 49659] train loss: 1.1195, accuracy: 91.4563%, tar: 0.0208 \n",
      "l0: 0.022175, l1: 0.023539, l2: 0.031070, l3: 0.045737, l4: 0.078274, l5: 0.154349, l6: 0.356017\n",
      "\n",
      "[epoch: 375/400, batch: 272/1000, ite: 49660] train loss: 1.1195, accuracy: 95.0617%, tar: 0.0208 \n",
      "l0: 0.016359, l1: 0.018085, l2: 0.026343, l3: 0.037874, l4: 0.072845, l5: 0.146347, l6: 0.329665\n",
      "\n",
      "[epoch: 375/400, batch: 280/1000, ite: 49661] train loss: 1.1194, accuracy: 95.8690%, tar: 0.0208 \n",
      "l0: 0.019659, l1: 0.021757, l2: 0.032066, l3: 0.058120, l4: 0.114567, l5: 0.257569, l6: 0.510201\n",
      "\n",
      "[epoch: 375/400, batch: 288/1000, ite: 49662] train loss: 1.1196, accuracy: 93.9802%, tar: 0.0208 \n",
      "l0: 0.026743, l1: 0.028470, l2: 0.038367, l3: 0.057177, l4: 0.104752, l5: 0.202199, l6: 0.418961\n",
      "\n",
      "[epoch: 375/400, batch: 296/1000, ite: 49663] train loss: 1.1197, accuracy: 93.8925%, tar: 0.0208 \n",
      "l0: 0.014895, l1: 0.016222, l2: 0.022496, l3: 0.033840, l4: 0.063546, l5: 0.132792, l6: 0.325885\n",
      "\n",
      "[epoch: 375/400, batch: 304/1000, ite: 49664] train loss: 1.1196, accuracy: 95.8573%, tar: 0.0208 \n",
      "l0: 0.018002, l1: 0.018785, l2: 0.023983, l3: 0.034493, l4: 0.060951, l5: 0.118048, l6: 0.257940\n",
      "\n",
      "[epoch: 375/400, batch: 312/1000, ite: 49665] train loss: 1.1194, accuracy: 96.1574%, tar: 0.0208 \n",
      "l0: 0.019141, l1: 0.020257, l2: 0.028028, l3: 0.041490, l4: 0.075105, l5: 0.159472, l6: 0.370535\n",
      "\n",
      "[epoch: 375/400, batch: 320/1000, ite: 49666] train loss: 1.1194, accuracy: 95.0302%, tar: 0.0208 \n",
      "l0: 0.021216, l1: 0.022397, l2: 0.031360, l3: 0.050214, l4: 0.086971, l5: 0.152319, l6: 0.320494\n",
      "\n",
      "[epoch: 375/400, batch: 328/1000, ite: 49667] train loss: 1.1193, accuracy: 95.9904%, tar: 0.0208 \n",
      "l0: 0.023640, l1: 0.025737, l2: 0.032881, l3: 0.048237, l4: 0.094630, l5: 0.227097, l6: 0.406177\n",
      "\n",
      "[epoch: 375/400, batch: 336/1000, ite: 49668] train loss: 1.1194, accuracy: 94.7597%, tar: 0.0208 \n",
      "l0: 0.020988, l1: 0.023172, l2: 0.032480, l3: 0.053000, l4: 0.104415, l5: 0.195450, l6: 0.374446\n",
      "\n",
      "[epoch: 375/400, batch: 344/1000, ite: 49669] train loss: 1.1195, accuracy: 94.6238%, tar: 0.0208 \n",
      "l0: 0.021982, l1: 0.023706, l2: 0.031919, l3: 0.053973, l4: 0.134070, l5: 0.264060, l6: 0.498221\n",
      "\n",
      "[epoch: 375/400, batch: 352/1000, ite: 49670] train loss: 1.1197, accuracy: 93.8102%, tar: 0.0208 \n",
      "l0: 0.014138, l1: 0.014989, l2: 0.018740, l3: 0.029671, l4: 0.062133, l5: 0.145826, l6: 0.387924\n",
      "\n",
      "[epoch: 375/400, batch: 360/1000, ite: 49671] train loss: 1.1197, accuracy: 94.2994%, tar: 0.0208 \n",
      "l0: 0.019614, l1: 0.021014, l2: 0.030425, l3: 0.045393, l4: 0.078152, l5: 0.133718, l6: 0.307645\n",
      "\n",
      "[epoch: 375/400, batch: 368/1000, ite: 49672] train loss: 1.1196, accuracy: 95.6638%, tar: 0.0208 \n",
      "l0: 0.022400, l1: 0.023885, l2: 0.033284, l3: 0.050231, l4: 0.090129, l5: 0.189914, l6: 0.408652\n",
      "\n",
      "[epoch: 375/400, batch: 376/1000, ite: 49673] train loss: 1.1197, accuracy: 94.8433%, tar: 0.0208 \n",
      "l0: 0.019346, l1: 0.021100, l2: 0.029579, l3: 0.047834, l4: 0.091747, l5: 0.197042, l6: 0.343561\n",
      "\n",
      "[epoch: 375/400, batch: 384/1000, ite: 49674] train loss: 1.1196, accuracy: 95.3229%, tar: 0.0208 \n",
      "l0: 0.021722, l1: 0.022200, l2: 0.029565, l3: 0.043155, l4: 0.074717, l5: 0.151581, l6: 0.360000\n",
      "\n",
      "[epoch: 375/400, batch: 392/1000, ite: 49675] train loss: 1.1196, accuracy: 95.0377%, tar: 0.0208 \n",
      "l0: 0.018829, l1: 0.019381, l2: 0.026872, l3: 0.038627, l4: 0.064282, l5: 0.132564, l6: 0.330107\n",
      "\n",
      "[epoch: 375/400, batch: 400/1000, ite: 49676] train loss: 1.1195, accuracy: 95.2168%, tar: 0.0208 \n",
      "l0: 0.016741, l1: 0.017851, l2: 0.025243, l3: 0.039245, l4: 0.069296, l5: 0.159851, l6: 0.307041\n",
      "\n",
      "[epoch: 375/400, batch: 408/1000, ite: 49677] train loss: 1.1194, accuracy: 95.3710%, tar: 0.0208 \n",
      "l0: 0.016682, l1: 0.017943, l2: 0.025877, l3: 0.041294, l4: 0.085473, l5: 0.184526, l6: 0.341603\n",
      "\n",
      "[epoch: 375/400, batch: 416/1000, ite: 49678] train loss: 1.1194, accuracy: 95.3723%, tar: 0.0208 \n",
      "l0: 0.020417, l1: 0.021401, l2: 0.029136, l3: 0.042159, l4: 0.078008, l5: 0.163356, l6: 0.363059\n",
      "\n",
      "[epoch: 375/400, batch: 424/1000, ite: 49679] train loss: 1.1194, accuracy: 95.0965%, tar: 0.0208 \n",
      "l0: 0.019248, l1: 0.020492, l2: 0.027927, l3: 0.046417, l4: 0.075414, l5: 0.148711, l6: 0.373901\n",
      "\n",
      "[epoch: 375/400, batch: 432/1000, ite: 49680] train loss: 1.1193, accuracy: 95.0686%, tar: 0.0208 \n",
      "l0: 0.022713, l1: 0.023179, l2: 0.029867, l3: 0.041887, l4: 0.064682, l5: 0.142188, l6: 0.293081\n",
      "\n",
      "[epoch: 375/400, batch: 440/1000, ite: 49681] train loss: 1.1192, accuracy: 95.9119%, tar: 0.0208 \n",
      "l0: 0.019066, l1: 0.019885, l2: 0.024560, l3: 0.034868, l4: 0.061205, l5: 0.105785, l6: 0.230327\n",
      "\n",
      "[epoch: 375/400, batch: 448/1000, ite: 49682] train loss: 1.1190, accuracy: 96.1721%, tar: 0.0208 \n",
      "l0: 0.017797, l1: 0.019020, l2: 0.023496, l3: 0.034660, l4: 0.055394, l5: 0.113405, l6: 0.234141\n",
      "\n",
      "[epoch: 375/400, batch: 456/1000, ite: 49683] train loss: 1.1188, accuracy: 96.5329%, tar: 0.0208 \n",
      "l0: 0.022710, l1: 0.023933, l2: 0.031887, l3: 0.048563, l4: 0.085596, l5: 0.159158, l6: 0.419438\n",
      "\n",
      "[epoch: 375/400, batch: 464/1000, ite: 49684] train loss: 1.1188, accuracy: 94.5437%, tar: 0.0208 \n",
      "l0: 0.017231, l1: 0.019070, l2: 0.027015, l3: 0.043341, l4: 0.076152, l5: 0.152704, l6: 0.388183\n",
      "\n",
      "[epoch: 375/400, batch: 472/1000, ite: 49685] train loss: 1.1188, accuracy: 96.0403%, tar: 0.0208 \n",
      "l0: 0.021865, l1: 0.022992, l2: 0.029571, l3: 0.046438, l4: 0.086193, l5: 0.190611, l6: 0.411381\n",
      "\n",
      "[epoch: 375/400, batch: 480/1000, ite: 49686] train loss: 1.1189, accuracy: 93.7487%, tar: 0.0208 \n",
      "l0: 0.018516, l1: 0.019170, l2: 0.026122, l3: 0.038343, l4: 0.060031, l5: 0.110698, l6: 0.266899\n",
      "\n",
      "[epoch: 375/400, batch: 488/1000, ite: 49687] train loss: 1.1187, accuracy: 95.8702%, tar: 0.0208 \n",
      "l0: 0.022694, l1: 0.024057, l2: 0.033222, l3: 0.049629, l4: 0.089850, l5: 0.195154, l6: 0.407151\n",
      "\n",
      "[epoch: 375/400, batch: 496/1000, ite: 49688] train loss: 1.1188, accuracy: 94.4082%, tar: 0.0208 \n",
      "l0: 0.022846, l1: 0.024768, l2: 0.035016, l3: 0.056521, l4: 0.107557, l5: 0.221111, l6: 0.426041\n",
      "\n",
      "[epoch: 375/400, batch: 504/1000, ite: 49689] train loss: 1.1189, accuracy: 95.1314%, tar: 0.0208 \n",
      "l0: 0.019050, l1: 0.019636, l2: 0.026093, l3: 0.040418, l4: 0.072719, l5: 0.124704, l6: 0.229061\n",
      "\n",
      "[epoch: 375/400, batch: 512/1000, ite: 49690] train loss: 1.1187, accuracy: 95.9477%, tar: 0.0208 \n",
      "l0: 0.019402, l1: 0.020446, l2: 0.026743, l3: 0.040949, l4: 0.081118, l5: 0.199373, l6: 0.344112\n",
      "\n",
      "[epoch: 375/400, batch: 520/1000, ite: 49691] train loss: 1.1186, accuracy: 94.9221%, tar: 0.0208 \n",
      "l0: 0.020945, l1: 0.021961, l2: 0.030432, l3: 0.047407, l4: 0.096651, l5: 0.176714, l6: 0.416638\n",
      "\n",
      "[epoch: 375/400, batch: 528/1000, ite: 49692] train loss: 1.1187, accuracy: 94.5842%, tar: 0.0208 \n",
      "l0: 0.021232, l1: 0.021781, l2: 0.029571, l3: 0.043230, l4: 0.077691, l5: 0.176984, l6: 0.404741\n",
      "\n",
      "[epoch: 375/400, batch: 536/1000, ite: 49693] train loss: 1.1188, accuracy: 94.7699%, tar: 0.0208 \n",
      "l0: 0.017805, l1: 0.018886, l2: 0.025100, l3: 0.038036, l4: 0.068260, l5: 0.133348, l6: 0.281038\n",
      "\n",
      "[epoch: 375/400, batch: 544/1000, ite: 49694] train loss: 1.1186, accuracy: 95.6707%, tar: 0.0208 \n",
      "l0: 0.023077, l1: 0.025407, l2: 0.036233, l3: 0.056001, l4: 0.113425, l5: 0.225735, l6: 0.432473\n",
      "\n",
      "[epoch: 375/400, batch: 552/1000, ite: 49695] train loss: 1.1187, accuracy: 94.4763%, tar: 0.0208 \n",
      "l0: 0.018673, l1: 0.019797, l2: 0.023601, l3: 0.033494, l4: 0.058627, l5: 0.105616, l6: 0.224663\n",
      "\n",
      "[epoch: 375/400, batch: 560/1000, ite: 49696] train loss: 1.1185, accuracy: 96.3727%, tar: 0.0208 \n",
      "l0: 0.017425, l1: 0.018796, l2: 0.025707, l3: 0.040661, l4: 0.066772, l5: 0.130708, l6: 0.301846\n",
      "\n",
      "[epoch: 375/400, batch: 568/1000, ite: 49697] train loss: 1.1184, accuracy: 95.6308%, tar: 0.0208 \n",
      "l0: 0.026872, l1: 0.028134, l2: 0.036116, l3: 0.051086, l4: 0.088569, l5: 0.177378, l6: 0.414862\n",
      "\n",
      "[epoch: 375/400, batch: 576/1000, ite: 49698] train loss: 1.1184, accuracy: 93.7101%, tar: 0.0208 \n",
      "l0: 0.020426, l1: 0.021729, l2: 0.030014, l3: 0.043713, l4: 0.076456, l5: 0.159683, l6: 0.312586\n",
      "\n",
      "[epoch: 375/400, batch: 584/1000, ite: 49699] train loss: 1.1184, accuracy: 95.3526%, tar: 0.0208 \n",
      "l0: 0.020832, l1: 0.022209, l2: 0.030568, l3: 0.046397, l4: 0.077657, l5: 0.139492, l6: 0.311839\n",
      "\n",
      "[epoch: 375/400, batch: 592/1000, ite: 49700] train loss: 1.1183, accuracy: 95.2197%, tar: 0.0208 \n",
      "l0: 0.028793, l1: 0.030450, l2: 0.038426, l3: 0.061098, l4: 0.127001, l5: 0.266961, l6: 0.540563\n",
      "\n",
      "[epoch: 375/400, batch: 600/1000, ite: 49701] train loss: 1.1186, accuracy: 93.2042%, tar: 0.0208 \n",
      "l0: 0.016352, l1: 0.017583, l2: 0.025071, l3: 0.042932, l4: 0.083154, l5: 0.157499, l6: 0.344733\n",
      "\n",
      "[epoch: 375/400, batch: 608/1000, ite: 49702] train loss: 1.1185, accuracy: 95.8159%, tar: 0.0208 \n",
      "l0: 0.023961, l1: 0.025136, l2: 0.033656, l3: 0.055703, l4: 0.107851, l5: 0.206847, l6: 0.453481\n",
      "\n",
      "[epoch: 375/400, batch: 616/1000, ite: 49703] train loss: 1.1187, accuracy: 93.8541%, tar: 0.0208 \n",
      "l0: 0.023101, l1: 0.024092, l2: 0.034537, l3: 0.048253, l4: 0.083568, l5: 0.166370, l6: 0.352115\n",
      "\n",
      "[epoch: 375/400, batch: 624/1000, ite: 49704] train loss: 1.1187, accuracy: 95.2334%, tar: 0.0208 \n",
      "l0: 0.017914, l1: 0.019346, l2: 0.028404, l3: 0.049214, l4: 0.099381, l5: 0.178240, l6: 0.298834\n",
      "\n",
      "[epoch: 375/400, batch: 632/1000, ite: 49705] train loss: 1.1186, accuracy: 96.1912%, tar: 0.0208 \n",
      "l0: 0.016813, l1: 0.017798, l2: 0.025064, l3: 0.036229, l4: 0.062873, l5: 0.123910, l6: 0.288289\n",
      "\n",
      "[epoch: 375/400, batch: 640/1000, ite: 49706] train loss: 1.1184, accuracy: 96.0688%, tar: 0.0208 \n",
      "l0: 0.023989, l1: 0.025410, l2: 0.033773, l3: 0.051436, l4: 0.091127, l5: 0.204051, l6: 0.414006\n",
      "\n",
      "[epoch: 375/400, batch: 648/1000, ite: 49707] train loss: 1.1185, accuracy: 93.8926%, tar: 0.0208 \n",
      "l0: 0.023772, l1: 0.025149, l2: 0.034168, l3: 0.048427, l4: 0.097606, l5: 0.168217, l6: 0.333933\n",
      "\n",
      "[epoch: 375/400, batch: 656/1000, ite: 49708] train loss: 1.1185, accuracy: 95.0090%, tar: 0.0208 \n",
      "l0: 0.024929, l1: 0.026115, l2: 0.036125, l3: 0.051287, l4: 0.094087, l5: 0.192789, l6: 0.443849\n",
      "\n",
      "[epoch: 375/400, batch: 664/1000, ite: 49709] train loss: 1.1186, accuracy: 94.6262%, tar: 0.0208 \n",
      "l0: 0.020630, l1: 0.022196, l2: 0.032783, l3: 0.050932, l4: 0.110911, l5: 0.216029, l6: 0.391470\n",
      "\n",
      "[epoch: 375/400, batch: 672/1000, ite: 49710] train loss: 1.1187, accuracy: 94.6854%, tar: 0.0208 \n",
      "l0: 0.020845, l1: 0.021512, l2: 0.028547, l3: 0.042977, l4: 0.073854, l5: 0.136965, l6: 0.257169\n",
      "\n",
      "[epoch: 375/400, batch: 680/1000, ite: 49711] train loss: 1.1185, accuracy: 96.1810%, tar: 0.0208 \n",
      "l0: 0.016132, l1: 0.017133, l2: 0.022988, l3: 0.034055, l4: 0.061468, l5: 0.121971, l6: 0.258270\n",
      "\n",
      "[epoch: 375/400, batch: 688/1000, ite: 49712] train loss: 1.1183, accuracy: 96.2716%, tar: 0.0208 \n",
      "l0: 0.015441, l1: 0.016800, l2: 0.025846, l3: 0.038515, l4: 0.071819, l5: 0.147551, l6: 0.250541\n",
      "\n",
      "[epoch: 375/400, batch: 696/1000, ite: 49713] train loss: 1.1181, accuracy: 97.0825%, tar: 0.0208 \n",
      "l0: 0.024520, l1: 0.025581, l2: 0.032333, l3: 0.046719, l4: 0.075805, l5: 0.153158, l6: 0.316174\n",
      "\n",
      "[epoch: 375/400, batch: 704/1000, ite: 49714] train loss: 1.1181, accuracy: 94.8783%, tar: 0.0208 \n",
      "l0: 0.024399, l1: 0.025721, l2: 0.035099, l3: 0.053746, l4: 0.104087, l5: 0.228275, l6: 0.424797\n",
      "\n",
      "[epoch: 375/400, batch: 712/1000, ite: 49715] train loss: 1.1182, accuracy: 93.8325%, tar: 0.0208 \n",
      "l0: 0.016200, l1: 0.016991, l2: 0.022451, l3: 0.032997, l4: 0.061842, l5: 0.136722, l6: 0.393991\n",
      "\n",
      "[epoch: 375/400, batch: 720/1000, ite: 49716] train loss: 1.1182, accuracy: 95.5762%, tar: 0.0208 \n",
      "l0: 0.022942, l1: 0.024078, l2: 0.031837, l3: 0.043673, l4: 0.084343, l5: 0.166503, l6: 0.295528\n",
      "\n",
      "[epoch: 375/400, batch: 728/1000, ite: 49717] train loss: 1.1181, accuracy: 95.7546%, tar: 0.0208 \n",
      "l0: 0.014171, l1: 0.014917, l2: 0.020893, l3: 0.030228, l4: 0.054232, l5: 0.115701, l6: 0.265800\n",
      "\n",
      "[epoch: 375/400, batch: 736/1000, ite: 49718] train loss: 1.1179, accuracy: 96.1286%, tar: 0.0208 \n",
      "l0: 0.014650, l1: 0.015666, l2: 0.021436, l3: 0.033389, l4: 0.055452, l5: 0.107895, l6: 0.220509\n",
      "\n",
      "[epoch: 375/400, batch: 744/1000, ite: 49719] train loss: 1.1176, accuracy: 96.7465%, tar: 0.0208 \n",
      "l0: 0.021263, l1: 0.022597, l2: 0.030993, l3: 0.048161, l4: 0.095760, l5: 0.206088, l6: 0.388061\n",
      "\n",
      "[epoch: 375/400, batch: 752/1000, ite: 49720] train loss: 1.1177, accuracy: 95.0022%, tar: 0.0208 \n",
      "l0: 0.022620, l1: 0.023827, l2: 0.029705, l3: 0.043757, l4: 0.071393, l5: 0.139388, l6: 0.312680\n",
      "\n",
      "[epoch: 375/400, batch: 760/1000, ite: 49721] train loss: 1.1176, accuracy: 94.6629%, tar: 0.0208 \n",
      "l0: 0.021001, l1: 0.022165, l2: 0.027866, l3: 0.041554, l4: 0.081274, l5: 0.200468, l6: 0.382709\n",
      "\n",
      "[epoch: 375/400, batch: 768/1000, ite: 49722] train loss: 1.1176, accuracy: 94.8610%, tar: 0.0208 \n",
      "l0: 0.024786, l1: 0.025451, l2: 0.032946, l3: 0.047381, l4: 0.084060, l5: 0.161802, l6: 0.337760\n",
      "\n",
      "[epoch: 375/400, batch: 776/1000, ite: 49723] train loss: 1.1176, accuracy: 94.6476%, tar: 0.0208 \n",
      "l0: 0.020492, l1: 0.021855, l2: 0.028606, l3: 0.039907, l4: 0.071984, l5: 0.147159, l6: 0.277117\n",
      "\n",
      "[epoch: 375/400, batch: 784/1000, ite: 49724] train loss: 1.1175, accuracy: 95.8186%, tar: 0.0208 \n",
      "l0: 0.020034, l1: 0.021816, l2: 0.030402, l3: 0.050445, l4: 0.090974, l5: 0.180783, l6: 0.342886\n",
      "\n",
      "[epoch: 375/400, batch: 792/1000, ite: 49725] train loss: 1.1174, accuracy: 95.7413%, tar: 0.0208 \n",
      "l0: 0.023011, l1: 0.024461, l2: 0.032716, l3: 0.056326, l4: 0.123954, l5: 0.238632, l6: 0.424297\n",
      "\n",
      "[epoch: 375/400, batch: 800/1000, ite: 49726] train loss: 1.1176, accuracy: 94.2756%, tar: 0.0208 \n",
      "l0: 0.019954, l1: 0.021499, l2: 0.028662, l3: 0.045605, l4: 0.078576, l5: 0.148058, l6: 0.338794\n",
      "\n",
      "[epoch: 375/400, batch: 808/1000, ite: 49727] train loss: 1.1175, accuracy: 95.4715%, tar: 0.0208 \n",
      "l0: 0.018185, l1: 0.020353, l2: 0.029415, l3: 0.048433, l4: 0.088929, l5: 0.163554, l6: 0.381934\n",
      "\n",
      "[epoch: 375/400, batch: 816/1000, ite: 49728] train loss: 1.1175, accuracy: 95.4012%, tar: 0.0208 \n",
      "l0: 0.022905, l1: 0.025492, l2: 0.034642, l3: 0.055728, l4: 0.107406, l5: 0.247614, l6: 0.577673\n",
      "\n",
      "[epoch: 375/400, batch: 824/1000, ite: 49729] train loss: 1.1178, accuracy: 93.3422%, tar: 0.0208 \n",
      "l0: 0.015053, l1: 0.016299, l2: 0.022076, l3: 0.034694, l4: 0.070216, l5: 0.127078, l6: 0.281360\n",
      "\n",
      "[epoch: 375/400, batch: 832/1000, ite: 49730] train loss: 1.1177, accuracy: 96.4667%, tar: 0.0208 \n",
      "l0: 0.023082, l1: 0.024394, l2: 0.031005, l3: 0.043495, l4: 0.072676, l5: 0.137577, l6: 0.313551\n",
      "\n",
      "[epoch: 375/400, batch: 840/1000, ite: 49731] train loss: 1.1176, accuracy: 95.4810%, tar: 0.0208 \n",
      "l0: 0.021613, l1: 0.023235, l2: 0.032413, l3: 0.047353, l4: 0.085142, l5: 0.202052, l6: 0.425140\n",
      "\n",
      "[epoch: 375/400, batch: 848/1000, ite: 49732] train loss: 1.1177, accuracy: 94.4406%, tar: 0.0208 \n",
      "l0: 0.022415, l1: 0.023661, l2: 0.032075, l3: 0.050173, l4: 0.110826, l5: 0.182713, l6: 0.331071\n",
      "\n",
      "[epoch: 375/400, batch: 856/1000, ite: 49733] train loss: 1.1177, accuracy: 95.2093%, tar: 0.0208 \n",
      "l0: 0.018757, l1: 0.020218, l2: 0.027466, l3: 0.041773, l4: 0.088806, l5: 0.217359, l6: 0.411424\n",
      "\n",
      "[epoch: 375/400, batch: 864/1000, ite: 49734] train loss: 1.1177, accuracy: 94.1849%, tar: 0.0208 \n",
      "l0: 0.020414, l1: 0.021032, l2: 0.026556, l3: 0.039718, l4: 0.069880, l5: 0.138695, l6: 0.310996\n",
      "\n",
      "[epoch: 375/400, batch: 872/1000, ite: 49735] train loss: 1.1176, accuracy: 94.9391%, tar: 0.0208 \n",
      "l0: 0.026414, l1: 0.027505, l2: 0.034726, l3: 0.050210, l4: 0.101065, l5: 0.228516, l6: 0.493595\n",
      "\n",
      "[epoch: 375/400, batch: 880/1000, ite: 49736] train loss: 1.1178, accuracy: 92.8735%, tar: 0.0208 \n",
      "l0: 0.018618, l1: 0.019268, l2: 0.025983, l3: 0.037950, l4: 0.064113, l5: 0.141108, l6: 0.318168\n",
      "\n",
      "[epoch: 375/400, batch: 888/1000, ite: 49737] train loss: 1.1177, accuracy: 95.9308%, tar: 0.0208 \n",
      "l0: 0.021513, l1: 0.022516, l2: 0.029340, l3: 0.043584, l4: 0.078237, l5: 0.146762, l6: 0.360502\n",
      "\n",
      "[epoch: 375/400, batch: 896/1000, ite: 49738] train loss: 1.1177, accuracy: 94.5859%, tar: 0.0208 \n",
      "l0: 0.019761, l1: 0.021061, l2: 0.031101, l3: 0.050205, l4: 0.116307, l5: 0.241068, l6: 0.428148\n",
      "\n",
      "[epoch: 375/400, batch: 904/1000, ite: 49739] train loss: 1.1178, accuracy: 94.8246%, tar: 0.0208 \n",
      "l0: 0.020331, l1: 0.021116, l2: 0.028011, l3: 0.040872, l4: 0.076791, l5: 0.182855, l6: 0.390774\n",
      "\n",
      "[epoch: 375/400, batch: 912/1000, ite: 49740] train loss: 1.1178, accuracy: 95.1422%, tar: 0.0208 \n",
      "l0: 0.023228, l1: 0.024973, l2: 0.035233, l3: 0.057665, l4: 0.120090, l5: 0.238712, l6: 0.424927\n",
      "\n",
      "[epoch: 375/400, batch: 920/1000, ite: 49741] train loss: 1.1180, accuracy: 94.3954%, tar: 0.0208 \n",
      "l0: 0.021731, l1: 0.022825, l2: 0.029408, l3: 0.043759, l4: 0.083914, l5: 0.193674, l6: 0.395963\n",
      "\n",
      "[epoch: 375/400, batch: 928/1000, ite: 49742] train loss: 1.1180, accuracy: 94.7831%, tar: 0.0208 \n",
      "l0: 0.024751, l1: 0.026042, l2: 0.034982, l3: 0.052694, l4: 0.094835, l5: 0.178848, l6: 0.342938\n",
      "\n",
      "[epoch: 375/400, batch: 936/1000, ite: 49743] train loss: 1.1180, accuracy: 94.3815%, tar: 0.0208 \n",
      "l0: 0.023008, l1: 0.024474, l2: 0.032146, l3: 0.048139, l4: 0.094240, l5: 0.219684, l6: 0.437601\n",
      "\n",
      "[epoch: 375/400, batch: 944/1000, ite: 49744] train loss: 1.1181, accuracy: 94.2579%, tar: 0.0208 \n",
      "l0: 0.014774, l1: 0.016404, l2: 0.024723, l3: 0.039520, l4: 0.088835, l5: 0.208857, l6: 0.412568\n",
      "\n",
      "[epoch: 375/400, batch: 952/1000, ite: 49745] train loss: 1.1182, accuracy: 95.4152%, tar: 0.0208 \n",
      "l0: 0.022165, l1: 0.023376, l2: 0.030651, l3: 0.046923, l4: 0.091718, l5: 0.185147, l6: 0.315500\n",
      "\n",
      "[epoch: 375/400, batch: 960/1000, ite: 49746] train loss: 1.1181, accuracy: 95.1015%, tar: 0.0208 \n",
      "l0: 0.019430, l1: 0.020967, l2: 0.030352, l3: 0.047131, l4: 0.082955, l5: 0.152256, l6: 0.307618\n",
      "\n",
      "[epoch: 375/400, batch: 968/1000, ite: 49747] train loss: 1.1181, accuracy: 96.1697%, tar: 0.0208 \n",
      "l0: 0.021209, l1: 0.022516, l2: 0.032312, l3: 0.053584, l4: 0.109980, l5: 0.217770, l6: 0.391356\n",
      "\n",
      "[epoch: 375/400, batch: 976/1000, ite: 49748] train loss: 1.1181, accuracy: 94.9111%, tar: 0.0208 \n",
      "l0: 0.019709, l1: 0.020610, l2: 0.026815, l3: 0.038495, l4: 0.076517, l5: 0.160905, l6: 0.366561\n",
      "\n",
      "[epoch: 375/400, batch: 984/1000, ite: 49749] train loss: 1.1181, accuracy: 95.0879%, tar: 0.0208 \n",
      "l0: 0.022969, l1: 0.024214, l2: 0.032029, l3: 0.047266, l4: 0.087195, l5: 0.197108, l6: 0.399742\n",
      "\n",
      "[epoch: 375/400, batch: 992/1000, ite: 49750] train loss: 1.1182, accuracy: 94.3271%, tar: 0.0208 \n",
      "l0: 0.017051, l1: 0.018121, l2: 0.026631, l3: 0.041529, l4: 0.074329, l5: 0.133801, l6: 0.265783\n",
      "\n",
      "[epoch: 375/400, batch: 1000/1000, ite: 49751] train loss: 1.1180, accuracy: 96.5050%, tar: 0.0208 \n",
      "l0: 0.024295, l1: 0.025753, l2: 0.033261, l3: 0.050079, l4: 0.096467, l5: 0.201624, l6: 0.470322\n",
      "\n",
      "[epoch: 376/400, batch: 8/1000, ite: 49752] train loss: 1.1181, accuracy: 93.2840%, tar: 0.0208 \n",
      "l0: 0.019061, l1: 0.020464, l2: 0.028063, l3: 0.044754, l4: 0.103033, l5: 0.181608, l6: 0.364531\n",
      "\n",
      "[epoch: 376/400, batch: 16/1000, ite: 49753] train loss: 1.1182, accuracy: 95.2438%, tar: 0.0208 \n",
      "l0: 0.016920, l1: 0.017890, l2: 0.025909, l3: 0.039382, l4: 0.071040, l5: 0.134940, l6: 0.347640\n",
      "\n",
      "[epoch: 376/400, batch: 24/1000, ite: 49754] train loss: 1.1181, accuracy: 95.7204%, tar: 0.0208 \n",
      "l0: 0.019092, l1: 0.019940, l2: 0.028449, l3: 0.043264, l4: 0.072870, l5: 0.148848, l6: 0.284830\n",
      "\n",
      "[epoch: 376/400, batch: 32/1000, ite: 49755] train loss: 1.1180, accuracy: 95.7591%, tar: 0.0208 \n",
      "l0: 0.019870, l1: 0.021440, l2: 0.030807, l3: 0.052380, l4: 0.103504, l5: 0.264467, l6: 0.487223\n",
      "\n",
      "[epoch: 376/400, batch: 40/1000, ite: 49756] train loss: 1.1182, accuracy: 94.4989%, tar: 0.0208 \n",
      "l0: 0.018999, l1: 0.020311, l2: 0.028392, l3: 0.044497, l4: 0.083695, l5: 0.181341, l6: 0.385136\n",
      "\n",
      "[epoch: 376/400, batch: 48/1000, ite: 49757] train loss: 1.1182, accuracy: 95.0526%, tar: 0.0208 \n",
      "l0: 0.021610, l1: 0.023386, l2: 0.031833, l3: 0.050619, l4: 0.086150, l5: 0.172209, l6: 0.325298\n",
      "\n",
      "[epoch: 376/400, batch: 56/1000, ite: 49758] train loss: 1.1181, accuracy: 95.7347%, tar: 0.0208 \n",
      "l0: 0.015676, l1: 0.016638, l2: 0.022615, l3: 0.034508, l4: 0.061215, l5: 0.104165, l6: 0.256803\n",
      "\n",
      "[epoch: 376/400, batch: 64/1000, ite: 49759] train loss: 1.1179, accuracy: 96.3577%, tar: 0.0208 \n",
      "l0: 0.018834, l1: 0.019943, l2: 0.026855, l3: 0.042414, l4: 0.080963, l5: 0.164551, l6: 0.342426\n",
      "\n",
      "[epoch: 376/400, batch: 72/1000, ite: 49760] train loss: 1.1179, accuracy: 95.0370%, tar: 0.0208 \n",
      "l0: 0.019998, l1: 0.020967, l2: 0.028229, l3: 0.041292, l4: 0.070458, l5: 0.149550, l6: 0.343067\n",
      "\n",
      "[epoch: 376/400, batch: 80/1000, ite: 49761] train loss: 1.1179, accuracy: 94.9040%, tar: 0.0208 \n",
      "l0: 0.016018, l1: 0.017387, l2: 0.025143, l3: 0.038163, l4: 0.072032, l5: 0.137645, l6: 0.328264\n",
      "\n",
      "[epoch: 376/400, batch: 88/1000, ite: 49762] train loss: 1.1178, accuracy: 96.0869%, tar: 0.0208 \n",
      "l0: 0.019520, l1: 0.020798, l2: 0.028419, l3: 0.045729, l4: 0.090256, l5: 0.180101, l6: 0.362296\n",
      "\n",
      "[epoch: 376/400, batch: 96/1000, ite: 49763] train loss: 1.1178, accuracy: 95.0380%, tar: 0.0208 \n",
      "l0: 0.015150, l1: 0.016479, l2: 0.023345, l3: 0.036906, l4: 0.080726, l5: 0.175521, l6: 0.335112\n",
      "\n",
      "[epoch: 376/400, batch: 104/1000, ite: 49764] train loss: 1.1177, accuracy: 95.3732%, tar: 0.0208 \n",
      "l0: 0.019769, l1: 0.020978, l2: 0.029486, l3: 0.042095, l4: 0.080713, l5: 0.168777, l6: 0.367376\n",
      "\n",
      "[epoch: 376/400, batch: 112/1000, ite: 49765] train loss: 1.1177, accuracy: 95.1650%, tar: 0.0208 \n",
      "l0: 0.030664, l1: 0.031878, l2: 0.041150, l3: 0.060633, l4: 0.102568, l5: 0.186259, l6: 0.354429\n",
      "\n",
      "[epoch: 376/400, batch: 120/1000, ite: 49766] train loss: 1.1177, accuracy: 93.9170%, tar: 0.0208 \n",
      "l0: 0.022350, l1: 0.022904, l2: 0.030702, l3: 0.045349, l4: 0.093139, l5: 0.205950, l6: 0.416447\n",
      "\n",
      "[epoch: 376/400, batch: 128/1000, ite: 49767] train loss: 1.1178, accuracy: 94.2129%, tar: 0.0208 \n",
      "l0: 0.020257, l1: 0.021722, l2: 0.030138, l3: 0.045731, l4: 0.093062, l5: 0.163245, l6: 0.353890\n",
      "\n",
      "[epoch: 376/400, batch: 136/1000, ite: 49768] train loss: 1.1178, accuracy: 95.5579%, tar: 0.0208 \n",
      "l0: 0.018252, l1: 0.018962, l2: 0.025611, l3: 0.036642, l4: 0.079292, l5: 0.141619, l6: 0.363619\n",
      "\n",
      "[epoch: 376/400, batch: 144/1000, ite: 49769] train loss: 1.1177, accuracy: 95.1471%, tar: 0.0208 \n",
      "l0: 0.025235, l1: 0.026228, l2: 0.033848, l3: 0.052465, l4: 0.094746, l5: 0.219235, l6: 0.478644\n",
      "\n",
      "[epoch: 376/400, batch: 152/1000, ite: 49770] train loss: 1.1179, accuracy: 92.6609%, tar: 0.0208 \n",
      "l0: 0.024310, l1: 0.025578, l2: 0.034135, l3: 0.050738, l4: 0.088925, l5: 0.187757, l6: 0.437402\n",
      "\n",
      "[epoch: 376/400, batch: 160/1000, ite: 49771] train loss: 1.1180, accuracy: 93.7923%, tar: 0.0208 \n",
      "l0: 0.025269, l1: 0.026548, l2: 0.035034, l3: 0.051946, l4: 0.097509, l5: 0.230726, l6: 0.481824\n",
      "\n",
      "[epoch: 376/400, batch: 168/1000, ite: 49772] train loss: 1.1182, accuracy: 93.0108%, tar: 0.0208 \n",
      "l0: 0.024717, l1: 0.026688, l2: 0.035351, l3: 0.052706, l4: 0.096164, l5: 0.187777, l6: 0.407600\n",
      "\n",
      "[epoch: 376/400, batch: 176/1000, ite: 49773] train loss: 1.1182, accuracy: 95.1899%, tar: 0.0208 \n",
      "l0: 0.023384, l1: 0.024862, l2: 0.035829, l3: 0.051349, l4: 0.098384, l5: 0.194425, l6: 0.437548\n",
      "\n",
      "[epoch: 376/400, batch: 184/1000, ite: 49774] train loss: 1.1183, accuracy: 94.2263%, tar: 0.0208 \n",
      "l0: 0.026190, l1: 0.027893, l2: 0.034977, l3: 0.053927, l4: 0.101663, l5: 0.179328, l6: 0.354490\n",
      "\n",
      "[epoch: 376/400, batch: 192/1000, ite: 49775] train loss: 1.1184, accuracy: 95.1229%, tar: 0.0208 \n",
      "l0: 0.023369, l1: 0.024424, l2: 0.033023, l3: 0.050380, l4: 0.090427, l5: 0.175530, l6: 0.330637\n",
      "\n",
      "[epoch: 376/400, batch: 200/1000, ite: 49776] train loss: 1.1183, accuracy: 94.5047%, tar: 0.0208 \n",
      "l0: 0.018231, l1: 0.019544, l2: 0.026632, l3: 0.040039, l4: 0.075105, l5: 0.164584, l6: 0.330364\n",
      "\n",
      "[epoch: 376/400, batch: 208/1000, ite: 49777] train loss: 1.1183, accuracy: 95.2266%, tar: 0.0208 \n",
      "l0: 0.019958, l1: 0.021931, l2: 0.031860, l3: 0.051202, l4: 0.092025, l5: 0.173144, l6: 0.295204\n",
      "\n",
      "[epoch: 376/400, batch: 216/1000, ite: 49778] train loss: 1.1182, accuracy: 95.4991%, tar: 0.0208 \n",
      "l0: 0.013439, l1: 0.014622, l2: 0.021145, l3: 0.033561, l4: 0.064671, l5: 0.138631, l6: 0.303219\n",
      "\n",
      "[epoch: 376/400, batch: 224/1000, ite: 49779] train loss: 1.1181, accuracy: 96.6338%, tar: 0.0208 \n",
      "l0: 0.019447, l1: 0.020703, l2: 0.026781, l3: 0.042064, l4: 0.075404, l5: 0.154345, l6: 0.299367\n",
      "\n",
      "[epoch: 376/400, batch: 232/1000, ite: 49780] train loss: 1.1180, accuracy: 95.6185%, tar: 0.0208 \n",
      "l0: 0.016250, l1: 0.017182, l2: 0.023273, l3: 0.036162, l4: 0.068566, l5: 0.127553, l6: 0.260798\n",
      "\n",
      "[epoch: 376/400, batch: 240/1000, ite: 49781] train loss: 1.1178, accuracy: 96.4742%, tar: 0.0208 \n",
      "l0: 0.017495, l1: 0.019351, l2: 0.028178, l3: 0.048659, l4: 0.102078, l5: 0.202337, l6: 0.362002\n",
      "\n",
      "[epoch: 376/400, batch: 248/1000, ite: 49782] train loss: 1.1178, accuracy: 96.0309%, tar: 0.0208 \n",
      "l0: 0.022392, l1: 0.024022, l2: 0.032360, l3: 0.050374, l4: 0.095000, l5: 0.177190, l6: 0.375027\n",
      "\n",
      "[epoch: 376/400, batch: 256/1000, ite: 49783] train loss: 1.1178, accuracy: 94.5076%, tar: 0.0208 \n",
      "l0: 0.019045, l1: 0.019730, l2: 0.027087, l3: 0.041698, l4: 0.080280, l5: 0.151792, l6: 0.305999\n",
      "\n",
      "[epoch: 376/400, batch: 264/1000, ite: 49784] train loss: 1.1177, accuracy: 95.6742%, tar: 0.0208 \n",
      "l0: 0.024870, l1: 0.026172, l2: 0.034440, l3: 0.049422, l4: 0.088679, l5: 0.178739, l6: 0.436312\n",
      "\n",
      "[epoch: 376/400, batch: 272/1000, ite: 49785] train loss: 1.1178, accuracy: 94.5216%, tar: 0.0208 \n",
      "l0: 0.012865, l1: 0.014589, l2: 0.022070, l3: 0.032876, l4: 0.059691, l5: 0.110077, l6: 0.247946\n",
      "\n",
      "[epoch: 376/400, batch: 280/1000, ite: 49786] train loss: 1.1176, accuracy: 97.0461%, tar: 0.0208 \n",
      "l0: 0.016868, l1: 0.018495, l2: 0.025414, l3: 0.043328, l4: 0.088023, l5: 0.159665, l6: 0.294895\n",
      "\n",
      "[epoch: 376/400, batch: 288/1000, ite: 49787] train loss: 1.1175, accuracy: 95.9361%, tar: 0.0208 \n",
      "l0: 0.023314, l1: 0.024470, l2: 0.031879, l3: 0.046285, l4: 0.077661, l5: 0.178350, l6: 0.377800\n",
      "\n",
      "[epoch: 376/400, batch: 296/1000, ite: 49788] train loss: 1.1176, accuracy: 95.0401%, tar: 0.0208 \n",
      "l0: 0.024420, l1: 0.024760, l2: 0.031737, l3: 0.043497, l4: 0.073473, l5: 0.135518, l6: 0.281087\n",
      "\n",
      "[epoch: 376/400, batch: 304/1000, ite: 49789] train loss: 1.1174, accuracy: 95.5338%, tar: 0.0208 \n",
      "l0: 0.021989, l1: 0.023973, l2: 0.033140, l3: 0.053040, l4: 0.106864, l5: 0.200908, l6: 0.427932\n",
      "\n",
      "[epoch: 376/400, batch: 312/1000, ite: 49790] train loss: 1.1175, accuracy: 94.8718%, tar: 0.0208 \n",
      "l0: 0.018828, l1: 0.020533, l2: 0.030066, l3: 0.049015, l4: 0.096136, l5: 0.202742, l6: 0.443694\n",
      "\n",
      "[epoch: 376/400, batch: 320/1000, ite: 49791] train loss: 1.1176, accuracy: 94.8276%, tar: 0.0208 \n",
      "l0: 0.021792, l1: 0.022650, l2: 0.029495, l3: 0.044000, l4: 0.076779, l5: 0.144541, l6: 0.274085\n",
      "\n",
      "[epoch: 376/400, batch: 328/1000, ite: 49792] train loss: 1.1175, accuracy: 95.6853%, tar: 0.0208 \n",
      "l0: 0.028395, l1: 0.031283, l2: 0.044426, l3: 0.071431, l4: 0.132782, l5: 0.229862, l6: 0.442138\n",
      "\n",
      "[epoch: 376/400, batch: 336/1000, ite: 49793] train loss: 1.1177, accuracy: 94.3645%, tar: 0.0208 \n",
      "l0: 0.016982, l1: 0.018561, l2: 0.026006, l3: 0.041801, l4: 0.081662, l5: 0.184869, l6: 0.425831\n",
      "\n",
      "[epoch: 376/400, batch: 344/1000, ite: 49794] train loss: 1.1177, accuracy: 95.1235%, tar: 0.0208 \n",
      "l0: 0.016533, l1: 0.018101, l2: 0.025628, l3: 0.038233, l4: 0.063707, l5: 0.133646, l6: 0.283276\n",
      "\n",
      "[epoch: 376/400, batch: 352/1000, ite: 49795] train loss: 1.1176, accuracy: 96.2956%, tar: 0.0208 \n",
      "l0: 0.023534, l1: 0.025398, l2: 0.034850, l3: 0.053132, l4: 0.105027, l5: 0.247579, l6: 0.466126\n",
      "\n",
      "[epoch: 376/400, batch: 360/1000, ite: 49796] train loss: 1.1178, accuracy: 93.3423%, tar: 0.0208 \n",
      "l0: 0.023310, l1: 0.024188, l2: 0.031376, l3: 0.046556, l4: 0.083104, l5: 0.169657, l6: 0.398351\n",
      "\n",
      "[epoch: 376/400, batch: 368/1000, ite: 49797] train loss: 1.1178, accuracy: 93.8380%, tar: 0.0208 \n",
      "l0: 0.023502, l1: 0.025870, l2: 0.034956, l3: 0.052861, l4: 0.093896, l5: 0.204872, l6: 0.403377\n",
      "\n",
      "[epoch: 376/400, batch: 376/1000, ite: 49798] train loss: 1.1179, accuracy: 95.3213%, tar: 0.0208 \n",
      "l0: 0.017439, l1: 0.018465, l2: 0.024062, l3: 0.037774, l4: 0.066298, l5: 0.142253, l6: 0.307968\n",
      "\n",
      "[epoch: 376/400, batch: 384/1000, ite: 49799] train loss: 1.1178, accuracy: 95.9289%, tar: 0.0208 \n",
      "l0: 0.020820, l1: 0.022555, l2: 0.031390, l3: 0.048104, l4: 0.094028, l5: 0.215267, l6: 0.417478\n",
      "\n",
      "[epoch: 376/400, batch: 392/1000, ite: 49800] train loss: 1.1179, accuracy: 94.3511%, tar: 0.0208 \n",
      "l0: 0.021846, l1: 0.023100, l2: 0.031813, l3: 0.049397, l4: 0.099265, l5: 0.236421, l6: 0.462417\n",
      "\n",
      "[epoch: 376/400, batch: 400/1000, ite: 49801] train loss: 1.1180, accuracy: 93.8037%, tar: 0.0208 \n",
      "l0: 0.026899, l1: 0.028579, l2: 0.038244, l3: 0.058494, l4: 0.123771, l5: 0.278817, l6: 0.596421\n",
      "\n",
      "[epoch: 376/400, batch: 408/1000, ite: 49802] train loss: 1.1184, accuracy: 92.2832%, tar: 0.0208 \n",
      "l0: 0.023985, l1: 0.025637, l2: 0.035040, l3: 0.051909, l4: 0.093666, l5: 0.191554, l6: 0.374986\n",
      "\n",
      "[epoch: 376/400, batch: 416/1000, ite: 49803] train loss: 1.1184, accuracy: 94.5153%, tar: 0.0208 \n",
      "l0: 0.014615, l1: 0.015248, l2: 0.021740, l3: 0.034384, l4: 0.058799, l5: 0.142701, l6: 0.247344\n",
      "\n",
      "[epoch: 376/400, batch: 424/1000, ite: 49804] train loss: 1.1182, accuracy: 96.4250%, tar: 0.0208 \n",
      "l0: 0.016612, l1: 0.017758, l2: 0.022848, l3: 0.032786, l4: 0.053348, l5: 0.101154, l6: 0.249518\n",
      "\n",
      "[epoch: 376/400, batch: 432/1000, ite: 49805] train loss: 1.1180, accuracy: 96.2756%, tar: 0.0208 \n",
      "l0: 0.021025, l1: 0.021854, l2: 0.028999, l3: 0.043013, l4: 0.078353, l5: 0.172112, l6: 0.376817\n",
      "\n",
      "[epoch: 376/400, batch: 440/1000, ite: 49806] train loss: 1.1180, accuracy: 94.8351%, tar: 0.0208 \n",
      "l0: 0.022353, l1: 0.023559, l2: 0.031530, l3: 0.046721, l4: 0.088080, l5: 0.167357, l6: 0.308954\n",
      "\n",
      "[epoch: 376/400, batch: 448/1000, ite: 49807] train loss: 1.1179, accuracy: 95.6378%, tar: 0.0208 \n",
      "l0: 0.021724, l1: 0.022913, l2: 0.031513, l3: 0.049438, l4: 0.096252, l5: 0.205242, l6: 0.367797\n",
      "\n",
      "[epoch: 376/400, batch: 456/1000, ite: 49808] train loss: 1.1180, accuracy: 94.6193%, tar: 0.0208 \n",
      "l0: 0.020995, l1: 0.022272, l2: 0.029869, l3: 0.048340, l4: 0.087496, l5: 0.158241, l6: 0.338733\n",
      "\n",
      "[epoch: 376/400, batch: 464/1000, ite: 49809] train loss: 1.1179, accuracy: 95.1510%, tar: 0.0208 \n",
      "l0: 0.019763, l1: 0.021876, l2: 0.030896, l3: 0.044421, l4: 0.078957, l5: 0.203604, l6: 0.447984\n",
      "\n",
      "[epoch: 376/400, batch: 472/1000, ite: 49810] train loss: 1.1180, accuracy: 95.1360%, tar: 0.0208 \n",
      "l0: 0.021135, l1: 0.022062, l2: 0.028243, l3: 0.037572, l4: 0.065498, l5: 0.169116, l6: 0.353386\n",
      "\n",
      "[epoch: 376/400, batch: 480/1000, ite: 49811] train loss: 1.1180, accuracy: 94.8372%, tar: 0.0208 \n",
      "l0: 0.026823, l1: 0.028126, l2: 0.036427, l3: 0.054626, l4: 0.100048, l5: 0.220046, l6: 0.441637\n",
      "\n",
      "[epoch: 376/400, batch: 488/1000, ite: 49812] train loss: 1.1181, accuracy: 93.2201%, tar: 0.0208 \n",
      "l0: 0.020050, l1: 0.021592, l2: 0.027684, l3: 0.040686, l4: 0.074952, l5: 0.139991, l6: 0.285191\n",
      "\n",
      "[epoch: 376/400, batch: 496/1000, ite: 49813] train loss: 1.1180, accuracy: 95.5297%, tar: 0.0208 \n",
      "l0: 0.022755, l1: 0.024178, l2: 0.033914, l3: 0.051100, l4: 0.095532, l5: 0.196661, l6: 0.437454\n",
      "\n",
      "[epoch: 376/400, batch: 504/1000, ite: 49814] train loss: 1.1181, accuracy: 95.0778%, tar: 0.0208 \n",
      "l0: 0.021556, l1: 0.022890, l2: 0.030161, l3: 0.042573, l4: 0.076957, l5: 0.165661, l6: 0.327182\n",
      "\n",
      "[epoch: 376/400, batch: 512/1000, ite: 49815] train loss: 1.1181, accuracy: 95.2712%, tar: 0.0208 \n",
      "l0: 0.018163, l1: 0.019043, l2: 0.026947, l3: 0.040983, l4: 0.073281, l5: 0.148653, l6: 0.337218\n",
      "\n",
      "[epoch: 376/400, batch: 520/1000, ite: 49816] train loss: 1.1180, accuracy: 95.2871%, tar: 0.0208 \n",
      "l0: 0.018710, l1: 0.019633, l2: 0.025887, l3: 0.039175, l4: 0.069065, l5: 0.142593, l6: 0.333264\n",
      "\n",
      "[epoch: 376/400, batch: 528/1000, ite: 49817] train loss: 1.1179, accuracy: 95.1160%, tar: 0.0208 \n",
      "l0: 0.022209, l1: 0.024448, l2: 0.034467, l3: 0.055958, l4: 0.097321, l5: 0.157329, l6: 0.283158\n",
      "\n",
      "[epoch: 376/400, batch: 536/1000, ite: 49818] train loss: 1.1178, accuracy: 95.9672%, tar: 0.0208 \n",
      "l0: 0.024763, l1: 0.025706, l2: 0.033428, l3: 0.047847, l4: 0.080566, l5: 0.169894, l6: 0.369555\n",
      "\n",
      "[epoch: 376/400, batch: 544/1000, ite: 49819] train loss: 1.1178, accuracy: 94.7881%, tar: 0.0208 \n",
      "l0: 0.020438, l1: 0.021372, l2: 0.028851, l3: 0.046268, l4: 0.092765, l5: 0.188737, l6: 0.390786\n",
      "\n",
      "[epoch: 376/400, batch: 552/1000, ite: 49820] train loss: 1.1179, accuracy: 94.6067%, tar: 0.0208 \n",
      "l0: 0.017916, l1: 0.019536, l2: 0.026806, l3: 0.042986, l4: 0.072545, l5: 0.127469, l6: 0.259028\n",
      "\n",
      "[epoch: 376/400, batch: 560/1000, ite: 49821] train loss: 1.1177, accuracy: 96.2347%, tar: 0.0208 \n",
      "l0: 0.030562, l1: 0.032983, l2: 0.043139, l3: 0.066724, l4: 0.120161, l5: 0.294834, l6: 0.581361\n",
      "\n",
      "[epoch: 376/400, batch: 568/1000, ite: 49822] train loss: 1.1181, accuracy: 91.7925%, tar: 0.0208 \n",
      "l0: 0.023911, l1: 0.025191, l2: 0.030887, l3: 0.046903, l4: 0.085191, l5: 0.180354, l6: 0.401055\n",
      "\n",
      "[epoch: 376/400, batch: 576/1000, ite: 49823] train loss: 1.1181, accuracy: 94.3136%, tar: 0.0208 \n",
      "l0: 0.019236, l1: 0.020644, l2: 0.028675, l3: 0.042610, l4: 0.087225, l5: 0.197376, l6: 0.449170\n",
      "\n",
      "[epoch: 376/400, batch: 584/1000, ite: 49824] train loss: 1.1182, accuracy: 94.4952%, tar: 0.0208 \n",
      "l0: 0.015085, l1: 0.015463, l2: 0.020308, l3: 0.031906, l4: 0.068341, l5: 0.122666, l6: 0.244805\n",
      "\n",
      "[epoch: 376/400, batch: 592/1000, ite: 49825] train loss: 1.1180, accuracy: 96.1508%, tar: 0.0208 \n",
      "l0: 0.023773, l1: 0.025163, l2: 0.033789, l3: 0.050984, l4: 0.100227, l5: 0.216938, l6: 0.478901\n",
      "\n",
      "[epoch: 376/400, batch: 600/1000, ite: 49826] train loss: 1.1182, accuracy: 94.1339%, tar: 0.0208 \n",
      "l0: 0.017424, l1: 0.018920, l2: 0.026998, l3: 0.042562, l4: 0.070227, l5: 0.130071, l6: 0.260512\n",
      "\n",
      "[epoch: 376/400, batch: 608/1000, ite: 49827] train loss: 1.1180, accuracy: 96.5456%, tar: 0.0208 \n",
      "l0: 0.020679, l1: 0.021825, l2: 0.027809, l3: 0.041687, l4: 0.078712, l5: 0.171703, l6: 0.368587\n",
      "\n",
      "[epoch: 376/400, batch: 616/1000, ite: 49828] train loss: 1.1180, accuracy: 94.9664%, tar: 0.0208 \n",
      "l0: 0.022502, l1: 0.023653, l2: 0.031344, l3: 0.043550, l4: 0.078019, l5: 0.191482, l6: 0.420562\n",
      "\n",
      "[epoch: 376/400, batch: 624/1000, ite: 49829] train loss: 1.1181, accuracy: 94.5181%, tar: 0.0208 \n",
      "l0: 0.017419, l1: 0.019044, l2: 0.028692, l3: 0.047875, l4: 0.098259, l5: 0.173422, l6: 0.286934\n",
      "\n",
      "[epoch: 376/400, batch: 632/1000, ite: 49830] train loss: 1.1180, accuracy: 96.8244%, tar: 0.0208 \n",
      "l0: 0.019610, l1: 0.020962, l2: 0.028817, l3: 0.044944, l4: 0.087019, l5: 0.186207, l6: 0.415588\n",
      "\n",
      "[epoch: 376/400, batch: 640/1000, ite: 49831] train loss: 1.1180, accuracy: 94.7014%, tar: 0.0208 \n",
      "l0: 0.016252, l1: 0.017474, l2: 0.024860, l3: 0.036748, l4: 0.066236, l5: 0.126620, l6: 0.266555\n",
      "\n",
      "[epoch: 376/400, batch: 648/1000, ite: 49832] train loss: 1.1179, accuracy: 96.4771%, tar: 0.0208 \n",
      "l0: 0.019710, l1: 0.021252, l2: 0.028783, l3: 0.040044, l4: 0.065827, l5: 0.142699, l6: 0.339660\n",
      "\n",
      "[epoch: 376/400, batch: 656/1000, ite: 49833] train loss: 1.1178, accuracy: 96.0200%, tar: 0.0208 \n",
      "l0: 0.020047, l1: 0.022008, l2: 0.031102, l3: 0.053301, l4: 0.103300, l5: 0.206771, l6: 0.387730\n",
      "\n",
      "[epoch: 376/400, batch: 664/1000, ite: 49834] train loss: 1.1179, accuracy: 95.3987%, tar: 0.0208 \n",
      "l0: 0.013995, l1: 0.014973, l2: 0.020204, l3: 0.032260, l4: 0.059165, l5: 0.120965, l6: 0.294537\n",
      "\n",
      "[epoch: 376/400, batch: 672/1000, ite: 49835] train loss: 1.1177, accuracy: 96.5015%, tar: 0.0208 \n",
      "l0: 0.023483, l1: 0.025012, l2: 0.034001, l3: 0.046137, l4: 0.082757, l5: 0.171256, l6: 0.344839\n",
      "\n",
      "[epoch: 376/400, batch: 680/1000, ite: 49836] train loss: 1.1177, accuracy: 95.8731%, tar: 0.0208 \n",
      "l0: 0.019814, l1: 0.021064, l2: 0.028101, l3: 0.041287, l4: 0.076712, l5: 0.143790, l6: 0.322906\n",
      "\n",
      "[epoch: 376/400, batch: 688/1000, ite: 49837] train loss: 1.1176, accuracy: 95.7489%, tar: 0.0208 \n",
      "l0: 0.021620, l1: 0.023130, l2: 0.032565, l3: 0.047998, l4: 0.086873, l5: 0.235449, l6: 0.473103\n",
      "\n",
      "[epoch: 376/400, batch: 696/1000, ite: 49838] train loss: 1.1178, accuracy: 94.6228%, tar: 0.0208 \n",
      "l0: 0.017826, l1: 0.019137, l2: 0.024631, l3: 0.036165, l4: 0.067612, l5: 0.144203, l6: 0.288651\n",
      "\n",
      "[epoch: 376/400, batch: 704/1000, ite: 49839] train loss: 1.1176, accuracy: 95.9886%, tar: 0.0208 \n",
      "l0: 0.013778, l1: 0.014585, l2: 0.020251, l3: 0.029752, l4: 0.048979, l5: 0.090074, l6: 0.200805\n",
      "\n",
      "[epoch: 376/400, batch: 712/1000, ite: 49840] train loss: 1.1174, accuracy: 97.0732%, tar: 0.0208 \n",
      "l0: 0.022908, l1: 0.024130, l2: 0.032303, l3: 0.048839, l4: 0.096439, l5: 0.204672, l6: 0.448568\n",
      "\n",
      "[epoch: 376/400, batch: 720/1000, ite: 49841] train loss: 1.1175, accuracy: 94.1786%, tar: 0.0208 \n",
      "l0: 0.017594, l1: 0.019255, l2: 0.026094, l3: 0.040240, l4: 0.085804, l5: 0.201982, l6: 0.334557\n",
      "\n",
      "[epoch: 376/400, batch: 728/1000, ite: 49842] train loss: 1.1175, accuracy: 95.7322%, tar: 0.0208 \n",
      "l0: 0.019124, l1: 0.020415, l2: 0.027165, l3: 0.043115, l4: 0.073145, l5: 0.153721, l6: 0.385639\n",
      "\n",
      "[epoch: 376/400, batch: 736/1000, ite: 49843] train loss: 1.1175, accuracy: 94.7194%, tar: 0.0208 \n",
      "l0: 0.030946, l1: 0.032649, l2: 0.042393, l3: 0.066863, l4: 0.141204, l5: 0.323004, l6: 0.593934\n",
      "\n",
      "[epoch: 376/400, batch: 744/1000, ite: 49844] train loss: 1.1178, accuracy: 92.2267%, tar: 0.0208 \n",
      "l0: 0.015254, l1: 0.016439, l2: 0.023058, l3: 0.036695, l4: 0.064107, l5: 0.138672, l6: 0.323521\n",
      "\n",
      "[epoch: 376/400, batch: 752/1000, ite: 49845] train loss: 1.1177, accuracy: 95.4164%, tar: 0.0208 \n",
      "l0: 0.017514, l1: 0.018429, l2: 0.026442, l3: 0.039485, l4: 0.070157, l5: 0.132793, l6: 0.401099\n",
      "\n",
      "[epoch: 376/400, batch: 760/1000, ite: 49846] train loss: 1.1177, accuracy: 94.5050%, tar: 0.0208 \n",
      "l0: 0.018263, l1: 0.019299, l2: 0.025314, l3: 0.037988, l4: 0.069767, l5: 0.133031, l6: 0.253173\n",
      "\n",
      "[epoch: 376/400, batch: 768/1000, ite: 49847] train loss: 1.1176, accuracy: 96.2405%, tar: 0.0208 \n",
      "l0: 0.020249, l1: 0.021741, l2: 0.028322, l3: 0.044002, l4: 0.080409, l5: 0.171479, l6: 0.394207\n",
      "\n",
      "[epoch: 376/400, batch: 776/1000, ite: 49848] train loss: 1.1176, accuracy: 94.8219%, tar: 0.0208 \n",
      "l0: 0.017566, l1: 0.019101, l2: 0.028550, l3: 0.044726, l4: 0.095240, l5: 0.155219, l6: 0.324104\n",
      "\n",
      "[epoch: 376/400, batch: 784/1000, ite: 49849] train loss: 1.1175, accuracy: 96.1928%, tar: 0.0208 \n",
      "l0: 0.026289, l1: 0.028020, l2: 0.036556, l3: 0.060421, l4: 0.160004, l5: 0.305173, l6: 0.619632\n",
      "\n",
      "[epoch: 376/400, batch: 792/1000, ite: 49850] train loss: 1.1179, accuracy: 91.4571%, tar: 0.0208 \n",
      "l0: 0.018287, l1: 0.019482, l2: 0.027040, l3: 0.042857, l4: 0.077438, l5: 0.149882, l6: 0.344894\n",
      "\n",
      "[epoch: 376/400, batch: 800/1000, ite: 49851] train loss: 1.1179, accuracy: 95.2951%, tar: 0.0208 \n",
      "l0: 0.016870, l1: 0.017719, l2: 0.025299, l3: 0.036867, l4: 0.060178, l5: 0.111866, l6: 0.266044\n",
      "\n",
      "[epoch: 376/400, batch: 808/1000, ite: 49852] train loss: 1.1177, accuracy: 96.0665%, tar: 0.0208 \n",
      "l0: 0.021674, l1: 0.023030, l2: 0.029914, l3: 0.046204, l4: 0.079026, l5: 0.186859, l6: 0.359806\n",
      "\n",
      "[epoch: 376/400, batch: 816/1000, ite: 49853] train loss: 1.1177, accuracy: 95.6315%, tar: 0.0208 \n",
      "l0: 0.018373, l1: 0.019087, l2: 0.025368, l3: 0.035905, l4: 0.062963, l5: 0.116048, l6: 0.255807\n",
      "\n",
      "[epoch: 376/400, batch: 824/1000, ite: 49854] train loss: 1.1175, accuracy: 96.1632%, tar: 0.0208 \n",
      "l0: 0.019546, l1: 0.020631, l2: 0.026656, l3: 0.041374, l4: 0.072479, l5: 0.137809, l6: 0.324733\n",
      "\n",
      "[epoch: 376/400, batch: 832/1000, ite: 49855] train loss: 1.1175, accuracy: 95.7911%, tar: 0.0208 \n",
      "l0: 0.020340, l1: 0.021770, l2: 0.028586, l3: 0.044123, l4: 0.078601, l5: 0.142708, l6: 0.369443\n",
      "\n",
      "[epoch: 376/400, batch: 840/1000, ite: 49856] train loss: 1.1174, accuracy: 94.9222%, tar: 0.0208 \n",
      "l0: 0.018403, l1: 0.019624, l2: 0.026319, l3: 0.041629, l4: 0.086822, l5: 0.195545, l6: 0.345497\n",
      "\n",
      "[epoch: 376/400, batch: 848/1000, ite: 49857] train loss: 1.1174, accuracy: 94.5477%, tar: 0.0208 \n",
      "l0: 0.017517, l1: 0.018804, l2: 0.026329, l3: 0.045328, l4: 0.080314, l5: 0.165077, l6: 0.345646\n",
      "\n",
      "[epoch: 376/400, batch: 856/1000, ite: 49858] train loss: 1.1174, accuracy: 95.0193%, tar: 0.0208 \n",
      "l0: 0.022083, l1: 0.023587, l2: 0.030503, l3: 0.048804, l4: 0.105651, l5: 0.246873, l6: 0.448921\n",
      "\n",
      "[epoch: 376/400, batch: 864/1000, ite: 49859] train loss: 1.1175, accuracy: 93.9435%, tar: 0.0208 \n",
      "l0: 0.019038, l1: 0.020206, l2: 0.026858, l3: 0.040561, l4: 0.075828, l5: 0.152417, l6: 0.292158\n",
      "\n",
      "[epoch: 376/400, batch: 872/1000, ite: 49860] train loss: 1.1174, accuracy: 96.2196%, tar: 0.0208 \n",
      "l0: 0.017838, l1: 0.019685, l2: 0.028580, l3: 0.050474, l4: 0.093735, l5: 0.160608, l6: 0.299962\n",
      "\n",
      "[epoch: 376/400, batch: 880/1000, ite: 49861] train loss: 1.1174, accuracy: 96.0198%, tar: 0.0208 \n",
      "l0: 0.020354, l1: 0.021727, l2: 0.029243, l3: 0.043038, l4: 0.078850, l5: 0.161350, l6: 0.379932\n",
      "\n",
      "[epoch: 376/400, batch: 888/1000, ite: 49862] train loss: 1.1174, accuracy: 95.5227%, tar: 0.0208 \n",
      "l0: 0.017545, l1: 0.018529, l2: 0.024871, l3: 0.035567, l4: 0.060182, l5: 0.105058, l6: 0.229372\n",
      "\n",
      "[epoch: 376/400, batch: 896/1000, ite: 49863] train loss: 1.1171, accuracy: 96.5051%, tar: 0.0208 \n",
      "l0: 0.020052, l1: 0.021560, l2: 0.028677, l3: 0.047662, l4: 0.090213, l5: 0.170770, l6: 0.368695\n",
      "\n",
      "[epoch: 376/400, batch: 904/1000, ite: 49864] train loss: 1.1171, accuracy: 95.1853%, tar: 0.0208 \n",
      "l0: 0.022929, l1: 0.025443, l2: 0.037880, l3: 0.060616, l4: 0.117767, l5: 0.224600, l6: 0.413556\n",
      "\n",
      "[epoch: 376/400, batch: 912/1000, ite: 49865] train loss: 1.1173, accuracy: 95.2422%, tar: 0.0208 \n",
      "l0: 0.017964, l1: 0.019404, l2: 0.026458, l3: 0.044616, l4: 0.080079, l5: 0.166839, l6: 0.289455\n",
      "\n",
      "[epoch: 376/400, batch: 920/1000, ite: 49866] train loss: 1.1172, accuracy: 95.9011%, tar: 0.0208 \n",
      "l0: 0.020965, l1: 0.022596, l2: 0.030700, l3: 0.053648, l4: 0.106026, l5: 0.195543, l6: 0.380343\n",
      "\n",
      "[epoch: 376/400, batch: 928/1000, ite: 49867] train loss: 1.1172, accuracy: 94.8135%, tar: 0.0208 \n",
      "l0: 0.025533, l1: 0.028714, l2: 0.040277, l3: 0.062274, l4: 0.120957, l5: 0.303310, l6: 0.587524\n",
      "\n",
      "[epoch: 376/400, batch: 936/1000, ite: 49868] train loss: 1.1175, accuracy: 93.2876%, tar: 0.0208 \n",
      "l0: 0.018183, l1: 0.021365, l2: 0.030977, l3: 0.047890, l4: 0.078432, l5: 0.166970, l6: 0.297842\n",
      "\n",
      "[epoch: 376/400, batch: 944/1000, ite: 49869] train loss: 1.1175, accuracy: 96.4370%, tar: 0.0208 \n",
      "l0: 0.018860, l1: 0.020389, l2: 0.028768, l3: 0.045743, l4: 0.089060, l5: 0.209737, l6: 0.419829\n",
      "\n",
      "[epoch: 376/400, batch: 952/1000, ite: 49870] train loss: 1.1175, accuracy: 94.8734%, tar: 0.0208 \n",
      "l0: 0.021799, l1: 0.023846, l2: 0.032615, l3: 0.055615, l4: 0.130574, l5: 0.245068, l6: 0.402836\n",
      "\n",
      "[epoch: 376/400, batch: 960/1000, ite: 49871] train loss: 1.1176, accuracy: 93.9416%, tar: 0.0208 \n",
      "l0: 0.019670, l1: 0.021641, l2: 0.032830, l3: 0.061775, l4: 0.118367, l5: 0.223583, l6: 0.385638\n",
      "\n",
      "[epoch: 376/400, batch: 968/1000, ite: 49872] train loss: 1.1177, accuracy: 94.6288%, tar: 0.0208 \n",
      "l0: 0.021712, l1: 0.023596, l2: 0.031415, l3: 0.046138, l4: 0.082548, l5: 0.169186, l6: 0.346357\n",
      "\n",
      "[epoch: 376/400, batch: 976/1000, ite: 49873] train loss: 1.1177, accuracy: 95.2909%, tar: 0.0208 \n",
      "l0: 0.025751, l1: 0.027533, l2: 0.037634, l3: 0.060071, l4: 0.115351, l5: 0.232250, l6: 0.541525\n",
      "\n",
      "[epoch: 376/400, batch: 984/1000, ite: 49874] train loss: 1.1179, accuracy: 92.5160%, tar: 0.0208 \n",
      "l0: 0.025315, l1: 0.026345, l2: 0.035039, l3: 0.050893, l4: 0.083180, l5: 0.167376, l6: 0.347923\n",
      "\n",
      "[epoch: 376/400, batch: 992/1000, ite: 49875] train loss: 1.1179, accuracy: 95.1412%, tar: 0.0208 \n",
      "l0: 0.024334, l1: 0.025239, l2: 0.033611, l3: 0.047981, l4: 0.085402, l5: 0.195321, l6: 0.492465\n",
      "\n",
      "[epoch: 376/400, batch: 1000/1000, ite: 49876] train loss: 1.1181, accuracy: 93.5687%, tar: 0.0208 \n",
      "l0: 0.017757, l1: 0.018723, l2: 0.025233, l3: 0.036783, l4: 0.066537, l5: 0.137323, l6: 0.310145\n",
      "\n",
      "[epoch: 377/400, batch: 8/1000, ite: 49877] train loss: 1.1180, accuracy: 95.0442%, tar: 0.0208 \n",
      "l0: 0.027648, l1: 0.028647, l2: 0.039303, l3: 0.058136, l4: 0.096129, l5: 0.179865, l6: 0.409086\n",
      "\n",
      "[epoch: 377/400, batch: 16/1000, ite: 49878] train loss: 1.1181, accuracy: 94.2571%, tar: 0.0208 \n",
      "l0: 0.015894, l1: 0.016921, l2: 0.023208, l3: 0.034729, l4: 0.066327, l5: 0.136783, l6: 0.303004\n",
      "\n",
      "[epoch: 377/400, batch: 24/1000, ite: 49879] train loss: 1.1179, accuracy: 95.6898%, tar: 0.0208 \n",
      "l0: 0.021889, l1: 0.023188, l2: 0.030842, l3: 0.047831, l4: 0.103861, l5: 0.218242, l6: 0.435435\n",
      "\n",
      "[epoch: 377/400, batch: 32/1000, ite: 49880] train loss: 1.1180, accuracy: 94.3934%, tar: 0.0208 \n",
      "l0: 0.018554, l1: 0.019571, l2: 0.028677, l3: 0.044514, l4: 0.072169, l5: 0.138636, l6: 0.299466\n",
      "\n",
      "[epoch: 377/400, batch: 40/1000, ite: 49881] train loss: 1.1179, accuracy: 95.6517%, tar: 0.0208 \n",
      "l0: 0.019647, l1: 0.022531, l2: 0.036368, l3: 0.059193, l4: 0.111027, l5: 0.241613, l6: 0.510124\n",
      "\n",
      "[epoch: 377/400, batch: 48/1000, ite: 49882] train loss: 1.1182, accuracy: 94.7571%, tar: 0.0208 \n",
      "l0: 0.022525, l1: 0.023961, l2: 0.030399, l3: 0.041992, l4: 0.076459, l5: 0.166450, l6: 0.375027\n",
      "\n",
      "[epoch: 377/400, batch: 56/1000, ite: 49883] train loss: 1.1182, accuracy: 94.4295%, tar: 0.0208 \n",
      "l0: 0.022742, l1: 0.023806, l2: 0.032681, l3: 0.049467, l4: 0.082726, l5: 0.158799, l6: 0.376432\n",
      "\n",
      "[epoch: 377/400, batch: 64/1000, ite: 49884] train loss: 1.1182, accuracy: 94.5897%, tar: 0.0208 \n",
      "l0: 0.017772, l1: 0.018892, l2: 0.024098, l3: 0.038235, l4: 0.068845, l5: 0.127175, l6: 0.309648\n",
      "\n",
      "[epoch: 377/400, batch: 72/1000, ite: 49885] train loss: 1.1181, accuracy: 96.0753%, tar: 0.0208 \n",
      "l0: 0.015438, l1: 0.016718, l2: 0.023005, l3: 0.035742, l4: 0.069180, l5: 0.143151, l6: 0.336286\n",
      "\n",
      "[epoch: 377/400, batch: 80/1000, ite: 49886] train loss: 1.1180, accuracy: 96.1144%, tar: 0.0208 \n",
      "l0: 0.021776, l1: 0.022742, l2: 0.030820, l3: 0.047445, l4: 0.098396, l5: 0.209316, l6: 0.396231\n",
      "\n",
      "[epoch: 377/400, batch: 88/1000, ite: 49887] train loss: 1.1180, accuracy: 95.0360%, tar: 0.0208 \n",
      "l0: 0.014379, l1: 0.014613, l2: 0.017358, l3: 0.022340, l4: 0.035832, l5: 0.061797, l6: 0.157797\n",
      "\n",
      "[epoch: 377/400, batch: 96/1000, ite: 49888] train loss: 1.1177, accuracy: 97.3196%, tar: 0.0208 \n",
      "l0: 0.019320, l1: 0.020466, l2: 0.028684, l3: 0.042724, l4: 0.082016, l5: 0.171888, l6: 0.376478\n",
      "\n",
      "[epoch: 377/400, batch: 104/1000, ite: 49889] train loss: 1.1177, accuracy: 94.7337%, tar: 0.0208 \n",
      "l0: 0.018770, l1: 0.020825, l2: 0.029820, l3: 0.049883, l4: 0.111733, l5: 0.261464, l6: 0.395728\n",
      "\n",
      "[epoch: 377/400, batch: 112/1000, ite: 49890] train loss: 1.1178, accuracy: 94.9385%, tar: 0.0208 \n",
      "l0: 0.026599, l1: 0.028963, l2: 0.036378, l3: 0.056124, l4: 0.107090, l5: 0.228897, l6: 0.396080\n",
      "\n",
      "[epoch: 377/400, batch: 120/1000, ite: 49891] train loss: 1.1179, accuracy: 94.4621%, tar: 0.0208 \n",
      "l0: 0.022035, l1: 0.023064, l2: 0.030664, l3: 0.047346, l4: 0.092303, l5: 0.205308, l6: 0.438562\n",
      "\n",
      "[epoch: 377/400, batch: 128/1000, ite: 49892] train loss: 1.1180, accuracy: 93.5481%, tar: 0.0208 \n",
      "l0: 0.016661, l1: 0.018352, l2: 0.027119, l3: 0.046429, l4: 0.085501, l5: 0.159073, l6: 0.349852\n",
      "\n",
      "[epoch: 377/400, batch: 136/1000, ite: 49893] train loss: 1.1179, accuracy: 95.3325%, tar: 0.0208 \n",
      "l0: 0.017366, l1: 0.018910, l2: 0.027000, l3: 0.041951, l4: 0.083038, l5: 0.169712, l6: 0.341739\n",
      "\n",
      "[epoch: 377/400, batch: 144/1000, ite: 49894] train loss: 1.1179, accuracy: 95.2698%, tar: 0.0208 \n",
      "l0: 0.017675, l1: 0.019286, l2: 0.027083, l3: 0.042649, l4: 0.086644, l5: 0.155528, l6: 0.287637\n",
      "\n",
      "[epoch: 377/400, batch: 152/1000, ite: 49895] train loss: 1.1178, accuracy: 96.4255%, tar: 0.0207 \n",
      "l0: 0.024560, l1: 0.026740, l2: 0.037925, l3: 0.056109, l4: 0.113209, l5: 0.248231, l6: 0.429206\n",
      "\n",
      "[epoch: 377/400, batch: 160/1000, ite: 49896] train loss: 1.1179, accuracy: 94.8408%, tar: 0.0208 \n",
      "l0: 0.022881, l1: 0.024979, l2: 0.034537, l3: 0.052930, l4: 0.096815, l5: 0.194886, l6: 0.437641\n",
      "\n",
      "[epoch: 377/400, batch: 168/1000, ite: 49897] train loss: 1.1180, accuracy: 94.5175%, tar: 0.0208 \n",
      "l0: 0.018736, l1: 0.019635, l2: 0.026106, l3: 0.041445, l4: 0.083698, l5: 0.189479, l6: 0.342885\n",
      "\n",
      "[epoch: 377/400, batch: 176/1000, ite: 49898] train loss: 1.1180, accuracy: 95.5638%, tar: 0.0208 \n",
      "l0: 0.016330, l1: 0.017432, l2: 0.024775, l3: 0.039509, l4: 0.076598, l5: 0.145324, l6: 0.332626\n",
      "\n",
      "[epoch: 377/400, batch: 184/1000, ite: 49899] train loss: 1.1179, accuracy: 96.1409%, tar: 0.0207 \n",
      "l0: 0.018741, l1: 0.019821, l2: 0.026602, l3: 0.040554, l4: 0.073348, l5: 0.137217, l6: 0.288841\n",
      "\n",
      "[epoch: 377/400, batch: 192/1000, ite: 49900] train loss: 1.1178, accuracy: 95.4847%, tar: 0.0207 \n",
      "l0: 0.025837, l1: 0.027435, l2: 0.037664, l3: 0.057228, l4: 0.097100, l5: 0.180247, l6: 0.395643\n",
      "\n",
      "[epoch: 377/400, batch: 200/1000, ite: 49901] train loss: 1.1179, accuracy: 94.1916%, tar: 0.0208 \n",
      "l0: 0.023796, l1: 0.025006, l2: 0.032000, l3: 0.046431, l4: 0.084049, l5: 0.193593, l6: 0.356708\n",
      "\n",
      "[epoch: 377/400, batch: 208/1000, ite: 49902] train loss: 1.1179, accuracy: 94.7499%, tar: 0.0208 \n",
      "l0: 0.022566, l1: 0.023767, l2: 0.034778, l3: 0.055014, l4: 0.107138, l5: 0.208853, l6: 0.476534\n",
      "\n",
      "[epoch: 377/400, batch: 216/1000, ite: 49903] train loss: 1.1180, accuracy: 93.8083%, tar: 0.0208 \n",
      "l0: 0.028393, l1: 0.029719, l2: 0.040098, l3: 0.056023, l4: 0.093805, l5: 0.166850, l6: 0.363368\n",
      "\n",
      "[epoch: 377/400, batch: 224/1000, ite: 49904] train loss: 1.1180, accuracy: 94.1982%, tar: 0.0208 \n",
      "l0: 0.019658, l1: 0.020857, l2: 0.027857, l3: 0.041455, l4: 0.077155, l5: 0.172914, l6: 0.359034\n",
      "\n",
      "[epoch: 377/400, batch: 232/1000, ite: 49905] train loss: 1.1180, accuracy: 94.9716%, tar: 0.0208 \n",
      "l0: 0.017701, l1: 0.018838, l2: 0.025791, l3: 0.040381, l4: 0.077028, l5: 0.161771, l6: 0.330336\n",
      "\n",
      "[epoch: 377/400, batch: 240/1000, ite: 49906] train loss: 1.1180, accuracy: 94.8469%, tar: 0.0208 \n",
      "l0: 0.019052, l1: 0.020584, l2: 0.029471, l3: 0.044941, l4: 0.082107, l5: 0.203038, l6: 0.503082\n",
      "\n",
      "[epoch: 377/400, batch: 248/1000, ite: 49907] train loss: 1.1181, accuracy: 93.7659%, tar: 0.0208 \n",
      "l0: 0.022162, l1: 0.023018, l2: 0.030496, l3: 0.046456, l4: 0.081633, l5: 0.174954, l6: 0.341372\n",
      "\n",
      "[epoch: 377/400, batch: 256/1000, ite: 49908] train loss: 1.1181, accuracy: 94.7945%, tar: 0.0208 \n",
      "l0: 0.020884, l1: 0.021382, l2: 0.028210, l3: 0.040022, l4: 0.064659, l5: 0.131197, l6: 0.302102\n",
      "\n",
      "l0: 0.023885, l1: 0.025469, l2: 0.035096, l3: 0.050345, l4: 0.092812, l5: 0.202487, l6: 0.379389\n",
      "\n",
      "[epoch: 377/400, batch: 280/1000, ite: 49911] train loss: 1.1179, accuracy: 94.3501%, tar: 0.0208 \n",
      "l0: 0.018940, l1: 0.020413, l2: 0.028643, l3: 0.046155, l4: 0.083643, l5: 0.172310, l6: 0.356623\n",
      "\n",
      "[epoch: 377/400, batch: 288/1000, ite: 49912] train loss: 1.1179, accuracy: 95.4292%, tar: 0.0208 \n",
      "l0: 0.020279, l1: 0.021964, l2: 0.031148, l3: 0.050842, l4: 0.098698, l5: 0.186677, l6: 0.408904\n",
      "\n",
      "[epoch: 377/400, batch: 296/1000, ite: 49913] train loss: 1.1180, accuracy: 94.6752%, tar: 0.0208 \n",
      "l0: 0.018374, l1: 0.019498, l2: 0.025651, l3: 0.038663, l4: 0.075593, l5: 0.157924, l6: 0.306032\n",
      "\n",
      "[epoch: 377/400, batch: 304/1000, ite: 49914] train loss: 1.1179, accuracy: 95.0110%, tar: 0.0208 \n",
      "l0: 0.022159, l1: 0.024019, l2: 0.032606, l3: 0.051724, l4: 0.094283, l5: 0.167965, l6: 0.316547\n",
      "\n",
      "[epoch: 377/400, batch: 312/1000, ite: 49915] train loss: 1.1179, accuracy: 94.9818%, tar: 0.0208 \n",
      "l0: 0.017635, l1: 0.020520, l2: 0.032643, l3: 0.057589, l4: 0.108423, l5: 0.197970, l6: 0.397034\n",
      "\n",
      "[epoch: 377/400, batch: 320/1000, ite: 49916] train loss: 1.1179, accuracy: 95.4076%, tar: 0.0208 \n",
      "l0: 0.017497, l1: 0.019125, l2: 0.027317, l3: 0.043188, l4: 0.084156, l5: 0.169085, l6: 0.316894\n",
      "\n",
      "[epoch: 377/400, batch: 328/1000, ite: 49917] train loss: 1.1178, accuracy: 95.7923%, tar: 0.0208 \n",
      "l0: 0.021282, l1: 0.022769, l2: 0.031003, l3: 0.049784, l4: 0.101767, l5: 0.199203, l6: 0.411988\n",
      "\n",
      "[epoch: 377/400, batch: 336/1000, ite: 49918] train loss: 1.1179, accuracy: 94.5394%, tar: 0.0208 \n",
      "l0: 0.018863, l1: 0.019937, l2: 0.027602, l3: 0.040746, l4: 0.064576, l5: 0.117572, l6: 0.285793\n",
      "\n",
      "[epoch: 377/400, batch: 344/1000, ite: 49919] train loss: 1.1178, accuracy: 96.6050%, tar: 0.0208 \n",
      "l0: 0.019688, l1: 0.021034, l2: 0.029420, l3: 0.044870, l4: 0.076647, l5: 0.164574, l6: 0.350740\n",
      "\n",
      "[epoch: 377/400, batch: 352/1000, ite: 49920] train loss: 1.1178, accuracy: 95.7509%, tar: 0.0207 \n",
      "l0: 0.023252, l1: 0.024336, l2: 0.033845, l3: 0.055997, l4: 0.121255, l5: 0.218021, l6: 0.450073\n",
      "\n",
      "[epoch: 377/400, batch: 360/1000, ite: 49921] train loss: 1.1179, accuracy: 93.5551%, tar: 0.0208 \n",
      "l0: 0.023989, l1: 0.025405, l2: 0.033557, l3: 0.051261, l4: 0.097012, l5: 0.238683, l6: 0.439469\n",
      "\n",
      "[epoch: 377/400, batch: 368/1000, ite: 49922] train loss: 1.1180, accuracy: 93.5837%, tar: 0.0208 \n",
      "l0: 0.019092, l1: 0.020167, l2: 0.027413, l3: 0.039566, l4: 0.070804, l5: 0.143960, l6: 0.312636\n",
      "\n",
      "[epoch: 377/400, batch: 376/1000, ite: 49923] train loss: 1.1179, accuracy: 95.4422%, tar: 0.0208 \n",
      "l0: 0.020071, l1: 0.020851, l2: 0.027876, l3: 0.039583, l4: 0.064016, l5: 0.113574, l6: 0.273923\n",
      "\n",
      "[epoch: 377/400, batch: 384/1000, ite: 49924] train loss: 1.1178, accuracy: 95.7551%, tar: 0.0208 \n",
      "l0: 0.015458, l1: 0.016588, l2: 0.022803, l3: 0.035726, l4: 0.060491, l5: 0.142572, l6: 0.283248\n",
      "\n",
      "[epoch: 377/400, batch: 392/1000, ite: 49925] train loss: 1.1176, accuracy: 96.9951%, tar: 0.0207 \n",
      "l0: 0.018281, l1: 0.019367, l2: 0.026399, l3: 0.037603, l4: 0.060944, l5: 0.104455, l6: 0.234510\n",
      "\n",
      "[epoch: 377/400, batch: 400/1000, ite: 49926] train loss: 1.1174, accuracy: 96.7412%, tar: 0.0207 \n",
      "l0: 0.018512, l1: 0.019338, l2: 0.025088, l3: 0.039736, l4: 0.062925, l5: 0.134054, l6: 0.280569\n",
      "\n",
      "[epoch: 377/400, batch: 408/1000, ite: 49927] train loss: 1.1173, accuracy: 95.7546%, tar: 0.0207 \n",
      "l0: 0.018112, l1: 0.019665, l2: 0.027967, l3: 0.042010, l4: 0.084706, l5: 0.196445, l6: 0.375840\n",
      "\n",
      "[epoch: 377/400, batch: 416/1000, ite: 49928] train loss: 1.1173, accuracy: 94.5630%, tar: 0.0207 \n",
      "l0: 0.017035, l1: 0.018010, l2: 0.023721, l3: 0.039894, l4: 0.073774, l5: 0.143983, l6: 0.305867\n",
      "\n",
      "[epoch: 377/400, batch: 424/1000, ite: 49929] train loss: 1.1172, accuracy: 95.0973%, tar: 0.0207 \n",
      "l0: 0.018803, l1: 0.019594, l2: 0.026714, l3: 0.038955, l4: 0.066877, l5: 0.135427, l6: 0.346769\n",
      "\n",
      "[epoch: 377/400, batch: 432/1000, ite: 49930] train loss: 1.1172, accuracy: 95.0637%, tar: 0.0207 \n",
      "l0: 0.020843, l1: 0.021890, l2: 0.028041, l3: 0.042365, l4: 0.083864, l5: 0.176832, l6: 0.380032\n",
      "\n",
      "[epoch: 377/400, batch: 440/1000, ite: 49931] train loss: 1.1172, accuracy: 94.7950%, tar: 0.0207 \n",
      "l0: 0.014816, l1: 0.016008, l2: 0.024359, l3: 0.036246, l4: 0.066863, l5: 0.127823, l6: 0.251330\n",
      "\n",
      "[epoch: 377/400, batch: 448/1000, ite: 49932] train loss: 1.1170, accuracy: 96.4405%, tar: 0.0207 \n",
      "l0: 0.018521, l1: 0.019357, l2: 0.025834, l3: 0.040013, l4: 0.080599, l5: 0.154068, l6: 0.419472\n",
      "\n",
      "[epoch: 377/400, batch: 456/1000, ite: 49933] train loss: 1.1171, accuracy: 94.7001%, tar: 0.0207 \n",
      "l0: 0.020256, l1: 0.021870, l2: 0.028258, l3: 0.042749, l4: 0.080302, l5: 0.181800, l6: 0.432436\n",
      "\n",
      "[epoch: 377/400, batch: 464/1000, ite: 49934] train loss: 1.1171, accuracy: 94.0595%, tar: 0.0207 \n",
      "l0: 0.019737, l1: 0.020911, l2: 0.028115, l3: 0.048162, l4: 0.097428, l5: 0.199955, l6: 0.381491\n",
      "\n",
      "[epoch: 377/400, batch: 472/1000, ite: 49935] train loss: 1.1171, accuracy: 95.0179%, tar: 0.0207 \n",
      "l0: 0.025294, l1: 0.026779, l2: 0.037317, l3: 0.058345, l4: 0.123727, l5: 0.256266, l6: 0.534398\n",
      "\n",
      "[epoch: 377/400, batch: 480/1000, ite: 49936] train loss: 1.1174, accuracy: 93.5381%, tar: 0.0207 \n",
      "l0: 0.024789, l1: 0.026374, l2: 0.033558, l3: 0.047723, l4: 0.100702, l5: 0.177377, l6: 0.325673\n",
      "\n",
      "[epoch: 377/400, batch: 488/1000, ite: 49937] train loss: 1.1174, accuracy: 95.2723%, tar: 0.0207 \n",
      "l0: 0.019802, l1: 0.021236, l2: 0.030091, l3: 0.051885, l4: 0.100954, l5: 0.167093, l6: 0.401047\n",
      "\n",
      "[epoch: 377/400, batch: 496/1000, ite: 49938] train loss: 1.1174, accuracy: 95.2605%, tar: 0.0207 \n",
      "l0: 0.021387, l1: 0.022434, l2: 0.030373, l3: 0.043976, l4: 0.072251, l5: 0.158490, l6: 0.363753\n",
      "\n",
      "[epoch: 377/400, batch: 504/1000, ite: 49939] train loss: 1.1174, accuracy: 94.8100%, tar: 0.0207 \n",
      "l0: 0.017155, l1: 0.018567, l2: 0.025704, l3: 0.041791, l4: 0.073476, l5: 0.154620, l6: 0.308796\n",
      "\n",
      "[epoch: 377/400, batch: 512/1000, ite: 49940] train loss: 1.1173, accuracy: 95.5762%, tar: 0.0207 \n",
      "l0: 0.023416, l1: 0.026221, l2: 0.037850, l3: 0.062129, l4: 0.132162, l5: 0.283325, l6: 0.493359\n",
      "\n",
      "[epoch: 377/400, batch: 520/1000, ite: 49941] train loss: 1.1175, accuracy: 94.6383%, tar: 0.0207 \n",
      "l0: 0.028365, l1: 0.030372, l2: 0.039680, l3: 0.063847, l4: 0.148468, l5: 0.328600, l6: 0.661729\n",
      "\n",
      "[epoch: 377/400, batch: 528/1000, ite: 49942] train loss: 1.1180, accuracy: 91.4567%, tar: 0.0207 \n",
      "l0: 0.018631, l1: 0.020069, l2: 0.027962, l3: 0.042786, l4: 0.088467, l5: 0.229960, l6: 0.405784\n",
      "\n",
      "[epoch: 377/400, batch: 536/1000, ite: 49943] train loss: 1.1180, accuracy: 94.4893%, tar: 0.0207 \n",
      "l0: 0.017983, l1: 0.019445, l2: 0.028469, l3: 0.043400, l4: 0.082741, l5: 0.200103, l6: 0.395933\n",
      "\n",
      "[epoch: 377/400, batch: 544/1000, ite: 49944] train loss: 1.1181, accuracy: 94.6801%, tar: 0.0207 \n",
      "l0: 0.015820, l1: 0.017046, l2: 0.023569, l3: 0.037636, l4: 0.066408, l5: 0.128282, l6: 0.301267\n",
      "\n",
      "[epoch: 377/400, batch: 552/1000, ite: 49945] train loss: 1.1180, accuracy: 95.9384%, tar: 0.0207 \n",
      "l0: 0.015483, l1: 0.016402, l2: 0.022844, l3: 0.036862, l4: 0.069680, l5: 0.145133, l6: 0.254282\n",
      "\n",
      "[epoch: 377/400, batch: 560/1000, ite: 49946] train loss: 1.1178, accuracy: 96.1741%, tar: 0.0207 \n",
      "l0: 0.017470, l1: 0.018779, l2: 0.024867, l3: 0.039237, l4: 0.083582, l5: 0.152768, l6: 0.248247\n",
      "\n",
      "[epoch: 377/400, batch: 568/1000, ite: 49947] train loss: 1.1177, accuracy: 96.8386%, tar: 0.0207 \n",
      "l0: 0.023617, l1: 0.025304, l2: 0.033526, l3: 0.052926, l4: 0.103345, l5: 0.207753, l6: 0.396663\n",
      "\n",
      "[epoch: 377/400, batch: 576/1000, ite: 49948] train loss: 1.1177, accuracy: 94.1593%, tar: 0.0207 \n",
      "l0: 0.018561, l1: 0.021108, l2: 0.034378, l3: 0.057714, l4: 0.090211, l5: 0.137788, l6: 0.323542\n",
      "\n",
      "[epoch: 377/400, batch: 584/1000, ite: 49949] train loss: 1.1177, accuracy: 96.4577%, tar: 0.0207 \n",
      "l0: 0.030244, l1: 0.031766, l2: 0.042715, l3: 0.066802, l4: 0.141031, l5: 0.304071, l6: 0.567019\n",
      "\n",
      "[epoch: 377/400, batch: 592/1000, ite: 49950] train loss: 1.1180, accuracy: 93.2435%, tar: 0.0207 \n",
      "l0: 0.017157, l1: 0.018465, l2: 0.025140, l3: 0.041137, l4: 0.076430, l5: 0.171243, l6: 0.344762\n",
      "\n",
      "[epoch: 377/400, batch: 600/1000, ite: 49951] train loss: 1.1180, accuracy: 95.3556%, tar: 0.0207 \n",
      "l0: 0.015571, l1: 0.016367, l2: 0.022735, l3: 0.035750, l4: 0.065280, l5: 0.118802, l6: 0.270563\n",
      "\n",
      "[epoch: 377/400, batch: 608/1000, ite: 49952] train loss: 1.1178, accuracy: 96.2609%, tar: 0.0207 \n",
      "l0: 0.024559, l1: 0.026545, l2: 0.035098, l3: 0.056250, l4: 0.097831, l5: 0.237543, l6: 0.453215\n",
      "\n",
      "[epoch: 377/400, batch: 616/1000, ite: 49953] train loss: 1.1179, accuracy: 93.3211%, tar: 0.0207 \n",
      "l0: 0.016832, l1: 0.017882, l2: 0.022643, l3: 0.033951, l4: 0.058929, l5: 0.111675, l6: 0.257686\n",
      "\n",
      "[epoch: 377/400, batch: 624/1000, ite: 49954] train loss: 1.1178, accuracy: 95.6797%, tar: 0.0207 \n",
      "l0: 0.021699, l1: 0.023311, l2: 0.030858, l3: 0.048676, l4: 0.097315, l5: 0.220784, l6: 0.395262\n",
      "\n",
      "[epoch: 377/400, batch: 632/1000, ite: 49955] train loss: 1.1178, accuracy: 94.3422%, tar: 0.0207 \n",
      "l0: 0.025515, l1: 0.026867, l2: 0.035043, l3: 0.048088, l4: 0.091830, l5: 0.194977, l6: 0.426867\n",
      "\n",
      "[epoch: 377/400, batch: 640/1000, ite: 49956] train loss: 1.1179, accuracy: 94.1054%, tar: 0.0207 \n",
      "l0: 0.018793, l1: 0.020266, l2: 0.028195, l3: 0.045397, l4: 0.091255, l5: 0.188218, l6: 0.324049\n",
      "\n",
      "[epoch: 377/400, batch: 648/1000, ite: 49957] train loss: 1.1179, accuracy: 95.9441%, tar: 0.0207 \n",
      "l0: 0.016625, l1: 0.018017, l2: 0.025933, l3: 0.046954, l4: 0.084474, l5: 0.169061, l6: 0.334750\n",
      "\n",
      "[epoch: 377/400, batch: 656/1000, ite: 49958] train loss: 1.1178, accuracy: 95.3527%, tar: 0.0207 \n",
      "l0: 0.025265, l1: 0.026299, l2: 0.033741, l3: 0.047505, l4: 0.080513, l5: 0.183404, l6: 0.421940\n",
      "\n",
      "[epoch: 377/400, batch: 664/1000, ite: 49959] train loss: 1.1179, accuracy: 94.0365%, tar: 0.0207 \n",
      "l0: 0.022669, l1: 0.023763, l2: 0.030349, l3: 0.044331, l4: 0.076663, l5: 0.150714, l6: 0.324565\n",
      "\n",
      "[epoch: 377/400, batch: 672/1000, ite: 49960] train loss: 1.1178, accuracy: 94.9735%, tar: 0.0207 \n",
      "l0: 0.018860, l1: 0.019936, l2: 0.027264, l3: 0.040536, l4: 0.075016, l5: 0.160771, l6: 0.385296\n",
      "\n",
      "[epoch: 377/400, batch: 680/1000, ite: 49961] train loss: 1.1178, accuracy: 94.9566%, tar: 0.0207 \n",
      "l0: 0.025078, l1: 0.027208, l2: 0.035746, l3: 0.054585, l4: 0.099118, l5: 0.175353, l6: 0.321944\n",
      "\n",
      "[epoch: 377/400, batch: 688/1000, ite: 49962] train loss: 1.1178, accuracy: 95.4381%, tar: 0.0207 \n",
      "l0: 0.017698, l1: 0.019657, l2: 0.031709, l3: 0.053686, l4: 0.101303, l5: 0.209679, l6: 0.425193\n",
      "\n",
      "[epoch: 377/400, batch: 696/1000, ite: 49963] train loss: 1.1179, accuracy: 95.6874%, tar: 0.0207 \n",
      "l0: 0.017771, l1: 0.019110, l2: 0.027709, l3: 0.041007, l4: 0.075728, l5: 0.159609, l6: 0.342743\n",
      "\n",
      "[epoch: 377/400, batch: 704/1000, ite: 49964] train loss: 1.1178, accuracy: 95.4807%, tar: 0.0207 \n",
      "l0: 0.028089, l1: 0.029617, l2: 0.038598, l3: 0.055132, l4: 0.101068, l5: 0.231360, l6: 0.449919\n",
      "\n",
      "[epoch: 377/400, batch: 712/1000, ite: 49965] train loss: 1.1180, accuracy: 93.8090%, tar: 0.0207 \n",
      "l0: 0.020061, l1: 0.022173, l2: 0.029674, l3: 0.051236, l4: 0.102411, l5: 0.232620, l6: 0.397968\n",
      "\n",
      "[epoch: 377/400, batch: 720/1000, ite: 49966] train loss: 1.1181, accuracy: 94.4495%, tar: 0.0207 \n",
      "l0: 0.018429, l1: 0.019567, l2: 0.027003, l3: 0.039778, l4: 0.076060, l5: 0.151290, l6: 0.351586\n",
      "\n",
      "[epoch: 377/400, batch: 728/1000, ite: 49967] train loss: 1.1180, accuracy: 95.6993%, tar: 0.0207 \n",
      "l0: 0.016796, l1: 0.018031, l2: 0.025355, l3: 0.039449, l4: 0.075213, l5: 0.173038, l6: 0.409732\n",
      "\n",
      "[epoch: 377/400, batch: 736/1000, ite: 49968] train loss: 1.1180, accuracy: 95.7791%, tar: 0.0207 \n",
      "l0: 0.019667, l1: 0.020579, l2: 0.030116, l3: 0.045125, l4: 0.079352, l5: 0.173225, l6: 0.369799\n",
      "\n",
      "[epoch: 377/400, batch: 744/1000, ite: 49969] train loss: 1.1180, accuracy: 95.2271%, tar: 0.0207 \n",
      "l0: 0.021756, l1: 0.023031, l2: 0.029665, l3: 0.043478, l4: 0.079727, l5: 0.150808, l6: 0.351148\n",
      "\n",
      "[epoch: 377/400, batch: 752/1000, ite: 49970] train loss: 1.1180, accuracy: 95.1807%, tar: 0.0207 \n",
      "l0: 0.019910, l1: 0.020990, l2: 0.028010, l3: 0.041961, l4: 0.079176, l5: 0.187507, l6: 0.404035\n",
      "\n",
      "[epoch: 377/400, batch: 760/1000, ite: 49971] train loss: 1.1180, accuracy: 94.0267%, tar: 0.0207 \n",
      "l0: 0.015823, l1: 0.016734, l2: 0.022968, l3: 0.033689, l4: 0.060630, l5: 0.139606, l6: 0.336226\n",
      "\n",
      "[epoch: 377/400, batch: 768/1000, ite: 49972] train loss: 1.1180, accuracy: 95.9327%, tar: 0.0207 \n",
      "l0: 0.020501, l1: 0.021776, l2: 0.028963, l3: 0.043758, l4: 0.087398, l5: 0.169002, l6: 0.325366\n",
      "\n",
      "[epoch: 377/400, batch: 776/1000, ite: 49973] train loss: 1.1179, accuracy: 95.1085%, tar: 0.0207 \n",
      "l0: 0.018927, l1: 0.020121, l2: 0.026719, l3: 0.041506, l4: 0.083415, l5: 0.156320, l6: 0.349679\n",
      "\n",
      "[epoch: 377/400, batch: 784/1000, ite: 49974] train loss: 1.1179, accuracy: 95.2542%, tar: 0.0207 \n",
      "l0: 0.025675, l1: 0.027590, l2: 0.036965, l3: 0.057151, l4: 0.112582, l5: 0.238218, l6: 0.504960\n",
      "\n",
      "[epoch: 377/400, batch: 792/1000, ite: 49975] train loss: 1.1181, accuracy: 93.4621%, tar: 0.0207 \n",
      "l0: 0.013937, l1: 0.014946, l2: 0.021278, l3: 0.033008, l4: 0.062522, l5: 0.115474, l6: 0.299822\n",
      "\n",
      "[epoch: 377/400, batch: 800/1000, ite: 49976] train loss: 1.1180, accuracy: 95.9088%, tar: 0.0207 \n",
      "l0: 0.025218, l1: 0.026531, l2: 0.035939, l3: 0.056106, l4: 0.094283, l5: 0.200655, l6: 0.432143\n",
      "\n",
      "[epoch: 377/400, batch: 808/1000, ite: 49977] train loss: 1.1180, accuracy: 94.5569%, tar: 0.0207 \n",
      "l0: 0.020513, l1: 0.022180, l2: 0.029579, l3: 0.046854, l4: 0.085854, l5: 0.169810, l6: 0.360259\n",
      "\n",
      "[epoch: 377/400, batch: 816/1000, ite: 49978] train loss: 1.1180, accuracy: 95.2737%, tar: 0.0207 \n",
      "l0: 0.018751, l1: 0.019747, l2: 0.029088, l3: 0.043126, l4: 0.071151, l5: 0.125946, l6: 0.284943\n",
      "\n",
      "[epoch: 377/400, batch: 824/1000, ite: 49979] train loss: 1.1179, accuracy: 95.9383%, tar: 0.0207 \n",
      "l0: 0.020570, l1: 0.022924, l2: 0.031408, l3: 0.052572, l4: 0.106688, l5: 0.234316, l6: 0.433798\n",
      "\n",
      "[epoch: 377/400, batch: 832/1000, ite: 49980] train loss: 1.1180, accuracy: 95.1385%, tar: 0.0207 \n",
      "l0: 0.021148, l1: 0.022632, l2: 0.031882, l3: 0.046616, l4: 0.089326, l5: 0.211700, l6: 0.410407\n",
      "\n",
      "[epoch: 377/400, batch: 840/1000, ite: 49981] train loss: 1.1181, accuracy: 94.5284%, tar: 0.0207 \n",
      "l0: 0.020435, l1: 0.022027, l2: 0.029578, l3: 0.044719, l4: 0.083020, l5: 0.197704, l6: 0.424474\n",
      "\n",
      "[epoch: 377/400, batch: 848/1000, ite: 49982] train loss: 1.1182, accuracy: 94.5842%, tar: 0.0207 \n",
      "l0: 0.028837, l1: 0.030730, l2: 0.038619, l3: 0.056768, l4: 0.096390, l5: 0.225629, l6: 0.462631\n",
      "\n",
      "[epoch: 377/400, batch: 856/1000, ite: 49983] train loss: 1.1183, accuracy: 93.8931%, tar: 0.0207 \n",
      "l0: 0.018999, l1: 0.020258, l2: 0.026218, l3: 0.039483, l4: 0.071064, l5: 0.173459, l6: 0.354158\n",
      "\n",
      "[epoch: 377/400, batch: 864/1000, ite: 49984] train loss: 1.1183, accuracy: 95.5087%, tar: 0.0207 \n",
      "l0: 0.017970, l1: 0.019473, l2: 0.026177, l3: 0.044469, l4: 0.082464, l5: 0.147448, l6: 0.265265\n",
      "\n",
      "[epoch: 377/400, batch: 872/1000, ite: 49985] train loss: 1.1182, accuracy: 95.7811%, tar: 0.0207 \n",
      "l0: 0.019978, l1: 0.020964, l2: 0.028312, l3: 0.049796, l4: 0.105100, l5: 0.203282, l6: 0.374756\n",
      "\n",
      "[epoch: 377/400, batch: 880/1000, ite: 49986] train loss: 1.1182, accuracy: 95.0293%, tar: 0.0207 \n",
      "l0: 0.021625, l1: 0.022678, l2: 0.029121, l3: 0.043289, l4: 0.085948, l5: 0.179581, l6: 0.389206\n",
      "\n",
      "[epoch: 377/400, batch: 888/1000, ite: 49987] train loss: 1.1182, accuracy: 95.0005%, tar: 0.0207 \n",
      "l0: 0.014339, l1: 0.015229, l2: 0.021954, l3: 0.033709, l4: 0.061854, l5: 0.116792, l6: 0.227910\n",
      "\n",
      "[epoch: 377/400, batch: 896/1000, ite: 49988] train loss: 1.1180, accuracy: 96.6427%, tar: 0.0207 \n",
      "l0: 0.017644, l1: 0.018972, l2: 0.025982, l3: 0.044244, l4: 0.085806, l5: 0.174844, l6: 0.351868\n",
      "\n",
      "[epoch: 377/400, batch: 904/1000, ite: 49989] train loss: 1.1180, accuracy: 95.6006%, tar: 0.0207 \n",
      "l0: 0.014616, l1: 0.015749, l2: 0.020740, l3: 0.029446, l4: 0.055315, l5: 0.130117, l6: 0.279236\n",
      "\n",
      "[epoch: 377/400, batch: 912/1000, ite: 49990] train loss: 1.1178, accuracy: 96.3751%, tar: 0.0207 \n",
      "l0: 0.017418, l1: 0.018446, l2: 0.027110, l3: 0.040445, l4: 0.071893, l5: 0.176870, l6: 0.398046\n",
      "\n",
      "[epoch: 377/400, batch: 920/1000, ite: 49991] train loss: 1.1179, accuracy: 95.7309%, tar: 0.0207 \n",
      "l0: 0.018620, l1: 0.019879, l2: 0.027460, l3: 0.043422, l4: 0.085671, l5: 0.169025, l6: 0.329668\n",
      "\n",
      "[epoch: 377/400, batch: 928/1000, ite: 49992] train loss: 1.1178, accuracy: 95.3690%, tar: 0.0207 \n",
      "l0: 0.020527, l1: 0.021394, l2: 0.026761, l3: 0.037480, l4: 0.058988, l5: 0.112865, l6: 0.302734\n",
      "\n",
      "[epoch: 377/400, batch: 936/1000, ite: 49993] train loss: 1.1177, accuracy: 95.4618%, tar: 0.0207 \n",
      "l0: 0.020485, l1: 0.021517, l2: 0.027002, l3: 0.040917, l4: 0.073702, l5: 0.154290, l6: 0.290527\n",
      "\n",
      "[epoch: 377/400, batch: 944/1000, ite: 49994] train loss: 1.1176, accuracy: 95.7584%, tar: 0.0207 \n",
      "l0: 0.018763, l1: 0.019707, l2: 0.027477, l3: 0.042033, l4: 0.080768, l5: 0.155615, l6: 0.281555\n",
      "\n",
      "[epoch: 377/400, batch: 952/1000, ite: 49995] train loss: 1.1175, accuracy: 96.3673%, tar: 0.0207 \n",
      "l0: 0.019465, l1: 0.020641, l2: 0.028956, l3: 0.048040, l4: 0.096439, l5: 0.188128, l6: 0.353581\n",
      "\n",
      "[epoch: 377/400, batch: 960/1000, ite: 49996] train loss: 1.1175, accuracy: 94.6081%, tar: 0.0207 \n",
      "l0: 0.022082, l1: 0.022879, l2: 0.031358, l3: 0.047838, l4: 0.092412, l5: 0.196532, l6: 0.371907\n",
      "\n",
      "[epoch: 377/400, batch: 968/1000, ite: 49997] train loss: 1.1175, accuracy: 94.4572%, tar: 0.0207 \n",
      "l0: 0.019242, l1: 0.021642, l2: 0.031113, l3: 0.049344, l4: 0.112591, l5: 0.182929, l6: 0.366795\n",
      "\n",
      "[epoch: 377/400, batch: 976/1000, ite: 49998] train loss: 1.1175, accuracy: 96.0033%, tar: 0.0207 \n",
      "l0: 0.020797, l1: 0.022681, l2: 0.030859, l3: 0.048657, l4: 0.089291, l5: 0.204143, l6: 0.437338\n",
      "\n",
      "[epoch: 377/400, batch: 984/1000, ite: 49999] train loss: 1.1176, accuracy: 94.1380%, tar: 0.0207 \n",
      "l0: 0.023260, l1: 0.025028, l2: 0.034444, l3: 0.055216, l4: 0.099786, l5: 0.201347, l6: 0.448453\n",
      "\n",
      "[epoch: 377/400, batch: 992/1000, ite: 50000] train loss: 1.1177, accuracy: 94.2806%, tar: 0.0207 \n",
      "l0: 0.020433, l1: 0.021459, l2: 0.028704, l3: 0.041322, l4: 0.076911, l5: 0.197742, l6: 0.434124\n",
      "\n",
      "[epoch: 377/400, batch: 1000/1000, ite: 50001] train loss: 1.2620, accuracy: 94.2181%, tar: 0.0204 \n",
      "l0: 0.019712, l1: 0.020541, l2: 0.026807, l3: 0.037998, l4: 0.063064, l5: 0.128274, l6: 0.293615\n",
      "\n",
      "[epoch: 378/400, batch: 8/1000, ite: 50002] train loss: 1.0745, accuracy: 95.2367%, tar: 0.0201 \n",
      "l0: 0.019681, l1: 0.021246, l2: 0.032736, l3: 0.057490, l4: 0.112577, l5: 0.237203, l6: 0.466944\n",
      "\n",
      "[epoch: 378/400, batch: 16/1000, ite: 50003] train loss: 1.1897, accuracy: 94.2179%, tar: 0.0199 \n",
      "l0: 0.020046, l1: 0.021198, l2: 0.028582, l3: 0.045668, l4: 0.082553, l5: 0.162915, l6: 0.312019\n",
      "\n",
      "[epoch: 378/400, batch: 24/1000, ite: 50004] train loss: 1.1399, accuracy: 95.9047%, tar: 0.0200 \n",
      "l0: 0.017944, l1: 0.020273, l2: 0.028803, l3: 0.045246, l4: 0.080702, l5: 0.149034, l6: 0.301401\n",
      "\n",
      "[epoch: 378/400, batch: 32/1000, ite: 50005] train loss: 1.1020, accuracy: 96.4037%, tar: 0.0196 \n",
      "l0: 0.020271, l1: 0.021861, l2: 0.029844, l3: 0.046012, l4: 0.083734, l5: 0.179556, l6: 0.421107\n",
      "\n",
      "[epoch: 378/400, batch: 40/1000, ite: 50006] train loss: 1.1231, accuracy: 94.9049%, tar: 0.0197 \n",
      "l0: 0.023158, l1: 0.024326, l2: 0.031742, l3: 0.045208, l4: 0.081008, l5: 0.162133, l6: 0.313763\n",
      "\n",
      "[epoch: 378/400, batch: 48/1000, ite: 50007] train loss: 1.1055, accuracy: 95.2474%, tar: 0.0202 \n",
      "l0: 0.025942, l1: 0.027665, l2: 0.038346, l3: 0.058024, l4: 0.119657, l5: 0.249600, l6: 0.470759\n",
      "\n",
      "[epoch: 378/400, batch: 56/1000, ite: 50008] train loss: 1.1501, accuracy: 93.5471%, tar: 0.0209 \n",
      "l0: 0.014646, l1: 0.015575, l2: 0.021171, l3: 0.032541, l4: 0.059520, l5: 0.129862, l6: 0.287939\n",
      "\n",
      "[epoch: 378/400, batch: 64/1000, ite: 50009] train loss: 1.1171, accuracy: 96.1815%, tar: 0.0202 \n",
      "l0: 0.017735, l1: 0.019411, l2: 0.025806, l3: 0.038181, l4: 0.075659, l5: 0.128778, l6: 0.274570\n",
      "\n",
      "[epoch: 378/400, batch: 72/1000, ite: 50010] train loss: 1.0915, accuracy: 96.1524%, tar: 0.0200 \n",
      "l0: 0.016168, l1: 0.017786, l2: 0.025077, l3: 0.036753, l4: 0.062894, l5: 0.122948, l6: 0.315014\n",
      "\n",
      "[epoch: 378/400, batch: 80/1000, ite: 50011] train loss: 1.0757, accuracy: 96.5037%, tar: 0.0196 \n",
      "l0: 0.020944, l1: 0.022809, l2: 0.030286, l3: 0.043482, l4: 0.077899, l5: 0.159530, l6: 0.322837\n",
      "\n",
      "[epoch: 378/400, batch: 88/1000, ite: 50012] train loss: 1.0708, accuracy: 95.8538%, tar: 0.0197 \n",
      "l0: 0.025197, l1: 0.026953, l2: 0.037413, l3: 0.059528, l4: 0.108259, l5: 0.187196, l6: 0.327920\n",
      "\n",
      "[epoch: 378/400, batch: 96/1000, ite: 50013] train loss: 1.0734, accuracy: 95.2529%, tar: 0.0201 \n",
      "l0: 0.015861, l1: 0.016882, l2: 0.021891, l3: 0.031590, l4: 0.067025, l5: 0.172797, l6: 0.334178\n",
      "\n",
      "[epoch: 378/400, batch: 104/1000, ite: 50014] train loss: 1.0680, accuracy: 95.2860%, tar: 0.0198 \n",
      "l0: 0.018820, l1: 0.020340, l2: 0.028925, l3: 0.046277, l4: 0.079522, l5: 0.167302, l6: 0.370542\n",
      "\n",
      "[epoch: 378/400, batch: 112/1000, ite: 50015] train loss: 1.0707, accuracy: 95.1163%, tar: 0.0198 \n",
      "l0: 0.020582, l1: 0.022290, l2: 0.030655, l3: 0.049273, l4: 0.111435, l5: 0.226673, l6: 0.428127\n",
      "\n",
      "[epoch: 378/400, batch: 120/1000, ite: 50016] train loss: 1.0860, accuracy: 95.0578%, tar: 0.0198 \n",
      "l0: 0.015734, l1: 0.016756, l2: 0.023051, l3: 0.034827, l4: 0.056129, l5: 0.120620, l6: 0.278451\n",
      "\n",
      "[epoch: 378/400, batch: 128/1000, ite: 50017] train loss: 1.0706, accuracy: 96.5512%, tar: 0.0196 \n",
      "l0: 0.019242, l1: 0.020505, l2: 0.029628, l3: 0.048274, l4: 0.099881, l5: 0.156364, l6: 0.277210\n",
      "\n",
      "[epoch: 378/400, batch: 136/1000, ite: 50018] train loss: 1.0630, accuracy: 96.0860%, tar: 0.0196 \n",
      "l0: 0.017354, l1: 0.018836, l2: 0.027907, l3: 0.040607, l4: 0.078788, l5: 0.197679, l6: 0.334756\n",
      "\n",
      "[epoch: 378/400, batch: 144/1000, ite: 50019] train loss: 1.0628, accuracy: 96.0355%, tar: 0.0194 \n",
      "l0: 0.019211, l1: 0.020918, l2: 0.028178, l3: 0.041891, l4: 0.078481, l5: 0.162070, l6: 0.354187\n",
      "\n",
      "[epoch: 378/400, batch: 152/1000, ite: 50020] train loss: 1.0627, accuracy: 95.2754%, tar: 0.0194 \n",
      "l0: 0.017487, l1: 0.019031, l2: 0.026345, l3: 0.044599, l4: 0.084633, l5: 0.166428, l6: 0.346480\n",
      "\n",
      "[epoch: 378/400, batch: 160/1000, ite: 50021] train loss: 1.0624, accuracy: 95.3086%, tar: 0.0193 \n",
      "l0: 0.019158, l1: 0.020163, l2: 0.027911, l3: 0.045490, l4: 0.082830, l5: 0.164839, l6: 0.359405\n",
      "\n",
      "[epoch: 378/400, batch: 168/1000, ite: 50022] train loss: 1.0633, accuracy: 95.0754%, tar: 0.0193 \n",
      "l0: 0.018533, l1: 0.019689, l2: 0.027637, l3: 0.040776, l4: 0.071840, l5: 0.158580, l6: 0.348129\n",
      "\n",
      "[epoch: 378/400, batch: 176/1000, ite: 50023] train loss: 1.0624, accuracy: 95.3169%, tar: 0.0193 \n",
      "l0: 0.017516, l1: 0.018614, l2: 0.024795, l3: 0.038756, l4: 0.077814, l5: 0.189693, l6: 0.394769\n",
      "\n",
      "[epoch: 378/400, batch: 184/1000, ite: 50024] train loss: 1.0668, accuracy: 94.3337%, tar: 0.0192 \n",
      "l0: 0.017235, l1: 0.018949, l2: 0.026700, l3: 0.042432, l4: 0.075930, l5: 0.195005, l6: 0.312237\n",
      "\n",
      "[epoch: 378/400, batch: 192/1000, ite: 50025] train loss: 1.0642, accuracy: 95.7237%, tar: 0.0191 \n",
      "l0: 0.015072, l1: 0.016495, l2: 0.024726, l3: 0.041082, l4: 0.081138, l5: 0.154854, l6: 0.286839\n",
      "\n",
      "[epoch: 378/400, batch: 200/1000, ite: 50026] train loss: 1.0582, accuracy: 96.7246%, tar: 0.0190 \n",
      "l0: 0.018566, l1: 0.019587, l2: 0.026573, l3: 0.043878, l4: 0.075868, l5: 0.161850, l6: 0.415864\n",
      "\n",
      "[epoch: 378/400, batch: 208/1000, ite: 50027] train loss: 1.0627, accuracy: 94.7250%, tar: 0.0190 \n",
      "l0: 0.014622, l1: 0.016152, l2: 0.025070, l3: 0.044316, l4: 0.085656, l5: 0.183347, l6: 0.362813\n",
      "\n",
      "[epoch: 378/400, batch: 216/1000, ite: 50028] train loss: 1.0640, accuracy: 95.3765%, tar: 0.0188 \n",
      "l0: 0.019936, l1: 0.020840, l2: 0.027481, l3: 0.039906, l4: 0.069584, l5: 0.136133, l6: 0.293784\n",
      "\n",
      "[epoch: 378/400, batch: 224/1000, ite: 50029] train loss: 1.0584, accuracy: 95.9152%, tar: 0.0189 \n",
      "l0: 0.020704, l1: 0.021853, l2: 0.029487, l3: 0.044010, l4: 0.078061, l5: 0.191730, l6: 0.431280\n",
      "\n",
      "[epoch: 378/400, batch: 232/1000, ite: 50030] train loss: 1.0648, accuracy: 94.6170%, tar: 0.0189 \n",
      "l0: 0.015076, l1: 0.016141, l2: 0.021538, l3: 0.033702, l4: 0.061393, l5: 0.122842, l6: 0.248310\n",
      "\n",
      "[epoch: 378/400, batch: 240/1000, ite: 50031] train loss: 1.0553, accuracy: 96.1316%, tar: 0.0188 \n",
      "l0: 0.028406, l1: 0.029646, l2: 0.040382, l3: 0.061497, l4: 0.105647, l5: 0.202214, l6: 0.375643\n",
      "\n",
      "[epoch: 378/400, batch: 248/1000, ite: 50032] train loss: 1.0606, accuracy: 94.3485%, tar: 0.0191 \n",
      "l0: 0.022307, l1: 0.023705, l2: 0.033282, l3: 0.047835, l4: 0.078598, l5: 0.158817, l6: 0.377572\n",
      "\n",
      "[epoch: 378/400, batch: 256/1000, ite: 50033] train loss: 1.0624, accuracy: 94.4963%, tar: 0.0192 \n",
      "l0: 0.013944, l1: 0.014731, l2: 0.022129, l3: 0.036248, l4: 0.074558, l5: 0.143444, l6: 0.302462\n",
      "\n",
      "[epoch: 378/400, batch: 264/1000, ite: 50034] train loss: 1.0579, accuracy: 95.9176%, tar: 0.0190 \n",
      "l0: 0.018626, l1: 0.020272, l2: 0.029266, l3: 0.045024, l4: 0.085206, l5: 0.178323, l6: 0.450637\n",
      "\n",
      "[epoch: 378/400, batch: 272/1000, ite: 50035] train loss: 1.0642, accuracy: 94.4437%, tar: 0.0190 \n",
      "l0: 0.024891, l1: 0.026716, l2: 0.035907, l3: 0.057124, l4: 0.118266, l5: 0.256597, l6: 0.436399\n",
      "\n",
      "[epoch: 378/400, batch: 280/1000, ite: 50036] train loss: 1.0735, accuracy: 93.7308%, tar: 0.0192 \n",
      "l0: 0.024363, l1: 0.026303, l2: 0.035519, l3: 0.055445, l4: 0.115771, l5: 0.230096, l6: 0.499869\n",
      "\n",
      "[epoch: 378/400, batch: 288/1000, ite: 50037] train loss: 1.0847, accuracy: 93.0515%, tar: 0.0193 \n",
      "l0: 0.019758, l1: 0.020670, l2: 0.027945, l3: 0.041675, l4: 0.071753, l5: 0.152159, l6: 0.311002\n",
      "\n",
      "[epoch: 378/400, batch: 296/1000, ite: 50038] train loss: 1.0814, accuracy: 95.4499%, tar: 0.0193 \n",
      "l0: 0.019314, l1: 0.020789, l2: 0.029105, l3: 0.048024, l4: 0.080757, l5: 0.161552, l6: 0.335929\n",
      "\n",
      "[epoch: 378/400, batch: 304/1000, ite: 50039] train loss: 1.0802, accuracy: 95.9863%, tar: 0.0193 \n",
      "l0: 0.019782, l1: 0.020768, l2: 0.029094, l3: 0.043829, l4: 0.087803, l5: 0.194404, l6: 0.387669\n",
      "\n",
      "[epoch: 378/400, batch: 312/1000, ite: 50040] train loss: 1.0826, accuracy: 95.4055%, tar: 0.0193 \n",
      "l0: 0.018547, l1: 0.020434, l2: 0.030902, l3: 0.053837, l4: 0.104744, l5: 0.191866, l6: 0.360899\n",
      "\n",
      "[epoch: 378/400, batch: 320/1000, ite: 50041] train loss: 1.0841, accuracy: 95.2575%, tar: 0.0193 \n",
      "l0: 0.019284, l1: 0.020402, l2: 0.028704, l3: 0.040273, l4: 0.070252, l5: 0.144052, l6: 0.318949\n",
      "\n",
      "[epoch: 378/400, batch: 328/1000, ite: 50042] train loss: 1.0814, accuracy: 95.4229%, tar: 0.0193 \n",
      "l0: 0.020571, l1: 0.021899, l2: 0.028583, l3: 0.043201, l4: 0.077099, l5: 0.148910, l6: 0.271479\n",
      "\n",
      "[epoch: 378/400, batch: 336/1000, ite: 50043] train loss: 1.0769, accuracy: 96.0234%, tar: 0.0194 \n",
      "l0: 0.018342, l1: 0.019270, l2: 0.027398, l3: 0.042665, l4: 0.084108, l5: 0.174502, l6: 0.367022\n",
      "\n",
      "[epoch: 378/400, batch: 344/1000, ite: 50044] train loss: 1.0776, accuracy: 94.9122%, tar: 0.0193 \n",
      "l0: 0.015047, l1: 0.015986, l2: 0.021919, l3: 0.034563, l4: 0.060259, l5: 0.116482, l6: 0.249323\n",
      "\n",
      "[epoch: 378/400, batch: 352/1000, ite: 50045] train loss: 1.0707, accuracy: 96.0431%, tar: 0.0192 \n",
      "l0: 0.023850, l1: 0.025392, l2: 0.030679, l3: 0.045420, l4: 0.091839, l5: 0.211414, l6: 0.392187\n",
      "\n",
      "[epoch: 378/400, batch: 360/1000, ite: 50046] train loss: 1.0739, accuracy: 94.7971%, tar: 0.0193 \n",
      "l0: 0.015259, l1: 0.016884, l2: 0.022930, l3: 0.040477, l4: 0.085128, l5: 0.199442, l6: 0.417571\n",
      "\n",
      "[epoch: 378/400, batch: 368/1000, ite: 50047] train loss: 1.0769, accuracy: 95.8873%, tar: 0.0193 \n",
      "l0: 0.023378, l1: 0.024956, l2: 0.032456, l3: 0.051208, l4: 0.100158, l5: 0.201193, l6: 0.399352\n",
      "\n",
      "[epoch: 378/400, batch: 376/1000, ite: 50048] train loss: 1.0802, accuracy: 94.1791%, tar: 0.0193 \n",
      "l0: 0.017234, l1: 0.018521, l2: 0.026836, l3: 0.042918, l4: 0.083055, l5: 0.148151, l6: 0.287006\n",
      "\n",
      "[epoch: 378/400, batch: 384/1000, ite: 50049] train loss: 1.0769, accuracy: 95.9994%, tar: 0.0193 \n",
      "l0: 0.018338, l1: 0.019895, l2: 0.030736, l3: 0.051472, l4: 0.105366, l5: 0.191104, l6: 0.367025\n",
      "\n",
      "[epoch: 378/400, batch: 392/1000, ite: 50050] train loss: 1.0784, accuracy: 95.3270%, tar: 0.0193 \n",
      "l0: 0.018711, l1: 0.020558, l2: 0.029113, l3: 0.044458, l4: 0.079924, l5: 0.157269, l6: 0.399666\n",
      "\n",
      "[epoch: 378/400, batch: 400/1000, ite: 50051] train loss: 1.0798, accuracy: 95.6672%, tar: 0.0193 \n",
      "l0: 0.017579, l1: 0.019142, l2: 0.028698, l3: 0.046963, l4: 0.079877, l5: 0.181031, l6: 0.390616\n",
      "\n",
      "[epoch: 378/400, batch: 408/1000, ite: 50052] train loss: 1.0814, accuracy: 95.0821%, tar: 0.0192 \n",
      "l0: 0.018773, l1: 0.020560, l2: 0.030186, l3: 0.050265, l4: 0.111077, l5: 0.182399, l6: 0.290563\n",
      "\n",
      "[epoch: 378/400, batch: 416/1000, ite: 50053] train loss: 1.0799, accuracy: 95.8513%, tar: 0.0192 \n",
      "l0: 0.020780, l1: 0.022641, l2: 0.034047, l3: 0.058116, l4: 0.102055, l5: 0.207629, l6: 0.425511\n",
      "\n",
      "[epoch: 378/400, batch: 424/1000, ite: 50054] train loss: 1.0839, accuracy: 95.3259%, tar: 0.0193 \n",
      "l0: 0.019418, l1: 0.020373, l2: 0.028301, l3: 0.040107, l4: 0.072409, l5: 0.169445, l6: 0.372746\n",
      "\n",
      "[epoch: 378/400, batch: 432/1000, ite: 50055] train loss: 1.0843, accuracy: 95.2239%, tar: 0.0193 \n",
      "l0: 0.022589, l1: 0.024369, l2: 0.032559, l3: 0.048531, l4: 0.098706, l5: 0.246662, l6: 0.557392\n",
      "\n",
      "[epoch: 378/400, batch: 440/1000, ite: 50056] train loss: 1.0932, accuracy: 93.7217%, tar: 0.0193 \n",
      "l0: 0.020040, l1: 0.022035, l2: 0.030854, l3: 0.047257, l4: 0.092029, l5: 0.190189, l6: 0.415928\n",
      "\n",
      "[epoch: 378/400, batch: 448/1000, ite: 50057] train loss: 1.0958, accuracy: 94.9152%, tar: 0.0193 \n",
      "l0: 0.020983, l1: 0.022296, l2: 0.029791, l3: 0.046949, l4: 0.094956, l5: 0.186618, l6: 0.404100\n",
      "\n",
      "[epoch: 378/400, batch: 456/1000, ite: 50058] train loss: 1.0977, accuracy: 94.4791%, tar: 0.0194 \n",
      "l0: 0.019165, l1: 0.020734, l2: 0.027612, l3: 0.041482, l4: 0.074630, l5: 0.142614, l6: 0.261860\n",
      "\n",
      "[epoch: 378/400, batch: 464/1000, ite: 50059] train loss: 1.0936, accuracy: 96.5134%, tar: 0.0194 \n",
      "l0: 0.018871, l1: 0.019757, l2: 0.027713, l3: 0.042957, l4: 0.085984, l5: 0.152129, l6: 0.305983\n",
      "\n",
      "[epoch: 378/400, batch: 472/1000, ite: 50060] train loss: 1.0914, accuracy: 95.6296%, tar: 0.0193 \n",
      "l0: 0.017741, l1: 0.019200, l2: 0.027603, l3: 0.041123, l4: 0.077173, l5: 0.158298, l6: 0.344623\n",
      "\n",
      "[epoch: 378/400, batch: 480/1000, ite: 50061] train loss: 1.0905, accuracy: 95.7684%, tar: 0.0193 \n",
      "l0: 0.016543, l1: 0.017421, l2: 0.024184, l3: 0.036971, l4: 0.074449, l5: 0.156398, l6: 0.368988\n",
      "\n",
      "[epoch: 378/400, batch: 488/1000, ite: 50062] train loss: 1.0901, accuracy: 94.5543%, tar: 0.0193 \n",
      "l0: 0.020511, l1: 0.021526, l2: 0.028171, l3: 0.040849, l4: 0.073259, l5: 0.138677, l6: 0.274761\n",
      "\n",
      "[epoch: 378/400, batch: 496/1000, ite: 50063] train loss: 1.0867, accuracy: 95.3520%, tar: 0.0193 \n",
      "l0: 0.017002, l1: 0.018027, l2: 0.026642, l3: 0.041332, l4: 0.072323, l5: 0.127041, l6: 0.282142\n",
      "\n",
      "[epoch: 378/400, batch: 504/1000, ite: 50064] train loss: 1.0833, accuracy: 95.5852%, tar: 0.0193 \n",
      "l0: 0.029205, l1: 0.030858, l2: 0.041458, l3: 0.062804, l4: 0.122296, l5: 0.255269, l6: 0.519465\n",
      "\n",
      "[epoch: 378/400, batch: 512/1000, ite: 50065] train loss: 1.0910, accuracy: 93.1440%, tar: 0.0194 \n",
      "l0: 0.027875, l1: 0.029017, l2: 0.036258, l3: 0.051567, l4: 0.095141, l5: 0.177074, l6: 0.377208\n",
      "\n",
      "[epoch: 378/400, batch: 520/1000, ite: 50066] train loss: 1.0923, accuracy: 94.3496%, tar: 0.0195 \n",
      "l0: 0.023871, l1: 0.025238, l2: 0.033847, l3: 0.056647, l4: 0.114164, l5: 0.227244, l6: 0.478357\n",
      "\n",
      "[epoch: 378/400, batch: 528/1000, ite: 50067] train loss: 1.0975, accuracy: 94.1026%, tar: 0.0196 \n",
      "l0: 0.018081, l1: 0.018788, l2: 0.025631, l3: 0.038250, l4: 0.064705, l5: 0.136836, l6: 0.289047\n",
      "\n",
      "[epoch: 378/400, batch: 536/1000, ite: 50068] train loss: 1.0944, accuracy: 95.8538%, tar: 0.0196 \n",
      "l0: 0.021237, l1: 0.022634, l2: 0.032098, l3: 0.049967, l4: 0.088124, l5: 0.179150, l6: 0.352688\n",
      "\n",
      "[epoch: 378/400, batch: 544/1000, ite: 50069] train loss: 1.0945, accuracy: 94.9501%, tar: 0.0196 \n",
      "l0: 0.023767, l1: 0.025049, l2: 0.035226, l3: 0.052174, l4: 0.094290, l5: 0.196600, l6: 0.397368\n",
      "\n",
      "[epoch: 378/400, batch: 552/1000, ite: 50070] train loss: 1.0964, accuracy: 94.2294%, tar: 0.0197 \n",
      "l0: 0.017554, l1: 0.018851, l2: 0.027724, l3: 0.043680, l4: 0.081389, l5: 0.146881, l6: 0.258612\n",
      "\n",
      "[epoch: 378/400, batch: 560/1000, ite: 50071] train loss: 1.0930, accuracy: 96.0508%, tar: 0.0196 \n",
      "l0: 0.021363, l1: 0.022413, l2: 0.030008, l3: 0.047409, l4: 0.086764, l5: 0.186869, l6: 0.406304\n",
      "\n",
      "[epoch: 378/400, batch: 568/1000, ite: 50072] train loss: 1.0947, accuracy: 93.8391%, tar: 0.0197 \n",
      "l0: 0.018395, l1: 0.019874, l2: 0.027223, l3: 0.042159, l4: 0.081609, l5: 0.166565, l6: 0.350969\n",
      "\n",
      "[epoch: 378/400, batch: 576/1000, ite: 50073] train loss: 1.0942, accuracy: 95.0086%, tar: 0.0196 \n",
      "l0: 0.021908, l1: 0.022908, l2: 0.031745, l3: 0.049686, l4: 0.107790, l5: 0.254410, l6: 0.483779\n",
      "\n",
      "[epoch: 378/400, batch: 584/1000, ite: 50074] train loss: 1.0990, accuracy: 93.3962%, tar: 0.0197 \n",
      "l0: 0.033988, l1: 0.036203, l2: 0.050492, l3: 0.082759, l4: 0.194697, l5: 0.425193, l6: 0.761990\n",
      "\n",
      "[epoch: 378/400, batch: 592/1000, ite: 50075] train loss: 1.1157, accuracy: 90.4928%, tar: 0.0199 \n",
      "l0: 0.019274, l1: 0.020253, l2: 0.028996, l3: 0.049740, l4: 0.095241, l5: 0.185977, l6: 0.424673\n",
      "\n",
      "[epoch: 378/400, batch: 600/1000, ite: 50076] train loss: 1.1175, accuracy: 95.0338%, tar: 0.0199 \n",
      "l0: 0.016489, l1: 0.019353, l2: 0.029743, l3: 0.047545, l4: 0.087982, l5: 0.176584, l6: 0.376046\n",
      "\n",
      "[epoch: 378/400, batch: 608/1000, ite: 50077] train loss: 1.1177, accuracy: 96.1076%, tar: 0.0198 \n",
      "l0: 0.019526, l1: 0.021813, l2: 0.031150, l3: 0.049653, l4: 0.153479, l5: 0.282641, l6: 0.435563\n",
      "\n",
      "[epoch: 378/400, batch: 616/1000, ite: 50078] train loss: 1.1217, accuracy: 94.9770%, tar: 0.0198 \n",
      "l0: 0.015610, l1: 0.016485, l2: 0.021356, l3: 0.032403, l4: 0.055125, l5: 0.107648, l6: 0.260660\n",
      "\n",
      "[epoch: 378/400, batch: 624/1000, ite: 50079] train loss: 1.1173, accuracy: 95.7033%, tar: 0.0198 \n",
      "l0: 0.019099, l1: 0.020019, l2: 0.027303, l3: 0.040391, l4: 0.074942, l5: 0.168709, l6: 0.331940\n",
      "\n",
      "[epoch: 378/400, batch: 632/1000, ite: 50080] train loss: 1.1161, accuracy: 95.1100%, tar: 0.0197 \n",
      "l0: 0.013059, l1: 0.013942, l2: 0.020177, l3: 0.032025, l4: 0.056368, l5: 0.115963, l6: 0.218984\n",
      "\n",
      "[epoch: 378/400, batch: 640/1000, ite: 50081] train loss: 1.1108, accuracy: 96.7197%, tar: 0.0197 \n",
      "l0: 0.017758, l1: 0.019252, l2: 0.028101, l3: 0.044581, l4: 0.091178, l5: 0.181067, l6: 0.392702\n",
      "\n",
      "[epoch: 378/400, batch: 648/1000, ite: 50082] train loss: 1.1115, accuracy: 95.0215%, tar: 0.0196 \n",
      "l0: 0.017746, l1: 0.018825, l2: 0.025069, l3: 0.037140, l4: 0.069954, l5: 0.159942, l6: 0.340488\n",
      "\n",
      "[epoch: 378/400, batch: 656/1000, ite: 50083] train loss: 1.1103, accuracy: 95.9719%, tar: 0.0196 \n",
      "l0: 0.026806, l1: 0.028653, l2: 0.036052, l3: 0.054961, l4: 0.092620, l5: 0.193730, l6: 0.501469\n",
      "\n",
      "[epoch: 378/400, batch: 664/1000, ite: 50084] train loss: 1.1142, accuracy: 93.7355%, tar: 0.0197 \n",
      "l0: 0.014638, l1: 0.016422, l2: 0.024185, l3: 0.040242, l4: 0.084005, l5: 0.146667, l6: 0.332445\n",
      "\n",
      "[epoch: 378/400, batch: 672/1000, ite: 50085] train loss: 1.1128, accuracy: 95.7571%, tar: 0.0196 \n",
      "l0: 0.026686, l1: 0.028701, l2: 0.038809, l3: 0.056296, l4: 0.102983, l5: 0.218534, l6: 0.404700\n",
      "\n",
      "[epoch: 378/400, batch: 680/1000, ite: 50086] train loss: 1.1148, accuracy: 94.2633%, tar: 0.0197 \n",
      "l0: 0.017000, l1: 0.018674, l2: 0.027319, l3: 0.046449, l4: 0.089221, l5: 0.155102, l6: 0.283240\n",
      "\n",
      "[epoch: 378/400, batch: 688/1000, ite: 50087] train loss: 1.1126, accuracy: 96.3335%, tar: 0.0197 \n",
      "l0: 0.018468, l1: 0.020001, l2: 0.027939, l3: 0.047422, l4: 0.100462, l5: 0.213874, l6: 0.416113\n",
      "\n",
      "[epoch: 378/400, batch: 696/1000, ite: 50088] train loss: 1.1143, accuracy: 95.1531%, tar: 0.0197 \n",
      "l0: 0.014568, l1: 0.015901, l2: 0.021093, l3: 0.030173, l4: 0.051432, l5: 0.105223, l6: 0.236047\n",
      "\n",
      "[epoch: 378/400, batch: 704/1000, ite: 50089] train loss: 1.1100, accuracy: 96.8543%, tar: 0.0196 \n",
      "l0: 0.018439, l1: 0.019337, l2: 0.025620, l3: 0.037755, l4: 0.066276, l5: 0.123670, l6: 0.265429\n",
      "\n",
      "[epoch: 378/400, batch: 712/1000, ite: 50090] train loss: 1.1069, accuracy: 95.8854%, tar: 0.0196 \n",
      "l0: 0.024299, l1: 0.025985, l2: 0.035930, l3: 0.057472, l4: 0.112731, l5: 0.246913, l6: 0.456450\n",
      "\n",
      "[epoch: 378/400, batch: 720/1000, ite: 50091] train loss: 1.1102, accuracy: 93.5587%, tar: 0.0197 \n",
      "l0: 0.017176, l1: 0.018047, l2: 0.023254, l3: 0.033928, l4: 0.059030, l5: 0.127055, l6: 0.283695\n",
      "\n",
      "[epoch: 378/400, batch: 728/1000, ite: 50092] train loss: 1.1074, accuracy: 96.0433%, tar: 0.0196 \n",
      "l0: 0.024611, l1: 0.026025, l2: 0.036566, l3: 0.056875, l4: 0.112656, l5: 0.252962, l6: 0.445068\n",
      "\n",
      "[epoch: 378/400, batch: 736/1000, ite: 50093] train loss: 1.1106, accuracy: 93.9081%, tar: 0.0197 \n",
      "l0: 0.017807, l1: 0.018707, l2: 0.024962, l3: 0.038369, l4: 0.070963, l5: 0.146695, l6: 0.352514\n",
      "\n",
      "[epoch: 378/400, batch: 744/1000, ite: 50094] train loss: 1.1097, accuracy: 94.5482%, tar: 0.0197 \n",
      "l0: 0.020239, l1: 0.021956, l2: 0.029903, l3: 0.049232, l4: 0.083452, l5: 0.152483, l6: 0.379783\n",
      "\n",
      "[epoch: 378/400, batch: 752/1000, ite: 50095] train loss: 1.1098, accuracy: 94.7924%, tar: 0.0197 \n",
      "l0: 0.022130, l1: 0.023327, l2: 0.031626, l3: 0.045354, l4: 0.084791, l5: 0.171705, l6: 0.336673\n",
      "\n",
      "[epoch: 378/400, batch: 760/1000, ite: 50096] train loss: 1.1092, accuracy: 94.6930%, tar: 0.0197 \n",
      "l0: 0.021817, l1: 0.024142, l2: 0.033095, l3: 0.054150, l4: 0.115402, l5: 0.230699, l6: 0.440505\n",
      "\n",
      "[epoch: 378/400, batch: 768/1000, ite: 50097] train loss: 1.1119, accuracy: 94.7388%, tar: 0.0197 \n",
      "l0: 0.017189, l1: 0.018012, l2: 0.025480, l3: 0.041141, l4: 0.085734, l5: 0.179669, l6: 0.316975\n",
      "\n",
      "[epoch: 378/400, batch: 776/1000, ite: 50098] train loss: 1.1108, accuracy: 95.4525%, tar: 0.0197 \n",
      "l0: 0.015773, l1: 0.017346, l2: 0.024836, l3: 0.038743, l4: 0.081570, l5: 0.185411, l6: 0.360589\n",
      "\n",
      "[epoch: 378/400, batch: 784/1000, ite: 50099] train loss: 1.1106, accuracy: 95.4856%, tar: 0.0197 \n",
      "l0: 0.020156, l1: 0.021498, l2: 0.029588, l3: 0.044582, l4: 0.089646, l5: 0.215729, l6: 0.417767\n",
      "\n",
      "[epoch: 378/400, batch: 792/1000, ite: 50100] train loss: 1.1121, accuracy: 94.4168%, tar: 0.0197 \n",
      "l0: 0.020102, l1: 0.021674, l2: 0.028906, l3: 0.044241, l4: 0.081268, l5: 0.165571, l6: 0.425291\n",
      "\n",
      "[epoch: 378/400, batch: 800/1000, ite: 50101] train loss: 1.1131, accuracy: 95.0552%, tar: 0.0197 \n",
      "l0: 0.019756, l1: 0.020850, l2: 0.027885, l3: 0.039847, l4: 0.066707, l5: 0.124620, l6: 0.283950\n",
      "\n",
      "[epoch: 378/400, batch: 808/1000, ite: 50102] train loss: 1.1108, accuracy: 95.8467%, tar: 0.0197 \n",
      "l0: 0.019929, l1: 0.021477, l2: 0.029474, l3: 0.045856, l4: 0.084563, l5: 0.175839, l6: 0.384171\n",
      "\n",
      "[epoch: 378/400, batch: 816/1000, ite: 50103] train loss: 1.1111, accuracy: 94.2618%, tar: 0.0197 \n",
      "l0: 0.017019, l1: 0.017602, l2: 0.023506, l3: 0.036865, l4: 0.064853, l5: 0.143776, l6: 0.309017\n",
      "\n",
      "[epoch: 378/400, batch: 824/1000, ite: 50104] train loss: 1.1094, accuracy: 95.3667%, tar: 0.0196 \n",
      "l0: 0.024495, l1: 0.025922, l2: 0.034311, l3: 0.050712, l4: 0.093807, l5: 0.235134, l6: 0.496568\n",
      "\n",
      "[epoch: 378/400, batch: 832/1000, ite: 50105] train loss: 1.1127, accuracy: 93.2333%, tar: 0.0197 \n",
      "l0: 0.022052, l1: 0.023280, l2: 0.030877, l3: 0.048648, l4: 0.098584, l5: 0.206313, l6: 0.399457\n",
      "\n",
      "[epoch: 378/400, batch: 840/1000, ite: 50106] train loss: 1.1138, accuracy: 94.4245%, tar: 0.0197 \n",
      "l0: 0.024636, l1: 0.025606, l2: 0.034677, l3: 0.052648, l4: 0.093990, l5: 0.202708, l6: 0.371252\n",
      "\n",
      "[epoch: 378/400, batch: 848/1000, ite: 50107] train loss: 1.1144, accuracy: 94.6208%, tar: 0.0198 \n",
      "l0: 0.022949, l1: 0.023722, l2: 0.032161, l3: 0.047038, l4: 0.095114, l5: 0.220594, l6: 0.402153\n",
      "\n",
      "[epoch: 378/400, batch: 856/1000, ite: 50108] train loss: 1.1157, accuracy: 93.8297%, tar: 0.0198 \n",
      "l0: 0.016693, l1: 0.017336, l2: 0.023013, l3: 0.036160, l4: 0.064189, l5: 0.134707, l6: 0.322007\n",
      "\n",
      "[epoch: 378/400, batch: 864/1000, ite: 50109] train loss: 1.1141, accuracy: 95.5443%, tar: 0.0198 \n",
      "l0: 0.021491, l1: 0.022400, l2: 0.029031, l3: 0.041966, l4: 0.077987, l5: 0.177676, l6: 0.412597\n",
      "\n",
      "[epoch: 378/400, batch: 872/1000, ite: 50110] train loss: 1.1149, accuracy: 94.3759%, tar: 0.0198 \n",
      "l0: 0.016736, l1: 0.018251, l2: 0.026248, l3: 0.041526, l4: 0.083826, l5: 0.148076, l6: 0.314217\n",
      "\n",
      "[epoch: 378/400, batch: 880/1000, ite: 50111] train loss: 1.1136, accuracy: 95.7810%, tar: 0.0197 \n",
      "l0: 0.017725, l1: 0.019052, l2: 0.027445, l3: 0.042751, l4: 0.079973, l5: 0.157858, l6: 0.338741\n",
      "\n",
      "[epoch: 378/400, batch: 888/1000, ite: 50112] train loss: 1.1128, accuracy: 95.6947%, tar: 0.0197 \n",
      "l0: 0.023198, l1: 0.024546, l2: 0.033344, l3: 0.050560, l4: 0.099207, l5: 0.214697, l6: 0.428959\n",
      "\n",
      "[epoch: 378/400, batch: 896/1000, ite: 50113] train loss: 1.1145, accuracy: 93.9555%, tar: 0.0198 \n",
      "l0: 0.017199, l1: 0.018365, l2: 0.025202, l3: 0.038504, l4: 0.076150, l5: 0.155205, l6: 0.339629\n",
      "\n",
      "[epoch: 378/400, batch: 904/1000, ite: 50114] train loss: 1.1136, accuracy: 95.4206%, tar: 0.0197 \n",
      "l0: 0.020827, l1: 0.021940, l2: 0.029667, l3: 0.045532, l4: 0.083227, l5: 0.184994, l6: 0.389448\n",
      "\n",
      "[epoch: 378/400, batch: 912/1000, ite: 50115] train loss: 1.1141, accuracy: 94.1001%, tar: 0.0197 \n",
      "l0: 0.020161, l1: 0.021212, l2: 0.027576, l3: 0.042777, l4: 0.079074, l5: 0.151270, l6: 0.318872\n",
      "\n",
      "[epoch: 378/400, batch: 920/1000, ite: 50116] train loss: 1.1130, accuracy: 94.8688%, tar: 0.0198 \n",
      "l0: 0.021709, l1: 0.023462, l2: 0.033343, l3: 0.055389, l4: 0.123670, l5: 0.247782, l6: 0.443065\n",
      "\n",
      "[epoch: 378/400, batch: 928/1000, ite: 50117] train loss: 1.1154, accuracy: 94.1440%, tar: 0.0198 \n",
      "l0: 0.018816, l1: 0.019986, l2: 0.026226, l3: 0.037598, l4: 0.067368, l5: 0.142726, l6: 0.302885\n",
      "\n",
      "[epoch: 378/400, batch: 936/1000, ite: 50118] train loss: 1.1138, accuracy: 95.0323%, tar: 0.0198 \n",
      "l0: 0.019652, l1: 0.020783, l2: 0.026754, l3: 0.038436, l4: 0.062389, l5: 0.106691, l6: 0.238897\n",
      "\n",
      "[epoch: 378/400, batch: 944/1000, ite: 50119] train loss: 1.1107, accuracy: 96.0983%, tar: 0.0198 \n",
      "l0: 0.022379, l1: 0.023448, l2: 0.030399, l3: 0.040958, l4: 0.066061, l5: 0.136548, l6: 0.289605\n",
      "\n",
      "[epoch: 378/400, batch: 952/1000, ite: 50120] train loss: 1.1090, accuracy: 95.5632%, tar: 0.0198 \n",
      "l0: 0.020427, l1: 0.021857, l2: 0.030623, l3: 0.047854, l4: 0.096841, l5: 0.195439, l6: 0.409456\n",
      "\n",
      "[epoch: 378/400, batch: 960/1000, ite: 50121] train loss: 1.1101, accuracy: 94.8696%, tar: 0.0198 \n",
      "l0: 0.021250, l1: 0.022455, l2: 0.028538, l3: 0.044516, l4: 0.085454, l5: 0.171953, l6: 0.408093\n",
      "\n",
      "[epoch: 378/400, batch: 968/1000, ite: 50122] train loss: 1.1107, accuracy: 94.2988%, tar: 0.0198 \n",
      "l0: 0.022890, l1: 0.023761, l2: 0.030437, l3: 0.042785, l4: 0.081187, l5: 0.142076, l6: 0.294053\n",
      "\n",
      "[epoch: 378/400, batch: 976/1000, ite: 50123] train loss: 1.1093, accuracy: 95.0035%, tar: 0.0198 \n",
      "l0: 0.023890, l1: 0.025606, l2: 0.035183, l3: 0.053746, l4: 0.091713, l5: 0.217481, l6: 0.549268\n",
      "\n",
      "[epoch: 378/400, batch: 984/1000, ite: 50124] train loss: 1.1128, accuracy: 93.3887%, tar: 0.0199 \n",
      "l0: 0.017773, l1: 0.018881, l2: 0.025360, l3: 0.036474, l4: 0.070349, l5: 0.141263, l6: 0.349343\n",
      "\n",
      "[epoch: 378/400, batch: 992/1000, ite: 50125] train loss: 1.1119, accuracy: 95.2274%, tar: 0.0198 \n",
      "l0: 0.017676, l1: 0.018918, l2: 0.025444, l3: 0.040271, l4: 0.070226, l5: 0.153691, l6: 0.345751\n",
      "\n",
      "[epoch: 378/400, batch: 1000/1000, ite: 50126] train loss: 1.1112, accuracy: 94.8507%, tar: 0.0198 \n",
      "l0: 0.015727, l1: 0.016948, l2: 0.024521, l3: 0.037651, l4: 0.075929, l5: 0.141631, l6: 0.299852\n",
      "\n",
      "[epoch: 379/400, batch: 8/1000, ite: 50127] train loss: 1.1097, accuracy: 95.9994%, tar: 0.0198 \n",
      "l0: 0.019805, l1: 0.021209, l2: 0.029299, l3: 0.044242, l4: 0.084991, l5: 0.186707, l6: 0.361831\n",
      "\n",
      "[epoch: 379/400, batch: 16/1000, ite: 50128] train loss: 1.1098, accuracy: 95.0679%, tar: 0.0198 \n",
      "l0: 0.022016, l1: 0.024192, l2: 0.033975, l3: 0.052483, l4: 0.103078, l5: 0.232623, l6: 0.453330\n",
      "\n",
      "[epoch: 379/400, batch: 24/1000, ite: 50129] train loss: 1.1118, accuracy: 93.7877%, tar: 0.0198 \n",
      "l0: 0.024312, l1: 0.026069, l2: 0.036256, l3: 0.058845, l4: 0.109614, l5: 0.243586, l6: 0.457607\n",
      "\n",
      "[epoch: 379/400, batch: 32/1000, ite: 50130] train loss: 1.1141, accuracy: 94.2920%, tar: 0.0198 \n",
      "l0: 0.016969, l1: 0.017869, l2: 0.024903, l3: 0.039282, l4: 0.069936, l5: 0.135208, l6: 0.294136\n",
      "\n",
      "[epoch: 379/400, batch: 40/1000, ite: 50131] train loss: 1.1125, accuracy: 95.6512%, tar: 0.0198 \n",
      "l0: 0.018439, l1: 0.019541, l2: 0.027735, l3: 0.040946, l4: 0.072273, l5: 0.133956, l6: 0.296538\n",
      "\n",
      "[epoch: 379/400, batch: 48/1000, ite: 50132] train loss: 1.1109, accuracy: 96.0755%, tar: 0.0198 \n",
      "l0: 0.019786, l1: 0.021363, l2: 0.029746, l3: 0.044165, l4: 0.083749, l5: 0.172239, l6: 0.441237\n",
      "\n",
      "[epoch: 379/400, batch: 56/1000, ite: 50133] train loss: 1.1120, accuracy: 94.5350%, tar: 0.0198 \n",
      "l0: 0.020437, l1: 0.022507, l2: 0.031505, l3: 0.051428, l4: 0.096350, l5: 0.179770, l6: 0.379505\n",
      "\n",
      "[epoch: 379/400, batch: 64/1000, ite: 50134] train loss: 1.1124, accuracy: 95.0567%, tar: 0.0198 \n",
      "l0: 0.021151, l1: 0.023118, l2: 0.031494, l3: 0.054383, l4: 0.105959, l5: 0.223108, l6: 0.452443\n",
      "\n",
      "[epoch: 379/400, batch: 72/1000, ite: 50135] train loss: 1.1143, accuracy: 94.0466%, tar: 0.0198 \n",
      "l0: 0.016399, l1: 0.017617, l2: 0.023848, l3: 0.038177, l4: 0.078868, l5: 0.193732, l6: 0.386448\n",
      "\n",
      "[epoch: 379/400, batch: 80/1000, ite: 50136] train loss: 1.1145, accuracy: 95.0996%, tar: 0.0198 \n",
      "l0: 0.016283, l1: 0.017626, l2: 0.026483, l3: 0.045467, l4: 0.089125, l5: 0.181405, l6: 0.395828\n",
      "\n",
      "[epoch: 379/400, batch: 88/1000, ite: 50137] train loss: 1.1149, accuracy: 95.1011%, tar: 0.0198 \n",
      "l0: 0.013426, l1: 0.015172, l2: 0.022592, l3: 0.038620, l4: 0.071920, l5: 0.118197, l6: 0.214119\n",
      "\n",
      "[epoch: 379/400, batch: 96/1000, ite: 50138] train loss: 1.1119, accuracy: 96.7250%, tar: 0.0197 \n",
      "l0: 0.017555, l1: 0.018283, l2: 0.023917, l3: 0.034767, l4: 0.058652, l5: 0.113404, l6: 0.287562\n",
      "\n",
      "[epoch: 379/400, batch: 104/1000, ite: 50139] train loss: 1.1100, accuracy: 95.6327%, tar: 0.0197 \n",
      "l0: 0.015258, l1: 0.016230, l2: 0.023977, l3: 0.036130, l4: 0.064309, l5: 0.114608, l6: 0.254689\n",
      "\n",
      "[epoch: 379/400, batch: 112/1000, ite: 50140] train loss: 1.1077, accuracy: 95.9675%, tar: 0.0197 \n",
      "l0: 0.023349, l1: 0.025180, l2: 0.035728, l3: 0.056911, l4: 0.090951, l5: 0.186110, l6: 0.352685\n",
      "\n",
      "[epoch: 379/400, batch: 120/1000, ite: 50141] train loss: 1.1078, accuracy: 94.7760%, tar: 0.0197 \n",
      "l0: 0.022398, l1: 0.023635, l2: 0.031764, l3: 0.048649, l4: 0.088598, l5: 0.196524, l6: 0.434753\n",
      "\n",
      "[epoch: 379/400, batch: 128/1000, ite: 50142] train loss: 1.1091, accuracy: 93.6264%, tar: 0.0197 \n",
      "l0: 0.026238, l1: 0.027599, l2: 0.035531, l3: 0.054897, l4: 0.100199, l5: 0.206910, l6: 0.465180\n",
      "\n",
      "[epoch: 379/400, batch: 136/1000, ite: 50143] train loss: 1.1109, accuracy: 92.9865%, tar: 0.0198 \n",
      "l0: 0.015244, l1: 0.016294, l2: 0.025104, l3: 0.039215, l4: 0.069399, l5: 0.150093, l6: 0.328363\n",
      "\n",
      "[epoch: 379/400, batch: 144/1000, ite: 50144] train loss: 1.1100, accuracy: 95.3853%, tar: 0.0197 \n",
      "l0: 0.030509, l1: 0.032565, l2: 0.042895, l3: 0.061478, l4: 0.109880, l5: 0.260095, l6: 0.536191\n",
      "\n",
      "[epoch: 379/400, batch: 152/1000, ite: 50145] train loss: 1.1135, accuracy: 92.4363%, tar: 0.0198 \n",
      "l0: 0.019981, l1: 0.021339, l2: 0.029807, l3: 0.043145, l4: 0.075022, l5: 0.169835, l6: 0.351415\n",
      "\n",
      "[epoch: 379/400, batch: 160/1000, ite: 50146] train loss: 1.1132, accuracy: 95.3000%, tar: 0.0198 \n",
      "l0: 0.022513, l1: 0.024077, l2: 0.032108, l3: 0.049125, l4: 0.089180, l5: 0.179581, l6: 0.323101\n",
      "\n",
      "[epoch: 379/400, batch: 168/1000, ite: 50147] train loss: 1.1127, accuracy: 95.2425%, tar: 0.0198 \n",
      "l0: 0.020791, l1: 0.022131, l2: 0.030287, l3: 0.048018, l4: 0.087814, l5: 0.182581, l6: 0.432091\n",
      "\n",
      "[epoch: 379/400, batch: 176/1000, ite: 50148] train loss: 1.1136, accuracy: 94.6794%, tar: 0.0198 \n",
      "l0: 0.020706, l1: 0.021950, l2: 0.028916, l3: 0.046179, l4: 0.084783, l5: 0.154255, l6: 0.348435\n",
      "\n",
      "[epoch: 379/400, batch: 184/1000, ite: 50149] train loss: 1.1132, accuracy: 94.9484%, tar: 0.0198 \n",
      "l0: 0.021003, l1: 0.022545, l2: 0.030771, l3: 0.044993, l4: 0.082771, l5: 0.180696, l6: 0.356979\n",
      "\n",
      "[epoch: 379/400, batch: 192/1000, ite: 50150] train loss: 1.1132, accuracy: 95.6425%, tar: 0.0199 \n",
      "l0: 0.020979, l1: 0.022629, l2: 0.031271, l3: 0.044467, l4: 0.074279, l5: 0.172288, l6: 0.337332\n",
      "\n",
      "[epoch: 379/400, batch: 200/1000, ite: 50151] train loss: 1.1127, accuracy: 94.5493%, tar: 0.0199 \n",
      "l0: 0.024452, l1: 0.025939, l2: 0.033197, l3: 0.055261, l4: 0.116656, l5: 0.226810, l6: 0.467758\n",
      "\n",
      "[epoch: 379/400, batch: 208/1000, ite: 50152] train loss: 1.1148, accuracy: 93.9469%, tar: 0.0199 \n",
      "l0: 0.020697, l1: 0.022029, l2: 0.032225, l3: 0.050481, l4: 0.103992, l5: 0.211213, l6: 0.386935\n",
      "\n",
      "[epoch: 379/400, batch: 216/1000, ite: 50153] train loss: 1.1154, accuracy: 94.6452%, tar: 0.0199 \n",
      "l0: 0.015880, l1: 0.016704, l2: 0.022902, l3: 0.035793, l4: 0.076006, l5: 0.160942, l6: 0.412218\n",
      "\n",
      "[epoch: 379/400, batch: 224/1000, ite: 50154] train loss: 1.1157, accuracy: 94.9459%, tar: 0.0199 \n",
      "l0: 0.019768, l1: 0.020810, l2: 0.028397, l3: 0.042524, l4: 0.073098, l5: 0.144470, l6: 0.275462\n",
      "\n",
      "[epoch: 379/400, batch: 232/1000, ite: 50155] train loss: 1.1142, accuracy: 95.9755%, tar: 0.0199 \n",
      "l0: 0.020911, l1: 0.022059, l2: 0.027926, l3: 0.041857, l4: 0.078595, l5: 0.170802, l6: 0.415201\n",
      "\n",
      "[epoch: 379/400, batch: 240/1000, ite: 50156] train loss: 1.1147, accuracy: 94.4087%, tar: 0.0199 \n",
      "l0: 0.022001, l1: 0.023289, l2: 0.033329, l3: 0.050815, l4: 0.102636, l5: 0.195705, l6: 0.375848\n",
      "\n",
      "[epoch: 379/400, batch: 248/1000, ite: 50157] train loss: 1.1151, accuracy: 94.7660%, tar: 0.0199 \n",
      "l0: 0.019742, l1: 0.020909, l2: 0.028026, l3: 0.042714, l4: 0.083705, l5: 0.155493, l6: 0.305441\n",
      "\n",
      "[epoch: 379/400, batch: 256/1000, ite: 50158] train loss: 1.1142, accuracy: 95.7355%, tar: 0.0199 \n",
      "l0: 0.017969, l1: 0.019584, l2: 0.027774, l3: 0.045053, l4: 0.088305, l5: 0.184220, l6: 0.386474\n",
      "\n",
      "[epoch: 379/400, batch: 264/1000, ite: 50159] train loss: 1.1144, accuracy: 95.7816%, tar: 0.0199 \n",
      "l0: 0.021235, l1: 0.022417, l2: 0.030717, l3: 0.046517, l4: 0.096365, l5: 0.186633, l6: 0.356069\n",
      "\n",
      "[epoch: 379/400, batch: 272/1000, ite: 50160] train loss: 1.1144, accuracy: 95.1442%, tar: 0.0199 \n",
      "l0: 0.022350, l1: 0.024658, l2: 0.035365, l3: 0.053016, l4: 0.094557, l5: 0.191156, l6: 0.393660\n",
      "\n",
      "[epoch: 379/400, batch: 280/1000, ite: 50161] train loss: 1.1150, accuracy: 95.1334%, tar: 0.0199 \n",
      "l0: 0.020204, l1: 0.022116, l2: 0.030041, l3: 0.049855, l4: 0.103425, l5: 0.211922, l6: 0.414362\n",
      "\n",
      "[epoch: 379/400, batch: 288/1000, ite: 50162] train loss: 1.1160, accuracy: 94.7492%, tar: 0.0199 \n",
      "l0: 0.033985, l1: 0.037620, l2: 0.054209, l3: 0.083017, l4: 0.186922, l5: 0.364176, l6: 0.675051\n",
      "\n",
      "[epoch: 379/400, batch: 296/1000, ite: 50163] train loss: 1.1221, accuracy: 91.3168%, tar: 0.0200 \n",
      "l0: 0.017066, l1: 0.018241, l2: 0.024477, l3: 0.036509, l4: 0.071771, l5: 0.141025, l6: 0.354634\n",
      "\n",
      "[epoch: 379/400, batch: 304/1000, ite: 50164] train loss: 1.1215, accuracy: 94.8771%, tar: 0.0200 \n",
      "l0: 0.016563, l1: 0.018204, l2: 0.026202, l3: 0.044660, l4: 0.110445, l5: 0.231288, l6: 0.439990\n",
      "\n",
      "[epoch: 379/400, batch: 312/1000, ite: 50165] train loss: 1.1228, accuracy: 94.7336%, tar: 0.0199 \n",
      "l0: 0.013642, l1: 0.014711, l2: 0.020198, l3: 0.030991, l4: 0.065749, l5: 0.135616, l6: 0.323880\n",
      "\n",
      "[epoch: 379/400, batch: 320/1000, ite: 50166] train loss: 1.1216, accuracy: 96.0830%, tar: 0.0199 \n",
      "l0: 0.015078, l1: 0.016496, l2: 0.023264, l3: 0.035987, l4: 0.073868, l5: 0.156460, l6: 0.334441\n",
      "\n",
      "[epoch: 379/400, batch: 328/1000, ite: 50167] train loss: 1.1209, accuracy: 95.7618%, tar: 0.0199 \n",
      "l0: 0.026031, l1: 0.028356, l2: 0.037749, l3: 0.054418, l4: 0.097170, l5: 0.192124, l6: 0.455108\n",
      "\n",
      "[epoch: 379/400, batch: 336/1000, ite: 50168] train loss: 1.1222, accuracy: 93.8104%, tar: 0.0199 \n",
      "l0: 0.020927, l1: 0.022553, l2: 0.031991, l3: 0.051598, l4: 0.100293, l5: 0.219795, l6: 0.493493\n",
      "\n",
      "[epoch: 379/400, batch: 344/1000, ite: 50169] train loss: 1.1240, accuracy: 93.0744%, tar: 0.0199 \n",
      "l0: 0.022844, l1: 0.024590, l2: 0.033583, l3: 0.058218, l4: 0.125184, l5: 0.287533, l6: 0.460010\n",
      "\n",
      "[epoch: 379/400, batch: 352/1000, ite: 50170] train loss: 1.1261, accuracy: 93.4543%, tar: 0.0199 \n",
      "l0: 0.024050, l1: 0.025403, l2: 0.035115, l3: 0.054568, l4: 0.100988, l5: 0.186532, l6: 0.415122\n",
      "\n",
      "[epoch: 379/400, batch: 360/1000, ite: 50171] train loss: 1.1269, accuracy: 93.9942%, tar: 0.0200 \n",
      "l0: 0.013383, l1: 0.013926, l2: 0.018116, l3: 0.025770, l4: 0.044331, l5: 0.083414, l6: 0.181772\n",
      "\n",
      "[epoch: 379/400, batch: 368/1000, ite: 50172] train loss: 1.1236, accuracy: 96.9959%, tar: 0.0199 \n",
      "l0: 0.018813, l1: 0.019431, l2: 0.026505, l3: 0.041722, l4: 0.072921, l5: 0.146696, l6: 0.345075\n",
      "\n",
      "[epoch: 379/400, batch: 376/1000, ite: 50173] train loss: 1.1230, accuracy: 95.2060%, tar: 0.0199 \n",
      "l0: 0.018756, l1: 0.019981, l2: 0.025309, l3: 0.037337, l4: 0.065097, l5: 0.130241, l6: 0.287805\n",
      "\n",
      "[epoch: 379/400, batch: 384/1000, ite: 50174] train loss: 1.1216, accuracy: 95.2539%, tar: 0.0199 \n",
      "l0: 0.023259, l1: 0.025050, l2: 0.033428, l3: 0.049685, l4: 0.109553, l5: 0.216813, l6: 0.412253\n",
      "\n",
      "[epoch: 379/400, batch: 392/1000, ite: 50175] train loss: 1.1225, accuracy: 94.6358%, tar: 0.0199 \n",
      "l0: 0.020476, l1: 0.021496, l2: 0.029083, l3: 0.043848, l4: 0.071669, l5: 0.141035, l6: 0.271901\n",
      "\n",
      "[epoch: 379/400, batch: 400/1000, ite: 50176] train loss: 1.1211, accuracy: 96.3085%, tar: 0.0199 \n",
      "l0: 0.020427, l1: 0.022045, l2: 0.029439, l3: 0.044399, l4: 0.070738, l5: 0.144366, l6: 0.295792\n",
      "\n",
      "[epoch: 379/400, batch: 408/1000, ite: 50177] train loss: 1.1201, accuracy: 95.2275%, tar: 0.0199 \n",
      "l0: 0.015721, l1: 0.017187, l2: 0.024324, l3: 0.039392, l4: 0.077308, l5: 0.144831, l6: 0.364594\n",
      "\n",
      "[epoch: 379/400, batch: 416/1000, ite: 50178] train loss: 1.1197, accuracy: 95.6286%, tar: 0.0199 \n",
      "l0: 0.022225, l1: 0.023178, l2: 0.030796, l3: 0.048422, l4: 0.085809, l5: 0.162304, l6: 0.318205\n",
      "\n",
      "[epoch: 379/400, batch: 424/1000, ite: 50179] train loss: 1.1191, accuracy: 95.4813%, tar: 0.0199 \n",
      "l0: 0.019044, l1: 0.020461, l2: 0.028727, l3: 0.043790, l4: 0.075620, l5: 0.138745, l6: 0.280005\n",
      "\n",
      "[epoch: 379/400, batch: 432/1000, ite: 50180] train loss: 1.1178, accuracy: 95.9434%, tar: 0.0199 \n",
      "l0: 0.025502, l1: 0.026593, l2: 0.034736, l3: 0.050387, l4: 0.082478, l5: 0.159500, l6: 0.369988\n",
      "\n",
      "[epoch: 379/400, batch: 440/1000, ite: 50181] train loss: 1.1178, accuracy: 94.0610%, tar: 0.0200 \n",
      "l0: 0.018006, l1: 0.019165, l2: 0.025197, l3: 0.034219, l4: 0.054544, l5: 0.085391, l6: 0.221101\n",
      "\n",
      "[epoch: 379/400, batch: 448/1000, ite: 50182] train loss: 1.1154, accuracy: 96.7230%, tar: 0.0199 \n",
      "l0: 0.021523, l1: 0.022936, l2: 0.030963, l3: 0.044469, l4: 0.082610, l5: 0.165599, l6: 0.354392\n",
      "\n",
      "[epoch: 379/400, batch: 456/1000, ite: 50183] train loss: 1.1152, accuracy: 94.5872%, tar: 0.0200 \n",
      "l0: 0.018855, l1: 0.020054, l2: 0.027552, l3: 0.041626, l4: 0.073154, l5: 0.156692, l6: 0.306924\n",
      "\n",
      "[epoch: 379/400, batch: 464/1000, ite: 50184] train loss: 1.1144, accuracy: 95.3935%, tar: 0.0199 \n",
      "l0: 0.020180, l1: 0.020829, l2: 0.028348, l3: 0.041542, l4: 0.081918, l5: 0.214629, l6: 0.457147\n",
      "\n",
      "[epoch: 379/400, batch: 472/1000, ite: 50185] train loss: 1.1155, accuracy: 93.9934%, tar: 0.0199 \n",
      "l0: 0.022587, l1: 0.023889, l2: 0.031758, l3: 0.048314, l4: 0.086584, l5: 0.179305, l6: 0.386984\n",
      "\n",
      "[epoch: 379/400, batch: 480/1000, ite: 50186] train loss: 1.1158, accuracy: 94.8087%, tar: 0.0200 \n",
      "l0: 0.022353, l1: 0.023266, l2: 0.030435, l3: 0.044238, l4: 0.072068, l5: 0.137046, l6: 0.267617\n",
      "\n",
      "[epoch: 379/400, batch: 488/1000, ite: 50187] train loss: 1.1145, accuracy: 95.7568%, tar: 0.0200 \n",
      "l0: 0.018792, l1: 0.020081, l2: 0.028356, l3: 0.043434, l4: 0.081979, l5: 0.187295, l6: 0.374263\n",
      "\n",
      "[epoch: 379/400, batch: 496/1000, ite: 50188] train loss: 1.1146, accuracy: 95.3447%, tar: 0.0200 \n",
      "l0: 0.016311, l1: 0.017759, l2: 0.028388, l3: 0.048540, l4: 0.084064, l5: 0.180995, l6: 0.360256\n",
      "\n",
      "[epoch: 379/400, batch: 504/1000, ite: 50189] train loss: 1.1145, accuracy: 95.8427%, tar: 0.0199 \n",
      "l0: 0.018343, l1: 0.019345, l2: 0.026920, l3: 0.041368, l4: 0.077321, l5: 0.145802, l6: 0.279441\n",
      "\n",
      "[epoch: 379/400, batch: 512/1000, ite: 50190] train loss: 1.1133, accuracy: 95.7048%, tar: 0.0199 \n",
      "l0: 0.022329, l1: 0.023840, l2: 0.032489, l3: 0.047105, l4: 0.082175, l5: 0.159271, l6: 0.357414\n",
      "\n",
      "[epoch: 379/400, batch: 520/1000, ite: 50191] train loss: 1.1132, accuracy: 94.6741%, tar: 0.0200 \n",
      "l0: 0.016090, l1: 0.017516, l2: 0.027880, l3: 0.046650, l4: 0.084865, l5: 0.152188, l6: 0.341698\n",
      "\n",
      "[epoch: 379/400, batch: 528/1000, ite: 50192] train loss: 1.1127, accuracy: 95.7088%, tar: 0.0199 \n",
      "l0: 0.018518, l1: 0.019442, l2: 0.025020, l3: 0.034042, l4: 0.052637, l5: 0.102625, l6: 0.220577\n",
      "\n",
      "[epoch: 379/400, batch: 536/1000, ite: 50193] train loss: 1.1106, accuracy: 96.0834%, tar: 0.0199 \n",
      "l0: 0.018983, l1: 0.019460, l2: 0.026486, l3: 0.037467, l4: 0.067823, l5: 0.137075, l6: 0.333167\n",
      "\n",
      "[epoch: 379/400, batch: 544/1000, ite: 50194] train loss: 1.1099, accuracy: 95.2662%, tar: 0.0199 \n",
      "l0: 0.021612, l1: 0.023616, l2: 0.032277, l3: 0.053257, l4: 0.104812, l5: 0.217733, l6: 0.421498\n",
      "\n",
      "[epoch: 379/400, batch: 552/1000, ite: 50195] train loss: 1.1108, accuracy: 94.3056%, tar: 0.0199 \n",
      "l0: 0.016595, l1: 0.017479, l2: 0.023286, l3: 0.033175, l4: 0.055011, l5: 0.113074, l6: 0.237633\n",
      "\n",
      "[epoch: 379/400, batch: 560/1000, ite: 50196] train loss: 1.1089, accuracy: 96.4153%, tar: 0.0199 \n",
      "l0: 0.020146, l1: 0.021871, l2: 0.029023, l3: 0.046924, l4: 0.079942, l5: 0.176469, l6: 0.415168\n",
      "\n",
      "[epoch: 379/400, batch: 568/1000, ite: 50197] train loss: 1.1095, accuracy: 95.4422%, tar: 0.0199 \n",
      "l0: 0.016787, l1: 0.017966, l2: 0.024919, l3: 0.042092, l4: 0.078004, l5: 0.149711, l6: 0.313485\n",
      "\n",
      "[epoch: 379/400, batch: 576/1000, ite: 50198] train loss: 1.1087, accuracy: 95.5137%, tar: 0.0199 \n",
      "l0: 0.019319, l1: 0.021394, l2: 0.032919, l3: 0.053690, l4: 0.102855, l5: 0.225207, l6: 0.464914\n",
      "\n",
      "[epoch: 379/400, batch: 584/1000, ite: 50199] train loss: 1.1101, accuracy: 94.6431%, tar: 0.0199 \n",
      "l0: 0.030081, l1: 0.031725, l2: 0.039602, l3: 0.054357, l4: 0.092850, l5: 0.212097, l6: 0.437833\n",
      "\n",
      "[epoch: 379/400, batch: 592/1000, ite: 50200] train loss: 1.1112, accuracy: 93.7933%, tar: 0.0199 \n",
      "l0: 0.016918, l1: 0.018099, l2: 0.025267, l3: 0.038744, l4: 0.074510, l5: 0.167113, l6: 0.381282\n",
      "\n",
      "[epoch: 379/400, batch: 600/1000, ite: 50201] train loss: 1.1112, accuracy: 95.2490%, tar: 0.0199 \n",
      "l0: 0.016668, l1: 0.017071, l2: 0.024413, l3: 0.038519, l4: 0.064303, l5: 0.152887, l6: 0.301460\n",
      "\n",
      "[epoch: 379/400, batch: 608/1000, ite: 50202] train loss: 1.1103, accuracy: 95.6389%, tar: 0.0199 \n",
      "l0: 0.018599, l1: 0.019228, l2: 0.024780, l3: 0.035652, l4: 0.062974, l5: 0.135457, l6: 0.352305\n",
      "\n",
      "[epoch: 379/400, batch: 616/1000, ite: 50203] train loss: 1.1097, accuracy: 95.1121%, tar: 0.0199 \n",
      "l0: 0.017154, l1: 0.017914, l2: 0.023226, l3: 0.035079, l4: 0.076687, l5: 0.171833, l6: 0.343848\n",
      "\n",
      "[epoch: 379/400, batch: 624/1000, ite: 50204] train loss: 1.1094, accuracy: 95.6860%, tar: 0.0199 \n",
      "l0: 0.020652, l1: 0.022691, l2: 0.033818, l3: 0.050832, l4: 0.084298, l5: 0.169628, l6: 0.329419\n",
      "\n",
      "[epoch: 379/400, batch: 632/1000, ite: 50205] train loss: 1.1090, accuracy: 95.7947%, tar: 0.0199 \n",
      "l0: 0.023837, l1: 0.025920, l2: 0.037666, l3: 0.059173, l4: 0.131017, l5: 0.256870, l6: 0.460310\n",
      "\n",
      "[epoch: 379/400, batch: 640/1000, ite: 50206] train loss: 1.1107, accuracy: 94.7059%, tar: 0.0199 \n",
      "l0: 0.013031, l1: 0.013848, l2: 0.018503, l3: 0.027773, l4: 0.060218, l5: 0.118707, l6: 0.315004\n",
      "\n",
      "[epoch: 379/400, batch: 648/1000, ite: 50207] train loss: 1.1096, accuracy: 95.4300%, tar: 0.0199 \n",
      "l0: 0.019095, l1: 0.020358, l2: 0.027038, l3: 0.039122, l4: 0.076576, l5: 0.162761, l6: 0.325652\n",
      "\n",
      "[epoch: 379/400, batch: 656/1000, ite: 50208] train loss: 1.1090, accuracy: 95.5775%, tar: 0.0199 \n",
      "l0: 0.022264, l1: 0.023563, l2: 0.031130, l3: 0.050968, l4: 0.090995, l5: 0.190228, l6: 0.423609\n",
      "\n",
      "[epoch: 379/400, batch: 664/1000, ite: 50209] train loss: 1.1098, accuracy: 94.7083%, tar: 0.0199 \n",
      "l0: 0.018216, l1: 0.019982, l2: 0.028348, l3: 0.046350, l4: 0.102936, l5: 0.215369, l6: 0.478907\n",
      "\n",
      "[epoch: 379/400, batch: 672/1000, ite: 50210] train loss: 1.1113, accuracy: 95.1151%, tar: 0.0199 \n",
      "l0: 0.016470, l1: 0.016980, l2: 0.022181, l3: 0.032183, l4: 0.055774, l5: 0.100530, l6: 0.212871\n",
      "\n",
      "[epoch: 379/400, batch: 680/1000, ite: 50211] train loss: 1.1092, accuracy: 96.5914%, tar: 0.0199 \n",
      "l0: 0.014201, l1: 0.015737, l2: 0.022957, l3: 0.035514, l4: 0.064626, l5: 0.143430, l6: 0.234662\n",
      "\n",
      "[epoch: 379/400, batch: 688/1000, ite: 50212] train loss: 1.1076, accuracy: 96.4817%, tar: 0.0198 \n",
      "l0: 0.019624, l1: 0.020589, l2: 0.027642, l3: 0.040757, l4: 0.077990, l5: 0.158625, l6: 0.320762\n",
      "\n",
      "[epoch: 379/400, batch: 696/1000, ite: 50213] train loss: 1.1071, accuracy: 95.6775%, tar: 0.0198 \n",
      "l0: 0.019052, l1: 0.020188, l2: 0.028932, l3: 0.048062, l4: 0.079627, l5: 0.172879, l6: 0.331708\n",
      "\n",
      "[epoch: 379/400, batch: 704/1000, ite: 50214] train loss: 1.1068, accuracy: 95.2748%, tar: 0.0198 \n",
      "l0: 0.015146, l1: 0.016704, l2: 0.025357, l3: 0.040095, l4: 0.074458, l5: 0.158732, l6: 0.324356\n",
      "\n",
      "[epoch: 379/400, batch: 712/1000, ite: 50215] train loss: 1.1062, accuracy: 96.1144%, tar: 0.0198 \n",
      "l0: 0.021093, l1: 0.022068, l2: 0.030370, l3: 0.045264, l4: 0.087769, l5: 0.156061, l6: 0.404927\n",
      "\n",
      "[epoch: 379/400, batch: 728/1000, ite: 50217] train loss: 1.1059, accuracy: 95.8084%, tar: 0.0198 \n",
      "l0: 0.014867, l1: 0.016097, l2: 0.023588, l3: 0.038241, l4: 0.110163, l5: 0.148895, l6: 0.276990\n",
      "\n",
      "[epoch: 379/400, batch: 736/1000, ite: 50218] train loss: 1.1050, accuracy: 96.4613%, tar: 0.0198 \n",
      "l0: 0.018116, l1: 0.019509, l2: 0.027708, l3: 0.045481, l4: 0.088712, l5: 0.187429, l6: 0.359928\n",
      "\n",
      "[epoch: 379/400, batch: 744/1000, ite: 50219] train loss: 1.1050, accuracy: 95.2717%, tar: 0.0198 \n",
      "l0: 0.021769, l1: 0.022785, l2: 0.031280, l3: 0.045743, l4: 0.093209, l5: 0.197383, l6: 0.421194\n",
      "\n",
      "[epoch: 379/400, batch: 752/1000, ite: 50220] train loss: 1.1057, accuracy: 93.5895%, tar: 0.0198 \n",
      "l0: 0.015184, l1: 0.016735, l2: 0.022631, l3: 0.036168, l4: 0.082101, l5: 0.137983, l6: 0.300165\n",
      "\n",
      "[epoch: 379/400, batch: 760/1000, ite: 50221] train loss: 1.1049, accuracy: 96.5166%, tar: 0.0198 \n",
      "l0: 0.017351, l1: 0.019144, l2: 0.027597, l3: 0.044594, l4: 0.084651, l5: 0.158979, l6: 0.298121\n",
      "\n",
      "[epoch: 379/400, batch: 768/1000, ite: 50222] train loss: 1.1042, accuracy: 96.0730%, tar: 0.0198 \n",
      "l0: 0.020006, l1: 0.021416, l2: 0.029106, l3: 0.042164, l4: 0.087326, l5: 0.169148, l6: 0.400253\n",
      "\n",
      "[epoch: 379/400, batch: 776/1000, ite: 50223] train loss: 1.1045, accuracy: 94.9636%, tar: 0.0198 \n",
      "l0: 0.014575, l1: 0.015167, l2: 0.020576, l3: 0.030788, l4: 0.059777, l5: 0.128688, l6: 0.318470\n",
      "\n",
      "[epoch: 379/400, batch: 784/1000, ite: 50224] train loss: 1.1037, accuracy: 95.9647%, tar: 0.0197 \n",
      "l0: 0.025481, l1: 0.027191, l2: 0.036438, l3: 0.056459, l4: 0.114300, l5: 0.228129, l6: 0.499350\n",
      "\n",
      "[epoch: 379/400, batch: 792/1000, ite: 50225] train loss: 1.1054, accuracy: 93.5809%, tar: 0.0198 \n",
      "l0: 0.017897, l1: 0.019126, l2: 0.027120, l3: 0.041598, l4: 0.073656, l5: 0.151457, l6: 0.302545\n",
      "\n",
      "[epoch: 379/400, batch: 800/1000, ite: 50226] train loss: 1.1047, accuracy: 95.6308%, tar: 0.0198 \n",
      "l0: 0.027880, l1: 0.029168, l2: 0.037066, l3: 0.053575, l4: 0.103524, l5: 0.213797, l6: 0.407109\n",
      "\n",
      "[epoch: 379/400, batch: 808/1000, ite: 50227] train loss: 1.1055, accuracy: 94.0235%, tar: 0.0198 \n",
      "l0: 0.020493, l1: 0.021506, l2: 0.030063, l3: 0.044816, l4: 0.081728, l5: 0.181068, l6: 0.392882\n",
      "\n",
      "[epoch: 379/400, batch: 816/1000, ite: 50228] train loss: 1.1058, accuracy: 94.1099%, tar: 0.0198 \n",
      "l0: 0.019676, l1: 0.020882, l2: 0.026238, l3: 0.036699, l4: 0.067647, l5: 0.138864, l6: 0.363689\n",
      "\n",
      "[epoch: 379/400, batch: 824/1000, ite: 50229] train loss: 1.1055, accuracy: 95.5297%, tar: 0.0198 \n",
      "l0: 0.025201, l1: 0.026865, l2: 0.034925, l3: 0.053881, l4: 0.114612, l5: 0.266637, l6: 0.521980\n",
      "\n",
      "[epoch: 379/400, batch: 832/1000, ite: 50230] train loss: 1.1075, accuracy: 93.1960%, tar: 0.0198 \n",
      "l0: 0.023798, l1: 0.025190, l2: 0.032033, l3: 0.050157, l4: 0.100332, l5: 0.204582, l6: 0.461091\n",
      "\n",
      "[epoch: 379/400, batch: 840/1000, ite: 50231] train loss: 1.1086, accuracy: 93.9543%, tar: 0.0198 \n",
      "l0: 0.020025, l1: 0.021544, l2: 0.029628, l3: 0.048313, l4: 0.087063, l5: 0.174040, l6: 0.400308\n",
      "\n",
      "[epoch: 379/400, batch: 848/1000, ite: 50232] train loss: 1.1089, accuracy: 94.9200%, tar: 0.0198 \n",
      "l0: 0.024664, l1: 0.025943, l2: 0.035996, l3: 0.052211, l4: 0.087984, l5: 0.184644, l6: 0.386192\n",
      "\n",
      "[epoch: 379/400, batch: 856/1000, ite: 50233] train loss: 1.1093, accuracy: 94.9175%, tar: 0.0199 \n",
      "l0: 0.018148, l1: 0.020905, l2: 0.031641, l3: 0.055958, l4: 0.105311, l5: 0.213703, l6: 0.359556\n",
      "\n",
      "[epoch: 379/400, batch: 864/1000, ite: 50234] train loss: 1.1095, accuracy: 96.2367%, tar: 0.0199 \n",
      "l0: 0.020087, l1: 0.021080, l2: 0.028419, l3: 0.042884, l4: 0.080955, l5: 0.153867, l6: 0.307840\n",
      "\n",
      "[epoch: 379/400, batch: 872/1000, ite: 50235] train loss: 1.1089, accuracy: 95.4686%, tar: 0.0199 \n",
      "l0: 0.018100, l1: 0.019330, l2: 0.026188, l3: 0.041682, l4: 0.081076, l5: 0.144028, l6: 0.330728\n",
      "\n",
      "[epoch: 379/400, batch: 880/1000, ite: 50236] train loss: 1.1085, accuracy: 95.9443%, tar: 0.0199 \n",
      "l0: 0.019780, l1: 0.020725, l2: 0.027307, l3: 0.045484, l4: 0.097217, l5: 0.185729, l6: 0.393895\n",
      "\n",
      "[epoch: 379/400, batch: 888/1000, ite: 50237] train loss: 1.1088, accuracy: 93.9721%, tar: 0.0199 \n",
      "l0: 0.015200, l1: 0.015832, l2: 0.021282, l3: 0.032106, l4: 0.056320, l5: 0.124137, l6: 0.317550\n",
      "\n",
      "[epoch: 379/400, batch: 896/1000, ite: 50238] train loss: 1.1079, accuracy: 95.6202%, tar: 0.0198 \n",
      "l0: 0.015798, l1: 0.017675, l2: 0.024067, l3: 0.036034, l4: 0.075819, l5: 0.160151, l6: 0.351662\n",
      "\n",
      "[epoch: 379/400, batch: 904/1000, ite: 50239] train loss: 1.1076, accuracy: 95.4134%, tar: 0.0198 \n",
      "l0: 0.021206, l1: 0.023119, l2: 0.030969, l3: 0.046009, l4: 0.081985, l5: 0.156255, l6: 0.335975\n",
      "\n",
      "[epoch: 379/400, batch: 912/1000, ite: 50240] train loss: 1.1073, accuracy: 96.0667%, tar: 0.0198 \n",
      "l0: 0.023815, l1: 0.026117, l2: 0.038284, l3: 0.067984, l4: 0.137336, l5: 0.259751, l6: 0.543461\n",
      "\n",
      "[epoch: 379/400, batch: 920/1000, ite: 50241] train loss: 1.1095, accuracy: 93.6457%, tar: 0.0198 \n",
      "l0: 0.018196, l1: 0.020029, l2: 0.030898, l3: 0.049829, l4: 0.083210, l5: 0.146329, l6: 0.285880\n",
      "\n",
      "[epoch: 379/400, batch: 928/1000, ite: 50242] train loss: 1.1087, accuracy: 96.2638%, tar: 0.0198 \n",
      "l0: 0.020645, l1: 0.021661, l2: 0.031074, l3: 0.046040, l4: 0.090377, l5: 0.194127, l6: 0.364106\n",
      "\n",
      "[epoch: 379/400, batch: 936/1000, ite: 50243] train loss: 1.1088, accuracy: 95.2141%, tar: 0.0198 \n",
      "l0: 0.021444, l1: 0.022489, l2: 0.030431, l3: 0.047246, l4: 0.086247, l5: 0.193317, l6: 0.434947\n",
      "\n",
      "[epoch: 379/400, batch: 944/1000, ite: 50244] train loss: 1.1095, accuracy: 94.4331%, tar: 0.0198 \n",
      "l0: 0.019360, l1: 0.020526, l2: 0.027387, l3: 0.041124, l4: 0.080971, l5: 0.193487, l6: 0.329951\n",
      "\n",
      "[epoch: 379/400, batch: 952/1000, ite: 50245] train loss: 1.1093, accuracy: 94.7503%, tar: 0.0198 \n",
      "l0: 0.016988, l1: 0.018514, l2: 0.026757, l3: 0.042361, l4: 0.077073, l5: 0.163477, l6: 0.322795\n",
      "\n",
      "[epoch: 379/400, batch: 960/1000, ite: 50246] train loss: 1.1088, accuracy: 95.9543%, tar: 0.0198 \n",
      "l0: 0.020631, l1: 0.021859, l2: 0.031146, l3: 0.048661, l4: 0.097013, l5: 0.228009, l6: 0.458242\n",
      "\n",
      "[epoch: 379/400, batch: 968/1000, ite: 50247] train loss: 1.1099, accuracy: 94.5434%, tar: 0.0198 \n",
      "l0: 0.015694, l1: 0.018749, l2: 0.029667, l3: 0.052254, l4: 0.117642, l5: 0.237878, l6: 0.447186\n",
      "\n",
      "[epoch: 379/400, batch: 976/1000, ite: 50248] train loss: 1.1110, accuracy: 95.7063%, tar: 0.0198 \n",
      "l0: 0.021655, l1: 0.023211, l2: 0.030196, l3: 0.043208, l4: 0.075757, l5: 0.145846, l6: 0.296062\n",
      "\n",
      "[epoch: 379/400, batch: 984/1000, ite: 50249] train loss: 1.1103, accuracy: 95.2370%, tar: 0.0198 \n",
      "l0: 0.020330, l1: 0.021504, l2: 0.029872, l3: 0.047998, l4: 0.092797, l5: 0.194770, l6: 0.394410\n",
      "\n",
      "[epoch: 379/400, batch: 992/1000, ite: 50250] train loss: 1.1106, accuracy: 94.4747%, tar: 0.0198 \n",
      "l0: 0.021618, l1: 0.023436, l2: 0.032333, l3: 0.048847, l4: 0.092755, l5: 0.208210, l6: 0.433020\n",
      "\n",
      "[epoch: 379/400, batch: 1000/1000, ite: 50251] train loss: 1.1113, accuracy: 94.8265%, tar: 0.0198 \n",
      "l0: 0.014398, l1: 0.015251, l2: 0.020069, l3: 0.028815, l4: 0.058491, l5: 0.138719, l6: 0.253856\n",
      "\n",
      "[epoch: 380/400, batch: 8/1000, ite: 50252] train loss: 1.1100, accuracy: 96.3539%, tar: 0.0198 \n",
      "l0: 0.019169, l1: 0.020157, l2: 0.027518, l3: 0.040752, l4: 0.068457, l5: 0.156592, l6: 0.291941\n",
      "\n",
      "[epoch: 380/400, batch: 16/1000, ite: 50253] train loss: 1.1093, accuracy: 95.2056%, tar: 0.0198 \n",
      "l0: 0.028005, l1: 0.030122, l2: 0.040317, l3: 0.066018, l4: 0.133783, l5: 0.282663, l6: 0.571116\n",
      "\n",
      "[epoch: 380/400, batch: 24/1000, ite: 50254] train loss: 1.1117, accuracy: 92.4703%, tar: 0.0198 \n",
      "l0: 0.016778, l1: 0.018178, l2: 0.025742, l3: 0.040894, l4: 0.079851, l5: 0.150004, l6: 0.342419\n",
      "\n",
      "[epoch: 380/400, batch: 32/1000, ite: 50255] train loss: 1.1113, accuracy: 95.5728%, tar: 0.0198 \n",
      "l0: 0.022705, l1: 0.024285, l2: 0.033531, l3: 0.049018, l4: 0.096710, l5: 0.195350, l6: 0.348410\n",
      "\n",
      "[epoch: 380/400, batch: 40/1000, ite: 50256] train loss: 1.1114, accuracy: 94.8896%, tar: 0.0198 \n",
      "l0: 0.021337, l1: 0.023076, l2: 0.032418, l3: 0.053920, l4: 0.109512, l5: 0.207206, l6: 0.404851\n",
      "\n",
      "[epoch: 380/400, batch: 48/1000, ite: 50257] train loss: 1.1119, accuracy: 94.0703%, tar: 0.0198 \n",
      "l0: 0.015985, l1: 0.017118, l2: 0.023678, l3: 0.035249, l4: 0.064251, l5: 0.112655, l6: 0.299724\n",
      "\n",
      "[epoch: 380/400, batch: 56/1000, ite: 50258] train loss: 1.1110, accuracy: 96.2669%, tar: 0.0198 \n",
      "l0: 0.021494, l1: 0.022851, l2: 0.029011, l3: 0.043657, l4: 0.066356, l5: 0.119698, l6: 0.251570\n",
      "\n",
      "[epoch: 380/400, batch: 64/1000, ite: 50259] train loss: 1.1099, accuracy: 96.1991%, tar: 0.0198 \n",
      "l0: 0.025358, l1: 0.026023, l2: 0.033256, l3: 0.049198, l4: 0.085586, l5: 0.176162, l6: 0.419083\n",
      "\n",
      "[epoch: 380/400, batch: 72/1000, ite: 50260] train loss: 1.1103, accuracy: 93.5289%, tar: 0.0199 \n",
      "l0: 0.019321, l1: 0.020495, l2: 0.027175, l3: 0.042755, l4: 0.072408, l5: 0.147011, l6: 0.368297\n",
      "\n",
      "[epoch: 380/400, batch: 80/1000, ite: 50261] train loss: 1.1102, accuracy: 95.4890%, tar: 0.0199 \n",
      "l0: 0.019044, l1: 0.020873, l2: 0.028680, l3: 0.048824, l4: 0.094483, l5: 0.188457, l6: 0.404351\n",
      "\n",
      "[epoch: 380/400, batch: 88/1000, ite: 50262] train loss: 1.1106, accuracy: 94.3138%, tar: 0.0199 \n",
      "l0: 0.015801, l1: 0.016971, l2: 0.023419, l3: 0.037564, l4: 0.074679, l5: 0.180694, l6: 0.426743\n",
      "\n",
      "[epoch: 380/400, batch: 96/1000, ite: 50263] train loss: 1.1109, accuracy: 95.0808%, tar: 0.0198 \n",
      "l0: 0.020616, l1: 0.022175, l2: 0.029366, l3: 0.046575, l4: 0.092745, l5: 0.205706, l6: 0.438563\n",
      "\n",
      "[epoch: 380/400, batch: 104/1000, ite: 50264] train loss: 1.1117, accuracy: 94.5725%, tar: 0.0198 \n",
      "l0: 0.024309, l1: 0.026228, l2: 0.036406, l3: 0.057199, l4: 0.112135, l5: 0.248742, l6: 0.477900\n",
      "\n",
      "[epoch: 380/400, batch: 112/1000, ite: 50265] train loss: 1.1130, accuracy: 93.8426%, tar: 0.0199 \n",
      "l0: 0.022203, l1: 0.023464, l2: 0.030536, l3: 0.043424, l4: 0.079031, l5: 0.160998, l6: 0.343864\n",
      "\n",
      "[epoch: 380/400, batch: 120/1000, ite: 50266] train loss: 1.1127, accuracy: 95.0096%, tar: 0.0199 \n",
      "l0: 0.019413, l1: 0.021379, l2: 0.031795, l3: 0.048982, l4: 0.090983, l5: 0.177691, l6: 0.379407\n",
      "\n",
      "[epoch: 380/400, batch: 128/1000, ite: 50267] train loss: 1.1129, accuracy: 95.3228%, tar: 0.0199 \n",
      "l0: 0.021365, l1: 0.022687, l2: 0.031370, l3: 0.044924, l4: 0.080978, l5: 0.177281, l6: 0.406090\n",
      "\n",
      "[epoch: 380/400, batch: 136/1000, ite: 50268] train loss: 1.1132, accuracy: 94.9635%, tar: 0.0199 \n",
      "l0: 0.020050, l1: 0.021943, l2: 0.030475, l3: 0.050646, l4: 0.106623, l5: 0.233233, l6: 0.440175\n",
      "\n",
      "[epoch: 380/400, batch: 144/1000, ite: 50269] train loss: 1.1141, accuracy: 94.6053%, tar: 0.0199 \n",
      "l0: 0.018099, l1: 0.019713, l2: 0.027561, l3: 0.040385, l4: 0.074535, l5: 0.152850, l6: 0.301549\n",
      "\n",
      "[epoch: 380/400, batch: 152/1000, ite: 50270] train loss: 1.1134, accuracy: 95.6707%, tar: 0.0199 \n",
      "l0: 0.019157, l1: 0.021010, l2: 0.031158, l3: 0.050063, l4: 0.095569, l5: 0.219117, l6: 0.403603\n",
      "\n",
      "[epoch: 380/400, batch: 160/1000, ite: 50271] train loss: 1.1139, accuracy: 95.2089%, tar: 0.0199 \n",
      "l0: 0.023001, l1: 0.024004, l2: 0.033155, l3: 0.049765, l4: 0.090476, l5: 0.175897, l6: 0.358194\n",
      "\n",
      "[epoch: 380/400, batch: 168/1000, ite: 50272] train loss: 1.1139, accuracy: 94.8763%, tar: 0.0199 \n",
      "l0: 0.030685, l1: 0.032604, l2: 0.042705, l3: 0.061749, l4: 0.108865, l5: 0.249123, l6: 0.488702\n",
      "\n",
      "[epoch: 380/400, batch: 176/1000, ite: 50273] train loss: 1.1154, accuracy: 92.7522%, tar: 0.0199 \n",
      "l0: 0.014502, l1: 0.014901, l2: 0.021409, l3: 0.034765, l4: 0.065219, l5: 0.128187, l6: 0.249176\n",
      "\n",
      "[epoch: 380/400, batch: 184/1000, ite: 50274] train loss: 1.1141, accuracy: 95.9337%, tar: 0.0199 \n",
      "l0: 0.019669, l1: 0.020829, l2: 0.028272, l3: 0.043558, l4: 0.075669, l5: 0.163464, l6: 0.347245\n",
      "\n",
      "[epoch: 380/400, batch: 192/1000, ite: 50275] train loss: 1.1139, accuracy: 95.5454%, tar: 0.0199 \n",
      "l0: 0.016266, l1: 0.017988, l2: 0.025313, l3: 0.038917, l4: 0.081268, l5: 0.172472, l6: 0.391863\n",
      "\n",
      "[epoch: 380/400, batch: 200/1000, ite: 50276] train loss: 1.1140, accuracy: 95.4888%, tar: 0.0199 \n",
      "l0: 0.017927, l1: 0.020277, l2: 0.029966, l3: 0.052783, l4: 0.106777, l5: 0.176897, l6: 0.315875\n",
      "\n",
      "[epoch: 380/400, batch: 208/1000, ite: 50277] train loss: 1.1137, accuracy: 96.2698%, tar: 0.0199 \n",
      "l0: 0.018584, l1: 0.019323, l2: 0.025913, l3: 0.037487, l4: 0.065806, l5: 0.148142, l6: 0.329455\n",
      "\n",
      "[epoch: 380/400, batch: 216/1000, ite: 50278] train loss: 1.1132, accuracy: 95.5149%, tar: 0.0199 \n",
      "l0: 0.019848, l1: 0.021198, l2: 0.029711, l3: 0.045207, l4: 0.084568, l5: 0.198209, l6: 0.460993\n",
      "\n",
      "[epoch: 380/400, batch: 224/1000, ite: 50279] train loss: 1.1140, accuracy: 93.4471%, tar: 0.0199 \n",
      "l0: 0.020833, l1: 0.022090, l2: 0.028564, l3: 0.041146, l4: 0.073581, l5: 0.156104, l6: 0.396888\n",
      "\n",
      "[epoch: 380/400, batch: 232/1000, ite: 50280] train loss: 1.1141, accuracy: 94.6010%, tar: 0.0199 \n",
      "l0: 0.021151, l1: 0.022668, l2: 0.032005, l3: 0.049580, l4: 0.088667, l5: 0.171756, l6: 0.341192\n",
      "\n",
      "[epoch: 380/400, batch: 240/1000, ite: 50281] train loss: 1.1139, accuracy: 95.2176%, tar: 0.0199 \n",
      "l0: 0.015000, l1: 0.015956, l2: 0.022329, l3: 0.035205, l4: 0.062577, l5: 0.141189, l6: 0.291561\n",
      "\n",
      "[epoch: 380/400, batch: 248/1000, ite: 50282] train loss: 1.1131, accuracy: 95.6637%, tar: 0.0199 \n",
      "l0: 0.020126, l1: 0.021921, l2: 0.033905, l3: 0.056821, l4: 0.115367, l5: 0.236146, l6: 0.435383\n",
      "\n",
      "[epoch: 380/400, batch: 256/1000, ite: 50283] train loss: 1.1139, accuracy: 94.9648%, tar: 0.0199 \n",
      "l0: 0.025543, l1: 0.026739, l2: 0.036143, l3: 0.054230, l4: 0.115197, l5: 0.240799, l6: 0.470203\n",
      "\n",
      "[epoch: 380/400, batch: 264/1000, ite: 50284] train loss: 1.1151, accuracy: 92.7890%, tar: 0.0199 \n",
      "l0: 0.016714, l1: 0.018304, l2: 0.025061, l3: 0.038725, l4: 0.073841, l5: 0.173886, l6: 0.317120\n",
      "\n",
      "[epoch: 380/400, batch: 272/1000, ite: 50285] train loss: 1.1147, accuracy: 96.1676%, tar: 0.0199 \n",
      "l0: 0.020114, l1: 0.021438, l2: 0.028058, l3: 0.040446, l4: 0.081590, l5: 0.181126, l6: 0.482183\n",
      "\n",
      "[epoch: 380/400, batch: 280/1000, ite: 50286] train loss: 1.1154, accuracy: 94.0423%, tar: 0.0199 \n",
      "l0: 0.024732, l1: 0.026603, l2: 0.033991, l3: 0.050178, l4: 0.093293, l5: 0.184571, l6: 0.363336\n",
      "\n",
      "[epoch: 380/400, batch: 288/1000, ite: 50287] train loss: 1.1155, accuracy: 94.5352%, tar: 0.0199 \n",
      "l0: 0.016631, l1: 0.017977, l2: 0.026928, l3: 0.048264, l4: 0.092669, l5: 0.226438, l6: 0.435977\n",
      "\n",
      "[epoch: 380/400, batch: 296/1000, ite: 50288] train loss: 1.1162, accuracy: 94.7115%, tar: 0.0199 \n",
      "l0: 0.023972, l1: 0.024848, l2: 0.031350, l3: 0.043731, l4: 0.081955, l5: 0.178897, l6: 0.326189\n",
      "\n",
      "[epoch: 380/400, batch: 304/1000, ite: 50289] train loss: 1.1160, accuracy: 95.2481%, tar: 0.0199 \n",
      "l0: 0.017660, l1: 0.020133, l2: 0.030418, l3: 0.062952, l4: 0.132964, l5: 0.236083, l6: 0.366607\n",
      "\n",
      "[epoch: 380/400, batch: 312/1000, ite: 50290] train loss: 1.1163, accuracy: 95.4799%, tar: 0.0199 \n",
      "l0: 0.016586, l1: 0.017594, l2: 0.024695, l3: 0.039299, l4: 0.092364, l5: 0.169915, l6: 0.410606\n",
      "\n",
      "[epoch: 380/400, batch: 320/1000, ite: 50291] train loss: 1.1166, accuracy: 95.1172%, tar: 0.0199 \n",
      "l0: 0.019575, l1: 0.020384, l2: 0.027979, l3: 0.041823, l4: 0.078321, l5: 0.152794, l6: 0.388732\n",
      "\n",
      "[epoch: 380/400, batch: 328/1000, ite: 50292] train loss: 1.1166, accuracy: 94.3540%, tar: 0.0199 \n",
      "l0: 0.016267, l1: 0.017710, l2: 0.024419, l3: 0.034707, l4: 0.061649, l5: 0.109643, l6: 0.253062\n",
      "\n",
      "[epoch: 380/400, batch: 336/1000, ite: 50293] train loss: 1.1155, accuracy: 96.3550%, tar: 0.0199 \n",
      "l0: 0.016782, l1: 0.017956, l2: 0.025986, l3: 0.041748, l4: 0.077926, l5: 0.183342, l6: 0.323334\n",
      "\n",
      "[epoch: 380/400, batch: 344/1000, ite: 50294] train loss: 1.1151, accuracy: 95.7865%, tar: 0.0198 \n",
      "l0: 0.018298, l1: 0.019299, l2: 0.027554, l3: 0.045029, l4: 0.089943, l5: 0.177466, l6: 0.410392\n",
      "\n",
      "[epoch: 380/400, batch: 352/1000, ite: 50295] train loss: 1.1154, accuracy: 94.7992%, tar: 0.0198 \n",
      "l0: 0.025544, l1: 0.026162, l2: 0.034691, l3: 0.049786, l4: 0.079881, l5: 0.158996, l6: 0.351600\n",
      "\n",
      "[epoch: 380/400, batch: 360/1000, ite: 50296] train loss: 1.1153, accuracy: 94.0677%, tar: 0.0199 \n",
      "l0: 0.019153, l1: 0.020671, l2: 0.030407, l3: 0.049079, l4: 0.085382, l5: 0.188872, l6: 0.321972\n",
      "\n",
      "[epoch: 380/400, batch: 368/1000, ite: 50297] train loss: 1.1150, accuracy: 95.9639%, tar: 0.0199 \n",
      "l0: 0.032558, l1: 0.034591, l2: 0.047362, l3: 0.073415, l4: 0.155324, l5: 0.354827, l6: 0.640072\n",
      "\n",
      "[epoch: 380/400, batch: 376/1000, ite: 50298] train loss: 1.1179, accuracy: 91.7830%, tar: 0.0199 \n",
      "l0: 0.022632, l1: 0.023984, l2: 0.033009, l3: 0.053611, l4: 0.126073, l5: 0.230386, l6: 0.413613\n",
      "\n",
      "[epoch: 380/400, batch: 384/1000, ite: 50299] train loss: 1.1186, accuracy: 94.2200%, tar: 0.0199 \n",
      "l0: 0.018526, l1: 0.020114, l2: 0.028265, l3: 0.045612, l4: 0.090056, l5: 0.176957, l6: 0.348002\n",
      "\n",
      "[epoch: 380/400, batch: 392/1000, ite: 50300] train loss: 1.1184, accuracy: 95.1054%, tar: 0.0199 \n",
      "l0: 0.014156, l1: 0.014894, l2: 0.021063, l3: 0.031982, l4: 0.059048, l5: 0.122113, l6: 0.241122\n",
      "\n",
      "[epoch: 380/400, batch: 400/1000, ite: 50301] train loss: 1.1172, accuracy: 96.2879%, tar: 0.0199 \n",
      "l0: 0.016977, l1: 0.018723, l2: 0.025974, l3: 0.041295, l4: 0.078550, l5: 0.151183, l6: 0.327276\n",
      "\n",
      "[epoch: 380/400, batch: 408/1000, ite: 50302] train loss: 1.1168, accuracy: 96.7424%, tar: 0.0199 \n",
      "l0: 0.019726, l1: 0.020676, l2: 0.026245, l3: 0.038589, l4: 0.067387, l5: 0.125429, l6: 0.274609\n",
      "\n",
      "[epoch: 380/400, batch: 416/1000, ite: 50303] train loss: 1.1159, accuracy: 96.3336%, tar: 0.0199 \n",
      "l0: 0.019747, l1: 0.020493, l2: 0.028102, l3: 0.040583, l4: 0.073061, l5: 0.180453, l6: 0.426359\n",
      "\n",
      "[epoch: 380/400, batch: 424/1000, ite: 50304] train loss: 1.1163, accuracy: 94.3739%, tar: 0.0199 \n",
      "l0: 0.020570, l1: 0.022232, l2: 0.030744, l3: 0.043243, l4: 0.085421, l5: 0.181172, l6: 0.382846\n",
      "\n",
      "[epoch: 380/400, batch: 432/1000, ite: 50305] train loss: 1.1164, accuracy: 94.9294%, tar: 0.0199 \n",
      "l0: 0.019863, l1: 0.021284, l2: 0.030556, l3: 0.049478, l4: 0.106120, l5: 0.238806, l6: 0.460865\n",
      "\n",
      "[epoch: 380/400, batch: 440/1000, ite: 50306] train loss: 1.1173, accuracy: 94.1451%, tar: 0.0199 \n",
      "l0: 0.021037, l1: 0.022719, l2: 0.030671, l3: 0.043630, l4: 0.085239, l5: 0.209661, l6: 0.428313\n",
      "\n",
      "[epoch: 380/400, batch: 448/1000, ite: 50307] train loss: 1.1178, accuracy: 94.1350%, tar: 0.0199 \n",
      "l0: 0.018664, l1: 0.019831, l2: 0.026188, l3: 0.041008, l4: 0.075466, l5: 0.168081, l6: 0.335190\n",
      "\n",
      "[epoch: 380/400, batch: 456/1000, ite: 50308] train loss: 1.1175, accuracy: 95.2482%, tar: 0.0199 \n",
      "l0: 0.019547, l1: 0.020482, l2: 0.027524, l3: 0.040994, l4: 0.069211, l5: 0.158840, l6: 0.346319\n",
      "\n",
      "[epoch: 380/400, batch: 464/1000, ite: 50309] train loss: 1.1172, accuracy: 95.3425%, tar: 0.0199 \n",
      "l0: 0.017043, l1: 0.017661, l2: 0.023780, l3: 0.034105, l4: 0.061998, l5: 0.118395, l6: 0.276932\n",
      "\n",
      "[epoch: 380/400, batch: 472/1000, ite: 50310] train loss: 1.1163, accuracy: 96.1468%, tar: 0.0199 \n",
      "l0: 0.018628, l1: 0.019990, l2: 0.027764, l3: 0.043910, l4: 0.098813, l5: 0.187883, l6: 0.349005\n",
      "\n",
      "[epoch: 380/400, batch: 480/1000, ite: 50311] train loss: 1.1162, accuracy: 95.4625%, tar: 0.0199 \n",
      "l0: 0.026979, l1: 0.028578, l2: 0.038589, l3: 0.057664, l4: 0.099654, l5: 0.227573, l6: 0.489061\n",
      "\n",
      "[epoch: 380/400, batch: 488/1000, ite: 50312] train loss: 1.1173, accuracy: 93.1449%, tar: 0.0199 \n",
      "l0: 0.021634, l1: 0.022439, l2: 0.030633, l3: 0.045969, l4: 0.073915, l5: 0.135186, l6: 0.284263\n",
      "\n",
      "[epoch: 380/400, batch: 496/1000, ite: 50313] train loss: 1.1167, accuracy: 95.5861%, tar: 0.0199 \n",
      "l0: 0.014958, l1: 0.015739, l2: 0.021356, l3: 0.033042, l4: 0.055094, l5: 0.105355, l6: 0.231872\n",
      "\n",
      "[epoch: 380/400, batch: 504/1000, ite: 50314] train loss: 1.1154, accuracy: 96.3022%, tar: 0.0199 \n",
      "l0: 0.016907, l1: 0.018095, l2: 0.026285, l3: 0.040210, l4: 0.070726, l5: 0.144229, l6: 0.357969\n",
      "\n",
      "[epoch: 380/400, batch: 512/1000, ite: 50315] train loss: 1.1151, accuracy: 95.4016%, tar: 0.0199 \n",
      "l0: 0.024165, l1: 0.026011, l2: 0.033549, l3: 0.052211, l4: 0.103005, l5: 0.226886, l6: 0.422378\n",
      "\n",
      "[epoch: 380/400, batch: 520/1000, ite: 50316] train loss: 1.1157, accuracy: 94.0488%, tar: 0.0199 \n",
      "l0: 0.021236, l1: 0.022302, l2: 0.029162, l3: 0.042779, l4: 0.069395, l5: 0.141532, l6: 0.402691\n",
      "\n",
      "[epoch: 380/400, batch: 528/1000, ite: 50317] train loss: 1.1158, accuracy: 94.6241%, tar: 0.0199 \n",
      "l0: 0.021263, l1: 0.022308, l2: 0.029065, l3: 0.043778, l4: 0.077676, l5: 0.161396, l6: 0.357155\n",
      "\n",
      "[epoch: 380/400, batch: 536/1000, ite: 50318] train loss: 1.1157, accuracy: 94.7483%, tar: 0.0199 \n",
      "l0: 0.015835, l1: 0.017409, l2: 0.024512, l3: 0.041371, l4: 0.080189, l5: 0.164818, l6: 0.402332\n",
      "\n",
      "[epoch: 380/400, batch: 544/1000, ite: 50319] train loss: 1.1158, accuracy: 95.1797%, tar: 0.0199 \n",
      "l0: 0.019830, l1: 0.021206, l2: 0.029250, l3: 0.049148, l4: 0.097901, l5: 0.180386, l6: 0.345737\n",
      "\n",
      "[epoch: 380/400, batch: 552/1000, ite: 50320] train loss: 1.1157, accuracy: 95.4449%, tar: 0.0199 \n",
      "l0: 0.025289, l1: 0.028148, l2: 0.040102, l3: 0.065818, l4: 0.134942, l5: 0.256681, l6: 0.444709\n",
      "\n",
      "[epoch: 380/400, batch: 560/1000, ite: 50321] train loss: 1.1168, accuracy: 94.1993%, tar: 0.0199 \n",
      "l0: 0.018288, l1: 0.019147, l2: 0.026282, l3: 0.040304, l4: 0.079106, l5: 0.155647, l6: 0.325462\n",
      "\n",
      "[epoch: 380/400, batch: 568/1000, ite: 50322] train loss: 1.1164, accuracy: 95.2814%, tar: 0.0199 \n",
      "l0: 0.019848, l1: 0.020991, l2: 0.030085, l3: 0.047815, l4: 0.082448, l5: 0.159353, l6: 0.304007\n",
      "\n",
      "[epoch: 380/400, batch: 576/1000, ite: 50323] train loss: 1.1159, accuracy: 95.6518%, tar: 0.0199 \n",
      "l0: 0.021107, l1: 0.022880, l2: 0.033326, l3: 0.058218, l4: 0.105575, l5: 0.219698, l6: 0.449409\n",
      "\n",
      "[epoch: 380/400, batch: 584/1000, ite: 50324] train loss: 1.1167, accuracy: 94.7050%, tar: 0.0199 \n",
      "l0: 0.018181, l1: 0.019723, l2: 0.028532, l3: 0.047838, l4: 0.090564, l5: 0.196889, l6: 0.394413\n",
      "\n",
      "[epoch: 380/400, batch: 592/1000, ite: 50325] train loss: 1.1170, accuracy: 94.3536%, tar: 0.0199 \n",
      "l0: 0.028604, l1: 0.029858, l2: 0.038844, l3: 0.055910, l4: 0.096486, l5: 0.172970, l6: 0.314872\n",
      "\n",
      "[epoch: 380/400, batch: 600/1000, ite: 50326] train loss: 1.1168, accuracy: 94.6614%, tar: 0.0199 \n",
      "l0: 0.020922, l1: 0.022313, l2: 0.030624, l3: 0.046389, l4: 0.087285, l5: 0.216061, l6: 0.465265\n",
      "\n",
      "[epoch: 380/400, batch: 608/1000, ite: 50327] train loss: 1.1175, accuracy: 93.6599%, tar: 0.0199 \n",
      "l0: 0.017740, l1: 0.018910, l2: 0.027497, l3: 0.044301, l4: 0.080588, l5: 0.157109, l6: 0.361409\n",
      "\n",
      "[epoch: 380/400, batch: 616/1000, ite: 50328] train loss: 1.1174, accuracy: 95.6678%, tar: 0.0199 \n",
      "l0: 0.021204, l1: 0.022064, l2: 0.029196, l3: 0.050278, l4: 0.091666, l5: 0.195934, l6: 0.399340\n",
      "\n",
      "[epoch: 380/400, batch: 624/1000, ite: 50329] train loss: 1.1177, accuracy: 94.2798%, tar: 0.0199 \n",
      "l0: 0.016934, l1: 0.018348, l2: 0.025917, l3: 0.041640, l4: 0.078079, l5: 0.138503, l6: 0.309459\n",
      "\n",
      "[epoch: 380/400, batch: 632/1000, ite: 50330] train loss: 1.1171, accuracy: 95.9856%, tar: 0.0199 \n",
      "l0: 0.022026, l1: 0.022803, l2: 0.028115, l3: 0.039972, l4: 0.071719, l5: 0.140401, l6: 0.320362\n",
      "\n",
      "[epoch: 380/400, batch: 640/1000, ite: 50331] train loss: 1.1167, accuracy: 95.2679%, tar: 0.0199 \n",
      "l0: 0.021285, l1: 0.023072, l2: 0.035005, l3: 0.052259, l4: 0.090941, l5: 0.183593, l6: 0.349103\n",
      "\n",
      "[epoch: 380/400, batch: 648/1000, ite: 50332] train loss: 1.1166, accuracy: 95.2496%, tar: 0.0199 \n",
      "l0: 0.016573, l1: 0.017449, l2: 0.022097, l3: 0.034002, l4: 0.059348, l5: 0.124425, l6: 0.361388\n",
      "\n",
      "[epoch: 380/400, batch: 656/1000, ite: 50333] train loss: 1.1163, accuracy: 95.2195%, tar: 0.0199 \n",
      "l0: 0.023898, l1: 0.025571, l2: 0.035005, l3: 0.054336, l4: 0.092696, l5: 0.187668, l6: 0.451413\n",
      "\n",
      "[epoch: 380/400, batch: 664/1000, ite: 50334] train loss: 1.1169, accuracy: 94.4713%, tar: 0.0199 \n",
      "l0: 0.015787, l1: 0.017068, l2: 0.024123, l3: 0.041019, l4: 0.076153, l5: 0.153695, l6: 0.278900\n",
      "\n",
      "[epoch: 380/400, batch: 672/1000, ite: 50335] train loss: 1.1162, accuracy: 96.4061%, tar: 0.0199 \n",
      "l0: 0.014460, l1: 0.015437, l2: 0.022485, l3: 0.035752, l4: 0.070497, l5: 0.140501, l6: 0.332163\n",
      "\n",
      "[epoch: 380/400, batch: 680/1000, ite: 50336] train loss: 1.1158, accuracy: 95.7696%, tar: 0.0199 \n",
      "l0: 0.022135, l1: 0.023563, l2: 0.031906, l3: 0.049217, l4: 0.084966, l5: 0.175613, l6: 0.404795\n",
      "\n",
      "[epoch: 380/400, batch: 688/1000, ite: 50337] train loss: 1.1160, accuracy: 95.1891%, tar: 0.0199 \n",
      "l0: 0.020183, l1: 0.021293, l2: 0.028862, l3: 0.045419, l4: 0.077938, l5: 0.166077, l6: 0.382513\n",
      "\n",
      "[epoch: 380/400, batch: 696/1000, ite: 50338] train loss: 1.1160, accuracy: 95.3816%, tar: 0.0199 \n",
      "l0: 0.018926, l1: 0.019834, l2: 0.027752, l3: 0.041519, l4: 0.071708, l5: 0.136973, l6: 0.263335\n",
      "\n",
      "[epoch: 380/400, batch: 704/1000, ite: 50339] train loss: 1.1152, accuracy: 95.9960%, tar: 0.0199 \n",
      "l0: 0.019836, l1: 0.021272, l2: 0.029653, l3: 0.045482, l4: 0.089837, l5: 0.248102, l6: 0.458979\n",
      "\n",
      "[epoch: 380/400, batch: 712/1000, ite: 50340] train loss: 1.1160, accuracy: 93.6135%, tar: 0.0199 \n",
      "l0: 0.016062, l1: 0.017690, l2: 0.025192, l3: 0.040272, l4: 0.078269, l5: 0.155001, l6: 0.300405\n",
      "\n",
      "[epoch: 380/400, batch: 720/1000, ite: 50341] train loss: 1.1155, accuracy: 96.1267%, tar: 0.0199 \n",
      "l0: 0.018818, l1: 0.019821, l2: 0.027602, l3: 0.042033, l4: 0.080661, l5: 0.159694, l6: 0.302180\n",
      "\n",
      "[epoch: 380/400, batch: 728/1000, ite: 50342] train loss: 1.1150, accuracy: 95.6522%, tar: 0.0199 \n",
      "l0: 0.018121, l1: 0.018533, l2: 0.025188, l3: 0.038296, l4: 0.064093, l5: 0.114976, l6: 0.252975\n",
      "\n",
      "[epoch: 380/400, batch: 736/1000, ite: 50343] train loss: 1.1141, accuracy: 96.4805%, tar: 0.0199 \n",
      "l0: 0.018834, l1: 0.020134, l2: 0.029025, l3: 0.043946, l4: 0.086938, l5: 0.188717, l6: 0.380088\n",
      "\n",
      "[epoch: 380/400, batch: 744/1000, ite: 50344] train loss: 1.1142, accuracy: 95.2373%, tar: 0.0199 \n",
      "l0: 0.019236, l1: 0.019965, l2: 0.026358, l3: 0.036782, l4: 0.067332, l5: 0.154096, l6: 0.351046\n",
      "\n",
      "[epoch: 380/400, batch: 752/1000, ite: 50345] train loss: 1.1139, accuracy: 94.8779%, tar: 0.0199 \n",
      "l0: 0.022083, l1: 0.023519, l2: 0.033419, l3: 0.049147, l4: 0.093311, l5: 0.198502, l6: 0.381826\n",
      "\n",
      "[epoch: 380/400, batch: 760/1000, ite: 50346] train loss: 1.1142, accuracy: 95.0986%, tar: 0.0199 \n",
      "l0: 0.018815, l1: 0.020193, l2: 0.027370, l3: 0.041373, l4: 0.074194, l5: 0.151407, l6: 0.373105\n",
      "\n",
      "[epoch: 380/400, batch: 768/1000, ite: 50347] train loss: 1.1141, accuracy: 94.4787%, tar: 0.0199 \n",
      "l0: 0.022277, l1: 0.023597, l2: 0.030475, l3: 0.044984, l4: 0.074953, l5: 0.148203, l6: 0.345950\n",
      "\n",
      "[epoch: 380/400, batch: 776/1000, ite: 50348] train loss: 1.1139, accuracy: 94.8054%, tar: 0.0199 \n",
      "l0: 0.017656, l1: 0.018571, l2: 0.026335, l3: 0.038056, l4: 0.060084, l5: 0.150629, l6: 0.300855\n",
      "\n",
      "[epoch: 380/400, batch: 784/1000, ite: 50349] train loss: 1.1133, accuracy: 95.4686%, tar: 0.0199 \n",
      "l0: 0.021284, l1: 0.022405, l2: 0.029763, l3: 0.042274, l4: 0.075320, l5: 0.182669, l6: 0.393301\n",
      "\n",
      "[epoch: 380/400, batch: 792/1000, ite: 50350] train loss: 1.1134, accuracy: 94.9791%, tar: 0.0199 \n",
      "l0: 0.020358, l1: 0.021352, l2: 0.028838, l3: 0.042339, l4: 0.067683, l5: 0.153355, l6: 0.326785\n",
      "\n",
      "[epoch: 380/400, batch: 800/1000, ite: 50351] train loss: 1.1131, accuracy: 94.9794%, tar: 0.0199 \n",
      "l0: 0.016833, l1: 0.018297, l2: 0.026203, l3: 0.044050, l4: 0.093324, l5: 0.195919, l6: 0.411316\n",
      "\n",
      "[epoch: 380/400, batch: 808/1000, ite: 50352] train loss: 1.1134, accuracy: 94.8166%, tar: 0.0199 \n",
      "l0: 0.019114, l1: 0.020249, l2: 0.026534, l3: 0.039489, l4: 0.069825, l5: 0.151451, l6: 0.315220\n",
      "\n",
      "[epoch: 380/400, batch: 816/1000, ite: 50353] train loss: 1.1129, accuracy: 95.9990%, tar: 0.0199 \n",
      "l0: 0.019038, l1: 0.020424, l2: 0.026880, l3: 0.041145, l4: 0.090369, l5: 0.201193, l6: 0.371599\n",
      "\n",
      "[epoch: 380/400, batch: 824/1000, ite: 50354] train loss: 1.1130, accuracy: 95.1456%, tar: 0.0199 \n",
      "l0: 0.018030, l1: 0.019514, l2: 0.027509, l3: 0.045680, l4: 0.112027, l5: 0.213117, l6: 0.406367\n",
      "\n",
      "[epoch: 380/400, batch: 832/1000, ite: 50355] train loss: 1.1134, accuracy: 95.2342%, tar: 0.0199 \n",
      "l0: 0.016929, l1: 0.018539, l2: 0.027033, l3: 0.042091, l4: 0.077051, l5: 0.142822, l6: 0.344825\n",
      "\n",
      "[epoch: 380/400, batch: 840/1000, ite: 50356] train loss: 1.1131, accuracy: 95.7585%, tar: 0.0198 \n",
      "l0: 0.015989, l1: 0.017566, l2: 0.026731, l3: 0.046291, l4: 0.085034, l5: 0.153183, l6: 0.325475\n",
      "\n",
      "[epoch: 380/400, batch: 848/1000, ite: 50357] train loss: 1.1128, accuracy: 95.8465%, tar: 0.0198 \n",
      "l0: 0.023901, l1: 0.024769, l2: 0.032468, l3: 0.045370, l4: 0.078329, l5: 0.156012, l6: 0.408260\n",
      "\n",
      "[epoch: 380/400, batch: 856/1000, ite: 50358] train loss: 1.1130, accuracy: 94.3124%, tar: 0.0198 \n",
      "l0: 0.021417, l1: 0.022442, l2: 0.029390, l3: 0.040722, l4: 0.072333, l5: 0.142836, l6: 0.302377\n",
      "\n",
      "[epoch: 380/400, batch: 864/1000, ite: 50359] train loss: 1.1125, accuracy: 95.4099%, tar: 0.0199 \n",
      "l0: 0.019186, l1: 0.021593, l2: 0.030065, l3: 0.051288, l4: 0.102899, l5: 0.200352, l6: 0.391725\n",
      "\n",
      "[epoch: 380/400, batch: 872/1000, ite: 50360] train loss: 1.1128, accuracy: 95.4682%, tar: 0.0199 \n",
      "l0: 0.027961, l1: 0.030415, l2: 0.040183, l3: 0.060820, l4: 0.107275, l5: 0.217481, l6: 0.485896\n",
      "\n",
      "[epoch: 380/400, batch: 880/1000, ite: 50361] train loss: 1.1137, accuracy: 93.9154%, tar: 0.0199 \n",
      "l0: 0.018700, l1: 0.019907, l2: 0.027192, l3: 0.044089, l4: 0.093803, l5: 0.202897, l6: 0.389332\n",
      "\n",
      "[epoch: 380/400, batch: 888/1000, ite: 50362] train loss: 1.1139, accuracy: 94.7723%, tar: 0.0199 \n",
      "l0: 0.017348, l1: 0.019026, l2: 0.024952, l3: 0.041159, l4: 0.078242, l5: 0.154774, l6: 0.311680\n",
      "\n",
      "[epoch: 380/400, batch: 896/1000, ite: 50363] train loss: 1.1135, accuracy: 95.5591%, tar: 0.0199 \n",
      "l0: 0.022890, l1: 0.024842, l2: 0.032249, l3: 0.050941, l4: 0.114147, l5: 0.223754, l6: 0.395699\n",
      "\n",
      "[epoch: 380/400, batch: 904/1000, ite: 50364] train loss: 1.1140, accuracy: 94.4599%, tar: 0.0199 \n",
      "l0: 0.022376, l1: 0.024442, l2: 0.034842, l3: 0.061149, l4: 0.148354, l5: 0.309571, l6: 0.576825\n",
      "\n",
      "[epoch: 380/400, batch: 912/1000, ite: 50365] train loss: 1.1157, accuracy: 93.9248%, tar: 0.0199 \n",
      "l0: 0.017674, l1: 0.018698, l2: 0.024700, l3: 0.038225, l4: 0.069814, l5: 0.139741, l6: 0.341591\n",
      "\n",
      "[epoch: 380/400, batch: 920/1000, ite: 50366] train loss: 1.1154, accuracy: 95.5292%, tar: 0.0199 \n",
      "l0: 0.022038, l1: 0.022845, l2: 0.031609, l3: 0.045226, l4: 0.080021, l5: 0.166042, l6: 0.390125\n",
      "\n",
      "[epoch: 380/400, batch: 928/1000, ite: 50367] train loss: 1.1155, accuracy: 94.6260%, tar: 0.0199 \n",
      "l0: 0.014746, l1: 0.015177, l2: 0.019554, l3: 0.028672, l4: 0.046815, l5: 0.088949, l6: 0.201599\n",
      "\n",
      "[epoch: 380/400, batch: 936/1000, ite: 50368] train loss: 1.1142, accuracy: 96.7752%, tar: 0.0199 \n",
      "l0: 0.017233, l1: 0.019203, l2: 0.029873, l3: 0.053006, l4: 0.103408, l5: 0.222255, l6: 0.377960\n",
      "\n",
      "[epoch: 380/400, batch: 944/1000, ite: 50369] train loss: 1.1144, accuracy: 95.1695%, tar: 0.0199 \n",
      "l0: 0.021266, l1: 0.023476, l2: 0.032502, l3: 0.053125, l4: 0.107282, l5: 0.219694, l6: 0.440143\n",
      "\n",
      "[epoch: 380/400, batch: 952/1000, ite: 50370] train loss: 1.1150, accuracy: 94.7447%, tar: 0.0199 \n",
      "l0: 0.021324, l1: 0.022483, l2: 0.029812, l3: 0.044694, l4: 0.081852, l5: 0.155986, l6: 0.321115\n",
      "\n",
      "[epoch: 380/400, batch: 960/1000, ite: 50371] train loss: 1.1147, accuracy: 95.3900%, tar: 0.0199 \n",
      "l0: 0.016467, l1: 0.017703, l2: 0.023807, l3: 0.037385, l4: 0.070685, l5: 0.157428, l6: 0.346590\n",
      "\n",
      "[epoch: 380/400, batch: 968/1000, ite: 50372] train loss: 1.1144, accuracy: 95.1574%, tar: 0.0199 \n",
      "l0: 0.017262, l1: 0.018620, l2: 0.027109, l3: 0.040112, l4: 0.068267, l5: 0.148346, l6: 0.328600\n",
      "\n",
      "[epoch: 380/400, batch: 976/1000, ite: 50373] train loss: 1.1141, accuracy: 95.4023%, tar: 0.0199 \n",
      "l0: 0.014090, l1: 0.015087, l2: 0.020676, l3: 0.030787, l4: 0.062290, l5: 0.116459, l6: 0.261698\n",
      "\n",
      "[epoch: 380/400, batch: 984/1000, ite: 50374] train loss: 1.1132, accuracy: 95.9031%, tar: 0.0198 \n",
      "l0: 0.018491, l1: 0.019578, l2: 0.027387, l3: 0.042010, l4: 0.070808, l5: 0.165321, l6: 0.322203\n",
      "\n",
      "[epoch: 380/400, batch: 992/1000, ite: 50375] train loss: 1.1129, accuracy: 95.2993%, tar: 0.0198 \n",
      "l0: 0.019816, l1: 0.021417, l2: 0.030053, l3: 0.046640, l4: 0.078887, l5: 0.152788, l6: 0.418668\n",
      "\n",
      "[epoch: 380/400, batch: 1000/1000, ite: 50376] train loss: 1.1131, accuracy: 94.7124%, tar: 0.0198 \n",
      "l0: 0.022836, l1: 0.024103, l2: 0.033025, l3: 0.048918, l4: 0.085973, l5: 0.175155, l6: 0.363279\n",
      "\n",
      "[epoch: 381/400, batch: 8/1000, ite: 50377] train loss: 1.1131, accuracy: 94.6480%, tar: 0.0198 \n",
      "l0: 0.019601, l1: 0.021876, l2: 0.032207, l3: 0.050388, l4: 0.110231, l5: 0.229522, l6: 0.463370\n",
      "\n",
      "[epoch: 381/400, batch: 16/1000, ite: 50378] train loss: 1.1139, accuracy: 95.2917%, tar: 0.0198 \n",
      "l0: 0.025661, l1: 0.027557, l2: 0.037132, l3: 0.062346, l4: 0.135324, l5: 0.273448, l6: 0.528197\n",
      "\n",
      "[epoch: 381/400, batch: 24/1000, ite: 50379] train loss: 1.1152, accuracy: 93.1490%, tar: 0.0199 \n",
      "l0: 0.012144, l1: 0.013250, l2: 0.017587, l3: 0.027746, l4: 0.050349, l5: 0.114301, l6: 0.259169\n",
      "\n",
      "[epoch: 381/400, batch: 32/1000, ite: 50380] train loss: 1.1143, accuracy: 97.0091%, tar: 0.0198 \n",
      "l0: 0.017234, l1: 0.018981, l2: 0.028084, l3: 0.044998, l4: 0.080049, l5: 0.168527, l6: 0.323446\n",
      "\n",
      "[epoch: 381/400, batch: 40/1000, ite: 50381] train loss: 1.1140, accuracy: 95.5291%, tar: 0.0198 \n",
      "l0: 0.022646, l1: 0.023733, l2: 0.029631, l3: 0.044556, l4: 0.090324, l5: 0.183471, l6: 0.358620\n",
      "\n",
      "[epoch: 381/400, batch: 48/1000, ite: 50382] train loss: 1.1140, accuracy: 94.7425%, tar: 0.0198 \n",
      "l0: 0.020673, l1: 0.022719, l2: 0.034314, l3: 0.058654, l4: 0.117509, l5: 0.223010, l6: 0.394067\n",
      "\n",
      "[epoch: 381/400, batch: 56/1000, ite: 50383] train loss: 1.1144, accuracy: 95.2915%, tar: 0.0198 \n",
      "l0: 0.019960, l1: 0.021259, l2: 0.027387, l3: 0.041794, l4: 0.086169, l5: 0.189648, l6: 0.371186\n",
      "\n",
      "[epoch: 381/400, batch: 64/1000, ite: 50384] train loss: 1.1144, accuracy: 94.2349%, tar: 0.0198 \n",
      "l0: 0.026851, l1: 0.028767, l2: 0.037921, l3: 0.062547, l4: 0.114389, l5: 0.225204, l6: 0.429005\n",
      "\n",
      "[epoch: 381/400, batch: 72/1000, ite: 50385] train loss: 1.1151, accuracy: 93.9083%, tar: 0.0199 \n",
      "l0: 0.015450, l1: 0.017000, l2: 0.024853, l3: 0.039418, l4: 0.067257, l5: 0.136947, l6: 0.304436\n",
      "\n",
      "[epoch: 381/400, batch: 80/1000, ite: 50386] train loss: 1.1145, accuracy: 96.3418%, tar: 0.0198 \n",
      "l0: 0.024690, l1: 0.025784, l2: 0.034445, l3: 0.051375, l4: 0.104449, l5: 0.227613, l6: 0.468207\n",
      "\n",
      "[epoch: 381/400, batch: 88/1000, ite: 50387] train loss: 1.1153, accuracy: 93.0707%, tar: 0.0199 \n",
      "l0: 0.024571, l1: 0.026102, l2: 0.037308, l3: 0.054446, l4: 0.101041, l5: 0.252941, l6: 0.548995\n",
      "\n",
      "[epoch: 381/400, batch: 96/1000, ite: 50388] train loss: 1.1165, accuracy: 92.6734%, tar: 0.0199 \n",
      "l0: 0.015237, l1: 0.016173, l2: 0.022194, l3: 0.030456, l4: 0.051217, l5: 0.116264, l6: 0.346308\n",
      "\n",
      "[epoch: 381/400, batch: 104/1000, ite: 50389] train loss: 1.1161, accuracy: 95.1241%, tar: 0.0199 \n",
      "l0: 0.016787, l1: 0.017680, l2: 0.021865, l3: 0.036072, l4: 0.091978, l5: 0.136731, l6: 0.296549\n",
      "\n",
      "[epoch: 381/400, batch: 112/1000, ite: 50390] train loss: 1.1156, accuracy: 95.8371%, tar: 0.0198 \n",
      "l0: 0.023578, l1: 0.024670, l2: 0.033170, l3: 0.049218, l4: 0.090008, l5: 0.219726, l6: 0.484241\n",
      "\n",
      "[epoch: 381/400, batch: 120/1000, ite: 50391] train loss: 1.1164, accuracy: 93.0332%, tar: 0.0199 \n",
      "l0: 0.020154, l1: 0.022630, l2: 0.031759, l3: 0.050142, l4: 0.098622, l5: 0.215678, l6: 0.443821\n",
      "\n",
      "[epoch: 381/400, batch: 128/1000, ite: 50392] train loss: 1.1169, accuracy: 94.4276%, tar: 0.0199 \n",
      "l0: 0.019232, l1: 0.020262, l2: 0.029331, l3: 0.044347, l4: 0.075118, l5: 0.130582, l6: 0.306598\n",
      "\n",
      "[epoch: 381/400, batch: 136/1000, ite: 50393] train loss: 1.1165, accuracy: 96.1672%, tar: 0.0199 \n",
      "l0: 0.020012, l1: 0.021354, l2: 0.028741, l3: 0.042473, l4: 0.079584, l5: 0.165448, l6: 0.330216\n",
      "\n",
      "[epoch: 381/400, batch: 144/1000, ite: 50394] train loss: 1.1162, accuracy: 94.7280%, tar: 0.0199 \n",
      "l0: 0.021939, l1: 0.023712, l2: 0.031032, l3: 0.047278, l4: 0.096556, l5: 0.218389, l6: 0.428962\n",
      "\n",
      "[epoch: 381/400, batch: 152/1000, ite: 50395] train loss: 1.1166, accuracy: 94.9066%, tar: 0.0199 \n",
      "l0: 0.021734, l1: 0.023054, l2: 0.030610, l3: 0.045027, l4: 0.076562, l5: 0.180633, l6: 0.403068\n",
      "\n",
      "[epoch: 381/400, batch: 160/1000, ite: 50396] train loss: 1.1168, accuracy: 95.2263%, tar: 0.0199 \n",
      "l0: 0.015664, l1: 0.016744, l2: 0.023759, l3: 0.036289, l4: 0.071492, l5: 0.153852, l6: 0.314589\n",
      "\n",
      "[epoch: 381/400, batch: 168/1000, ite: 50397] train loss: 1.1164, accuracy: 95.7551%, tar: 0.0199 \n",
      "l0: 0.016658, l1: 0.017891, l2: 0.025433, l3: 0.040994, l4: 0.085297, l5: 0.197156, l6: 0.333686\n",
      "\n",
      "[epoch: 381/400, batch: 176/1000, ite: 50398] train loss: 1.1163, accuracy: 95.2100%, tar: 0.0198 \n",
      "l0: 0.018251, l1: 0.019289, l2: 0.026404, l3: 0.037605, l4: 0.068147, l5: 0.146932, l6: 0.280006\n",
      "\n",
      "[epoch: 381/400, batch: 184/1000, ite: 50399] train loss: 1.1157, accuracy: 95.6381%, tar: 0.0198 \n",
      "l0: 0.022366, l1: 0.024611, l2: 0.033924, l3: 0.054146, l4: 0.101509, l5: 0.234089, l6: 0.535821\n",
      "\n",
      "[epoch: 381/400, batch: 192/1000, ite: 50400] train loss: 1.1167, accuracy: 93.2084%, tar: 0.0199 \n",
      "l0: 0.019863, l1: 0.020984, l2: 0.028652, l3: 0.042846, l4: 0.084595, l5: 0.158906, l6: 0.290653\n",
      "\n",
      "[epoch: 381/400, batch: 200/1000, ite: 50401] train loss: 1.1163, accuracy: 94.9103%, tar: 0.0199 \n",
      "l0: 0.023332, l1: 0.025613, l2: 0.035490, l3: 0.054514, l4: 0.106930, l5: 0.226431, l6: 0.443115\n",
      "\n",
      "[epoch: 381/400, batch: 208/1000, ite: 50402] train loss: 1.1169, accuracy: 95.0583%, tar: 0.0199 \n",
      "l0: 0.022543, l1: 0.023309, l2: 0.030894, l3: 0.044278, l4: 0.079814, l5: 0.162408, l6: 0.326836\n",
      "\n",
      "[epoch: 381/400, batch: 216/1000, ite: 50403] train loss: 1.1166, accuracy: 95.1356%, tar: 0.0199 \n",
      "l0: 0.015895, l1: 0.017393, l2: 0.026334, l3: 0.044380, l4: 0.082518, l5: 0.173204, l6: 0.427480\n",
      "\n",
      "[epoch: 381/400, batch: 224/1000, ite: 50404] train loss: 1.1169, accuracy: 95.5162%, tar: 0.0199 \n",
      "l0: 0.025768, l1: 0.027992, l2: 0.035885, l3: 0.061775, l4: 0.155462, l5: 0.275560, l6: 0.451125\n",
      "\n",
      "[epoch: 381/400, batch: 232/1000, ite: 50405] train loss: 1.1178, accuracy: 93.7791%, tar: 0.0199 \n",
      "l0: 0.019118, l1: 0.019948, l2: 0.026213, l3: 0.038491, l4: 0.078350, l5: 0.222793, l6: 0.419101\n",
      "\n",
      "[epoch: 381/400, batch: 240/1000, ite: 50406] train loss: 1.1181, accuracy: 94.6366%, tar: 0.0199 \n",
      "l0: 0.022786, l1: 0.023965, l2: 0.032658, l3: 0.046714, l4: 0.076700, l5: 0.130040, l6: 0.298525\n",
      "\n",
      "[epoch: 381/400, batch: 248/1000, ite: 50407] train loss: 1.1177, accuracy: 95.3537%, tar: 0.0199 \n",
      "l0: 0.016291, l1: 0.017686, l2: 0.023508, l3: 0.039668, l4: 0.072802, l5: 0.135795, l6: 0.306648\n",
      "\n",
      "[epoch: 381/400, batch: 256/1000, ite: 50408] train loss: 1.1172, accuracy: 95.8458%, tar: 0.0199 \n",
      "l0: 0.016264, l1: 0.017763, l2: 0.025566, l3: 0.039006, l4: 0.076915, l5: 0.161308, l6: 0.278276\n",
      "\n",
      "[epoch: 381/400, batch: 264/1000, ite: 50409] train loss: 1.1167, accuracy: 96.1434%, tar: 0.0199 \n",
      "l0: 0.017994, l1: 0.018911, l2: 0.025569, l3: 0.040072, l4: 0.090887, l5: 0.209259, l6: 0.396688\n",
      "\n",
      "[epoch: 381/400, batch: 272/1000, ite: 50410] train loss: 1.1169, accuracy: 94.8865%, tar: 0.0199 \n",
      "l0: 0.019200, l1: 0.020514, l2: 0.028251, l3: 0.039563, l4: 0.068879, l5: 0.128420, l6: 0.351052\n",
      "\n",
      "[epoch: 381/400, batch: 280/1000, ite: 50411] train loss: 1.1166, accuracy: 95.5090%, tar: 0.0199 \n",
      "l0: 0.018500, l1: 0.020540, l2: 0.031156, l3: 0.050314, l4: 0.100951, l5: 0.223833, l6: 0.490564\n",
      "\n",
      "[epoch: 381/400, batch: 288/1000, ite: 50412] train loss: 1.1174, accuracy: 94.7459%, tar: 0.0198 \n",
      "l0: 0.018885, l1: 0.020558, l2: 0.029455, l3: 0.044657, l4: 0.082531, l5: 0.181902, l6: 0.376168\n",
      "\n",
      "[epoch: 381/400, batch: 296/1000, ite: 50413] train loss: 1.1174, accuracy: 95.3715%, tar: 0.0198 \n",
      "l0: 0.022705, l1: 0.024174, l2: 0.029781, l3: 0.041514, l4: 0.082174, l5: 0.172380, l6: 0.339668\n",
      "\n",
      "[epoch: 381/400, batch: 304/1000, ite: 50414] train loss: 1.1173, accuracy: 95.2647%, tar: 0.0199 \n",
      "l0: 0.026769, l1: 0.027791, l2: 0.033156, l3: 0.045708, l4: 0.076631, l5: 0.143936, l6: 0.360754\n",
      "\n",
      "[epoch: 381/400, batch: 312/1000, ite: 50415] train loss: 1.1172, accuracy: 94.8348%, tar: 0.0199 \n",
      "l0: 0.012908, l1: 0.014745, l2: 0.021302, l3: 0.038075, l4: 0.080260, l5: 0.161464, l6: 0.355258\n",
      "\n",
      "[epoch: 381/400, batch: 320/1000, ite: 50416] train loss: 1.1170, accuracy: 95.5677%, tar: 0.0199 \n",
      "l0: 0.020692, l1: 0.021833, l2: 0.029509, l3: 0.043666, l4: 0.074090, l5: 0.141129, l6: 0.327142\n",
      "\n",
      "[epoch: 381/400, batch: 328/1000, ite: 50417] train loss: 1.1167, accuracy: 95.6637%, tar: 0.0199 \n",
      "l0: 0.022913, l1: 0.024163, l2: 0.031744, l3: 0.048181, l4: 0.088404, l5: 0.176420, l6: 0.386637\n",
      "\n",
      "[epoch: 381/400, batch: 336/1000, ite: 50418] train loss: 1.1168, accuracy: 94.8360%, tar: 0.0199 \n",
      "l0: 0.024625, l1: 0.026741, l2: 0.038772, l3: 0.062599, l4: 0.125322, l5: 0.302504, l6: 0.586092\n",
      "\n",
      "[epoch: 381/400, batch: 344/1000, ite: 50419] train loss: 1.1184, accuracy: 92.4729%, tar: 0.0199 \n",
      "l0: 0.011748, l1: 0.012829, l2: 0.019129, l3: 0.030373, l4: 0.052903, l5: 0.103085, l6: 0.232429\n",
      "\n",
      "[epoch: 381/400, batch: 352/1000, ite: 50420] train loss: 1.1174, accuracy: 97.0603%, tar: 0.0199 \n",
      "l0: 0.026595, l1: 0.029243, l2: 0.039565, l3: 0.065002, l4: 0.143302, l5: 0.272115, l6: 0.588181\n",
      "\n",
      "[epoch: 381/400, batch: 360/1000, ite: 50421] train loss: 1.1189, accuracy: 92.6551%, tar: 0.0199 \n",
      "l0: 0.014315, l1: 0.015729, l2: 0.021510, l3: 0.033453, l4: 0.063340, l5: 0.136596, l6: 0.304595\n",
      "\n",
      "[epoch: 381/400, batch: 368/1000, ite: 50422] train loss: 1.1184, accuracy: 96.1587%, tar: 0.0199 \n",
      "l0: 0.018864, l1: 0.020142, l2: 0.026661, l3: 0.042461, l4: 0.080315, l5: 0.172320, l6: 0.365812\n",
      "\n",
      "[epoch: 381/400, batch: 376/1000, ite: 50423] train loss: 1.1183, accuracy: 95.0644%, tar: 0.0199 \n",
      "l0: 0.019055, l1: 0.020333, l2: 0.028987, l3: 0.047992, l4: 0.095963, l5: 0.191170, l6: 0.406289\n",
      "\n",
      "[epoch: 381/400, batch: 384/1000, ite: 50424] train loss: 1.1186, accuracy: 94.8663%, tar: 0.0199 \n",
      "l0: 0.019807, l1: 0.021609, l2: 0.030380, l3: 0.049856, l4: 0.093711, l5: 0.205935, l6: 0.401570\n",
      "\n",
      "[epoch: 381/400, batch: 392/1000, ite: 50425] train loss: 1.1188, accuracy: 95.1690%, tar: 0.0199 \n",
      "l0: 0.018471, l1: 0.020478, l2: 0.030458, l3: 0.048699, l4: 0.081866, l5: 0.153341, l6: 0.315361\n",
      "\n",
      "[epoch: 381/400, batch: 400/1000, ite: 50426] train loss: 1.1185, accuracy: 95.9943%, tar: 0.0199 \n",
      "l0: 0.016369, l1: 0.017883, l2: 0.025466, l3: 0.042791, l4: 0.078951, l5: 0.141984, l6: 0.283268\n",
      "\n",
      "[epoch: 381/400, batch: 408/1000, ite: 50427] train loss: 1.1180, accuracy: 95.6913%, tar: 0.0198 \n",
      "l0: 0.020708, l1: 0.022253, l2: 0.029861, l3: 0.051020, l4: 0.101286, l5: 0.200624, l6: 0.405202\n",
      "\n",
      "[epoch: 381/400, batch: 416/1000, ite: 50428] train loss: 1.1183, accuracy: 93.9814%, tar: 0.0198 \n",
      "l0: 0.019443, l1: 0.020534, l2: 0.029951, l3: 0.045323, l4: 0.079863, l5: 0.154711, l6: 0.302310\n",
      "\n",
      "[epoch: 381/400, batch: 424/1000, ite: 50429] train loss: 1.1179, accuracy: 95.7149%, tar: 0.0198 \n",
      "l0: 0.025565, l1: 0.026917, l2: 0.034440, l3: 0.051722, l4: 0.098012, l5: 0.221249, l6: 0.493743\n",
      "\n",
      "[epoch: 381/400, batch: 432/1000, ite: 50430] train loss: 1.1187, accuracy: 92.8236%, tar: 0.0199 \n",
      "l0: 0.016649, l1: 0.018753, l2: 0.027781, l3: 0.052692, l4: 0.110540, l5: 0.200156, l6: 0.373678\n",
      "\n",
      "[epoch: 381/400, batch: 440/1000, ite: 50431] train loss: 1.1188, accuracy: 95.9148%, tar: 0.0198 \n",
      "l0: 0.020412, l1: 0.021201, l2: 0.028502, l3: 0.043053, l4: 0.080579, l5: 0.160307, l6: 0.349661\n",
      "\n",
      "[epoch: 381/400, batch: 448/1000, ite: 50432] train loss: 1.1187, accuracy: 94.8796%, tar: 0.0199 \n",
      "l0: 0.016814, l1: 0.017838, l2: 0.025146, l3: 0.038934, l4: 0.075270, l5: 0.137484, l6: 0.343267\n",
      "\n",
      "[epoch: 381/400, batch: 456/1000, ite: 50433] train loss: 1.1184, accuracy: 95.5346%, tar: 0.0198 \n",
      "l0: 0.017723, l1: 0.018800, l2: 0.025318, l3: 0.038366, l4: 0.072106, l5: 0.164042, l6: 0.351430\n",
      "\n",
      "[epoch: 381/400, batch: 464/1000, ite: 50434] train loss: 1.1182, accuracy: 95.0745%, tar: 0.0198 \n",
      "l0: 0.023320, l1: 0.024728, l2: 0.035382, l3: 0.051736, l4: 0.091934, l5: 0.234815, l6: 0.387335\n",
      "\n",
      "[epoch: 381/400, batch: 472/1000, ite: 50435] train loss: 1.1185, accuracy: 94.5368%, tar: 0.0198 \n",
      "l0: 0.023554, l1: 0.024661, l2: 0.033012, l3: 0.047102, l4: 0.073529, l5: 0.127156, l6: 0.318781\n",
      "\n",
      "[epoch: 381/400, batch: 480/1000, ite: 50436] train loss: 1.1182, accuracy: 95.0370%, tar: 0.0199 \n",
      "l0: 0.022140, l1: 0.023627, l2: 0.031696, l3: 0.049498, l4: 0.104815, l5: 0.220884, l6: 0.420915\n",
      "\n",
      "[epoch: 381/400, batch: 488/1000, ite: 50437] train loss: 1.1186, accuracy: 94.2590%, tar: 0.0199 \n",
      "l0: 0.024620, l1: 0.025919, l2: 0.035175, l3: 0.049528, l4: 0.087479, l5: 0.172937, l6: 0.352637\n",
      "\n",
      "[epoch: 381/400, batch: 496/1000, ite: 50438] train loss: 1.1186, accuracy: 94.3266%, tar: 0.0199 \n",
      "l0: 0.023219, l1: 0.024531, l2: 0.032764, l3: 0.047450, l4: 0.095242, l5: 0.189913, l6: 0.379662\n",
      "\n",
      "[epoch: 381/400, batch: 504/1000, ite: 50439] train loss: 1.1187, accuracy: 94.6866%, tar: 0.0199 \n",
      "l0: 0.015838, l1: 0.016608, l2: 0.022377, l3: 0.032214, l4: 0.054259, l5: 0.116605, l6: 0.314041\n",
      "\n",
      "[epoch: 381/400, batch: 512/1000, ite: 50440] train loss: 1.1181, accuracy: 96.0208%, tar: 0.0199 \n",
      "l0: 0.019052, l1: 0.021425, l2: 0.035014, l3: 0.059102, l4: 0.102573, l5: 0.213997, l6: 0.406273\n",
      "\n",
      "[epoch: 381/400, batch: 520/1000, ite: 50441] train loss: 1.1185, accuracy: 95.4414%, tar: 0.0199 \n",
      "l0: 0.017958, l1: 0.019270, l2: 0.027381, l3: 0.041925, l4: 0.071753, l5: 0.126722, l6: 0.275611\n",
      "\n",
      "l0: 0.014637, l1: 0.015916, l2: 0.022922, l3: 0.034728, l4: 0.064682, l5: 0.126022, l6: 0.281941\n",
      "\n",
      "[epoch: 381/400, batch: 544/1000, ite: 50444] train loss: 1.1169, accuracy: 96.0731%, tar: 0.0198 \n",
      "l0: 0.022988, l1: 0.023834, l2: 0.032109, l3: 0.047880, l4: 0.105580, l5: 0.202406, l6: 0.457271\n",
      "\n",
      "[epoch: 381/400, batch: 552/1000, ite: 50445] train loss: 1.1174, accuracy: 94.1253%, tar: 0.0198 \n",
      "l0: 0.024406, l1: 0.026042, l2: 0.035223, l3: 0.053380, l4: 0.104421, l5: 0.231129, l6: 0.476504\n",
      "\n",
      "[epoch: 381/400, batch: 560/1000, ite: 50446] train loss: 1.1181, accuracy: 93.9471%, tar: 0.0199 \n",
      "l0: 0.016372, l1: 0.017300, l2: 0.023129, l3: 0.037273, l4: 0.066243, l5: 0.120470, l6: 0.232224\n",
      "\n",
      "[epoch: 381/400, batch: 568/1000, ite: 50447] train loss: 1.1173, accuracy: 96.2946%, tar: 0.0199 \n",
      "l0: 0.021247, l1: 0.022704, l2: 0.030296, l3: 0.047614, l4: 0.098622, l5: 0.208341, l6: 0.403933\n",
      "\n",
      "[epoch: 381/400, batch: 576/1000, ite: 50448] train loss: 1.1176, accuracy: 94.0774%, tar: 0.0199 \n",
      "l0: 0.023367, l1: 0.025290, l2: 0.035625, l3: 0.064586, l4: 0.123965, l5: 0.230269, l6: 0.441234\n",
      "\n",
      "[epoch: 381/400, batch: 584/1000, ite: 50449] train loss: 1.1182, accuracy: 94.2712%, tar: 0.0199 \n",
      "l0: 0.020692, l1: 0.021819, l2: 0.030339, l3: 0.044826, l4: 0.079907, l5: 0.173517, l6: 0.348731\n",
      "\n",
      "[epoch: 381/400, batch: 592/1000, ite: 50450] train loss: 1.1181, accuracy: 94.7773%, tar: 0.0199 \n",
      "l0: 0.016342, l1: 0.018751, l2: 0.030705, l3: 0.054951, l4: 0.103162, l5: 0.214650, l6: 0.416039\n",
      "\n",
      "[epoch: 381/400, batch: 600/1000, ite: 50451] train loss: 1.1185, accuracy: 95.5569%, tar: 0.0199 \n",
      "l0: 0.021971, l1: 0.023627, l2: 0.031090, l3: 0.052992, l4: 0.095230, l5: 0.202225, l6: 0.373016\n",
      "\n",
      "[epoch: 381/400, batch: 608/1000, ite: 50452] train loss: 1.1186, accuracy: 94.4564%, tar: 0.0199 \n",
      "l0: 0.013113, l1: 0.014127, l2: 0.019566, l3: 0.031192, l4: 0.060798, l5: 0.124305, l6: 0.261018\n",
      "\n",
      "[epoch: 381/400, batch: 616/1000, ite: 50453] train loss: 1.1179, accuracy: 96.3251%, tar: 0.0198 \n",
      "l0: 0.014017, l1: 0.015005, l2: 0.021327, l3: 0.039156, l4: 0.073955, l5: 0.139485, l6: 0.276764\n",
      "\n",
      "[epoch: 381/400, batch: 624/1000, ite: 50454] train loss: 1.1173, accuracy: 96.4551%, tar: 0.0198 \n",
      "l0: 0.023990, l1: 0.024818, l2: 0.031802, l3: 0.045402, l4: 0.082966, l5: 0.163585, l6: 0.343066\n",
      "\n",
      "[epoch: 381/400, batch: 632/1000, ite: 50455] train loss: 1.1172, accuracy: 94.5391%, tar: 0.0198 \n",
      "l0: 0.021559, l1: 0.022359, l2: 0.029222, l3: 0.042078, l4: 0.071673, l5: 0.136831, l6: 0.292430\n",
      "\n",
      "[epoch: 381/400, batch: 640/1000, ite: 50456] train loss: 1.1167, accuracy: 95.8825%, tar: 0.0198 \n",
      "l0: 0.017137, l1: 0.018304, l2: 0.026157, l3: 0.037227, l4: 0.068321, l5: 0.140871, l6: 0.285044\n",
      "\n",
      "[epoch: 381/400, batch: 648/1000, ite: 50457] train loss: 1.1162, accuracy: 96.1097%, tar: 0.0198 \n",
      "l0: 0.029799, l1: 0.032065, l2: 0.043093, l3: 0.067330, l4: 0.130093, l5: 0.236308, l6: 0.530130\n",
      "\n",
      "[epoch: 381/400, batch: 656/1000, ite: 50458] train loss: 1.1172, accuracy: 93.1248%, tar: 0.0199 \n",
      "l0: 0.016167, l1: 0.018090, l2: 0.025507, l3: 0.040393, l4: 0.085669, l5: 0.176550, l6: 0.346742\n",
      "\n",
      "[epoch: 381/400, batch: 664/1000, ite: 50459] train loss: 1.1171, accuracy: 95.6105%, tar: 0.0199 \n",
      "l0: 0.014182, l1: 0.014792, l2: 0.020569, l3: 0.031750, l4: 0.061244, l5: 0.113709, l6: 0.259407\n",
      "\n",
      "[epoch: 381/400, batch: 672/1000, ite: 50460] train loss: 1.1164, accuracy: 96.0022%, tar: 0.0198 \n",
      "l0: 0.019081, l1: 0.020020, l2: 0.026403, l3: 0.042917, l4: 0.084378, l5: 0.154157, l6: 0.384469\n",
      "\n",
      "[epoch: 381/400, batch: 680/1000, ite: 50461] train loss: 1.1164, accuracy: 95.3901%, tar: 0.0198 \n",
      "l0: 0.015989, l1: 0.017463, l2: 0.025089, l3: 0.039644, l4: 0.071232, l5: 0.162507, l6: 0.341358\n",
      "\n",
      "[epoch: 381/400, batch: 688/1000, ite: 50462] train loss: 1.1162, accuracy: 95.7457%, tar: 0.0198 \n",
      "l0: 0.019074, l1: 0.020368, l2: 0.025892, l3: 0.036621, l4: 0.060274, l5: 0.128199, l6: 0.420175\n",
      "\n",
      "[epoch: 381/400, batch: 696/1000, ite: 50463] train loss: 1.1162, accuracy: 94.7568%, tar: 0.0198 \n",
      "l0: 0.018061, l1: 0.019196, l2: 0.027369, l3: 0.042058, l4: 0.074185, l5: 0.138960, l6: 0.298330\n",
      "\n",
      "[epoch: 381/400, batch: 704/1000, ite: 50464] train loss: 1.1158, accuracy: 95.4288%, tar: 0.0198 \n",
      "l0: 0.020381, l1: 0.021199, l2: 0.028433, l3: 0.046065, l4: 0.103080, l5: 0.231570, l6: 0.444774\n",
      "\n",
      "[epoch: 381/400, batch: 712/1000, ite: 50465] train loss: 1.1163, accuracy: 94.6150%, tar: 0.0198 \n",
      "l0: 0.017460, l1: 0.018655, l2: 0.026386, l3: 0.038598, l4: 0.076870, l5: 0.163048, l6: 0.352600\n",
      "\n",
      "[epoch: 381/400, batch: 720/1000, ite: 50466] train loss: 1.1161, accuracy: 95.2351%, tar: 0.0198 \n",
      "l0: 0.017696, l1: 0.018705, l2: 0.025084, l3: 0.037674, l4: 0.067134, l5: 0.150627, l6: 0.333943\n",
      "\n",
      "[epoch: 381/400, batch: 728/1000, ite: 50467] train loss: 1.1158, accuracy: 94.7951%, tar: 0.0198 \n",
      "l0: 0.019462, l1: 0.021629, l2: 0.030794, l3: 0.048260, l4: 0.091923, l5: 0.220483, l6: 0.411470\n",
      "\n",
      "[epoch: 381/400, batch: 736/1000, ite: 50468] train loss: 1.1161, accuracy: 94.6987%, tar: 0.0198 \n",
      "l0: 0.019249, l1: 0.020082, l2: 0.028559, l3: 0.043711, l4: 0.077294, l5: 0.170579, l6: 0.353620\n",
      "\n",
      "[epoch: 381/400, batch: 744/1000, ite: 50469] train loss: 1.1160, accuracy: 95.5134%, tar: 0.0198 \n",
      "l0: 0.019648, l1: 0.021340, l2: 0.029058, l3: 0.045496, l4: 0.099116, l5: 0.215579, l6: 0.424011\n",
      "\n",
      "[epoch: 381/400, batch: 752/1000, ite: 50470] train loss: 1.1164, accuracy: 94.6242%, tar: 0.0198 \n",
      "l0: 0.018637, l1: 0.020226, l2: 0.028983, l3: 0.045483, l4: 0.106441, l5: 0.183344, l6: 0.387241\n",
      "\n",
      "[epoch: 381/400, batch: 760/1000, ite: 50471] train loss: 1.1165, accuracy: 95.1934%, tar: 0.0198 \n",
      "l0: 0.018459, l1: 0.019772, l2: 0.025525, l3: 0.039163, l4: 0.073157, l5: 0.131201, l6: 0.316359\n",
      "\n",
      "[epoch: 381/400, batch: 768/1000, ite: 50472] train loss: 1.1162, accuracy: 95.4842%, tar: 0.0198 \n",
      "l0: 0.018735, l1: 0.019809, l2: 0.027406, l3: 0.039896, l4: 0.064021, l5: 0.138109, l6: 0.279043\n",
      "\n",
      "[epoch: 381/400, batch: 776/1000, ite: 50473] train loss: 1.1156, accuracy: 96.3844%, tar: 0.0198 \n",
      "l0: 0.019677, l1: 0.020709, l2: 0.028746, l3: 0.041438, l4: 0.072934, l5: 0.142088, l6: 0.328889\n",
      "\n",
      "[epoch: 381/400, batch: 784/1000, ite: 50474] train loss: 1.1154, accuracy: 95.3869%, tar: 0.0198 \n",
      "l0: 0.016680, l1: 0.017605, l2: 0.023840, l3: 0.036053, l4: 0.066220, l5: 0.134150, l6: 0.257548\n",
      "\n",
      "[epoch: 381/400, batch: 792/1000, ite: 50475] train loss: 1.1147, accuracy: 96.2193%, tar: 0.0198 \n",
      "l0: 0.020732, l1: 0.022073, l2: 0.032138, l3: 0.047619, l4: 0.084215, l5: 0.168469, l6: 0.339383\n",
      "\n",
      "[epoch: 381/400, batch: 800/1000, ite: 50476] train loss: 1.1146, accuracy: 94.9420%, tar: 0.0198 \n",
      "l0: 0.018694, l1: 0.019840, l2: 0.028481, l3: 0.044463, l4: 0.080987, l5: 0.150349, l6: 0.302805\n",
      "\n",
      "[epoch: 381/400, batch: 808/1000, ite: 50477] train loss: 1.1143, accuracy: 95.5636%, tar: 0.0198 \n",
      "l0: 0.019726, l1: 0.021339, l2: 0.031809, l3: 0.048783, l4: 0.089646, l5: 0.168882, l6: 0.343960\n",
      "\n",
      "[epoch: 381/400, batch: 816/1000, ite: 50478] train loss: 1.1142, accuracy: 95.5406%, tar: 0.0198 \n",
      "l0: 0.019106, l1: 0.020362, l2: 0.031491, l3: 0.055107, l4: 0.109351, l5: 0.213434, l6: 0.429649\n",
      "\n",
      "[epoch: 381/400, batch: 824/1000, ite: 50479] train loss: 1.1146, accuracy: 94.1869%, tar: 0.0198 \n",
      "l0: 0.015796, l1: 0.016590, l2: 0.023098, l3: 0.035383, l4: 0.064200, l5: 0.146699, l6: 0.313761\n",
      "\n",
      "[epoch: 381/400, batch: 832/1000, ite: 50480] train loss: 1.1142, accuracy: 95.8032%, tar: 0.0198 \n",
      "l0: 0.019237, l1: 0.020550, l2: 0.028271, l3: 0.043253, l4: 0.086874, l5: 0.203534, l6: 0.406438\n",
      "\n",
      "[epoch: 381/400, batch: 840/1000, ite: 50481] train loss: 1.1144, accuracy: 95.0372%, tar: 0.0198 \n",
      "l0: 0.021190, l1: 0.022783, l2: 0.030027, l3: 0.049679, l4: 0.093060, l5: 0.187842, l6: 0.367761\n",
      "\n",
      "[epoch: 381/400, batch: 848/1000, ite: 50482] train loss: 1.1145, accuracy: 94.6108%, tar: 0.0198 \n",
      "l0: 0.018667, l1: 0.019939, l2: 0.027263, l3: 0.041174, l4: 0.077783, l5: 0.175263, l6: 0.372637\n",
      "\n",
      "[epoch: 381/400, batch: 856/1000, ite: 50483] train loss: 1.1145, accuracy: 94.9068%, tar: 0.0198 \n",
      "l0: 0.014045, l1: 0.016084, l2: 0.023750, l3: 0.035327, l4: 0.067415, l5: 0.145576, l6: 0.269974\n",
      "\n",
      "[epoch: 381/400, batch: 864/1000, ite: 50484] train loss: 1.1139, accuracy: 96.9727%, tar: 0.0198 \n",
      "l0: 0.015830, l1: 0.016603, l2: 0.022874, l3: 0.034758, l4: 0.059407, l5: 0.117193, l6: 0.227153\n",
      "\n",
      "[epoch: 381/400, batch: 872/1000, ite: 50485] train loss: 1.1131, accuracy: 96.3877%, tar: 0.0198 \n",
      "l0: 0.024474, l1: 0.026544, l2: 0.037033, l3: 0.059746, l4: 0.119658, l5: 0.221345, l6: 0.418696\n",
      "\n",
      "[epoch: 381/400, batch: 880/1000, ite: 50486] train loss: 1.1135, accuracy: 94.0480%, tar: 0.0198 \n",
      "l0: 0.021396, l1: 0.022622, l2: 0.030816, l3: 0.046774, l4: 0.087980, l5: 0.172799, l6: 0.388396\n",
      "\n",
      "[epoch: 381/400, batch: 888/1000, ite: 50487] train loss: 1.1136, accuracy: 95.0986%, tar: 0.0198 \n",
      "l0: 0.018229, l1: 0.019016, l2: 0.026280, l3: 0.041201, l4: 0.082854, l5: 0.181034, l6: 0.392995\n",
      "\n",
      "[epoch: 381/400, batch: 896/1000, ite: 50488] train loss: 1.1137, accuracy: 94.9547%, tar: 0.0198 \n",
      "l0: 0.018526, l1: 0.019508, l2: 0.026748, l3: 0.037730, l4: 0.064537, l5: 0.159591, l6: 0.344590\n",
      "\n",
      "[epoch: 381/400, batch: 904/1000, ite: 50489] train loss: 1.1135, accuracy: 95.2435%, tar: 0.0198 \n",
      "l0: 0.019812, l1: 0.021540, l2: 0.029342, l3: 0.047389, l4: 0.086106, l5: 0.174014, l6: 0.344731\n",
      "\n",
      "[epoch: 381/400, batch: 912/1000, ite: 50490] train loss: 1.1134, accuracy: 95.3220%, tar: 0.0198 \n",
      "l0: 0.022222, l1: 0.023914, l2: 0.032661, l3: 0.050127, l4: 0.092810, l5: 0.231058, l6: 0.541186\n",
      "\n",
      "[epoch: 381/400, batch: 920/1000, ite: 50491] train loss: 1.1143, accuracy: 93.5711%, tar: 0.0198 \n",
      "l0: 0.020237, l1: 0.021308, l2: 0.030431, l3: 0.046840, l4: 0.087072, l5: 0.170218, l6: 0.343408\n",
      "\n",
      "[epoch: 381/400, batch: 928/1000, ite: 50492] train loss: 1.1142, accuracy: 94.9518%, tar: 0.0198 \n",
      "l0: 0.016688, l1: 0.018246, l2: 0.026303, l3: 0.041968, l4: 0.075133, l5: 0.134320, l6: 0.296493\n",
      "\n",
      "[epoch: 381/400, batch: 936/1000, ite: 50493] train loss: 1.1138, accuracy: 96.1219%, tar: 0.0198 \n",
      "l0: 0.021241, l1: 0.022627, l2: 0.030227, l3: 0.043023, l4: 0.074208, l5: 0.177512, l6: 0.347799\n",
      "\n",
      "[epoch: 381/400, batch: 944/1000, ite: 50494] train loss: 1.1137, accuracy: 95.1921%, tar: 0.0198 \n",
      "l0: 0.024160, l1: 0.026148, l2: 0.034665, l3: 0.051777, l4: 0.100287, l5: 0.191287, l6: 0.396273\n",
      "\n",
      "[epoch: 381/400, batch: 952/1000, ite: 50495] train loss: 1.1139, accuracy: 94.5525%, tar: 0.0198 \n",
      "l0: 0.021722, l1: 0.022918, l2: 0.031123, l3: 0.048749, l4: 0.096880, l5: 0.197326, l6: 0.376173\n",
      "\n",
      "[epoch: 381/400, batch: 960/1000, ite: 50496] train loss: 1.1140, accuracy: 94.8901%, tar: 0.0198 \n",
      "l0: 0.015686, l1: 0.017107, l2: 0.024972, l3: 0.040186, l4: 0.081905, l5: 0.175190, l6: 0.336347\n",
      "\n",
      "[epoch: 381/400, batch: 968/1000, ite: 50497] train loss: 1.1139, accuracy: 95.7120%, tar: 0.0198 \n",
      "l0: 0.021879, l1: 0.023286, l2: 0.030787, l3: 0.044326, l4: 0.076660, l5: 0.164602, l6: 0.314096\n",
      "\n",
      "[epoch: 381/400, batch: 976/1000, ite: 50498] train loss: 1.1136, accuracy: 96.2938%, tar: 0.0198 \n",
      "l0: 0.017894, l1: 0.018637, l2: 0.024120, l3: 0.036572, l4: 0.069077, l5: 0.140443, l6: 0.283421\n",
      "\n",
      "[epoch: 381/400, batch: 984/1000, ite: 50499] train loss: 1.1131, accuracy: 95.6526%, tar: 0.0198 \n",
      "l0: 0.018331, l1: 0.019826, l2: 0.026942, l3: 0.040482, l4: 0.076684, l5: 0.161826, l6: 0.314371\n",
      "\n",
      "[epoch: 381/400, batch: 992/1000, ite: 50500] train loss: 1.1129, accuracy: 95.4819%, tar: 0.0198 \n",
      "l0: 0.018673, l1: 0.020112, l2: 0.026151, l3: 0.040448, l4: 0.076366, l5: 0.171006, l6: 0.346931\n",
      "\n",
      "[epoch: 381/400, batch: 1000/1000, ite: 50501] train loss: 1.1127, accuracy: 95.3673%, tar: 0.0198 \n",
      "l0: 0.017834, l1: 0.019268, l2: 0.027761, l3: 0.045356, l4: 0.087683, l5: 0.176204, l6: 0.358018\n",
      "\n",
      "[epoch: 382/400, batch: 8/1000, ite: 50502] train loss: 1.1127, accuracy: 95.4793%, tar: 0.0198 \n",
      "l0: 0.018161, l1: 0.020948, l2: 0.031923, l3: 0.056037, l4: 0.109915, l5: 0.204531, l6: 0.383000\n",
      "\n",
      "[epoch: 382/400, batch: 16/1000, ite: 50503] train loss: 1.1129, accuracy: 95.8731%, tar: 0.0198 \n",
      "l0: 0.016511, l1: 0.017819, l2: 0.024764, l3: 0.038976, l4: 0.070758, l5: 0.157006, l6: 0.302721\n",
      "\n",
      "[epoch: 382/400, batch: 24/1000, ite: 50504] train loss: 1.1125, accuracy: 95.9358%, tar: 0.0198 \n",
      "l0: 0.020460, l1: 0.021994, l2: 0.031060, l3: 0.045620, l4: 0.077159, l5: 0.135414, l6: 0.301566\n",
      "\n",
      "[epoch: 382/400, batch: 32/1000, ite: 50505] train loss: 1.1122, accuracy: 95.6091%, tar: 0.0198 \n",
      "l0: 0.021950, l1: 0.024079, l2: 0.037910, l3: 0.062257, l4: 0.116094, l5: 0.245367, l6: 0.481099\n",
      "\n",
      "[epoch: 382/400, batch: 40/1000, ite: 50506] train loss: 1.1129, accuracy: 94.3781%, tar: 0.0198 \n",
      "l0: 0.021089, l1: 0.022357, l2: 0.028214, l3: 0.041800, l4: 0.083457, l5: 0.181190, l6: 0.354409\n",
      "\n",
      "[epoch: 382/400, batch: 48/1000, ite: 50507] train loss: 1.1129, accuracy: 94.3230%, tar: 0.0198 \n",
      "l0: 0.022461, l1: 0.024228, l2: 0.034201, l3: 0.050097, l4: 0.090050, l5: 0.175633, l6: 0.413023\n",
      "\n",
      "[epoch: 382/400, batch: 56/1000, ite: 50508] train loss: 1.1131, accuracy: 94.3880%, tar: 0.0198 \n",
      "l0: 0.018524, l1: 0.019866, l2: 0.028189, l3: 0.041497, l4: 0.073727, l5: 0.153480, l6: 0.333127\n",
      "\n",
      "[epoch: 382/400, batch: 64/1000, ite: 50509] train loss: 1.1129, accuracy: 95.7438%, tar: 0.0198 \n",
      "l0: 0.016130, l1: 0.017751, l2: 0.024637, l3: 0.038353, l4: 0.078102, l5: 0.177880, l6: 0.367213\n",
      "\n",
      "[epoch: 382/400, batch: 72/1000, ite: 50510] train loss: 1.1128, accuracy: 95.5467%, tar: 0.0198 \n",
      "l0: 0.020153, l1: 0.021426, l2: 0.028809, l3: 0.044142, l4: 0.079777, l5: 0.153650, l6: 0.354909\n",
      "\n",
      "[epoch: 382/400, batch: 80/1000, ite: 50511] train loss: 1.1127, accuracy: 95.3374%, tar: 0.0198 \n",
      "l0: 0.012345, l1: 0.014931, l2: 0.023016, l3: 0.039273, l4: 0.082235, l5: 0.176649, l6: 0.347439\n",
      "\n",
      "[epoch: 382/400, batch: 88/1000, ite: 50512] train loss: 1.1126, accuracy: 96.0176%, tar: 0.0198 \n",
      "l0: 0.017186, l1: 0.018452, l2: 0.025002, l3: 0.039944, l4: 0.078823, l5: 0.164723, l6: 0.328185\n",
      "\n",
      "[epoch: 382/400, batch: 96/1000, ite: 50513] train loss: 1.1124, accuracy: 95.0953%, tar: 0.0198 \n",
      "l0: 0.014978, l1: 0.015718, l2: 0.019670, l3: 0.029065, l4: 0.054464, l5: 0.109923, l6: 0.275857\n",
      "\n",
      "[epoch: 382/400, batch: 104/1000, ite: 50514] train loss: 1.1118, accuracy: 95.5808%, tar: 0.0197 \n",
      "l0: 0.017587, l1: 0.018436, l2: 0.026502, l3: 0.040049, l4: 0.071501, l5: 0.142246, l6: 0.387318\n",
      "\n",
      "[epoch: 382/400, batch: 112/1000, ite: 50515] train loss: 1.1117, accuracy: 94.7444%, tar: 0.0197 \n",
      "l0: 0.023159, l1: 0.024607, l2: 0.032930, l3: 0.051878, l4: 0.108359, l5: 0.196178, l6: 0.390100\n",
      "\n",
      "[epoch: 382/400, batch: 120/1000, ite: 50516] train loss: 1.1119, accuracy: 94.9296%, tar: 0.0197 \n",
      "l0: 0.016903, l1: 0.017569, l2: 0.024787, l3: 0.036353, l4: 0.062105, l5: 0.130780, l6: 0.270904\n",
      "\n",
      "[epoch: 382/400, batch: 128/1000, ite: 50517] train loss: 1.1114, accuracy: 95.7752%, tar: 0.0197 \n",
      "l0: 0.020108, l1: 0.021478, l2: 0.028459, l3: 0.047708, l4: 0.092059, l5: 0.203888, l6: 0.444704\n",
      "\n",
      "[epoch: 382/400, batch: 136/1000, ite: 50518] train loss: 1.1118, accuracy: 94.4892%, tar: 0.0197 \n",
      "l0: 0.014771, l1: 0.015897, l2: 0.022647, l3: 0.033625, l4: 0.060272, l5: 0.118891, l6: 0.265221\n",
      "\n",
      "[epoch: 382/400, batch: 144/1000, ite: 50519] train loss: 1.1112, accuracy: 96.6580%, tar: 0.0197 \n",
      "l0: 0.019105, l1: 0.019990, l2: 0.025885, l3: 0.037463, l4: 0.060152, l5: 0.111239, l6: 0.239678\n",
      "\n",
      "[epoch: 382/400, batch: 152/1000, ite: 50520] train loss: 1.1105, accuracy: 95.9361%, tar: 0.0197 \n",
      "l0: 0.017967, l1: 0.019108, l2: 0.024148, l3: 0.034925, l4: 0.061627, l5: 0.121544, l6: 0.253961\n",
      "\n",
      "[epoch: 382/400, batch: 160/1000, ite: 50521] train loss: 1.1099, accuracy: 95.8736%, tar: 0.0197 \n",
      "l0: 0.018725, l1: 0.020383, l2: 0.029377, l3: 0.048134, l4: 0.094102, l5: 0.219568, l6: 0.367681\n",
      "\n",
      "[epoch: 382/400, batch: 168/1000, ite: 50522] train loss: 1.1100, accuracy: 94.8742%, tar: 0.0197 \n",
      "l0: 0.021399, l1: 0.023209, l2: 0.032051, l3: 0.049633, l4: 0.097078, l5: 0.187303, l6: 0.355072\n",
      "\n",
      "[epoch: 382/400, batch: 176/1000, ite: 50523] train loss: 1.1100, accuracy: 95.4119%, tar: 0.0197 \n",
      "l0: 0.020047, l1: 0.021353, l2: 0.029598, l3: 0.046536, l4: 0.084786, l5: 0.170530, l6: 0.380717\n",
      "\n",
      "[epoch: 382/400, batch: 184/1000, ite: 50524] train loss: 1.1101, accuracy: 95.2434%, tar: 0.0197 \n",
      "l0: 0.013386, l1: 0.014159, l2: 0.018349, l3: 0.027459, l4: 0.053776, l5: 0.099112, l6: 0.222116\n",
      "\n",
      "[epoch: 382/400, batch: 192/1000, ite: 50525] train loss: 1.1092, accuracy: 96.6892%, tar: 0.0197 \n",
      "l0: 0.020525, l1: 0.021836, l2: 0.029960, l3: 0.045191, l4: 0.090896, l5: 0.182663, l6: 0.369630\n",
      "\n",
      "[epoch: 382/400, batch: 200/1000, ite: 50526] train loss: 1.1093, accuracy: 95.2513%, tar: 0.0197 \n",
      "l0: 0.016021, l1: 0.017159, l2: 0.025388, l3: 0.048815, l4: 0.133894, l5: 0.199989, l6: 0.373454\n",
      "\n",
      "[epoch: 382/400, batch: 208/1000, ite: 50527] train loss: 1.1094, accuracy: 95.3572%, tar: 0.0197 \n",
      "l0: 0.016675, l1: 0.018064, l2: 0.025071, l3: 0.041498, l4: 0.084888, l5: 0.166418, l6: 0.307141\n",
      "\n",
      "[epoch: 382/400, batch: 216/1000, ite: 50528] train loss: 1.1092, accuracy: 95.5259%, tar: 0.0197 \n",
      "l0: 0.018339, l1: 0.020443, l2: 0.029599, l3: 0.048278, l4: 0.105694, l5: 0.200567, l6: 0.353838\n",
      "\n",
      "[epoch: 382/400, batch: 224/1000, ite: 50529] train loss: 1.1092, accuracy: 95.7586%, tar: 0.0197 \n",
      "l0: 0.018251, l1: 0.020534, l2: 0.030939, l3: 0.050184, l4: 0.077911, l5: 0.138020, l6: 0.276197\n",
      "\n",
      "[epoch: 382/400, batch: 232/1000, ite: 50530] train loss: 1.1088, accuracy: 96.6733%, tar: 0.0197 \n",
      "l0: 0.018564, l1: 0.019856, l2: 0.028859, l3: 0.044038, l4: 0.073360, l5: 0.132521, l6: 0.259579\n",
      "\n",
      "[epoch: 382/400, batch: 240/1000, ite: 50531] train loss: 1.1083, accuracy: 95.9565%, tar: 0.0197 \n",
      "l0: 0.021426, l1: 0.023160, l2: 0.030668, l3: 0.048845, l4: 0.092008, l5: 0.197348, l6: 0.408356\n",
      "\n",
      "[epoch: 382/400, batch: 248/1000, ite: 50532] train loss: 1.1085, accuracy: 94.6528%, tar: 0.0197 \n",
      "l0: 0.031607, l1: 0.033379, l2: 0.042902, l3: 0.067340, l4: 0.141651, l5: 0.267769, l6: 0.513171\n",
      "\n",
      "[epoch: 382/400, batch: 256/1000, ite: 50533] train loss: 1.1095, accuracy: 93.1539%, tar: 0.0197 \n",
      "l0: 0.024510, l1: 0.025683, l2: 0.033121, l3: 0.047477, l4: 0.090076, l5: 0.194414, l6: 0.407363\n",
      "\n",
      "[epoch: 382/400, batch: 264/1000, ite: 50534] train loss: 1.1098, accuracy: 93.8427%, tar: 0.0197 \n",
      "l0: 0.021260, l1: 0.023370, l2: 0.031312, l3: 0.044598, l4: 0.086310, l5: 0.198302, l6: 0.378232\n",
      "\n",
      "[epoch: 382/400, batch: 272/1000, ite: 50535] train loss: 1.1099, accuracy: 95.0714%, tar: 0.0197 \n",
      "l0: 0.022962, l1: 0.024432, l2: 0.033656, l3: 0.052785, l4: 0.100175, l5: 0.197019, l6: 0.420802\n",
      "\n",
      "[epoch: 382/400, batch: 280/1000, ite: 50536] train loss: 1.1102, accuracy: 93.6449%, tar: 0.0197 \n",
      "l0: 0.023277, l1: 0.024336, l2: 0.030503, l3: 0.042277, l4: 0.078757, l5: 0.202967, l6: 0.395400\n",
      "\n",
      "[epoch: 382/400, batch: 288/1000, ite: 50537] train loss: 1.1103, accuracy: 93.8852%, tar: 0.0197 \n",
      "l0: 0.020300, l1: 0.021682, l2: 0.029625, l3: 0.048751, l4: 0.090075, l5: 0.182250, l6: 0.322008\n",
      "\n",
      "[epoch: 382/400, batch: 296/1000, ite: 50538] train loss: 1.1102, accuracy: 94.9833%, tar: 0.0197 \n",
      "l0: 0.021099, l1: 0.022730, l2: 0.030324, l3: 0.044978, l4: 0.093702, l5: 0.201280, l6: 0.389742\n",
      "\n",
      "[epoch: 382/400, batch: 304/1000, ite: 50539] train loss: 1.1104, accuracy: 95.2559%, tar: 0.0197 \n",
      "l0: 0.017944, l1: 0.020130, l2: 0.027320, l3: 0.043234, l4: 0.091894, l5: 0.211545, l6: 0.506737\n",
      "\n",
      "[epoch: 382/400, batch: 312/1000, ite: 50540] train loss: 1.1110, accuracy: 94.3725%, tar: 0.0197 \n",
      "l0: 0.017119, l1: 0.018257, l2: 0.025834, l3: 0.041685, l4: 0.078544, l5: 0.139639, l6: 0.267834\n",
      "\n",
      "[epoch: 382/400, batch: 320/1000, ite: 50541] train loss: 1.1105, accuracy: 95.8432%, tar: 0.0197 \n",
      "l0: 0.017369, l1: 0.018740, l2: 0.023528, l3: 0.038195, l4: 0.067723, l5: 0.154501, l6: 0.291803\n",
      "\n",
      "[epoch: 382/400, batch: 328/1000, ite: 50542] train loss: 1.1101, accuracy: 96.3937%, tar: 0.0197 \n",
      "l0: 0.018820, l1: 0.020309, l2: 0.027588, l3: 0.042115, l4: 0.078613, l5: 0.154607, l6: 0.334653\n",
      "\n",
      "[epoch: 382/400, batch: 336/1000, ite: 50543] train loss: 1.1099, accuracy: 95.6063%, tar: 0.0197 \n",
      "l0: 0.027366, l1: 0.029279, l2: 0.036333, l3: 0.052787, l4: 0.105526, l5: 0.264633, l6: 0.515728\n",
      "\n",
      "[epoch: 382/400, batch: 344/1000, ite: 50544] train loss: 1.1107, accuracy: 92.5572%, tar: 0.0197 \n",
      "l0: 0.018140, l1: 0.020743, l2: 0.030088, l3: 0.046786, l4: 0.078679, l5: 0.192781, l6: 0.399600\n",
      "\n",
      "[epoch: 382/400, batch: 352/1000, ite: 50545] train loss: 1.1109, accuracy: 95.7237%, tar: 0.0197 \n",
      "l0: 0.019373, l1: 0.021781, l2: 0.031784, l3: 0.054732, l4: 0.118837, l5: 0.231893, l6: 0.428138\n",
      "\n",
      "[epoch: 382/400, batch: 360/1000, ite: 50546] train loss: 1.1113, accuracy: 95.0142%, tar: 0.0197 \n",
      "l0: 0.019093, l1: 0.020183, l2: 0.027156, l3: 0.040103, l4: 0.070351, l5: 0.133654, l6: 0.274734\n",
      "\n",
      "[epoch: 382/400, batch: 368/1000, ite: 50547] train loss: 1.1109, accuracy: 95.4362%, tar: 0.0197 \n",
      "l0: 0.024545, l1: 0.025671, l2: 0.035250, l3: 0.050484, l4: 0.094692, l5: 0.212659, l6: 0.420887\n",
      "\n",
      "[epoch: 382/400, batch: 376/1000, ite: 50548] train loss: 1.1112, accuracy: 94.3834%, tar: 0.0198 \n",
      "l0: 0.017761, l1: 0.018689, l2: 0.024946, l3: 0.038681, l4: 0.070569, l5: 0.143610, l6: 0.338398\n",
      "\n",
      "[epoch: 382/400, batch: 384/1000, ite: 50549] train loss: 1.1110, accuracy: 95.2803%, tar: 0.0197 \n",
      "l0: 0.021410, l1: 0.022711, l2: 0.027887, l3: 0.041971, l4: 0.070876, l5: 0.127976, l6: 0.266178\n",
      "\n",
      "[epoch: 382/400, batch: 392/1000, ite: 50550] train loss: 1.1105, accuracy: 94.9714%, tar: 0.0198 \n",
      "l0: 0.018557, l1: 0.020131, l2: 0.026837, l3: 0.042112, l4: 0.099498, l5: 0.174727, l6: 0.376785\n",
      "\n",
      "[epoch: 382/400, batch: 400/1000, ite: 50551] train loss: 1.1105, accuracy: 95.1663%, tar: 0.0198 \n",
      "l0: 0.019614, l1: 0.020790, l2: 0.028766, l3: 0.043174, l4: 0.074053, l5: 0.159593, l6: 0.347975\n",
      "\n",
      "[epoch: 382/400, batch: 408/1000, ite: 50552] train loss: 1.1104, accuracy: 95.0639%, tar: 0.0198 \n",
      "l0: 0.020495, l1: 0.021675, l2: 0.030790, l3: 0.048055, l4: 0.096768, l5: 0.206554, l6: 0.380453\n",
      "\n",
      "[epoch: 382/400, batch: 416/1000, ite: 50553] train loss: 1.1106, accuracy: 95.0274%, tar: 0.0198 \n",
      "l0: 0.027691, l1: 0.029688, l2: 0.037971, l3: 0.058110, l4: 0.116863, l5: 0.244303, l6: 0.427407\n",
      "\n",
      "[epoch: 382/400, batch: 424/1000, ite: 50554] train loss: 1.1110, accuracy: 93.8953%, tar: 0.0198 \n",
      "l0: 0.023428, l1: 0.024647, l2: 0.032318, l3: 0.046838, l4: 0.076380, l5: 0.152752, l6: 0.332688\n",
      "\n",
      "[epoch: 382/400, batch: 432/1000, ite: 50555] train loss: 1.1109, accuracy: 94.6030%, tar: 0.0198 \n",
      "l0: 0.018520, l1: 0.019593, l2: 0.027873, l3: 0.042773, l4: 0.082387, l5: 0.219347, l6: 0.450697\n",
      "\n",
      "[epoch: 382/400, batch: 440/1000, ite: 50556] train loss: 1.1113, accuracy: 94.4035%, tar: 0.0198 \n",
      "l0: 0.028174, l1: 0.031427, l2: 0.044270, l3: 0.068499, l4: 0.138203, l5: 0.284537, l6: 0.542027\n",
      "\n",
      "[epoch: 382/400, batch: 448/1000, ite: 50557] train loss: 1.1123, accuracy: 93.3915%, tar: 0.0198 \n",
      "l0: 0.021707, l1: 0.022402, l2: 0.029879, l3: 0.045044, l4: 0.080274, l5: 0.154651, l6: 0.358861\n",
      "\n",
      "[epoch: 382/400, batch: 456/1000, ite: 50558] train loss: 1.1122, accuracy: 94.9262%, tar: 0.0198 \n",
      "l0: 0.022053, l1: 0.023177, l2: 0.030269, l3: 0.045401, l4: 0.085756, l5: 0.189243, l6: 0.355363\n",
      "\n",
      "[epoch: 382/400, batch: 464/1000, ite: 50559] train loss: 1.1122, accuracy: 95.1846%, tar: 0.0198 \n",
      "l0: 0.016455, l1: 0.017859, l2: 0.026791, l3: 0.043595, l4: 0.086912, l5: 0.185150, l6: 0.399370\n",
      "\n",
      "[epoch: 382/400, batch: 472/1000, ite: 50560] train loss: 1.1123, accuracy: 96.0361%, tar: 0.0198 \n",
      "l0: 0.025551, l1: 0.027247, l2: 0.035872, l3: 0.055540, l4: 0.113117, l5: 0.223909, l6: 0.435242\n",
      "\n",
      "[epoch: 382/400, batch: 480/1000, ite: 50561] train loss: 1.1128, accuracy: 94.2091%, tar: 0.0198 \n",
      "l0: 0.021395, l1: 0.023147, l2: 0.032768, l3: 0.050952, l4: 0.098446, l5: 0.184622, l6: 0.425701\n",
      "\n",
      "[epoch: 382/400, batch: 488/1000, ite: 50562] train loss: 1.1130, accuracy: 94.3325%, tar: 0.0198 \n",
      "l0: 0.021997, l1: 0.023617, l2: 0.033288, l3: 0.047158, l4: 0.090315, l5: 0.173943, l6: 0.456982\n",
      "\n",
      "[epoch: 382/400, batch: 496/1000, ite: 50563] train loss: 1.1134, accuracy: 94.3212%, tar: 0.0198 \n",
      "l0: 0.019614, l1: 0.020961, l2: 0.029154, l3: 0.044052, l4: 0.080761, l5: 0.169253, l6: 0.357912\n",
      "\n",
      "[epoch: 382/400, batch: 504/1000, ite: 50564] train loss: 1.1133, accuracy: 95.8970%, tar: 0.0198 \n",
      "l0: 0.018920, l1: 0.020714, l2: 0.027762, l3: 0.043709, l4: 0.092361, l5: 0.169692, l6: 0.315266\n",
      "\n",
      "[epoch: 382/400, batch: 512/1000, ite: 50565] train loss: 1.1131, accuracy: 95.7770%, tar: 0.0198 \n",
      "l0: 0.016963, l1: 0.017801, l2: 0.025981, l3: 0.041598, l4: 0.075326, l5: 0.132724, l6: 0.290423\n",
      "\n",
      "[epoch: 382/400, batch: 520/1000, ite: 50566] train loss: 1.1127, accuracy: 95.6271%, tar: 0.0198 \n",
      "l0: 0.023232, l1: 0.024933, l2: 0.034371, l3: 0.054613, l4: 0.102343, l5: 0.172645, l6: 0.337220\n",
      "\n",
      "[epoch: 382/400, batch: 528/1000, ite: 50567] train loss: 1.1127, accuracy: 94.9434%, tar: 0.0198 \n",
      "l0: 0.023209, l1: 0.024007, l2: 0.029751, l3: 0.044367, l4: 0.076729, l5: 0.142928, l6: 0.283223\n",
      "\n",
      "[epoch: 382/400, batch: 536/1000, ite: 50568] train loss: 1.1123, accuracy: 95.3851%, tar: 0.0198 \n",
      "l0: 0.017059, l1: 0.017706, l2: 0.023970, l3: 0.034142, l4: 0.058263, l5: 0.105398, l6: 0.253240\n",
      "\n",
      "[epoch: 382/400, batch: 544/1000, ite: 50569] train loss: 1.1117, accuracy: 96.0852%, tar: 0.0198 \n",
      "l0: 0.016424, l1: 0.018247, l2: 0.026522, l3: 0.044947, l4: 0.088161, l5: 0.171560, l6: 0.371156\n",
      "\n",
      "[epoch: 382/400, batch: 552/1000, ite: 50570] train loss: 1.1117, accuracy: 95.0342%, tar: 0.0198 \n",
      "l0: 0.020811, l1: 0.021859, l2: 0.030418, l3: 0.045538, l4: 0.094685, l5: 0.216371, l6: 0.415587\n",
      "\n",
      "[epoch: 382/400, batch: 560/1000, ite: 50571] train loss: 1.1120, accuracy: 94.0955%, tar: 0.0198 \n",
      "l0: 0.016748, l1: 0.018119, l2: 0.025162, l3: 0.038358, l4: 0.078161, l5: 0.174613, l6: 0.291309\n",
      "\n",
      "[epoch: 382/400, batch: 568/1000, ite: 50572] train loss: 1.1117, accuracy: 96.2576%, tar: 0.0198 \n",
      "l0: 0.021875, l1: 0.023829, l2: 0.032209, l3: 0.052416, l4: 0.103131, l5: 0.209217, l6: 0.489051\n",
      "\n",
      "[epoch: 382/400, batch: 576/1000, ite: 50573] train loss: 1.1122, accuracy: 94.1687%, tar: 0.0198 \n",
      "l0: 0.020691, l1: 0.022188, l2: 0.031486, l3: 0.049487, l4: 0.084026, l5: 0.184599, l6: 0.407055\n",
      "\n",
      "[epoch: 382/400, batch: 584/1000, ite: 50574] train loss: 1.1124, accuracy: 94.6245%, tar: 0.0198 \n",
      "l0: 0.019320, l1: 0.020801, l2: 0.027988, l3: 0.043072, l4: 0.085867, l5: 0.192879, l6: 0.461765\n",
      "\n",
      "[epoch: 382/400, batch: 592/1000, ite: 50575] train loss: 1.1127, accuracy: 94.7960%, tar: 0.0198 \n",
      "l0: 0.016231, l1: 0.017267, l2: 0.022304, l3: 0.033250, l4: 0.060839, l5: 0.134657, l6: 0.360356\n",
      "\n",
      "[epoch: 382/400, batch: 600/1000, ite: 50576] train loss: 1.1126, accuracy: 95.4093%, tar: 0.0198 \n",
      "l0: 0.023822, l1: 0.025017, l2: 0.033867, l3: 0.049332, l4: 0.089795, l5: 0.165562, l6: 0.414646\n",
      "\n",
      "[epoch: 382/400, batch: 608/1000, ite: 50577] train loss: 1.1127, accuracy: 94.2394%, tar: 0.0198 \n",
      "l0: 0.024129, l1: 0.025127, l2: 0.032693, l3: 0.046912, l4: 0.083802, l5: 0.161538, l6: 0.373195\n",
      "\n",
      "[epoch: 382/400, batch: 616/1000, ite: 50578] train loss: 1.1127, accuracy: 94.0356%, tar: 0.0198 \n",
      "l0: 0.016203, l1: 0.017490, l2: 0.025416, l3: 0.040827, l4: 0.082617, l5: 0.143685, l6: 0.305378\n",
      "\n",
      "[epoch: 382/400, batch: 624/1000, ite: 50579] train loss: 1.1125, accuracy: 96.0155%, tar: 0.0198 \n",
      "l0: 0.018506, l1: 0.019934, l2: 0.027489, l3: 0.041662, l4: 0.079610, l5: 0.177833, l6: 0.365211\n",
      "\n",
      "[epoch: 382/400, batch: 632/1000, ite: 50580] train loss: 1.1124, accuracy: 94.9162%, tar: 0.0198 \n",
      "l0: 0.014684, l1: 0.016008, l2: 0.022974, l3: 0.035393, l4: 0.066186, l5: 0.117123, l6: 0.264466\n",
      "\n",
      "[epoch: 382/400, batch: 640/1000, ite: 50581] train loss: 1.1119, accuracy: 96.3069%, tar: 0.0198 \n",
      "l0: 0.017008, l1: 0.018553, l2: 0.026932, l3: 0.040983, l4: 0.086789, l5: 0.178273, l6: 0.323388\n",
      "\n",
      "[epoch: 382/400, batch: 648/1000, ite: 50582] train loss: 1.1118, accuracy: 95.7456%, tar: 0.0198 \n",
      "l0: 0.018288, l1: 0.019608, l2: 0.028438, l3: 0.044351, l4: 0.077239, l5: 0.145228, l6: 0.290562\n",
      "\n",
      "[epoch: 382/400, batch: 656/1000, ite: 50583] train loss: 1.1114, accuracy: 95.9394%, tar: 0.0198 \n",
      "l0: 0.021412, l1: 0.022256, l2: 0.028191, l3: 0.040995, l4: 0.075818, l5: 0.157476, l6: 0.328215\n",
      "\n",
      "[epoch: 382/400, batch: 664/1000, ite: 50584] train loss: 1.1112, accuracy: 95.0214%, tar: 0.0198 \n",
      "l0: 0.018281, l1: 0.019858, l2: 0.027418, l3: 0.045494, l4: 0.088393, l5: 0.182372, l6: 0.405226\n",
      "\n",
      "[epoch: 382/400, batch: 672/1000, ite: 50585] train loss: 1.1114, accuracy: 94.7110%, tar: 0.0198 \n",
      "l0: 0.017868, l1: 0.019441, l2: 0.028301, l3: 0.045348, l4: 0.079880, l5: 0.155436, l6: 0.381681\n",
      "\n",
      "[epoch: 382/400, batch: 680/1000, ite: 50586] train loss: 1.1114, accuracy: 95.4592%, tar: 0.0198 \n",
      "l0: 0.017398, l1: 0.019301, l2: 0.025647, l3: 0.043628, l4: 0.087723, l5: 0.184861, l6: 0.323688\n",
      "\n",
      "[epoch: 382/400, batch: 688/1000, ite: 50587] train loss: 1.1112, accuracy: 95.6786%, tar: 0.0198 \n",
      "l0: 0.015761, l1: 0.017297, l2: 0.025301, l3: 0.038321, l4: 0.069572, l5: 0.134862, l6: 0.261034\n",
      "\n",
      "[epoch: 382/400, batch: 696/1000, ite: 50588] train loss: 1.1107, accuracy: 97.1870%, tar: 0.0198 \n",
      "l0: 0.017191, l1: 0.018066, l2: 0.023611, l3: 0.034411, l4: 0.058878, l5: 0.122153, l6: 0.256666\n",
      "\n",
      "[epoch: 382/400, batch: 704/1000, ite: 50589] train loss: 1.1102, accuracy: 95.7206%, tar: 0.0198 \n",
      "l0: 0.018065, l1: 0.020016, l2: 0.030329, l3: 0.049678, l4: 0.093826, l5: 0.188787, l6: 0.358745\n",
      "\n",
      "[epoch: 382/400, batch: 712/1000, ite: 50590] train loss: 1.1102, accuracy: 95.3315%, tar: 0.0198 \n",
      "l0: 0.022016, l1: 0.023793, l2: 0.033279, l3: 0.052176, l4: 0.093858, l5: 0.211308, l6: 0.399066\n",
      "\n",
      "[epoch: 382/400, batch: 720/1000, ite: 50591] train loss: 1.1105, accuracy: 94.2169%, tar: 0.0198 \n",
      "l0: 0.017506, l1: 0.018487, l2: 0.025376, l3: 0.035426, l4: 0.061077, l5: 0.133288, l6: 0.259013\n",
      "\n",
      "[epoch: 382/400, batch: 728/1000, ite: 50592] train loss: 1.1100, accuracy: 95.9433%, tar: 0.0198 \n",
      "l0: 0.023776, l1: 0.025326, l2: 0.034064, l3: 0.047386, l4: 0.091132, l5: 0.197760, l6: 0.405616\n",
      "\n",
      "[epoch: 382/400, batch: 736/1000, ite: 50593] train loss: 1.1102, accuracy: 94.7583%, tar: 0.0198 \n",
      "l0: 0.017875, l1: 0.019340, l2: 0.027378, l3: 0.044456, l4: 0.116851, l5: 0.218249, l6: 0.391024\n",
      "\n",
      "[epoch: 382/400, batch: 744/1000, ite: 50594] train loss: 1.1104, accuracy: 94.5006%, tar: 0.0198 \n",
      "l0: 0.023845, l1: 0.024689, l2: 0.032286, l3: 0.045561, l4: 0.086954, l5: 0.228377, l6: 0.458330\n",
      "\n",
      "[epoch: 382/400, batch: 752/1000, ite: 50595] train loss: 1.1108, accuracy: 93.5959%, tar: 0.0198 \n",
      "l0: 0.025775, l1: 0.027143, l2: 0.033713, l3: 0.044895, l4: 0.077305, l5: 0.145320, l6: 0.358478\n",
      "\n",
      "[epoch: 382/400, batch: 760/1000, ite: 50596] train loss: 1.1107, accuracy: 94.7903%, tar: 0.0198 \n",
      "l0: 0.023317, l1: 0.025049, l2: 0.036918, l3: 0.054357, l4: 0.100644, l5: 0.236067, l6: 0.480686\n",
      "\n",
      "[epoch: 382/400, batch: 768/1000, ite: 50597] train loss: 1.1113, accuracy: 94.1550%, tar: 0.0198 \n",
      "l0: 0.020486, l1: 0.022196, l2: 0.031928, l3: 0.048863, l4: 0.089165, l5: 0.184049, l6: 0.392494\n",
      "\n",
      "[epoch: 382/400, batch: 776/1000, ite: 50598] train loss: 1.1114, accuracy: 95.2127%, tar: 0.0198 \n",
      "l0: 0.017995, l1: 0.018905, l2: 0.028109, l3: 0.042549, l4: 0.078510, l5: 0.153783, l6: 0.424040\n",
      "\n",
      "[epoch: 382/400, batch: 784/1000, ite: 50599] train loss: 1.1115, accuracy: 94.7640%, tar: 0.0198 \n",
      "l0: 0.027018, l1: 0.028787, l2: 0.037781, l3: 0.055518, l4: 0.109952, l5: 0.248313, l6: 0.548306\n",
      "\n",
      "[epoch: 382/400, batch: 792/1000, ite: 50600] train loss: 1.1124, accuracy: 93.5555%, tar: 0.0198 \n",
      "l0: 0.017797, l1: 0.018885, l2: 0.027192, l3: 0.038375, l4: 0.066302, l5: 0.135511, l6: 0.326037\n",
      "\n",
      "[epoch: 382/400, batch: 800/1000, ite: 50601] train loss: 1.1121, accuracy: 95.6505%, tar: 0.0198 \n",
      "l0: 0.021709, l1: 0.023419, l2: 0.032090, l3: 0.051730, l4: 0.102460, l5: 0.219293, l6: 0.442509\n",
      "\n",
      "[epoch: 382/400, batch: 808/1000, ite: 50602] train loss: 1.1125, accuracy: 95.1960%, tar: 0.0198 \n",
      "l0: 0.019588, l1: 0.021715, l2: 0.033909, l3: 0.061301, l4: 0.128361, l5: 0.259859, l6: 0.491115\n",
      "\n",
      "[epoch: 382/400, batch: 816/1000, ite: 50603] train loss: 1.1131, accuracy: 95.2632%, tar: 0.0198 \n",
      "l0: 0.024500, l1: 0.027235, l2: 0.038397, l3: 0.060868, l4: 0.115627, l5: 0.258378, l6: 0.564723\n",
      "\n",
      "[epoch: 382/400, batch: 824/1000, ite: 50604] train loss: 1.1140, accuracy: 93.2589%, tar: 0.0198 \n",
      "l0: 0.019351, l1: 0.020815, l2: 0.027914, l3: 0.047959, l4: 0.096173, l5: 0.216798, l6: 0.451241\n",
      "\n",
      "[epoch: 382/400, batch: 832/1000, ite: 50605] train loss: 1.1144, accuracy: 94.1305%, tar: 0.0198 \n",
      "l0: 0.018691, l1: 0.019499, l2: 0.027127, l3: 0.040359, l4: 0.064418, l5: 0.137664, l6: 0.319090\n",
      "\n",
      "[epoch: 382/400, batch: 840/1000, ite: 50606] train loss: 1.1141, accuracy: 95.4172%, tar: 0.0198 \n",
      "l0: 0.022785, l1: 0.024076, l2: 0.032124, l3: 0.048112, l4: 0.096026, l5: 0.223708, l6: 0.515366\n",
      "\n",
      "[epoch: 382/400, batch: 848/1000, ite: 50607] train loss: 1.1147, accuracy: 92.9575%, tar: 0.0198 \n",
      "l0: 0.025561, l1: 0.027739, l2: 0.037242, l3: 0.057202, l4: 0.117924, l5: 0.274423, l6: 0.595765\n",
      "\n",
      "[epoch: 382/400, batch: 856/1000, ite: 50608] train loss: 1.1157, accuracy: 92.8707%, tar: 0.0198 \n",
      "l0: 0.019123, l1: 0.020022, l2: 0.025549, l3: 0.035674, l4: 0.061134, l5: 0.118559, l6: 0.299454\n",
      "\n",
      "[epoch: 382/400, batch: 864/1000, ite: 50609] train loss: 1.1154, accuracy: 95.2941%, tar: 0.0198 \n",
      "l0: 0.024133, l1: 0.025200, l2: 0.032993, l3: 0.047198, l4: 0.084865, l5: 0.169529, l6: 0.378800\n",
      "\n",
      "[epoch: 382/400, batch: 872/1000, ite: 50610] train loss: 1.1154, accuracy: 94.1522%, tar: 0.0198 \n",
      "l0: 0.016408, l1: 0.017724, l2: 0.023849, l3: 0.038272, l4: 0.067988, l5: 0.114098, l6: 0.216236\n",
      "\n",
      "[epoch: 382/400, batch: 880/1000, ite: 50611] train loss: 1.1147, accuracy: 97.3381%, tar: 0.0198 \n",
      "l0: 0.021256, l1: 0.022486, l2: 0.029710, l3: 0.041693, l4: 0.065051, l5: 0.121042, l6: 0.283506\n",
      "\n",
      "[epoch: 382/400, batch: 888/1000, ite: 50612] train loss: 1.1144, accuracy: 95.7823%, tar: 0.0198 \n",
      "l0: 0.018237, l1: 0.019495, l2: 0.027188, l3: 0.041244, l4: 0.084451, l5: 0.178622, l6: 0.319609\n",
      "\n",
      "[epoch: 382/400, batch: 896/1000, ite: 50613] train loss: 1.1142, accuracy: 95.7453%, tar: 0.0198 \n",
      "l0: 0.020826, l1: 0.021774, l2: 0.028217, l3: 0.042636, l4: 0.072038, l5: 0.132427, l6: 0.301390\n",
      "\n",
      "[epoch: 382/400, batch: 904/1000, ite: 50614] train loss: 1.1139, accuracy: 95.2165%, tar: 0.0198 \n",
      "l0: 0.020561, l1: 0.022191, l2: 0.031637, l3: 0.046852, l4: 0.092788, l5: 0.204005, l6: 0.366097\n",
      "\n",
      "[epoch: 382/400, batch: 912/1000, ite: 50615] train loss: 1.1140, accuracy: 94.8201%, tar: 0.0198 \n",
      "l0: 0.025628, l1: 0.026618, l2: 0.034919, l3: 0.054769, l4: 0.103108, l5: 0.210511, l6: 0.411670\n",
      "\n",
      "[epoch: 382/400, batch: 920/1000, ite: 50616] train loss: 1.1142, accuracy: 93.8840%, tar: 0.0198 \n",
      "l0: 0.019450, l1: 0.020699, l2: 0.027520, l3: 0.039701, l4: 0.080465, l5: 0.188322, l6: 0.409887\n",
      "\n",
      "[epoch: 382/400, batch: 928/1000, ite: 50617] train loss: 1.1144, accuracy: 95.1003%, tar: 0.0198 \n",
      "l0: 0.020699, l1: 0.021727, l2: 0.029587, l3: 0.046141, l4: 0.088922, l5: 0.165792, l6: 0.339753\n",
      "\n",
      "[epoch: 382/400, batch: 936/1000, ite: 50618] train loss: 1.1143, accuracy: 94.6482%, tar: 0.0198 \n",
      "l0: 0.018752, l1: 0.019600, l2: 0.026461, l3: 0.039336, l4: 0.078563, l5: 0.184247, l6: 0.359892\n",
      "\n",
      "[epoch: 382/400, batch: 944/1000, ite: 50619] train loss: 1.1142, accuracy: 95.0451%, tar: 0.0198 \n",
      "l0: 0.023189, l1: 0.024778, l2: 0.031301, l3: 0.047173, l4: 0.098327, l5: 0.196759, l6: 0.375368\n",
      "\n",
      "[epoch: 382/400, batch: 952/1000, ite: 50620] train loss: 1.1143, accuracy: 94.9745%, tar: 0.0198 \n",
      "l0: 0.019164, l1: 0.020495, l2: 0.027629, l3: 0.040294, l4: 0.076120, l5: 0.141120, l6: 0.308529\n",
      "\n",
      "[epoch: 382/400, batch: 960/1000, ite: 50621] train loss: 1.1141, accuracy: 95.9441%, tar: 0.0198 \n",
      "l0: 0.016925, l1: 0.018286, l2: 0.026175, l3: 0.039846, l4: 0.071738, l5: 0.137693, l6: 0.305885\n",
      "\n",
      "[epoch: 382/400, batch: 968/1000, ite: 50622] train loss: 1.1138, accuracy: 95.9316%, tar: 0.0198 \n",
      "l0: 0.014983, l1: 0.016109, l2: 0.021807, l3: 0.034286, l4: 0.059683, l5: 0.108223, l6: 0.259388\n",
      "\n",
      "[epoch: 382/400, batch: 976/1000, ite: 50623] train loss: 1.1132, accuracy: 96.0425%, tar: 0.0198 \n",
      "l0: 0.016682, l1: 0.017286, l2: 0.023357, l3: 0.036205, l4: 0.072414, l5: 0.149930, l6: 0.336173\n",
      "\n",
      "[epoch: 382/400, batch: 984/1000, ite: 50624] train loss: 1.1130, accuracy: 95.3084%, tar: 0.0198 \n",
      "l0: 0.020577, l1: 0.022140, l2: 0.030759, l3: 0.049574, l4: 0.093492, l5: 0.197226, l6: 0.406594\n",
      "\n",
      "[epoch: 382/400, batch: 992/1000, ite: 50625] train loss: 1.1132, accuracy: 94.8942%, tar: 0.0198 \n",
      "l0: 0.016940, l1: 0.017892, l2: 0.025469, l3: 0.038596, l4: 0.072886, l5: 0.154994, l6: 0.368320\n",
      "\n",
      "[epoch: 382/400, batch: 1000/1000, ite: 50626] train loss: 1.1131, accuracy: 94.5960%, tar: 0.0198 \n",
      "l0: 0.013540, l1: 0.014438, l2: 0.020815, l3: 0.031277, l4: 0.062971, l5: 0.153912, l6: 0.372544\n",
      "\n",
      "[epoch: 383/400, batch: 8/1000, ite: 50627] train loss: 1.1130, accuracy: 96.1224%, tar: 0.0198 \n",
      "l0: 0.023741, l1: 0.024531, l2: 0.033060, l3: 0.048180, l4: 0.082312, l5: 0.185125, l6: 0.381375\n",
      "\n",
      "[epoch: 383/400, batch: 16/1000, ite: 50628] train loss: 1.1131, accuracy: 93.9658%, tar: 0.0198 \n",
      "l0: 0.017329, l1: 0.018472, l2: 0.026181, l3: 0.039894, l4: 0.078555, l5: 0.161725, l6: 0.359648\n",
      "\n",
      "[epoch: 383/400, batch: 24/1000, ite: 50629] train loss: 1.1130, accuracy: 94.9921%, tar: 0.0198 \n",
      "l0: 0.020394, l1: 0.021544, l2: 0.030405, l3: 0.042437, l4: 0.075766, l5: 0.154567, l6: 0.293031\n",
      "\n",
      "[epoch: 383/400, batch: 32/1000, ite: 50630] train loss: 1.1127, accuracy: 95.8459%, tar: 0.0198 \n",
      "l0: 0.018224, l1: 0.019470, l2: 0.028035, l3: 0.044953, l4: 0.093575, l5: 0.200520, l6: 0.441633\n",
      "\n",
      "[epoch: 383/400, batch: 40/1000, ite: 50631] train loss: 1.1130, accuracy: 94.9271%, tar: 0.0198 \n",
      "l0: 0.016155, l1: 0.017160, l2: 0.023982, l3: 0.035630, l4: 0.074601, l5: 0.144058, l6: 0.303547\n",
      "\n",
      "[epoch: 383/400, batch: 48/1000, ite: 50632] train loss: 1.1127, accuracy: 95.2197%, tar: 0.0198 \n",
      "l0: 0.020962, l1: 0.022957, l2: 0.032102, l3: 0.050926, l4: 0.100799, l5: 0.234513, l6: 0.520787\n",
      "\n",
      "[epoch: 383/400, batch: 56/1000, ite: 50633] train loss: 1.1133, accuracy: 94.1858%, tar: 0.0198 \n",
      "l0: 0.018610, l1: 0.019829, l2: 0.027531, l3: 0.042552, l4: 0.078611, l5: 0.172246, l6: 0.354926\n",
      "\n",
      "[epoch: 383/400, batch: 64/1000, ite: 50634] train loss: 1.1133, accuracy: 95.6531%, tar: 0.0198 \n",
      "l0: 0.016995, l1: 0.018996, l2: 0.027890, l3: 0.047680, l4: 0.082698, l5: 0.182034, l6: 0.309395\n",
      "\n",
      "[epoch: 383/400, batch: 72/1000, ite: 50635] train loss: 1.1131, accuracy: 96.4241%, tar: 0.0198 \n",
      "l0: 0.013185, l1: 0.014511, l2: 0.020281, l3: 0.032013, l4: 0.054657, l5: 0.092092, l6: 0.200637\n",
      "\n",
      "[epoch: 383/400, batch: 80/1000, ite: 50636] train loss: 1.1123, accuracy: 96.8604%, tar: 0.0198 \n",
      "l0: 0.019317, l1: 0.021851, l2: 0.033678, l3: 0.055669, l4: 0.112666, l5: 0.269506, l6: 0.491685\n",
      "\n",
      "[epoch: 383/400, batch: 88/1000, ite: 50637] train loss: 1.1129, accuracy: 94.6979%, tar: 0.0198 \n",
      "l0: 0.015627, l1: 0.016884, l2: 0.024102, l3: 0.038154, l4: 0.066985, l5: 0.126852, l6: 0.252600\n",
      "\n",
      "[epoch: 383/400, batch: 96/1000, ite: 50638] train loss: 1.1124, accuracy: 96.3841%, tar: 0.0198 \n",
      "l0: 0.019750, l1: 0.021068, l2: 0.028406, l3: 0.043273, l4: 0.110362, l5: 0.215103, l6: 0.450147\n",
      "\n",
      "[epoch: 383/400, batch: 104/1000, ite: 50639] train loss: 1.1128, accuracy: 94.2355%, tar: 0.0198 \n",
      "l0: 0.021309, l1: 0.023166, l2: 0.032503, l3: 0.050375, l4: 0.092005, l5: 0.211394, l6: 0.422602\n",
      "\n",
      "[epoch: 383/400, batch: 112/1000, ite: 50640] train loss: 1.1131, accuracy: 95.3552%, tar: 0.0198 \n",
      "l0: 0.019652, l1: 0.020879, l2: 0.029446, l3: 0.046839, l4: 0.092795, l5: 0.191891, l6: 0.462916\n",
      "\n",
      "[epoch: 383/400, batch: 120/1000, ite: 50641] train loss: 1.1134, accuracy: 94.1319%, tar: 0.0198 \n",
      "l0: 0.017966, l1: 0.018927, l2: 0.027399, l3: 0.039572, l4: 0.066988, l5: 0.144250, l6: 0.292724\n",
      "\n",
      "[epoch: 383/400, batch: 128/1000, ite: 50642] train loss: 1.1131, accuracy: 95.6617%, tar: 0.0198 \n",
      "l0: 0.017551, l1: 0.018570, l2: 0.027114, l3: 0.039760, l4: 0.069348, l5: 0.148019, l6: 0.349652\n",
      "\n",
      "[epoch: 383/400, batch: 136/1000, ite: 50643] train loss: 1.1129, accuracy: 95.2641%, tar: 0.0198 \n",
      "l0: 0.021048, l1: 0.022059, l2: 0.028838, l3: 0.044318, l4: 0.084493, l5: 0.162121, l6: 0.300867\n",
      "\n",
      "[epoch: 383/400, batch: 144/1000, ite: 50644] train loss: 1.1127, accuracy: 95.5675%, tar: 0.0198 \n",
      "l0: 0.022539, l1: 0.024665, l2: 0.031938, l3: 0.054194, l4: 0.111475, l5: 0.226339, l6: 0.408959\n",
      "\n",
      "[epoch: 383/400, batch: 152/1000, ite: 50645] train loss: 1.1130, accuracy: 94.5650%, tar: 0.0198 \n",
      "l0: 0.016410, l1: 0.017836, l2: 0.024329, l3: 0.040087, l4: 0.073297, l5: 0.144707, l6: 0.272787\n",
      "\n",
      "[epoch: 383/400, batch: 160/1000, ite: 50646] train loss: 1.1126, accuracy: 95.9857%, tar: 0.0198 \n",
      "l0: 0.018183, l1: 0.019275, l2: 0.025672, l3: 0.038790, l4: 0.074834, l5: 0.176153, l6: 0.362818\n",
      "\n",
      "[epoch: 383/400, batch: 168/1000, ite: 50647] train loss: 1.1126, accuracy: 95.4540%, tar: 0.0198 \n",
      "l0: 0.025829, l1: 0.027382, l2: 0.035180, l3: 0.051461, l4: 0.091680, l5: 0.207876, l6: 0.406321\n",
      "\n",
      "[epoch: 383/400, batch: 176/1000, ite: 50648] train loss: 1.1128, accuracy: 94.3115%, tar: 0.0198 \n",
      "l0: 0.023602, l1: 0.024908, l2: 0.032454, l3: 0.046573, l4: 0.080811, l5: 0.152802, l6: 0.372377\n",
      "\n",
      "[epoch: 383/400, batch: 184/1000, ite: 50649] train loss: 1.1127, accuracy: 94.3480%, tar: 0.0198 \n",
      "l0: 0.014862, l1: 0.016015, l2: 0.022593, l3: 0.039305, l4: 0.084093, l5: 0.160269, l6: 0.317180\n",
      "\n",
      "[epoch: 383/400, batch: 192/1000, ite: 50650] train loss: 1.1125, accuracy: 95.7566%, tar: 0.0198 \n",
      "l0: 0.020113, l1: 0.021047, l2: 0.029251, l3: 0.045429, l4: 0.082488, l5: 0.169951, l6: 0.426292\n",
      "\n",
      "[epoch: 383/400, batch: 200/1000, ite: 50651] train loss: 1.1127, accuracy: 94.9936%, tar: 0.0198 \n",
      "l0: 0.016380, l1: 0.017577, l2: 0.023576, l3: 0.036487, l4: 0.067264, l5: 0.138376, l6: 0.327517\n",
      "\n",
      "[epoch: 383/400, batch: 208/1000, ite: 50652] train loss: 1.1125, accuracy: 95.2375%, tar: 0.0198 \n",
      "l0: 0.019164, l1: 0.020233, l2: 0.028469, l3: 0.046344, l4: 0.099504, l5: 0.194206, l6: 0.376514\n",
      "\n",
      "[epoch: 383/400, batch: 216/1000, ite: 50653] train loss: 1.1125, accuracy: 95.4835%, tar: 0.0198 \n",
      "l0: 0.025693, l1: 0.027305, l2: 0.035401, l3: 0.055134, l4: 0.106422, l5: 0.210450, l6: 0.436555\n",
      "\n",
      "[epoch: 383/400, batch: 224/1000, ite: 50654] train loss: 1.1129, accuracy: 93.3250%, tar: 0.0198 \n",
      "l0: 0.022522, l1: 0.024240, l2: 0.035768, l3: 0.053522, l4: 0.109840, l5: 0.277136, l6: 0.614812\n",
      "\n",
      "[epoch: 383/400, batch: 232/1000, ite: 50655] train loss: 1.1139, accuracy: 92.3948%, tar: 0.0198 \n",
      "l0: 0.020602, l1: 0.022910, l2: 0.036072, l3: 0.059115, l4: 0.123988, l5: 0.243099, l6: 0.417532\n",
      "\n",
      "[epoch: 383/400, batch: 240/1000, ite: 50656] train loss: 1.1142, accuracy: 94.7697%, tar: 0.0198 \n",
      "l0: 0.017735, l1: 0.019239, l2: 0.027415, l3: 0.044865, l4: 0.095026, l5: 0.176564, l6: 0.434334\n",
      "\n",
      "[epoch: 383/400, batch: 248/1000, ite: 50657] train loss: 1.1144, accuracy: 94.8089%, tar: 0.0198 \n",
      "l0: 0.018532, l1: 0.019985, l2: 0.027267, l3: 0.041786, l4: 0.081261, l5: 0.173146, l6: 0.365873\n",
      "\n",
      "[epoch: 383/400, batch: 256/1000, ite: 50658] train loss: 1.1144, accuracy: 95.4771%, tar: 0.0198 \n",
      "l0: 0.020576, l1: 0.021971, l2: 0.029204, l3: 0.044337, l4: 0.082304, l5: 0.183737, l6: 0.370998\n",
      "\n",
      "[epoch: 383/400, batch: 264/1000, ite: 50659] train loss: 1.1144, accuracy: 95.0838%, tar: 0.0198 \n",
      "l0: 0.017949, l1: 0.019598, l2: 0.029622, l3: 0.043356, l4: 0.083496, l5: 0.193144, l6: 0.425547\n",
      "\n",
      "[epoch: 383/400, batch: 272/1000, ite: 50660] train loss: 1.1146, accuracy: 95.0520%, tar: 0.0198 \n",
      "l0: 0.020012, l1: 0.021300, l2: 0.028859, l3: 0.042842, l4: 0.085319, l5: 0.209924, l6: 0.404555\n",
      "\n",
      "[epoch: 383/400, batch: 280/1000, ite: 50661] train loss: 1.1148, accuracy: 94.5804%, tar: 0.0198 \n",
      "l0: 0.015536, l1: 0.016358, l2: 0.023960, l3: 0.035091, l4: 0.060941, l5: 0.101154, l6: 0.232655\n",
      "\n",
      "[epoch: 383/400, batch: 288/1000, ite: 50662] train loss: 1.1142, accuracy: 96.4554%, tar: 0.0198 \n",
      "l0: 0.016324, l1: 0.018164, l2: 0.028549, l3: 0.046568, l4: 0.091049, l5: 0.168708, l6: 0.292059\n",
      "\n",
      "[epoch: 383/400, batch: 296/1000, ite: 50663] train loss: 1.1140, accuracy: 95.9953%, tar: 0.0198 \n",
      "l0: 0.011695, l1: 0.012755, l2: 0.018707, l3: 0.029658, l4: 0.052694, l5: 0.099737, l6: 0.209416\n",
      "\n",
      "[epoch: 383/400, batch: 304/1000, ite: 50664] train loss: 1.1133, accuracy: 97.2117%, tar: 0.0198 \n",
      "l0: 0.017817, l1: 0.020064, l2: 0.030480, l3: 0.060023, l4: 0.142879, l5: 0.242096, l6: 0.451132\n",
      "\n",
      "[epoch: 383/400, batch: 312/1000, ite: 50665] train loss: 1.1137, accuracy: 94.5257%, tar: 0.0198 \n",
      "l0: 0.018395, l1: 0.020225, l2: 0.027901, l3: 0.041058, l4: 0.080618, l5: 0.210565, l6: 0.445787\n",
      "\n",
      "[epoch: 383/400, batch: 320/1000, ite: 50666] train loss: 1.1140, accuracy: 95.1702%, tar: 0.0198 \n",
      "l0: 0.016860, l1: 0.017714, l2: 0.025338, l3: 0.040785, l4: 0.078085, l5: 0.153526, l6: 0.355970\n",
      "\n",
      "[epoch: 383/400, batch: 328/1000, ite: 50667] train loss: 1.1139, accuracy: 94.8352%, tar: 0.0197 \n",
      "l0: 0.018775, l1: 0.019340, l2: 0.026008, l3: 0.039664, l4: 0.069931, l5: 0.142157, l6: 0.334278\n",
      "\n",
      "[epoch: 383/400, batch: 336/1000, ite: 50668] train loss: 1.1137, accuracy: 94.8390%, tar: 0.0197 \n",
      "l0: 0.021106, l1: 0.022987, l2: 0.033631, l3: 0.060137, l4: 0.125775, l5: 0.230212, l6: 0.545630\n",
      "\n",
      "[epoch: 383/400, batch: 344/1000, ite: 50669] train loss: 1.1144, accuracy: 93.7690%, tar: 0.0197 \n",
      "l0: 0.017961, l1: 0.019550, l2: 0.028306, l3: 0.045717, l4: 0.075709, l5: 0.143426, l6: 0.314315\n",
      "\n",
      "[epoch: 383/400, batch: 352/1000, ite: 50670] train loss: 1.1142, accuracy: 96.4024%, tar: 0.0197 \n",
      "l0: 0.017403, l1: 0.018596, l2: 0.026125, l3: 0.042423, l4: 0.075952, l5: 0.169477, l6: 0.374004\n",
      "\n",
      "[epoch: 383/400, batch: 360/1000, ite: 50671] train loss: 1.1142, accuracy: 94.9780%, tar: 0.0197 \n",
      "l0: 0.018427, l1: 0.020148, l2: 0.027231, l3: 0.042735, l4: 0.084771, l5: 0.196297, l6: 0.380593\n",
      "\n",
      "[epoch: 383/400, batch: 368/1000, ite: 50672] train loss: 1.1142, accuracy: 94.9525%, tar: 0.0197 \n",
      "l0: 0.015068, l1: 0.016504, l2: 0.023397, l3: 0.042249, l4: 0.079870, l5: 0.135465, l6: 0.287974\n",
      "\n",
      "[epoch: 383/400, batch: 376/1000, ite: 50673] train loss: 1.1139, accuracy: 96.1534%, tar: 0.0197 \n",
      "l0: 0.012632, l1: 0.013937, l2: 0.019650, l3: 0.033240, l4: 0.069176, l5: 0.157159, l6: 0.331235\n",
      "\n",
      "[epoch: 383/400, batch: 384/1000, ite: 50674] train loss: 1.1137, accuracy: 95.8896%, tar: 0.0197 \n",
      "l0: 0.017766, l1: 0.019513, l2: 0.028013, l3: 0.049570, l4: 0.090649, l5: 0.209437, l6: 0.381147\n",
      "\n",
      "[epoch: 383/400, batch: 392/1000, ite: 50675] train loss: 1.1138, accuracy: 95.7911%, tar: 0.0197 \n",
      "l0: 0.016386, l1: 0.017716, l2: 0.026915, l3: 0.042688, l4: 0.075770, l5: 0.148644, l6: 0.403944\n",
      "\n",
      "[epoch: 383/400, batch: 400/1000, ite: 50676] train loss: 1.1138, accuracy: 94.5572%, tar: 0.0197 \n",
      "l0: 0.026590, l1: 0.028529, l2: 0.037669, l3: 0.056234, l4: 0.101229, l5: 0.227305, l6: 0.482096\n",
      "\n",
      "[epoch: 383/400, batch: 408/1000, ite: 50677] train loss: 1.1143, accuracy: 93.3904%, tar: 0.0197 \n",
      "l0: 0.021168, l1: 0.022692, l2: 0.032501, l3: 0.049606, l4: 0.086959, l5: 0.192568, l6: 0.372106\n",
      "\n",
      "[epoch: 383/400, batch: 416/1000, ite: 50678] train loss: 1.1144, accuracy: 95.3965%, tar: 0.0197 \n",
      "l0: 0.021435, l1: 0.022573, l2: 0.028319, l3: 0.040490, l4: 0.067742, l5: 0.120714, l6: 0.328976\n",
      "\n",
      "[epoch: 383/400, batch: 424/1000, ite: 50679] train loss: 1.1141, accuracy: 95.1159%, tar: 0.0197 \n",
      "l0: 0.023926, l1: 0.025805, l2: 0.034693, l3: 0.053921, l4: 0.110009, l5: 0.276901, l6: 0.529559\n",
      "\n",
      "[epoch: 383/400, batch: 432/1000, ite: 50680] train loss: 1.1148, accuracy: 93.1425%, tar: 0.0197 \n",
      "l0: 0.021566, l1: 0.022792, l2: 0.029609, l3: 0.046281, l4: 0.097792, l5: 0.234104, l6: 0.471877\n",
      "\n",
      "[epoch: 383/400, batch: 440/1000, ite: 50681] train loss: 1.1152, accuracy: 93.2647%, tar: 0.0197 \n",
      "l0: 0.024479, l1: 0.026270, l2: 0.036596, l3: 0.055738, l4: 0.104676, l5: 0.169607, l6: 0.333294\n",
      "\n",
      "[epoch: 383/400, batch: 448/1000, ite: 50682] train loss: 1.1152, accuracy: 95.5317%, tar: 0.0197 \n",
      "l0: 0.017244, l1: 0.018470, l2: 0.025774, l3: 0.038517, l4: 0.070154, l5: 0.136014, l6: 0.265727\n",
      "\n",
      "[epoch: 383/400, batch: 456/1000, ite: 50683] train loss: 1.1148, accuracy: 95.9311%, tar: 0.0197 \n",
      "l0: 0.020629, l1: 0.021692, l2: 0.029104, l3: 0.045022, l4: 0.082891, l5: 0.144115, l6: 0.300479\n",
      "\n",
      "[epoch: 383/400, batch: 464/1000, ite: 50684] train loss: 1.1146, accuracy: 95.7810%, tar: 0.0197 \n",
      "l0: 0.020449, l1: 0.021319, l2: 0.027541, l3: 0.038011, l4: 0.066256, l5: 0.128936, l6: 0.314148\n",
      "\n",
      "[epoch: 383/400, batch: 472/1000, ite: 50685] train loss: 1.1143, accuracy: 95.1760%, tar: 0.0197 \n",
      "l0: 0.021013, l1: 0.022762, l2: 0.032782, l3: 0.049738, l4: 0.101747, l5: 0.184928, l6: 0.412773\n",
      "\n",
      "[epoch: 383/400, batch: 480/1000, ite: 50686] train loss: 1.1145, accuracy: 94.8107%, tar: 0.0197 \n",
      "l0: 0.015089, l1: 0.017010, l2: 0.026050, l3: 0.041365, l4: 0.084483, l5: 0.166772, l6: 0.319887\n",
      "\n",
      "[epoch: 383/400, batch: 488/1000, ite: 50687] train loss: 1.1143, accuracy: 96.1399%, tar: 0.0197 \n",
      "l0: 0.021680, l1: 0.022954, l2: 0.030584, l3: 0.049381, l4: 0.086936, l5: 0.192869, l6: 0.389999\n",
      "\n",
      "[epoch: 383/400, batch: 496/1000, ite: 50688] train loss: 1.1144, accuracy: 94.2495%, tar: 0.0197 \n",
      "l0: 0.018717, l1: 0.021444, l2: 0.031765, l3: 0.051282, l4: 0.096117, l5: 0.220840, l6: 0.452301\n",
      "\n",
      "[epoch: 383/400, batch: 504/1000, ite: 50689] train loss: 1.1148, accuracy: 94.3157%, tar: 0.0197 \n",
      "l0: 0.017290, l1: 0.018286, l2: 0.023738, l3: 0.036715, l4: 0.075813, l5: 0.156835, l6: 0.373256\n",
      "\n",
      "[epoch: 383/400, batch: 512/1000, ite: 50690] train loss: 1.1147, accuracy: 95.1044%, tar: 0.0197 \n",
      "l0: 0.021054, l1: 0.022307, l2: 0.032257, l3: 0.050018, l4: 0.088154, l5: 0.187907, l6: 0.398803\n",
      "\n",
      "[epoch: 383/400, batch: 520/1000, ite: 50691] train loss: 1.1149, accuracy: 94.3551%, tar: 0.0197 \n",
      "l0: 0.017618, l1: 0.018925, l2: 0.025979, l3: 0.038250, l4: 0.079087, l5: 0.141516, l6: 0.275660\n",
      "\n",
      "[epoch: 383/400, batch: 528/1000, ite: 50692] train loss: 1.1145, accuracy: 96.2842%, tar: 0.0197 \n",
      "l0: 0.020754, l1: 0.023040, l2: 0.032663, l3: 0.052125, l4: 0.098431, l5: 0.223137, l6: 0.420824\n",
      "\n",
      "[epoch: 383/400, batch: 536/1000, ite: 50693] train loss: 1.1148, accuracy: 95.3064%, tar: 0.0197 \n",
      "l0: 0.022448, l1: 0.023702, l2: 0.030343, l3: 0.045386, l4: 0.087002, l5: 0.189740, l6: 0.447687\n",
      "\n",
      "[epoch: 383/400, batch: 544/1000, ite: 50694] train loss: 1.1150, accuracy: 94.1607%, tar: 0.0197 \n",
      "l0: 0.014261, l1: 0.015438, l2: 0.022276, l3: 0.035167, l4: 0.065380, l5: 0.144987, l6: 0.338609\n",
      "\n",
      "[epoch: 383/400, batch: 552/1000, ite: 50695] train loss: 1.1148, accuracy: 95.8760%, tar: 0.0197 \n",
      "l0: 0.018086, l1: 0.019931, l2: 0.029163, l3: 0.053831, l4: 0.103659, l5: 0.243698, l6: 0.487703\n",
      "\n",
      "[epoch: 383/400, batch: 560/1000, ite: 50696] train loss: 1.1153, accuracy: 93.8208%, tar: 0.0197 \n",
      "l0: 0.021701, l1: 0.023090, l2: 0.030837, l3: 0.049674, l4: 0.101773, l5: 0.194838, l6: 0.363187\n",
      "\n",
      "[epoch: 383/400, batch: 568/1000, ite: 50697] train loss: 1.1154, accuracy: 94.7685%, tar: 0.0197 \n",
      "l0: 0.018813, l1: 0.020229, l2: 0.028309, l3: 0.041965, l4: 0.067773, l5: 0.117165, l6: 0.257149\n",
      "\n",
      "[epoch: 383/400, batch: 576/1000, ite: 50698] train loss: 1.1149, accuracy: 95.9793%, tar: 0.0197 \n",
      "l0: 0.018624, l1: 0.019757, l2: 0.025425, l3: 0.036929, l4: 0.062352, l5: 0.110487, l6: 0.256176\n",
      "\n",
      "[epoch: 383/400, batch: 584/1000, ite: 50699] train loss: 1.1145, accuracy: 96.2521%, tar: 0.0197 \n",
      "l0: 0.023424, l1: 0.024679, l2: 0.032404, l3: 0.048963, l4: 0.085199, l5: 0.168290, l6: 0.375662\n",
      "\n",
      "[epoch: 383/400, batch: 592/1000, ite: 50700] train loss: 1.1145, accuracy: 94.0065%, tar: 0.0197 \n",
      "l0: 0.018105, l1: 0.019342, l2: 0.027119, l3: 0.041268, l4: 0.081172, l5: 0.167635, l6: 0.333848\n",
      "\n",
      "[epoch: 383/400, batch: 600/1000, ite: 50701] train loss: 1.1144, accuracy: 95.3651%, tar: 0.0197 \n",
      "l0: 0.018123, l1: 0.018865, l2: 0.026502, l3: 0.039919, l4: 0.092901, l5: 0.157310, l6: 0.294782\n",
      "\n",
      "[epoch: 383/400, batch: 608/1000, ite: 50702] train loss: 1.1141, accuracy: 95.6080%, tar: 0.0197 \n",
      "l0: 0.020805, l1: 0.021523, l2: 0.030635, l3: 0.044996, l4: 0.078409, l5: 0.153324, l6: 0.338662\n",
      "\n",
      "[epoch: 383/400, batch: 616/1000, ite: 50703] train loss: 1.1140, accuracy: 95.5182%, tar: 0.0197 \n",
      "l0: 0.023263, l1: 0.025449, l2: 0.036070, l3: 0.056474, l4: 0.109490, l5: 0.235218, l6: 0.452240\n",
      "\n",
      "[epoch: 383/400, batch: 624/1000, ite: 50704] train loss: 1.1144, accuracy: 93.9563%, tar: 0.0197 \n",
      "l0: 0.021342, l1: 0.022468, l2: 0.030528, l3: 0.045527, l4: 0.071993, l5: 0.125191, l6: 0.265139\n",
      "\n",
      "[epoch: 383/400, batch: 632/1000, ite: 50705] train loss: 1.1140, accuracy: 95.8559%, tar: 0.0197 \n",
      "l0: 0.024432, l1: 0.025901, l2: 0.033184, l3: 0.051163, l4: 0.092536, l5: 0.184906, l6: 0.408542\n",
      "\n",
      "[epoch: 383/400, batch: 640/1000, ite: 50706] train loss: 1.1142, accuracy: 94.7882%, tar: 0.0197 \n",
      "l0: 0.020820, l1: 0.022457, l2: 0.032946, l3: 0.048682, l4: 0.083106, l5: 0.154916, l6: 0.344356\n",
      "\n",
      "[epoch: 383/400, batch: 648/1000, ite: 50707] train loss: 1.1141, accuracy: 95.4437%, tar: 0.0197 \n",
      "l0: 0.017046, l1: 0.018156, l2: 0.024959, l3: 0.035607, l4: 0.057928, l5: 0.113355, l6: 0.328084\n",
      "\n",
      "[epoch: 383/400, batch: 656/1000, ite: 50708] train loss: 1.1139, accuracy: 95.7935%, tar: 0.0197 \n",
      "l0: 0.023612, l1: 0.024941, l2: 0.034084, l3: 0.050147, l4: 0.091587, l5: 0.214659, l6: 0.437404\n",
      "\n",
      "[epoch: 383/400, batch: 664/1000, ite: 50709] train loss: 1.1142, accuracy: 94.0945%, tar: 0.0197 \n",
      "l0: 0.024998, l1: 0.026735, l2: 0.035525, l3: 0.057664, l4: 0.098753, l5: 0.179811, l6: 0.394315\n",
      "\n",
      "[epoch: 383/400, batch: 672/1000, ite: 50710] train loss: 1.1143, accuracy: 94.4169%, tar: 0.0198 \n",
      "l0: 0.021398, l1: 0.023499, l2: 0.031027, l3: 0.045509, l4: 0.080720, l5: 0.153221, l6: 0.362059\n",
      "\n",
      "[epoch: 383/400, batch: 680/1000, ite: 50711] train loss: 1.1143, accuracy: 95.0485%, tar: 0.0198 \n",
      "l0: 0.021578, l1: 0.023481, l2: 0.032869, l3: 0.047713, l4: 0.092655, l5: 0.177394, l6: 0.343981\n",
      "\n",
      "[epoch: 383/400, batch: 688/1000, ite: 50712] train loss: 1.1142, accuracy: 95.2396%, tar: 0.0198 \n",
      "l0: 0.014267, l1: 0.015036, l2: 0.021808, l3: 0.034652, l4: 0.059987, l5: 0.113015, l6: 0.264067\n",
      "\n",
      "[epoch: 383/400, batch: 696/1000, ite: 50713] train loss: 1.1138, accuracy: 96.2402%, tar: 0.0198 \n",
      "l0: 0.019992, l1: 0.021295, l2: 0.029337, l3: 0.047289, l4: 0.092734, l5: 0.175256, l6: 0.321874\n",
      "\n",
      "[epoch: 383/400, batch: 704/1000, ite: 50714] train loss: 1.1137, accuracy: 96.0824%, tar: 0.0198 \n",
      "l0: 0.024732, l1: 0.025495, l2: 0.033588, l3: 0.054642, l4: 0.108285, l5: 0.270237, l6: 0.516619\n",
      "\n",
      "[epoch: 383/400, batch: 712/1000, ite: 50715] train loss: 1.1143, accuracy: 93.2553%, tar: 0.0198 \n",
      "l0: 0.029010, l1: 0.030206, l2: 0.039258, l3: 0.058037, l4: 0.117827, l5: 0.248597, l6: 0.564252\n",
      "\n",
      "[epoch: 383/400, batch: 720/1000, ite: 50716] train loss: 1.1150, accuracy: 92.7015%, tar: 0.0198 \n",
      "l0: 0.017925, l1: 0.018919, l2: 0.025804, l3: 0.038953, l4: 0.074211, l5: 0.156410, l6: 0.339516\n",
      "\n",
      "[epoch: 383/400, batch: 728/1000, ite: 50717] train loss: 1.1149, accuracy: 95.5649%, tar: 0.0198 \n",
      "l0: 0.015482, l1: 0.016394, l2: 0.023243, l3: 0.036585, l4: 0.067215, l5: 0.133230, l6: 0.278603\n",
      "\n",
      "[epoch: 383/400, batch: 736/1000, ite: 50718] train loss: 1.1145, accuracy: 95.3277%, tar: 0.0198 \n",
      "l0: 0.013800, l1: 0.015339, l2: 0.021713, l3: 0.034735, l4: 0.070311, l5: 0.131424, l6: 0.292976\n",
      "\n",
      "[epoch: 383/400, batch: 744/1000, ite: 50719] train loss: 1.1142, accuracy: 96.9143%, tar: 0.0198 \n",
      "l0: 0.018850, l1: 0.020068, l2: 0.027125, l3: 0.041167, l4: 0.070427, l5: 0.144436, l6: 0.324967\n",
      "\n",
      "[epoch: 383/400, batch: 752/1000, ite: 50720] train loss: 1.1140, accuracy: 95.8556%, tar: 0.0198 \n",
      "l0: 0.020897, l1: 0.021542, l2: 0.030032, l3: 0.044590, l4: 0.096599, l5: 0.207157, l6: 0.417172\n",
      "\n",
      "[epoch: 383/400, batch: 760/1000, ite: 50721] train loss: 1.1142, accuracy: 94.4913%, tar: 0.0198 \n",
      "l0: 0.018940, l1: 0.020178, l2: 0.024391, l3: 0.036758, l4: 0.073935, l5: 0.135155, l6: 0.268970\n",
      "\n",
      "[epoch: 383/400, batch: 768/1000, ite: 50722] train loss: 1.1138, accuracy: 95.8359%, tar: 0.0198 \n",
      "l0: 0.017215, l1: 0.018588, l2: 0.026132, l3: 0.040767, l4: 0.082638, l5: 0.161053, l6: 0.340218\n",
      "\n",
      "[epoch: 383/400, batch: 776/1000, ite: 50723] train loss: 1.1137, accuracy: 95.8801%, tar: 0.0198 \n",
      "l0: 0.022149, l1: 0.023307, l2: 0.029869, l3: 0.046928, l4: 0.087152, l5: 0.180221, l6: 0.345068\n",
      "\n",
      "[epoch: 383/400, batch: 784/1000, ite: 50724] train loss: 1.1137, accuracy: 94.3828%, tar: 0.0198 \n",
      "l0: 0.025352, l1: 0.026775, l2: 0.034390, l3: 0.050177, l4: 0.087977, l5: 0.165633, l6: 0.388071\n",
      "\n",
      "[epoch: 383/400, batch: 792/1000, ite: 50725] train loss: 1.1138, accuracy: 95.4258%, tar: 0.0198 \n",
      "l0: 0.023072, l1: 0.024468, l2: 0.032658, l3: 0.048114, l4: 0.082689, l5: 0.189237, l6: 0.418744\n",
      "\n",
      "[epoch: 383/400, batch: 800/1000, ite: 50726] train loss: 1.1139, accuracy: 93.9292%, tar: 0.0198 \n",
      "l0: 0.022348, l1: 0.023249, l2: 0.031183, l3: 0.047992, l4: 0.093473, l5: 0.206451, l6: 0.377577\n",
      "\n",
      "[epoch: 383/400, batch: 808/1000, ite: 50727] train loss: 1.1140, accuracy: 94.5343%, tar: 0.0198 \n",
      "[epoch: 383/400, batch: 824/1000, ite: 50729] train loss: 1.1144, accuracy: 94.2368%, tar: 0.0198 \n",
      "l0: 0.021138, l1: 0.022711, l2: 0.032985, l3: 0.053653, l4: 0.095121, l5: 0.191745, l6: 0.437388\n",
      "\n",
      "[epoch: 383/400, batch: 832/1000, ite: 50730] train loss: 1.1147, accuracy: 94.8876%, tar: 0.0198 \n",
      "l0: 0.021458, l1: 0.023275, l2: 0.030591, l3: 0.045660, l4: 0.084866, l5: 0.193403, l6: 0.466718\n",
      "\n",
      "[epoch: 383/400, batch: 840/1000, ite: 50731] train loss: 1.1150, accuracy: 94.4691%, tar: 0.0198 \n",
      "l0: 0.022248, l1: 0.023790, l2: 0.030458, l3: 0.046501, l4: 0.083893, l5: 0.158342, l6: 0.347382\n",
      "\n",
      "[epoch: 383/400, batch: 848/1000, ite: 50732] train loss: 1.1149, accuracy: 94.7933%, tar: 0.0198 \n",
      "l0: 0.015463, l1: 0.016095, l2: 0.023805, l3: 0.039204, l4: 0.067768, l5: 0.130845, l6: 0.268264\n",
      "\n",
      "[epoch: 383/400, batch: 856/1000, ite: 50733] train loss: 1.1145, accuracy: 96.4403%, tar: 0.0198 \n",
      "l0: 0.024780, l1: 0.026220, l2: 0.034507, l3: 0.050583, l4: 0.086251, l5: 0.157825, l6: 0.331778\n",
      "\n",
      "[epoch: 383/400, batch: 864/1000, ite: 50734] train loss: 1.1145, accuracy: 94.8829%, tar: 0.0198 \n",
      "l0: 0.018618, l1: 0.019573, l2: 0.026879, l3: 0.042174, l4: 0.073874, l5: 0.135250, l6: 0.260759\n",
      "\n",
      "[epoch: 383/400, batch: 872/1000, ite: 50735] train loss: 1.1141, accuracy: 96.0799%, tar: 0.0198 \n",
      "l0: 0.020463, l1: 0.021955, l2: 0.029808, l3: 0.044818, l4: 0.092722, l5: 0.197177, l6: 0.399326\n",
      "\n",
      "[epoch: 383/400, batch: 880/1000, ite: 50736] train loss: 1.1142, accuracy: 94.7638%, tar: 0.0198 \n",
      "l0: 0.020067, l1: 0.021071, l2: 0.030162, l3: 0.046981, l4: 0.085257, l5: 0.184756, l6: 0.352907\n",
      "\n",
      "[epoch: 383/400, batch: 888/1000, ite: 50737] train loss: 1.1142, accuracy: 94.6238%, tar: 0.0198 \n",
      "l0: 0.015878, l1: 0.017475, l2: 0.025178, l3: 0.038757, l4: 0.067090, l5: 0.118084, l6: 0.229316\n",
      "\n",
      "[epoch: 383/400, batch: 896/1000, ite: 50738] train loss: 1.1137, accuracy: 96.5937%, tar: 0.0198 \n",
      "l0: 0.019111, l1: 0.020419, l2: 0.026810, l3: 0.038097, l4: 0.065056, l5: 0.129109, l6: 0.280614\n",
      "\n",
      "[epoch: 383/400, batch: 904/1000, ite: 50739] train loss: 1.1134, accuracy: 95.6640%, tar: 0.0198 \n",
      "l0: 0.021571, l1: 0.023019, l2: 0.030473, l3: 0.048677, l4: 0.093502, l5: 0.193568, l6: 0.503363\n",
      "\n",
      "[epoch: 383/400, batch: 912/1000, ite: 50740] train loss: 1.1138, accuracy: 93.8890%, tar: 0.0198 \n",
      "l0: 0.024576, l1: 0.025802, l2: 0.034291, l3: 0.050770, l4: 0.087511, l5: 0.174317, l6: 0.364706\n",
      "\n",
      "[epoch: 383/400, batch: 920/1000, ite: 50741] train loss: 1.1138, accuracy: 94.5029%, tar: 0.0198 \n",
      "l0: 0.018257, l1: 0.019302, l2: 0.024776, l3: 0.034310, l4: 0.056820, l5: 0.094928, l6: 0.190092\n",
      "\n",
      "[epoch: 383/400, batch: 928/1000, ite: 50742] train loss: 1.1131, accuracy: 96.7281%, tar: 0.0198 \n",
      "l0: 0.033593, l1: 0.035378, l2: 0.046971, l3: 0.066635, l4: 0.134441, l5: 0.274887, l6: 0.551198\n",
      "\n",
      "[epoch: 383/400, batch: 936/1000, ite: 50743] train loss: 1.1139, accuracy: 92.4199%, tar: 0.0198 \n",
      "l0: 0.019363, l1: 0.020819, l2: 0.028539, l3: 0.044271, l4: 0.085159, l5: 0.178816, l6: 0.413363\n",
      "\n",
      "[epoch: 383/400, batch: 944/1000, ite: 50744] train loss: 1.1141, accuracy: 94.3273%, tar: 0.0198 \n",
      "l0: 0.022496, l1: 0.024026, l2: 0.031185, l3: 0.048268, l4: 0.089983, l5: 0.180044, l6: 0.392503\n",
      "\n",
      "[epoch: 383/400, batch: 952/1000, ite: 50745] train loss: 1.1142, accuracy: 94.9750%, tar: 0.0198 \n",
      "l0: 0.015395, l1: 0.016292, l2: 0.021844, l3: 0.033696, l4: 0.059704, l5: 0.122031, l6: 0.250710\n",
      "\n",
      "[epoch: 383/400, batch: 960/1000, ite: 50746] train loss: 1.1137, accuracy: 96.3488%, tar: 0.0198 \n",
      "l0: 0.020977, l1: 0.022196, l2: 0.028959, l3: 0.041319, l4: 0.113552, l5: 0.190093, l6: 0.332260\n",
      "\n",
      "[epoch: 383/400, batch: 968/1000, ite: 50747] train loss: 1.1137, accuracy: 95.3105%, tar: 0.0198 \n",
      "l0: 0.024596, l1: 0.026777, l2: 0.036723, l3: 0.060513, l4: 0.117436, l5: 0.221106, l6: 0.406956\n",
      "\n",
      "[epoch: 383/400, batch: 976/1000, ite: 50748] train loss: 1.1139, accuracy: 93.8078%, tar: 0.0198 \n",
      "l0: 0.019452, l1: 0.020626, l2: 0.028119, l3: 0.042086, l4: 0.074903, l5: 0.138103, l6: 0.280229\n",
      "\n",
      "[epoch: 383/400, batch: 984/1000, ite: 50749] train loss: 1.1136, accuracy: 95.3666%, tar: 0.0198 \n",
      "l0: 0.023796, l1: 0.026047, l2: 0.034588, l3: 0.059162, l4: 0.110399, l5: 0.205706, l6: 0.399008\n",
      "\n",
      "[epoch: 383/400, batch: 992/1000, ite: 50750] train loss: 1.1138, accuracy: 94.2899%, tar: 0.0198 \n",
      "l0: 0.021900, l1: 0.023347, l2: 0.030966, l3: 0.047403, l4: 0.098663, l5: 0.203943, l6: 0.433514\n",
      "\n",
      "[epoch: 383/400, batch: 1000/1000, ite: 50751] train loss: 1.1141, accuracy: 94.6504%, tar: 0.0198 \n",
      "l0: 0.020186, l1: 0.021459, l2: 0.031005, l3: 0.045922, l4: 0.072286, l5: 0.137853, l6: 0.317734\n",
      "\n",
      "[epoch: 384/400, batch: 8/1000, ite: 50752] train loss: 1.1139, accuracy: 95.2786%, tar: 0.0198 \n",
      "l0: 0.015138, l1: 0.015906, l2: 0.023807, l3: 0.034308, l4: 0.061839, l5: 0.113574, l6: 0.229062\n",
      "\n",
      "[epoch: 384/400, batch: 16/1000, ite: 50753] train loss: 1.1133, accuracy: 96.3630%, tar: 0.0198 \n",
      "l0: 0.020633, l1: 0.021775, l2: 0.028573, l3: 0.045226, l4: 0.090890, l5: 0.165102, l6: 0.359168\n",
      "\n",
      "[epoch: 384/400, batch: 24/1000, ite: 50754] train loss: 1.1133, accuracy: 95.8905%, tar: 0.0198 \n",
      "l0: 0.010300, l1: 0.010636, l2: 0.014627, l3: 0.022447, l4: 0.037287, l5: 0.067151, l6: 0.164762\n",
      "\n",
      "[epoch: 384/400, batch: 32/1000, ite: 50755] train loss: 1.1125, accuracy: 97.3325%, tar: 0.0198 \n",
      "l0: 0.022954, l1: 0.023701, l2: 0.031775, l3: 0.045228, l4: 0.085580, l5: 0.184143, l6: 0.433372\n",
      "\n",
      "[epoch: 384/400, batch: 40/1000, ite: 50756] train loss: 1.1127, accuracy: 94.4252%, tar: 0.0198 \n",
      "l0: 0.019691, l1: 0.021603, l2: 0.030656, l3: 0.055375, l4: 0.131592, l5: 0.291721, l6: 0.508137\n",
      "\n",
      "[epoch: 384/400, batch: 48/1000, ite: 50757] train loss: 1.1133, accuracy: 93.5836%, tar: 0.0198 \n",
      "l0: 0.017831, l1: 0.019647, l2: 0.027236, l3: 0.043844, l4: 0.081855, l5: 0.185980, l6: 0.365960\n",
      "\n",
      "[epoch: 384/400, batch: 56/1000, ite: 50758] train loss: 1.1133, accuracy: 95.2577%, tar: 0.0198 \n",
      "l0: 0.023038, l1: 0.024319, l2: 0.030901, l3: 0.044291, l4: 0.075272, l5: 0.164904, l6: 0.284056\n",
      "\n",
      "[epoch: 384/400, batch: 64/1000, ite: 50759] train loss: 1.1131, accuracy: 95.3947%, tar: 0.0198 \n",
      "l0: 0.017078, l1: 0.018706, l2: 0.025732, l3: 0.039148, l4: 0.078549, l5: 0.127042, l6: 0.236807\n",
      "\n",
      "[epoch: 384/400, batch: 72/1000, ite: 50760] train loss: 1.1126, accuracy: 97.0195%, tar: 0.0198 \n",
      "l0: 0.020469, l1: 0.022176, l2: 0.029415, l3: 0.044459, l4: 0.078212, l5: 0.154531, l6: 0.322241\n",
      "\n",
      "[epoch: 384/400, batch: 80/1000, ite: 50761] train loss: 1.1125, accuracy: 95.8770%, tar: 0.0198 \n",
      "l0: 0.013150, l1: 0.014220, l2: 0.019493, l3: 0.032213, l4: 0.063148, l5: 0.133396, l6: 0.337309\n",
      "\n",
      "[epoch: 384/400, batch: 88/1000, ite: 50762] train loss: 1.1123, accuracy: 95.4890%, tar: 0.0198 \n",
      "l0: 0.021137, l1: 0.022090, l2: 0.029213, l3: 0.043065, l4: 0.074803, l5: 0.139303, l6: 0.315191\n",
      "\n",
      "[epoch: 384/400, batch: 96/1000, ite: 50763] train loss: 1.1121, accuracy: 95.1590%, tar: 0.0198 \n",
      "l0: 0.019677, l1: 0.021445, l2: 0.028805, l3: 0.047294, l4: 0.108924, l5: 0.214404, l6: 0.366380\n",
      "\n",
      "[epoch: 384/400, batch: 104/1000, ite: 50764] train loss: 1.1122, accuracy: 94.6063%, tar: 0.0198 \n",
      "l0: 0.028822, l1: 0.030568, l2: 0.038163, l3: 0.052619, l4: 0.094229, l5: 0.198969, l6: 0.437112\n",
      "\n",
      "[epoch: 384/400, batch: 112/1000, ite: 50765] train loss: 1.1124, accuracy: 94.0679%, tar: 0.0198 \n",
      "l0: 0.016420, l1: 0.017720, l2: 0.024630, l3: 0.039662, l4: 0.081194, l5: 0.168421, l6: 0.317492\n",
      "\n",
      "[epoch: 384/400, batch: 120/1000, ite: 50766] train loss: 1.1123, accuracy: 95.5172%, tar: 0.0198 \n",
      "l0: 0.016429, l1: 0.017891, l2: 0.025355, l3: 0.037892, l4: 0.067892, l5: 0.134170, l6: 0.293483\n",
      "\n",
      "[epoch: 384/400, batch: 128/1000, ite: 50767] train loss: 1.1120, accuracy: 96.3090%, tar: 0.0198 \n",
      "l0: 0.020047, l1: 0.020935, l2: 0.028343, l3: 0.043128, l4: 0.074301, l5: 0.136125, l6: 0.266051\n",
      "\n",
      "[epoch: 384/400, batch: 136/1000, ite: 50768] train loss: 1.1116, accuracy: 95.4539%, tar: 0.0198 \n",
      "l0: 0.020364, l1: 0.021231, l2: 0.029086, l3: 0.043159, l4: 0.070814, l5: 0.137770, l6: 0.320163\n",
      "\n",
      "[epoch: 384/400, batch: 144/1000, ite: 50769] train loss: 1.1115, accuracy: 95.1479%, tar: 0.0198 \n",
      "l0: 0.018813, l1: 0.020104, l2: 0.027656, l3: 0.042783, l4: 0.078143, l5: 0.159921, l6: 0.337468\n",
      "\n",
      "[epoch: 384/400, batch: 152/1000, ite: 50770] train loss: 1.1113, accuracy: 95.4117%, tar: 0.0198 \n",
      "l0: 0.017124, l1: 0.018985, l2: 0.027761, l3: 0.040932, l4: 0.092843, l5: 0.203426, l6: 0.402246\n",
      "\n",
      "[epoch: 384/400, batch: 160/1000, ite: 50771] train loss: 1.1115, accuracy: 95.1272%, tar: 0.0198 \n",
      "l0: 0.018271, l1: 0.019394, l2: 0.025801, l3: 0.039731, l4: 0.079487, l5: 0.180784, l6: 0.344292\n",
      "\n",
      "[epoch: 384/400, batch: 168/1000, ite: 50772] train loss: 1.1114, accuracy: 94.9634%, tar: 0.0198 \n",
      "l0: 0.018383, l1: 0.019573, l2: 0.025532, l3: 0.041382, l4: 0.078754, l5: 0.178972, l6: 0.408852\n",
      "\n",
      "[epoch: 384/400, batch: 176/1000, ite: 50773] train loss: 1.1115, accuracy: 94.8848%, tar: 0.0198 \n",
      "l0: 0.017667, l1: 0.018394, l2: 0.024124, l3: 0.034127, l4: 0.064918, l5: 0.131927, l6: 0.269876\n",
      "\n",
      "[epoch: 384/400, batch: 184/1000, ite: 50774] train loss: 1.1111, accuracy: 95.8544%, tar: 0.0198 \n",
      "l0: 0.022504, l1: 0.024633, l2: 0.032510, l3: 0.047938, l4: 0.097822, l5: 0.261982, l6: 0.527405\n",
      "\n",
      "[epoch: 384/400, batch: 192/1000, ite: 50775] train loss: 1.1117, accuracy: 93.9345%, tar: 0.0198 \n",
      "l0: 0.020257, l1: 0.022094, l2: 0.030686, l3: 0.048464, l4: 0.102960, l5: 0.214102, l6: 0.422034\n",
      "\n",
      "[epoch: 384/400, batch: 200/1000, ite: 50776] train loss: 1.1119, accuracy: 94.3042%, tar: 0.0198 \n",
      "l0: 0.019250, l1: 0.021414, l2: 0.031379, l3: 0.052335, l4: 0.121178, l5: 0.260754, l6: 0.477583\n",
      "\n",
      "[epoch: 384/400, batch: 208/1000, ite: 50777] train loss: 1.1124, accuracy: 95.3142%, tar: 0.0198 \n",
      "l0: 0.020638, l1: 0.021517, l2: 0.027613, l3: 0.042083, l4: 0.072835, l5: 0.179101, l6: 0.374806\n",
      "\n",
      "[epoch: 384/400, batch: 216/1000, ite: 50778] train loss: 1.1124, accuracy: 94.0498%, tar: 0.0198 \n",
      "l0: 0.018653, l1: 0.020237, l2: 0.026713, l3: 0.039150, l4: 0.075603, l5: 0.149411, l6: 0.333320\n",
      "\n",
      "[epoch: 384/400, batch: 224/1000, ite: 50779] train loss: 1.1122, accuracy: 95.9391%, tar: 0.0198 \n",
      "l0: 0.016288, l1: 0.017681, l2: 0.024888, l3: 0.037572, l4: 0.070249, l5: 0.153689, l6: 0.324727\n",
      "\n",
      "[epoch: 384/400, batch: 232/1000, ite: 50780] train loss: 1.1120, accuracy: 95.3138%, tar: 0.0198 \n",
      "l0: 0.021970, l1: 0.023242, l2: 0.031996, l3: 0.046111, l4: 0.085182, l5: 0.178544, l6: 0.337143\n",
      "\n",
      "[epoch: 384/400, batch: 240/1000, ite: 50781] train loss: 1.1120, accuracy: 95.1456%, tar: 0.0198 \n",
      "l0: 0.021433, l1: 0.023373, l2: 0.032493, l3: 0.050728, l4: 0.096009, l5: 0.195444, l6: 0.387676\n",
      "\n",
      "[epoch: 384/400, batch: 248/1000, ite: 50782] train loss: 1.1121, accuracy: 95.2099%, tar: 0.0198 \n",
      "l0: 0.021059, l1: 0.021926, l2: 0.027195, l3: 0.038593, l4: 0.064188, l5: 0.130042, l6: 0.289931\n",
      "\n",
      "[epoch: 384/400, batch: 256/1000, ite: 50783] train loss: 1.1118, accuracy: 96.0826%, tar: 0.0198 \n",
      "l0: 0.020316, l1: 0.021971, l2: 0.030789, l3: 0.052031, l4: 0.126366, l5: 0.246834, l6: 0.444441\n",
      "\n",
      "[epoch: 384/400, batch: 264/1000, ite: 50784] train loss: 1.1122, accuracy: 93.8943%, tar: 0.0198 \n",
      "l0: 0.016044, l1: 0.016864, l2: 0.022392, l3: 0.033038, l4: 0.057377, l5: 0.116009, l6: 0.293701\n",
      "\n",
      "[epoch: 384/400, batch: 272/1000, ite: 50785] train loss: 1.1118, accuracy: 95.7204%, tar: 0.0198 \n",
      "l0: 0.016429, l1: 0.017682, l2: 0.025526, l3: 0.047352, l4: 0.103741, l5: 0.224213, l6: 0.388445\n",
      "\n",
      "[epoch: 384/400, batch: 280/1000, ite: 50786] train loss: 1.1120, accuracy: 95.6412%, tar: 0.0198 \n",
      "l0: 0.020611, l1: 0.021785, l2: 0.028113, l3: 0.043949, l4: 0.076774, l5: 0.154098, l6: 0.360301\n",
      "\n",
      "[epoch: 384/400, batch: 288/1000, ite: 50787] train loss: 1.1119, accuracy: 94.2727%, tar: 0.0198 \n",
      "l0: 0.018182, l1: 0.019184, l2: 0.028034, l3: 0.044491, l4: 0.076516, l5: 0.137245, l6: 0.267639\n",
      "\n",
      "[epoch: 384/400, batch: 296/1000, ite: 50788] train loss: 1.1116, accuracy: 95.8899%, tar: 0.0198 \n",
      "l0: 0.017725, l1: 0.019867, l2: 0.030409, l3: 0.049759, l4: 0.087640, l5: 0.190273, l6: 0.379519\n",
      "\n",
      "[epoch: 384/400, batch: 304/1000, ite: 50789] train loss: 1.1117, accuracy: 95.3664%, tar: 0.0198 \n",
      "l0: 0.021972, l1: 0.023474, l2: 0.033288, l3: 0.048997, l4: 0.080560, l5: 0.162396, l6: 0.377494\n",
      "\n",
      "[epoch: 384/400, batch: 312/1000, ite: 50790] train loss: 1.1117, accuracy: 94.7584%, tar: 0.0198 \n",
      "l0: 0.019427, l1: 0.020900, l2: 0.029360, l3: 0.047791, l4: 0.097846, l5: 0.198418, l6: 0.432703\n",
      "\n",
      "[epoch: 384/400, batch: 320/1000, ite: 50791] train loss: 1.1119, accuracy: 94.7631%, tar: 0.0198 \n",
      "l0: 0.023160, l1: 0.025545, l2: 0.036438, l3: 0.062590, l4: 0.140873, l5: 0.300460, l6: 0.544107\n",
      "\n",
      "[epoch: 384/400, batch: 328/1000, ite: 50792] train loss: 1.1126, accuracy: 93.6378%, tar: 0.0198 \n",
      "l0: 0.017532, l1: 0.018922, l2: 0.025044, l3: 0.039180, l4: 0.082484, l5: 0.166100, l6: 0.380572\n",
      "\n",
      "[epoch: 384/400, batch: 336/1000, ite: 50793] train loss: 1.1126, accuracy: 95.1090%, tar: 0.0198 \n",
      "l0: 0.023879, l1: 0.025404, l2: 0.034304, l3: 0.054140, l4: 0.104487, l5: 0.194036, l6: 0.362216\n",
      "\n",
      "[epoch: 384/400, batch: 344/1000, ite: 50794] train loss: 1.1127, accuracy: 94.5338%, tar: 0.0198 \n",
      "l0: 0.021208, l1: 0.022322, l2: 0.029559, l3: 0.043172, l4: 0.076891, l5: 0.154452, l6: 0.326372\n",
      "\n",
      "[epoch: 384/400, batch: 352/1000, ite: 50795] train loss: 1.1125, accuracy: 94.9908%, tar: 0.0198 \n",
      "l0: 0.020271, l1: 0.021848, l2: 0.029784, l3: 0.039956, l4: 0.070644, l5: 0.126556, l6: 0.296792\n",
      "\n",
      "[epoch: 384/400, batch: 360/1000, ite: 50796] train loss: 1.1123, accuracy: 95.6993%, tar: 0.0198 \n",
      "l0: 0.012700, l1: 0.014057, l2: 0.021959, l3: 0.037668, l4: 0.070137, l5: 0.201829, l6: 0.385330\n",
      "\n",
      "[epoch: 384/400, batch: 368/1000, ite: 50797] train loss: 1.1123, accuracy: 95.5531%, tar: 0.0198 \n",
      "l0: 0.027659, l1: 0.029387, l2: 0.041783, l3: 0.063051, l4: 0.119005, l5: 0.257382, l6: 0.530199\n",
      "\n",
      "[epoch: 384/400, batch: 376/1000, ite: 50798] train loss: 1.1129, accuracy: 93.1356%, tar: 0.0198 \n",
      "l0: 0.021291, l1: 0.022420, l2: 0.028771, l3: 0.042022, l4: 0.088778, l5: 0.197955, l6: 0.482711\n",
      "\n",
      "[epoch: 384/400, batch: 384/1000, ite: 50799] train loss: 1.1133, accuracy: 94.2832%, tar: 0.0198 \n",
      "l0: 0.020048, l1: 0.021625, l2: 0.030355, l3: 0.047040, l4: 0.086434, l5: 0.223173, l6: 0.437570\n",
      "\n",
      "[epoch: 384/400, batch: 392/1000, ite: 50800] train loss: 1.1135, accuracy: 94.6131%, tar: 0.0198 \n",
      "l0: 0.016324, l1: 0.017371, l2: 0.024409, l3: 0.037160, l4: 0.064309, l5: 0.117738, l6: 0.250604\n",
      "\n",
      "[epoch: 384/400, batch: 400/1000, ite: 50801] train loss: 1.1131, accuracy: 96.1103%, tar: 0.0198 \n",
      "l0: 0.023738, l1: 0.025455, l2: 0.035287, l3: 0.051895, l4: 0.090966, l5: 0.199053, l6: 0.385013\n",
      "\n",
      "[epoch: 384/400, batch: 408/1000, ite: 50802] train loss: 1.1132, accuracy: 94.7828%, tar: 0.0198 \n",
      "l0: 0.017650, l1: 0.018905, l2: 0.026048, l3: 0.038567, l4: 0.063990, l5: 0.124555, l6: 0.323926\n",
      "\n",
      "[epoch: 384/400, batch: 416/1000, ite: 50803] train loss: 1.1130, accuracy: 95.3387%, tar: 0.0198 \n",
      "l0: 0.020085, l1: 0.021669, l2: 0.031151, l3: 0.059124, l4: 0.099161, l5: 0.163401, l6: 0.306020\n",
      "\n",
      "[epoch: 384/400, batch: 424/1000, ite: 50804] train loss: 1.1129, accuracy: 95.8080%, tar: 0.0198 \n",
      "l0: 0.022283, l1: 0.023835, l2: 0.031878, l3: 0.045500, l4: 0.096449, l5: 0.216459, l6: 0.398983\n",
      "\n",
      "[epoch: 384/400, batch: 432/1000, ite: 50805] train loss: 1.1130, accuracy: 94.1712%, tar: 0.0198 \n",
      "l0: 0.015540, l1: 0.016593, l2: 0.022963, l3: 0.033814, l4: 0.061901, l5: 0.164179, l6: 0.339351\n",
      "\n",
      "[epoch: 384/400, batch: 440/1000, ite: 50806] train loss: 1.1129, accuracy: 95.1488%, tar: 0.0198 \n",
      "l0: 0.019265, l1: 0.020150, l2: 0.028376, l3: 0.042007, l4: 0.082969, l5: 0.169300, l6: 0.380057\n",
      "\n",
      "[epoch: 384/400, batch: 448/1000, ite: 50807] train loss: 1.1129, accuracy: 95.1432%, tar: 0.0198 \n",
      "l0: 0.024203, l1: 0.026858, l2: 0.035508, l3: 0.054511, l4: 0.106595, l5: 0.228390, l6: 0.427646\n",
      "\n",
      "[epoch: 384/400, batch: 456/1000, ite: 50808] train loss: 1.1132, accuracy: 94.8867%, tar: 0.0198 \n",
      "l0: 0.018199, l1: 0.019763, l2: 0.026838, l3: 0.041410, l4: 0.088439, l5: 0.148748, l6: 0.253035\n",
      "\n",
      "[epoch: 384/400, batch: 464/1000, ite: 50809] train loss: 1.1129, accuracy: 96.1272%, tar: 0.0198 \n",
      "l0: 0.027033, l1: 0.029644, l2: 0.040983, l3: 0.064832, l4: 0.142865, l5: 0.262179, l6: 0.462587\n",
      "\n",
      "[epoch: 384/400, batch: 472/1000, ite: 50810] train loss: 1.1134, accuracy: 94.3625%, tar: 0.0198 \n",
      "l0: 0.021453, l1: 0.022926, l2: 0.032218, l3: 0.048861, l4: 0.092286, l5: 0.202862, l6: 0.412641\n",
      "\n",
      "[epoch: 384/400, batch: 480/1000, ite: 50811] train loss: 1.1135, accuracy: 94.2514%, tar: 0.0198 \n",
      "l0: 0.018946, l1: 0.021473, l2: 0.028844, l3: 0.049763, l4: 0.095666, l5: 0.195129, l6: 0.328621\n",
      "\n",
      "[epoch: 384/400, batch: 488/1000, ite: 50812] train loss: 1.1135, accuracy: 95.9626%, tar: 0.0198 \n",
      "l0: 0.019628, l1: 0.020801, l2: 0.029467, l3: 0.046155, l4: 0.092618, l5: 0.188743, l6: 0.455887\n",
      "\n",
      "[epoch: 384/400, batch: 496/1000, ite: 50813] train loss: 1.1137, accuracy: 94.6708%, tar: 0.0198 \n",
      "l0: 0.017941, l1: 0.020223, l2: 0.029776, l3: 0.049817, l4: 0.098495, l5: 0.228738, l6: 0.423851\n",
      "\n",
      "[epoch: 384/400, batch: 504/1000, ite: 50814] train loss: 1.1139, accuracy: 94.7169%, tar: 0.0198 \n",
      "l0: 0.015998, l1: 0.016831, l2: 0.023739, l3: 0.035923, l4: 0.064885, l5: 0.125287, l6: 0.244864\n",
      "\n",
      "[epoch: 384/400, batch: 512/1000, ite: 50815] train loss: 1.1135, accuracy: 96.2647%, tar: 0.0198 \n",
      "l0: 0.021605, l1: 0.022971, l2: 0.030178, l3: 0.044813, l4: 0.102742, l5: 0.182801, l6: 0.379875\n",
      "\n",
      "[epoch: 384/400, batch: 520/1000, ite: 50816] train loss: 1.1136, accuracy: 94.3554%, tar: 0.0198 \n",
      "l0: 0.014592, l1: 0.015645, l2: 0.023098, l3: 0.038328, l4: 0.075580, l5: 0.154758, l6: 0.293204\n",
      "\n",
      "[epoch: 384/400, batch: 528/1000, ite: 50817] train loss: 1.1134, accuracy: 96.6144%, tar: 0.0198 \n",
      "l0: 0.016830, l1: 0.017614, l2: 0.023553, l3: 0.037779, l4: 0.101159, l5: 0.171689, l6: 0.333041\n",
      "\n",
      "[epoch: 384/400, batch: 536/1000, ite: 50818] train loss: 1.1133, accuracy: 95.5688%, tar: 0.0198 \n",
      "l0: 0.014663, l1: 0.016284, l2: 0.025460, l3: 0.043436, l4: 0.083104, l5: 0.152555, l6: 0.331398\n",
      "\n",
      "[epoch: 384/400, batch: 544/1000, ite: 50819] train loss: 1.1131, accuracy: 95.6403%, tar: 0.0198 \n",
      "l0: 0.015754, l1: 0.016758, l2: 0.024682, l3: 0.037845, l4: 0.071258, l5: 0.154779, l6: 0.325292\n",
      "\n",
      "[epoch: 384/400, batch: 552/1000, ite: 50820] train loss: 1.1130, accuracy: 95.7918%, tar: 0.0198 \n",
      "l0: 0.034705, l1: 0.036884, l2: 0.047476, l3: 0.072066, l4: 0.145055, l5: 0.360101, l6: 0.701330\n",
      "\n",
      "[epoch: 384/400, batch: 560/1000, ite: 50821] train loss: 1.1142, accuracy: 91.3921%, tar: 0.0198 \n",
      "l0: 0.027817, l1: 0.030397, l2: 0.043888, l3: 0.070891, l4: 0.140253, l5: 0.290519, l6: 0.507381\n",
      "\n",
      "[epoch: 384/400, batch: 568/1000, ite: 50822] train loss: 1.1148, accuracy: 93.7106%, tar: 0.0198 \n",
      "l0: 0.028273, l1: 0.029562, l2: 0.038507, l3: 0.053855, l4: 0.094913, l5: 0.172496, l6: 0.399478\n",
      "\n",
      "[epoch: 384/400, batch: 576/1000, ite: 50823] train loss: 1.1149, accuracy: 94.1716%, tar: 0.0198 \n",
      "l0: 0.023569, l1: 0.024752, l2: 0.032596, l3: 0.051677, l4: 0.096979, l5: 0.183701, l6: 0.381869\n",
      "\n",
      "[epoch: 384/400, batch: 584/1000, ite: 50824] train loss: 1.1150, accuracy: 93.9625%, tar: 0.0198 \n",
      "l0: 0.019968, l1: 0.020941, l2: 0.027818, l3: 0.043735, l4: 0.081446, l5: 0.181050, l6: 0.365622\n",
      "\n",
      "[epoch: 384/400, batch: 592/1000, ite: 50825] train loss: 1.1150, accuracy: 95.1653%, tar: 0.0198 \n",
      "l0: 0.021807, l1: 0.022933, l2: 0.031383, l3: 0.043860, l4: 0.079872, l5: 0.170198, l6: 0.337586\n",
      "\n",
      "[epoch: 384/400, batch: 600/1000, ite: 50826] train loss: 1.1149, accuracy: 95.2150%, tar: 0.0198 \n",
      "l0: 0.019707, l1: 0.020871, l2: 0.027001, l3: 0.039945, l4: 0.068412, l5: 0.138811, l6: 0.323838\n",
      "\n",
      "[epoch: 384/400, batch: 608/1000, ite: 50827] train loss: 1.1148, accuracy: 95.0135%, tar: 0.0198 \n",
      "l0: 0.026146, l1: 0.028167, l2: 0.039346, l3: 0.060932, l4: 0.112158, l5: 0.260986, l6: 0.487814\n",
      "\n",
      "[epoch: 384/400, batch: 616/1000, ite: 50828] train loss: 1.1152, accuracy: 93.6298%, tar: 0.0198 \n",
      "l0: 0.019429, l1: 0.020808, l2: 0.029125, l3: 0.046493, l4: 0.078831, l5: 0.149824, l6: 0.298889\n",
      "\n",
      "[epoch: 384/400, batch: 624/1000, ite: 50829] train loss: 1.1150, accuracy: 95.3350%, tar: 0.0198 \n",
      "l0: 0.019107, l1: 0.020208, l2: 0.027417, l3: 0.039639, l4: 0.070150, l5: 0.142486, l6: 0.360439\n",
      "\n",
      "[epoch: 384/400, batch: 632/1000, ite: 50830] train loss: 1.1149, accuracy: 95.1220%, tar: 0.0198 \n",
      "l0: 0.016757, l1: 0.017597, l2: 0.026112, l3: 0.043447, l4: 0.085644, l5: 0.158539, l6: 0.303277\n",
      "\n",
      "[epoch: 384/400, batch: 640/1000, ite: 50831] train loss: 1.1148, accuracy: 95.6603%, tar: 0.0198 \n",
      "l0: 0.017907, l1: 0.018894, l2: 0.026463, l3: 0.039489, l4: 0.073194, l5: 0.158513, l6: 0.373557\n",
      "\n",
      "[epoch: 384/400, batch: 648/1000, ite: 50832] train loss: 1.1147, accuracy: 94.9764%, tar: 0.0198 \n",
      "l0: 0.022499, l1: 0.023351, l2: 0.031240, l3: 0.046271, l4: 0.084442, l5: 0.160192, l6: 0.406760\n",
      "\n",
      "[epoch: 384/400, batch: 656/1000, ite: 50833] train loss: 1.1148, accuracy: 94.3236%, tar: 0.0198 \n",
      "l0: 0.022914, l1: 0.023629, l2: 0.033688, l3: 0.055866, l4: 0.100112, l5: 0.200383, l6: 0.426780\n",
      "\n",
      "[epoch: 384/400, batch: 664/1000, ite: 50834] train loss: 1.1150, accuracy: 93.7638%, tar: 0.0198 \n",
      "l0: 0.023104, l1: 0.024415, l2: 0.032692, l3: 0.046276, l4: 0.078382, l5: 0.155071, l6: 0.369260\n",
      "\n",
      "[epoch: 384/400, batch: 672/1000, ite: 50835] train loss: 1.1150, accuracy: 94.7145%, tar: 0.0198 \n",
      "l0: 0.020494, l1: 0.021887, l2: 0.030274, l3: 0.045680, l4: 0.084847, l5: 0.188286, l6: 0.380532\n",
      "\n",
      "[epoch: 384/400, batch: 680/1000, ite: 50836] train loss: 1.1150, accuracy: 94.7538%, tar: 0.0198 \n",
      "l0: 0.019034, l1: 0.020438, l2: 0.029090, l3: 0.048045, l4: 0.090743, l5: 0.190944, l6: 0.389958\n",
      "\n",
      "[epoch: 384/400, batch: 688/1000, ite: 50837] train loss: 1.1151, accuracy: 95.0914%, tar: 0.0198 \n",
      "l0: 0.015254, l1: 0.016606, l2: 0.024638, l3: 0.039679, l4: 0.089072, l5: 0.173674, l6: 0.308793\n",
      "\n",
      "[epoch: 384/400, batch: 696/1000, ite: 50838] train loss: 1.1150, accuracy: 96.1717%, tar: 0.0198 \n",
      "l0: 0.016648, l1: 0.018398, l2: 0.025314, l3: 0.042227, l4: 0.076478, l5: 0.165836, l6: 0.312481\n",
      "\n",
      "[epoch: 384/400, batch: 704/1000, ite: 50839] train loss: 1.1148, accuracy: 96.2407%, tar: 0.0198 \n",
      "l0: 0.022650, l1: 0.023273, l2: 0.029851, l3: 0.044001, l4: 0.075997, l5: 0.148494, l6: 0.383593\n",
      "\n",
      "[epoch: 384/400, batch: 712/1000, ite: 50840] train loss: 1.1148, accuracy: 94.3514%, tar: 0.0198 \n",
      "l0: 0.020126, l1: 0.020700, l2: 0.027365, l3: 0.038862, l4: 0.070774, l5: 0.134117, l6: 0.288662\n",
      "\n",
      "[epoch: 384/400, batch: 720/1000, ite: 50841] train loss: 1.1146, accuracy: 95.5296%, tar: 0.0198 \n",
      "l0: 0.019434, l1: 0.020215, l2: 0.026818, l3: 0.041764, l4: 0.080102, l5: 0.186846, l6: 0.404476\n",
      "\n",
      "[epoch: 384/400, batch: 728/1000, ite: 50842] train loss: 1.1146, accuracy: 94.6909%, tar: 0.0198 \n",
      "l0: 0.021452, l1: 0.022748, l2: 0.032084, l3: 0.050620, l4: 0.087236, l5: 0.169542, l6: 0.320180\n",
      "\n",
      "[epoch: 384/400, batch: 736/1000, ite: 50843] train loss: 1.1145, accuracy: 94.8412%, tar: 0.0198 \n",
      "l0: 0.017723, l1: 0.019233, l2: 0.026392, l3: 0.040964, l4: 0.088275, l5: 0.195507, l6: 0.384050\n",
      "\n",
      "[epoch: 384/400, batch: 744/1000, ite: 50844] train loss: 1.1146, accuracy: 95.3231%, tar: 0.0198 \n",
      "l0: 0.018749, l1: 0.020009, l2: 0.026454, l3: 0.038346, l4: 0.075928, l5: 0.140765, l6: 0.322356\n",
      "\n",
      "[epoch: 384/400, batch: 752/1000, ite: 50845] train loss: 1.1144, accuracy: 95.6623%, tar: 0.0198 \n",
      "l0: 0.020878, l1: 0.022236, l2: 0.033961, l3: 0.051053, l4: 0.089263, l5: 0.176091, l6: 0.410631\n",
      "\n",
      "[epoch: 384/400, batch: 760/1000, ite: 50846] train loss: 1.1145, accuracy: 94.8330%, tar: 0.0198 \n",
      "l0: 0.014727, l1: 0.015959, l2: 0.023432, l3: 0.039530, l4: 0.071785, l5: 0.150121, l6: 0.317477\n",
      "\n",
      "[epoch: 384/400, batch: 768/1000, ite: 50847] train loss: 1.1144, accuracy: 96.3007%, tar: 0.0198 \n",
      "l0: 0.017910, l1: 0.018422, l2: 0.024090, l3: 0.034199, l4: 0.062153, l5: 0.142259, l6: 0.286925\n",
      "\n",
      "[epoch: 384/400, batch: 776/1000, ite: 50848] train loss: 1.1141, accuracy: 95.6452%, tar: 0.0198 \n",
      "l0: 0.019028, l1: 0.020330, l2: 0.028826, l3: 0.045342, l4: 0.081718, l5: 0.157508, l6: 0.357489\n",
      "\n",
      "[epoch: 384/400, batch: 784/1000, ite: 50849] train loss: 1.1140, accuracy: 94.9755%, tar: 0.0198 \n",
      "l0: 0.020934, l1: 0.021973, l2: 0.029878, l3: 0.046395, l4: 0.078226, l5: 0.158373, l6: 0.379209\n",
      "\n",
      "[epoch: 384/400, batch: 792/1000, ite: 50850] train loss: 1.1140, accuracy: 95.1854%, tar: 0.0198 \n",
      "l0: 0.022124, l1: 0.023541, l2: 0.032843, l3: 0.050643, l4: 0.091012, l5: 0.181160, l6: 0.377435\n",
      "\n",
      "[epoch: 384/400, batch: 800/1000, ite: 50851] train loss: 1.1141, accuracy: 94.2990%, tar: 0.0198 \n",
      "l0: 0.015459, l1: 0.016473, l2: 0.022996, l3: 0.034755, l4: 0.059506, l5: 0.125268, l6: 0.301758\n",
      "\n",
      "[epoch: 384/400, batch: 808/1000, ite: 50852] train loss: 1.1138, accuracy: 95.8848%, tar: 0.0198 \n",
      "l0: 0.018443, l1: 0.019681, l2: 0.027669, l3: 0.043494, l4: 0.083966, l5: 0.167183, l6: 0.366113\n",
      "\n",
      "[epoch: 384/400, batch: 816/1000, ite: 50853] train loss: 1.1138, accuracy: 94.9953%, tar: 0.0198 \n",
      "l0: 0.018054, l1: 0.019104, l2: 0.025560, l3: 0.037080, l4: 0.066289, l5: 0.128709, l6: 0.324592\n",
      "\n",
      "[epoch: 384/400, batch: 824/1000, ite: 50854] train loss: 1.1136, accuracy: 95.5664%, tar: 0.0198 \n",
      "l0: 0.022894, l1: 0.023633, l2: 0.032169, l3: 0.046262, l4: 0.082927, l5: 0.173580, l6: 0.409227\n",
      "\n",
      "[epoch: 384/400, batch: 832/1000, ite: 50855] train loss: 1.1137, accuracy: 94.2120%, tar: 0.0198 \n",
      "l0: 0.029185, l1: 0.030490, l2: 0.039458, l3: 0.059172, l4: 0.110225, l5: 0.251367, l6: 0.542022\n",
      "\n",
      "[epoch: 384/400, batch: 840/1000, ite: 50856] train loss: 1.1143, accuracy: 93.4180%, tar: 0.0198 \n",
      "l0: 0.022194, l1: 0.024623, l2: 0.033268, l3: 0.055338, l4: 0.111496, l5: 0.191326, l6: 0.376825\n",
      "\n",
      "[epoch: 384/400, batch: 848/1000, ite: 50857] train loss: 1.1144, accuracy: 95.5596%, tar: 0.0198 \n",
      "l0: 0.026687, l1: 0.027930, l2: 0.036626, l3: 0.056997, l4: 0.115847, l5: 0.303321, l6: 0.565508\n",
      "\n",
      "[epoch: 384/400, batch: 856/1000, ite: 50858] train loss: 1.1151, accuracy: 92.3851%, tar: 0.0198 \n",
      "l0: 0.023549, l1: 0.025341, l2: 0.035309, l3: 0.051311, l4: 0.103847, l5: 0.192012, l6: 0.359852\n",
      "\n",
      "[epoch: 384/400, batch: 864/1000, ite: 50859] train loss: 1.1151, accuracy: 95.2450%, tar: 0.0198 \n",
      "l0: 0.021686, l1: 0.023019, l2: 0.031232, l3: 0.046208, l4: 0.079955, l5: 0.149943, l6: 0.308211\n",
      "\n",
      "[epoch: 384/400, batch: 872/1000, ite: 50860] train loss: 1.1150, accuracy: 95.1960%, tar: 0.0198 \n",
      "l0: 0.021768, l1: 0.023296, l2: 0.033392, l3: 0.053868, l4: 0.094013, l5: 0.199743, l6: 0.409051\n",
      "\n",
      "[epoch: 384/400, batch: 880/1000, ite: 50861] train loss: 1.1151, accuracy: 94.4424%, tar: 0.0198 \n",
      "l0: 0.015825, l1: 0.018757, l2: 0.028638, l3: 0.051959, l4: 0.102705, l5: 0.174631, l6: 0.294181\n",
      "\n",
      "[epoch: 384/400, batch: 888/1000, ite: 50862] train loss: 1.1150, accuracy: 96.0760%, tar: 0.0198 \n",
      "l0: 0.020538, l1: 0.021957, l2: 0.030388, l3: 0.043245, l4: 0.073443, l5: 0.161839, l6: 0.342357\n",
      "\n",
      "[epoch: 384/400, batch: 896/1000, ite: 50863] train loss: 1.1149, accuracy: 95.4827%, tar: 0.0198 \n",
      "l0: 0.017473, l1: 0.019095, l2: 0.028389, l3: 0.044912, l4: 0.088350, l5: 0.204401, l6: 0.392467\n",
      "\n",
      "[epoch: 384/400, batch: 904/1000, ite: 50864] train loss: 1.1150, accuracy: 94.9531%, tar: 0.0198 \n",
      "l0: 0.015649, l1: 0.016931, l2: 0.023252, l3: 0.035281, l4: 0.059043, l5: 0.118081, l6: 0.255891\n",
      "\n",
      "[epoch: 384/400, batch: 912/1000, ite: 50865] train loss: 1.1146, accuracy: 96.1186%, tar: 0.0198 \n",
      "l0: 0.018969, l1: 0.020210, l2: 0.027939, l3: 0.039865, l4: 0.072709, l5: 0.143903, l6: 0.296426\n",
      "\n",
      "[epoch: 384/400, batch: 920/1000, ite: 50866] train loss: 1.1143, accuracy: 96.0918%, tar: 0.0198 \n",
      "l0: 0.008588, l1: 0.010011, l2: 0.015446, l3: 0.025847, l4: 0.056947, l5: 0.115040, l6: 0.218543\n",
      "\n",
      "[epoch: 384/400, batch: 928/1000, ite: 50867] train loss: 1.1138, accuracy: 97.5900%, tar: 0.0198 \n",
      "l0: 0.022728, l1: 0.025476, l2: 0.037995, l3: 0.061885, l4: 0.109977, l5: 0.189066, l6: 0.373219\n",
      "\n",
      "[epoch: 384/400, batch: 936/1000, ite: 50868] train loss: 1.1139, accuracy: 95.4179%, tar: 0.0198 \n",
      "l0: 0.020097, l1: 0.020890, l2: 0.026581, l3: 0.039066, l4: 0.072198, l5: 0.134863, l6: 0.278574\n",
      "\n",
      "[epoch: 384/400, batch: 944/1000, ite: 50869] train loss: 1.1136, accuracy: 95.5556%, tar: 0.0198 \n",
      "l0: 0.023346, l1: 0.025373, l2: 0.034455, l3: 0.051603, l4: 0.095399, l5: 0.206339, l6: 0.497565\n",
      "\n",
      "[epoch: 384/400, batch: 952/1000, ite: 50870] train loss: 1.1140, accuracy: 93.3398%, tar: 0.0198 \n",
      "l0: 0.019553, l1: 0.020652, l2: 0.027486, l3: 0.041558, l4: 0.077412, l5: 0.158900, l6: 0.356730\n",
      "\n",
      "[epoch: 384/400, batch: 960/1000, ite: 50871] train loss: 1.1140, accuracy: 95.3477%, tar: 0.0198 \n",
      "l0: 0.018276, l1: 0.018879, l2: 0.023811, l3: 0.033358, l4: 0.049631, l5: 0.085302, l6: 0.170688\n",
      "\n",
      "[epoch: 384/400, batch: 968/1000, ite: 50872] train loss: 1.1133, accuracy: 96.8147%, tar: 0.0198 \n",
      "l0: 0.017043, l1: 0.018732, l2: 0.025718, l3: 0.041419, l4: 0.091979, l5: 0.192645, l6: 0.359120\n",
      "\n",
      "[epoch: 384/400, batch: 976/1000, ite: 50873] train loss: 1.1133, accuracy: 95.6149%, tar: 0.0198 \n",
      "l0: 0.021767, l1: 0.023157, l2: 0.031533, l3: 0.046024, l4: 0.087189, l5: 0.160672, l6: 0.370968\n",
      "\n",
      "[epoch: 384/400, batch: 984/1000, ite: 50874] train loss: 1.1133, accuracy: 95.2224%, tar: 0.0198 \n",
      "l0: 0.024171, l1: 0.025547, l2: 0.034214, l3: 0.049821, l4: 0.084071, l5: 0.169948, l6: 0.392512\n",
      "\n",
      "[epoch: 384/400, batch: 992/1000, ite: 50875] train loss: 1.1134, accuracy: 94.9888%, tar: 0.0198 \n",
      "l0: 0.024139, l1: 0.025759, l2: 0.032671, l3: 0.048486, l4: 0.090059, l5: 0.197284, l6: 0.494091\n",
      "\n",
      "[epoch: 384/400, batch: 1000/1000, ite: 50876] train loss: 1.1138, accuracy: 93.0886%, tar: 0.0198 \n",
      "l0: 0.019119, l1: 0.020181, l2: 0.027418, l3: 0.040569, l4: 0.077187, l5: 0.174347, l6: 0.385580\n",
      "\n",
      "[epoch: 385/400, batch: 8/1000, ite: 50877] train loss: 1.1138, accuracy: 94.7578%, tar: 0.0198 \n",
      "l0: 0.012433, l1: 0.013516, l2: 0.020447, l3: 0.031948, l4: 0.055519, l5: 0.100215, l6: 0.207509\n",
      "\n",
      "[epoch: 385/400, batch: 16/1000, ite: 50878] train loss: 1.1133, accuracy: 97.0230%, tar: 0.0198 \n",
      "l0: 0.027068, l1: 0.028935, l2: 0.037111, l3: 0.053981, l4: 0.103039, l5: 0.246208, l6: 0.454341\n",
      "\n",
      "[epoch: 385/400, batch: 24/1000, ite: 50879] train loss: 1.1136, accuracy: 94.4080%, tar: 0.0198 \n",
      "l0: 0.025616, l1: 0.026685, l2: 0.036705, l3: 0.054448, l4: 0.091834, l5: 0.161521, l6: 0.346597\n",
      "\n",
      "[epoch: 385/400, batch: 32/1000, ite: 50880] train loss: 1.1136, accuracy: 94.6565%, tar: 0.0198 \n",
      "l0: 0.016469, l1: 0.017729, l2: 0.026065, l3: 0.043631, l4: 0.086023, l5: 0.164172, l6: 0.366525\n",
      "\n",
      "[epoch: 385/400, batch: 40/1000, ite: 50881] train loss: 1.1136, accuracy: 95.2190%, tar: 0.0198 \n",
      "l0: 0.016749, l1: 0.017869, l2: 0.023244, l3: 0.035361, l4: 0.066299, l5: 0.132179, l6: 0.386064\n",
      "\n",
      "[epoch: 385/400, batch: 48/1000, ite: 50882] train loss: 1.1135, accuracy: 94.9868%, tar: 0.0198 \n",
      "l0: 0.022228, l1: 0.023018, l2: 0.029961, l3: 0.045999, l4: 0.092007, l5: 0.187505, l6: 0.414320\n",
      "\n",
      "[epoch: 385/400, batch: 56/1000, ite: 50883] train loss: 1.1136, accuracy: 94.2226%, tar: 0.0198 \n",
      "l0: 0.019649, l1: 0.021482, l2: 0.030132, l3: 0.045524, l4: 0.092471, l5: 0.230599, l6: 0.507208\n",
      "\n",
      "[epoch: 385/400, batch: 64/1000, ite: 50884] train loss: 1.1140, accuracy: 93.0849%, tar: 0.0198 \n",
      "l0: 0.014107, l1: 0.014557, l2: 0.019881, l3: 0.030116, l4: 0.051491, l5: 0.105148, l6: 0.226702\n",
      "\n",
      "[epoch: 385/400, batch: 72/1000, ite: 50885] train loss: 1.1136, accuracy: 96.5977%, tar: 0.0198 \n",
      "l0: 0.022633, l1: 0.023876, l2: 0.031286, l3: 0.049132, l4: 0.107993, l5: 0.209404, l6: 0.423791\n",
      "\n",
      "[epoch: 385/400, batch: 80/1000, ite: 50886] train loss: 1.1138, accuracy: 94.6252%, tar: 0.0198 \n",
      "l0: 0.020506, l1: 0.021621, l2: 0.029222, l3: 0.041764, l4: 0.074094, l5: 0.161387, l6: 0.354808\n",
      "\n",
      "[epoch: 385/400, batch: 88/1000, ite: 50887] train loss: 1.1137, accuracy: 94.3609%, tar: 0.0198 \n",
      "l0: 0.019309, l1: 0.021199, l2: 0.029205, l3: 0.045690, l4: 0.079388, l5: 0.167226, l6: 0.316703\n",
      "\n",
      "[epoch: 385/400, batch: 96/1000, ite: 50888] train loss: 1.1136, accuracy: 95.6180%, tar: 0.0198 \n",
      "l0: 0.015545, l1: 0.017212, l2: 0.024282, l3: 0.039388, l4: 0.069734, l5: 0.154469, l6: 0.345362\n",
      "\n",
      "[epoch: 385/400, batch: 104/1000, ite: 50889] train loss: 1.1135, accuracy: 95.8058%, tar: 0.0198 \n",
      "l0: 0.025364, l1: 0.026657, l2: 0.034806, l3: 0.052855, l4: 0.107747, l5: 0.242557, l6: 0.516236\n",
      "\n",
      "[epoch: 385/400, batch: 112/1000, ite: 50890] train loss: 1.1139, accuracy: 93.0562%, tar: 0.0198 \n",
      "l0: 0.024404, l1: 0.026785, l2: 0.037744, l3: 0.060915, l4: 0.112106, l5: 0.237996, l6: 0.530503\n",
      "\n",
      "[epoch: 385/400, batch: 120/1000, ite: 50891] train loss: 1.1144, accuracy: 93.7760%, tar: 0.0198 \n",
      "l0: 0.019433, l1: 0.020404, l2: 0.027720, l3: 0.040906, l4: 0.080820, l5: 0.172871, l6: 0.393394\n",
      "\n",
      "[epoch: 385/400, batch: 128/1000, ite: 50892] train loss: 1.1145, accuracy: 95.2807%, tar: 0.0198 \n",
      "l0: 0.021554, l1: 0.022821, l2: 0.030784, l3: 0.045350, l4: 0.077936, l5: 0.166154, l6: 0.349950\n",
      "\n",
      "[epoch: 385/400, batch: 136/1000, ite: 50893] train loss: 1.1144, accuracy: 94.6701%, tar: 0.0198 \n",
      "l0: 0.019204, l1: 0.020274, l2: 0.028395, l3: 0.044056, l4: 0.082039, l5: 0.157957, l6: 0.355545\n",
      "\n",
      "[epoch: 385/400, batch: 144/1000, ite: 50894] train loss: 1.1144, accuracy: 94.7253%, tar: 0.0198 \n",
      "l0: 0.017687, l1: 0.018616, l2: 0.026520, l3: 0.038840, l4: 0.066103, l5: 0.123602, l6: 0.251789\n",
      "\n",
      "[epoch: 385/400, batch: 152/1000, ite: 50895] train loss: 1.1140, accuracy: 96.4534%, tar: 0.0198 \n",
      "l0: 0.021739, l1: 0.023173, l2: 0.030809, l3: 0.049509, l4: 0.092101, l5: 0.190164, l6: 0.428467\n",
      "\n",
      "[epoch: 385/400, batch: 160/1000, ite: 50896] train loss: 1.1142, accuracy: 94.0977%, tar: 0.0198 \n",
      "l0: 0.015787, l1: 0.018095, l2: 0.023832, l3: 0.041881, l4: 0.084487, l5: 0.185559, l6: 0.322442\n",
      "\n",
      "[epoch: 385/400, batch: 168/1000, ite: 50897] train loss: 1.1141, accuracy: 95.8360%, tar: 0.0198 \n",
      "l0: 0.021017, l1: 0.021978, l2: 0.029044, l3: 0.041172, l4: 0.071088, l5: 0.154965, l6: 0.309815\n",
      "\n",
      "[epoch: 385/400, batch: 176/1000, ite: 50898] train loss: 1.1139, accuracy: 95.5406%, tar: 0.0198 \n",
      "l0: 0.015552, l1: 0.017185, l2: 0.025217, l3: 0.038918, l4: 0.079283, l5: 0.155740, l6: 0.347033\n",
      "\n",
      "[epoch: 385/400, batch: 184/1000, ite: 50899] train loss: 1.1138, accuracy: 95.7739%, tar: 0.0198 \n",
      "l0: 0.018449, l1: 0.020036, l2: 0.027808, l3: 0.044725, l4: 0.078345, l5: 0.193678, l6: 0.411556\n",
      "\n",
      "[epoch: 385/400, batch: 192/1000, ite: 50900] train loss: 1.1139, accuracy: 94.7742%, tar: 0.0198 \n",
      "l0: 0.021194, l1: 0.023062, l2: 0.032676, l3: 0.054742, l4: 0.095899, l5: 0.166099, l6: 0.329928\n",
      "\n",
      "[epoch: 385/400, batch: 200/1000, ite: 50901] train loss: 1.1139, accuracy: 95.5905%, tar: 0.0198 \n",
      "l0: 0.016600, l1: 0.017947, l2: 0.024338, l3: 0.038550, l4: 0.070519, l5: 0.147959, l6: 0.364638\n",
      "\n",
      "[epoch: 385/400, batch: 208/1000, ite: 50902] train loss: 1.1138, accuracy: 95.2928%, tar: 0.0198 \n",
      "l0: 0.016963, l1: 0.018677, l2: 0.026865, l3: 0.041524, l4: 0.109158, l5: 0.149136, l6: 0.368169\n",
      "\n",
      "[epoch: 385/400, batch: 216/1000, ite: 50903] train loss: 1.1138, accuracy: 96.1014%, tar: 0.0198 \n",
      "l0: 0.014540, l1: 0.015697, l2: 0.022168, l3: 0.034185, l4: 0.076381, l5: 0.170643, l6: 0.310698\n",
      "\n",
      "[epoch: 385/400, batch: 224/1000, ite: 50904] train loss: 1.1136, accuracy: 95.7351%, tar: 0.0198 \n",
      "l0: 0.014543, l1: 0.016629, l2: 0.025315, l3: 0.047267, l4: 0.097168, l5: 0.175692, l6: 0.376450\n",
      "\n",
      "[epoch: 385/400, batch: 232/1000, ite: 50905] train loss: 1.1136, accuracy: 95.8708%, tar: 0.0198 \n",
      "l0: 0.018345, l1: 0.019802, l2: 0.027243, l3: 0.044255, l4: 0.092097, l5: 0.184700, l6: 0.309493\n",
      "\n",
      "[epoch: 385/400, batch: 240/1000, ite: 50906] train loss: 1.1135, accuracy: 95.6420%, tar: 0.0198 \n",
      "l0: 0.014564, l1: 0.015194, l2: 0.020852, l3: 0.031804, l4: 0.055572, l5: 0.112025, l6: 0.203119\n",
      "\n",
      "[epoch: 385/400, batch: 248/1000, ite: 50907] train loss: 1.1130, accuracy: 96.8818%, tar: 0.0198 \n",
      "l0: 0.016384, l1: 0.018068, l2: 0.027210, l3: 0.046022, l4: 0.102255, l5: 0.274200, l6: 0.470796\n",
      "\n",
      "[epoch: 385/400, batch: 256/1000, ite: 50908] train loss: 1.1134, accuracy: 93.9430%, tar: 0.0198 \n",
      "l0: 0.017673, l1: 0.018856, l2: 0.028427, l3: 0.045328, l4: 0.094472, l5: 0.173031, l6: 0.378967\n",
      "\n",
      "[epoch: 385/400, batch: 264/1000, ite: 50909] train loss: 1.1134, accuracy: 95.4347%, tar: 0.0198 \n",
      "l0: 0.018659, l1: 0.019983, l2: 0.026935, l3: 0.042463, l4: 0.079327, l5: 0.169220, l6: 0.260056\n",
      "\n",
      "[epoch: 385/400, batch: 272/1000, ite: 50910] train loss: 1.1131, accuracy: 96.1824%, tar: 0.0198 \n",
      "l0: 0.019232, l1: 0.021645, l2: 0.030669, l3: 0.052411, l4: 0.090686, l5: 0.174732, l6: 0.379959\n",
      "\n",
      "[epoch: 385/400, batch: 280/1000, ite: 50911] train loss: 1.1132, accuracy: 96.0266%, tar: 0.0198 \n",
      "l0: 0.025714, l1: 0.028151, l2: 0.038631, l3: 0.062501, l4: 0.121885, l5: 0.281229, l6: 0.546873\n",
      "\n",
      "[epoch: 385/400, batch: 288/1000, ite: 50912] train loss: 1.1138, accuracy: 92.7836%, tar: 0.0198 \n",
      "l0: 0.018268, l1: 0.020643, l2: 0.028035, l3: 0.049748, l4: 0.109668, l5: 0.229304, l6: 0.431384\n",
      "\n",
      "[epoch: 385/400, batch: 296/1000, ite: 50913] train loss: 1.1140, accuracy: 94.1947%, tar: 0.0198 \n",
      "l0: 0.014036, l1: 0.015217, l2: 0.022743, l3: 0.034997, l4: 0.063907, l5: 0.125462, l6: 0.266719\n",
      "\n",
      "[epoch: 385/400, batch: 304/1000, ite: 50914] train loss: 1.1137, accuracy: 96.6903%, tar: 0.0198 \n",
      "l0: 0.021534, l1: 0.022726, l2: 0.031812, l3: 0.046716, l4: 0.077691, l5: 0.168379, l6: 0.372635\n",
      "\n",
      "[epoch: 385/400, batch: 312/1000, ite: 50915] train loss: 1.1137, accuracy: 95.4156%, tar: 0.0198 \n",
      "l0: 0.020213, l1: 0.022833, l2: 0.032780, l3: 0.056853, l4: 0.120529, l5: 0.232066, l6: 0.389379\n",
      "\n",
      "[epoch: 385/400, batch: 320/1000, ite: 50916] train loss: 1.1138, accuracy: 95.6167%, tar: 0.0198 \n",
      "l0: 0.021490, l1: 0.022560, l2: 0.029362, l3: 0.047526, l4: 0.087962, l5: 0.185270, l6: 0.371503\n",
      "\n",
      "[epoch: 385/400, batch: 328/1000, ite: 50917] train loss: 1.1139, accuracy: 94.4892%, tar: 0.0198 \n",
      "l0: 0.022270, l1: 0.023512, l2: 0.032452, l3: 0.049026, l4: 0.088730, l5: 0.197485, l6: 0.457957\n",
      "\n",
      "[epoch: 385/400, batch: 336/1000, ite: 50918] train loss: 1.1141, accuracy: 93.8245%, tar: 0.0198 \n",
      "l0: 0.018161, l1: 0.019213, l2: 0.025532, l3: 0.037498, l4: 0.066946, l5: 0.127215, l6: 0.241971\n",
      "\n",
      "[epoch: 385/400, batch: 344/1000, ite: 50919] train loss: 1.1138, accuracy: 96.1072%, tar: 0.0198 \n",
      "l0: 0.018010, l1: 0.019235, l2: 0.027393, l3: 0.040962, l4: 0.073377, l5: 0.144800, l6: 0.387566\n",
      "\n",
      "[epoch: 385/400, batch: 352/1000, ite: 50920] train loss: 1.1137, accuracy: 94.9574%, tar: 0.0198 \n",
      "l0: 0.019854, l1: 0.020498, l2: 0.025924, l3: 0.038144, l4: 0.067108, l5: 0.123364, l6: 0.270389\n",
      "\n",
      "[epoch: 385/400, batch: 360/1000, ite: 50921] train loss: 1.1134, accuracy: 95.3580%, tar: 0.0198 \n",
      "l0: 0.015992, l1: 0.017037, l2: 0.023438, l3: 0.034309, l4: 0.062583, l5: 0.135115, l6: 0.349281\n",
      "\n",
      "[epoch: 385/400, batch: 368/1000, ite: 50922] train loss: 1.1133, accuracy: 95.0149%, tar: 0.0198 \n",
      "l0: 0.021740, l1: 0.022969, l2: 0.031396, l3: 0.048536, l4: 0.081478, l5: 0.158286, l6: 0.367556\n",
      "\n",
      "[epoch: 385/400, batch: 376/1000, ite: 50923] train loss: 1.1133, accuracy: 93.9628%, tar: 0.0198 \n",
      "l0: 0.022583, l1: 0.024164, l2: 0.035725, l3: 0.058030, l4: 0.105866, l5: 0.224171, l6: 0.561219\n",
      "\n",
      "[epoch: 385/400, batch: 384/1000, ite: 50924] train loss: 1.1138, accuracy: 93.9628%, tar: 0.0198 \n",
      "l0: 0.021097, l1: 0.022642, l2: 0.032091, l3: 0.049829, l4: 0.096465, l5: 0.192163, l6: 0.418163\n",
      "\n",
      "[epoch: 385/400, batch: 392/1000, ite: 50925] train loss: 1.1140, accuracy: 94.3908%, tar: 0.0198 \n",
      "l0: 0.015421, l1: 0.016613, l2: 0.024554, l3: 0.040057, l4: 0.074152, l5: 0.136038, l6: 0.344151\n",
      "\n",
      "[epoch: 385/400, batch: 400/1000, ite: 50926] train loss: 1.1138, accuracy: 96.2618%, tar: 0.0198 \n",
      "l0: 0.021956, l1: 0.023398, l2: 0.031997, l3: 0.051502, l4: 0.095812, l5: 0.201086, l6: 0.389651\n",
      "\n",
      "[epoch: 385/400, batch: 408/1000, ite: 50927] train loss: 1.1139, accuracy: 94.1307%, tar: 0.0198 \n",
      "l0: 0.020775, l1: 0.022115, l2: 0.028875, l3: 0.046154, l4: 0.098084, l5: 0.196987, l6: 0.355794\n",
      "\n",
      "[epoch: 385/400, batch: 416/1000, ite: 50928] train loss: 1.1140, accuracy: 95.3511%, tar: 0.0198 \n",
      "l0: 0.019061, l1: 0.020632, l2: 0.029051, l3: 0.046638, l4: 0.079490, l5: 0.153382, l6: 0.345863\n",
      "\n",
      "[epoch: 385/400, batch: 424/1000, ite: 50929] train loss: 1.1139, accuracy: 95.4769%, tar: 0.0198 \n",
      "l0: 0.023001, l1: 0.024842, l2: 0.035200, l3: 0.052625, l4: 0.095742, l5: 0.213163, l6: 0.430776\n",
      "\n",
      "[epoch: 385/400, batch: 432/1000, ite: 50930] train loss: 1.1141, accuracy: 94.1771%, tar: 0.0198 \n",
      "l0: 0.019410, l1: 0.020558, l2: 0.027097, l3: 0.042235, l4: 0.084467, l5: 0.157479, l6: 0.336586\n",
      "\n",
      "[epoch: 385/400, batch: 440/1000, ite: 50931] train loss: 1.1140, accuracy: 95.1808%, tar: 0.0198 \n",
      "l0: 0.021597, l1: 0.023462, l2: 0.031509, l3: 0.048355, l4: 0.089616, l5: 0.191962, l6: 0.394460\n",
      "\n",
      "[epoch: 385/400, batch: 448/1000, ite: 50932] train loss: 1.1141, accuracy: 94.3839%, tar: 0.0198 \n",
      "l0: 0.017194, l1: 0.018408, l2: 0.024723, l3: 0.035543, l4: 0.073207, l5: 0.181053, l6: 0.373832\n",
      "\n",
      "[epoch: 385/400, batch: 456/1000, ite: 50933] train loss: 1.1141, accuracy: 95.7143%, tar: 0.0198 \n",
      "l0: 0.022758, l1: 0.024571, l2: 0.033596, l3: 0.054420, l4: 0.104239, l5: 0.197057, l6: 0.359025\n",
      "\n",
      "[epoch: 385/400, batch: 464/1000, ite: 50934] train loss: 1.1141, accuracy: 94.4864%, tar: 0.0198 \n",
      "l0: 0.024070, l1: 0.025343, l2: 0.031740, l3: 0.045231, l4: 0.079013, l5: 0.162097, l6: 0.340725\n",
      "\n",
      "[epoch: 385/400, batch: 472/1000, ite: 50935] train loss: 1.1141, accuracy: 94.9108%, tar: 0.0198 \n",
      "l0: 0.019978, l1: 0.020848, l2: 0.028574, l3: 0.043816, l4: 0.073770, l5: 0.147785, l6: 0.296690\n",
      "\n",
      "[epoch: 385/400, batch: 480/1000, ite: 50936] train loss: 1.1139, accuracy: 95.7283%, tar: 0.0198 \n",
      "l0: 0.017652, l1: 0.018593, l2: 0.023881, l3: 0.033454, l4: 0.056265, l5: 0.113484, l6: 0.308436\n",
      "\n",
      "[epoch: 385/400, batch: 488/1000, ite: 50937] train loss: 1.1136, accuracy: 95.2998%, tar: 0.0198 \n",
      "l0: 0.021444, l1: 0.022487, l2: 0.030031, l3: 0.045848, l4: 0.079497, l5: 0.168574, l6: 0.366834\n",
      "\n",
      "[epoch: 385/400, batch: 496/1000, ite: 50938] train loss: 1.1136, accuracy: 94.5792%, tar: 0.0198 \n",
      "l0: 0.019481, l1: 0.020391, l2: 0.028273, l3: 0.044595, l4: 0.086023, l5: 0.167531, l6: 0.359246\n",
      "\n",
      "[epoch: 385/400, batch: 504/1000, ite: 50939] train loss: 1.1136, accuracy: 95.2413%, tar: 0.0198 \n",
      "l0: 0.019371, l1: 0.020426, l2: 0.029304, l3: 0.044531, l4: 0.080987, l5: 0.172435, l6: 0.346164\n",
      "\n",
      "[epoch: 385/400, batch: 512/1000, ite: 50940] train loss: 1.1135, accuracy: 95.2784%, tar: 0.0198 \n",
      "l0: 0.024085, l1: 0.025389, l2: 0.035174, l3: 0.052948, l4: 0.091251, l5: 0.167162, l6: 0.359252\n",
      "\n",
      "[epoch: 385/400, batch: 520/1000, ite: 50941] train loss: 1.1135, accuracy: 95.1437%, tar: 0.0198 \n",
      "l0: 0.017120, l1: 0.018478, l2: 0.025620, l3: 0.036571, l4: 0.072286, l5: 0.176189, l6: 0.340971\n",
      "\n",
      "[epoch: 385/400, batch: 528/1000, ite: 50942] train loss: 1.1135, accuracy: 95.8175%, tar: 0.0198 \n",
      "l0: 0.023307, l1: 0.025053, l2: 0.035691, l3: 0.056751, l4: 0.116271, l5: 0.240043, l6: 0.509530\n",
      "\n",
      "[epoch: 385/400, batch: 536/1000, ite: 50943] train loss: 1.1139, accuracy: 93.7127%, tar: 0.0198 \n",
      "l0: 0.024833, l1: 0.026221, l2: 0.036736, l3: 0.056549, l4: 0.101367, l5: 0.191710, l6: 0.441317\n",
      "\n",
      "[epoch: 385/400, batch: 544/1000, ite: 50944] train loss: 1.1141, accuracy: 94.9273%, tar: 0.0198 \n",
      "l0: 0.017844, l1: 0.019200, l2: 0.027492, l3: 0.039203, l4: 0.069418, l5: 0.160487, l6: 0.334319\n",
      "\n",
      "[epoch: 385/400, batch: 552/1000, ite: 50945] train loss: 1.1140, accuracy: 95.6071%, tar: 0.0198 \n",
      "l0: 0.016869, l1: 0.017999, l2: 0.025297, l3: 0.039726, l4: 0.066514, l5: 0.127615, l6: 0.295906\n",
      "\n",
      "[epoch: 385/400, batch: 560/1000, ite: 50946] train loss: 1.1138, accuracy: 95.7823%, tar: 0.0198 \n",
      "l0: 0.019576, l1: 0.020991, l2: 0.027524, l3: 0.038994, l4: 0.067994, l5: 0.177922, l6: 0.382366\n",
      "\n",
      "[epoch: 385/400, batch: 568/1000, ite: 50947] train loss: 1.1138, accuracy: 95.4643%, tar: 0.0198 \n",
      "l0: 0.024004, l1: 0.025388, l2: 0.032543, l3: 0.046277, l4: 0.086512, l5: 0.171454, l6: 0.364677\n",
      "\n",
      "[epoch: 385/400, batch: 576/1000, ite: 50948] train loss: 1.1138, accuracy: 94.8268%, tar: 0.0198 \n",
      "l0: 0.015754, l1: 0.016962, l2: 0.023792, l3: 0.034994, l4: 0.066289, l5: 0.132931, l6: 0.315348\n",
      "\n",
      "[epoch: 385/400, batch: 584/1000, ite: 50949] train loss: 1.1136, accuracy: 95.8521%, tar: 0.0198 \n",
      "l0: 0.018038, l1: 0.019224, l2: 0.026386, l3: 0.040566, l4: 0.082326, l5: 0.159691, l6: 0.350921\n",
      "\n",
      "[epoch: 385/400, batch: 592/1000, ite: 50950] train loss: 1.1135, accuracy: 94.9002%, tar: 0.0198 \n",
      "l0: 0.020033, l1: 0.021592, l2: 0.029601, l3: 0.045204, l4: 0.082309, l5: 0.178488, l6: 0.323710\n",
      "\n",
      "[epoch: 385/400, batch: 600/1000, ite: 50951] train loss: 1.1134, accuracy: 95.2263%, tar: 0.0198 \n",
      "l0: 0.023023, l1: 0.023877, l2: 0.031746, l3: 0.050216, l4: 0.096645, l5: 0.187665, l6: 0.371078\n",
      "\n",
      "[epoch: 385/400, batch: 608/1000, ite: 50952] train loss: 1.1135, accuracy: 94.6090%, tar: 0.0198 \n",
      "l0: 0.021713, l1: 0.023513, l2: 0.033279, l3: 0.054215, l4: 0.107801, l5: 0.204652, l6: 0.370792\n",
      "\n",
      "[epoch: 385/400, batch: 616/1000, ite: 50953] train loss: 1.1136, accuracy: 94.6786%, tar: 0.0198 \n",
      "l0: 0.021408, l1: 0.022300, l2: 0.030138, l3: 0.042922, l4: 0.070286, l5: 0.132524, l6: 0.284301\n",
      "\n",
      "[epoch: 385/400, batch: 624/1000, ite: 50954] train loss: 1.1133, accuracy: 95.4173%, tar: 0.0198 \n",
      "l0: 0.019646, l1: 0.021394, l2: 0.028947, l3: 0.045480, l4: 0.095614, l5: 0.178279, l6: 0.349216\n",
      "\n",
      "[epoch: 385/400, batch: 632/1000, ite: 50955] train loss: 1.1133, accuracy: 95.5071%, tar: 0.0198 \n",
      "l0: 0.019908, l1: 0.020826, l2: 0.027522, l3: 0.041015, l4: 0.086028, l5: 0.187318, l6: 0.339751\n",
      "\n",
      "[epoch: 385/400, batch: 640/1000, ite: 50956] train loss: 1.1132, accuracy: 95.0369%, tar: 0.0198 \n",
      "l0: 0.027690, l1: 0.029614, l2: 0.038815, l3: 0.059922, l4: 0.112027, l5: 0.267219, l6: 0.539840\n",
      "\n",
      "[epoch: 385/400, batch: 648/1000, ite: 50957] train loss: 1.1138, accuracy: 93.2714%, tar: 0.0198 \n",
      "l0: 0.022302, l1: 0.023492, l2: 0.031517, l3: 0.046917, l4: 0.092540, l5: 0.182114, l6: 0.382977\n",
      "\n",
      "[epoch: 385/400, batch: 656/1000, ite: 50958] train loss: 1.1138, accuracy: 94.9157%, tar: 0.0198 \n",
      "l0: 0.020830, l1: 0.022008, l2: 0.029403, l3: 0.043410, l4: 0.078891, l5: 0.158942, l6: 0.383062\n",
      "\n",
      "[epoch: 385/400, batch: 664/1000, ite: 50959] train loss: 1.1138, accuracy: 95.0150%, tar: 0.0198 \n",
      "l0: 0.015158, l1: 0.015951, l2: 0.021410, l3: 0.033760, l4: 0.060221, l5: 0.132155, l6: 0.327414\n",
      "\n",
      "[epoch: 385/400, batch: 672/1000, ite: 50960] train loss: 1.1137, accuracy: 95.2632%, tar: 0.0198 \n",
      "l0: 0.021504, l1: 0.023139, l2: 0.031157, l3: 0.046674, l4: 0.079919, l5: 0.183468, l6: 0.345207\n",
      "\n",
      "[epoch: 385/400, batch: 680/1000, ite: 50961] train loss: 1.1136, accuracy: 95.4970%, tar: 0.0198 \n",
      "l0: 0.016032, l1: 0.017191, l2: 0.024186, l3: 0.037129, l4: 0.076894, l5: 0.136903, l6: 0.322409\n",
      "\n",
      "[epoch: 385/400, batch: 688/1000, ite: 50962] train loss: 1.1135, accuracy: 95.8751%, tar: 0.0198 \n",
      "l0: 0.023342, l1: 0.024416, l2: 0.034183, l3: 0.051276, l4: 0.089462, l5: 0.192020, l6: 0.386586\n",
      "\n",
      "[epoch: 385/400, batch: 696/1000, ite: 50963] train loss: 1.1135, accuracy: 93.9081%, tar: 0.0198 \n",
      "l0: 0.022388, l1: 0.023204, l2: 0.031939, l3: 0.048588, l4: 0.092236, l5: 0.229243, l6: 0.477443\n",
      "\n",
      "[epoch: 385/400, batch: 704/1000, ite: 50964] train loss: 1.1138, accuracy: 94.0533%, tar: 0.0198 \n",
      "l0: 0.017882, l1: 0.018895, l2: 0.026493, l3: 0.043482, l4: 0.082867, l5: 0.192555, l6: 0.357464\n",
      "\n",
      "[epoch: 385/400, batch: 712/1000, ite: 50965] train loss: 1.1138, accuracy: 94.7643%, tar: 0.0198 \n",
      "l0: 0.012020, l1: 0.012877, l2: 0.016919, l3: 0.026390, l4: 0.043914, l5: 0.094322, l6: 0.214147\n",
      "\n",
      "[epoch: 385/400, batch: 720/1000, ite: 50966] train loss: 1.1133, accuracy: 97.1160%, tar: 0.0198 \n",
      "l0: 0.021283, l1: 0.022702, l2: 0.030440, l3: 0.047450, l4: 0.089458, l5: 0.200286, l6: 0.387308\n",
      "\n",
      "[epoch: 385/400, batch: 728/1000, ite: 50967] train loss: 1.1134, accuracy: 94.8892%, tar: 0.0198 \n",
      "l0: 0.022199, l1: 0.023466, l2: 0.030414, l3: 0.045451, l4: 0.078392, l5: 0.164325, l6: 0.359612\n",
      "\n",
      "[epoch: 385/400, batch: 736/1000, ite: 50968] train loss: 1.1134, accuracy: 94.8051%, tar: 0.0198 \n",
      "l0: 0.018179, l1: 0.019914, l2: 0.030114, l3: 0.045620, l4: 0.076535, l5: 0.135105, l6: 0.260625\n",
      "\n",
      "[epoch: 385/400, batch: 744/1000, ite: 50969] train loss: 1.1131, accuracy: 96.2813%, tar: 0.0198 \n",
      "l0: 0.016187, l1: 0.017454, l2: 0.025806, l3: 0.043313, l4: 0.077712, l5: 0.154479, l6: 0.337262\n",
      "\n",
      "[epoch: 385/400, batch: 752/1000, ite: 50970] train loss: 1.1130, accuracy: 95.9907%, tar: 0.0198 \n",
      "l0: 0.020694, l1: 0.022302, l2: 0.028240, l3: 0.039645, l4: 0.067830, l5: 0.131751, l6: 0.300297\n",
      "\n",
      "[epoch: 385/400, batch: 760/1000, ite: 50971] train loss: 1.1128, accuracy: 96.2364%, tar: 0.0198 \n",
      "l0: 0.019315, l1: 0.020580, l2: 0.025981, l3: 0.038148, l4: 0.074240, l5: 0.170916, l6: 0.378454\n",
      "\n",
      "[epoch: 385/400, batch: 768/1000, ite: 50972] train loss: 1.1128, accuracy: 95.0153%, tar: 0.0198 \n",
      "l0: 0.018399, l1: 0.020075, l2: 0.027450, l3: 0.044599, l4: 0.095999, l5: 0.196171, l6: 0.383264\n",
      "\n",
      "[epoch: 385/400, batch: 776/1000, ite: 50973] train loss: 1.1129, accuracy: 94.5432%, tar: 0.0198 \n",
      "l0: 0.021109, l1: 0.022160, l2: 0.029612, l3: 0.043248, l4: 0.073797, l5: 0.149286, l6: 0.281113\n",
      "\n",
      "[epoch: 385/400, batch: 784/1000, ite: 50974] train loss: 1.1127, accuracy: 95.7138%, tar: 0.0198 \n",
      "l0: 0.019522, l1: 0.020517, l2: 0.026082, l3: 0.038470, l4: 0.071688, l5: 0.166691, l6: 0.374230\n",
      "\n",
      "[epoch: 385/400, batch: 792/1000, ite: 50975] train loss: 1.1126, accuracy: 95.1554%, tar: 0.0198 \n",
      "l0: 0.020494, l1: 0.021753, l2: 0.029282, l3: 0.047574, l4: 0.092716, l5: 0.183396, l6: 0.319254\n",
      "\n",
      "[epoch: 385/400, batch: 800/1000, ite: 50976] train loss: 1.1126, accuracy: 96.3429%, tar: 0.0198 \n",
      "l0: 0.017761, l1: 0.018790, l2: 0.023594, l3: 0.033347, l4: 0.057192, l5: 0.104454, l6: 0.194511\n",
      "\n",
      "[epoch: 385/400, batch: 808/1000, ite: 50977] train loss: 1.1121, accuracy: 96.3501%, tar: 0.0198 \n",
      "l0: 0.023210, l1: 0.024330, l2: 0.031579, l3: 0.046279, l4: 0.084088, l5: 0.203633, l6: 0.448254\n",
      "\n",
      "[epoch: 385/400, batch: 816/1000, ite: 50978] train loss: 1.1123, accuracy: 94.0544%, tar: 0.0198 \n",
      "l0: 0.021234, l1: 0.022006, l2: 0.029678, l3: 0.043723, l4: 0.090007, l5: 0.174120, l6: 0.357379\n",
      "\n",
      "[epoch: 385/400, batch: 824/1000, ite: 50979] train loss: 1.1123, accuracy: 94.9727%, tar: 0.0198 \n",
      "l0: 0.028060, l1: 0.030854, l2: 0.044404, l3: 0.073329, l4: 0.146414, l5: 0.267708, l6: 0.492522\n",
      "\n",
      "[epoch: 385/400, batch: 832/1000, ite: 50980] train loss: 1.1128, accuracy: 93.1408%, tar: 0.0198 \n",
      "l0: 0.020831, l1: 0.022928, l2: 0.032744, l3: 0.049945, l4: 0.106945, l5: 0.215625, l6: 0.448738\n",
      "\n",
      "[epoch: 385/400, batch: 840/1000, ite: 50981] train loss: 1.1130, accuracy: 94.5302%, tar: 0.0198 \n",
      "l0: 0.023924, l1: 0.026274, l2: 0.035681, l3: 0.056454, l4: 0.115734, l5: 0.249628, l6: 0.514184\n",
      "\n",
      "[epoch: 385/400, batch: 848/1000, ite: 50982] train loss: 1.1134, accuracy: 93.4855%, tar: 0.0198 \n",
      "l0: 0.019306, l1: 0.020149, l2: 0.027319, l3: 0.041699, l4: 0.072447, l5: 0.143972, l6: 0.296983\n",
      "\n",
      "[epoch: 385/400, batch: 856/1000, ite: 50983] train loss: 1.1132, accuracy: 95.6701%, tar: 0.0198 \n",
      "l0: 0.019166, l1: 0.019866, l2: 0.024985, l3: 0.034837, l4: 0.061523, l5: 0.120426, l6: 0.275263\n",
      "\n",
      "[epoch: 385/400, batch: 864/1000, ite: 50984] train loss: 1.1130, accuracy: 95.5184%, tar: 0.0198 \n",
      "l0: 0.017504, l1: 0.018875, l2: 0.025931, l3: 0.038688, l4: 0.069002, l5: 0.127290, l6: 0.275564\n",
      "\n",
      "[epoch: 385/400, batch: 872/1000, ite: 50985] train loss: 1.1127, accuracy: 96.2112%, tar: 0.0198 \n",
      "l0: 0.026005, l1: 0.027836, l2: 0.036870, l3: 0.053542, l4: 0.107886, l5: 0.185447, l6: 0.449769\n",
      "\n",
      "[epoch: 385/400, batch: 880/1000, ite: 50986] train loss: 1.1129, accuracy: 93.5544%, tar: 0.0198 \n",
      "l0: 0.015545, l1: 0.016733, l2: 0.023883, l3: 0.033513, l4: 0.066488, l5: 0.151325, l6: 0.319638\n",
      "\n",
      "[epoch: 385/400, batch: 888/1000, ite: 50987] train loss: 1.1128, accuracy: 95.8854%, tar: 0.0198 \n",
      "l0: 0.017461, l1: 0.019254, l2: 0.028172, l3: 0.046630, l4: 0.092968, l5: 0.206317, l6: 0.379559\n",
      "\n",
      "[epoch: 385/400, batch: 896/1000, ite: 50988] train loss: 1.1128, accuracy: 95.2120%, tar: 0.0198 \n",
      "l0: 0.021281, l1: 0.023467, l2: 0.034344, l3: 0.058929, l4: 0.126152, l5: 0.260995, l6: 0.405060\n",
      "\n",
      "[epoch: 385/400, batch: 904/1000, ite: 50989] train loss: 1.1130, accuracy: 94.9943%, tar: 0.0198 \n",
      "l0: 0.017967, l1: 0.019466, l2: 0.027417, l3: 0.041595, l4: 0.069904, l5: 0.136099, l6: 0.272309\n",
      "\n",
      "[epoch: 385/400, batch: 912/1000, ite: 50990] train loss: 1.1128, accuracy: 95.9440%, tar: 0.0198 \n",
      "l0: 0.025244, l1: 0.026767, l2: 0.035806, l3: 0.056249, l4: 0.111553, l5: 0.261483, l6: 0.511690\n",
      "\n",
      "[epoch: 385/400, batch: 920/1000, ite: 50991] train loss: 1.1132, accuracy: 92.7981%, tar: 0.0198 \n",
      "l0: 0.023024, l1: 0.024796, l2: 0.032518, l3: 0.050313, l4: 0.104670, l5: 0.209127, l6: 0.455052\n",
      "\n",
      "[epoch: 385/400, batch: 928/1000, ite: 50992] train loss: 1.1135, accuracy: 93.8209%, tar: 0.0198 \n",
      "l0: 0.026120, l1: 0.027761, l2: 0.036214, l3: 0.060837, l4: 0.124109, l5: 0.263813, l6: 0.485252\n",
      "\n",
      "[epoch: 385/400, batch: 936/1000, ite: 50993] train loss: 1.1139, accuracy: 93.7219%, tar: 0.0198 \n",
      "l0: 0.017204, l1: 0.018012, l2: 0.023532, l3: 0.034317, l4: 0.058666, l5: 0.111080, l6: 0.237645\n",
      "\n",
      "[epoch: 385/400, batch: 944/1000, ite: 50994] train loss: 1.1135, accuracy: 96.4951%, tar: 0.0198 \n",
      "l0: 0.019647, l1: 0.021152, l2: 0.029288, l3: 0.046617, l4: 0.085066, l5: 0.169472, l6: 0.335477\n",
      "\n",
      "[epoch: 385/400, batch: 952/1000, ite: 50995] train loss: 1.1134, accuracy: 95.4369%, tar: 0.0198 \n",
      "l0: 0.017440, l1: 0.018555, l2: 0.026504, l3: 0.039727, l4: 0.062641, l5: 0.102734, l6: 0.225128\n",
      "\n",
      "[epoch: 385/400, batch: 960/1000, ite: 50996] train loss: 1.1130, accuracy: 96.2662%, tar: 0.0198 \n",
      "l0: 0.015315, l1: 0.017262, l2: 0.024633, l3: 0.035637, l4: 0.073744, l5: 0.167963, l6: 0.319007\n",
      "\n",
      "[epoch: 385/400, batch: 968/1000, ite: 50997] train loss: 1.1129, accuracy: 96.1345%, tar: 0.0198 \n",
      "l0: 0.020768, l1: 0.022122, l2: 0.029071, l3: 0.044365, l4: 0.078952, l5: 0.151754, l6: 0.319452\n",
      "\n",
      "[epoch: 385/400, batch: 976/1000, ite: 50998] train loss: 1.1128, accuracy: 95.3966%, tar: 0.0198 \n",
      "l0: 0.030115, l1: 0.031815, l2: 0.039809, l3: 0.058635, l4: 0.105644, l5: 0.224466, l6: 0.453381\n",
      "\n",
      "[epoch: 385/400, batch: 984/1000, ite: 50999] train loss: 1.1131, accuracy: 93.5834%, tar: 0.0198 \n",
      "l0: 0.021221, l1: 0.022184, l2: 0.030472, l3: 0.048166, l4: 0.099589, l5: 0.180621, l6: 0.330440\n",
      "\n",
      "[epoch: 385/400, batch: 992/1000, ite: 51000] train loss: 1.1130, accuracy: 94.6785%, tar: 0.0198 \n",
      "l0: 0.024558, l1: 0.027111, l2: 0.037663, l3: 0.060489, l4: 0.120391, l5: 0.189451, l6: 0.350568\n",
      "\n",
      "[epoch: 385/400, batch: 1000/1000, ite: 51001] train loss: 1.1131, accuracy: 95.6059%, tar: 0.0199 \n",
      "l0: 0.021438, l1: 0.022588, l2: 0.029845, l3: 0.043039, l4: 0.074321, l5: 0.138290, l6: 0.325030\n",
      "\n",
      "[epoch: 386/400, batch: 8/1000, ite: 51002] train loss: 1.1129, accuracy: 95.0535%, tar: 0.0199 \n",
      "l0: 0.018205, l1: 0.019231, l2: 0.026146, l3: 0.037164, l4: 0.067252, l5: 0.121663, l6: 0.282987\n",
      "\n",
      "[epoch: 386/400, batch: 16/1000, ite: 51003] train loss: 1.1127, accuracy: 96.3158%, tar: 0.0199 \n",
      "l0: 0.020851, l1: 0.021997, l2: 0.030601, l3: 0.042877, l4: 0.078948, l5: 0.177506, l6: 0.340778\n",
      "\n",
      "[epoch: 386/400, batch: 24/1000, ite: 51004] train loss: 1.1126, accuracy: 95.5213%, tar: 0.0199 \n",
      "l0: 0.021734, l1: 0.022830, l2: 0.029470, l3: 0.044456, l4: 0.083783, l5: 0.139350, l6: 0.408587\n",
      "\n",
      "[epoch: 386/400, batch: 32/1000, ite: 51005] train loss: 1.1127, accuracy: 94.6012%, tar: 0.0199 \n",
      "l0: 0.020274, l1: 0.021652, l2: 0.030694, l3: 0.050945, l4: 0.139622, l5: 0.226286, l6: 0.439979\n",
      "\n",
      "[epoch: 386/400, batch: 40/1000, ite: 51006] train loss: 1.1130, accuracy: 94.7898%, tar: 0.0199 \n",
      "l0: 0.022712, l1: 0.024503, l2: 0.031753, l3: 0.048663, l4: 0.092618, l5: 0.179653, l6: 0.400453\n",
      "\n",
      "[epoch: 386/400, batch: 48/1000, ite: 51007] train loss: 1.1131, accuracy: 94.4265%, tar: 0.0199 \n",
      "l0: 0.017897, l1: 0.018812, l2: 0.027700, l3: 0.049679, l4: 0.093444, l5: 0.155419, l6: 0.328576\n",
      "\n",
      "[epoch: 386/400, batch: 56/1000, ite: 51008] train loss: 1.1130, accuracy: 95.6512%, tar: 0.0199 \n",
      "l0: 0.024800, l1: 0.026488, l2: 0.035771, l3: 0.055515, l4: 0.090663, l5: 0.165851, l6: 0.379319\n",
      "\n",
      "[epoch: 386/400, batch: 64/1000, ite: 51009] train loss: 1.1130, accuracy: 94.7476%, tar: 0.0199 \n",
      "l0: 0.020555, l1: 0.022359, l2: 0.029640, l3: 0.045464, l4: 0.088310, l5: 0.182324, l6: 0.368208\n",
      "\n",
      "[epoch: 386/400, batch: 72/1000, ite: 51010] train loss: 1.1130, accuracy: 95.0501%, tar: 0.0199 \n",
      "l0: 0.018262, l1: 0.019531, l2: 0.026168, l3: 0.038867, l4: 0.072242, l5: 0.139264, l6: 0.303849\n",
      "\n",
      "[epoch: 386/400, batch: 80/1000, ite: 51011] train loss: 1.1128, accuracy: 95.5214%, tar: 0.0199 \n",
      "l0: 0.021521, l1: 0.022877, l2: 0.031133, l3: 0.047302, l4: 0.094108, l5: 0.222821, l6: 0.497599\n",
      "\n",
      "[epoch: 386/400, batch: 88/1000, ite: 51012] train loss: 1.1132, accuracy: 93.7529%, tar: 0.0199 \n",
      "l0: 0.012839, l1: 0.013710, l2: 0.019211, l3: 0.028573, l4: 0.061074, l5: 0.138466, l6: 0.292442\n",
      "\n",
      "[epoch: 386/400, batch: 96/1000, ite: 51013] train loss: 1.1129, accuracy: 96.1003%, tar: 0.0199 \n",
      "l0: 0.017951, l1: 0.019767, l2: 0.029858, l3: 0.048499, l4: 0.107827, l5: 0.243869, l6: 0.459827\n",
      "\n",
      "[epoch: 386/400, batch: 104/1000, ite: 51014] train loss: 1.1132, accuracy: 94.9462%, tar: 0.0199 \n",
      "l0: 0.016419, l1: 0.017746, l2: 0.024922, l3: 0.037593, l4: 0.071078, l5: 0.166530, l6: 0.380342\n",
      "\n",
      "[epoch: 386/400, batch: 112/1000, ite: 51015] train loss: 1.1132, accuracy: 94.6473%, tar: 0.0198 \n",
      "l0: 0.013996, l1: 0.015018, l2: 0.022591, l3: 0.038573, l4: 0.070416, l5: 0.137497, l6: 0.274017\n",
      "\n",
      "[epoch: 386/400, batch: 120/1000, ite: 51016] train loss: 1.1129, accuracy: 96.4798%, tar: 0.0198 \n",
      "l0: 0.022282, l1: 0.023361, l2: 0.032141, l3: 0.053614, l4: 0.103002, l5: 0.190383, l6: 0.362905\n",
      "\n",
      "[epoch: 386/400, batch: 128/1000, ite: 51017] train loss: 1.1130, accuracy: 94.4222%, tar: 0.0198 \n",
      "l0: 0.019874, l1: 0.021537, l2: 0.033418, l3: 0.055183, l4: 0.101968, l5: 0.209887, l6: 0.386914\n",
      "\n",
      "[epoch: 386/400, batch: 136/1000, ite: 51018] train loss: 1.1131, accuracy: 94.9260%, tar: 0.0198 \n",
      "l0: 0.021210, l1: 0.022988, l2: 0.033019, l3: 0.056084, l4: 0.119071, l5: 0.222773, l6: 0.430118\n",
      "\n",
      "[epoch: 386/400, batch: 144/1000, ite: 51019] train loss: 1.1133, accuracy: 94.4103%, tar: 0.0198 \n",
      "l0: 0.015403, l1: 0.016905, l2: 0.023687, l3: 0.036005, l4: 0.066246, l5: 0.150440, l6: 0.301711\n",
      "\n",
      "[epoch: 386/400, batch: 152/1000, ite: 51020] train loss: 1.1131, accuracy: 95.6137%, tar: 0.0198 \n",
      "l0: 0.019055, l1: 0.019939, l2: 0.029415, l3: 0.043758, l4: 0.083431, l5: 0.160838, l6: 0.389465\n",
      "\n",
      "[epoch: 386/400, batch: 160/1000, ite: 51021] train loss: 1.1131, accuracy: 94.9752%, tar: 0.0198 \n",
      "l0: 0.018939, l1: 0.020044, l2: 0.028805, l3: 0.039892, l4: 0.065898, l5: 0.112070, l6: 0.259256\n",
      "\n",
      "[epoch: 386/400, batch: 168/1000, ite: 51022] train loss: 1.1128, accuracy: 95.9778%, tar: 0.0198 \n",
      "l0: 0.017653, l1: 0.018827, l2: 0.024418, l3: 0.036427, l4: 0.066542, l5: 0.134467, l6: 0.301580\n",
      "\n",
      "[epoch: 386/400, batch: 176/1000, ite: 51023] train loss: 1.1126, accuracy: 95.3884%, tar: 0.0198 \n",
      "l0: 0.016251, l1: 0.017307, l2: 0.022929, l3: 0.038940, l4: 0.070144, l5: 0.129243, l6: 0.296010\n",
      "\n",
      "[epoch: 386/400, batch: 184/1000, ite: 51024] train loss: 1.1124, accuracy: 95.6519%, tar: 0.0198 \n",
      "l0: 0.018608, l1: 0.019904, l2: 0.028254, l3: 0.047177, l4: 0.101682, l5: 0.242219, l6: 0.436891\n",
      "\n",
      "[epoch: 386/400, batch: 192/1000, ite: 51025] train loss: 1.1126, accuracy: 94.3018%, tar: 0.0198 \n",
      "l0: 0.018482, l1: 0.019957, l2: 0.027244, l3: 0.045347, l4: 0.108275, l5: 0.242658, l6: 0.482931\n",
      "\n",
      "[epoch: 386/400, batch: 200/1000, ite: 51026] train loss: 1.1129, accuracy: 94.3075%, tar: 0.0198 \n",
      "l0: 0.018493, l1: 0.019364, l2: 0.026715, l3: 0.042265, l4: 0.068240, l5: 0.136848, l6: 0.342682\n",
      "\n",
      "[epoch: 386/400, batch: 208/1000, ite: 51027] train loss: 1.1128, accuracy: 95.5995%, tar: 0.0198 \n",
      "l0: 0.019624, l1: 0.020639, l2: 0.029776, l3: 0.046104, l4: 0.096675, l5: 0.201453, l6: 0.479020\n",
      "\n",
      "[epoch: 386/400, batch: 216/1000, ite: 51028] train loss: 1.1131, accuracy: 94.4034%, tar: 0.0198 \n",
      "l0: 0.015260, l1: 0.016341, l2: 0.022005, l3: 0.034221, l4: 0.061207, l5: 0.117598, l6: 0.219295\n",
      "\n",
      "[epoch: 386/400, batch: 224/1000, ite: 51029] train loss: 1.1127, accuracy: 96.2806%, tar: 0.0198 \n",
      "l0: 0.016118, l1: 0.018184, l2: 0.028156, l3: 0.053269, l4: 0.113758, l5: 0.199428, l6: 0.419728\n",
      "\n",
      "[epoch: 386/400, batch: 232/1000, ite: 51030] train loss: 1.1128, accuracy: 95.0442%, tar: 0.0198 \n",
      "l0: 0.022321, l1: 0.023447, l2: 0.030600, l3: 0.041334, l4: 0.070628, l5: 0.142254, l6: 0.301071\n",
      "\n",
      "[epoch: 386/400, batch: 240/1000, ite: 51031] train loss: 1.1127, accuracy: 95.4399%, tar: 0.0198 \n",
      "l0: 0.017801, l1: 0.019253, l2: 0.026578, l3: 0.042173, l4: 0.079734, l5: 0.162034, l6: 0.375352\n",
      "\n",
      "[epoch: 386/400, batch: 248/1000, ite: 51032] train loss: 1.1127, accuracy: 95.2938%, tar: 0.0198 \n",
      "l0: 0.020343, l1: 0.022400, l2: 0.032420, l3: 0.053078, l4: 0.104462, l5: 0.207340, l6: 0.416295\n",
      "\n",
      "[epoch: 386/400, batch: 256/1000, ite: 51033] train loss: 1.1128, accuracy: 94.6199%, tar: 0.0198 \n",
      "l0: 0.017028, l1: 0.017793, l2: 0.023337, l3: 0.036861, l4: 0.066765, l5: 0.148375, l6: 0.251425\n",
      "\n",
      "[epoch: 386/400, batch: 264/1000, ite: 51034] train loss: 1.1125, accuracy: 95.5621%, tar: 0.0198 \n",
      "l0: 0.015906, l1: 0.017394, l2: 0.023906, l3: 0.036678, l4: 0.065801, l5: 0.149662, l6: 0.344947\n",
      "\n",
      "[epoch: 386/400, batch: 272/1000, ite: 51035] train loss: 1.1124, accuracy: 96.1323%, tar: 0.0198 \n",
      "l0: 0.023199, l1: 0.024416, l2: 0.032106, l3: 0.049158, l4: 0.083864, l5: 0.161382, l6: 0.332103\n",
      "\n",
      "[epoch: 386/400, batch: 280/1000, ite: 51036] train loss: 1.1123, accuracy: 95.1846%, tar: 0.0198 \n",
      "l0: 0.020046, l1: 0.022144, l2: 0.031972, l3: 0.049565, l4: 0.086898, l5: 0.187423, l6: 0.471174\n",
      "\n",
      "[epoch: 386/400, batch: 288/1000, ite: 51037] train loss: 1.1126, accuracy: 94.3652%, tar: 0.0198 \n",
      "l0: 0.019743, l1: 0.021317, l2: 0.028171, l3: 0.044453, l4: 0.085614, l5: 0.172245, l6: 0.393003\n",
      "\n",
      "[epoch: 386/400, batch: 296/1000, ite: 51038] train loss: 1.1126, accuracy: 94.9879%, tar: 0.0198 \n",
      "l0: 0.020452, l1: 0.023173, l2: 0.031472, l3: 0.051826, l4: 0.106821, l5: 0.215146, l6: 0.427056\n",
      "\n",
      "[epoch: 386/400, batch: 304/1000, ite: 51039] train loss: 1.1128, accuracy: 95.7512%, tar: 0.0198 \n",
      "l0: 0.017111, l1: 0.018830, l2: 0.027341, l3: 0.048858, l4: 0.108677, l5: 0.231830, l6: 0.429799\n",
      "\n",
      "[epoch: 386/400, batch: 312/1000, ite: 51040] train loss: 1.1130, accuracy: 94.7037%, tar: 0.0198 \n",
      "l0: 0.011526, l1: 0.012847, l2: 0.019635, l3: 0.029091, l4: 0.054890, l5: 0.115429, l6: 0.227636\n",
      "\n",
      "[epoch: 386/400, batch: 320/1000, ite: 51041] train loss: 1.1126, accuracy: 97.4652%, tar: 0.0198 \n",
      "l0: 0.021178, l1: 0.022263, l2: 0.030009, l3: 0.041980, l4: 0.073594, l5: 0.154748, l6: 0.315307\n",
      "\n",
      "[epoch: 386/400, batch: 328/1000, ite: 51042] train loss: 1.1125, accuracy: 95.1386%, tar: 0.0198 \n",
      "l0: 0.022205, l1: 0.024205, l2: 0.033540, l3: 0.051175, l4: 0.105323, l5: 0.229408, l6: 0.427792\n",
      "\n",
      "[epoch: 386/400, batch: 336/1000, ite: 51043] train loss: 1.1127, accuracy: 94.2099%, tar: 0.0198 \n",
      "l0: 0.016879, l1: 0.017803, l2: 0.023630, l3: 0.035566, l4: 0.068464, l5: 0.134883, l6: 0.340222\n",
      "\n",
      "[epoch: 386/400, batch: 344/1000, ite: 51044] train loss: 1.1125, accuracy: 95.1279%, tar: 0.0198 \n",
      "l0: 0.014239, l1: 0.015495, l2: 0.023258, l3: 0.036021, l4: 0.063534, l5: 0.123883, l6: 0.237877\n",
      "\n",
      "[epoch: 386/400, batch: 352/1000, ite: 51045] train loss: 1.1122, accuracy: 96.8376%, tar: 0.0198 \n",
      "l0: 0.023411, l1: 0.025886, l2: 0.034807, l3: 0.050102, l4: 0.095642, l5: 0.203641, l6: 0.399311\n",
      "\n",
      "[epoch: 386/400, batch: 360/1000, ite: 51046] train loss: 1.1123, accuracy: 95.6149%, tar: 0.0198 \n",
      "l0: 0.021052, l1: 0.022562, l2: 0.031552, l3: 0.048151, l4: 0.085850, l5: 0.182772, l6: 0.435720\n",
      "\n",
      "[epoch: 386/400, batch: 368/1000, ite: 51047] train loss: 1.1125, accuracy: 95.0181%, tar: 0.0198 \n",
      "l0: 0.018779, l1: 0.019371, l2: 0.024969, l3: 0.035417, l4: 0.059122, l5: 0.114200, l6: 0.238001\n",
      "\n",
      "[epoch: 386/400, batch: 376/1000, ite: 51048] train loss: 1.1121, accuracy: 96.2929%, tar: 0.0198 \n",
      "l0: 0.014849, l1: 0.015988, l2: 0.024009, l3: 0.039801, l4: 0.074275, l5: 0.160682, l6: 0.379419\n",
      "\n",
      "[epoch: 386/400, batch: 384/1000, ite: 51049] train loss: 1.1121, accuracy: 95.4810%, tar: 0.0198 \n",
      "l0: 0.018043, l1: 0.018830, l2: 0.025548, l3: 0.038610, l4: 0.062639, l5: 0.136733, l6: 0.306157\n",
      "\n",
      "[epoch: 386/400, batch: 392/1000, ite: 51050] train loss: 1.1119, accuracy: 95.7079%, tar: 0.0198 \n",
      "l0: 0.017285, l1: 0.019449, l2: 0.028684, l3: 0.044844, l4: 0.078065, l5: 0.147892, l6: 0.312941\n",
      "\n",
      "[epoch: 386/400, batch: 400/1000, ite: 51051] train loss: 1.1118, accuracy: 96.6289%, tar: 0.0198 \n",
      "l0: 0.016961, l1: 0.018240, l2: 0.024250, l3: 0.037308, l4: 0.067688, l5: 0.129525, l6: 0.345545\n",
      "\n",
      "[epoch: 386/400, batch: 408/1000, ite: 51052] train loss: 1.1117, accuracy: 95.3494%, tar: 0.0198 \n",
      "l0: 0.019108, l1: 0.020728, l2: 0.029522, l3: 0.045548, l4: 0.094201, l5: 0.193705, l6: 0.355762\n",
      "\n",
      "[epoch: 386/400, batch: 416/1000, ite: 51053] train loss: 1.1117, accuracy: 95.4025%, tar: 0.0198 \n",
      "l0: 0.017926, l1: 0.019022, l2: 0.027832, l3: 0.042324, l4: 0.090751, l5: 0.180108, l6: 0.344433\n",
      "\n",
      "[epoch: 386/400, batch: 424/1000, ite: 51054] train loss: 1.1116, accuracy: 95.3277%, tar: 0.0198 \n",
      "l0: 0.020062, l1: 0.021081, l2: 0.028950, l3: 0.045292, l4: 0.079761, l5: 0.162887, l6: 0.342215\n",
      "\n",
      "[epoch: 386/400, batch: 432/1000, ite: 51055] train loss: 1.1116, accuracy: 95.1356%, tar: 0.0198 \n",
      "l0: 0.016536, l1: 0.018038, l2: 0.026581, l3: 0.044114, l4: 0.087183, l5: 0.203324, l6: 0.404768\n",
      "\n",
      "[epoch: 386/400, batch: 440/1000, ite: 51056] train loss: 1.1116, accuracy: 95.3621%, tar: 0.0198 \n",
      "l0: 0.014811, l1: 0.015897, l2: 0.021954, l3: 0.033579, l4: 0.063503, l5: 0.128829, l6: 0.331510\n",
      "\n",
      "[epoch: 386/400, batch: 448/1000, ite: 51057] train loss: 1.1115, accuracy: 95.9715%, tar: 0.0198 \n",
      "l0: 0.022455, l1: 0.023709, l2: 0.033744, l3: 0.052266, l4: 0.088319, l5: 0.165796, l6: 0.358633\n",
      "\n",
      "[epoch: 386/400, batch: 456/1000, ite: 51058] train loss: 1.1115, accuracy: 95.1968%, tar: 0.0198 \n",
      "l0: 0.020966, l1: 0.022164, l2: 0.030771, l3: 0.048740, l4: 0.091147, l5: 0.179307, l6: 0.397220\n",
      "\n",
      "[epoch: 386/400, batch: 464/1000, ite: 51059] train loss: 1.1116, accuracy: 94.2685%, tar: 0.0198 \n",
      "l0: 0.026394, l1: 0.027893, l2: 0.036868, l3: 0.058082, l4: 0.134251, l5: 0.291492, l6: 0.534788\n",
      "\n",
      "[epoch: 386/400, batch: 472/1000, ite: 51060] train loss: 1.1121, accuracy: 93.7230%, tar: 0.0198 \n",
      "l0: 0.019589, l1: 0.020899, l2: 0.029844, l3: 0.043661, l4: 0.083270, l5: 0.200221, l6: 0.432658\n",
      "\n",
      "[epoch: 386/400, batch: 480/1000, ite: 51061] train loss: 1.1122, accuracy: 93.7805%, tar: 0.0198 \n",
      "l0: 0.019052, l1: 0.020665, l2: 0.028724, l3: 0.043717, l4: 0.088126, l5: 0.200040, l6: 0.371326\n",
      "\n",
      "[epoch: 386/400, batch: 488/1000, ite: 51062] train loss: 1.1122, accuracy: 95.0154%, tar: 0.0198 \n",
      "l0: 0.018981, l1: 0.020271, l2: 0.028183, l3: 0.045977, l4: 0.091392, l5: 0.180416, l6: 0.304686\n",
      "\n",
      "[epoch: 386/400, batch: 496/1000, ite: 51063] train loss: 1.1121, accuracy: 96.3562%, tar: 0.0198 \n",
      "l0: 0.018413, l1: 0.018987, l2: 0.024710, l3: 0.034448, l4: 0.059058, l5: 0.116784, l6: 0.312102\n",
      "\n",
      "[epoch: 386/400, batch: 504/1000, ite: 51064] train loss: 1.1119, accuracy: 95.6728%, tar: 0.0198 \n",
      "l0: 0.013970, l1: 0.014612, l2: 0.019768, l3: 0.027731, l4: 0.056399, l5: 0.102904, l6: 0.243334\n",
      "\n",
      "[epoch: 386/400, batch: 512/1000, ite: 51065] train loss: 1.1116, accuracy: 96.9918%, tar: 0.0198 \n",
      "l0: 0.021746, l1: 0.022734, l2: 0.027760, l3: 0.038601, l4: 0.068700, l5: 0.132884, l6: 0.337804\n",
      "\n",
      "[epoch: 386/400, batch: 520/1000, ite: 51066] train loss: 1.1115, accuracy: 95.3654%, tar: 0.0198 \n",
      "l0: 0.023494, l1: 0.025041, l2: 0.032841, l3: 0.050662, l4: 0.103831, l5: 0.247008, l6: 0.527944\n",
      "\n",
      "[epoch: 386/400, batch: 528/1000, ite: 51067] train loss: 1.1119, accuracy: 93.6600%, tar: 0.0198 \n",
      "l0: 0.019118, l1: 0.020097, l2: 0.027780, l3: 0.042708, l4: 0.084097, l5: 0.170159, l6: 0.360146\n",
      "\n",
      "[epoch: 386/400, batch: 536/1000, ite: 51068] train loss: 1.1118, accuracy: 95.0002%, tar: 0.0198 \n",
      "l0: 0.018949, l1: 0.021030, l2: 0.028244, l3: 0.046851, l4: 0.099699, l5: 0.199543, l6: 0.407088\n",
      "\n",
      "[epoch: 386/400, batch: 544/1000, ite: 51069] train loss: 1.1120, accuracy: 94.5669%, tar: 0.0198 \n",
      "l0: 0.019746, l1: 0.021030, l2: 0.029120, l3: 0.043456, l4: 0.072372, l5: 0.142087, l6: 0.274532\n",
      "\n",
      "[epoch: 386/400, batch: 552/1000, ite: 51070] train loss: 1.1117, accuracy: 95.6862%, tar: 0.0198 \n",
      "l0: 0.024631, l1: 0.026445, l2: 0.036331, l3: 0.055778, l4: 0.105039, l5: 0.211276, l6: 0.422476\n",
      "\n",
      "[epoch: 386/400, batch: 560/1000, ite: 51071] train loss: 1.1119, accuracy: 94.1465%, tar: 0.0198 \n",
      "l0: 0.021877, l1: 0.023190, l2: 0.029157, l3: 0.044778, l4: 0.092582, l5: 0.172101, l6: 0.322957\n",
      "\n",
      "[epoch: 386/400, batch: 568/1000, ite: 51072] train loss: 1.1119, accuracy: 95.3055%, tar: 0.0198 \n",
      "l0: 0.017552, l1: 0.018661, l2: 0.026308, l3: 0.044764, l4: 0.106152, l5: 0.197295, l6: 0.357687\n",
      "\n",
      "[epoch: 386/400, batch: 576/1000, ite: 51073] train loss: 1.1119, accuracy: 95.0260%, tar: 0.0198 \n",
      "l0: 0.018207, l1: 0.020092, l2: 0.028758, l3: 0.048714, l4: 0.089878, l5: 0.166023, l6: 0.337755\n",
      "\n",
      "[epoch: 386/400, batch: 584/1000, ite: 51074] train loss: 1.1118, accuracy: 95.1883%, tar: 0.0198 \n",
      "l0: 0.021150, l1: 0.022451, l2: 0.029176, l3: 0.044820, l4: 0.088734, l5: 0.193592, l6: 0.369632\n",
      "\n",
      "[epoch: 386/400, batch: 592/1000, ite: 51075] train loss: 1.1118, accuracy: 94.8139%, tar: 0.0198 \n",
      "l0: 0.017416, l1: 0.018146, l2: 0.026135, l3: 0.037955, l4: 0.064398, l5: 0.135121, l6: 0.256666\n",
      "\n",
      "[epoch: 386/400, batch: 600/1000, ite: 51076] train loss: 1.1116, accuracy: 96.1218%, tar: 0.0198 \n",
      "l0: 0.019126, l1: 0.020139, l2: 0.026271, l3: 0.037221, l4: 0.060534, l5: 0.134168, l6: 0.297543\n",
      "\n",
      "[epoch: 386/400, batch: 608/1000, ite: 51077] train loss: 1.1114, accuracy: 95.8916%, tar: 0.0198 \n",
      "l0: 0.020787, l1: 0.022006, l2: 0.031269, l3: 0.050733, l4: 0.095789, l5: 0.195381, l6: 0.365956\n",
      "\n",
      "[epoch: 386/400, batch: 616/1000, ite: 51078] train loss: 1.1114, accuracy: 94.7639%, tar: 0.0198 \n",
      "l0: 0.022767, l1: 0.024426, l2: 0.033565, l3: 0.051496, l4: 0.094173, l5: 0.190617, l6: 0.363890\n",
      "\n",
      "[epoch: 386/400, batch: 624/1000, ite: 51079] train loss: 1.1114, accuracy: 94.5668%, tar: 0.0198 \n",
      "l0: 0.026393, l1: 0.027687, l2: 0.035948, l3: 0.050109, l4: 0.084738, l5: 0.158301, l6: 0.390484\n",
      "\n",
      "[epoch: 386/400, batch: 632/1000, ite: 51080] train loss: 1.1115, accuracy: 94.2999%, tar: 0.0198 \n",
      "l0: 0.016778, l1: 0.019343, l2: 0.028007, l3: 0.050619, l4: 0.103393, l5: 0.196409, l6: 0.414925\n",
      "\n",
      "[epoch: 386/400, batch: 640/1000, ite: 51081] train loss: 1.1116, accuracy: 94.9448%, tar: 0.0198 \n",
      "l0: 0.019530, l1: 0.021344, l2: 0.029228, l3: 0.046757, l4: 0.094722, l5: 0.207420, l6: 0.412451\n",
      "\n",
      "[epoch: 386/400, batch: 648/1000, ite: 51082] train loss: 1.1117, accuracy: 94.0169%, tar: 0.0198 \n",
      "l0: 0.017991, l1: 0.019265, l2: 0.027120, l3: 0.042135, l4: 0.076569, l5: 0.163455, l6: 0.312432\n",
      "\n",
      "[epoch: 386/400, batch: 656/1000, ite: 51083] train loss: 1.1116, accuracy: 95.9093%, tar: 0.0198 \n",
      "l0: 0.016579, l1: 0.018378, l2: 0.027557, l3: 0.045214, l4: 0.091938, l5: 0.200047, l6: 0.363077\n",
      "\n",
      "[epoch: 386/400, batch: 664/1000, ite: 51084] train loss: 1.1116, accuracy: 95.6830%, tar: 0.0198 \n",
      "l0: 0.025287, l1: 0.026912, l2: 0.035326, l3: 0.051319, l4: 0.082425, l5: 0.184874, l6: 0.439006\n",
      "\n",
      "[epoch: 386/400, batch: 672/1000, ite: 51085] train loss: 1.1118, accuracy: 94.2687%, tar: 0.0198 \n",
      "l0: 0.017988, l1: 0.020300, l2: 0.029724, l3: 0.048407, l4: 0.104827, l5: 0.210849, l6: 0.463144\n",
      "\n",
      "[epoch: 386/400, batch: 680/1000, ite: 51086] train loss: 1.1120, accuracy: 94.8754%, tar: 0.0198 \n",
      "l0: 0.022136, l1: 0.023131, l2: 0.029823, l3: 0.043629, l4: 0.086309, l5: 0.178118, l6: 0.380316\n",
      "\n",
      "[epoch: 386/400, batch: 688/1000, ite: 51087] train loss: 1.1121, accuracy: 94.7412%, tar: 0.0198 \n",
      "l0: 0.025259, l1: 0.026505, l2: 0.033699, l3: 0.052713, l4: 0.112280, l5: 0.237433, l6: 0.435825\n",
      "\n",
      "[epoch: 386/400, batch: 696/1000, ite: 51088] train loss: 1.1123, accuracy: 93.2714%, tar: 0.0198 \n",
      "l0: 0.019560, l1: 0.021316, l2: 0.029185, l3: 0.048818, l4: 0.110843, l5: 0.221023, l6: 0.472242\n",
      "\n",
      "[epoch: 386/400, batch: 704/1000, ite: 51089] train loss: 1.1125, accuracy: 94.4310%, tar: 0.0198 \n",
      "l0: 0.018986, l1: 0.020538, l2: 0.029259, l3: 0.043458, l4: 0.082812, l5: 0.176962, l6: 0.375896\n",
      "\n",
      "[epoch: 386/400, batch: 712/1000, ite: 51090] train loss: 1.1126, accuracy: 94.8390%, tar: 0.0198 \n",
      "l0: 0.017481, l1: 0.018795, l2: 0.026194, l3: 0.042496, l4: 0.102647, l5: 0.191601, l6: 0.386697\n",
      "\n",
      "[epoch: 386/400, batch: 720/1000, ite: 51091] train loss: 1.1126, accuracy: 94.7209%, tar: 0.0198 \n",
      "l0: 0.022963, l1: 0.023980, l2: 0.031600, l3: 0.044694, l4: 0.071565, l5: 0.136350, l6: 0.296550\n",
      "\n",
      "[epoch: 386/400, batch: 728/1000, ite: 51092] train loss: 1.1124, accuracy: 94.9336%, tar: 0.0198 \n",
      "l0: 0.023362, l1: 0.024576, l2: 0.034397, l3: 0.052546, l4: 0.086698, l5: 0.154742, l6: 0.330391\n",
      "\n",
      "[epoch: 386/400, batch: 736/1000, ite: 51093] train loss: 1.1124, accuracy: 94.9123%, tar: 0.0198 \n",
      "l0: 0.018278, l1: 0.020968, l2: 0.029331, l3: 0.051690, l4: 0.098155, l5: 0.221079, l6: 0.434982\n",
      "\n",
      "[epoch: 386/400, batch: 744/1000, ite: 51094] train loss: 1.1126, accuracy: 95.1094%, tar: 0.0198 \n",
      "l0: 0.017320, l1: 0.018662, l2: 0.027065, l3: 0.040290, l4: 0.069418, l5: 0.151420, l6: 0.256819\n",
      "\n",
      "[epoch: 386/400, batch: 752/1000, ite: 51095] train loss: 1.1123, accuracy: 96.6022%, tar: 0.0198 \n",
      "l0: 0.018520, l1: 0.019850, l2: 0.028300, l3: 0.043795, l4: 0.079229, l5: 0.175032, l6: 0.360135\n",
      "\n",
      "[epoch: 386/400, batch: 760/1000, ite: 51096] train loss: 1.1123, accuracy: 94.9635%, tar: 0.0198 \n",
      "l0: 0.013199, l1: 0.014199, l2: 0.019805, l3: 0.031748, l4: 0.056675, l5: 0.116037, l6: 0.254312\n",
      "\n",
      "[epoch: 386/400, batch: 768/1000, ite: 51097] train loss: 1.1120, accuracy: 96.6735%, tar: 0.0198 \n",
      "l0: 0.023917, l1: 0.025634, l2: 0.034274, l3: 0.054495, l4: 0.104065, l5: 0.205853, l6: 0.432139\n",
      "\n",
      "[epoch: 386/400, batch: 776/1000, ite: 51098] train loss: 1.1122, accuracy: 94.5467%, tar: 0.0198 \n",
      "l0: 0.021998, l1: 0.023572, l2: 0.032374, l3: 0.049377, l4: 0.089459, l5: 0.256032, l6: 0.491189\n",
      "\n",
      "[epoch: 386/400, batch: 784/1000, ite: 51099] train loss: 1.1125, accuracy: 93.9366%, tar: 0.0198 \n",
      "l0: 0.022409, l1: 0.024011, l2: 0.034587, l3: 0.050207, l4: 0.100576, l5: 0.285958, l6: 0.532395\n",
      "\n",
      "[epoch: 386/400, batch: 792/1000, ite: 51100] train loss: 1.1129, accuracy: 92.9033%, tar: 0.0198 \n",
      "l0: 0.018258, l1: 0.019705, l2: 0.028223, l3: 0.042386, l4: 0.078146, l5: 0.153669, l6: 0.323997\n",
      "\n",
      "[epoch: 386/400, batch: 800/1000, ite: 51101] train loss: 1.1128, accuracy: 95.7141%, tar: 0.0198 \n",
      "l0: 0.022806, l1: 0.023927, l2: 0.030017, l3: 0.046308, l4: 0.089840, l5: 0.207751, l6: 0.429700\n",
      "\n",
      "[epoch: 386/400, batch: 808/1000, ite: 51102] train loss: 1.1129, accuracy: 93.5222%, tar: 0.0198 \n",
      "l0: 0.017804, l1: 0.019132, l2: 0.026042, l3: 0.039361, l4: 0.075589, l5: 0.159151, l6: 0.305938\n",
      "\n",
      "[epoch: 386/400, batch: 816/1000, ite: 51103] train loss: 1.1128, accuracy: 95.5279%, tar: 0.0198 \n",
      "l0: 0.019774, l1: 0.022097, l2: 0.031882, l3: 0.053866, l4: 0.098650, l5: 0.192169, l6: 0.337368\n",
      "\n",
      "[epoch: 386/400, batch: 824/1000, ite: 51104] train loss: 1.1128, accuracy: 95.5291%, tar: 0.0198 \n",
      "l0: 0.022189, l1: 0.023705, l2: 0.031766, l3: 0.045205, l4: 0.076929, l5: 0.170992, l6: 0.310206\n",
      "\n",
      "[epoch: 386/400, batch: 832/1000, ite: 51105] train loss: 1.1127, accuracy: 95.4650%, tar: 0.0198 \n",
      "l0: 0.026256, l1: 0.028345, l2: 0.038401, l3: 0.060542, l4: 0.114585, l5: 0.216214, l6: 0.469244\n",
      "\n",
      "[epoch: 386/400, batch: 840/1000, ite: 51106] train loss: 1.1129, accuracy: 93.5092%, tar: 0.0198 \n",
      "l0: 0.018424, l1: 0.019663, l2: 0.026314, l3: 0.041361, l4: 0.074609, l5: 0.147555, l6: 0.308266\n",
      "\n",
      "[epoch: 386/400, batch: 848/1000, ite: 51107] train loss: 1.1128, accuracy: 95.2245%, tar: 0.0198 \n",
      "l0: 0.021972, l1: 0.023317, l2: 0.031946, l3: 0.049944, l4: 0.085583, l5: 0.154221, l6: 0.318405\n",
      "\n",
      "[epoch: 386/400, batch: 856/1000, ite: 51108] train loss: 1.1127, accuracy: 94.6420%, tar: 0.0198 \n",
      "l0: 0.030704, l1: 0.032559, l2: 0.039158, l3: 0.054820, l4: 0.094979, l5: 0.221514, l6: 0.443023\n",
      "\n",
      "[epoch: 386/400, batch: 864/1000, ite: 51109] train loss: 1.1129, accuracy: 94.2937%, tar: 0.0198 \n",
      "l0: 0.023725, l1: 0.025016, l2: 0.030623, l3: 0.048490, l4: 0.096413, l5: 0.194696, l6: 0.401068\n",
      "\n",
      "[epoch: 386/400, batch: 872/1000, ite: 51110] train loss: 1.1130, accuracy: 93.4804%, tar: 0.0198 \n",
      "l0: 0.017808, l1: 0.019008, l2: 0.025101, l3: 0.033662, l4: 0.061034, l5: 0.124676, l6: 0.274649\n",
      "\n",
      "[epoch: 386/400, batch: 880/1000, ite: 51111] train loss: 1.1128, accuracy: 96.0518%, tar: 0.0198 \n",
      "l0: 0.024154, l1: 0.025405, l2: 0.035338, l3: 0.054661, l4: 0.108833, l5: 0.238684, l6: 0.505229\n",
      "\n",
      "[epoch: 386/400, batch: 888/1000, ite: 51112] train loss: 1.1131, accuracy: 92.9997%, tar: 0.0198 \n",
      "l0: 0.023021, l1: 0.024765, l2: 0.035281, l3: 0.055254, l4: 0.098883, l5: 0.163724, l6: 0.322288\n",
      "\n",
      "[epoch: 386/400, batch: 896/1000, ite: 51113] train loss: 1.1131, accuracy: 95.0665%, tar: 0.0198 \n",
      "l0: 0.017636, l1: 0.019474, l2: 0.030294, l3: 0.057234, l4: 0.102567, l5: 0.169646, l6: 0.378554\n",
      "\n",
      "[epoch: 386/400, batch: 904/1000, ite: 51114] train loss: 1.1131, accuracy: 95.6371%, tar: 0.0198 \n",
      "l0: 0.023695, l1: 0.024841, l2: 0.032539, l3: 0.052791, l4: 0.105991, l5: 0.226925, l6: 0.434121\n",
      "\n",
      "[epoch: 386/400, batch: 912/1000, ite: 51115] train loss: 1.1133, accuracy: 94.2232%, tar: 0.0198 \n",
      "l0: 0.020563, l1: 0.021505, l2: 0.028372, l3: 0.044627, l4: 0.081716, l5: 0.149291, l6: 0.311983\n",
      "\n",
      "[epoch: 386/400, batch: 920/1000, ite: 51116] train loss: 1.1132, accuracy: 95.2234%, tar: 0.0198 \n",
      "l0: 0.024121, l1: 0.025092, l2: 0.031317, l3: 0.043174, l4: 0.075210, l5: 0.157142, l6: 0.406596\n",
      "\n",
      "[epoch: 386/400, batch: 928/1000, ite: 51117] train loss: 1.1133, accuracy: 93.8811%, tar: 0.0198 \n",
      "l0: 0.022993, l1: 0.024816, l2: 0.035276, l3: 0.051703, l4: 0.094100, l5: 0.176242, l6: 0.416402\n",
      "\n",
      "[epoch: 386/400, batch: 936/1000, ite: 51118] train loss: 1.1134, accuracy: 95.0491%, tar: 0.0198 \n",
      "l0: 0.021480, l1: 0.022919, l2: 0.031414, l3: 0.047255, l4: 0.087407, l5: 0.244594, l6: 0.470799\n",
      "\n",
      "[epoch: 386/400, batch: 944/1000, ite: 51119] train loss: 1.1136, accuracy: 94.2381%, tar: 0.0198 \n",
      "l0: 0.019593, l1: 0.020761, l2: 0.029233, l3: 0.046195, l4: 0.082871, l5: 0.194623, l6: 0.339337\n",
      "\n",
      "[epoch: 386/400, batch: 952/1000, ite: 51120] train loss: 1.1136, accuracy: 94.9805%, tar: 0.0198 \n",
      "l0: 0.020740, l1: 0.021637, l2: 0.027829, l3: 0.038517, l4: 0.061218, l5: 0.112666, l6: 0.271665\n",
      "\n",
      "[epoch: 386/400, batch: 960/1000, ite: 51121] train loss: 1.1133, accuracy: 95.7018%, tar: 0.0198 \n",
      "l0: 0.022121, l1: 0.023277, l2: 0.032364, l3: 0.051831, l4: 0.090471, l5: 0.157874, l6: 0.287296\n",
      "\n",
      "[epoch: 386/400, batch: 968/1000, ite: 51122] train loss: 1.1132, accuracy: 95.4879%, tar: 0.0198 \n",
      "l0: 0.019292, l1: 0.020680, l2: 0.028384, l3: 0.043009, l4: 0.074656, l5: 0.154749, l6: 0.328216\n",
      "\n",
      "[epoch: 386/400, batch: 976/1000, ite: 51123] train loss: 1.1131, accuracy: 95.1284%, tar: 0.0198 \n",
      "l0: 0.016841, l1: 0.018272, l2: 0.026804, l3: 0.041293, l4: 0.072317, l5: 0.150644, l6: 0.341250\n",
      "\n",
      "[epoch: 386/400, batch: 984/1000, ite: 51124] train loss: 1.1130, accuracy: 95.7252%, tar: 0.0198 \n",
      "l0: 0.026635, l1: 0.027994, l2: 0.034728, l3: 0.047302, l4: 0.083593, l5: 0.184098, l6: 0.448614\n",
      "\n",
      "[epoch: 386/400, batch: 992/1000, ite: 51125] train loss: 1.1132, accuracy: 93.6581%, tar: 0.0199 \n",
      "l0: 0.016805, l1: 0.017832, l2: 0.026623, l3: 0.040359, l4: 0.066887, l5: 0.128630, l6: 0.290527\n",
      "\n",
      "[epoch: 386/400, batch: 1000/1000, ite: 51126] train loss: 1.1130, accuracy: 96.1379%, tar: 0.0198 \n",
      "l0: 0.021433, l1: 0.023425, l2: 0.030920, l3: 0.048502, l4: 0.101155, l5: 0.230572, l6: 0.425932\n",
      "\n",
      "[epoch: 387/400, batch: 8/1000, ite: 51127] train loss: 1.1131, accuracy: 94.8197%, tar: 0.0198 \n",
      "l0: 0.015696, l1: 0.017134, l2: 0.024665, l3: 0.039461, l4: 0.083301, l5: 0.205754, l6: 0.364041\n",
      "\n",
      "[epoch: 387/400, batch: 16/1000, ite: 51128] train loss: 1.1131, accuracy: 95.1237%, tar: 0.0198 \n",
      "l0: 0.018350, l1: 0.019251, l2: 0.026595, l3: 0.038910, l4: 0.070559, l5: 0.146274, l6: 0.309937\n",
      "\n",
      "[epoch: 387/400, batch: 24/1000, ite: 51129] train loss: 1.1130, accuracy: 95.3348%, tar: 0.0198 \n",
      "l0: 0.019436, l1: 0.021537, l2: 0.032685, l3: 0.055368, l4: 0.108929, l5: 0.271428, l6: 0.426966\n",
      "\n",
      "[epoch: 387/400, batch: 32/1000, ite: 51130] train loss: 1.1132, accuracy: 94.4698%, tar: 0.0198 \n",
      "l0: 0.015966, l1: 0.017370, l2: 0.025549, l3: 0.040519, l4: 0.097106, l5: 0.200709, l6: 0.344815\n",
      "\n",
      "[epoch: 387/400, batch: 40/1000, ite: 51131] train loss: 1.1132, accuracy: 96.0678%, tar: 0.0198 \n",
      "l0: 0.018444, l1: 0.020039, l2: 0.028796, l3: 0.044145, l4: 0.076410, l5: 0.157954, l6: 0.383628\n",
      "\n",
      "[epoch: 387/400, batch: 48/1000, ite: 51132] train loss: 1.1132, accuracy: 95.3289%, tar: 0.0198 \n",
      "l0: 0.020330, l1: 0.021869, l2: 0.029800, l3: 0.047284, l4: 0.085043, l5: 0.190157, l6: 0.370099\n",
      "\n",
      "[epoch: 387/400, batch: 56/1000, ite: 51133] train loss: 1.1132, accuracy: 94.9731%, tar: 0.0198 \n",
      "l0: 0.016761, l1: 0.017515, l2: 0.023070, l3: 0.031359, l4: 0.050709, l5: 0.093929, l6: 0.232115\n",
      "\n",
      "[epoch: 387/400, batch: 64/1000, ite: 51134] train loss: 1.1128, accuracy: 96.3534%, tar: 0.0198 \n",
      "l0: 0.026390, l1: 0.028836, l2: 0.039241, l3: 0.063878, l4: 0.116899, l5: 0.240614, l6: 0.506483\n",
      "\n",
      "[epoch: 387/400, batch: 72/1000, ite: 51135] train loss: 1.1132, accuracy: 92.8352%, tar: 0.0198 \n",
      "l0: 0.019333, l1: 0.020703, l2: 0.030354, l3: 0.047478, l4: 0.087730, l5: 0.206557, l6: 0.439662\n",
      "\n",
      "[epoch: 387/400, batch: 80/1000, ite: 51136] train loss: 1.1134, accuracy: 94.9266%, tar: 0.0198 \n",
      "l0: 0.023188, l1: 0.024427, l2: 0.031763, l3: 0.047252, l4: 0.084935, l5: 0.167724, l6: 0.397725\n",
      "\n",
      "[epoch: 387/400, batch: 88/1000, ite: 51137] train loss: 1.1134, accuracy: 93.9430%, tar: 0.0198 \n",
      "l0: 0.019933, l1: 0.020572, l2: 0.027180, l3: 0.041096, l4: 0.071150, l5: 0.135237, l6: 0.297705\n",
      "\n",
      "[epoch: 387/400, batch: 96/1000, ite: 51138] train loss: 1.1132, accuracy: 95.5117%, tar: 0.0198 \n",
      "l0: 0.021289, l1: 0.022419, l2: 0.030216, l3: 0.044117, l4: 0.080647, l5: 0.183630, l6: 0.446297\n",
      "\n",
      "[epoch: 387/400, batch: 104/1000, ite: 51139] train loss: 1.1134, accuracy: 94.1997%, tar: 0.0198 \n",
      "l0: 0.015173, l1: 0.016192, l2: 0.023538, l3: 0.034307, l4: 0.066949, l5: 0.159745, l6: 0.371727\n",
      "\n",
      "[epoch: 387/400, batch: 112/1000, ite: 51140] train loss: 1.1133, accuracy: 95.8623%, tar: 0.0198 \n",
      "l0: 0.022783, l1: 0.024162, l2: 0.032111, l3: 0.046896, l4: 0.080057, l5: 0.169335, l6: 0.375907\n",
      "\n",
      "[epoch: 387/400, batch: 120/1000, ite: 51141] train loss: 1.1134, accuracy: 94.1674%, tar: 0.0198 \n",
      "l0: 0.020460, l1: 0.021614, l2: 0.028782, l3: 0.046186, l4: 0.081157, l5: 0.182991, l6: 0.354033\n",
      "\n",
      "[epoch: 387/400, batch: 128/1000, ite: 51142] train loss: 1.1133, accuracy: 94.9980%, tar: 0.0198 \n",
      "l0: 0.016796, l1: 0.017854, l2: 0.023593, l3: 0.036297, l4: 0.070250, l5: 0.126795, l6: 0.264723\n",
      "\n",
      "[epoch: 387/400, batch: 136/1000, ite: 51143] train loss: 1.1131, accuracy: 96.1914%, tar: 0.0198 \n",
      "l0: 0.022232, l1: 0.023553, l2: 0.030923, l3: 0.046780, l4: 0.088446, l5: 0.171761, l6: 0.312421\n",
      "\n",
      "[epoch: 387/400, batch: 144/1000, ite: 51144] train loss: 1.1130, accuracy: 95.2615%, tar: 0.0198 \n",
      "l0: 0.021086, l1: 0.022018, l2: 0.028931, l3: 0.039809, l4: 0.065915, l5: 0.133554, l6: 0.297623\n",
      "\n",
      "[epoch: 387/400, batch: 152/1000, ite: 51145] train loss: 1.1128, accuracy: 95.0253%, tar: 0.0198 \n",
      "l0: 0.018529, l1: 0.019663, l2: 0.025679, l3: 0.039031, l4: 0.070069, l5: 0.160573, l6: 0.307077\n",
      "\n",
      "[epoch: 387/400, batch: 160/1000, ite: 51146] train loss: 1.1127, accuracy: 95.7611%, tar: 0.0198 \n",
      "l0: 0.018559, l1: 0.019848, l2: 0.027496, l3: 0.041517, l4: 0.075995, l5: 0.170574, l6: 0.353434\n",
      "\n",
      "[epoch: 387/400, batch: 168/1000, ite: 51147] train loss: 1.1126, accuracy: 94.8504%, tar: 0.0198 \n",
      "l0: 0.017335, l1: 0.018142, l2: 0.025720, l3: 0.042196, l4: 0.076198, l5: 0.181957, l6: 0.402734\n",
      "\n",
      "[epoch: 387/400, batch: 176/1000, ite: 51148] train loss: 1.1127, accuracy: 94.6645%, tar: 0.0198 \n",
      "l0: 0.019675, l1: 0.021605, l2: 0.032698, l3: 0.057262, l4: 0.112795, l5: 0.210755, l6: 0.499854\n",
      "\n",
      "[epoch: 387/400, batch: 184/1000, ite: 51149] train loss: 1.1130, accuracy: 95.1382%, tar: 0.0198 \n",
      "l0: 0.022520, l1: 0.024573, l2: 0.032143, l3: 0.046914, l4: 0.087889, l5: 0.163567, l6: 0.335677\n",
      "\n",
      "[epoch: 387/400, batch: 192/1000, ite: 51150] train loss: 1.1129, accuracy: 95.4061%, tar: 0.0198 \n",
      "l0: 0.015804, l1: 0.017729, l2: 0.025083, l3: 0.039577, l4: 0.080861, l5: 0.150177, l6: 0.324755\n",
      "\n",
      "[epoch: 387/400, batch: 200/1000, ite: 51151] train loss: 1.1128, accuracy: 96.1404%, tar: 0.0198 \n",
      "l0: 0.022534, l1: 0.023759, l2: 0.033028, l3: 0.048507, l4: 0.094034, l5: 0.194507, l6: 0.394780\n",
      "\n",
      "[epoch: 387/400, batch: 208/1000, ite: 51152] train loss: 1.1129, accuracy: 94.1110%, tar: 0.0198 \n",
      "l0: 0.024032, l1: 0.025458, l2: 0.034022, l3: 0.052574, l4: 0.105808, l5: 0.235062, l6: 0.474633\n",
      "\n",
      "[epoch: 387/400, batch: 216/1000, ite: 51153] train loss: 1.1132, accuracy: 93.3743%, tar: 0.0198 \n",
      "l0: 0.015280, l1: 0.016637, l2: 0.023183, l3: 0.035671, l4: 0.071686, l5: 0.145234, l6: 0.326735\n",
      "\n",
      "[epoch: 387/400, batch: 224/1000, ite: 51154] train loss: 1.1130, accuracy: 96.1792%, tar: 0.0198 \n",
      "l0: 0.019857, l1: 0.021737, l2: 0.031084, l3: 0.050457, l4: 0.105214, l5: 0.223961, l6: 0.487431\n",
      "\n",
      "[epoch: 387/400, batch: 232/1000, ite: 51155] train loss: 1.1133, accuracy: 94.7013%, tar: 0.0198 \n",
      "l0: 0.022346, l1: 0.024000, l2: 0.033113, l3: 0.052039, l4: 0.114111, l5: 0.234566, l6: 0.481512\n",
      "\n",
      "[epoch: 387/400, batch: 240/1000, ite: 51156] train loss: 1.1136, accuracy: 93.0811%, tar: 0.0198 \n",
      "l0: 0.019614, l1: 0.021081, l2: 0.028086, l3: 0.046932, l4: 0.114044, l5: 0.198287, l6: 0.378727\n",
      "\n",
      "[epoch: 387/400, batch: 248/1000, ite: 51157] train loss: 1.1137, accuracy: 95.3765%, tar: 0.0198 \n",
      "l0: 0.018164, l1: 0.019499, l2: 0.027147, l3: 0.041786, l4: 0.074806, l5: 0.161618, l6: 0.336658\n",
      "\n",
      "[epoch: 387/400, batch: 256/1000, ite: 51158] train loss: 1.1136, accuracy: 95.2055%, tar: 0.0198 \n",
      "l0: 0.019718, l1: 0.020989, l2: 0.028316, l3: 0.043686, l4: 0.083991, l5: 0.194508, l6: 0.406722\n",
      "\n",
      "[epoch: 387/400, batch: 264/1000, ite: 51159] train loss: 1.1137, accuracy: 94.1920%, tar: 0.0198 \n",
      "l0: 0.016248, l1: 0.017050, l2: 0.023119, l3: 0.036206, l4: 0.059747, l5: 0.118713, l6: 0.283115\n",
      "\n",
      "[epoch: 387/400, batch: 272/1000, ite: 51160] train loss: 1.1134, accuracy: 96.0808%, tar: 0.0198 \n",
      "l0: 0.019123, l1: 0.020701, l2: 0.028181, l3: 0.039674, l4: 0.069827, l5: 0.140897, l6: 0.347027\n",
      "\n",
      "[epoch: 387/400, batch: 280/1000, ite: 51161] train loss: 1.1134, accuracy: 95.6718%, tar: 0.0198 \n",
      "l0: 0.019624, l1: 0.020918, l2: 0.030194, l3: 0.049313, l4: 0.092714, l5: 0.173220, l6: 0.320704\n",
      "\n",
      "[epoch: 387/400, batch: 288/1000, ite: 51162] train loss: 1.1133, accuracy: 95.3900%, tar: 0.0198 \n",
      "l0: 0.016937, l1: 0.018427, l2: 0.025398, l3: 0.043342, l4: 0.073652, l5: 0.131457, l6: 0.263008\n",
      "\n",
      "[epoch: 387/400, batch: 296/1000, ite: 51163] train loss: 1.1130, accuracy: 96.2580%, tar: 0.0198 \n",
      "l0: 0.024391, l1: 0.026141, l2: 0.035586, l3: 0.058870, l4: 0.116549, l5: 0.254510, l6: 0.474349\n",
      "\n",
      "[epoch: 387/400, batch: 304/1000, ite: 51164] train loss: 1.1134, accuracy: 93.6653%, tar: 0.0198 \n",
      "l0: 0.018992, l1: 0.020224, l2: 0.028134, l3: 0.043052, l4: 0.089434, l5: 0.197693, l6: 0.433983\n",
      "\n",
      "[epoch: 387/400, batch: 312/1000, ite: 51165] train loss: 1.1135, accuracy: 93.9489%, tar: 0.0198 \n",
      "l0: 0.018094, l1: 0.019074, l2: 0.025473, l3: 0.040126, l4: 0.069056, l5: 0.143623, l6: 0.321205\n",
      "\n",
      "[epoch: 387/400, batch: 320/1000, ite: 51166] train loss: 1.1134, accuracy: 95.8934%, tar: 0.0198 \n",
      "l0: 0.014732, l1: 0.016489, l2: 0.021852, l3: 0.030851, l4: 0.061178, l5: 0.127123, l6: 0.256622\n",
      "\n",
      "[epoch: 387/400, batch: 328/1000, ite: 51167] train loss: 1.1131, accuracy: 96.8428%, tar: 0.0198 \n",
      "l0: 0.024334, l1: 0.026435, l2: 0.036714, l3: 0.059554, l4: 0.118122, l5: 0.267574, l6: 0.553835\n",
      "\n",
      "[epoch: 387/400, batch: 336/1000, ite: 51168] train loss: 1.1136, accuracy: 92.9038%, tar: 0.0198 \n",
      "l0: 0.023582, l1: 0.025141, l2: 0.033619, l3: 0.053815, l4: 0.108592, l5: 0.216519, l6: 0.398435\n",
      "\n",
      "[epoch: 387/400, batch: 344/1000, ite: 51169] train loss: 1.1137, accuracy: 94.8450%, tar: 0.0198 \n",
      "l0: 0.022443, l1: 0.023384, l2: 0.029076, l3: 0.041934, l4: 0.074611, l5: 0.133466, l6: 0.254360\n",
      "\n",
      "[epoch: 387/400, batch: 352/1000, ite: 51170] train loss: 1.1134, accuracy: 95.4765%, tar: 0.0198 \n",
      "l0: 0.014670, l1: 0.016416, l2: 0.023832, l3: 0.036417, l4: 0.065920, l5: 0.119147, l6: 0.266686\n",
      "\n",
      "[epoch: 387/400, batch: 360/1000, ite: 51171] train loss: 1.1132, accuracy: 96.3307%, tar: 0.0198 \n",
      "l0: 0.019782, l1: 0.021200, l2: 0.029504, l3: 0.046924, l4: 0.082376, l5: 0.175850, l6: 0.373624\n",
      "\n",
      "[epoch: 387/400, batch: 368/1000, ite: 51172] train loss: 1.1132, accuracy: 95.1719%, tar: 0.0198 \n",
      "l0: 0.017972, l1: 0.019327, l2: 0.026526, l3: 0.042582, l4: 0.088885, l5: 0.185736, l6: 0.371680\n",
      "\n",
      "[epoch: 387/400, batch: 376/1000, ite: 51173] train loss: 1.1132, accuracy: 95.2021%, tar: 0.0198 \n",
      "l0: 0.018943, l1: 0.020277, l2: 0.026262, l3: 0.041979, l4: 0.083063, l5: 0.149962, l6: 0.330681\n",
      "\n",
      "[epoch: 387/400, batch: 384/1000, ite: 51174] train loss: 1.1131, accuracy: 95.3265%, tar: 0.0198 \n",
      "l0: 0.018685, l1: 0.020361, l2: 0.030130, l3: 0.046920, l4: 0.107909, l5: 0.171362, l6: 0.349076\n",
      "\n",
      "[epoch: 387/400, batch: 392/1000, ite: 51175] train loss: 1.1131, accuracy: 95.5396%, tar: 0.0198 \n",
      "l0: 0.019266, l1: 0.020092, l2: 0.026863, l3: 0.040458, l4: 0.071475, l5: 0.151656, l6: 0.321418\n",
      "\n",
      "[epoch: 387/400, batch: 400/1000, ite: 51176] train loss: 1.1130, accuracy: 95.2792%, tar: 0.0198 \n",
      "l0: 0.022359, l1: 0.024606, l2: 0.034065, l3: 0.051745, l4: 0.096912, l5: 0.193530, l6: 0.367463\n",
      "\n",
      "[epoch: 387/400, batch: 408/1000, ite: 51177] train loss: 1.1130, accuracy: 95.5163%, tar: 0.0198 \n",
      "l0: 0.024783, l1: 0.026857, l2: 0.036808, l3: 0.064633, l4: 0.143993, l5: 0.298481, l6: 0.564175\n",
      "\n",
      "[epoch: 387/400, batch: 416/1000, ite: 51178] train loss: 1.1136, accuracy: 92.3921%, tar: 0.0198 \n",
      "l0: 0.018328, l1: 0.019465, l2: 0.025050, l3: 0.037955, l4: 0.070732, l5: 0.133621, l6: 0.305436\n",
      "\n",
      "[epoch: 387/400, batch: 424/1000, ite: 51179] train loss: 1.1134, accuracy: 95.3670%, tar: 0.0198 \n",
      "l0: 0.017955, l1: 0.019071, l2: 0.027618, l3: 0.042746, l4: 0.087860, l5: 0.182499, l6: 0.408604\n",
      "\n",
      "[epoch: 387/400, batch: 432/1000, ite: 51180] train loss: 1.1135, accuracy: 94.1675%, tar: 0.0198 \n",
      "l0: 0.019087, l1: 0.020881, l2: 0.030275, l3: 0.045994, l4: 0.089761, l5: 0.201035, l6: 0.405092\n",
      "\n",
      "[epoch: 387/400, batch: 440/1000, ite: 51181] train loss: 1.1136, accuracy: 95.2041%, tar: 0.0198 \n",
      "l0: 0.021059, l1: 0.023943, l2: 0.037355, l3: 0.064487, l4: 0.112809, l5: 0.196302, l6: 0.358072\n",
      "\n",
      "[epoch: 387/400, batch: 448/1000, ite: 51182] train loss: 1.1136, accuracy: 95.7162%, tar: 0.0198 \n",
      "l0: 0.024528, l1: 0.025897, l2: 0.036141, l3: 0.055636, l4: 0.122107, l5: 0.295324, l6: 0.533003\n",
      "\n",
      "[epoch: 387/400, batch: 456/1000, ite: 51183] train loss: 1.1140, accuracy: 92.7458%, tar: 0.0198 \n",
      "l0: 0.017226, l1: 0.018753, l2: 0.027388, l3: 0.045118, l4: 0.076767, l5: 0.149937, l6: 0.293551\n",
      "\n",
      "[epoch: 387/400, batch: 464/1000, ite: 51184] train loss: 1.1139, accuracy: 96.4585%, tar: 0.0198 \n",
      "l0: 0.015697, l1: 0.016687, l2: 0.022999, l3: 0.035447, l4: 0.061674, l5: 0.136718, l6: 0.261475\n",
      "\n",
      "[epoch: 387/400, batch: 472/1000, ite: 51185] train loss: 1.1136, accuracy: 96.6795%, tar: 0.0198 \n",
      "l0: 0.022381, l1: 0.024003, l2: 0.032324, l3: 0.049322, l4: 0.095624, l5: 0.207970, l6: 0.407286\n",
      "\n",
      "[epoch: 387/400, batch: 480/1000, ite: 51186] train loss: 1.1138, accuracy: 94.7832%, tar: 0.0198 \n",
      "l0: 0.013725, l1: 0.014548, l2: 0.020826, l3: 0.032632, l4: 0.052647, l5: 0.105404, l6: 0.254566\n",
      "\n",
      "[epoch: 387/400, batch: 488/1000, ite: 51187] train loss: 1.1135, accuracy: 96.5401%, tar: 0.0198 \n",
      "l0: 0.018970, l1: 0.020017, l2: 0.028207, l3: 0.043621, l4: 0.075123, l5: 0.152552, l6: 0.345021\n",
      "\n",
      "[epoch: 387/400, batch: 496/1000, ite: 51188] train loss: 1.1134, accuracy: 95.1411%, tar: 0.0198 \n",
      "l0: 0.018979, l1: 0.020495, l2: 0.026903, l3: 0.042601, l4: 0.085364, l5: 0.165271, l6: 0.363662\n",
      "\n",
      "[epoch: 387/400, batch: 504/1000, ite: 51189] train loss: 1.1134, accuracy: 95.3833%, tar: 0.0198 \n",
      "l0: 0.022276, l1: 0.023715, l2: 0.032419, l3: 0.047392, l4: 0.086840, l5: 0.191234, l6: 0.390278\n",
      "\n",
      "[epoch: 387/400, batch: 512/1000, ite: 51190] train loss: 1.1134, accuracy: 94.6468%, tar: 0.0198 \n",
      "l0: 0.020038, l1: 0.021397, l2: 0.029831, l3: 0.045206, l4: 0.079297, l5: 0.166982, l6: 0.404939\n",
      "\n",
      "[epoch: 387/400, batch: 520/1000, ite: 51191] train loss: 1.1135, accuracy: 94.6899%, tar: 0.0198 \n",
      "l0: 0.019856, l1: 0.020652, l2: 0.026159, l3: 0.039120, l4: 0.072712, l5: 0.155144, l6: 0.303355\n",
      "\n",
      "[epoch: 387/400, batch: 528/1000, ite: 51192] train loss: 1.1133, accuracy: 95.5090%, tar: 0.0198 \n",
      "l0: 0.016213, l1: 0.016877, l2: 0.021574, l3: 0.032257, l4: 0.059880, l5: 0.137788, l6: 0.313780\n",
      "\n",
      "[epoch: 387/400, batch: 536/1000, ite: 51193] train loss: 1.1132, accuracy: 95.1078%, tar: 0.0198 \n",
      "l0: 0.016425, l1: 0.017815, l2: 0.025753, l3: 0.040822, l4: 0.079465, l5: 0.202588, l6: 0.431394\n",
      "\n",
      "[epoch: 387/400, batch: 544/1000, ite: 51194] train loss: 1.1133, accuracy: 94.8746%, tar: 0.0198 \n",
      "l0: 0.019705, l1: 0.021648, l2: 0.032331, l3: 0.051715, l4: 0.099337, l5: 0.208529, l6: 0.481886\n",
      "\n",
      "[epoch: 387/400, batch: 552/1000, ite: 51195] train loss: 1.1135, accuracy: 94.2948%, tar: 0.0198 \n",
      "l0: 0.018080, l1: 0.020325, l2: 0.029171, l3: 0.045613, l4: 0.085117, l5: 0.180529, l6: 0.384130\n",
      "\n",
      "[epoch: 387/400, batch: 560/1000, ite: 51196] train loss: 1.1136, accuracy: 95.4810%, tar: 0.0198 \n",
      "l0: 0.019171, l1: 0.019790, l2: 0.027474, l3: 0.039786, l4: 0.066003, l5: 0.125446, l6: 0.253975\n",
      "\n",
      "[epoch: 387/400, batch: 568/1000, ite: 51197] train loss: 1.1133, accuracy: 95.7414%, tar: 0.0198 \n",
      "l0: 0.022985, l1: 0.024582, l2: 0.033350, l3: 0.055400, l4: 0.150412, l5: 0.302551, l6: 0.538961\n",
      "\n",
      "[epoch: 387/400, batch: 576/1000, ite: 51198] train loss: 1.1138, accuracy: 92.8056%, tar: 0.0198 \n",
      "l0: 0.018169, l1: 0.019378, l2: 0.026631, l3: 0.041632, l4: 0.079334, l5: 0.138162, l6: 0.269318\n",
      "\n",
      "[epoch: 387/400, batch: 584/1000, ite: 51199] train loss: 1.1136, accuracy: 95.9433%, tar: 0.0198 \n",
      "l0: 0.017671, l1: 0.018899, l2: 0.029208, l3: 0.048432, l4: 0.093343, l5: 0.217199, l6: 0.404630\n",
      "\n",
      "[epoch: 387/400, batch: 592/1000, ite: 51200] train loss: 1.1137, accuracy: 94.3279%, tar: 0.0198 \n",
      "l0: 0.021787, l1: 0.023381, l2: 0.030482, l3: 0.046185, l4: 0.091557, l5: 0.188373, l6: 0.420424\n",
      "\n",
      "[epoch: 387/400, batch: 600/1000, ite: 51201] train loss: 1.1138, accuracy: 94.7609%, tar: 0.0198 \n",
      "l0: 0.021281, l1: 0.023693, l2: 0.033618, l3: 0.051893, l4: 0.091808, l5: 0.177326, l6: 0.343274\n",
      "\n",
      "[epoch: 387/400, batch: 608/1000, ite: 51202] train loss: 1.1138, accuracy: 95.1828%, tar: 0.0198 \n",
      "l0: 0.018380, l1: 0.019550, l2: 0.027686, l3: 0.043437, l4: 0.081622, l5: 0.166741, l6: 0.303078\n",
      "\n",
      "[epoch: 387/400, batch: 616/1000, ite: 51203] train loss: 1.1136, accuracy: 95.4279%, tar: 0.0198 \n",
      "l0: 0.017968, l1: 0.018788, l2: 0.023120, l3: 0.034207, l4: 0.061804, l5: 0.123766, l6: 0.257823\n",
      "\n",
      "[epoch: 387/400, batch: 624/1000, ite: 51204] train loss: 1.1134, accuracy: 95.5858%, tar: 0.0198 \n",
      "l0: 0.019833, l1: 0.021319, l2: 0.029174, l3: 0.045367, l4: 0.084805, l5: 0.177863, l6: 0.433827\n",
      "\n",
      "[epoch: 387/400, batch: 632/1000, ite: 51205] train loss: 1.1135, accuracy: 94.5742%, tar: 0.0198 \n",
      "l0: 0.022663, l1: 0.025109, l2: 0.037641, l3: 0.061155, l4: 0.114276, l5: 0.225914, l6: 0.449567\n",
      "\n",
      "[epoch: 387/400, batch: 640/1000, ite: 51206] train loss: 1.1137, accuracy: 94.7068%, tar: 0.0198 \n",
      "l0: 0.019682, l1: 0.020972, l2: 0.027506, l3: 0.045501, l4: 0.082386, l5: 0.186487, l6: 0.416346\n",
      "\n",
      "[epoch: 387/400, batch: 648/1000, ite: 51207] train loss: 1.1138, accuracy: 94.3586%, tar: 0.0198 \n",
      "l0: 0.022092, l1: 0.024207, l2: 0.034722, l3: 0.055450, l4: 0.122063, l5: 0.272227, l6: 0.578369\n",
      "\n",
      "[epoch: 387/400, batch: 656/1000, ite: 51208] train loss: 1.1143, accuracy: 93.6441%, tar: 0.0198 \n",
      "l0: 0.023007, l1: 0.024370, l2: 0.032013, l3: 0.047813, l4: 0.092785, l5: 0.192096, l6: 0.425436\n",
      "\n",
      "[epoch: 387/400, batch: 664/1000, ite: 51209] train loss: 1.1144, accuracy: 93.6187%, tar: 0.0198 \n",
      "l0: 0.021020, l1: 0.022090, l2: 0.028369, l3: 0.041199, l4: 0.073491, l5: 0.153883, l6: 0.388226\n",
      "\n",
      "[epoch: 387/400, batch: 672/1000, ite: 51210] train loss: 1.1144, accuracy: 95.1285%, tar: 0.0198 \n",
      "l0: 0.016503, l1: 0.017597, l2: 0.023491, l3: 0.038790, l4: 0.071492, l5: 0.133256, l6: 0.253665\n",
      "\n",
      "[epoch: 387/400, batch: 680/1000, ite: 51211] train loss: 1.1142, accuracy: 95.8334%, tar: 0.0198 \n",
      "l0: 0.019876, l1: 0.021094, l2: 0.028441, l3: 0.044577, l4: 0.077796, l5: 0.154660, l6: 0.360080\n",
      "\n",
      "[epoch: 387/400, batch: 688/1000, ite: 51212] train loss: 1.1141, accuracy: 95.2541%, tar: 0.0198 \n",
      "l0: 0.020567, l1: 0.021967, l2: 0.031013, l3: 0.046974, l4: 0.092262, l5: 0.218223, l6: 0.425953\n",
      "\n",
      "[epoch: 387/400, batch: 696/1000, ite: 51213] train loss: 1.1143, accuracy: 94.2251%, tar: 0.0198 \n",
      "l0: 0.017613, l1: 0.018924, l2: 0.026710, l3: 0.042396, l4: 0.078970, l5: 0.156748, l6: 0.333423\n",
      "\n",
      "[epoch: 387/400, batch: 704/1000, ite: 51214] train loss: 1.1142, accuracy: 95.2350%, tar: 0.0198 \n",
      "l0: 0.015734, l1: 0.016699, l2: 0.021461, l3: 0.032023, l4: 0.057862, l5: 0.118493, l6: 0.236868\n",
      "\n",
      "[epoch: 387/400, batch: 712/1000, ite: 51215] train loss: 1.1139, accuracy: 96.3303%, tar: 0.0198 \n",
      "l0: 0.018015, l1: 0.018769, l2: 0.025445, l3: 0.038128, l4: 0.081607, l5: 0.155119, l6: 0.349186\n",
      "\n",
      "[epoch: 387/400, batch: 720/1000, ite: 51216] train loss: 1.1138, accuracy: 95.2879%, tar: 0.0198 \n",
      "l0: 0.018757, l1: 0.020032, l2: 0.027304, l3: 0.038610, l4: 0.065168, l5: 0.134847, l6: 0.393755\n",
      "\n",
      "[epoch: 387/400, batch: 728/1000, ite: 51217] train loss: 1.1138, accuracy: 94.8517%, tar: 0.0198 \n",
      "l0: 0.019396, l1: 0.020456, l2: 0.026255, l3: 0.040655, l4: 0.078926, l5: 0.173829, l6: 0.401071\n",
      "\n",
      "[epoch: 387/400, batch: 736/1000, ite: 51218] train loss: 1.1138, accuracy: 94.9088%, tar: 0.0198 \n",
      "l0: 0.013988, l1: 0.014973, l2: 0.021938, l3: 0.035588, l4: 0.069022, l5: 0.148511, l6: 0.358738\n",
      "\n",
      "[epoch: 387/400, batch: 744/1000, ite: 51219] train loss: 1.1138, accuracy: 96.0694%, tar: 0.0198 \n",
      "l0: 0.017458, l1: 0.018261, l2: 0.025064, l3: 0.034960, l4: 0.054113, l5: 0.100829, l6: 0.211095\n",
      "\n",
      "[epoch: 387/400, batch: 752/1000, ite: 51220] train loss: 1.1134, accuracy: 96.6857%, tar: 0.0198 \n",
      "l0: 0.018744, l1: 0.020240, l2: 0.028589, l3: 0.046952, l4: 0.088859, l5: 0.164624, l6: 0.308528\n",
      "\n",
      "[epoch: 387/400, batch: 760/1000, ite: 51221] train loss: 1.1133, accuracy: 95.4147%, tar: 0.0198 \n",
      "l0: 0.018795, l1: 0.019892, l2: 0.028540, l3: 0.039356, l4: 0.069110, l5: 0.141443, l6: 0.361821\n",
      "\n",
      "[epoch: 387/400, batch: 768/1000, ite: 51222] train loss: 1.1132, accuracy: 95.1554%, tar: 0.0198 \n",
      "l0: 0.016384, l1: 0.017871, l2: 0.025393, l3: 0.042781, l4: 0.093249, l5: 0.166474, l6: 0.283605\n",
      "\n",
      "[epoch: 387/400, batch: 776/1000, ite: 51223] train loss: 1.1131, accuracy: 95.9223%, tar: 0.0198 \n",
      "l0: 0.028206, l1: 0.030168, l2: 0.039558, l3: 0.059347, l4: 0.109068, l5: 0.237349, l6: 0.451092\n",
      "\n",
      "[epoch: 387/400, batch: 784/1000, ite: 51224] train loss: 1.1133, accuracy: 93.5706%, tar: 0.0198 \n",
      "l0: 0.018465, l1: 0.020081, l2: 0.029308, l3: 0.050367, l4: 0.115003, l5: 0.217159, l6: 0.361876\n",
      "\n",
      "[epoch: 387/400, batch: 792/1000, ite: 51225] train loss: 1.1134, accuracy: 95.5222%, tar: 0.0198 \n",
      "l0: 0.018687, l1: 0.019908, l2: 0.027099, l3: 0.040662, l4: 0.075252, l5: 0.178804, l6: 0.332963\n",
      "\n",
      "[epoch: 387/400, batch: 800/1000, ite: 51226] train loss: 1.1133, accuracy: 95.1931%, tar: 0.0198 \n",
      "l0: 0.019298, l1: 0.020753, l2: 0.028644, l3: 0.041268, l4: 0.069303, l5: 0.133763, l6: 0.294761\n",
      "\n",
      "[epoch: 387/400, batch: 808/1000, ite: 51227] train loss: 1.1132, accuracy: 95.5457%, tar: 0.0198 \n",
      "l0: 0.022904, l1: 0.024851, l2: 0.037624, l3: 0.060991, l4: 0.090188, l5: 0.155122, l6: 0.308211\n",
      "\n",
      "[epoch: 387/400, batch: 816/1000, ite: 51228] train loss: 1.1131, accuracy: 95.5823%, tar: 0.0198 \n",
      "l0: 0.022958, l1: 0.024327, l2: 0.033206, l3: 0.048898, l4: 0.092940, l5: 0.171690, l6: 0.323886\n",
      "\n",
      "[epoch: 387/400, batch: 824/1000, ite: 51229] train loss: 1.1130, accuracy: 95.2685%, tar: 0.0198 \n",
      "l0: 0.013810, l1: 0.015819, l2: 0.022047, l3: 0.033265, l4: 0.062884, l5: 0.134351, l6: 0.343732\n",
      "\n",
      "[epoch: 387/400, batch: 832/1000, ite: 51230] train loss: 1.1129, accuracy: 96.8127%, tar: 0.0198 \n",
      "l0: 0.018435, l1: 0.020481, l2: 0.028303, l3: 0.042456, l4: 0.073963, l5: 0.148894, l6: 0.304145\n",
      "\n",
      "[epoch: 387/400, batch: 840/1000, ite: 51231] train loss: 1.1128, accuracy: 96.0163%, tar: 0.0198 \n",
      "l0: 0.021033, l1: 0.022278, l2: 0.032441, l3: 0.049014, l4: 0.088688, l5: 0.204996, l6: 0.403114\n",
      "\n",
      "[epoch: 387/400, batch: 848/1000, ite: 51232] train loss: 1.1129, accuracy: 94.4559%, tar: 0.0198 \n",
      "l0: 0.021723, l1: 0.023593, l2: 0.032374, l3: 0.054098, l4: 0.102897, l5: 0.208716, l6: 0.464295\n",
      "\n",
      "[epoch: 387/400, batch: 856/1000, ite: 51233] train loss: 1.1131, accuracy: 94.2440%, tar: 0.0198 \n",
      "l0: 0.021446, l1: 0.022685, l2: 0.029279, l3: 0.043811, l4: 0.078996, l5: 0.160767, l6: 0.333865\n",
      "\n",
      "[epoch: 387/400, batch: 864/1000, ite: 51234] train loss: 1.1130, accuracy: 94.9129%, tar: 0.0198 \n",
      "l0: 0.021972, l1: 0.022836, l2: 0.030190, l3: 0.043676, l4: 0.074918, l5: 0.144065, l6: 0.411590\n",
      "\n",
      "[epoch: 387/400, batch: 872/1000, ite: 51235] train loss: 1.1131, accuracy: 93.9601%, tar: 0.0198 \n",
      "l0: 0.022375, l1: 0.024471, l2: 0.035386, l3: 0.059587, l4: 0.140767, l5: 0.290561, l6: 0.540974\n",
      "\n",
      "[epoch: 387/400, batch: 880/1000, ite: 51236] train loss: 1.1135, accuracy: 93.6303%, tar: 0.0198 \n",
      "l0: 0.021824, l1: 0.023896, l2: 0.033533, l3: 0.052256, l4: 0.103525, l5: 0.202641, l6: 0.477333\n",
      "\n",
      "[epoch: 387/400, batch: 888/1000, ite: 51237] train loss: 1.1137, accuracy: 94.2060%, tar: 0.0198 \n",
      "l0: 0.022913, l1: 0.024250, l2: 0.031767, l3: 0.050323, l4: 0.098490, l5: 0.196872, l6: 0.413435\n",
      "\n",
      "[epoch: 387/400, batch: 896/1000, ite: 51238] train loss: 1.1138, accuracy: 94.0433%, tar: 0.0198 \n",
      "l0: 0.021080, l1: 0.023264, l2: 0.034022, l3: 0.050727, l4: 0.095420, l5: 0.203836, l6: 0.378123\n",
      "\n",
      "[epoch: 387/400, batch: 904/1000, ite: 51239] train loss: 1.1139, accuracy: 95.8673%, tar: 0.0198 \n",
      "l0: 0.020981, l1: 0.022129, l2: 0.029412, l3: 0.044467, l4: 0.083872, l5: 0.151756, l6: 0.381517\n",
      "\n",
      "[epoch: 387/400, batch: 912/1000, ite: 51240] train loss: 1.1139, accuracy: 94.9694%, tar: 0.0198 \n",
      "l0: 0.024524, l1: 0.026364, l2: 0.036529, l3: 0.055405, l4: 0.102466, l5: 0.244893, l6: 0.553334\n",
      "\n",
      "[epoch: 387/400, batch: 920/1000, ite: 51241] train loss: 1.1143, accuracy: 93.5409%, tar: 0.0198 \n",
      "l0: 0.023438, l1: 0.024379, l2: 0.031935, l3: 0.047955, l4: 0.101418, l5: 0.194032, l6: 0.406705\n",
      "\n",
      "[epoch: 387/400, batch: 928/1000, ite: 51242] train loss: 1.1144, accuracy: 94.3952%, tar: 0.0198 \n",
      "l0: 0.020462, l1: 0.021893, l2: 0.031589, l3: 0.053002, l4: 0.096928, l5: 0.208975, l6: 0.411608\n",
      "\n",
      "[epoch: 387/400, batch: 936/1000, ite: 51243] train loss: 1.1145, accuracy: 94.8775%, tar: 0.0198 \n",
      "l0: 0.014995, l1: 0.016838, l2: 0.025198, l3: 0.041085, l4: 0.079113, l5: 0.148727, l6: 0.325349\n",
      "\n",
      "[epoch: 387/400, batch: 944/1000, ite: 51244] train loss: 1.1144, accuracy: 96.1196%, tar: 0.0198 \n",
      "l0: 0.017265, l1: 0.017781, l2: 0.025437, l3: 0.037630, l4: 0.060625, l5: 0.122044, l6: 0.288667\n",
      "\n",
      "[epoch: 387/400, batch: 952/1000, ite: 51245] train loss: 1.1142, accuracy: 95.6014%, tar: 0.0198 \n",
      "l0: 0.019279, l1: 0.020513, l2: 0.030065, l3: 0.046784, l4: 0.082888, l5: 0.156826, l6: 0.292202\n",
      "\n",
      "[epoch: 387/400, batch: 960/1000, ite: 51246] train loss: 1.1140, accuracy: 95.7010%, tar: 0.0198 \n",
      "l0: 0.015393, l1: 0.016889, l2: 0.024582, l3: 0.041835, l4: 0.070577, l5: 0.140387, l6: 0.281872\n",
      "\n",
      "[epoch: 387/400, batch: 968/1000, ite: 51247] train loss: 1.1139, accuracy: 96.5261%, tar: 0.0198 \n",
      "l0: 0.016738, l1: 0.017604, l2: 0.022453, l3: 0.033005, l4: 0.054476, l5: 0.098176, l6: 0.233027\n",
      "\n",
      "[epoch: 387/400, batch: 976/1000, ite: 51248] train loss: 1.1135, accuracy: 95.9652%, tar: 0.0198 \n",
      "l0: 0.018876, l1: 0.019911, l2: 0.026810, l3: 0.037830, l4: 0.062830, l5: 0.114281, l6: 0.266652\n",
      "\n",
      "[epoch: 387/400, batch: 984/1000, ite: 51249] train loss: 1.1133, accuracy: 95.9181%, tar: 0.0198 \n",
      "l0: 0.018264, l1: 0.019403, l2: 0.026919, l3: 0.043618, l4: 0.093371, l5: 0.187012, l6: 0.320707\n",
      "\n",
      "[epoch: 387/400, batch: 992/1000, ite: 51250] train loss: 1.1132, accuracy: 95.2828%, tar: 0.0198 \n",
      "l0: 0.023630, l1: 0.024627, l2: 0.032376, l3: 0.047355, l4: 0.081034, l5: 0.153285, l6: 0.307403\n",
      "\n",
      "[epoch: 387/400, batch: 1000/1000, ite: 51251] train loss: 1.1131, accuracy: 95.2021%, tar: 0.0198 \n",
      "l0: 0.015711, l1: 0.017213, l2: 0.024934, l3: 0.042214, l4: 0.078257, l5: 0.155996, l6: 0.354335\n",
      "\n",
      "[epoch: 388/400, batch: 8/1000, ite: 51252] train loss: 1.1131, accuracy: 95.4270%, tar: 0.0198 \n",
      "l0: 0.019975, l1: 0.021735, l2: 0.031584, l3: 0.048399, l4: 0.092131, l5: 0.179855, l6: 0.377915\n",
      "\n",
      "[epoch: 388/400, batch: 16/1000, ite: 51253] train loss: 1.1131, accuracy: 95.7201%, tar: 0.0198 \n",
      "l0: 0.019294, l1: 0.020196, l2: 0.026517, l3: 0.038501, l4: 0.064330, l5: 0.131068, l6: 0.298508\n",
      "\n",
      "[epoch: 388/400, batch: 24/1000, ite: 51254] train loss: 1.1129, accuracy: 95.6765%, tar: 0.0198 \n",
      "l0: 0.020727, l1: 0.022068, l2: 0.030845, l3: 0.047732, l4: 0.093677, l5: 0.203945, l6: 0.529343\n",
      "\n",
      "[epoch: 388/400, batch: 32/1000, ite: 51255] train loss: 1.1132, accuracy: 94.1695%, tar: 0.0198 \n",
      "l0: 0.014225, l1: 0.015711, l2: 0.024376, l3: 0.036862, l4: 0.065231, l5: 0.127703, l6: 0.301030\n",
      "\n",
      "[epoch: 388/400, batch: 40/1000, ite: 51256] train loss: 1.1130, accuracy: 96.4226%, tar: 0.0198 \n",
      "l0: 0.020509, l1: 0.023189, l2: 0.033733, l3: 0.053474, l4: 0.099897, l5: 0.192338, l6: 0.414630\n",
      "\n",
      "[epoch: 388/400, batch: 48/1000, ite: 51257] train loss: 1.1132, accuracy: 95.5034%, tar: 0.0198 \n",
      "l0: 0.022067, l1: 0.023471, l2: 0.031486, l3: 0.048728, l4: 0.086547, l5: 0.169870, l6: 0.409199\n",
      "\n",
      "[epoch: 388/400, batch: 56/1000, ite: 51258] train loss: 1.1132, accuracy: 94.3346%, tar: 0.0198 \n",
      "l0: 0.016420, l1: 0.018040, l2: 0.024629, l3: 0.036881, l4: 0.066737, l5: 0.152821, l6: 0.310255\n",
      "\n",
      "[epoch: 388/400, batch: 64/1000, ite: 51259] train loss: 1.1131, accuracy: 95.9832%, tar: 0.0198 \n",
      "l0: 0.021209, l1: 0.022943, l2: 0.033247, l3: 0.052964, l4: 0.097516, l5: 0.197071, l6: 0.444645\n",
      "\n",
      "[epoch: 388/400, batch: 72/1000, ite: 51260] train loss: 1.1133, accuracy: 94.3641%, tar: 0.0198 \n",
      "l0: 0.018887, l1: 0.020344, l2: 0.030695, l3: 0.048220, l4: 0.081109, l5: 0.155057, l6: 0.345591\n",
      "\n",
      "[epoch: 388/400, batch: 80/1000, ite: 51261] train loss: 1.1132, accuracy: 95.0537%, tar: 0.0198 \n",
      "l0: 0.015775, l1: 0.016995, l2: 0.022496, l3: 0.034477, l4: 0.064124, l5: 0.155140, l6: 0.325052\n",
      "\n",
      "[epoch: 388/400, batch: 88/1000, ite: 51262] train loss: 1.1131, accuracy: 95.1282%, tar: 0.0198 \n",
      "l0: 0.027811, l1: 0.029946, l2: 0.041509, l3: 0.067089, l4: 0.137402, l5: 0.250096, l6: 0.517038\n",
      "\n",
      "[epoch: 388/400, batch: 96/1000, ite: 51263] train loss: 1.1135, accuracy: 93.4266%, tar: 0.0198 \n",
      "l0: 0.014966, l1: 0.016337, l2: 0.023247, l3: 0.042248, l4: 0.124523, l5: 0.188931, l6: 0.362439\n",
      "\n",
      "[epoch: 388/400, batch: 104/1000, ite: 51264] train loss: 1.1135, accuracy: 95.9319%, tar: 0.0198 \n",
      "l0: 0.016784, l1: 0.018545, l2: 0.024887, l3: 0.042196, l4: 0.088644, l5: 0.172681, l6: 0.335343\n",
      "\n",
      "[epoch: 388/400, batch: 112/1000, ite: 51265] train loss: 1.1134, accuracy: 96.7137%, tar: 0.0198 \n",
      "l0: 0.023075, l1: 0.024414, l2: 0.031797, l3: 0.047266, l4: 0.088753, l5: 0.175653, l6: 0.397357\n",
      "\n",
      "[epoch: 388/400, batch: 120/1000, ite: 51266] train loss: 1.1135, accuracy: 94.1220%, tar: 0.0198 \n",
      "l0: 0.017118, l1: 0.018763, l2: 0.026874, l3: 0.043767, l4: 0.085878, l5: 0.181819, l6: 0.346088\n",
      "\n",
      "[epoch: 388/400, batch: 128/1000, ite: 51267] train loss: 1.1134, accuracy: 95.4854%, tar: 0.0198 \n",
      "l0: 0.018732, l1: 0.020234, l2: 0.029206, l3: 0.043553, l4: 0.085041, l5: 0.169355, l6: 0.325968\n",
      "\n",
      "[epoch: 388/400, batch: 136/1000, ite: 51268] train loss: 1.1134, accuracy: 95.3629%, tar: 0.0198 \n",
      "l0: 0.023730, l1: 0.025816, l2: 0.038672, l3: 0.062890, l4: 0.120065, l5: 0.231763, l6: 0.457531\n",
      "\n",
      "[epoch: 388/400, batch: 144/1000, ite: 51269] train loss: 1.1136, accuracy: 93.5954%, tar: 0.0198 \n",
      "l0: 0.019605, l1: 0.020957, l2: 0.027602, l3: 0.043390, l4: 0.080275, l5: 0.159567, l6: 0.372533\n",
      "\n",
      "[epoch: 388/400, batch: 152/1000, ite: 51270] train loss: 1.1136, accuracy: 95.3249%, tar: 0.0198 \n",
      "l0: 0.021988, l1: 0.023398, l2: 0.032269, l3: 0.049383, l4: 0.101709, l5: 0.225342, l6: 0.559720\n",
      "\n",
      "[epoch: 388/400, batch: 160/1000, ite: 51271] train loss: 1.1140, accuracy: 92.6112%, tar: 0.0198 \n",
      "l0: 0.018141, l1: 0.019039, l2: 0.026224, l3: 0.041398, l4: 0.072539, l5: 0.144199, l6: 0.335208\n",
      "\n",
      "[epoch: 388/400, batch: 168/1000, ite: 51272] train loss: 1.1139, accuracy: 95.1069%, tar: 0.0198 \n",
      "l0: 0.017776, l1: 0.019537, l2: 0.028606, l3: 0.046661, l4: 0.093024, l5: 0.188609, l6: 0.432973\n",
      "\n",
      "[epoch: 388/400, batch: 176/1000, ite: 51273] train loss: 1.1140, accuracy: 94.7413%, tar: 0.0198 \n",
      "l0: 0.019167, l1: 0.019970, l2: 0.025164, l3: 0.038202, l4: 0.070450, l5: 0.135721, l6: 0.277193\n",
      "\n",
      "[epoch: 388/400, batch: 184/1000, ite: 51274] train loss: 1.1138, accuracy: 95.9861%, tar: 0.0198 \n",
      "l0: 0.015911, l1: 0.016892, l2: 0.023200, l3: 0.039632, l4: 0.081512, l5: 0.155825, l6: 0.294520\n",
      "\n",
      "[epoch: 388/400, batch: 192/1000, ite: 51275] train loss: 1.1136, accuracy: 96.4838%, tar: 0.0198 \n",
      "l0: 0.023520, l1: 0.026717, l2: 0.037506, l3: 0.059906, l4: 0.128738, l5: 0.317463, l6: 0.623066\n",
      "\n",
      "[epoch: 388/400, batch: 200/1000, ite: 51276] train loss: 1.1142, accuracy: 94.1840%, tar: 0.0198 \n",
      "l0: 0.023333, l1: 0.025084, l2: 0.035505, l3: 0.050857, l4: 0.097201, l5: 0.201435, l6: 0.428812\n",
      "\n",
      "[epoch: 388/400, batch: 208/1000, ite: 51277] train loss: 1.1144, accuracy: 94.0917%, tar: 0.0198 \n",
      "l0: 0.020380, l1: 0.021836, l2: 0.030098, l3: 0.047448, l4: 0.101155, l5: 0.222903, l6: 0.455988\n",
      "\n",
      "[epoch: 388/400, batch: 216/1000, ite: 51278] train loss: 1.1146, accuracy: 94.1982%, tar: 0.0198 \n",
      "l0: 0.021549, l1: 0.022706, l2: 0.029832, l3: 0.046342, l4: 0.093160, l5: 0.225687, l6: 0.436063\n",
      "\n",
      "[epoch: 388/400, batch: 224/1000, ite: 51279] train loss: 1.1147, accuracy: 94.1830%, tar: 0.0198 \n",
      "l0: 0.018927, l1: 0.019947, l2: 0.027155, l3: 0.040279, l4: 0.064162, l5: 0.131610, l6: 0.292772\n",
      "\n",
      "[epoch: 388/400, batch: 232/1000, ite: 51280] train loss: 1.1145, accuracy: 95.7994%, tar: 0.0198 \n",
      "l0: 0.015640, l1: 0.016952, l2: 0.024789, l3: 0.035754, l4: 0.063968, l5: 0.132982, l6: 0.294141\n",
      "\n",
      "[epoch: 388/400, batch: 240/1000, ite: 51281] train loss: 1.1143, accuracy: 96.5874%, tar: 0.0198 \n",
      "l0: 0.022909, l1: 0.024375, l2: 0.033456, l3: 0.049917, l4: 0.089856, l5: 0.183016, l6: 0.358240\n",
      "\n",
      "[epoch: 388/400, batch: 248/1000, ite: 51282] train loss: 1.1144, accuracy: 94.5927%, tar: 0.0198 \n",
      "l0: 0.016787, l1: 0.018218, l2: 0.025336, l3: 0.039084, l4: 0.066274, l5: 0.116474, l6: 0.265552\n",
      "\n",
      "[epoch: 388/400, batch: 256/1000, ite: 51283] train loss: 1.1141, accuracy: 96.1849%, tar: 0.0198 \n",
      "l0: 0.019746, l1: 0.021015, l2: 0.028639, l3: 0.041586, l4: 0.081270, l5: 0.170747, l6: 0.345348\n",
      "\n",
      "[epoch: 388/400, batch: 264/1000, ite: 51284] train loss: 1.1141, accuracy: 95.1860%, tar: 0.0198 \n",
      "l0: 0.019369, l1: 0.020613, l2: 0.026624, l3: 0.040155, l4: 0.062873, l5: 0.122132, l6: 0.302786\n",
      "\n",
      "[epoch: 388/400, batch: 272/1000, ite: 51285] train loss: 1.1139, accuracy: 95.3848%, tar: 0.0198 \n",
      "l0: 0.020071, l1: 0.021450, l2: 0.029387, l3: 0.050393, l4: 0.100671, l5: 0.182088, l6: 0.306435\n",
      "\n",
      "[epoch: 388/400, batch: 280/1000, ite: 51286] train loss: 1.1138, accuracy: 95.8925%, tar: 0.0198 \n",
      "l0: 0.018371, l1: 0.019359, l2: 0.027316, l3: 0.041188, l4: 0.072035, l5: 0.136347, l6: 0.310619\n",
      "\n",
      "[epoch: 388/400, batch: 288/1000, ite: 51287] train loss: 1.1137, accuracy: 95.4776%, tar: 0.0198 \n",
      "l0: 0.020831, l1: 0.022010, l2: 0.029180, l3: 0.042717, l4: 0.080100, l5: 0.145643, l6: 0.333900\n",
      "\n",
      "[epoch: 388/400, batch: 296/1000, ite: 51288] train loss: 1.1136, accuracy: 95.1940%, tar: 0.0198 \n",
      "l0: 0.017294, l1: 0.018768, l2: 0.025781, l3: 0.037820, l4: 0.065564, l5: 0.143370, l6: 0.272937\n",
      "\n",
      "[epoch: 388/400, batch: 304/1000, ite: 51289] train loss: 1.1134, accuracy: 95.9967%, tar: 0.0198 \n",
      "l0: 0.022955, l1: 0.024220, l2: 0.035138, l3: 0.051263, l4: 0.089489, l5: 0.189048, l6: 0.404920\n",
      "\n",
      "[epoch: 388/400, batch: 312/1000, ite: 51290] train loss: 1.1135, accuracy: 94.4374%, tar: 0.0198 \n",
      "l0: 0.019097, l1: 0.020812, l2: 0.030654, l3: 0.046926, l4: 0.084561, l5: 0.211606, l6: 0.412485\n",
      "\n",
      "[epoch: 388/400, batch: 320/1000, ite: 51291] train loss: 1.1136, accuracy: 94.8338%, tar: 0.0198 \n",
      "l0: 0.019882, l1: 0.020785, l2: 0.026380, l3: 0.037262, l4: 0.064933, l5: 0.127737, l6: 0.264215\n",
      "\n",
      "[epoch: 388/400, batch: 328/1000, ite: 51292] train loss: 1.1134, accuracy: 95.9382%, tar: 0.0198 \n",
      "l0: 0.021650, l1: 0.023537, l2: 0.032754, l3: 0.049938, l4: 0.104436, l5: 0.210117, l6: 0.455682\n",
      "\n",
      "[epoch: 388/400, batch: 336/1000, ite: 51293] train loss: 1.1136, accuracy: 94.4866%, tar: 0.0198 \n",
      "l0: 0.019238, l1: 0.020214, l2: 0.028148, l3: 0.040001, l4: 0.071469, l5: 0.166266, l6: 0.416329\n",
      "\n",
      "[epoch: 388/400, batch: 344/1000, ite: 51294] train loss: 1.1136, accuracy: 94.9288%, tar: 0.0198 \n",
      "l0: 0.018592, l1: 0.019337, l2: 0.025447, l3: 0.036883, l4: 0.066397, l5: 0.144212, l6: 0.352743\n",
      "\n",
      "[epoch: 388/400, batch: 352/1000, ite: 51295] train loss: 1.1135, accuracy: 94.4406%, tar: 0.0198 \n",
      "l0: 0.020553, l1: 0.022093, l2: 0.032060, l3: 0.052619, l4: 0.115677, l5: 0.215221, l6: 0.424275\n",
      "\n",
      "[epoch: 388/400, batch: 360/1000, ite: 51296] train loss: 1.1137, accuracy: 94.3292%, tar: 0.0198 \n",
      "l0: 0.013847, l1: 0.015320, l2: 0.022916, l3: 0.036840, l4: 0.070127, l5: 0.130184, l6: 0.270010\n",
      "\n",
      "[epoch: 388/400, batch: 368/1000, ite: 51297] train loss: 1.1135, accuracy: 96.3114%, tar: 0.0198 \n",
      "l0: 0.018039, l1: 0.018735, l2: 0.025646, l3: 0.036705, l4: 0.061846, l5: 0.118727, l6: 0.336527\n",
      "\n",
      "[epoch: 388/400, batch: 376/1000, ite: 51298] train loss: 1.1134, accuracy: 95.3523%, tar: 0.0198 \n",
      "l0: 0.019645, l1: 0.021146, l2: 0.030235, l3: 0.050909, l4: 0.110452, l5: 0.208638, l6: 0.390879\n",
      "\n",
      "[epoch: 388/400, batch: 384/1000, ite: 51299] train loss: 1.1134, accuracy: 94.6511%, tar: 0.0198 \n",
      "l0: 0.013707, l1: 0.014802, l2: 0.021596, l3: 0.033044, l4: 0.073580, l5: 0.127286, l6: 0.269400\n",
      "\n",
      "[epoch: 388/400, batch: 392/1000, ite: 51300] train loss: 1.1132, accuracy: 96.7386%, tar: 0.0198 \n",
      "l0: 0.018326, l1: 0.019710, l2: 0.026525, l3: 0.041242, l4: 0.063995, l5: 0.143885, l6: 0.321698\n",
      "\n",
      "[epoch: 388/400, batch: 400/1000, ite: 51301] train loss: 1.1131, accuracy: 95.4336%, tar: 0.0198 \n",
      "l0: 0.018516, l1: 0.019312, l2: 0.025347, l3: 0.039379, l4: 0.067104, l5: 0.142939, l6: 0.308090\n",
      "\n",
      "[epoch: 388/400, batch: 408/1000, ite: 51302] train loss: 1.1130, accuracy: 95.4710%, tar: 0.0198 \n",
      "l0: 0.019043, l1: 0.020837, l2: 0.029473, l3: 0.046863, l4: 0.089247, l5: 0.221646, l6: 0.395968\n",
      "\n",
      "[epoch: 388/400, batch: 416/1000, ite: 51303] train loss: 1.1131, accuracy: 95.4972%, tar: 0.0198 \n",
      "l0: 0.020455, l1: 0.022353, l2: 0.030861, l3: 0.048424, l4: 0.095752, l5: 0.205259, l6: 0.414363\n",
      "\n",
      "[epoch: 388/400, batch: 424/1000, ite: 51304] train loss: 1.1132, accuracy: 94.4851%, tar: 0.0198 \n",
      "l0: 0.020217, l1: 0.021406, l2: 0.029419, l3: 0.045999, l4: 0.087992, l5: 0.177347, l6: 0.368344\n",
      "\n",
      "[epoch: 388/400, batch: 432/1000, ite: 51305] train loss: 1.1132, accuracy: 94.6966%, tar: 0.0198 \n",
      "l0: 0.021500, l1: 0.022573, l2: 0.030879, l3: 0.046339, l4: 0.081844, l5: 0.164279, l6: 0.385274\n",
      "\n",
      "[epoch: 388/400, batch: 440/1000, ite: 51306] train loss: 1.1132, accuracy: 95.0182%, tar: 0.0198 \n",
      "l0: 0.024886, l1: 0.026780, l2: 0.037471, l3: 0.054773, l4: 0.097978, l5: 0.203786, l6: 0.436142\n",
      "\n",
      "[epoch: 388/400, batch: 448/1000, ite: 51307] train loss: 1.1134, accuracy: 93.8484%, tar: 0.0198 \n",
      "l0: 0.020865, l1: 0.021767, l2: 0.031064, l3: 0.047913, l4: 0.090018, l5: 0.167895, l6: 0.320818\n",
      "\n",
      "[epoch: 388/400, batch: 456/1000, ite: 51308] train loss: 1.1133, accuracy: 94.7957%, tar: 0.0198 \n",
      "l0: 0.017578, l1: 0.019025, l2: 0.027728, l3: 0.044741, l4: 0.106694, l5: 0.218165, l6: 0.380130\n",
      "\n",
      "[epoch: 388/400, batch: 464/1000, ite: 51309] train loss: 1.1134, accuracy: 95.9480%, tar: 0.0198 \n",
      "l0: 0.021626, l1: 0.022222, l2: 0.032016, l3: 0.047876, l4: 0.088102, l5: 0.199889, l6: 0.403256\n",
      "\n",
      "[epoch: 388/400, batch: 472/1000, ite: 51310] train loss: 1.1134, accuracy: 93.9696%, tar: 0.0198 \n",
      "l0: 0.013975, l1: 0.015273, l2: 0.021633, l3: 0.032420, l4: 0.057600, l5: 0.112593, l6: 0.217892\n",
      "\n",
      "[epoch: 388/400, batch: 480/1000, ite: 51311] train loss: 1.1131, accuracy: 97.0249%, tar: 0.0198 \n",
      "l0: 0.017964, l1: 0.019088, l2: 0.025763, l3: 0.038789, l4: 0.065025, l5: 0.108699, l6: 0.278026\n",
      "\n",
      "[epoch: 388/400, batch: 488/1000, ite: 51312] train loss: 1.1129, accuracy: 95.7720%, tar: 0.0198 \n",
      "l0: 0.016103, l1: 0.016986, l2: 0.023442, l3: 0.035795, l4: 0.074902, l5: 0.152653, l6: 0.319027\n",
      "\n",
      "[epoch: 388/400, batch: 496/1000, ite: 51313] train loss: 1.1128, accuracy: 95.9992%, tar: 0.0198 \n",
      "l0: 0.023598, l1: 0.024932, l2: 0.031111, l3: 0.043644, l4: 0.084551, l5: 0.166376, l6: 0.344478\n",
      "\n",
      "[epoch: 388/400, batch: 504/1000, ite: 51314] train loss: 1.1128, accuracy: 94.9945%, tar: 0.0198 \n",
      "l0: 0.013472, l1: 0.014608, l2: 0.023375, l3: 0.036458, l4: 0.065348, l5: 0.119225, l6: 0.305590\n",
      "\n",
      "[epoch: 388/400, batch: 512/1000, ite: 51315] train loss: 1.1126, accuracy: 96.1536%, tar: 0.0198 \n",
      "l0: 0.020531, l1: 0.021865, l2: 0.028850, l3: 0.044494, l4: 0.083699, l5: 0.164486, l6: 0.287803\n",
      "\n",
      "[epoch: 388/400, batch: 520/1000, ite: 51316] train loss: 1.1125, accuracy: 95.6227%, tar: 0.0198 \n",
      "l0: 0.026819, l1: 0.028952, l2: 0.040547, l3: 0.059114, l4: 0.117588, l5: 0.281421, l6: 0.554288\n",
      "\n",
      "[epoch: 388/400, batch: 528/1000, ite: 51317] train loss: 1.1129, accuracy: 92.3803%, tar: 0.0198 \n",
      "l0: 0.022424, l1: 0.023745, l2: 0.033934, l3: 0.051234, l4: 0.094586, l5: 0.203621, l6: 0.369106\n",
      "\n",
      "[epoch: 388/400, batch: 536/1000, ite: 51318] train loss: 1.1129, accuracy: 94.9197%, tar: 0.0198 \n",
      "l0: 0.021093, l1: 0.022043, l2: 0.029156, l3: 0.043508, l4: 0.082382, l5: 0.161546, l6: 0.353183\n",
      "\n",
      "[epoch: 388/400, batch: 544/1000, ite: 51319] train loss: 1.1129, accuracy: 95.1262%, tar: 0.0198 \n",
      "l0: 0.022471, l1: 0.024330, l2: 0.033236, l3: 0.049965, l4: 0.089211, l5: 0.177519, l6: 0.349814\n",
      "\n",
      "[epoch: 388/400, batch: 552/1000, ite: 51320] train loss: 1.1129, accuracy: 95.1276%, tar: 0.0198 \n",
      "l0: 0.014753, l1: 0.017099, l2: 0.027801, l3: 0.047592, l4: 0.101510, l5: 0.230722, l6: 0.474279\n",
      "\n",
      "[epoch: 388/400, batch: 560/1000, ite: 51321] train loss: 1.1131, accuracy: 95.7708%, tar: 0.0198 \n",
      "l0: 0.011911, l1: 0.013381, l2: 0.018919, l3: 0.030491, l4: 0.053633, l5: 0.100621, l6: 0.226686\n",
      "\n",
      "[epoch: 388/400, batch: 568/1000, ite: 51322] train loss: 1.1128, accuracy: 96.7518%, tar: 0.0198 \n",
      "l0: 0.017462, l1: 0.019059, l2: 0.026188, l3: 0.039409, l4: 0.077236, l5: 0.165887, l6: 0.342668\n",
      "\n",
      "[epoch: 388/400, batch: 576/1000, ite: 51323] train loss: 1.1127, accuracy: 95.6368%, tar: 0.0198 \n",
      "l0: 0.020288, l1: 0.021431, l2: 0.027662, l3: 0.046399, l4: 0.115574, l5: 0.229576, l6: 0.390131\n",
      "\n",
      "[epoch: 388/400, batch: 584/1000, ite: 51324] train loss: 1.1128, accuracy: 93.8490%, tar: 0.0198 \n",
      "l0: 0.018208, l1: 0.019125, l2: 0.026808, l3: 0.037953, l4: 0.064898, l5: 0.113370, l6: 0.271470\n",
      "\n",
      "[epoch: 388/400, batch: 592/1000, ite: 51325] train loss: 1.1126, accuracy: 96.1379%, tar: 0.0198 \n",
      "l0: 0.022703, l1: 0.024787, l2: 0.033523, l3: 0.052100, l4: 0.091004, l5: 0.191147, l6: 0.374505\n",
      "\n",
      "[epoch: 388/400, batch: 600/1000, ite: 51326] train loss: 1.1126, accuracy: 94.6402%, tar: 0.0198 \n",
      "l0: 0.015446, l1: 0.016713, l2: 0.024431, l3: 0.040917, l4: 0.090611, l5: 0.170247, l6: 0.291741\n",
      "\n",
      "[epoch: 388/400, batch: 608/1000, ite: 51327] train loss: 1.1125, accuracy: 95.9775%, tar: 0.0198 \n",
      "l0: 0.017934, l1: 0.019969, l2: 0.029272, l3: 0.054093, l4: 0.130183, l5: 0.246271, l6: 0.568812\n",
      "\n",
      "[epoch: 388/400, batch: 616/1000, ite: 51328] train loss: 1.1129, accuracy: 94.4114%, tar: 0.0198 \n",
      "l0: 0.017107, l1: 0.017996, l2: 0.024595, l3: 0.037567, l4: 0.069067, l5: 0.131470, l6: 0.291112\n",
      "\n",
      "[epoch: 388/400, batch: 624/1000, ite: 51329] train loss: 1.1127, accuracy: 95.9718%, tar: 0.0198 \n",
      "l0: 0.018075, l1: 0.018925, l2: 0.025341, l3: 0.038439, l4: 0.077051, l5: 0.157380, l6: 0.339437\n",
      "\n",
      "[epoch: 388/400, batch: 632/1000, ite: 51330] train loss: 1.1126, accuracy: 95.6297%, tar: 0.0198 \n",
      "l0: 0.022239, l1: 0.024541, l2: 0.036482, l3: 0.053232, l4: 0.107430, l5: 0.248180, l6: 0.524212\n",
      "\n",
      "[epoch: 388/400, batch: 640/1000, ite: 51331] train loss: 1.1130, accuracy: 93.1583%, tar: 0.0198 \n",
      "l0: 0.016911, l1: 0.018173, l2: 0.025422, l3: 0.040866, l4: 0.086205, l5: 0.160299, l6: 0.265805\n",
      "\n",
      "[epoch: 388/400, batch: 648/1000, ite: 51332] train loss: 1.1128, accuracy: 95.8527%, tar: 0.0198 \n",
      "l0: 0.019581, l1: 0.020999, l2: 0.028744, l3: 0.047254, l4: 0.092298, l5: 0.181829, l6: 0.407923\n",
      "\n",
      "[epoch: 388/400, batch: 656/1000, ite: 51333] train loss: 1.1129, accuracy: 95.0175%, tar: 0.0198 \n",
      "l0: 0.018083, l1: 0.019677, l2: 0.027587, l3: 0.045811, l4: 0.091005, l5: 0.218524, l6: 0.477912\n",
      "\n",
      "[epoch: 388/400, batch: 664/1000, ite: 51334] train loss: 1.1131, accuracy: 94.5111%, tar: 0.0198 \n",
      "l0: 0.018300, l1: 0.019343, l2: 0.027141, l3: 0.042983, l4: 0.110184, l5: 0.193159, l6: 0.363994\n",
      "\n",
      "[epoch: 388/400, batch: 672/1000, ite: 51335] train loss: 1.1131, accuracy: 94.7439%, tar: 0.0198 \n",
      "l0: 0.026962, l1: 0.028144, l2: 0.036813, l3: 0.058725, l4: 0.103987, l5: 0.190325, l6: 0.439532\n",
      "\n",
      "[epoch: 388/400, batch: 680/1000, ite: 51336] train loss: 1.1133, accuracy: 93.8932%, tar: 0.0198 \n",
      "l0: 0.022082, l1: 0.022733, l2: 0.031193, l3: 0.041968, l4: 0.060947, l5: 0.110961, l6: 0.257246\n",
      "\n",
      "[epoch: 388/400, batch: 688/1000, ite: 51337] train loss: 1.1130, accuracy: 95.9263%, tar: 0.0198 \n",
      "l0: 0.017196, l1: 0.018655, l2: 0.025069, l3: 0.038730, l4: 0.072674, l5: 0.141642, l6: 0.301237\n",
      "\n",
      "[epoch: 388/400, batch: 696/1000, ite: 51338] train loss: 1.1129, accuracy: 95.1766%, tar: 0.0198 \n",
      "l0: 0.028770, l1: 0.031245, l2: 0.042222, l3: 0.063793, l4: 0.123251, l5: 0.272496, l6: 0.506433\n",
      "\n",
      "[epoch: 388/400, batch: 704/1000, ite: 51339] train loss: 1.1132, accuracy: 93.5061%, tar: 0.0198 \n",
      "l0: 0.019385, l1: 0.020901, l2: 0.031313, l3: 0.056166, l4: 0.107015, l5: 0.208217, l6: 0.406422\n",
      "\n",
      "[epoch: 388/400, batch: 712/1000, ite: 51340] train loss: 1.1133, accuracy: 95.1061%, tar: 0.0198 \n",
      "l0: 0.020668, l1: 0.021528, l2: 0.029026, l3: 0.041993, l4: 0.074383, l5: 0.131262, l6: 0.296253\n",
      "\n",
      "[epoch: 388/400, batch: 720/1000, ite: 51341] train loss: 1.1132, accuracy: 95.1847%, tar: 0.0198 \n",
      "l0: 0.017219, l1: 0.019346, l2: 0.028646, l3: 0.045316, l4: 0.087495, l5: 0.221609, l6: 0.455022\n",
      "\n",
      "[epoch: 388/400, batch: 728/1000, ite: 51342] train loss: 1.1134, accuracy: 94.6406%, tar: 0.0198 \n",
      "l0: 0.018157, l1: 0.019626, l2: 0.029651, l3: 0.045897, l4: 0.086460, l5: 0.156942, l6: 0.295747\n",
      "\n",
      "[epoch: 388/400, batch: 736/1000, ite: 51343] train loss: 1.1132, accuracy: 95.5375%, tar: 0.0198 \n",
      "l0: 0.020331, l1: 0.021143, l2: 0.027653, l3: 0.042142, l4: 0.072063, l5: 0.141256, l6: 0.325683\n",
      "\n",
      "[epoch: 388/400, batch: 744/1000, ite: 51344] train loss: 1.1131, accuracy: 95.3181%, tar: 0.0198 \n",
      "l0: 0.014815, l1: 0.016599, l2: 0.023497, l3: 0.041728, l4: 0.075042, l5: 0.159614, l6: 0.311324\n",
      "\n",
      "[epoch: 388/400, batch: 752/1000, ite: 51345] train loss: 1.1130, accuracy: 95.9170%, tar: 0.0198 \n",
      "l0: 0.018622, l1: 0.020159, l2: 0.026660, l3: 0.039859, l4: 0.082024, l5: 0.163987, l6: 0.349254\n",
      "\n",
      "[epoch: 388/400, batch: 760/1000, ite: 51346] train loss: 1.1130, accuracy: 95.2991%, tar: 0.0198 \n",
      "l0: 0.022561, l1: 0.023495, l2: 0.028757, l3: 0.039987, l4: 0.072124, l5: 0.151763, l6: 0.342089\n",
      "\n",
      "[epoch: 388/400, batch: 768/1000, ite: 51347] train loss: 1.1129, accuracy: 94.9741%, tar: 0.0198 \n",
      "l0: 0.026940, l1: 0.030038, l2: 0.041446, l3: 0.066855, l4: 0.139520, l5: 0.277288, l6: 0.489150\n",
      "\n",
      "[epoch: 388/400, batch: 776/1000, ite: 51348] train loss: 1.1132, accuracy: 93.0550%, tar: 0.0198 \n",
      "l0: 0.021948, l1: 0.023435, l2: 0.031083, l3: 0.043962, l4: 0.071928, l5: 0.126727, l6: 0.313680\n",
      "\n",
      "[epoch: 388/400, batch: 784/1000, ite: 51349] train loss: 1.1131, accuracy: 95.8703%, tar: 0.0198 \n",
      "l0: 0.017887, l1: 0.019137, l2: 0.026083, l3: 0.047535, l4: 0.101720, l5: 0.227065, l6: 0.442545\n",
      "\n",
      "[epoch: 388/400, batch: 792/1000, ite: 51350] train loss: 1.1133, accuracy: 93.9445%, tar: 0.0198 \n",
      "l0: 0.019463, l1: 0.020296, l2: 0.028670, l3: 0.043152, l4: 0.072286, l5: 0.132341, l6: 0.276434\n",
      "\n",
      "[epoch: 388/400, batch: 800/1000, ite: 51351] train loss: 1.1131, accuracy: 95.5779%, tar: 0.0198 \n",
      "l0: 0.022037, l1: 0.023511, l2: 0.030125, l3: 0.044679, l4: 0.090088, l5: 0.202672, l6: 0.433661\n",
      "\n",
      "[epoch: 388/400, batch: 808/1000, ite: 51352] train loss: 1.1132, accuracy: 94.2009%, tar: 0.0198 \n",
      "l0: 0.022576, l1: 0.023533, l2: 0.030091, l3: 0.045123, l4: 0.082894, l5: 0.158419, l6: 0.401563\n",
      "\n",
      "[epoch: 388/400, batch: 816/1000, ite: 51353] train loss: 1.1133, accuracy: 94.6490%, tar: 0.0198 \n",
      "l0: 0.016750, l1: 0.018184, l2: 0.026510, l3: 0.038721, l4: 0.068631, l5: 0.129496, l6: 0.290598\n",
      "\n",
      "[epoch: 388/400, batch: 824/1000, ite: 51354] train loss: 1.1131, accuracy: 95.5708%, tar: 0.0198 \n",
      "l0: 0.022349, l1: 0.022847, l2: 0.029239, l3: 0.041269, l4: 0.073852, l5: 0.130060, l6: 0.377445\n",
      "\n",
      "[epoch: 388/400, batch: 832/1000, ite: 51355] train loss: 1.1131, accuracy: 94.8132%, tar: 0.0198 \n",
      "l0: 0.017293, l1: 0.018539, l2: 0.025841, l3: 0.041704, l4: 0.081982, l5: 0.164583, l6: 0.364088\n",
      "\n",
      "[epoch: 388/400, batch: 840/1000, ite: 51356] train loss: 1.1130, accuracy: 95.3991%, tar: 0.0198 \n",
      "l0: 0.014227, l1: 0.015250, l2: 0.021978, l3: 0.036788, l4: 0.065779, l5: 0.134388, l6: 0.272920\n",
      "\n",
      "[epoch: 388/400, batch: 848/1000, ite: 51357] train loss: 1.1128, accuracy: 96.1114%, tar: 0.0198 \n",
      "l0: 0.023026, l1: 0.024000, l2: 0.029147, l3: 0.041433, l4: 0.070454, l5: 0.142387, l6: 0.344140\n",
      "\n",
      "[epoch: 388/400, batch: 856/1000, ite: 51358] train loss: 1.1128, accuracy: 95.1490%, tar: 0.0198 \n",
      "l0: 0.021476, l1: 0.022445, l2: 0.029436, l3: 0.044806, l4: 0.089028, l5: 0.210875, l6: 0.405835\n",
      "\n",
      "[epoch: 388/400, batch: 864/1000, ite: 51359] train loss: 1.1129, accuracy: 94.4408%, tar: 0.0198 \n",
      "l0: 0.018501, l1: 0.019305, l2: 0.027399, l3: 0.041437, l4: 0.069916, l5: 0.163225, l6: 0.327748\n",
      "\n",
      "[epoch: 388/400, batch: 872/1000, ite: 51360] train loss: 1.1128, accuracy: 95.4119%, tar: 0.0198 \n",
      "l0: 0.017103, l1: 0.018149, l2: 0.024902, l3: 0.040300, l4: 0.077980, l5: 0.161510, l6: 0.283387\n",
      "\n",
      "[epoch: 388/400, batch: 880/1000, ite: 51361] train loss: 1.1126, accuracy: 95.9431%, tar: 0.0198 \n",
      "l0: 0.027089, l1: 0.029267, l2: 0.040553, l3: 0.062898, l4: 0.107740, l5: 0.204683, l6: 0.372285\n",
      "\n",
      "[epoch: 388/400, batch: 888/1000, ite: 51362] train loss: 1.1127, accuracy: 94.5821%, tar: 0.0198 \n",
      "l0: 0.017015, l1: 0.018470, l2: 0.026376, l3: 0.043220, l4: 0.086917, l5: 0.173433, l6: 0.323158\n",
      "\n",
      "[epoch: 388/400, batch: 896/1000, ite: 51363] train loss: 1.1126, accuracy: 95.4093%, tar: 0.0198 \n",
      "l0: 0.021680, l1: 0.023016, l2: 0.031906, l3: 0.047581, l4: 0.089153, l5: 0.182528, l6: 0.439762\n",
      "\n",
      "[epoch: 388/400, batch: 904/1000, ite: 51364] train loss: 1.1128, accuracy: 94.0215%, tar: 0.0198 \n",
      "l0: 0.026251, l1: 0.028104, l2: 0.035145, l3: 0.052187, l4: 0.093424, l5: 0.196849, l6: 0.386301\n",
      "\n",
      "[epoch: 388/400, batch: 912/1000, ite: 51365] train loss: 1.1128, accuracy: 94.2986%, tar: 0.0198 \n",
      "l0: 0.016143, l1: 0.017934, l2: 0.028058, l3: 0.048698, l4: 0.103020, l5: 0.210363, l6: 0.404338\n",
      "\n",
      "[epoch: 388/400, batch: 920/1000, ite: 51366] train loss: 1.1129, accuracy: 95.3412%, tar: 0.0198 \n",
      "l0: 0.019796, l1: 0.021233, l2: 0.030081, l3: 0.047128, l4: 0.090156, l5: 0.193282, l6: 0.340017\n",
      "\n",
      "[epoch: 388/400, batch: 928/1000, ite: 51367] train loss: 1.1129, accuracy: 95.0756%, tar: 0.0198 \n",
      "l0: 0.019747, l1: 0.020607, l2: 0.025959, l3: 0.037484, l4: 0.064772, l5: 0.133394, l6: 0.295579\n",
      "\n",
      "[epoch: 388/400, batch: 936/1000, ite: 51368] train loss: 1.1127, accuracy: 96.0841%, tar: 0.0198 \n",
      "l0: 0.022038, l1: 0.023403, l2: 0.029266, l3: 0.043316, l4: 0.094016, l5: 0.194793, l6: 0.448236\n",
      "\n",
      "[epoch: 388/400, batch: 944/1000, ite: 51369] train loss: 1.1129, accuracy: 94.0563%, tar: 0.0198 \n",
      "l0: 0.016090, l1: 0.017123, l2: 0.024166, l3: 0.036027, l4: 0.068067, l5: 0.167727, l6: 0.352261\n",
      "\n",
      "[epoch: 388/400, batch: 952/1000, ite: 51370] train loss: 1.1128, accuracy: 95.5258%, tar: 0.0198 \n",
      "l0: 0.025692, l1: 0.027507, l2: 0.038477, l3: 0.059367, l4: 0.114616, l5: 0.219870, l6: 0.412574\n",
      "\n",
      "[epoch: 388/400, batch: 960/1000, ite: 51371] train loss: 1.1130, accuracy: 94.0618%, tar: 0.0198 \n",
      "l0: 0.021140, l1: 0.023578, l2: 0.035421, l3: 0.058313, l4: 0.108236, l5: 0.224825, l6: 0.387503\n",
      "\n",
      "[epoch: 388/400, batch: 968/1000, ite: 51372] train loss: 1.1131, accuracy: 94.9657%, tar: 0.0198 \n",
      "l0: 0.018573, l1: 0.019367, l2: 0.024931, l3: 0.039068, l4: 0.066389, l5: 0.138347, l6: 0.291301\n",
      "\n",
      "[epoch: 388/400, batch: 976/1000, ite: 51373] train loss: 1.1129, accuracy: 95.2781%, tar: 0.0198 \n",
      "l0: 0.017702, l1: 0.018813, l2: 0.024859, l3: 0.037869, l4: 0.072843, l5: 0.142890, l6: 0.316791\n",
      "\n",
      "[epoch: 388/400, batch: 984/1000, ite: 51374] train loss: 1.1128, accuracy: 95.6052%, tar: 0.0198 \n",
      "l0: 0.022340, l1: 0.023550, l2: 0.030742, l3: 0.047035, l4: 0.077355, l5: 0.173042, l6: 0.387906\n",
      "\n",
      "[epoch: 388/400, batch: 992/1000, ite: 51375] train loss: 1.1128, accuracy: 94.5197%, tar: 0.0198 \n",
      "l0: 0.021087, l1: 0.022327, l2: 0.031225, l3: 0.047106, l4: 0.084186, l5: 0.189603, l6: 0.373159\n",
      "\n",
      "[epoch: 388/400, batch: 1000/1000, ite: 51376] train loss: 1.1128, accuracy: 95.3374%, tar: 0.0198 \n",
      "l0: 0.015354, l1: 0.016919, l2: 0.024129, l3: 0.041338, l4: 0.089881, l5: 0.161457, l6: 0.346640\n",
      "\n",
      "[epoch: 389/400, batch: 8/1000, ite: 51377] train loss: 1.1128, accuracy: 96.0121%, tar: 0.0198 \n",
      "l0: 0.018996, l1: 0.021104, l2: 0.030244, l3: 0.046951, l4: 0.093662, l5: 0.240461, l6: 0.431856\n",
      "\n",
      "[epoch: 389/400, batch: 16/1000, ite: 51378] train loss: 1.1129, accuracy: 94.3324%, tar: 0.0198 \n",
      "l0: 0.017077, l1: 0.017685, l2: 0.021993, l3: 0.031475, l4: 0.050553, l5: 0.090592, l6: 0.195442\n",
      "\n",
      "[epoch: 389/400, batch: 24/1000, ite: 51379] train loss: 1.1126, accuracy: 96.3753%, tar: 0.0198 \n",
      "l0: 0.026691, l1: 0.029391, l2: 0.039578, l3: 0.058201, l4: 0.114411, l5: 0.269872, l6: 0.580076\n",
      "\n",
      "[epoch: 389/400, batch: 32/1000, ite: 51380] train loss: 1.1130, accuracy: 93.5550%, tar: 0.0198 \n",
      "l0: 0.020244, l1: 0.021236, l2: 0.028851, l3: 0.042791, l4: 0.070560, l5: 0.136148, l6: 0.332987\n",
      "\n",
      "[epoch: 389/400, batch: 40/1000, ite: 51381] train loss: 1.1129, accuracy: 94.8889%, tar: 0.0198 \n",
      "l0: 0.019093, l1: 0.020531, l2: 0.028925, l3: 0.044209, l4: 0.082055, l5: 0.152670, l6: 0.307262\n",
      "\n",
      "[epoch: 389/400, batch: 48/1000, ite: 51382] train loss: 1.1128, accuracy: 95.4464%, tar: 0.0198 \n",
      "l0: 0.022892, l1: 0.024341, l2: 0.033142, l3: 0.050943, l4: 0.109300, l5: 0.234881, l6: 0.481133\n",
      "\n",
      "[epoch: 389/400, batch: 56/1000, ite: 51383] train loss: 1.1130, accuracy: 93.4451%, tar: 0.0198 \n",
      "l0: 0.017797, l1: 0.019074, l2: 0.027901, l3: 0.047067, l4: 0.101950, l5: 0.214545, l6: 0.379011\n",
      "\n",
      "[epoch: 389/400, batch: 64/1000, ite: 51384] train loss: 1.1131, accuracy: 95.1366%, tar: 0.0198 \n",
      "l0: 0.024537, l1: 0.026045, l2: 0.034182, l3: 0.048003, l4: 0.094857, l5: 0.209798, l6: 0.537323\n",
      "\n",
      "[epoch: 389/400, batch: 72/1000, ite: 51385] train loss: 1.1134, accuracy: 93.2402%, tar: 0.0198 \n",
      "l0: 0.017250, l1: 0.018380, l2: 0.024177, l3: 0.035990, l4: 0.070252, l5: 0.129527, l6: 0.256223\n",
      "\n",
      "[epoch: 389/400, batch: 80/1000, ite: 51386] train loss: 1.1132, accuracy: 96.1589%, tar: 0.0198 \n",
      "l0: 0.020626, l1: 0.021863, l2: 0.030438, l3: 0.045532, l4: 0.079830, l5: 0.165147, l6: 0.300099\n",
      "\n",
      "[epoch: 389/400, batch: 88/1000, ite: 51387] train loss: 1.1131, accuracy: 95.4521%, tar: 0.0198 \n",
      "l0: 0.018798, l1: 0.021230, l2: 0.031290, l3: 0.056118, l4: 0.117436, l5: 0.263216, l6: 0.475802\n",
      "\n",
      "[epoch: 389/400, batch: 96/1000, ite: 51388] train loss: 1.1133, accuracy: 94.3229%, tar: 0.0198 \n",
      "l0: 0.015232, l1: 0.016256, l2: 0.023264, l3: 0.035209, l4: 0.065701, l5: 0.142791, l6: 0.276616\n",
      "\n",
      "[epoch: 389/400, batch: 104/1000, ite: 51389] train loss: 1.1131, accuracy: 96.1343%, tar: 0.0198 \n",
      "l0: 0.021578, l1: 0.023260, l2: 0.034033, l3: 0.048034, l4: 0.080652, l5: 0.176414, l6: 0.379775\n",
      "\n",
      "[epoch: 389/400, batch: 112/1000, ite: 51390] train loss: 1.1132, accuracy: 95.4780%, tar: 0.0198 \n",
      "l0: 0.024832, l1: 0.025966, l2: 0.033881, l3: 0.050957, l4: 0.097928, l5: 0.182143, l6: 0.361861\n",
      "\n",
      "[epoch: 389/400, batch: 120/1000, ite: 51391] train loss: 1.1132, accuracy: 94.7211%, tar: 0.0198 \n",
      "l0: 0.025006, l1: 0.027285, l2: 0.036134, l3: 0.057439, l4: 0.118696, l5: 0.292908, l6: 0.537877\n",
      "\n",
      "[epoch: 389/400, batch: 128/1000, ite: 51392] train loss: 1.1136, accuracy: 93.7810%, tar: 0.0198 \n",
      "l0: 0.012251, l1: 0.013255, l2: 0.017661, l3: 0.027599, l4: 0.057185, l5: 0.145999, l6: 0.277308\n",
      "\n",
      "[epoch: 389/400, batch: 136/1000, ite: 51393] train loss: 1.1134, accuracy: 96.8099%, tar: 0.0198 \n",
      "l0: 0.021720, l1: 0.023801, l2: 0.032480, l3: 0.051954, l4: 0.090403, l5: 0.169474, l6: 0.345719\n",
      "\n",
      "[epoch: 389/400, batch: 144/1000, ite: 51394] train loss: 1.1133, accuracy: 95.1994%, tar: 0.0198 \n",
      "l0: 0.024694, l1: 0.026849, l2: 0.038671, l3: 0.056788, l4: 0.108610, l5: 0.234426, l6: 0.423759\n",
      "\n",
      "[epoch: 389/400, batch: 152/1000, ite: 51395] train loss: 1.1135, accuracy: 94.4427%, tar: 0.0198 \n",
      "l0: 0.022066, l1: 0.022954, l2: 0.030753, l3: 0.045221, l4: 0.080283, l5: 0.165990, l6: 0.362391\n",
      "\n",
      "[epoch: 389/400, batch: 160/1000, ite: 51396] train loss: 1.1135, accuracy: 95.1112%, tar: 0.0198 \n",
      "l0: 0.019699, l1: 0.020832, l2: 0.027569, l3: 0.039167, l4: 0.064775, l5: 0.126082, l6: 0.246108\n",
      "\n",
      "[epoch: 389/400, batch: 168/1000, ite: 51397] train loss: 1.1133, accuracy: 96.1051%, tar: 0.0198 \n",
      "l0: 0.020509, l1: 0.022743, l2: 0.033844, l3: 0.054730, l4: 0.101346, l5: 0.192811, l6: 0.371960\n",
      "\n",
      "[epoch: 389/400, batch: 176/1000, ite: 51398] train loss: 1.1133, accuracy: 95.1129%, tar: 0.0198 \n",
      "l0: 0.016860, l1: 0.018565, l2: 0.029585, l3: 0.050751, l4: 0.090243, l5: 0.180833, l6: 0.338957\n",
      "\n",
      "[epoch: 389/400, batch: 184/1000, ite: 51399] train loss: 1.1133, accuracy: 96.1838%, tar: 0.0198 \n",
      "l0: 0.015792, l1: 0.016688, l2: 0.021847, l3: 0.033021, l4: 0.059282, l5: 0.139457, l6: 0.311615\n",
      "\n",
      "[epoch: 389/400, batch: 192/1000, ite: 51400] train loss: 1.1131, accuracy: 95.6878%, tar: 0.0198 \n",
      "l0: 0.016668, l1: 0.017804, l2: 0.026176, l3: 0.041897, l4: 0.079301, l5: 0.169907, l6: 0.338798\n",
      "\n",
      "[epoch: 389/400, batch: 200/1000, ite: 51401] train loss: 1.1131, accuracy: 95.9148%, tar: 0.0198 \n",
      "l0: 0.015508, l1: 0.017098, l2: 0.025325, l3: 0.040874, l4: 0.080900, l5: 0.155781, l6: 0.303000\n",
      "\n",
      "[epoch: 389/400, batch: 208/1000, ite: 51402] train loss: 1.1130, accuracy: 96.1981%, tar: 0.0198 \n",
      "l0: 0.022465, l1: 0.024728, l2: 0.034412, l3: 0.052570, l4: 0.105626, l5: 0.228403, l6: 0.433720\n",
      "\n",
      "[epoch: 389/400, batch: 216/1000, ite: 51403] train loss: 1.1131, accuracy: 94.7086%, tar: 0.0198 \n",
      "l0: 0.020508, l1: 0.022221, l2: 0.029506, l3: 0.042981, l4: 0.085280, l5: 0.183744, l6: 0.372531\n",
      "\n",
      "[epoch: 389/400, batch: 224/1000, ite: 51404] train loss: 1.1131, accuracy: 94.7124%, tar: 0.0198 \n",
      "l0: 0.023160, l1: 0.024164, l2: 0.034124, l3: 0.052703, l4: 0.091071, l5: 0.152694, l6: 0.283626\n",
      "\n",
      "[epoch: 389/400, batch: 232/1000, ite: 51405] train loss: 1.1130, accuracy: 95.4486%, tar: 0.0198 \n",
      "l0: 0.022038, l1: 0.023735, l2: 0.029808, l3: 0.048963, l4: 0.106159, l5: 0.224333, l6: 0.463194\n",
      "\n",
      "[epoch: 389/400, batch: 240/1000, ite: 51406] train loss: 1.1132, accuracy: 94.1068%, tar: 0.0198 \n",
      "l0: 0.017747, l1: 0.018504, l2: 0.024668, l3: 0.035950, l4: 0.061457, l5: 0.109756, l6: 0.278671\n",
      "\n",
      "[epoch: 389/400, batch: 248/1000, ite: 51407] train loss: 1.1130, accuracy: 95.8196%, tar: 0.0198 \n",
      "l0: 0.019643, l1: 0.021364, l2: 0.031480, l3: 0.055701, l4: 0.097011, l5: 0.206344, l6: 0.426806\n",
      "\n",
      "[epoch: 389/400, batch: 256/1000, ite: 51408] train loss: 1.1131, accuracy: 94.7244%, tar: 0.0198 \n",
      "l0: 0.026641, l1: 0.028607, l2: 0.036366, l3: 0.056788, l4: 0.110619, l5: 0.214137, l6: 0.466818\n",
      "\n",
      "[epoch: 389/400, batch: 264/1000, ite: 51409] train loss: 1.1133, accuracy: 93.6651%, tar: 0.0198 \n",
      "l0: 0.020518, l1: 0.022087, l2: 0.029632, l3: 0.043968, l4: 0.080488, l5: 0.174908, l6: 0.384148\n",
      "\n",
      "[epoch: 389/400, batch: 272/1000, ite: 51410] train loss: 1.1134, accuracy: 95.2925%, tar: 0.0198 \n",
      "l0: 0.020872, l1: 0.022097, l2: 0.029180, l3: 0.042505, l4: 0.071752, l5: 0.142254, l6: 0.275861\n",
      "\n",
      "[epoch: 389/400, batch: 280/1000, ite: 51411] train loss: 1.1132, accuracy: 95.2287%, tar: 0.0198 \n",
      "l0: 0.020326, l1: 0.021302, l2: 0.028534, l3: 0.042159, l4: 0.071897, l5: 0.118183, l6: 0.244561\n",
      "\n",
      "[epoch: 389/400, batch: 288/1000, ite: 51412] train loss: 1.1130, accuracy: 95.8392%, tar: 0.0198 \n",
      "l0: 0.021903, l1: 0.024355, l2: 0.036727, l3: 0.063896, l4: 0.125170, l5: 0.235985, l6: 0.479039\n",
      "\n",
      "[epoch: 389/400, batch: 296/1000, ite: 51413] train loss: 1.1132, accuracy: 93.9734%, tar: 0.0198 \n",
      "l0: 0.019186, l1: 0.020610, l2: 0.028066, l3: 0.042103, l4: 0.077174, l5: 0.148106, l6: 0.319982\n",
      "\n",
      "[epoch: 389/400, batch: 304/1000, ite: 51414] train loss: 1.1131, accuracy: 95.0780%, tar: 0.0198 \n",
      "l0: 0.023297, l1: 0.025301, l2: 0.036180, l3: 0.057371, l4: 0.109644, l5: 0.192283, l6: 0.343675\n",
      "\n",
      "[epoch: 389/400, batch: 312/1000, ite: 51415] train loss: 1.1131, accuracy: 95.1970%, tar: 0.0198 \n",
      "l0: 0.016742, l1: 0.018465, l2: 0.025466, l3: 0.040409, l4: 0.083350, l5: 0.172217, l6: 0.337129\n",
      "\n",
      "[epoch: 389/400, batch: 320/1000, ite: 51416] train loss: 1.1131, accuracy: 95.9440%, tar: 0.0198 \n",
      "l0: 0.021005, l1: 0.022296, l2: 0.031076, l3: 0.045555, l4: 0.084657, l5: 0.159485, l6: 0.387204\n",
      "\n",
      "[epoch: 389/400, batch: 328/1000, ite: 51417] train loss: 1.1131, accuracy: 94.5912%, tar: 0.0198 \n",
      "l0: 0.022935, l1: 0.024608, l2: 0.033776, l3: 0.053387, l4: 0.104397, l5: 0.216398, l6: 0.472816\n",
      "\n",
      "[epoch: 389/400, batch: 336/1000, ite: 51418] train loss: 1.1133, accuracy: 94.0157%, tar: 0.0198 \n",
      "l0: 0.016014, l1: 0.017332, l2: 0.022110, l3: 0.036772, l4: 0.070960, l5: 0.154417, l6: 0.290161\n",
      "\n",
      "[epoch: 389/400, batch: 344/1000, ite: 51419] train loss: 1.1132, accuracy: 96.1832%, tar: 0.0198 \n",
      "l0: 0.023575, l1: 0.024799, l2: 0.034540, l3: 0.055348, l4: 0.102187, l5: 0.178261, l6: 0.314872\n",
      "\n",
      "[epoch: 389/400, batch: 352/1000, ite: 51420] train loss: 1.1131, accuracy: 95.6065%, tar: 0.0198 \n",
      "l0: 0.018235, l1: 0.019972, l2: 0.028903, l3: 0.043404, l4: 0.079589, l5: 0.152482, l6: 0.233147\n",
      "\n",
      "[epoch: 389/400, batch: 360/1000, ite: 51421] train loss: 1.1129, accuracy: 97.0130%, tar: 0.0198 \n",
      "l0: 0.028795, l1: 0.030812, l2: 0.040647, l3: 0.060053, l4: 0.110337, l5: 0.258356, l6: 0.521443\n",
      "\n",
      "[epoch: 389/400, batch: 368/1000, ite: 51422] train loss: 1.1132, accuracy: 93.3969%, tar: 0.0198 \n",
      "l0: 0.012610, l1: 0.013431, l2: 0.020419, l3: 0.032069, l4: 0.056739, l5: 0.125703, l6: 0.308702\n",
      "\n",
      "[epoch: 389/400, batch: 376/1000, ite: 51423] train loss: 1.1131, accuracy: 96.1834%, tar: 0.0198 \n",
      "l0: 0.016709, l1: 0.018169, l2: 0.025494, l3: 0.038304, l4: 0.067134, l5: 0.153191, l6: 0.345179\n",
      "\n",
      "[epoch: 389/400, batch: 384/1000, ite: 51424] train loss: 1.1130, accuracy: 95.7446%, tar: 0.0198 \n",
      "l0: 0.017239, l1: 0.018262, l2: 0.024855, l3: 0.033773, l4: 0.062949, l5: 0.113416, l6: 0.293943\n",
      "\n",
      "[epoch: 389/400, batch: 392/1000, ite: 51425] train loss: 1.1128, accuracy: 96.0317%, tar: 0.0198 \n",
      "l0: 0.014699, l1: 0.015655, l2: 0.023188, l3: 0.037283, l4: 0.070972, l5: 0.130765, l6: 0.299508\n",
      "\n",
      "[epoch: 389/400, batch: 400/1000, ite: 51426] train loss: 1.1127, accuracy: 96.1785%, tar: 0.0198 \n",
      "l0: 0.020780, l1: 0.022390, l2: 0.029672, l3: 0.046205, l4: 0.087474, l5: 0.176309, l6: 0.419043\n",
      "\n",
      "[epoch: 389/400, batch: 408/1000, ite: 51427] train loss: 1.1127, accuracy: 94.3285%, tar: 0.0198 \n",
      "l0: 0.015272, l1: 0.016246, l2: 0.022714, l3: 0.035062, l4: 0.066424, l5: 0.128878, l6: 0.262812\n",
      "\n",
      "[epoch: 389/400, batch: 416/1000, ite: 51428] train loss: 1.1125, accuracy: 95.8891%, tar: 0.0198 \n",
      "l0: 0.021025, l1: 0.022874, l2: 0.031317, l3: 0.046503, l4: 0.089933, l5: 0.211514, l6: 0.399113\n",
      "\n",
      "[epoch: 389/400, batch: 424/1000, ite: 51429] train loss: 1.1126, accuracy: 95.1519%, tar: 0.0198 \n",
      "l0: 0.019751, l1: 0.021028, l2: 0.030100, l3: 0.047965, l4: 0.093881, l5: 0.203144, l6: 0.393484\n",
      "\n",
      "[epoch: 389/400, batch: 432/1000, ite: 51430] train loss: 1.1127, accuracy: 94.6306%, tar: 0.0198 \n",
      "l0: 0.018668, l1: 0.019872, l2: 0.026470, l3: 0.041235, l4: 0.078444, l5: 0.181601, l6: 0.347274\n",
      "\n",
      "[epoch: 389/400, batch: 440/1000, ite: 51431] train loss: 1.1126, accuracy: 95.0701%, tar: 0.0198 \n",
      "l0: 0.014824, l1: 0.015917, l2: 0.021280, l3: 0.032093, l4: 0.060001, l5: 0.099692, l6: 0.204018\n",
      "\n",
      "[epoch: 389/400, batch: 448/1000, ite: 51432] train loss: 1.1123, accuracy: 96.5871%, tar: 0.0198 \n",
      "l0: 0.020586, l1: 0.022776, l2: 0.035342, l3: 0.069410, l4: 0.132331, l5: 0.217469, l6: 0.443478\n",
      "\n",
      "[epoch: 389/400, batch: 456/1000, ite: 51433] train loss: 1.1125, accuracy: 94.2548%, tar: 0.0198 \n",
      "l0: 0.016660, l1: 0.018945, l2: 0.026375, l3: 0.051345, l4: 0.107429, l5: 0.202223, l6: 0.425514\n",
      "\n",
      "[epoch: 389/400, batch: 464/1000, ite: 51434] train loss: 1.1126, accuracy: 95.2937%, tar: 0.0198 \n",
      "l0: 0.016933, l1: 0.017871, l2: 0.024802, l3: 0.039672, l4: 0.064541, l5: 0.128184, l6: 0.314138\n",
      "\n",
      "[epoch: 389/400, batch: 472/1000, ite: 51435] train loss: 1.1125, accuracy: 95.8225%, tar: 0.0198 \n",
      "l0: 0.016723, l1: 0.017989, l2: 0.023746, l3: 0.037008, l4: 0.065853, l5: 0.132974, l6: 0.329646\n",
      "\n",
      "[epoch: 389/400, batch: 480/1000, ite: 51436] train loss: 1.1124, accuracy: 95.4399%, tar: 0.0198 \n",
      "l0: 0.015376, l1: 0.016532, l2: 0.024049, l3: 0.037374, l4: 0.068580, l5: 0.149893, l6: 0.307036\n",
      "\n",
      "[epoch: 389/400, batch: 488/1000, ite: 51437] train loss: 1.1123, accuracy: 95.9729%, tar: 0.0198 \n",
      "l0: 0.019582, l1: 0.020722, l2: 0.028238, l3: 0.041961, l4: 0.083995, l5: 0.200020, l6: 0.449687\n",
      "\n",
      "[epoch: 389/400, batch: 496/1000, ite: 51438] train loss: 1.1124, accuracy: 93.8317%, tar: 0.0198 \n",
      "l0: 0.031729, l1: 0.033417, l2: 0.044577, l3: 0.062527, l4: 0.116600, l5: 0.255608, l6: 0.496883\n",
      "\n",
      "[epoch: 389/400, batch: 504/1000, ite: 51439] train loss: 1.1127, accuracy: 93.0450%, tar: 0.0198 \n",
      "l0: 0.022269, l1: 0.023746, l2: 0.031599, l3: 0.046582, l4: 0.089481, l5: 0.172317, l6: 0.324984\n",
      "\n",
      "[epoch: 389/400, batch: 512/1000, ite: 51440] train loss: 1.1126, accuracy: 94.4528%, tar: 0.0198 \n",
      "l0: 0.017068, l1: 0.019394, l2: 0.029199, l3: 0.046062, l4: 0.090082, l5: 0.177163, l6: 0.384370\n",
      "\n",
      "[epoch: 389/400, batch: 520/1000, ite: 51441] train loss: 1.1127, accuracy: 95.3208%, tar: 0.0198 \n",
      "l0: 0.016088, l1: 0.017165, l2: 0.023692, l3: 0.034877, l4: 0.058630, l5: 0.114174, l6: 0.270327\n",
      "\n",
      "[epoch: 389/400, batch: 528/1000, ite: 51442] train loss: 1.1125, accuracy: 95.7798%, tar: 0.0198 \n",
      "l0: 0.015290, l1: 0.016295, l2: 0.023297, l3: 0.038940, l4: 0.075976, l5: 0.151906, l6: 0.325387\n",
      "\n",
      "[epoch: 389/400, batch: 536/1000, ite: 51443] train loss: 1.1124, accuracy: 95.7253%, tar: 0.0198 \n",
      "l0: 0.018726, l1: 0.019726, l2: 0.029425, l3: 0.043328, l4: 0.068833, l5: 0.117042, l6: 0.233088\n",
      "\n",
      "[epoch: 389/400, batch: 544/1000, ite: 51444] train loss: 1.1121, accuracy: 96.1147%, tar: 0.0198 \n",
      "l0: 0.019599, l1: 0.020438, l2: 0.027201, l3: 0.043912, l4: 0.086561, l5: 0.196932, l6: 0.398948\n",
      "\n",
      "[epoch: 389/400, batch: 552/1000, ite: 51445] train loss: 1.1122, accuracy: 94.4169%, tar: 0.0198 \n",
      "l0: 0.023496, l1: 0.024546, l2: 0.030981, l3: 0.046867, l4: 0.086344, l5: 0.176600, l6: 0.435204\n",
      "\n",
      "[epoch: 389/400, batch: 560/1000, ite: 51446] train loss: 1.1123, accuracy: 93.4291%, tar: 0.0198 \n",
      "l0: 0.019660, l1: 0.021679, l2: 0.033439, l3: 0.056937, l4: 0.120040, l5: 0.242103, l6: 0.503217\n",
      "\n",
      "[epoch: 389/400, batch: 568/1000, ite: 51447] train loss: 1.1126, accuracy: 95.1609%, tar: 0.0198 \n",
      "l0: 0.019607, l1: 0.020733, l2: 0.026888, l3: 0.044588, l4: 0.092093, l5: 0.174289, l6: 0.347537\n",
      "\n",
      "[epoch: 389/400, batch: 576/1000, ite: 51448] train loss: 1.1125, accuracy: 95.3530%, tar: 0.0198 \n",
      "l0: 0.021213, l1: 0.022912, l2: 0.031212, l3: 0.050341, l4: 0.093730, l5: 0.179780, l6: 0.365083\n",
      "\n",
      "[epoch: 389/400, batch: 584/1000, ite: 51449] train loss: 1.1126, accuracy: 95.0666%, tar: 0.0198 \n",
      "l0: 0.018553, l1: 0.020417, l2: 0.030467, l3: 0.049707, l4: 0.093462, l5: 0.190326, l6: 0.444360\n",
      "\n",
      "[epoch: 389/400, batch: 592/1000, ite: 51450] train loss: 1.1127, accuracy: 94.7803%, tar: 0.0198 \n",
      "l0: 0.021444, l1: 0.023363, l2: 0.033787, l3: 0.054202, l4: 0.152741, l5: 0.321949, l6: 0.562667\n",
      "\n",
      "[epoch: 389/400, batch: 600/1000, ite: 51451] train loss: 1.1131, accuracy: 92.9613%, tar: 0.0198 \n",
      "l0: 0.024680, l1: 0.026207, l2: 0.035297, l3: 0.051392, l4: 0.100432, l5: 0.252589, l6: 0.637981\n",
      "\n",
      "[epoch: 389/400, batch: 608/1000, ite: 51452] train loss: 1.1136, accuracy: 92.3360%, tar: 0.0198 \n",
      "l0: 0.019382, l1: 0.020694, l2: 0.029136, l3: 0.046332, l4: 0.084753, l5: 0.163740, l6: 0.326623\n",
      "\n",
      "[epoch: 389/400, batch: 616/1000, ite: 51453] train loss: 1.1135, accuracy: 94.8942%, tar: 0.0198 \n",
      "l0: 0.020430, l1: 0.020804, l2: 0.026513, l3: 0.037135, l4: 0.060865, l5: 0.122870, l6: 0.281905\n",
      "\n",
      "[epoch: 389/400, batch: 624/1000, ite: 51454] train loss: 1.1133, accuracy: 95.7302%, tar: 0.0198 \n",
      "l0: 0.018149, l1: 0.020155, l2: 0.029200, l3: 0.044087, l4: 0.082698, l5: 0.174237, l6: 0.367767\n",
      "\n",
      "[epoch: 389/400, batch: 632/1000, ite: 51455] train loss: 1.1133, accuracy: 95.8590%, tar: 0.0198 \n",
      "l0: 0.017506, l1: 0.019063, l2: 0.028132, l3: 0.047157, l4: 0.095866, l5: 0.179740, l6: 0.359175\n",
      "\n",
      "[epoch: 389/400, batch: 640/1000, ite: 51456] train loss: 1.1133, accuracy: 95.2580%, tar: 0.0198 \n",
      "l0: 0.021570, l1: 0.022917, l2: 0.030456, l3: 0.048088, l4: 0.092427, l5: 0.183317, l6: 0.397531\n",
      "\n",
      "[epoch: 389/400, batch: 648/1000, ite: 51457] train loss: 1.1134, accuracy: 94.3067%, tar: 0.0198 \n",
      "l0: 0.019572, l1: 0.020800, l2: 0.029195, l3: 0.044649, l4: 0.090024, l5: 0.185187, l6: 0.342867\n",
      "\n",
      "[epoch: 389/400, batch: 656/1000, ite: 51458] train loss: 1.1133, accuracy: 95.4380%, tar: 0.0198 \n",
      "l0: 0.015879, l1: 0.017681, l2: 0.026191, l3: 0.046650, l4: 0.098297, l5: 0.198295, l6: 0.433275\n",
      "\n",
      "[epoch: 389/400, batch: 664/1000, ite: 51459] train loss: 1.1135, accuracy: 95.4921%, tar: 0.0198 \n",
      "l0: 0.016667, l1: 0.017789, l2: 0.024463, l3: 0.039118, l4: 0.073914, l5: 0.155078, l6: 0.329782\n",
      "\n",
      "[epoch: 389/400, batch: 672/1000, ite: 51460] train loss: 1.1134, accuracy: 96.0471%, tar: 0.0198 \n",
      "l0: 0.019310, l1: 0.020328, l2: 0.028802, l3: 0.041415, l4: 0.068327, l5: 0.136428, l6: 0.320212\n",
      "\n",
      "[epoch: 389/400, batch: 680/1000, ite: 51461] train loss: 1.1133, accuracy: 95.5598%, tar: 0.0198 \n",
      "l0: 0.024363, l1: 0.025875, l2: 0.031842, l3: 0.045130, l4: 0.079810, l5: 0.162702, l6: 0.317370\n",
      "\n",
      "[epoch: 389/400, batch: 688/1000, ite: 51462] train loss: 1.1132, accuracy: 95.1896%, tar: 0.0198 \n",
      "l0: 0.019617, l1: 0.020329, l2: 0.028858, l3: 0.041482, l4: 0.073907, l5: 0.159979, l6: 0.350876\n",
      "\n",
      "[epoch: 389/400, batch: 696/1000, ite: 51463] train loss: 1.1132, accuracy: 94.9703%, tar: 0.0198 \n",
      "l0: 0.027047, l1: 0.028543, l2: 0.039748, l3: 0.058743, l4: 0.094934, l5: 0.219519, l6: 0.431771\n",
      "\n",
      "[epoch: 389/400, batch: 704/1000, ite: 51464] train loss: 1.1133, accuracy: 95.0131%, tar: 0.0198 \n",
      "l0: 0.024237, l1: 0.025613, l2: 0.033641, l3: 0.047545, l4: 0.111269, l5: 0.233196, l6: 0.473339\n",
      "\n",
      "[epoch: 389/400, batch: 712/1000, ite: 51465] train loss: 1.1135, accuracy: 93.4557%, tar: 0.0198 \n",
      "l0: 0.019819, l1: 0.020968, l2: 0.027816, l3: 0.039950, l4: 0.064025, l5: 0.138309, l6: 0.282249\n",
      "\n",
      "[epoch: 389/400, batch: 720/1000, ite: 51466] train loss: 1.1134, accuracy: 95.3579%, tar: 0.0198 \n",
      "l0: 0.014775, l1: 0.015755, l2: 0.022054, l3: 0.032064, l4: 0.052742, l5: 0.097499, l6: 0.241503\n",
      "\n",
      "[epoch: 389/400, batch: 728/1000, ite: 51467] train loss: 1.1131, accuracy: 95.8609%, tar: 0.0198 \n",
      "l0: 0.019321, l1: 0.021218, l2: 0.028635, l3: 0.043588, l4: 0.094332, l5: 0.216147, l6: 0.418428\n",
      "\n",
      "[epoch: 389/400, batch: 736/1000, ite: 51468] train loss: 1.1132, accuracy: 94.1736%, tar: 0.0198 \n",
      "l0: 0.024265, l1: 0.025975, l2: 0.035568, l3: 0.051830, l4: 0.087942, l5: 0.169190, l6: 0.341215\n",
      "\n",
      "[epoch: 389/400, batch: 744/1000, ite: 51469] train loss: 1.1132, accuracy: 95.1040%, tar: 0.0198 \n",
      "l0: 0.020192, l1: 0.021090, l2: 0.027450, l3: 0.041005, l4: 0.076219, l5: 0.178478, l6: 0.379900\n",
      "\n",
      "[epoch: 389/400, batch: 752/1000, ite: 51470] train loss: 1.1132, accuracy: 95.0881%, tar: 0.0198 \n",
      "l0: 0.023268, l1: 0.025874, l2: 0.036882, l3: 0.055781, l4: 0.105804, l5: 0.214870, l6: 0.432733\n",
      "\n",
      "[epoch: 389/400, batch: 760/1000, ite: 51471] train loss: 1.1133, accuracy: 95.4674%, tar: 0.0198 \n",
      "l0: 0.019153, l1: 0.020206, l2: 0.028983, l3: 0.042857, l4: 0.070973, l5: 0.132335, l6: 0.241590\n",
      "\n",
      "[epoch: 389/400, batch: 768/1000, ite: 51472] train loss: 1.1131, accuracy: 96.5245%, tar: 0.0198 \n",
      "l0: 0.024313, l1: 0.026159, l2: 0.037090, l3: 0.055619, l4: 0.094047, l5: 0.212004, l6: 0.443858\n",
      "\n",
      "[epoch: 389/400, batch: 776/1000, ite: 51473] train loss: 1.1133, accuracy: 94.2412%, tar: 0.0198 \n",
      "l0: 0.023540, l1: 0.025144, l2: 0.032422, l3: 0.044901, l4: 0.074651, l5: 0.140370, l6: 0.321461\n",
      "\n",
      "[epoch: 389/400, batch: 784/1000, ite: 51474] train loss: 1.1132, accuracy: 95.4837%, tar: 0.0198 \n",
      "l0: 0.018155, l1: 0.019829, l2: 0.029135, l3: 0.045924, l4: 0.083280, l5: 0.159841, l6: 0.355064\n",
      "\n",
      "[epoch: 389/400, batch: 792/1000, ite: 51475] train loss: 1.1132, accuracy: 95.4048%, tar: 0.0198 \n",
      "l0: 0.019644, l1: 0.020405, l2: 0.026091, l3: 0.037731, l4: 0.061989, l5: 0.116922, l6: 0.265182\n",
      "\n",
      "[epoch: 389/400, batch: 800/1000, ite: 51476] train loss: 1.1130, accuracy: 95.7519%, tar: 0.0198 \n",
      "l0: 0.013894, l1: 0.014884, l2: 0.019777, l3: 0.030573, l4: 0.054103, l5: 0.120878, l6: 0.248603\n",
      "\n",
      "[epoch: 389/400, batch: 808/1000, ite: 51477] train loss: 1.1127, accuracy: 96.2291%, tar: 0.0198 \n",
      "l0: 0.019616, l1: 0.021605, l2: 0.028328, l3: 0.046947, l4: 0.086915, l5: 0.178756, l6: 0.338775\n",
      "\n",
      "[epoch: 389/400, batch: 816/1000, ite: 51478] train loss: 1.1127, accuracy: 95.5028%, tar: 0.0198 \n",
      "l0: 0.018449, l1: 0.020312, l2: 0.030135, l3: 0.046158, l4: 0.092418, l5: 0.206340, l6: 0.402910\n",
      "\n",
      "[epoch: 389/400, batch: 824/1000, ite: 51479] train loss: 1.1128, accuracy: 95.0415%, tar: 0.0198 \n",
      "l0: 0.019822, l1: 0.020745, l2: 0.027127, l3: 0.041987, l4: 0.089300, l5: 0.160406, l6: 0.402763\n",
      "\n",
      "[epoch: 389/400, batch: 832/1000, ite: 51480] train loss: 1.1128, accuracy: 94.7739%, tar: 0.0198 \n",
      "l0: 0.020193, l1: 0.021831, l2: 0.030670, l3: 0.046393, l4: 0.084683, l5: 0.178299, l6: 0.380485\n",
      "\n",
      "[epoch: 389/400, batch: 840/1000, ite: 51481] train loss: 1.1128, accuracy: 94.7380%, tar: 0.0198 \n",
      "l0: 0.014611, l1: 0.015560, l2: 0.021171, l3: 0.031478, l4: 0.057879, l5: 0.099292, l6: 0.203565\n",
      "\n",
      "[epoch: 389/400, batch: 848/1000, ite: 51482] train loss: 1.1125, accuracy: 96.7391%, tar: 0.0198 \n",
      "l0: 0.016346, l1: 0.017280, l2: 0.022689, l3: 0.036356, l4: 0.068558, l5: 0.133222, l6: 0.281784\n",
      "\n",
      "[epoch: 389/400, batch: 856/1000, ite: 51483] train loss: 1.1123, accuracy: 96.0831%, tar: 0.0198 \n",
      "l0: 0.020009, l1: 0.020842, l2: 0.028535, l3: 0.042804, l4: 0.077110, l5: 0.153864, l6: 0.350385\n",
      "\n",
      "[epoch: 389/400, batch: 864/1000, ite: 51484] train loss: 1.1123, accuracy: 94.8986%, tar: 0.0198 \n",
      "l0: 0.025441, l1: 0.027916, l2: 0.037125, l3: 0.061553, l4: 0.152450, l5: 0.311446, l6: 0.522998\n",
      "\n",
      "[epoch: 389/400, batch: 872/1000, ite: 51485] train loss: 1.1127, accuracy: 93.1795%, tar: 0.0198 \n",
      "l0: 0.019415, l1: 0.020076, l2: 0.026862, l3: 0.038169, l4: 0.060070, l5: 0.109491, l6: 0.279206\n",
      "\n",
      "[epoch: 389/400, batch: 880/1000, ite: 51486] train loss: 1.1125, accuracy: 95.7763%, tar: 0.0198 \n",
      "l0: 0.027705, l1: 0.028459, l2: 0.035837, l3: 0.047801, l4: 0.089259, l5: 0.170520, l6: 0.397384\n",
      "\n",
      "[epoch: 389/400, batch: 888/1000, ite: 51487] train loss: 1.1125, accuracy: 93.6756%, tar: 0.0198 \n",
      "l0: 0.018970, l1: 0.020692, l2: 0.030293, l3: 0.045792, l4: 0.083851, l5: 0.183898, l6: 0.400905\n",
      "\n",
      "[epoch: 389/400, batch: 896/1000, ite: 51488] train loss: 1.1126, accuracy: 94.6078%, tar: 0.0198 \n",
      "l0: 0.017811, l1: 0.018526, l2: 0.025044, l3: 0.041377, l4: 0.078984, l5: 0.144542, l6: 0.299500\n",
      "\n",
      "[epoch: 389/400, batch: 904/1000, ite: 51489] train loss: 1.1125, accuracy: 95.5456%, tar: 0.0198 \n",
      "l0: 0.020477, l1: 0.021530, l2: 0.030348, l3: 0.046689, l4: 0.085540, l5: 0.167980, l6: 0.360933\n",
      "\n",
      "[epoch: 389/400, batch: 912/1000, ite: 51490] train loss: 1.1125, accuracy: 94.9398%, tar: 0.0198 \n",
      "l0: 0.025368, l1: 0.026278, l2: 0.034547, l3: 0.045128, l4: 0.078738, l5: 0.220572, l6: 0.470292\n",
      "\n",
      "[epoch: 389/400, batch: 920/1000, ite: 51491] train loss: 1.1126, accuracy: 93.7651%, tar: 0.0198 \n",
      "l0: 0.020757, l1: 0.021440, l2: 0.027149, l3: 0.039090, l4: 0.075689, l5: 0.170098, l6: 0.353479\n",
      "\n",
      "[epoch: 389/400, batch: 928/1000, ite: 51492] train loss: 1.1126, accuracy: 94.4366%, tar: 0.0198 \n",
      "l0: 0.020523, l1: 0.022101, l2: 0.030792, l3: 0.053104, l4: 0.104582, l5: 0.233316, l6: 0.461740\n",
      "\n",
      "[epoch: 389/400, batch: 936/1000, ite: 51493] train loss: 1.1128, accuracy: 93.7734%, tar: 0.0198 \n",
      "l0: 0.017076, l1: 0.018623, l2: 0.028473, l3: 0.046099, l4: 0.094294, l5: 0.210724, l6: 0.327380\n",
      "\n",
      "[epoch: 389/400, batch: 944/1000, ite: 51494] train loss: 1.1128, accuracy: 96.1576%, tar: 0.0198 \n",
      "l0: 0.016875, l1: 0.018055, l2: 0.024225, l3: 0.040072, l4: 0.086748, l5: 0.185939, l6: 0.335836\n",
      "\n",
      "[epoch: 389/400, batch: 952/1000, ite: 51495] train loss: 1.1127, accuracy: 95.0816%, tar: 0.0198 \n",
      "l0: 0.021823, l1: 0.022573, l2: 0.028585, l3: 0.041532, l4: 0.077961, l5: 0.159999, l6: 0.391990\n",
      "\n",
      "[epoch: 389/400, batch: 960/1000, ite: 51496] train loss: 1.1127, accuracy: 94.3258%, tar: 0.0198 \n",
      "l0: 0.020360, l1: 0.021763, l2: 0.028998, l3: 0.045501, l4: 0.082123, l5: 0.175387, l6: 0.360301\n",
      "\n",
      "[epoch: 389/400, batch: 968/1000, ite: 51497] train loss: 1.1127, accuracy: 94.6618%, tar: 0.0198 \n",
      "l0: 0.023682, l1: 0.024972, l2: 0.035127, l3: 0.053984, l4: 0.098258, l5: 0.231340, l6: 0.501381\n",
      "\n",
      "[epoch: 389/400, batch: 976/1000, ite: 51498] train loss: 1.1130, accuracy: 93.8547%, tar: 0.0198 \n",
      "l0: 0.020223, l1: 0.022122, l2: 0.029960, l3: 0.051674, l4: 0.118401, l5: 0.224976, l6: 0.438417\n",
      "\n",
      "[epoch: 389/400, batch: 984/1000, ite: 51499] train loss: 1.1131, accuracy: 94.4662%, tar: 0.0198 \n",
      "l0: 0.019729, l1: 0.021027, l2: 0.028148, l3: 0.041623, l4: 0.066683, l5: 0.121486, l6: 0.353963\n",
      "\n",
      "[epoch: 389/400, batch: 992/1000, ite: 51500] train loss: 1.1130, accuracy: 95.0588%, tar: 0.0198 \n",
      "l0: 0.022506, l1: 0.024140, l2: 0.031448, l3: 0.049971, l4: 0.097818, l5: 0.208344, l6: 0.473341\n",
      "\n",
      "[epoch: 389/400, batch: 1000/1000, ite: 51501] train loss: 1.1132, accuracy: 93.8388%, tar: 0.0198 \n",
      "l0: 0.015534, l1: 0.017737, l2: 0.028445, l3: 0.045480, l4: 0.094041, l5: 0.204743, l6: 0.405735\n",
      "\n",
      "[epoch: 390/400, batch: 8/1000, ite: 51502] train loss: 1.1133, accuracy: 95.2885%, tar: 0.0198 \n",
      "l0: 0.016905, l1: 0.018326, l2: 0.025354, l3: 0.039656, l4: 0.073698, l5: 0.123044, l6: 0.254959\n",
      "\n",
      "[epoch: 390/400, batch: 16/1000, ite: 51503] train loss: 1.1131, accuracy: 96.5820%, tar: 0.0198 \n",
      "l0: 0.013896, l1: 0.014916, l2: 0.021064, l3: 0.032925, l4: 0.061840, l5: 0.121642, l6: 0.260202\n",
      "\n",
      "[epoch: 390/400, batch: 24/1000, ite: 51504] train loss: 1.1129, accuracy: 96.2398%, tar: 0.0198 \n",
      "l0: 0.015646, l1: 0.016385, l2: 0.023579, l3: 0.039406, l4: 0.068878, l5: 0.157998, l6: 0.311971\n",
      "\n",
      "[epoch: 390/400, batch: 32/1000, ite: 51505] train loss: 1.1128, accuracy: 95.5473%, tar: 0.0198 \n",
      "l0: 0.018817, l1: 0.020408, l2: 0.030397, l3: 0.049815, l4: 0.095267, l5: 0.173764, l6: 0.356408\n",
      "\n",
      "[epoch: 390/400, batch: 40/1000, ite: 51506] train loss: 1.1127, accuracy: 95.5537%, tar: 0.0198 \n",
      "l0: 0.015288, l1: 0.016401, l2: 0.022667, l3: 0.036074, l4: 0.069567, l5: 0.130098, l6: 0.309068\n",
      "\n",
      "[epoch: 390/400, batch: 48/1000, ite: 51507] train loss: 1.1126, accuracy: 95.9033%, tar: 0.0198 \n",
      "l0: 0.022404, l1: 0.024320, l2: 0.033440, l3: 0.050934, l4: 0.101619, l5: 0.215648, l6: 0.383350\n",
      "\n",
      "[epoch: 390/400, batch: 56/1000, ite: 51508] train loss: 1.1127, accuracy: 95.1181%, tar: 0.0198 \n",
      "l0: 0.018183, l1: 0.020094, l2: 0.030718, l3: 0.056381, l4: 0.120966, l5: 0.270065, l6: 0.475068\n",
      "\n",
      "[epoch: 390/400, batch: 64/1000, ite: 51509] train loss: 1.1129, accuracy: 94.1498%, tar: 0.0198 \n",
      "l0: 0.019172, l1: 0.021118, l2: 0.031369, l3: 0.048502, l4: 0.084708, l5: 0.171957, l6: 0.376039\n",
      "\n",
      "[epoch: 390/400, batch: 72/1000, ite: 51510] train loss: 1.1129, accuracy: 95.6647%, tar: 0.0198 \n",
      "l0: 0.019879, l1: 0.021150, l2: 0.028482, l3: 0.041737, l4: 0.073844, l5: 0.138809, l6: 0.285972\n",
      "\n",
      "[epoch: 390/400, batch: 80/1000, ite: 51511] train loss: 1.1128, accuracy: 95.8418%, tar: 0.0198 \n",
      "l0: 0.025814, l1: 0.027377, l2: 0.034694, l3: 0.050435, l4: 0.094093, l5: 0.190547, l6: 0.402396\n",
      "\n",
      "[epoch: 390/400, batch: 88/1000, ite: 51512] train loss: 1.1129, accuracy: 94.2712%, tar: 0.0198 \n",
      "l0: 0.018732, l1: 0.019909, l2: 0.028159, l3: 0.042970, l4: 0.086438, l5: 0.201915, l6: 0.361814\n",
      "\n",
      "[epoch: 390/400, batch: 96/1000, ite: 51513] train loss: 1.1129, accuracy: 95.2501%, tar: 0.0198 \n",
      "l0: 0.016952, l1: 0.019255, l2: 0.027594, l3: 0.046505, l4: 0.090482, l5: 0.182266, l6: 0.349084\n",
      "\n",
      "[epoch: 390/400, batch: 104/1000, ite: 51514] train loss: 1.1129, accuracy: 96.1382%, tar: 0.0198 \n",
      "l0: 0.020120, l1: 0.021475, l2: 0.030492, l3: 0.046030, l4: 0.085129, l5: 0.169811, l6: 0.322892\n",
      "\n",
      "[epoch: 390/400, batch: 112/1000, ite: 51515] train loss: 1.1128, accuracy: 95.4550%, tar: 0.0198 \n",
      "l0: 0.017325, l1: 0.019925, l2: 0.029470, l3: 0.048898, l4: 0.110285, l5: 0.208163, l6: 0.410263\n",
      "\n",
      "[epoch: 390/400, batch: 120/1000, ite: 51516] train loss: 1.1129, accuracy: 95.2958%, tar: 0.0198 \n",
      "l0: 0.020755, l1: 0.022519, l2: 0.032065, l3: 0.053611, l4: 0.091592, l5: 0.171977, l6: 0.355752\n",
      "\n",
      "[epoch: 390/400, batch: 128/1000, ite: 51517] train loss: 1.1129, accuracy: 94.9104%, tar: 0.0198 \n",
      "l0: 0.017141, l1: 0.018765, l2: 0.024731, l3: 0.040623, l4: 0.104033, l5: 0.185747, l6: 0.356834\n",
      "\n",
      "[epoch: 390/400, batch: 136/1000, ite: 51518] train loss: 1.1129, accuracy: 95.1302%, tar: 0.0198 \n",
      "l0: 0.016637, l1: 0.018600, l2: 0.027623, l3: 0.039731, l4: 0.076439, l5: 0.157084, l6: 0.296528\n",
      "\n",
      "[epoch: 390/400, batch: 144/1000, ite: 51519] train loss: 1.1128, accuracy: 96.2200%, tar: 0.0198 \n",
      "l0: 0.021293, l1: 0.022555, l2: 0.029976, l3: 0.043075, l4: 0.089527, l5: 0.202756, l6: 0.372861\n",
      "\n",
      "[epoch: 390/400, batch: 152/1000, ite: 51520] train loss: 1.1128, accuracy: 95.0768%, tar: 0.0198 \n",
      "l0: 0.019724, l1: 0.021990, l2: 0.031546, l3: 0.053070, l4: 0.091870, l5: 0.160965, l6: 0.308338\n",
      "\n",
      "[epoch: 390/400, batch: 160/1000, ite: 51521] train loss: 1.1127, accuracy: 96.2291%, tar: 0.0198 \n",
      "l0: 0.017259, l1: 0.018179, l2: 0.024398, l3: 0.037127, l4: 0.065998, l5: 0.125465, l6: 0.273970\n",
      "\n",
      "[epoch: 390/400, batch: 168/1000, ite: 51522] train loss: 1.1125, accuracy: 95.5555%, tar: 0.0198 \n",
      "l0: 0.016657, l1: 0.017749, l2: 0.024201, l3: 0.042847, l4: 0.076183, l5: 0.147749, l6: 0.320003\n",
      "\n",
      "[epoch: 390/400, batch: 176/1000, ite: 51523] train loss: 1.1125, accuracy: 95.6832%, tar: 0.0198 \n",
      "l0: 0.017128, l1: 0.018505, l2: 0.025572, l3: 0.041283, l4: 0.077746, l5: 0.156861, l6: 0.342682\n",
      "\n",
      "[epoch: 390/400, batch: 184/1000, ite: 51524] train loss: 1.1124, accuracy: 95.4391%, tar: 0.0198 \n",
      "l0: 0.019286, l1: 0.019928, l2: 0.026679, l3: 0.040645, l4: 0.075611, l5: 0.158152, l6: 0.332878\n",
      "\n",
      "[epoch: 390/400, batch: 192/1000, ite: 51525] train loss: 1.1123, accuracy: 94.8467%, tar: 0.0198 \n",
      "l0: 0.022497, l1: 0.023296, l2: 0.029717, l3: 0.042943, l4: 0.070333, l5: 0.150420, l6: 0.389261\n",
      "\n",
      "[epoch: 390/400, batch: 200/1000, ite: 51526] train loss: 1.1123, accuracy: 94.4134%, tar: 0.0198 \n",
      "l0: 0.020963, l1: 0.022271, l2: 0.029649, l3: 0.049699, l4: 0.088629, l5: 0.156022, l6: 0.331166\n",
      "\n",
      "[epoch: 390/400, batch: 208/1000, ite: 51527] train loss: 1.1123, accuracy: 94.7321%, tar: 0.0198 \n",
      "l0: 0.021034, l1: 0.022092, l2: 0.031419, l3: 0.048253, l4: 0.096657, l5: 0.168652, l6: 0.305594\n",
      "\n",
      "[epoch: 390/400, batch: 216/1000, ite: 51528] train loss: 1.1122, accuracy: 95.5656%, tar: 0.0198 \n",
      "l0: 0.015758, l1: 0.017042, l2: 0.023923, l3: 0.037967, l4: 0.077486, l5: 0.169502, l6: 0.329825\n",
      "\n",
      "[epoch: 390/400, batch: 224/1000, ite: 51529] train loss: 1.1121, accuracy: 95.7042%, tar: 0.0198 \n",
      "l0: 0.026739, l1: 0.028103, l2: 0.035867, l3: 0.049640, l4: 0.086391, l5: 0.191989, l6: 0.404184\n",
      "\n",
      "[epoch: 390/400, batch: 232/1000, ite: 51530] train loss: 1.1122, accuracy: 94.3067%, tar: 0.0198 \n",
      "l0: 0.018288, l1: 0.019747, l2: 0.029516, l3: 0.046435, l4: 0.075749, l5: 0.130376, l6: 0.245341\n",
      "\n",
      "[epoch: 390/400, batch: 240/1000, ite: 51531] train loss: 1.1120, accuracy: 96.0951%, tar: 0.0198 \n",
      "l0: 0.016115, l1: 0.017033, l2: 0.022935, l3: 0.036272, l4: 0.076730, l5: 0.156470, l6: 0.322441\n",
      "\n",
      "[epoch: 390/400, batch: 248/1000, ite: 51532] train loss: 1.1119, accuracy: 95.3595%, tar: 0.0198 \n",
      "l0: 0.022188, l1: 0.024679, l2: 0.034937, l3: 0.052431, l4: 0.096094, l5: 0.192145, l6: 0.437295\n",
      "\n",
      "[epoch: 390/400, batch: 256/1000, ite: 51533] train loss: 1.1121, accuracy: 94.2726%, tar: 0.0198 \n",
      "l0: 0.024857, l1: 0.026265, l2: 0.034469, l3: 0.049276, l4: 0.103861, l5: 0.256082, l6: 0.499516\n",
      "\n",
      "[epoch: 390/400, batch: 264/1000, ite: 51534] train loss: 1.1123, accuracy: 93.7077%, tar: 0.0198 \n",
      "l0: 0.018305, l1: 0.018918, l2: 0.025565, l3: 0.040693, l4: 0.079509, l5: 0.140449, l6: 0.301940\n",
      "\n",
      "[epoch: 390/400, batch: 272/1000, ite: 51535] train loss: 1.1122, accuracy: 96.0779%, tar: 0.0198 \n",
      "l0: 0.020653, l1: 0.021612, l2: 0.029057, l3: 0.044461, l4: 0.082235, l5: 0.180604, l6: 0.391678\n",
      "\n",
      "[epoch: 390/400, batch: 280/1000, ite: 51536] train loss: 1.1122, accuracy: 94.8109%, tar: 0.0198 \n",
      "l0: 0.018522, l1: 0.019993, l2: 0.029325, l3: 0.047071, l4: 0.084482, l5: 0.161167, l6: 0.350546\n",
      "\n",
      "[epoch: 390/400, batch: 288/1000, ite: 51537] train loss: 1.1122, accuracy: 95.6516%, tar: 0.0198 \n",
      "l0: 0.016916, l1: 0.018706, l2: 0.025433, l3: 0.049517, l4: 0.089549, l5: 0.175356, l6: 0.365205\n",
      "\n",
      "[epoch: 390/400, batch: 296/1000, ite: 51538] train loss: 1.1122, accuracy: 95.8330%, tar: 0.0198 \n",
      "l0: 0.020391, l1: 0.021297, l2: 0.028187, l3: 0.042366, l4: 0.074694, l5: 0.169424, l6: 0.360016\n",
      "\n",
      "[epoch: 390/400, batch: 304/1000, ite: 51539] train loss: 1.1122, accuracy: 95.7021%, tar: 0.0198 \n",
      "l0: 0.016691, l1: 0.017891, l2: 0.024894, l3: 0.036841, l4: 0.064674, l5: 0.140888, l6: 0.289312\n",
      "\n",
      "[epoch: 390/400, batch: 312/1000, ite: 51540] train loss: 1.1120, accuracy: 95.9825%, tar: 0.0198 \n",
      "l0: 0.017156, l1: 0.018901, l2: 0.028099, l3: 0.047783, l4: 0.101709, l5: 0.210170, l6: 0.426587\n",
      "\n",
      "[epoch: 390/400, batch: 320/1000, ite: 51541] train loss: 1.1121, accuracy: 94.9591%, tar: 0.0198 \n",
      "l0: 0.015565, l1: 0.016957, l2: 0.022900, l3: 0.035420, l4: 0.071335, l5: 0.135671, l6: 0.258780\n",
      "\n",
      "[epoch: 390/400, batch: 328/1000, ite: 51542] train loss: 1.1119, accuracy: 96.0465%, tar: 0.0198 \n",
      "l0: 0.019670, l1: 0.020916, l2: 0.026199, l3: 0.039212, l4: 0.066052, l5: 0.142420, l6: 0.287974\n",
      "\n",
      "[epoch: 390/400, batch: 336/1000, ite: 51543] train loss: 1.1118, accuracy: 96.1405%, tar: 0.0198 \n",
      "l0: 0.015998, l1: 0.017266, l2: 0.025808, l3: 0.045919, l4: 0.103492, l5: 0.231233, l6: 0.458309\n",
      "\n",
      "[epoch: 390/400, batch: 344/1000, ite: 51544] train loss: 1.1120, accuracy: 94.5734%, tar: 0.0198 \n",
      "l0: 0.027538, l1: 0.029852, l2: 0.039317, l3: 0.053036, l4: 0.098430, l5: 0.227115, l6: 0.456120\n",
      "\n",
      "[epoch: 390/400, batch: 352/1000, ite: 51545] train loss: 1.1121, accuracy: 94.3542%, tar: 0.0198 \n",
      "l0: 0.017794, l1: 0.019288, l2: 0.027670, l3: 0.044873, l4: 0.122592, l5: 0.201917, l6: 0.352239\n",
      "\n",
      "[epoch: 390/400, batch: 360/1000, ite: 51546] train loss: 1.1122, accuracy: 95.4622%, tar: 0.0198 \n",
      "l0: 0.021743, l1: 0.024029, l2: 0.032385, l3: 0.046435, l4: 0.081920, l5: 0.164759, l6: 0.354903\n",
      "\n",
      "[epoch: 390/400, batch: 368/1000, ite: 51547] train loss: 1.1121, accuracy: 95.4631%, tar: 0.0198 \n",
      "l0: 0.021577, l1: 0.023919, l2: 0.033957, l3: 0.052622, l4: 0.090755, l5: 0.199263, l6: 0.332324\n",
      "\n",
      "[epoch: 390/400, batch: 376/1000, ite: 51548] train loss: 1.1121, accuracy: 95.4473%, tar: 0.0198 \n",
      "l0: 0.017836, l1: 0.019248, l2: 0.024673, l3: 0.034320, l4: 0.064658, l5: 0.140096, l6: 0.287899\n",
      "\n",
      "[epoch: 390/400, batch: 384/1000, ite: 51549] train loss: 1.1120, accuracy: 95.8500%, tar: 0.0198 \n",
      "l0: 0.020300, l1: 0.021703, l2: 0.030402, l3: 0.043673, l4: 0.077063, l5: 0.149009, l6: 0.293646\n",
      "\n",
      "[epoch: 390/400, batch: 392/1000, ite: 51550] train loss: 1.1119, accuracy: 95.1610%, tar: 0.0198 \n",
      "l0: 0.021498, l1: 0.023183, l2: 0.032725, l3: 0.048785, l4: 0.089989, l5: 0.200677, l6: 0.368577\n",
      "\n",
      "[epoch: 390/400, batch: 400/1000, ite: 51551] train loss: 1.1119, accuracy: 94.6235%, tar: 0.0198 \n",
      "l0: 0.021369, l1: 0.023019, l2: 0.032508, l3: 0.052769, l4: 0.090512, l5: 0.171957, l6: 0.381557\n",
      "\n",
      "[epoch: 390/400, batch: 408/1000, ite: 51552] train loss: 1.1119, accuracy: 94.9895%, tar: 0.0198 \n",
      "l0: 0.023956, l1: 0.026366, l2: 0.037080, l3: 0.056236, l4: 0.096471, l5: 0.226141, l6: 0.522475\n",
      "\n",
      "[epoch: 390/400, batch: 416/1000, ite: 51553] train loss: 1.1122, accuracy: 93.7423%, tar: 0.0198 \n",
      "l0: 0.020408, l1: 0.021182, l2: 0.029321, l3: 0.044985, l4: 0.082385, l5: 0.165380, l6: 0.397363\n",
      "\n",
      "[epoch: 390/400, batch: 424/1000, ite: 51554] train loss: 1.1122, accuracy: 94.8528%, tar: 0.0198 \n",
      "l0: 0.024539, l1: 0.025958, l2: 0.033233, l3: 0.047353, l4: 0.082922, l5: 0.181599, l6: 0.431703\n",
      "\n",
      "[epoch: 390/400, batch: 432/1000, ite: 51555] train loss: 1.1123, accuracy: 93.8961%, tar: 0.0198 \n",
      "l0: 0.020010, l1: 0.022034, l2: 0.030810, l3: 0.044927, l4: 0.093779, l5: 0.180258, l6: 0.404074\n",
      "\n",
      "[epoch: 390/400, batch: 440/1000, ite: 51556] train loss: 1.1124, accuracy: 94.6521%, tar: 0.0198 \n",
      "l0: 0.021159, l1: 0.022824, l2: 0.030631, l3: 0.048562, l4: 0.095423, l5: 0.206079, l6: 0.424714\n",
      "\n",
      "[epoch: 390/400, batch: 448/1000, ite: 51557] train loss: 1.1125, accuracy: 93.7401%, tar: 0.0198 \n",
      "l0: 0.017892, l1: 0.019071, l2: 0.026337, l3: 0.038261, l4: 0.070254, l5: 0.187736, l6: 0.384265\n",
      "\n",
      "[epoch: 390/400, batch: 456/1000, ite: 51558] train loss: 1.1125, accuracy: 94.7042%, tar: 0.0198 \n",
      "l0: 0.022188, l1: 0.024202, l2: 0.034350, l3: 0.054569, l4: 0.127239, l5: 0.256730, l6: 0.449956\n",
      "\n",
      "[epoch: 390/400, batch: 464/1000, ite: 51559] train loss: 1.1127, accuracy: 93.8392%, tar: 0.0198 \n",
      "l0: 0.018933, l1: 0.020418, l2: 0.028470, l3: 0.046168, l4: 0.085848, l5: 0.197533, l6: 0.494110\n",
      "\n",
      "[epoch: 390/400, batch: 472/1000, ite: 51560] train loss: 1.1129, accuracy: 94.1270%, tar: 0.0198 \n",
      "l0: 0.019842, l1: 0.021100, l2: 0.029190, l3: 0.042996, l4: 0.080052, l5: 0.171332, l6: 0.363059\n",
      "\n",
      "[epoch: 390/400, batch: 480/1000, ite: 51561] train loss: 1.1129, accuracy: 94.6930%, tar: 0.0198 \n",
      "l0: 0.016956, l1: 0.018076, l2: 0.025383, l3: 0.038014, l4: 0.067421, l5: 0.135715, l6: 0.257761\n",
      "\n",
      "[epoch: 390/400, batch: 488/1000, ite: 51562] train loss: 1.1127, accuracy: 95.9375%, tar: 0.0198 \n",
      "l0: 0.019245, l1: 0.020685, l2: 0.029622, l3: 0.046741, l4: 0.092655, l5: 0.171413, l6: 0.319323\n",
      "\n",
      "[epoch: 390/400, batch: 496/1000, ite: 51563] train loss: 1.1126, accuracy: 95.1919%, tar: 0.0198 \n",
      "l0: 0.022722, l1: 0.023933, l2: 0.032746, l3: 0.047234, l4: 0.084087, l5: 0.197286, l6: 0.424478\n",
      "\n",
      "[epoch: 390/400, batch: 504/1000, ite: 51564] train loss: 1.1127, accuracy: 94.5772%, tar: 0.0198 \n",
      "l0: 0.018782, l1: 0.019667, l2: 0.026416, l3: 0.042787, l4: 0.092204, l5: 0.169552, l6: 0.407984\n",
      "\n",
      "[epoch: 390/400, batch: 512/1000, ite: 51565] train loss: 1.1128, accuracy: 95.3088%, tar: 0.0198 \n",
      "l0: 0.025377, l1: 0.026817, l2: 0.035241, l3: 0.050795, l4: 0.084994, l5: 0.181190, l6: 0.413422\n",
      "\n",
      "[epoch: 390/400, batch: 520/1000, ite: 51566] train loss: 1.1128, accuracy: 93.7415%, tar: 0.0198 \n",
      "l0: 0.016004, l1: 0.016767, l2: 0.023825, l3: 0.037328, l4: 0.063265, l5: 0.114977, l6: 0.257347\n",
      "\n",
      "[epoch: 390/400, batch: 528/1000, ite: 51567] train loss: 1.1126, accuracy: 96.5172%, tar: 0.0198 \n",
      "l0: 0.016519, l1: 0.017911, l2: 0.025380, l3: 0.043777, l4: 0.077934, l5: 0.149542, l6: 0.273947\n",
      "\n",
      "[epoch: 390/400, batch: 536/1000, ite: 51568] train loss: 1.1125, accuracy: 96.3163%, tar: 0.0198 \n",
      "l0: 0.018432, l1: 0.019895, l2: 0.027552, l3: 0.041398, l4: 0.077417, l5: 0.184262, l6: 0.393826\n",
      "\n",
      "[epoch: 390/400, batch: 544/1000, ite: 51569] train loss: 1.1125, accuracy: 94.7819%, tar: 0.0198 \n",
      "l0: 0.013530, l1: 0.014796, l2: 0.022776, l3: 0.038945, l4: 0.077025, l5: 0.181673, l6: 0.374417\n",
      "\n",
      "[epoch: 390/400, batch: 552/1000, ite: 51570] train loss: 1.1125, accuracy: 95.8521%, tar: 0.0198 \n",
      "l0: 0.018689, l1: 0.019750, l2: 0.027073, l3: 0.039748, l4: 0.080676, l5: 0.161253, l6: 0.319449\n",
      "\n",
      "[epoch: 390/400, batch: 560/1000, ite: 51571] train loss: 1.1124, accuracy: 95.3510%, tar: 0.0198 \n",
      "l0: 0.017347, l1: 0.018292, l2: 0.024119, l3: 0.036790, l4: 0.064647, l5: 0.146180, l6: 0.308150\n",
      "\n",
      "[epoch: 390/400, batch: 568/1000, ite: 51572] train loss: 1.1123, accuracy: 96.0768%, tar: 0.0198 \n",
      "l0: 0.019824, l1: 0.021118, l2: 0.030262, l3: 0.047540, l4: 0.087815, l5: 0.192338, l6: 0.449502\n",
      "\n",
      "[epoch: 390/400, batch: 576/1000, ite: 51573] train loss: 1.1124, accuracy: 94.5088%, tar: 0.0198 \n",
      "l0: 0.023954, l1: 0.025307, l2: 0.033031, l3: 0.050248, l4: 0.103535, l5: 0.183754, l6: 0.345804\n",
      "\n",
      "[epoch: 390/400, batch: 584/1000, ite: 51574] train loss: 1.1124, accuracy: 94.7842%, tar: 0.0198 \n",
      "l0: 0.016279, l1: 0.017978, l2: 0.027264, l3: 0.042884, l4: 0.087404, l5: 0.161988, l6: 0.361245\n",
      "\n",
      "[epoch: 390/400, batch: 592/1000, ite: 51575] train loss: 1.1124, accuracy: 95.4422%, tar: 0.0198 \n",
      "l0: 0.018442, l1: 0.019654, l2: 0.027545, l3: 0.041360, l4: 0.070999, l5: 0.143590, l6: 0.277979\n",
      "\n",
      "[epoch: 390/400, batch: 600/1000, ite: 51576] train loss: 1.1123, accuracy: 95.4937%, tar: 0.0198 \n",
      "l0: 0.022932, l1: 0.024153, l2: 0.033395, l3: 0.050615, l4: 0.092228, l5: 0.208050, l6: 0.542915\n",
      "\n",
      "[epoch: 390/400, batch: 608/1000, ite: 51577] train loss: 1.1125, accuracy: 93.0596%, tar: 0.0198 \n",
      "l0: 0.021471, l1: 0.022565, l2: 0.029978, l3: 0.043494, l4: 0.077168, l5: 0.162999, l6: 0.362454\n",
      "\n",
      "[epoch: 390/400, batch: 616/1000, ite: 51578] train loss: 1.1125, accuracy: 95.0209%, tar: 0.0198 \n",
      "l0: 0.025226, l1: 0.026061, l2: 0.033906, l3: 0.049169, l4: 0.092871, l5: 0.170323, l6: 0.437360\n",
      "\n",
      "[epoch: 390/400, batch: 624/1000, ite: 51579] train loss: 1.1126, accuracy: 93.9903%, tar: 0.0198 \n",
      "l0: 0.016076, l1: 0.017047, l2: 0.022769, l3: 0.031169, l4: 0.059372, l5: 0.123830, l6: 0.268369\n",
      "\n",
      "[epoch: 390/400, batch: 632/1000, ite: 51580] train loss: 1.1124, accuracy: 96.0864%, tar: 0.0198 \n",
      "l0: 0.021894, l1: 0.023102, l2: 0.031113, l3: 0.045030, l4: 0.089105, l5: 0.179716, l6: 0.394308\n",
      "\n",
      "[epoch: 390/400, batch: 640/1000, ite: 51581] train loss: 1.1125, accuracy: 94.8058%, tar: 0.0198 \n",
      "l0: 0.020834, l1: 0.022407, l2: 0.029390, l3: 0.047234, l4: 0.089741, l5: 0.181935, l6: 0.377538\n",
      "\n",
      "[epoch: 390/400, batch: 648/1000, ite: 51582] train loss: 1.1125, accuracy: 95.5340%, tar: 0.0198 \n",
      "l0: 0.022125, l1: 0.023801, l2: 0.035010, l3: 0.058444, l4: 0.129183, l5: 0.263347, l6: 0.507537\n",
      "\n",
      "[epoch: 390/400, batch: 656/1000, ite: 51583] train loss: 1.1128, accuracy: 93.3932%, tar: 0.0198 \n",
      "l0: 0.016804, l1: 0.017735, l2: 0.024698, l3: 0.038648, l4: 0.080710, l5: 0.164243, l6: 0.378256\n",
      "\n",
      "[epoch: 390/400, batch: 664/1000, ite: 51584] train loss: 1.1128, accuracy: 94.9456%, tar: 0.0198 \n",
      "l0: 0.021154, l1: 0.022066, l2: 0.031160, l3: 0.042481, l4: 0.067901, l5: 0.140551, l6: 0.291990\n",
      "\n",
      "[epoch: 390/400, batch: 672/1000, ite: 51585] train loss: 1.1126, accuracy: 95.7190%, tar: 0.0198 \n",
      "l0: 0.017144, l1: 0.018607, l2: 0.025619, l3: 0.037576, l4: 0.067704, l5: 0.139614, l6: 0.304901\n",
      "\n",
      "[epoch: 390/400, batch: 680/1000, ite: 51586] train loss: 1.1125, accuracy: 96.1522%, tar: 0.0198 \n",
      "l0: 0.020532, l1: 0.021974, l2: 0.029992, l3: 0.045841, l4: 0.092597, l5: 0.187426, l6: 0.338296\n",
      "\n",
      "[epoch: 390/400, batch: 688/1000, ite: 51587] train loss: 1.1125, accuracy: 95.2942%, tar: 0.0198 \n",
      "l0: 0.016840, l1: 0.017763, l2: 0.025487, l3: 0.038977, l4: 0.073476, l5: 0.168514, l6: 0.383161\n",
      "\n",
      "[epoch: 390/400, batch: 696/1000, ite: 51588] train loss: 1.1125, accuracy: 95.7361%, tar: 0.0198 \n",
      "l0: 0.017509, l1: 0.018980, l2: 0.028264, l3: 0.048078, l4: 0.090680, l5: 0.183414, l6: 0.387982\n",
      "\n",
      "[epoch: 390/400, batch: 704/1000, ite: 51589] train loss: 1.1125, accuracy: 95.5451%, tar: 0.0198 \n",
      "l0: 0.019772, l1: 0.021673, l2: 0.031079, l3: 0.048507, l4: 0.093868, l5: 0.180752, l6: 0.373031\n",
      "\n",
      "[epoch: 390/400, batch: 712/1000, ite: 51590] train loss: 1.1125, accuracy: 95.5095%, tar: 0.0198 \n",
      "l0: 0.022658, l1: 0.024313, l2: 0.033145, l3: 0.048972, l4: 0.084585, l5: 0.190494, l6: 0.408083\n",
      "\n",
      "[epoch: 390/400, batch: 720/1000, ite: 51591] train loss: 1.1126, accuracy: 94.1075%, tar: 0.0198 \n",
      "l0: 0.015195, l1: 0.015866, l2: 0.021182, l3: 0.033306, l4: 0.067189, l5: 0.115102, l6: 0.315599\n",
      "\n",
      "[epoch: 390/400, batch: 728/1000, ite: 51592] train loss: 1.1125, accuracy: 95.8470%, tar: 0.0198 \n",
      "l0: 0.016579, l1: 0.017961, l2: 0.026621, l3: 0.039350, l4: 0.074458, l5: 0.143550, l6: 0.280258\n",
      "\n",
      "[epoch: 390/400, batch: 736/1000, ite: 51593] train loss: 1.1123, accuracy: 96.1628%, tar: 0.0198 \n",
      "l0: 0.030227, l1: 0.032929, l2: 0.043986, l3: 0.068962, l4: 0.135031, l5: 0.282171, l6: 0.500544\n",
      "\n",
      "[epoch: 390/400, batch: 744/1000, ite: 51594] train loss: 1.1126, accuracy: 92.9726%, tar: 0.0198 \n",
      "l0: 0.021426, l1: 0.023222, l2: 0.030388, l3: 0.047990, l4: 0.091492, l5: 0.195482, l6: 0.407175\n",
      "\n",
      "[epoch: 390/400, batch: 752/1000, ite: 51595] train loss: 1.1127, accuracy: 94.4995%, tar: 0.0198 \n",
      "l0: 0.020245, l1: 0.021954, l2: 0.031026, l3: 0.054012, l4: 0.127913, l5: 0.246596, l6: 0.461666\n",
      "\n",
      "[epoch: 390/400, batch: 760/1000, ite: 51596] train loss: 1.1129, accuracy: 94.7277%, tar: 0.0198 \n",
      "l0: 0.019730, l1: 0.020327, l2: 0.026631, l3: 0.039762, l4: 0.060973, l5: 0.117024, l6: 0.238852\n",
      "\n",
      "[epoch: 390/400, batch: 768/1000, ite: 51597] train loss: 1.1127, accuracy: 95.8291%, tar: 0.0198 \n",
      "l0: 0.016826, l1: 0.017650, l2: 0.023810, l3: 0.034248, l4: 0.062325, l5: 0.130656, l6: 0.272335\n",
      "\n",
      "[epoch: 390/400, batch: 776/1000, ite: 51598] train loss: 1.1125, accuracy: 95.5308%, tar: 0.0198 \n",
      "l0: 0.024367, l1: 0.025176, l2: 0.031366, l3: 0.045074, l4: 0.084921, l5: 0.169213, l6: 0.317975\n",
      "\n",
      "[epoch: 390/400, batch: 784/1000, ite: 51599] train loss: 1.1125, accuracy: 94.4202%, tar: 0.0198 \n",
      "l0: 0.022858, l1: 0.023795, l2: 0.031026, l3: 0.047662, l4: 0.097938, l5: 0.243250, l6: 0.481296\n",
      "\n",
      "[epoch: 390/400, batch: 792/1000, ite: 51600] train loss: 1.1127, accuracy: 93.6034%, tar: 0.0198 \n",
      "l0: 0.025372, l1: 0.026599, l2: 0.035778, l3: 0.052501, l4: 0.096291, l5: 0.222252, l6: 0.478641\n",
      "\n",
      "[epoch: 390/400, batch: 800/1000, ite: 51601] train loss: 1.1129, accuracy: 93.6214%, tar: 0.0198 \n",
      "l0: 0.017095, l1: 0.017812, l2: 0.023179, l3: 0.034748, l4: 0.060645, l5: 0.139611, l6: 0.329089\n",
      "\n",
      "[epoch: 390/400, batch: 808/1000, ite: 51602] train loss: 1.1128, accuracy: 95.7705%, tar: 0.0198 \n",
      "l0: 0.019667, l1: 0.021151, l2: 0.028531, l3: 0.044878, l4: 0.083256, l5: 0.169050, l6: 0.318865\n",
      "\n",
      "[epoch: 390/400, batch: 816/1000, ite: 51603] train loss: 1.1127, accuracy: 95.0997%, tar: 0.0198 \n",
      "l0: 0.020541, l1: 0.021697, l2: 0.028119, l3: 0.042250, l4: 0.074900, l5: 0.136958, l6: 0.267281\n",
      "\n",
      "[epoch: 390/400, batch: 824/1000, ite: 51604] train loss: 1.1126, accuracy: 95.4435%, tar: 0.0198 \n",
      "l0: 0.016207, l1: 0.016947, l2: 0.023945, l3: 0.034998, l4: 0.071658, l5: 0.137499, l6: 0.319797\n",
      "\n",
      "[epoch: 390/400, batch: 832/1000, ite: 51605] train loss: 1.1125, accuracy: 95.8990%, tar: 0.0198 \n",
      "l0: 0.024726, l1: 0.025706, l2: 0.032822, l3: 0.044413, l4: 0.076294, l5: 0.148159, l6: 0.308812\n",
      "\n",
      "[epoch: 390/400, batch: 840/1000, ite: 51606] train loss: 1.1124, accuracy: 95.0127%, tar: 0.0198 \n",
      "l0: 0.025360, l1: 0.026742, l2: 0.035886, l3: 0.050646, l4: 0.083690, l5: 0.162856, l6: 0.323435\n",
      "\n",
      "[epoch: 390/400, batch: 848/1000, ite: 51607] train loss: 1.1123, accuracy: 95.2551%, tar: 0.0198 \n",
      "l0: 0.016362, l1: 0.017531, l2: 0.024777, l3: 0.040287, l4: 0.076583, l5: 0.147841, l6: 0.328179\n",
      "\n",
      "[epoch: 390/400, batch: 856/1000, ite: 51608] train loss: 1.1122, accuracy: 95.3518%, tar: 0.0198 \n",
      "l0: 0.018162, l1: 0.019802, l2: 0.027565, l3: 0.041844, l4: 0.080612, l5: 0.188810, l6: 0.410439\n",
      "\n",
      "[epoch: 390/400, batch: 864/1000, ite: 51609] train loss: 1.1123, accuracy: 94.0960%, tar: 0.0198 \n",
      "l0: 0.021640, l1: 0.022763, l2: 0.028433, l3: 0.039733, l4: 0.071889, l5: 0.143788, l6: 0.332805\n",
      "\n",
      "[epoch: 390/400, batch: 872/1000, ite: 51610] train loss: 1.1122, accuracy: 94.8165%, tar: 0.0198 \n",
      "l0: 0.021821, l1: 0.023458, l2: 0.032509, l3: 0.049164, l4: 0.101878, l5: 0.226265, l6: 0.392435\n",
      "\n",
      "[epoch: 390/400, batch: 880/1000, ite: 51611] train loss: 1.1123, accuracy: 94.3416%, tar: 0.0198 \n",
      "l0: 0.024222, l1: 0.025541, l2: 0.034463, l3: 0.054584, l4: 0.097024, l5: 0.191604, l6: 0.376426\n",
      "\n",
      "[epoch: 390/400, batch: 888/1000, ite: 51612] train loss: 1.1124, accuracy: 94.1791%, tar: 0.0198 \n",
      "l0: 0.018508, l1: 0.019534, l2: 0.025632, l3: 0.041489, l4: 0.073298, l5: 0.136965, l6: 0.326510\n",
      "\n",
      "[epoch: 390/400, batch: 896/1000, ite: 51613] train loss: 1.1123, accuracy: 95.3957%, tar: 0.0198 \n",
      "l0: 0.021865, l1: 0.022576, l2: 0.029806, l3: 0.044641, l4: 0.075532, l5: 0.143464, l6: 0.326286\n",
      "\n",
      "[epoch: 390/400, batch: 904/1000, ite: 51614] train loss: 1.1122, accuracy: 94.7058%, tar: 0.0198 \n",
      "l0: 0.022344, l1: 0.023863, l2: 0.032905, l3: 0.047654, l4: 0.098400, l5: 0.205195, l6: 0.419213\n",
      "\n",
      "[epoch: 390/400, batch: 912/1000, ite: 51615] train loss: 1.1123, accuracy: 94.3967%, tar: 0.0198 \n",
      "l0: 0.021983, l1: 0.023033, l2: 0.032186, l3: 0.047761, l4: 0.076046, l5: 0.164541, l6: 0.407440\n",
      "\n",
      "[epoch: 390/400, batch: 920/1000, ite: 51616] train loss: 1.1124, accuracy: 94.8661%, tar: 0.0198 \n",
      "l0: 0.023155, l1: 0.025133, l2: 0.035351, l3: 0.060672, l4: 0.117006, l5: 0.248690, l6: 0.529809\n",
      "\n",
      "[epoch: 390/400, batch: 928/1000, ite: 51617] train loss: 1.1126, accuracy: 93.9710%, tar: 0.0198 \n",
      "l0: 0.021205, l1: 0.024551, l2: 0.037219, l3: 0.058465, l4: 0.122765, l5: 0.313677, l6: 0.529482\n",
      "\n",
      "[epoch: 390/400, batch: 936/1000, ite: 51618] train loss: 1.1130, accuracy: 94.2661%, tar: 0.0198 \n",
      "l0: 0.019688, l1: 0.021424, l2: 0.030198, l3: 0.046556, l4: 0.085322, l5: 0.177419, l6: 0.412442\n",
      "\n",
      "[epoch: 390/400, batch: 944/1000, ite: 51619] train loss: 1.1130, accuracy: 94.7639%, tar: 0.0198 \n",
      "l0: 0.022678, l1: 0.024140, l2: 0.032897, l3: 0.053325, l4: 0.113012, l5: 0.247036, l6: 0.503765\n",
      "\n",
      "[epoch: 390/400, batch: 952/1000, ite: 51620] train loss: 1.1133, accuracy: 93.4032%, tar: 0.0198 \n",
      "l0: 0.018372, l1: 0.019619, l2: 0.027804, l3: 0.039724, l4: 0.070255, l5: 0.129469, l6: 0.278146\n",
      "\n",
      "[epoch: 390/400, batch: 960/1000, ite: 51621] train loss: 1.1131, accuracy: 96.0617%, tar: 0.0198 \n",
      "l0: 0.023133, l1: 0.025694, l2: 0.036895, l3: 0.066136, l4: 0.120617, l5: 0.232682, l6: 0.503378\n",
      "\n",
      "[epoch: 390/400, batch: 968/1000, ite: 51622] train loss: 1.1134, accuracy: 94.0540%, tar: 0.0198 \n",
      "l0: 0.021556, l1: 0.022796, l2: 0.029975, l3: 0.046080, l4: 0.090298, l5: 0.216579, l6: 0.515424\n",
      "\n",
      "[epoch: 390/400, batch: 976/1000, ite: 51623] train loss: 1.1136, accuracy: 93.2466%, tar: 0.0198 \n",
      "l0: 0.017980, l1: 0.019079, l2: 0.027781, l3: 0.043385, l4: 0.075877, l5: 0.136010, l6: 0.312341\n",
      "\n",
      "[epoch: 390/400, batch: 984/1000, ite: 51624] train loss: 1.1135, accuracy: 95.3361%, tar: 0.0198 \n",
      "l0: 0.023677, l1: 0.025385, l2: 0.031933, l3: 0.048711, l4: 0.088830, l5: 0.176052, l6: 0.406708\n",
      "\n",
      "[epoch: 390/400, batch: 992/1000, ite: 51625] train loss: 1.1135, accuracy: 94.3355%, tar: 0.0198 \n",
      "l0: 0.020092, l1: 0.021261, l2: 0.029479, l3: 0.051942, l4: 0.111032, l5: 0.216154, l6: 0.533133\n",
      "\n",
      "[epoch: 390/400, batch: 1000/1000, ite: 51626] train loss: 1.1138, accuracy: 93.8554%, tar: 0.0198 \n",
      "l0: 0.020185, l1: 0.021510, l2: 0.027599, l3: 0.041629, l4: 0.073474, l5: 0.137856, l6: 0.276587\n",
      "\n",
      "[epoch: 391/400, batch: 8/1000, ite: 51627] train loss: 1.1136, accuracy: 95.4794%, tar: 0.0198 \n",
      "l0: 0.025365, l1: 0.026739, l2: 0.034480, l3: 0.052943, l4: 0.090051, l5: 0.155476, l6: 0.405065\n",
      "\n",
      "[epoch: 391/400, batch: 16/1000, ite: 51628] train loss: 1.1137, accuracy: 94.0507%, tar: 0.0198 \n",
      "l0: 0.016997, l1: 0.018493, l2: 0.025659, l3: 0.037494, l4: 0.073246, l5: 0.170070, l6: 0.322828\n",
      "\n",
      "[epoch: 391/400, batch: 24/1000, ite: 51629] train loss: 1.1136, accuracy: 95.6813%, tar: 0.0198 \n",
      "l0: 0.025328, l1: 0.026861, l2: 0.036247, l3: 0.056497, l4: 0.092299, l5: 0.166872, l6: 0.344067\n",
      "\n",
      "[epoch: 391/400, batch: 32/1000, ite: 51630] train loss: 1.1136, accuracy: 94.9498%, tar: 0.0198 \n",
      "l0: 0.024146, l1: 0.025823, l2: 0.032553, l3: 0.049067, l4: 0.090470, l5: 0.209457, l6: 0.456143\n",
      "\n",
      "[epoch: 391/400, batch: 40/1000, ite: 51631] train loss: 1.1138, accuracy: 93.7163%, tar: 0.0198 \n",
      "l0: 0.024902, l1: 0.027015, l2: 0.038067, l3: 0.058349, l4: 0.112603, l5: 0.218281, l6: 0.520654\n",
      "\n",
      "[epoch: 391/400, batch: 48/1000, ite: 51632] train loss: 1.1140, accuracy: 94.1449%, tar: 0.0198 \n",
      "l0: 0.025231, l1: 0.026326, l2: 0.035827, l3: 0.051915, l4: 0.089375, l5: 0.164929, l6: 0.399932\n",
      "\n",
      "[epoch: 391/400, batch: 56/1000, ite: 51633] train loss: 1.1141, accuracy: 94.9779%, tar: 0.0198 \n",
      "l0: 0.021034, l1: 0.021855, l2: 0.029893, l3: 0.042366, l4: 0.070318, l5: 0.137430, l6: 0.320694\n",
      "\n",
      "[epoch: 391/400, batch: 64/1000, ite: 51634] train loss: 1.1140, accuracy: 94.8755%, tar: 0.0198 \n",
      "l0: 0.027010, l1: 0.029334, l2: 0.041048, l3: 0.063128, l4: 0.133008, l5: 0.286583, l6: 0.584454\n",
      "\n",
      "[epoch: 391/400, batch: 72/1000, ite: 51635] train loss: 1.1144, accuracy: 93.3868%, tar: 0.0198 \n",
      "l0: 0.025402, l1: 0.026471, l2: 0.035415, l3: 0.052313, l4: 0.090605, l5: 0.169426, l6: 0.387442\n",
      "\n",
      "[epoch: 391/400, batch: 80/1000, ite: 51636] train loss: 1.1144, accuracy: 94.4467%, tar: 0.0199 \n",
      "l0: 0.021501, l1: 0.023447, l2: 0.037165, l3: 0.059112, l4: 0.115132, l5: 0.247552, l6: 0.478112\n",
      "\n",
      "[epoch: 391/400, batch: 88/1000, ite: 51637] train loss: 1.1146, accuracy: 93.6357%, tar: 0.0199 \n",
      "l0: 0.019046, l1: 0.020960, l2: 0.029509, l3: 0.043650, l4: 0.075297, l5: 0.149587, l6: 0.309474\n",
      "\n",
      "[epoch: 391/400, batch: 96/1000, ite: 51638] train loss: 1.1145, accuracy: 96.0810%, tar: 0.0199 \n",
      "l0: 0.019133, l1: 0.021124, l2: 0.028306, l3: 0.045059, l4: 0.087117, l5: 0.165752, l6: 0.288329\n",
      "\n",
      "[epoch: 391/400, batch: 104/1000, ite: 51639] train loss: 1.1144, accuracy: 95.9658%, tar: 0.0199 \n",
      "l0: 0.022317, l1: 0.023482, l2: 0.030713, l3: 0.042595, l4: 0.074709, l5: 0.176545, l6: 0.395907\n",
      "\n",
      "[epoch: 391/400, batch: 112/1000, ite: 51640] train loss: 1.1145, accuracy: 94.1119%, tar: 0.0199 \n",
      "l0: 0.015789, l1: 0.016973, l2: 0.024070, l3: 0.039968, l4: 0.085251, l5: 0.153938, l6: 0.328738\n",
      "\n",
      "[epoch: 391/400, batch: 120/1000, ite: 51641] train loss: 1.1144, accuracy: 96.1110%, tar: 0.0199 \n",
      "l0: 0.021064, l1: 0.021881, l2: 0.030319, l3: 0.043294, l4: 0.070606, l5: 0.118815, l6: 0.273369\n",
      "\n",
      "[epoch: 391/400, batch: 128/1000, ite: 51642] train loss: 1.1142, accuracy: 95.7489%, tar: 0.0199 \n",
      "l0: 0.025220, l1: 0.027104, l2: 0.038126, l3: 0.059181, l4: 0.102004, l5: 0.219548, l6: 0.482522\n",
      "\n",
      "[epoch: 391/400, batch: 136/1000, ite: 51643] train loss: 1.1144, accuracy: 94.1171%, tar: 0.0199 \n",
      "l0: 0.023909, l1: 0.025653, l2: 0.033303, l3: 0.047275, l4: 0.078611, l5: 0.147696, l6: 0.374687\n",
      "\n",
      "[epoch: 391/400, batch: 144/1000, ite: 51644] train loss: 1.1144, accuracy: 94.4845%, tar: 0.0199 \n",
      "l0: 0.020003, l1: 0.021506, l2: 0.031192, l3: 0.044790, l4: 0.079609, l5: 0.164993, l6: 0.337916\n",
      "\n",
      "[epoch: 391/400, batch: 160/1000, ite: 51646] train loss: 1.1145, accuracy: 94.1531%, tar: 0.0199 \n",
      "l0: 0.021974, l1: 0.023049, l2: 0.031423, l3: 0.047595, l4: 0.080560, l5: 0.185778, l6: 0.351479\n",
      "\n",
      "[epoch: 391/400, batch: 168/1000, ite: 51647] train loss: 1.1145, accuracy: 94.9043%, tar: 0.0199 \n",
      "l0: 0.018225, l1: 0.019656, l2: 0.027337, l3: 0.043848, l4: 0.099508, l5: 0.184203, l6: 0.385121\n",
      "\n",
      "[epoch: 391/400, batch: 176/1000, ite: 51648] train loss: 1.1145, accuracy: 94.9841%, tar: 0.0199 \n",
      "l0: 0.016288, l1: 0.017531, l2: 0.025348, l3: 0.041956, l4: 0.078831, l5: 0.168468, l6: 0.318831\n",
      "\n",
      "[epoch: 391/400, batch: 184/1000, ite: 51649] train loss: 1.1144, accuracy: 96.0417%, tar: 0.0199 \n",
      "l0: 0.019288, l1: 0.020728, l2: 0.028143, l3: 0.049418, l4: 0.100905, l5: 0.194770, l6: 0.428740\n",
      "\n",
      "[epoch: 391/400, batch: 192/1000, ite: 51650] train loss: 1.1145, accuracy: 94.8232%, tar: 0.0199 \n",
      "l0: 0.020661, l1: 0.022144, l2: 0.029985, l3: 0.044201, l4: 0.093294, l5: 0.196538, l6: 0.373826\n",
      "\n",
      "[epoch: 391/400, batch: 200/1000, ite: 51651] train loss: 1.1145, accuracy: 94.8512%, tar: 0.0199 \n",
      "l0: 0.018429, l1: 0.020280, l2: 0.027143, l3: 0.044468, l4: 0.086140, l5: 0.186757, l6: 0.350123\n",
      "\n",
      "[epoch: 391/400, batch: 208/1000, ite: 51652] train loss: 1.1145, accuracy: 95.3688%, tar: 0.0199 \n",
      "l0: 0.015612, l1: 0.016936, l2: 0.025171, l3: 0.041682, l4: 0.074865, l5: 0.154842, l6: 0.296524\n",
      "\n",
      "[epoch: 391/400, batch: 216/1000, ite: 51653] train loss: 1.1144, accuracy: 95.7786%, tar: 0.0199 \n",
      "l0: 0.017949, l1: 0.019098, l2: 0.023993, l3: 0.032658, l4: 0.058834, l5: 0.111315, l6: 0.236418\n",
      "\n",
      "[epoch: 391/400, batch: 224/1000, ite: 51654] train loss: 1.1142, accuracy: 96.4382%, tar: 0.0199 \n",
      "l0: 0.016867, l1: 0.018563, l2: 0.026123, l3: 0.042991, l4: 0.083809, l5: 0.151590, l6: 0.337359\n",
      "\n",
      "[epoch: 391/400, batch: 232/1000, ite: 51655] train loss: 1.1141, accuracy: 95.6388%, tar: 0.0199 \n",
      "l0: 0.016039, l1: 0.017389, l2: 0.023075, l3: 0.035399, l4: 0.069234, l5: 0.167383, l6: 0.389587\n",
      "\n",
      "[epoch: 391/400, batch: 240/1000, ite: 51656] train loss: 1.1141, accuracy: 95.6205%, tar: 0.0198 \n",
      "l0: 0.019034, l1: 0.020203, l2: 0.027807, l3: 0.043323, l4: 0.075111, l5: 0.158236, l6: 0.356479\n",
      "\n",
      "[epoch: 391/400, batch: 248/1000, ite: 51657] train loss: 1.1141, accuracy: 94.9353%, tar: 0.0198 \n",
      "l0: 0.022506, l1: 0.024105, l2: 0.032457, l3: 0.048795, l4: 0.093066, l5: 0.212929, l6: 0.457603\n",
      "\n",
      "[epoch: 391/400, batch: 256/1000, ite: 51658] train loss: 1.1142, accuracy: 94.6985%, tar: 0.0199 \n",
      "l0: 0.017249, l1: 0.018817, l2: 0.026193, l3: 0.036467, l4: 0.066643, l5: 0.125936, l6: 0.291989\n",
      "\n",
      "[epoch: 391/400, batch: 264/1000, ite: 51659] train loss: 1.1141, accuracy: 95.6801%, tar: 0.0198 \n",
      "l0: 0.013247, l1: 0.014169, l2: 0.020625, l3: 0.032570, l4: 0.060430, l5: 0.135097, l6: 0.250592\n",
      "\n",
      "[epoch: 391/400, batch: 272/1000, ite: 51660] train loss: 1.1139, accuracy: 96.2344%, tar: 0.0198 \n",
      "l0: 0.023196, l1: 0.024498, l2: 0.030031, l3: 0.042082, l4: 0.073998, l5: 0.162963, l6: 0.399910\n",
      "\n",
      "[epoch: 391/400, batch: 280/1000, ite: 51661] train loss: 1.1139, accuracy: 94.6108%, tar: 0.0198 \n",
      "l0: 0.023644, l1: 0.025709, l2: 0.032646, l3: 0.044214, l4: 0.084037, l5: 0.176567, l6: 0.337886\n",
      "\n",
      "[epoch: 391/400, batch: 288/1000, ite: 51662] train loss: 1.1139, accuracy: 96.2769%, tar: 0.0198 \n",
      "l0: 0.022186, l1: 0.023986, l2: 0.032261, l3: 0.052055, l4: 0.107347, l5: 0.207299, l6: 0.356623\n",
      "\n",
      "[epoch: 391/400, batch: 296/1000, ite: 51663] train loss: 1.1139, accuracy: 95.5955%, tar: 0.0199 \n",
      "l0: 0.021739, l1: 0.023362, l2: 0.031485, l3: 0.052312, l4: 0.092398, l5: 0.181800, l6: 0.400657\n",
      "\n",
      "[epoch: 391/400, batch: 304/1000, ite: 51664] train loss: 1.1140, accuracy: 94.5536%, tar: 0.0199 \n",
      "l0: 0.022107, l1: 0.023800, l2: 0.032726, l3: 0.051134, l4: 0.093710, l5: 0.192019, l6: 0.408245\n",
      "\n",
      "[epoch: 391/400, batch: 312/1000, ite: 51665] train loss: 1.1141, accuracy: 94.0950%, tar: 0.0199 \n",
      "l0: 0.023552, l1: 0.026136, l2: 0.037273, l3: 0.061306, l4: 0.123565, l5: 0.270992, l6: 0.482387\n",
      "\n",
      "[epoch: 391/400, batch: 320/1000, ite: 51666] train loss: 1.1143, accuracy: 94.2398%, tar: 0.0199 \n",
      "l0: 0.020336, l1: 0.021898, l2: 0.032645, l3: 0.055423, l4: 0.093571, l5: 0.197579, l6: 0.322039\n",
      "\n",
      "[epoch: 391/400, batch: 328/1000, ite: 51667] train loss: 1.1143, accuracy: 95.4340%, tar: 0.0199 \n",
      "l0: 0.022890, l1: 0.024830, l2: 0.032652, l3: 0.047928, l4: 0.092125, l5: 0.209477, l6: 0.414387\n",
      "\n",
      "[epoch: 391/400, batch: 336/1000, ite: 51668] train loss: 1.1144, accuracy: 94.7664%, tar: 0.0199 \n",
      "l0: 0.017906, l1: 0.018837, l2: 0.025430, l3: 0.039302, l4: 0.082111, l5: 0.157854, l6: 0.366722\n",
      "\n",
      "[epoch: 391/400, batch: 344/1000, ite: 51669] train loss: 1.1143, accuracy: 94.5841%, tar: 0.0199 \n",
      "l0: 0.015456, l1: 0.016810, l2: 0.021761, l3: 0.031140, l4: 0.053538, l5: 0.109004, l6: 0.232233\n",
      "\n",
      "[epoch: 391/400, batch: 352/1000, ite: 51670] train loss: 1.1141, accuracy: 97.1058%, tar: 0.0199 \n",
      "l0: 0.024268, l1: 0.025566, l2: 0.034035, l3: 0.048176, l4: 0.076781, l5: 0.148447, l6: 0.363443\n",
      "\n",
      "[epoch: 391/400, batch: 360/1000, ite: 51671] train loss: 1.1141, accuracy: 94.8636%, tar: 0.0199 \n",
      "l0: 0.017622, l1: 0.018845, l2: 0.025120, l3: 0.036419, l4: 0.063177, l5: 0.122733, l6: 0.283019\n",
      "\n",
      "[epoch: 391/400, batch: 368/1000, ite: 51672] train loss: 1.1139, accuracy: 95.9075%, tar: 0.0199 \n",
      "l0: 0.017805, l1: 0.019434, l2: 0.028232, l3: 0.047650, l4: 0.079399, l5: 0.149998, l6: 0.306116\n",
      "\n",
      "[epoch: 391/400, batch: 376/1000, ite: 51673] train loss: 1.1138, accuracy: 95.6411%, tar: 0.0199 \n",
      "l0: 0.019219, l1: 0.020766, l2: 0.028034, l3: 0.046955, l4: 0.102520, l5: 0.205743, l6: 0.383492\n",
      "\n",
      "[epoch: 391/400, batch: 384/1000, ite: 51674] train loss: 1.1139, accuracy: 94.9916%, tar: 0.0199 \n",
      "l0: 0.017865, l1: 0.018496, l2: 0.023366, l3: 0.035184, l4: 0.065908, l5: 0.118887, l6: 0.254589\n",
      "\n",
      "[epoch: 391/400, batch: 392/1000, ite: 51675] train loss: 1.1137, accuracy: 96.1844%, tar: 0.0199 \n",
      "l0: 0.019893, l1: 0.020728, l2: 0.027458, l3: 0.041917, l4: 0.078965, l5: 0.153452, l6: 0.290098\n",
      "\n",
      "[epoch: 391/400, batch: 400/1000, ite: 51676] train loss: 1.1136, accuracy: 95.4139%, tar: 0.0199 \n",
      "l0: 0.026340, l1: 0.027729, l2: 0.035211, l3: 0.050466, l4: 0.102546, l5: 0.225927, l6: 0.429319\n",
      "\n",
      "[epoch: 391/400, batch: 408/1000, ite: 51677] train loss: 1.1137, accuracy: 94.2841%, tar: 0.0199 \n",
      "l0: 0.012777, l1: 0.013549, l2: 0.019322, l3: 0.030616, l4: 0.061142, l5: 0.114624, l6: 0.284191\n",
      "\n",
      "[epoch: 391/400, batch: 416/1000, ite: 51678] train loss: 1.1135, accuracy: 96.4616%, tar: 0.0199 \n",
      "l0: 0.019654, l1: 0.020689, l2: 0.030402, l3: 0.044768, l4: 0.079929, l5: 0.185518, l6: 0.379268\n",
      "\n",
      "[epoch: 391/400, batch: 424/1000, ite: 51679] train loss: 1.1136, accuracy: 95.1334%, tar: 0.0199 \n",
      "l0: 0.019337, l1: 0.020688, l2: 0.030448, l3: 0.046603, l4: 0.085074, l5: 0.177053, l6: 0.403531\n",
      "\n",
      "[epoch: 391/400, batch: 432/1000, ite: 51680] train loss: 1.1136, accuracy: 94.5331%, tar: 0.0199 \n",
      "l0: 0.021006, l1: 0.021867, l2: 0.028652, l3: 0.041345, l4: 0.074571, l5: 0.202215, l6: 0.361696\n",
      "\n",
      "[epoch: 391/400, batch: 440/1000, ite: 51681] train loss: 1.1136, accuracy: 94.7839%, tar: 0.0199 \n",
      "l0: 0.028712, l1: 0.030584, l2: 0.039488, l3: 0.056115, l4: 0.107385, l5: 0.235197, l6: 0.488958\n",
      "\n",
      "[epoch: 391/400, batch: 448/1000, ite: 51682] train loss: 1.1138, accuracy: 92.8979%, tar: 0.0199 \n",
      "l0: 0.016984, l1: 0.018160, l2: 0.025716, l3: 0.040707, l4: 0.075242, l5: 0.160003, l6: 0.347526\n",
      "\n",
      "[epoch: 391/400, batch: 456/1000, ite: 51683] train loss: 1.1138, accuracy: 95.0008%, tar: 0.0199 \n",
      "l0: 0.016128, l1: 0.016838, l2: 0.025081, l3: 0.038319, l4: 0.067048, l5: 0.124673, l6: 0.225881\n",
      "\n",
      "[epoch: 391/400, batch: 464/1000, ite: 51684] train loss: 1.1136, accuracy: 96.0599%, tar: 0.0199 \n",
      "l0: 0.022393, l1: 0.024085, l2: 0.033465, l3: 0.053108, l4: 0.101755, l5: 0.214552, l6: 0.396371\n",
      "\n",
      "[epoch: 391/400, batch: 472/1000, ite: 51685] train loss: 1.1136, accuracy: 93.8648%, tar: 0.0199 \n",
      "l0: 0.027654, l1: 0.029326, l2: 0.039956, l3: 0.061168, l4: 0.117433, l5: 0.230372, l6: 0.451568\n",
      "\n",
      "[epoch: 391/400, batch: 480/1000, ite: 51686] train loss: 1.1138, accuracy: 93.3800%, tar: 0.0199 \n",
      "l0: 0.020193, l1: 0.021822, l2: 0.029330, l3: 0.044117, l4: 0.084883, l5: 0.169595, l6: 0.335834\n",
      "\n",
      "[epoch: 391/400, batch: 488/1000, ite: 51687] train loss: 1.1138, accuracy: 95.0069%, tar: 0.0199 \n",
      "l0: 0.018363, l1: 0.019308, l2: 0.024965, l3: 0.035357, l4: 0.056221, l5: 0.101557, l6: 0.251854\n",
      "\n",
      "[epoch: 391/400, batch: 496/1000, ite: 51688] train loss: 1.1136, accuracy: 95.6809%, tar: 0.0199 \n",
      "l0: 0.022455, l1: 0.023745, l2: 0.031070, l3: 0.048156, l4: 0.103512, l5: 0.187412, l6: 0.421790\n",
      "\n",
      "[epoch: 391/400, batch: 504/1000, ite: 51689] train loss: 1.1136, accuracy: 94.5837%, tar: 0.0199 \n",
      "l0: 0.014428, l1: 0.015509, l2: 0.020632, l3: 0.032881, l4: 0.063456, l5: 0.141713, l6: 0.303697\n",
      "\n",
      "[epoch: 391/400, batch: 512/1000, ite: 51690] train loss: 1.1135, accuracy: 96.0210%, tar: 0.0199 \n",
      "l0: 0.023535, l1: 0.024223, l2: 0.029476, l3: 0.039703, l4: 0.065985, l5: 0.158005, l6: 0.326233\n",
      "\n",
      "[epoch: 391/400, batch: 520/1000, ite: 51691] train loss: 1.1135, accuracy: 95.0665%, tar: 0.0199 \n",
      "l0: 0.023554, l1: 0.025248, l2: 0.034828, l3: 0.051977, l4: 0.095828, l5: 0.205246, l6: 0.431994\n",
      "\n",
      "[epoch: 391/400, batch: 528/1000, ite: 51692] train loss: 1.1136, accuracy: 93.9050%, tar: 0.0199 \n",
      "l0: 0.019511, l1: 0.021165, l2: 0.028470, l3: 0.043472, l4: 0.094169, l5: 0.210556, l6: 0.375311\n",
      "\n",
      "[epoch: 391/400, batch: 536/1000, ite: 51693] train loss: 1.1136, accuracy: 95.2437%, tar: 0.0199 \n",
      "l0: 0.013347, l1: 0.014468, l2: 0.019574, l3: 0.029865, l4: 0.056703, l5: 0.112664, l6: 0.287565\n",
      "\n",
      "[epoch: 391/400, batch: 544/1000, ite: 51694] train loss: 1.1134, accuracy: 96.2424%, tar: 0.0199 \n",
      "l0: 0.030131, l1: 0.031843, l2: 0.041189, l3: 0.062460, l4: 0.121450, l5: 0.280709, l6: 0.662414\n",
      "\n",
      "[epoch: 391/400, batch: 552/1000, ite: 51695] train loss: 1.1139, accuracy: 91.6693%, tar: 0.0199 \n",
      "l0: 0.023546, l1: 0.025424, l2: 0.034798, l3: 0.052725, l4: 0.102427, l5: 0.209159, l6: 0.471755\n",
      "\n",
      "[epoch: 391/400, batch: 560/1000, ite: 51696] train loss: 1.1141, accuracy: 94.7820%, tar: 0.0199 \n",
      "l0: 0.024341, l1: 0.025622, l2: 0.032584, l3: 0.047023, l4: 0.077157, l5: 0.160682, l6: 0.361731\n",
      "\n",
      "[epoch: 391/400, batch: 568/1000, ite: 51697] train loss: 1.1140, accuracy: 94.5120%, tar: 0.0199 \n",
      "l0: 0.021773, l1: 0.022491, l2: 0.029572, l3: 0.044934, l4: 0.086018, l5: 0.170202, l6: 0.353533\n",
      "\n",
      "[epoch: 391/400, batch: 576/1000, ite: 51698] train loss: 1.1140, accuracy: 94.5996%, tar: 0.0199 \n",
      "l0: 0.025763, l1: 0.027330, l2: 0.034971, l3: 0.049462, l4: 0.092037, l5: 0.195561, l6: 0.411951\n",
      "\n",
      "[epoch: 391/400, batch: 584/1000, ite: 51699] train loss: 1.1141, accuracy: 94.1642%, tar: 0.0199 \n",
      "l0: 0.019486, l1: 0.021042, l2: 0.026368, l3: 0.038675, l4: 0.070939, l5: 0.180427, l6: 0.335163\n",
      "\n",
      "[epoch: 391/400, batch: 592/1000, ite: 51700] train loss: 1.1141, accuracy: 95.6208%, tar: 0.0199 \n",
      "l0: 0.028423, l1: 0.030021, l2: 0.040149, l3: 0.063503, l4: 0.129257, l5: 0.255998, l6: 0.530720\n",
      "\n",
      "[epoch: 391/400, batch: 600/1000, ite: 51701] train loss: 1.1144, accuracy: 92.8219%, tar: 0.0199 \n",
      "l0: 0.021628, l1: 0.023573, l2: 0.032937, l3: 0.048518, l4: 0.089906, l5: 0.154454, l6: 0.340646\n",
      "\n",
      "[epoch: 391/400, batch: 608/1000, ite: 51702] train loss: 1.1143, accuracy: 95.2718%, tar: 0.0199 \n",
      "l0: 0.020997, l1: 0.023194, l2: 0.033253, l3: 0.055267, l4: 0.096914, l5: 0.183642, l6: 0.421293\n",
      "\n",
      "[epoch: 391/400, batch: 616/1000, ite: 51703] train loss: 1.1144, accuracy: 94.5080%, tar: 0.0199 \n",
      "l0: 0.018424, l1: 0.019877, l2: 0.026140, l3: 0.039404, l4: 0.081864, l5: 0.157913, l6: 0.271912\n",
      "\n",
      "[epoch: 391/400, batch: 624/1000, ite: 51704] train loss: 1.1143, accuracy: 95.6726%, tar: 0.0199 \n",
      "l0: 0.024231, l1: 0.026279, l2: 0.036604, l3: 0.063844, l4: 0.112829, l5: 0.227711, l6: 0.427528\n",
      "\n",
      "[epoch: 391/400, batch: 632/1000, ite: 51705] train loss: 1.1144, accuracy: 94.2528%, tar: 0.0199 \n",
      "l0: 0.018801, l1: 0.020494, l2: 0.028303, l3: 0.043713, l4: 0.084526, l5: 0.167414, l6: 0.300388\n",
      "\n",
      "[epoch: 391/400, batch: 640/1000, ite: 51706] train loss: 1.1143, accuracy: 96.1416%, tar: 0.0199 \n",
      "l0: 0.017363, l1: 0.018891, l2: 0.027319, l3: 0.042110, l4: 0.079512, l5: 0.145782, l6: 0.313775\n",
      "\n",
      "[epoch: 391/400, batch: 648/1000, ite: 51707] train loss: 1.1142, accuracy: 96.1627%, tar: 0.0199 \n",
      "l0: 0.021378, l1: 0.023952, l2: 0.033863, l3: 0.058241, l4: 0.144121, l5: 0.319195, l6: 0.562320\n",
      "\n",
      "[epoch: 391/400, batch: 656/1000, ite: 51708] train loss: 1.1146, accuracy: 93.1393%, tar: 0.0199 \n",
      "l0: 0.015513, l1: 0.016451, l2: 0.021603, l3: 0.032262, l4: 0.060960, l5: 0.125272, l6: 0.277067\n",
      "\n",
      "[epoch: 391/400, batch: 664/1000, ite: 51709] train loss: 1.1144, accuracy: 95.8366%, tar: 0.0199 \n",
      "l0: 0.014483, l1: 0.015473, l2: 0.020793, l3: 0.032164, l4: 0.051055, l5: 0.083316, l6: 0.187644\n",
      "\n",
      "[epoch: 391/400, batch: 672/1000, ite: 51710] train loss: 1.1141, accuracy: 96.8229%, tar: 0.0199 \n",
      "l0: 0.021602, l1: 0.022941, l2: 0.032449, l3: 0.052919, l4: 0.091222, l5: 0.166361, l6: 0.317403\n",
      "\n",
      "[epoch: 391/400, batch: 680/1000, ite: 51711] train loss: 1.1141, accuracy: 95.7335%, tar: 0.0199 \n",
      "l0: 0.023192, l1: 0.025052, l2: 0.033743, l3: 0.049384, l4: 0.094543, l5: 0.186766, l6: 0.464025\n",
      "\n",
      "[epoch: 391/400, batch: 688/1000, ite: 51712] train loss: 1.1142, accuracy: 94.3734%, tar: 0.0199 \n",
      "l0: 0.022051, l1: 0.023120, l2: 0.032354, l3: 0.047594, l4: 0.081457, l5: 0.154399, l6: 0.338468\n",
      "\n",
      "[epoch: 391/400, batch: 696/1000, ite: 51713] train loss: 1.1141, accuracy: 95.3173%, tar: 0.0199 \n",
      "l0: 0.024099, l1: 0.025410, l2: 0.034509, l3: 0.051127, l4: 0.100920, l5: 0.211197, l6: 0.406571\n",
      "\n",
      "[epoch: 391/400, batch: 704/1000, ite: 51714] train loss: 1.1142, accuracy: 94.1089%, tar: 0.0199 \n",
      "l0: 0.017154, l1: 0.017768, l2: 0.024615, l3: 0.035199, l4: 0.059725, l5: 0.143628, l6: 0.408950\n",
      "\n",
      "[epoch: 391/400, batch: 712/1000, ite: 51715] train loss: 1.1142, accuracy: 95.3988%, tar: 0.0199 \n",
      "l0: 0.020243, l1: 0.022250, l2: 0.032290, l3: 0.053342, l4: 0.106172, l5: 0.270099, l6: 0.510241\n",
      "\n",
      "[epoch: 391/400, batch: 720/1000, ite: 51716] train loss: 1.1145, accuracy: 94.0279%, tar: 0.0199 \n",
      "l0: 0.016509, l1: 0.017823, l2: 0.026091, l3: 0.041356, l4: 0.077627, l5: 0.155770, l6: 0.350730\n",
      "\n",
      "[epoch: 391/400, batch: 728/1000, ite: 51717] train loss: 1.1144, accuracy: 95.9753%, tar: 0.0199 \n",
      "l0: 0.015896, l1: 0.016547, l2: 0.022231, l3: 0.032590, l4: 0.054157, l5: 0.105247, l6: 0.217030\n",
      "\n",
      "[epoch: 391/400, batch: 736/1000, ite: 51718] train loss: 1.1142, accuracy: 96.4577%, tar: 0.0199 \n",
      "l0: 0.016271, l1: 0.017385, l2: 0.023230, l3: 0.039612, l4: 0.068923, l5: 0.133417, l6: 0.380298\n",
      "\n",
      "[epoch: 391/400, batch: 744/1000, ite: 51719] train loss: 1.1142, accuracy: 94.7567%, tar: 0.0199 \n",
      "l0: 0.023189, l1: 0.024376, l2: 0.032348, l3: 0.046270, l4: 0.092952, l5: 0.186025, l6: 0.399225\n",
      "\n",
      "[epoch: 391/400, batch: 752/1000, ite: 51720] train loss: 1.1142, accuracy: 94.4035%, tar: 0.0199 \n",
      "l0: 0.020445, l1: 0.021778, l2: 0.029115, l3: 0.048843, l4: 0.088403, l5: 0.188835, l6: 0.404350\n",
      "\n",
      "[epoch: 391/400, batch: 760/1000, ite: 51721] train loss: 1.1143, accuracy: 94.2392%, tar: 0.0199 \n",
      "l0: 0.023009, l1: 0.024234, l2: 0.031058, l3: 0.047318, l4: 0.091260, l5: 0.198089, l6: 0.398717\n",
      "\n",
      "[epoch: 391/400, batch: 768/1000, ite: 51722] train loss: 1.1143, accuracy: 94.5074%, tar: 0.0199 \n",
      "l0: 0.024563, l1: 0.026569, l2: 0.037113, l3: 0.056298, l4: 0.104614, l5: 0.197779, l6: 0.381667\n",
      "\n",
      "[epoch: 391/400, batch: 776/1000, ite: 51723] train loss: 1.1144, accuracy: 95.0109%, tar: 0.0199 \n",
      "l0: 0.021337, l1: 0.022187, l2: 0.028205, l3: 0.038637, l4: 0.065885, l5: 0.145750, l6: 0.341909\n",
      "\n",
      "[epoch: 391/400, batch: 784/1000, ite: 51724] train loss: 1.1143, accuracy: 95.4565%, tar: 0.0199 \n",
      "l0: 0.021758, l1: 0.023008, l2: 0.030741, l3: 0.046342, l4: 0.081339, l5: 0.176447, l6: 0.446175\n",
      "\n",
      "[epoch: 391/400, batch: 792/1000, ite: 51725] train loss: 1.1144, accuracy: 94.9159%, tar: 0.0199 \n",
      "l0: 0.022347, l1: 0.023427, l2: 0.030578, l3: 0.043811, l4: 0.073964, l5: 0.143663, l6: 0.279856\n",
      "\n",
      "[epoch: 391/400, batch: 800/1000, ite: 51726] train loss: 1.1143, accuracy: 95.3781%, tar: 0.0199 \n",
      "l0: 0.019987, l1: 0.021094, l2: 0.028269, l3: 0.043684, l4: 0.088528, l5: 0.168136, l6: 0.387194\n",
      "\n",
      "[epoch: 391/400, batch: 808/1000, ite: 51727] train loss: 1.1143, accuracy: 94.7367%, tar: 0.0199 \n",
      "l0: 0.022511, l1: 0.023826, l2: 0.032034, l3: 0.048364, l4: 0.095260, l5: 0.202851, l6: 0.368501\n",
      "\n",
      "[epoch: 391/400, batch: 816/1000, ite: 51728] train loss: 1.1144, accuracy: 95.0219%, tar: 0.0199 \n",
      "l0: 0.022190, l1: 0.023932, l2: 0.032416, l3: 0.053472, l4: 0.107457, l5: 0.199404, l6: 0.373276\n",
      "\n",
      "[epoch: 391/400, batch: 824/1000, ite: 51729] train loss: 1.1144, accuracy: 94.7103%, tar: 0.0199 \n",
      "l0: 0.022700, l1: 0.024071, l2: 0.031255, l3: 0.044390, l4: 0.084314, l5: 0.159787, l6: 0.327387\n",
      "\n",
      "[epoch: 391/400, batch: 832/1000, ite: 51730] train loss: 1.1143, accuracy: 95.3374%, tar: 0.0199 \n",
      "l0: 0.017452, l1: 0.018935, l2: 0.027377, l3: 0.047299, l4: 0.080295, l5: 0.137098, l6: 0.278220\n",
      "\n",
      "[epoch: 391/400, batch: 840/1000, ite: 51731] train loss: 1.1142, accuracy: 96.3695%, tar: 0.0199 \n",
      "l0: 0.020861, l1: 0.022708, l2: 0.032319, l3: 0.054937, l4: 0.111759, l5: 0.256088, l6: 0.556940\n",
      "\n",
      "[epoch: 391/400, batch: 848/1000, ite: 51732] train loss: 1.1145, accuracy: 93.2160%, tar: 0.0199 \n",
      "l0: 0.021756, l1: 0.023847, l2: 0.032961, l3: 0.048157, l4: 0.088401, l5: 0.167461, l6: 0.312207\n",
      "\n",
      "[epoch: 391/400, batch: 856/1000, ite: 51733] train loss: 1.1144, accuracy: 95.6576%, tar: 0.0199 \n",
      "l0: 0.021588, l1: 0.023366, l2: 0.031091, l3: 0.042759, l4: 0.080641, l5: 0.178755, l6: 0.364013\n",
      "\n",
      "[epoch: 391/400, batch: 864/1000, ite: 51734] train loss: 1.1144, accuracy: 94.9894%, tar: 0.0199 \n",
      "l0: 0.023872, l1: 0.025948, l2: 0.036778, l3: 0.058835, l4: 0.102513, l5: 0.213639, l6: 0.459803\n",
      "\n",
      "[epoch: 391/400, batch: 872/1000, ite: 51735] train loss: 1.1146, accuracy: 93.7729%, tar: 0.0199 \n",
      "l0: 0.019712, l1: 0.021191, l2: 0.030073, l3: 0.047056, l4: 0.089490, l5: 0.188660, l6: 0.373848\n",
      "\n",
      "[epoch: 391/400, batch: 880/1000, ite: 51736] train loss: 1.1146, accuracy: 95.2225%, tar: 0.0199 \n",
      "l0: 0.016054, l1: 0.018074, l2: 0.025504, l3: 0.042664, l4: 0.089128, l5: 0.146291, l6: 0.292989\n",
      "\n",
      "[epoch: 391/400, batch: 888/1000, ite: 51737] train loss: 1.1145, accuracy: 96.8256%, tar: 0.0199 \n",
      "l0: 0.021327, l1: 0.023381, l2: 0.031801, l3: 0.047921, l4: 0.085607, l5: 0.183939, l6: 0.397907\n",
      "\n",
      "[epoch: 391/400, batch: 896/1000, ite: 51738] train loss: 1.1146, accuracy: 94.6510%, tar: 0.0199 \n",
      "l0: 0.024702, l1: 0.025360, l2: 0.033203, l3: 0.047073, l4: 0.088628, l5: 0.185465, l6: 0.381710\n",
      "\n",
      "[epoch: 391/400, batch: 904/1000, ite: 51739] train loss: 1.1146, accuracy: 94.3148%, tar: 0.0199 \n",
      "l0: 0.023228, l1: 0.025541, l2: 0.035372, l3: 0.052098, l4: 0.099524, l5: 0.214765, l6: 0.421495\n",
      "\n",
      "[epoch: 391/400, batch: 912/1000, ite: 51740] train loss: 1.1147, accuracy: 94.3762%, tar: 0.0199 \n",
      "l0: 0.019688, l1: 0.020987, l2: 0.032317, l3: 0.050896, l4: 0.100849, l5: 0.183843, l6: 0.384879\n",
      "\n",
      "[epoch: 391/400, batch: 920/1000, ite: 51741] train loss: 1.1147, accuracy: 95.4952%, tar: 0.0199 \n",
      "l0: 0.030976, l1: 0.033383, l2: 0.044679, l3: 0.070966, l4: 0.148929, l5: 0.265637, l6: 0.439252\n",
      "\n",
      "[epoch: 391/400, batch: 928/1000, ite: 51742] train loss: 1.1149, accuracy: 93.5233%, tar: 0.0199 \n",
      "l0: 0.015400, l1: 0.016172, l2: 0.022868, l3: 0.035921, l4: 0.068094, l5: 0.138339, l6: 0.300324\n",
      "\n",
      "[epoch: 391/400, batch: 936/1000, ite: 51743] train loss: 1.1148, accuracy: 95.6574%, tar: 0.0199 \n",
      "l0: 0.026104, l1: 0.028033, l2: 0.037016, l3: 0.057030, l4: 0.101819, l5: 0.219471, l6: 0.424265\n",
      "\n",
      "[epoch: 391/400, batch: 944/1000, ite: 51744] train loss: 1.1149, accuracy: 94.4382%, tar: 0.0199 \n",
      "l0: 0.019804, l1: 0.020775, l2: 0.028696, l3: 0.044296, l4: 0.074101, l5: 0.133127, l6: 0.312468\n",
      "\n",
      "[epoch: 391/400, batch: 952/1000, ite: 51745] train loss: 1.1148, accuracy: 94.9287%, tar: 0.0199 \n",
      "l0: 0.021003, l1: 0.021948, l2: 0.028960, l3: 0.042378, l4: 0.073454, l5: 0.155297, l6: 0.393766\n",
      "\n",
      "[epoch: 391/400, batch: 960/1000, ite: 51746] train loss: 1.1148, accuracy: 95.1299%, tar: 0.0199 \n",
      "l0: 0.017125, l1: 0.018543, l2: 0.025126, l3: 0.042473, l4: 0.081014, l5: 0.140975, l6: 0.334316\n",
      "\n",
      "[epoch: 391/400, batch: 968/1000, ite: 51747] train loss: 1.1148, accuracy: 95.7333%, tar: 0.0199 \n",
      "l0: 0.018122, l1: 0.019239, l2: 0.026850, l3: 0.042319, l4: 0.083232, l5: 0.163083, l6: 0.323320\n",
      "\n",
      "[epoch: 391/400, batch: 976/1000, ite: 51748] train loss: 1.1147, accuracy: 95.7590%, tar: 0.0199 \n",
      "l0: 0.019413, l1: 0.020280, l2: 0.025058, l3: 0.041066, l4: 0.070474, l5: 0.130150, l6: 0.274918\n",
      "\n",
      "[epoch: 391/400, batch: 984/1000, ite: 51749] train loss: 1.1146, accuracy: 95.7375%, tar: 0.0199 \n",
      "l0: 0.021646, l1: 0.023010, l2: 0.032462, l3: 0.053035, l4: 0.099586, l5: 0.197784, l6: 0.410670\n",
      "\n",
      "[epoch: 391/400, batch: 992/1000, ite: 51750] train loss: 1.1147, accuracy: 94.9997%, tar: 0.0199 \n",
      "l0: 0.019145, l1: 0.020037, l2: 0.027411, l3: 0.042784, l4: 0.077069, l5: 0.148813, l6: 0.265676\n",
      "\n",
      "[epoch: 391/400, batch: 1000/1000, ite: 51751] train loss: 1.1145, accuracy: 95.3488%, tar: 0.0199 \n",
      "l0: 0.018888, l1: 0.020032, l2: 0.027845, l3: 0.041368, l4: 0.068556, l5: 0.120286, l6: 0.282652\n",
      "\n",
      "[epoch: 392/400, batch: 8/1000, ite: 51752] train loss: 1.1144, accuracy: 95.8792%, tar: 0.0199 \n",
      "l0: 0.021224, l1: 0.022403, l2: 0.031577, l3: 0.050519, l4: 0.087093, l5: 0.179548, l6: 0.378648\n",
      "\n",
      "[epoch: 392/400, batch: 16/1000, ite: 51753] train loss: 1.1144, accuracy: 94.6239%, tar: 0.0199 \n",
      "l0: 0.020433, l1: 0.022451, l2: 0.031917, l3: 0.051277, l4: 0.107255, l5: 0.196531, l6: 0.410375\n",
      "\n",
      "[epoch: 392/400, batch: 24/1000, ite: 51754] train loss: 1.1145, accuracy: 94.8682%, tar: 0.0199 \n",
      "l0: 0.013318, l1: 0.014939, l2: 0.022268, l3: 0.036569, l4: 0.090067, l5: 0.180176, l6: 0.357727\n",
      "\n",
      "[epoch: 392/400, batch: 32/1000, ite: 51755] train loss: 1.1144, accuracy: 95.5426%, tar: 0.0199 \n",
      "l0: 0.024049, l1: 0.025094, l2: 0.033556, l3: 0.054566, l4: 0.124266, l5: 0.198498, l6: 0.398430\n",
      "\n",
      "[epoch: 392/400, batch: 40/1000, ite: 51756] train loss: 1.1145, accuracy: 94.2291%, tar: 0.0199 \n",
      "l0: 0.023006, l1: 0.024130, l2: 0.033232, l3: 0.047067, l4: 0.088815, l5: 0.156839, l6: 0.296897\n",
      "\n",
      "[epoch: 392/400, batch: 48/1000, ite: 51757] train loss: 1.1144, accuracy: 95.5039%, tar: 0.0199 \n",
      "l0: 0.021476, l1: 0.022719, l2: 0.029840, l3: 0.045066, l4: 0.084667, l5: 0.197495, l6: 0.395324\n",
      "\n",
      "[epoch: 392/400, batch: 56/1000, ite: 51758] train loss: 1.1145, accuracy: 94.6056%, tar: 0.0199 \n",
      "l0: 0.022003, l1: 0.024166, l2: 0.034904, l3: 0.056100, l4: 0.106693, l5: 0.208143, l6: 0.525737\n",
      "\n",
      "[epoch: 392/400, batch: 64/1000, ite: 51759] train loss: 1.1147, accuracy: 93.7887%, tar: 0.0199 \n",
      "l0: 0.017466, l1: 0.018644, l2: 0.024399, l3: 0.035802, l4: 0.073854, l5: 0.169981, l6: 0.333384\n",
      "\n",
      "[epoch: 392/400, batch: 72/1000, ite: 51760] train loss: 1.1147, accuracy: 95.3034%, tar: 0.0199 \n",
      "l0: 0.021755, l1: 0.022960, l2: 0.031434, l3: 0.046651, l4: 0.084195, l5: 0.220155, l6: 0.391948\n",
      "\n",
      "[epoch: 392/400, batch: 80/1000, ite: 51761] train loss: 1.1147, accuracy: 93.9614%, tar: 0.0199 \n",
      "l0: 0.015665, l1: 0.017413, l2: 0.025374, l3: 0.040600, l4: 0.074488, l5: 0.141517, l6: 0.318674\n",
      "\n",
      "[epoch: 392/400, batch: 88/1000, ite: 51762] train loss: 1.1146, accuracy: 96.1813%, tar: 0.0199 \n",
      "l0: 0.018786, l1: 0.019751, l2: 0.027399, l3: 0.042119, l4: 0.072174, l5: 0.149835, l6: 0.335650\n",
      "\n",
      "[epoch: 392/400, batch: 96/1000, ite: 51763] train loss: 1.1146, accuracy: 95.0876%, tar: 0.0199 \n",
      "l0: 0.013892, l1: 0.015480, l2: 0.022766, l3: 0.035351, l4: 0.059721, l5: 0.121199, l6: 0.266422\n",
      "\n",
      "[epoch: 392/400, batch: 104/1000, ite: 51764] train loss: 1.1144, accuracy: 96.5994%, tar: 0.0199 \n",
      "l0: 0.018613, l1: 0.020216, l2: 0.029310, l3: 0.047357, l4: 0.091999, l5: 0.206273, l6: 0.431525\n",
      "\n",
      "[epoch: 392/400, batch: 112/1000, ite: 51765] train loss: 1.1145, accuracy: 94.4831%, tar: 0.0199 \n",
      "l0: 0.019045, l1: 0.020568, l2: 0.027948, l3: 0.041610, l4: 0.071517, l5: 0.129449, l6: 0.290248\n",
      "\n",
      "[epoch: 392/400, batch: 120/1000, ite: 51766] train loss: 1.1144, accuracy: 95.9420%, tar: 0.0199 \n",
      "l0: 0.016955, l1: 0.017906, l2: 0.023999, l3: 0.035749, l4: 0.063473, l5: 0.144020, l6: 0.334386\n",
      "\n",
      "[epoch: 392/400, batch: 128/1000, ite: 51767] train loss: 1.1143, accuracy: 95.8246%, tar: 0.0199 \n",
      "l0: 0.015708, l1: 0.016604, l2: 0.024834, l3: 0.040515, l4: 0.067924, l5: 0.143729, l6: 0.310461\n",
      "\n",
      "[epoch: 392/400, batch: 136/1000, ite: 51768] train loss: 1.1142, accuracy: 96.0333%, tar: 0.0199 \n",
      "l0: 0.020659, l1: 0.022660, l2: 0.032226, l3: 0.053754, l4: 0.115418, l5: 0.219151, l6: 0.411776\n",
      "\n",
      "[epoch: 392/400, batch: 144/1000, ite: 51769] train loss: 1.1143, accuracy: 95.0382%, tar: 0.0199 \n",
      "l0: 0.018263, l1: 0.019481, l2: 0.027905, l3: 0.044835, l4: 0.096488, l5: 0.182934, l6: 0.354249\n",
      "\n",
      "[epoch: 392/400, batch: 152/1000, ite: 51770] train loss: 1.1143, accuracy: 95.6238%, tar: 0.0199 \n",
      "l0: 0.021877, l1: 0.022882, l2: 0.031166, l3: 0.045381, l4: 0.079749, l5: 0.168703, l6: 0.344467\n",
      "\n",
      "[epoch: 392/400, batch: 160/1000, ite: 51771] train loss: 1.1142, accuracy: 94.8098%, tar: 0.0199 \n",
      "l0: 0.020393, l1: 0.022275, l2: 0.032246, l3: 0.045702, l4: 0.094423, l5: 0.214813, l6: 0.427027\n",
      "\n",
      "[epoch: 392/400, batch: 168/1000, ite: 51772] train loss: 1.1143, accuracy: 94.4706%, tar: 0.0199 \n",
      "l0: 0.019925, l1: 0.021705, l2: 0.029140, l3: 0.039282, l4: 0.080711, l5: 0.179177, l6: 0.296027\n",
      "\n",
      "[epoch: 392/400, batch: 176/1000, ite: 51773] train loss: 1.1142, accuracy: 96.6283%, tar: 0.0199 \n",
      "l0: 0.029864, l1: 0.032009, l2: 0.043182, l3: 0.067326, l4: 0.133034, l5: 0.234330, l6: 0.433953\n",
      "\n",
      "[epoch: 392/400, batch: 184/1000, ite: 51774] train loss: 1.1144, accuracy: 94.6864%, tar: 0.0199 \n",
      "l0: 0.019733, l1: 0.020934, l2: 0.027066, l3: 0.040342, l4: 0.072739, l5: 0.140731, l6: 0.328023\n",
      "\n",
      "[epoch: 392/400, batch: 192/1000, ite: 51775] train loss: 1.1143, accuracy: 95.4201%, tar: 0.0199 \n",
      "l0: 0.017422, l1: 0.018750, l2: 0.026245, l3: 0.039638, l4: 0.065830, l5: 0.126363, l6: 0.286773\n",
      "\n",
      "[epoch: 392/400, batch: 200/1000, ite: 51776] train loss: 1.1142, accuracy: 95.7959%, tar: 0.0199 \n",
      "l0: 0.021859, l1: 0.023857, l2: 0.034860, l3: 0.057661, l4: 0.093200, l5: 0.188113, l6: 0.394611\n",
      "\n",
      "[epoch: 392/400, batch: 208/1000, ite: 51777] train loss: 1.1143, accuracy: 94.3680%, tar: 0.0199 \n",
      "l0: 0.024893, l1: 0.026064, l2: 0.034488, l3: 0.051712, l4: 0.102667, l5: 0.219364, l6: 0.488452\n",
      "\n",
      "[epoch: 392/400, batch: 216/1000, ite: 51778] train loss: 1.1145, accuracy: 93.2844%, tar: 0.0199 \n",
      "l0: 0.015880, l1: 0.017208, l2: 0.024298, l3: 0.035250, l4: 0.061031, l5: 0.110083, l6: 0.232119\n",
      "\n",
      "[epoch: 392/400, batch: 224/1000, ite: 51779] train loss: 1.1142, accuracy: 95.9583%, tar: 0.0199 \n",
      "l0: 0.026627, l1: 0.028386, l2: 0.037998, l3: 0.058090, l4: 0.103940, l5: 0.215407, l6: 0.427271\n",
      "\n",
      "[epoch: 392/400, batch: 232/1000, ite: 51780] train loss: 1.1144, accuracy: 94.0515%, tar: 0.0199 \n",
      "l0: 0.018439, l1: 0.019282, l2: 0.025520, l3: 0.037671, l4: 0.064871, l5: 0.125945, l6: 0.296679\n",
      "\n",
      "[epoch: 392/400, batch: 240/1000, ite: 51781] train loss: 1.1142, accuracy: 95.6351%, tar: 0.0199 \n",
      "l0: 0.021791, l1: 0.023627, l2: 0.033026, l3: 0.052918, l4: 0.115196, l5: 0.248922, l6: 0.538472\n",
      "\n",
      "[epoch: 392/400, batch: 248/1000, ite: 51782] train loss: 1.1145, accuracy: 93.7305%, tar: 0.0199 \n",
      "l0: 0.019320, l1: 0.020541, l2: 0.026425, l3: 0.039987, l4: 0.080559, l5: 0.173889, l6: 0.334650\n",
      "\n",
      "[epoch: 392/400, batch: 256/1000, ite: 51783] train loss: 1.1144, accuracy: 95.0377%, tar: 0.0199 \n",
      "l0: 0.022622, l1: 0.024661, l2: 0.033636, l3: 0.056456, l4: 0.125386, l5: 0.255096, l6: 0.504244\n",
      "\n",
      "[epoch: 392/400, batch: 264/1000, ite: 51784] train loss: 1.1147, accuracy: 93.5746%, tar: 0.0199 \n",
      "l0: 0.019181, l1: 0.020312, l2: 0.028530, l3: 0.042560, l4: 0.080562, l5: 0.203419, l6: 0.371760\n",
      "\n",
      "[epoch: 392/400, batch: 272/1000, ite: 51785] train loss: 1.1147, accuracy: 94.9813%, tar: 0.0199 \n",
      "l0: 0.021478, l1: 0.022568, l2: 0.031552, l3: 0.047842, l4: 0.084177, l5: 0.223184, l6: 0.424284\n",
      "\n",
      "[epoch: 392/400, batch: 280/1000, ite: 51786] train loss: 1.1148, accuracy: 93.7222%, tar: 0.0199 \n",
      "l0: 0.016932, l1: 0.018018, l2: 0.024459, l3: 0.039073, l4: 0.075117, l5: 0.150526, l6: 0.296052\n",
      "\n",
      "[epoch: 392/400, batch: 288/1000, ite: 51787] train loss: 1.1147, accuracy: 95.7109%, tar: 0.0199 \n",
      "l0: 0.017548, l1: 0.018158, l2: 0.024555, l3: 0.034901, l4: 0.057949, l5: 0.127913, l6: 0.252484\n",
      "\n",
      "[epoch: 392/400, batch: 296/1000, ite: 51788] train loss: 1.1145, accuracy: 96.1846%, tar: 0.0199 \n",
      "l0: 0.021548, l1: 0.022613, l2: 0.030934, l3: 0.046386, l4: 0.100683, l5: 0.217850, l6: 0.402776\n",
      "\n",
      "[epoch: 392/400, batch: 304/1000, ite: 51789] train loss: 1.1146, accuracy: 94.7758%, tar: 0.0199 \n",
      "l0: 0.019777, l1: 0.020965, l2: 0.028072, l3: 0.045094, l4: 0.093763, l5: 0.184589, l6: 0.376015\n",
      "\n",
      "[epoch: 392/400, batch: 312/1000, ite: 51790] train loss: 1.1146, accuracy: 95.2577%, tar: 0.0199 \n",
      "l0: 0.019857, l1: 0.020859, l2: 0.028911, l3: 0.043771, l4: 0.083659, l5: 0.164992, l6: 0.347151\n",
      "\n",
      "[epoch: 392/400, batch: 320/1000, ite: 51791] train loss: 1.1146, accuracy: 95.2353%, tar: 0.0199 \n",
      "l0: 0.017038, l1: 0.018097, l2: 0.023309, l3: 0.033934, l4: 0.063746, l5: 0.120263, l6: 0.268328\n",
      "\n",
      "[epoch: 392/400, batch: 328/1000, ite: 51792] train loss: 1.1144, accuracy: 96.1966%, tar: 0.0199 \n",
      "l0: 0.020052, l1: 0.021606, l2: 0.031115, l3: 0.051702, l4: 0.091538, l5: 0.184621, l6: 0.363729\n",
      "\n",
      "[epoch: 392/400, batch: 336/1000, ite: 51793] train loss: 1.1144, accuracy: 95.1584%, tar: 0.0199 \n",
      "l0: 0.017531, l1: 0.018793, l2: 0.024657, l3: 0.039234, l4: 0.071663, l5: 0.158001, l6: 0.336801\n",
      "\n",
      "[epoch: 392/400, batch: 344/1000, ite: 51794] train loss: 1.1143, accuracy: 94.9613%, tar: 0.0199 \n",
      "l0: 0.021198, l1: 0.022753, l2: 0.031400, l3: 0.049854, l4: 0.093685, l5: 0.195528, l6: 0.359489\n",
      "\n",
      "[epoch: 392/400, batch: 352/1000, ite: 51795] train loss: 1.1143, accuracy: 94.9659%, tar: 0.0199 \n",
      "l0: 0.026347, l1: 0.028469, l2: 0.036124, l3: 0.054361, l4: 0.097297, l5: 0.198783, l6: 0.414106\n",
      "\n",
      "[epoch: 392/400, batch: 360/1000, ite: 51796] train loss: 1.1144, accuracy: 94.5261%, tar: 0.0199 \n",
      "l0: 0.019928, l1: 0.021363, l2: 0.027412, l3: 0.042145, l4: 0.089503, l5: 0.197797, l6: 0.443100\n",
      "\n",
      "[epoch: 392/400, batch: 368/1000, ite: 51797] train loss: 1.1145, accuracy: 94.5089%, tar: 0.0199 \n",
      "l0: 0.019493, l1: 0.021131, l2: 0.028532, l3: 0.045291, l4: 0.093933, l5: 0.166509, l6: 0.356450\n",
      "\n",
      "[epoch: 392/400, batch: 376/1000, ite: 51798] train loss: 1.1145, accuracy: 94.8158%, tar: 0.0199 \n",
      "l0: 0.023498, l1: 0.024401, l2: 0.031144, l3: 0.043236, l4: 0.075391, l5: 0.153924, l6: 0.293157\n",
      "\n",
      "[epoch: 392/400, batch: 384/1000, ite: 51799] train loss: 1.1144, accuracy: 96.0230%, tar: 0.0199 \n",
      "l0: 0.020788, l1: 0.021843, l2: 0.031010, l3: 0.046749, l4: 0.080014, l5: 0.156482, l6: 0.340982\n",
      "\n",
      "[epoch: 392/400, batch: 392/1000, ite: 51800] train loss: 1.1144, accuracy: 95.0010%, tar: 0.0199 \n",
      "l0: 0.016449, l1: 0.019128, l2: 0.030193, l3: 0.053492, l4: 0.102459, l5: 0.191454, l6: 0.329148\n",
      "\n",
      "[epoch: 392/400, batch: 400/1000, ite: 51801] train loss: 1.1144, accuracy: 95.7910%, tar: 0.0199 \n",
      "l0: 0.019699, l1: 0.020550, l2: 0.027111, l3: 0.040959, l4: 0.071856, l5: 0.145615, l6: 0.310087\n",
      "\n",
      "[epoch: 392/400, batch: 408/1000, ite: 51802] train loss: 1.1143, accuracy: 95.2206%, tar: 0.0199 \n",
      "l0: 0.017387, l1: 0.017958, l2: 0.022970, l3: 0.032638, l4: 0.052153, l5: 0.106136, l6: 0.248505\n",
      "\n",
      "[epoch: 392/400, batch: 416/1000, ite: 51803] train loss: 1.1141, accuracy: 95.9720%, tar: 0.0199 \n",
      "l0: 0.020932, l1: 0.024052, l2: 0.035255, l3: 0.059725, l4: 0.105403, l5: 0.236970, l6: 0.465237\n",
      "\n",
      "[epoch: 392/400, batch: 424/1000, ite: 51804] train loss: 1.1142, accuracy: 94.9388%, tar: 0.0199 \n",
      "l0: 0.013762, l1: 0.015601, l2: 0.024450, l3: 0.043435, l4: 0.086174, l5: 0.180901, l6: 0.320720\n",
      "\n",
      "[epoch: 392/400, batch: 432/1000, ite: 51805] train loss: 1.1142, accuracy: 96.5991%, tar: 0.0199 \n",
      "l0: 0.024835, l1: 0.026547, l2: 0.036727, l3: 0.063623, l4: 0.141632, l5: 0.309571, l6: 0.620544\n",
      "\n",
      "[epoch: 392/400, batch: 440/1000, ite: 51806] train loss: 1.1146, accuracy: 91.5586%, tar: 0.0199 \n",
      "l0: 0.018807, l1: 0.019986, l2: 0.026896, l3: 0.042553, l4: 0.080773, l5: 0.151977, l6: 0.334239\n",
      "\n",
      "[epoch: 392/400, batch: 448/1000, ite: 51807] train loss: 1.1145, accuracy: 95.5442%, tar: 0.0199 \n",
      "l0: 0.023054, l1: 0.024780, l2: 0.033780, l3: 0.055114, l4: 0.115566, l5: 0.261696, l6: 0.493151\n",
      "\n",
      "[epoch: 392/400, batch: 456/1000, ite: 51808] train loss: 1.1147, accuracy: 93.3250%, tar: 0.0199 \n",
      "l0: 0.020730, l1: 0.021654, l2: 0.029085, l3: 0.044795, l4: 0.082602, l5: 0.166087, l6: 0.348703\n",
      "\n",
      "[epoch: 392/400, batch: 464/1000, ite: 51809] train loss: 1.1147, accuracy: 94.8823%, tar: 0.0199 \n",
      "l0: 0.023691, l1: 0.026077, l2: 0.038237, l3: 0.064127, l4: 0.120804, l5: 0.223718, l6: 0.454705\n",
      "\n",
      "[epoch: 392/400, batch: 472/1000, ite: 51810] train loss: 1.1149, accuracy: 94.1811%, tar: 0.0199 \n",
      "l0: 0.018358, l1: 0.019442, l2: 0.027812, l3: 0.045703, l4: 0.092219, l5: 0.199644, l6: 0.414688\n",
      "\n",
      "[epoch: 392/400, batch: 480/1000, ite: 51811] train loss: 1.1149, accuracy: 94.1142%, tar: 0.0199 \n",
      "l0: 0.014417, l1: 0.015215, l2: 0.021932, l3: 0.033499, l4: 0.059710, l5: 0.113610, l6: 0.272534\n",
      "\n",
      "[epoch: 392/400, batch: 488/1000, ite: 51812] train loss: 1.1148, accuracy: 96.2047%, tar: 0.0199 \n",
      "l0: 0.021007, l1: 0.022439, l2: 0.030426, l3: 0.047287, l4: 0.096696, l5: 0.257082, l6: 0.536003\n",
      "\n",
      "[epoch: 392/400, batch: 496/1000, ite: 51813] train loss: 1.1150, accuracy: 93.0017%, tar: 0.0199 \n",
      "l0: 0.025166, l1: 0.026799, l2: 0.036498, l3: 0.058487, l4: 0.122575, l5: 0.245638, l6: 0.501004\n",
      "\n",
      "[epoch: 392/400, batch: 504/1000, ite: 51814] train loss: 1.1152, accuracy: 94.3200%, tar: 0.0199 \n",
      "l0: 0.016320, l1: 0.017233, l2: 0.022720, l3: 0.031409, l4: 0.056683, l5: 0.119091, l6: 0.296441\n",
      "\n",
      "[epoch: 392/400, batch: 512/1000, ite: 51815] train loss: 1.1151, accuracy: 96.3719%, tar: 0.0199 \n",
      "l0: 0.018894, l1: 0.020041, l2: 0.026325, l3: 0.042428, l4: 0.089339, l5: 0.178907, l6: 0.330628\n",
      "\n",
      "[epoch: 392/400, batch: 520/1000, ite: 51816] train loss: 1.1151, accuracy: 95.3858%, tar: 0.0199 \n",
      "l0: 0.013490, l1: 0.014859, l2: 0.021942, l3: 0.042286, l4: 0.070896, l5: 0.137329, l6: 0.238166\n",
      "\n",
      "[epoch: 392/400, batch: 528/1000, ite: 51817] train loss: 1.1149, accuracy: 96.9630%, tar: 0.0199 \n",
      "l0: 0.022313, l1: 0.023161, l2: 0.031519, l3: 0.047742, l4: 0.086743, l5: 0.175149, l6: 0.362507\n",
      "\n",
      "[epoch: 392/400, batch: 536/1000, ite: 51818] train loss: 1.1149, accuracy: 94.5903%, tar: 0.0199 \n",
      "l0: 0.020576, l1: 0.021808, l2: 0.027723, l3: 0.041298, l4: 0.078027, l5: 0.186823, l6: 0.419729\n",
      "\n",
      "[epoch: 392/400, batch: 544/1000, ite: 51819] train loss: 1.1149, accuracy: 94.0650%, tar: 0.0199 \n",
      "l0: 0.021744, l1: 0.023149, l2: 0.031811, l3: 0.043961, l4: 0.077227, l5: 0.164515, l6: 0.363740\n",
      "\n",
      "[epoch: 392/400, batch: 552/1000, ite: 51820] train loss: 1.1149, accuracy: 94.9626%, tar: 0.0199 \n",
      "l0: 0.019994, l1: 0.021463, l2: 0.028396, l3: 0.045788, l4: 0.087370, l5: 0.179060, l6: 0.346282\n",
      "\n",
      "[epoch: 392/400, batch: 560/1000, ite: 51821] train loss: 1.1149, accuracy: 94.6976%, tar: 0.0199 \n",
      "l0: 0.020228, l1: 0.021570, l2: 0.030551, l3: 0.049240, l4: 0.091274, l5: 0.221990, l6: 0.403129\n",
      "\n",
      "[epoch: 392/400, batch: 568/1000, ite: 51822] train loss: 1.1150, accuracy: 94.4129%, tar: 0.0199 \n",
      "l0: 0.021195, l1: 0.021790, l2: 0.027321, l3: 0.036915, l4: 0.063540, l5: 0.128323, l6: 0.360789\n",
      "\n",
      "[epoch: 392/400, batch: 576/1000, ite: 51823] train loss: 1.1149, accuracy: 95.0361%, tar: 0.0199 \n",
      "l0: 0.014086, l1: 0.015097, l2: 0.022056, l3: 0.035850, l4: 0.068932, l5: 0.132689, l6: 0.220057\n",
      "\n",
      "[epoch: 392/400, batch: 584/1000, ite: 51824] train loss: 1.1147, accuracy: 96.7884%, tar: 0.0199 \n",
      "l0: 0.015787, l1: 0.016921, l2: 0.024984, l3: 0.040122, l4: 0.073346, l5: 0.151963, l6: 0.319259\n",
      "\n",
      "[epoch: 392/400, batch: 592/1000, ite: 51825] train loss: 1.1146, accuracy: 95.8404%, tar: 0.0199 \n",
      "l0: 0.017884, l1: 0.018666, l2: 0.025164, l3: 0.036971, l4: 0.067862, l5: 0.127199, l6: 0.321938\n",
      "\n",
      "[epoch: 392/400, batch: 600/1000, ite: 51826] train loss: 1.1145, accuracy: 95.8452%, tar: 0.0199 \n",
      "l0: 0.023194, l1: 0.024934, l2: 0.031654, l3: 0.043313, l4: 0.070606, l5: 0.148691, l6: 0.288537\n",
      "\n",
      "[epoch: 392/400, batch: 608/1000, ite: 51827] train loss: 1.1144, accuracy: 95.4970%, tar: 0.0199 \n",
      "l0: 0.019939, l1: 0.022660, l2: 0.033892, l3: 0.061070, l4: 0.141392, l5: 0.278529, l6: 0.483850\n",
      "\n",
      "[epoch: 392/400, batch: 616/1000, ite: 51828] train loss: 1.1147, accuracy: 94.7541%, tar: 0.0199 \n",
      "l0: 0.021430, l1: 0.022859, l2: 0.031996, l3: 0.046629, l4: 0.082883, l5: 0.159357, l6: 0.322318\n",
      "\n",
      "[epoch: 392/400, batch: 624/1000, ite: 51829] train loss: 1.1146, accuracy: 95.4928%, tar: 0.0199 \n",
      "l0: 0.021670, l1: 0.023227, l2: 0.031027, l3: 0.048623, l4: 0.099510, l5: 0.184299, l6: 0.390604\n",
      "\n",
      "[epoch: 392/400, batch: 632/1000, ite: 51830] train loss: 1.1146, accuracy: 95.4967%, tar: 0.0199 \n",
      "l0: 0.019601, l1: 0.020787, l2: 0.027781, l3: 0.040393, l4: 0.064669, l5: 0.129087, l6: 0.277500\n",
      "\n",
      "[epoch: 392/400, batch: 640/1000, ite: 51831] train loss: 1.1145, accuracy: 95.4431%, tar: 0.0199 \n",
      "l0: 0.024313, l1: 0.026900, l2: 0.037257, l3: 0.061730, l4: 0.108714, l5: 0.198769, l6: 0.418542\n",
      "\n",
      "[epoch: 392/400, batch: 648/1000, ite: 51832] train loss: 1.1146, accuracy: 95.0313%, tar: 0.0199 \n",
      "l0: 0.021498, l1: 0.022986, l2: 0.031318, l3: 0.046364, l4: 0.086355, l5: 0.192356, l6: 0.411195\n",
      "\n",
      "[epoch: 392/400, batch: 656/1000, ite: 51833] train loss: 1.1147, accuracy: 95.2581%, tar: 0.0199 \n",
      "l0: 0.015525, l1: 0.016896, l2: 0.024077, l3: 0.038523, l4: 0.077989, l5: 0.181447, l6: 0.339451\n",
      "\n",
      "[epoch: 392/400, batch: 664/1000, ite: 51834] train loss: 1.1146, accuracy: 95.9036%, tar: 0.0199 \n",
      "l0: 0.016271, l1: 0.018049, l2: 0.027567, l3: 0.045607, l4: 0.083690, l5: 0.174613, l6: 0.376914\n",
      "\n",
      "[epoch: 392/400, batch: 672/1000, ite: 51835] train loss: 1.1146, accuracy: 95.2839%, tar: 0.0199 \n",
      "l0: 0.017463, l1: 0.018458, l2: 0.025223, l3: 0.038138, l4: 0.070086, l5: 0.162105, l6: 0.341034\n",
      "\n",
      "[epoch: 392/400, batch: 680/1000, ite: 51836] train loss: 1.1146, accuracy: 95.3825%, tar: 0.0199 \n",
      "l0: 0.022460, l1: 0.023653, l2: 0.030352, l3: 0.044387, l4: 0.078554, l5: 0.153990, l6: 0.362263\n",
      "\n",
      "[epoch: 392/400, batch: 688/1000, ite: 51837] train loss: 1.1145, accuracy: 94.3357%, tar: 0.0199 \n",
      "l0: 0.024274, l1: 0.025850, l2: 0.035268, l3: 0.055856, l4: 0.105928, l5: 0.226227, l6: 0.436978\n",
      "\n",
      "[epoch: 392/400, batch: 696/1000, ite: 51838] train loss: 1.1147, accuracy: 93.6767%, tar: 0.0199 \n",
      "l0: 0.017963, l1: 0.019731, l2: 0.027355, l3: 0.044674, l4: 0.094306, l5: 0.193397, l6: 0.348591\n",
      "\n",
      "[epoch: 392/400, batch: 704/1000, ite: 51839] train loss: 1.1147, accuracy: 95.1026%, tar: 0.0199 \n",
      "l0: 0.019990, l1: 0.021929, l2: 0.030631, l3: 0.047881, l4: 0.093328, l5: 0.195242, l6: 0.359355\n",
      "\n",
      "[epoch: 392/400, batch: 712/1000, ite: 51840] train loss: 1.1147, accuracy: 95.3480%, tar: 0.0199 \n",
      "l0: 0.019397, l1: 0.020475, l2: 0.029322, l3: 0.041311, l4: 0.068509, l5: 0.130607, l6: 0.321908\n",
      "\n",
      "[epoch: 392/400, batch: 720/1000, ite: 51841] train loss: 1.1146, accuracy: 95.3531%, tar: 0.0199 \n",
      "l0: 0.016907, l1: 0.018157, l2: 0.023758, l3: 0.038924, l4: 0.068541, l5: 0.131569, l6: 0.286802\n",
      "\n",
      "[epoch: 392/400, batch: 728/1000, ite: 51842] train loss: 1.1145, accuracy: 96.2721%, tar: 0.0199 \n",
      "l0: 0.017673, l1: 0.019365, l2: 0.029307, l3: 0.048139, l4: 0.089028, l5: 0.160484, l6: 0.358865\n",
      "\n",
      "[epoch: 392/400, batch: 736/1000, ite: 51843] train loss: 1.1144, accuracy: 95.6170%, tar: 0.0199 \n",
      "l0: 0.016708, l1: 0.017792, l2: 0.025291, l3: 0.040195, l4: 0.070177, l5: 0.130537, l6: 0.310004\n",
      "\n",
      "[epoch: 392/400, batch: 744/1000, ite: 51844] train loss: 1.1143, accuracy: 95.2568%, tar: 0.0199 \n",
      "l0: 0.016847, l1: 0.018792, l2: 0.025813, l3: 0.037680, l4: 0.069488, l5: 0.151968, l6: 0.418955\n",
      "\n",
      "[epoch: 392/400, batch: 752/1000, ite: 51845] train loss: 1.1144, accuracy: 95.6974%, tar: 0.0199 \n",
      "l0: 0.022090, l1: 0.023172, l2: 0.030739, l3: 0.047159, l4: 0.089967, l5: 0.204799, l6: 0.401613\n",
      "\n",
      "[epoch: 392/400, batch: 760/1000, ite: 51846] train loss: 1.1144, accuracy: 93.4517%, tar: 0.0199 \n",
      "l0: 0.018774, l1: 0.020435, l2: 0.028904, l3: 0.044879, l4: 0.088631, l5: 0.190478, l6: 0.377390\n",
      "\n",
      "[epoch: 392/400, batch: 768/1000, ite: 51847] train loss: 1.1144, accuracy: 95.6440%, tar: 0.0199 \n",
      "l0: 0.022050, l1: 0.023683, l2: 0.033873, l3: 0.046319, l4: 0.090292, l5: 0.160888, l6: 0.413355\n",
      "\n",
      "[epoch: 392/400, batch: 776/1000, ite: 51848] train loss: 1.1145, accuracy: 95.3882%, tar: 0.0199 \n",
      "l0: 0.016955, l1: 0.017754, l2: 0.022500, l3: 0.035399, l4: 0.075029, l5: 0.160709, l6: 0.356259\n",
      "\n",
      "[epoch: 392/400, batch: 784/1000, ite: 51849] train loss: 1.1145, accuracy: 95.2225%, tar: 0.0199 \n",
      "l0: 0.021602, l1: 0.023699, l2: 0.033823, l3: 0.059211, l4: 0.136457, l5: 0.296463, l6: 0.521699\n",
      "\n",
      "[epoch: 392/400, batch: 792/1000, ite: 51850] train loss: 1.1147, accuracy: 94.2851%, tar: 0.0199 \n",
      "l0: 0.018670, l1: 0.019931, l2: 0.026233, l3: 0.043682, l4: 0.108570, l5: 0.215422, l6: 0.396658\n",
      "\n",
      "[epoch: 392/400, batch: 800/1000, ite: 51851] train loss: 1.1148, accuracy: 94.1752%, tar: 0.0199 \n",
      "l0: 0.021639, l1: 0.022558, l2: 0.030252, l3: 0.047946, l4: 0.083634, l5: 0.168412, l6: 0.352769\n",
      "\n",
      "[epoch: 392/400, batch: 808/1000, ite: 51852] train loss: 1.1148, accuracy: 94.5061%, tar: 0.0199 \n",
      "l0: 0.017417, l1: 0.018725, l2: 0.026975, l3: 0.044861, l4: 0.083618, l5: 0.180556, l6: 0.382448\n",
      "\n",
      "[epoch: 392/400, batch: 816/1000, ite: 51853] train loss: 1.1148, accuracy: 94.4800%, tar: 0.0199 \n",
      "l0: 0.025451, l1: 0.028668, l2: 0.041350, l3: 0.073249, l4: 0.139292, l5: 0.249325, l6: 0.490316\n",
      "\n",
      "[epoch: 392/400, batch: 824/1000, ite: 51854] train loss: 1.1150, accuracy: 94.2383%, tar: 0.0199 \n",
      "l0: 0.019711, l1: 0.020622, l2: 0.028154, l3: 0.038953, l4: 0.067158, l5: 0.167266, l6: 0.321077\n",
      "\n",
      "[epoch: 392/400, batch: 832/1000, ite: 51855] train loss: 1.1149, accuracy: 94.7248%, tar: 0.0199 \n",
      "l0: 0.025851, l1: 0.027731, l2: 0.036251, l3: 0.050416, l4: 0.089713, l5: 0.196645, l6: 0.411566\n",
      "\n",
      "[epoch: 392/400, batch: 840/1000, ite: 51856] train loss: 1.1150, accuracy: 94.2152%, tar: 0.0199 \n",
      "l0: 0.021088, l1: 0.022357, l2: 0.028572, l3: 0.042536, l4: 0.074619, l5: 0.145267, l6: 0.316617\n",
      "\n",
      "[epoch: 392/400, batch: 848/1000, ite: 51857] train loss: 1.1149, accuracy: 94.9232%, tar: 0.0199 \n",
      "l0: 0.021637, l1: 0.022952, l2: 0.030358, l3: 0.045733, l4: 0.072775, l5: 0.126373, l6: 0.262422\n",
      "\n",
      "[epoch: 392/400, batch: 856/1000, ite: 51858] train loss: 1.1148, accuracy: 95.8073%, tar: 0.0199 \n",
      "l0: 0.019078, l1: 0.020523, l2: 0.028425, l3: 0.043684, l4: 0.081201, l5: 0.164795, l6: 0.439883\n",
      "\n",
      "[epoch: 392/400, batch: 864/1000, ite: 51859] train loss: 1.1149, accuracy: 94.1492%, tar: 0.0199 \n",
      "l0: 0.018681, l1: 0.020551, l2: 0.030805, l3: 0.049167, l4: 0.097302, l5: 0.228895, l6: 0.522215\n",
      "\n",
      "[epoch: 392/400, batch: 872/1000, ite: 51860] train loss: 1.1151, accuracy: 93.6421%, tar: 0.0199 \n",
      "l0: 0.019941, l1: 0.021144, l2: 0.028466, l3: 0.039893, l4: 0.067755, l5: 0.130748, l6: 0.302567\n",
      "\n",
      "[epoch: 392/400, batch: 880/1000, ite: 51861] train loss: 1.1150, accuracy: 95.4780%, tar: 0.0199 \n",
      "l0: 0.017051, l1: 0.018594, l2: 0.027528, l3: 0.041774, l4: 0.076999, l5: 0.166784, l6: 0.310495\n",
      "\n",
      "[epoch: 392/400, batch: 888/1000, ite: 51862] train loss: 1.1149, accuracy: 96.0524%, tar: 0.0199 \n",
      "l0: 0.016768, l1: 0.017822, l2: 0.024307, l3: 0.035523, l4: 0.062074, l5: 0.127069, l6: 0.249306\n",
      "\n",
      "[epoch: 392/400, batch: 896/1000, ite: 51863] train loss: 1.1147, accuracy: 96.3788%, tar: 0.0199 \n",
      "l0: 0.019583, l1: 0.020631, l2: 0.029908, l3: 0.045755, l4: 0.076809, l5: 0.146624, l6: 0.337837\n",
      "\n",
      "[epoch: 392/400, batch: 904/1000, ite: 51864] train loss: 1.1147, accuracy: 95.7440%, tar: 0.0199 \n",
      "l0: 0.018335, l1: 0.019794, l2: 0.027558, l3: 0.048425, l4: 0.090481, l5: 0.188276, l6: 0.416109\n",
      "\n",
      "[epoch: 392/400, batch: 912/1000, ite: 51865] train loss: 1.1147, accuracy: 94.3090%, tar: 0.0199 \n",
      "l0: 0.015186, l1: 0.016220, l2: 0.021951, l3: 0.032904, l4: 0.057878, l5: 0.120184, l6: 0.269206\n",
      "\n",
      "[epoch: 392/400, batch: 920/1000, ite: 51866] train loss: 1.1145, accuracy: 96.4868%, tar: 0.0199 \n",
      "l0: 0.016909, l1: 0.017366, l2: 0.023757, l3: 0.034935, l4: 0.058948, l5: 0.110572, l6: 0.262316\n",
      "\n",
      "[epoch: 392/400, batch: 928/1000, ite: 51867] train loss: 1.1144, accuracy: 96.0737%, tar: 0.0199 \n",
      "l0: 0.018039, l1: 0.019169, l2: 0.026534, l3: 0.041880, l4: 0.083427, l5: 0.164031, l6: 0.330163\n",
      "\n",
      "[epoch: 392/400, batch: 936/1000, ite: 51868] train loss: 1.1143, accuracy: 95.8036%, tar: 0.0199 \n",
      "l0: 0.020145, l1: 0.021861, l2: 0.030189, l3: 0.050715, l4: 0.094488, l5: 0.225034, l6: 0.476695\n",
      "\n",
      "[epoch: 392/400, batch: 944/1000, ite: 51869] train loss: 1.1145, accuracy: 94.6761%, tar: 0.0199 \n",
      "l0: 0.019665, l1: 0.021065, l2: 0.028336, l3: 0.044756, l4: 0.085520, l5: 0.172273, l6: 0.446430\n",
      "\n",
      "[epoch: 392/400, batch: 952/1000, ite: 51870] train loss: 1.1146, accuracy: 94.5126%, tar: 0.0199 \n",
      "l0: 0.020128, l1: 0.021682, l2: 0.030397, l3: 0.050755, l4: 0.095219, l5: 0.209805, l6: 0.414023\n",
      "\n",
      "[epoch: 392/400, batch: 960/1000, ite: 51871] train loss: 1.1146, accuracy: 94.1843%, tar: 0.0199 \n",
      "l0: 0.024164, l1: 0.025309, l2: 0.035566, l3: 0.053737, l4: 0.092298, l5: 0.182376, l6: 0.344365\n",
      "\n",
      "[epoch: 392/400, batch: 968/1000, ite: 51872] train loss: 1.1146, accuracy: 95.3948%, tar: 0.0199 \n",
      "l0: 0.014996, l1: 0.015974, l2: 0.020137, l3: 0.029292, l4: 0.050004, l5: 0.100165, l6: 0.246566\n",
      "\n",
      "[epoch: 392/400, batch: 976/1000, ite: 51873] train loss: 1.1144, accuracy: 96.0984%, tar: 0.0199 \n",
      "l0: 0.016986, l1: 0.018001, l2: 0.025114, l3: 0.037106, l4: 0.066465, l5: 0.144767, l6: 0.301035\n",
      "\n",
      "[epoch: 392/400, batch: 984/1000, ite: 51874] train loss: 1.1143, accuracy: 95.9204%, tar: 0.0199 \n",
      "l0: 0.019488, l1: 0.020624, l2: 0.029436, l3: 0.044313, l4: 0.082366, l5: 0.159397, l6: 0.421196\n",
      "\n",
      "[epoch: 392/400, batch: 992/1000, ite: 51875] train loss: 1.1144, accuracy: 94.6553%, tar: 0.0199 \n",
      "l0: 0.017850, l1: 0.019641, l2: 0.031196, l3: 0.049385, l4: 0.109700, l5: 0.239125, l6: 0.437677\n",
      "\n",
      "[epoch: 392/400, batch: 1000/1000, ite: 51876] train loss: 1.1145, accuracy: 95.2263%, tar: 0.0199 \n",
      "l0: 0.023371, l1: 0.025749, l2: 0.037279, l3: 0.056799, l4: 0.103464, l5: 0.209751, l6: 0.454338\n",
      "\n",
      "[epoch: 393/400, batch: 8/1000, ite: 51877] train loss: 1.1146, accuracy: 94.3460%, tar: 0.0199 \n",
      "l0: 0.020312, l1: 0.022699, l2: 0.033821, l3: 0.055149, l4: 0.100497, l5: 0.206597, l6: 0.439736\n",
      "\n",
      "[epoch: 393/400, batch: 16/1000, ite: 51878] train loss: 1.1147, accuracy: 95.5115%, tar: 0.0199 \n",
      "l0: 0.022631, l1: 0.024082, l2: 0.032611, l3: 0.047464, l4: 0.082077, l5: 0.162058, l6: 0.322822\n",
      "\n",
      "[epoch: 393/400, batch: 24/1000, ite: 51879] train loss: 1.1147, accuracy: 95.3657%, tar: 0.0199 \n",
      "l0: 0.016448, l1: 0.017820, l2: 0.024598, l3: 0.045639, l4: 0.099671, l5: 0.191063, l6: 0.393119\n",
      "\n",
      "[epoch: 393/400, batch: 32/1000, ite: 51880] train loss: 1.1147, accuracy: 95.1122%, tar: 0.0199 \n",
      "l0: 0.018945, l1: 0.020543, l2: 0.029044, l3: 0.046214, l4: 0.078793, l5: 0.148807, l6: 0.298394\n",
      "\n",
      "[epoch: 393/400, batch: 40/1000, ite: 51881] train loss: 1.1146, accuracy: 95.9526%, tar: 0.0199 \n",
      "l0: 0.019396, l1: 0.020835, l2: 0.028739, l3: 0.042302, l4: 0.076813, l5: 0.135271, l6: 0.363868\n",
      "\n",
      "[epoch: 393/400, batch: 48/1000, ite: 51882] train loss: 1.1146, accuracy: 95.5426%, tar: 0.0199 \n",
      "l0: 0.016974, l1: 0.018408, l2: 0.027811, l3: 0.043981, l4: 0.078772, l5: 0.159953, l6: 0.328722\n",
      "\n",
      "[epoch: 393/400, batch: 56/1000, ite: 51883] train loss: 1.1145, accuracy: 95.5936%, tar: 0.0199 \n",
      "l0: 0.020501, l1: 0.022040, l2: 0.030644, l3: 0.042764, l4: 0.080496, l5: 0.197626, l6: 0.397849\n",
      "\n",
      "[epoch: 393/400, batch: 64/1000, ite: 51884] train loss: 1.1146, accuracy: 94.6399%, tar: 0.0199 \n",
      "l0: 0.024624, l1: 0.026404, l2: 0.036917, l3: 0.056586, l4: 0.129550, l5: 0.275019, l6: 0.528368\n",
      "\n",
      "[epoch: 393/400, batch: 72/1000, ite: 51885] train loss: 1.1148, accuracy: 92.8469%, tar: 0.0199 \n",
      "l0: 0.017247, l1: 0.018833, l2: 0.026388, l3: 0.043199, l4: 0.093369, l5: 0.208902, l6: 0.401504\n",
      "\n",
      "[epoch: 393/400, batch: 80/1000, ite: 51886] train loss: 1.1149, accuracy: 95.2072%, tar: 0.0199 \n",
      "l0: 0.014917, l1: 0.016220, l2: 0.022046, l3: 0.032694, l4: 0.062461, l5: 0.125913, l6: 0.269753\n",
      "\n",
      "[epoch: 393/400, batch: 88/1000, ite: 51887] train loss: 1.1147, accuracy: 95.7787%, tar: 0.0199 \n",
      "l0: 0.017533, l1: 0.018422, l2: 0.023772, l3: 0.035078, l4: 0.067901, l5: 0.139419, l6: 0.278665\n",
      "\n",
      "[epoch: 393/400, batch: 96/1000, ite: 51888] train loss: 1.1146, accuracy: 95.9221%, tar: 0.0199 \n",
      "l0: 0.022568, l1: 0.023650, l2: 0.031163, l3: 0.043432, l4: 0.078041, l5: 0.143644, l6: 0.295813\n",
      "\n",
      "[epoch: 393/400, batch: 104/1000, ite: 51889] train loss: 1.1145, accuracy: 95.2592%, tar: 0.0199 \n",
      "l0: 0.023730, l1: 0.025413, l2: 0.037314, l3: 0.056020, l4: 0.115728, l5: 0.222752, l6: 0.411949\n",
      "\n",
      "[epoch: 393/400, batch: 112/1000, ite: 51890] train loss: 1.1146, accuracy: 94.5406%, tar: 0.0199 \n",
      "l0: 0.025599, l1: 0.027348, l2: 0.038283, l3: 0.057954, l4: 0.094012, l5: 0.192056, l6: 0.419411\n",
      "\n",
      "[epoch: 393/400, batch: 120/1000, ite: 51891] train loss: 1.1147, accuracy: 93.8917%, tar: 0.0199 \n",
      "l0: 0.015619, l1: 0.017117, l2: 0.023891, l3: 0.037518, l4: 0.067152, l5: 0.133103, l6: 0.295094\n",
      "\n",
      "[epoch: 393/400, batch: 128/1000, ite: 51892] train loss: 1.1146, accuracy: 95.9423%, tar: 0.0199 \n",
      "l0: 0.024206, l1: 0.026486, l2: 0.035531, l3: 0.056072, l4: 0.121020, l5: 0.236037, l6: 0.449720\n",
      "\n",
      "[epoch: 393/400, batch: 136/1000, ite: 51893] train loss: 1.1147, accuracy: 94.2042%, tar: 0.0199 \n",
      "l0: 0.019563, l1: 0.021028, l2: 0.027849, l3: 0.044153, l4: 0.088698, l5: 0.195672, l6: 0.425284\n",
      "\n",
      "[epoch: 393/400, batch: 144/1000, ite: 51894] train loss: 1.1148, accuracy: 93.8507%, tar: 0.0199 \n",
      "l0: 0.020111, l1: 0.021899, l2: 0.031217, l3: 0.047509, l4: 0.089240, l5: 0.207063, l6: 0.407932\n",
      "\n",
      "[epoch: 393/400, batch: 152/1000, ite: 51895] train loss: 1.1149, accuracy: 94.4106%, tar: 0.0199 \n",
      "l0: 0.018712, l1: 0.020927, l2: 0.029898, l3: 0.050634, l4: 0.107593, l5: 0.239754, l6: 0.462585\n",
      "\n",
      "[epoch: 393/400, batch: 160/1000, ite: 51896] train loss: 1.1150, accuracy: 93.9358%, tar: 0.0199 \n",
      "l0: 0.017985, l1: 0.019469, l2: 0.028009, l3: 0.048894, l4: 0.085522, l5: 0.153623, l6: 0.358353\n",
      "\n",
      "[epoch: 393/400, batch: 168/1000, ite: 51897] train loss: 1.1150, accuracy: 95.9767%, tar: 0.0199 \n",
      "l0: 0.021051, l1: 0.022759, l2: 0.029834, l3: 0.040985, l4: 0.077895, l5: 0.138764, l6: 0.298504\n",
      "\n",
      "[epoch: 393/400, batch: 176/1000, ite: 51898] train loss: 1.1149, accuracy: 95.3620%, tar: 0.0199 \n",
      "l0: 0.022630, l1: 0.024270, l2: 0.033641, l3: 0.050713, l4: 0.092350, l5: 0.194123, l6: 0.393405\n",
      "\n",
      "[epoch: 393/400, batch: 184/1000, ite: 51899] train loss: 1.1149, accuracy: 94.5559%, tar: 0.0199 \n",
      "l0: 0.020269, l1: 0.021727, l2: 0.027584, l3: 0.045985, l4: 0.091086, l5: 0.187355, l6: 0.434179\n",
      "\n",
      "[epoch: 393/400, batch: 192/1000, ite: 51900] train loss: 1.1150, accuracy: 94.1066%, tar: 0.0199 \n",
      "l0: 0.019100, l1: 0.020014, l2: 0.026965, l3: 0.040578, l4: 0.068624, l5: 0.142925, l6: 0.359066\n",
      "\n",
      "[epoch: 393/400, batch: 200/1000, ite: 51901] train loss: 1.1150, accuracy: 94.8157%, tar: 0.0199 \n",
      "l0: 0.018208, l1: 0.019598, l2: 0.028849, l3: 0.045674, l4: 0.085901, l5: 0.180684, l6: 0.392895\n",
      "\n",
      "[epoch: 393/400, batch: 208/1000, ite: 51902] train loss: 1.1150, accuracy: 95.0729%, tar: 0.0199 \n",
      "l0: 0.018562, l1: 0.019402, l2: 0.024220, l3: 0.032532, l4: 0.059471, l5: 0.127034, l6: 0.322458\n",
      "\n",
      "[epoch: 393/400, batch: 216/1000, ite: 51903] train loss: 1.1149, accuracy: 95.2018%, tar: 0.0199 \n",
      "l0: 0.019662, l1: 0.020867, l2: 0.029824, l3: 0.042098, l4: 0.079102, l5: 0.167245, l6: 0.415924\n",
      "\n",
      "[epoch: 393/400, batch: 224/1000, ite: 51904] train loss: 1.1150, accuracy: 94.6398%, tar: 0.0199 \n",
      "l0: 0.016718, l1: 0.017561, l2: 0.023982, l3: 0.037363, l4: 0.066491, l5: 0.141870, l6: 0.269159\n",
      "\n",
      "[epoch: 393/400, batch: 232/1000, ite: 51905] train loss: 1.1148, accuracy: 95.6138%, tar: 0.0199 \n",
      "l0: 0.017312, l1: 0.018700, l2: 0.026110, l3: 0.039080, l4: 0.075200, l5: 0.153847, l6: 0.338074\n",
      "\n",
      "[epoch: 393/400, batch: 240/1000, ite: 51906] train loss: 1.1148, accuracy: 95.7177%, tar: 0.0199 \n",
      "l0: 0.020178, l1: 0.021519, l2: 0.029649, l3: 0.045860, l4: 0.089062, l5: 0.168743, l6: 0.318388\n",
      "\n",
      "[epoch: 393/400, batch: 248/1000, ite: 51907] train loss: 1.1147, accuracy: 95.0562%, tar: 0.0199 \n",
      "l0: 0.022589, l1: 0.024579, l2: 0.034586, l3: 0.053635, l4: 0.096756, l5: 0.204170, l6: 0.448983\n",
      "\n",
      "[epoch: 393/400, batch: 256/1000, ite: 51908] train loss: 1.1148, accuracy: 93.8838%, tar: 0.0199 \n",
      "l0: 0.024741, l1: 0.026154, l2: 0.034389, l3: 0.051961, l4: 0.096983, l5: 0.240837, l6: 0.453843\n",
      "\n",
      "[epoch: 393/400, batch: 264/1000, ite: 51909] train loss: 1.1150, accuracy: 94.1080%, tar: 0.0199 \n",
      "l0: 0.015468, l1: 0.017072, l2: 0.027341, l3: 0.044985, l4: 0.094838, l5: 0.237337, l6: 0.461602\n",
      "\n",
      "[epoch: 393/400, batch: 272/1000, ite: 51910] train loss: 1.1151, accuracy: 94.2975%, tar: 0.0199 \n",
      "l0: 0.016940, l1: 0.017840, l2: 0.025187, l3: 0.037130, l4: 0.064909, l5: 0.129678, l6: 0.315879\n",
      "\n",
      "[epoch: 393/400, batch: 280/1000, ite: 51911] train loss: 1.1150, accuracy: 95.3087%, tar: 0.0199 \n",
      "l0: 0.017563, l1: 0.018678, l2: 0.026160, l3: 0.038265, l4: 0.066768, l5: 0.152178, l6: 0.414523\n",
      "\n",
      "[epoch: 393/400, batch: 288/1000, ite: 51912] train loss: 1.1150, accuracy: 95.0653%, tar: 0.0199 \n",
      "l0: 0.017269, l1: 0.017901, l2: 0.025436, l3: 0.038414, l4: 0.076274, l5: 0.153722, l6: 0.325352\n",
      "\n",
      "[epoch: 393/400, batch: 296/1000, ite: 51913] train loss: 1.1150, accuracy: 95.2508%, tar: 0.0199 \n",
      "l0: 0.015299, l1: 0.016382, l2: 0.023237, l3: 0.035535, l4: 0.067846, l5: 0.163528, l6: 0.338504\n",
      "\n",
      "[epoch: 393/400, batch: 304/1000, ite: 51914] train loss: 1.1149, accuracy: 96.0892%, tar: 0.0199 \n",
      "l0: 0.020410, l1: 0.021211, l2: 0.027651, l3: 0.039554, l4: 0.066546, l5: 0.146121, l6: 0.334532\n",
      "\n",
      "[epoch: 393/400, batch: 312/1000, ite: 51915] train loss: 1.1148, accuracy: 95.3744%, tar: 0.0199 \n",
      "l0: 0.014980, l1: 0.016406, l2: 0.020926, l3: 0.032152, l4: 0.067814, l5: 0.141707, l6: 0.326221\n",
      "\n",
      "[epoch: 393/400, batch: 320/1000, ite: 51916] train loss: 1.1148, accuracy: 95.7788%, tar: 0.0199 \n",
      "l0: 0.019238, l1: 0.020928, l2: 0.030245, l3: 0.045720, l4: 0.087127, l5: 0.173066, l6: 0.375352\n",
      "\n",
      "[epoch: 393/400, batch: 328/1000, ite: 51917] train loss: 1.1148, accuracy: 95.1745%, tar: 0.0199 \n",
      "l0: 0.020937, l1: 0.022002, l2: 0.029332, l3: 0.043228, l4: 0.090045, l5: 0.173016, l6: 0.373590\n",
      "\n",
      "[epoch: 393/400, batch: 336/1000, ite: 51918] train loss: 1.1148, accuracy: 94.7947%, tar: 0.0199 \n",
      "l0: 0.027434, l1: 0.028792, l2: 0.038523, l3: 0.062037, l4: 0.120333, l5: 0.288592, l6: 0.627148\n",
      "\n",
      "[epoch: 393/400, batch: 344/1000, ite: 51919] train loss: 1.1151, accuracy: 90.7964%, tar: 0.0199 \n",
      "l0: 0.015241, l1: 0.016023, l2: 0.020534, l3: 0.030347, l4: 0.053695, l5: 0.115002, l6: 0.259444\n",
      "\n",
      "[epoch: 393/400, batch: 352/1000, ite: 51920] train loss: 1.1150, accuracy: 96.3410%, tar: 0.0199 \n",
      "l0: 0.020175, l1: 0.021098, l2: 0.026750, l3: 0.040523, l4: 0.078153, l5: 0.203825, l6: 0.414877\n",
      "\n",
      "[epoch: 393/400, batch: 360/1000, ite: 51921] train loss: 1.1150, accuracy: 93.8160%, tar: 0.0199 \n",
      "l0: 0.014645, l1: 0.015466, l2: 0.021962, l3: 0.034432, l4: 0.057868, l5: 0.110202, l6: 0.225570\n",
      "\n",
      "[epoch: 393/400, batch: 368/1000, ite: 51922] train loss: 1.1148, accuracy: 96.4925%, tar: 0.0199 \n",
      "l0: 0.015551, l1: 0.017050, l2: 0.025504, l3: 0.039020, l4: 0.075095, l5: 0.164817, l6: 0.384154\n",
      "\n",
      "[epoch: 393/400, batch: 376/1000, ite: 51923] train loss: 1.1148, accuracy: 95.5433%, tar: 0.0199 \n",
      "l0: 0.017187, l1: 0.018364, l2: 0.024119, l3: 0.037026, l4: 0.066941, l5: 0.130412, l6: 0.265867\n",
      "\n",
      "[epoch: 393/400, batch: 384/1000, ite: 51924] train loss: 1.1147, accuracy: 95.7441%, tar: 0.0199 \n",
      "l0: 0.017451, l1: 0.019102, l2: 0.027450, l3: 0.039873, l4: 0.077743, l5: 0.147355, l6: 0.300311\n",
      "\n",
      "[epoch: 393/400, batch: 392/1000, ite: 51925] train loss: 1.1146, accuracy: 96.3528%, tar: 0.0199 \n",
      "l0: 0.014482, l1: 0.015888, l2: 0.023363, l3: 0.037059, l4: 0.070134, l5: 0.152857, l6: 0.312845\n",
      "\n",
      "[epoch: 393/400, batch: 400/1000, ite: 51926] train loss: 1.1145, accuracy: 95.6571%, tar: 0.0199 \n",
      "l0: 0.020451, l1: 0.021906, l2: 0.029430, l3: 0.044380, l4: 0.094607, l5: 0.209830, l6: 0.413051\n",
      "\n",
      "[epoch: 393/400, batch: 408/1000, ite: 51927] train loss: 1.1145, accuracy: 94.7406%, tar: 0.0199 \n",
      "l0: 0.022810, l1: 0.024918, l2: 0.035682, l3: 0.060884, l4: 0.130090, l5: 0.287854, l6: 0.498560\n",
      "\n",
      "[epoch: 393/400, batch: 416/1000, ite: 51928] train loss: 1.1148, accuracy: 93.7127%, tar: 0.0199 \n",
      "l0: 0.014500, l1: 0.015635, l2: 0.021550, l3: 0.034825, l4: 0.062187, l5: 0.111417, l6: 0.290664\n",
      "\n",
      "[epoch: 393/400, batch: 424/1000, ite: 51929] train loss: 1.1146, accuracy: 95.9218%, tar: 0.0199 \n",
      "l0: 0.017535, l1: 0.018282, l2: 0.025160, l3: 0.035212, l4: 0.062246, l5: 0.114106, l6: 0.227606\n",
      "\n",
      "[epoch: 393/400, batch: 432/1000, ite: 51930] train loss: 1.1144, accuracy: 96.2729%, tar: 0.0199 \n",
      "l0: 0.016148, l1: 0.018259, l2: 0.026794, l3: 0.042730, l4: 0.079235, l5: 0.179868, l6: 0.315014\n",
      "\n",
      "[epoch: 393/400, batch: 440/1000, ite: 51931] train loss: 1.1144, accuracy: 96.2704%, tar: 0.0199 \n",
      "l0: 0.019922, l1: 0.021667, l2: 0.029576, l3: 0.047005, l4: 0.088889, l5: 0.173757, l6: 0.432981\n",
      "\n",
      "[epoch: 393/400, batch: 448/1000, ite: 51932] train loss: 1.1144, accuracy: 94.5868%, tar: 0.0199 \n",
      "l0: 0.015115, l1: 0.016519, l2: 0.023669, l3: 0.043423, l4: 0.083069, l5: 0.164721, l6: 0.405848\n",
      "\n",
      "[epoch: 393/400, batch: 456/1000, ite: 51933] train loss: 1.1145, accuracy: 95.4737%, tar: 0.0199 \n",
      "l0: 0.017299, l1: 0.018247, l2: 0.025057, l3: 0.039314, l4: 0.074804, l5: 0.190575, l6: 0.421783\n",
      "\n",
      "[epoch: 393/400, batch: 464/1000, ite: 51934] train loss: 1.1145, accuracy: 94.8476%, tar: 0.0199 \n",
      "l0: 0.023207, l1: 0.026036, l2: 0.038205, l3: 0.062967, l4: 0.134560, l5: 0.292682, l6: 0.580669\n",
      "\n",
      "[epoch: 393/400, batch: 472/1000, ite: 51935] train loss: 1.1148, accuracy: 93.0585%, tar: 0.0199 \n",
      "l0: 0.017411, l1: 0.019212, l2: 0.028034, l3: 0.045437, l4: 0.087370, l5: 0.166325, l6: 0.321165\n",
      "\n",
      "[epoch: 393/400, batch: 480/1000, ite: 51936] train loss: 1.1148, accuracy: 95.2537%, tar: 0.0199 \n",
      "l0: 0.016621, l1: 0.017570, l2: 0.023645, l3: 0.033642, l4: 0.054369, l5: 0.115368, l6: 0.241471\n",
      "\n",
      "[epoch: 393/400, batch: 488/1000, ite: 51937] train loss: 1.1146, accuracy: 96.2490%, tar: 0.0199 \n",
      "l0: 0.015410, l1: 0.016451, l2: 0.023588, l3: 0.036091, l4: 0.067496, l5: 0.148239, l6: 0.379311\n",
      "\n",
      "[epoch: 393/400, batch: 496/1000, ite: 51938] train loss: 1.1146, accuracy: 95.3693%, tar: 0.0199 \n",
      "l0: 0.016764, l1: 0.017987, l2: 0.024407, l3: 0.037170, l4: 0.065124, l5: 0.126374, l6: 0.295199\n",
      "\n",
      "[epoch: 393/400, batch: 504/1000, ite: 51939] train loss: 1.1145, accuracy: 95.5322%, tar: 0.0199 \n",
      "l0: 0.017607, l1: 0.019443, l2: 0.028755, l3: 0.048086, l4: 0.101518, l5: 0.212491, l6: 0.455489\n",
      "\n",
      "[epoch: 393/400, batch: 512/1000, ite: 51940] train loss: 1.1146, accuracy: 95.1685%, tar: 0.0199 \n",
      "l0: 0.015405, l1: 0.016767, l2: 0.022472, l3: 0.038702, l4: 0.079959, l5: 0.163795, l6: 0.341226\n",
      "\n",
      "[epoch: 393/400, batch: 520/1000, ite: 51941] train loss: 1.1145, accuracy: 96.0540%, tar: 0.0199 \n",
      "l0: 0.019132, l1: 0.020223, l2: 0.026764, l3: 0.040343, l4: 0.117393, l5: 0.168243, l6: 0.331424\n",
      "\n",
      "[epoch: 393/400, batch: 528/1000, ite: 51942] train loss: 1.1145, accuracy: 95.3213%, tar: 0.0199 \n",
      "l0: 0.016553, l1: 0.017370, l2: 0.022894, l3: 0.034751, l4: 0.066103, l5: 0.142137, l6: 0.281486\n",
      "\n",
      "[epoch: 393/400, batch: 536/1000, ite: 51943] train loss: 1.1144, accuracy: 95.8908%, tar: 0.0199 \n",
      "l0: 0.011421, l1: 0.012383, l2: 0.018356, l3: 0.028736, l4: 0.054808, l5: 0.107220, l6: 0.204502\n",
      "\n",
      "[epoch: 393/400, batch: 544/1000, ite: 51944] train loss: 1.1141, accuracy: 97.1458%, tar: 0.0198 \n",
      "l0: 0.015996, l1: 0.017064, l2: 0.024982, l3: 0.038591, l4: 0.069897, l5: 0.125124, l6: 0.296590\n",
      "\n",
      "[epoch: 393/400, batch: 552/1000, ite: 51945] train loss: 1.1140, accuracy: 95.9415%, tar: 0.0198 \n",
      "l0: 0.020173, l1: 0.021845, l2: 0.030777, l3: 0.045316, l4: 0.072476, l5: 0.149048, l6: 0.312057\n",
      "\n",
      "[epoch: 393/400, batch: 560/1000, ite: 51946] train loss: 1.1139, accuracy: 95.3226%, tar: 0.0198 \n",
      "l0: 0.017853, l1: 0.020065, l2: 0.029157, l3: 0.048510, l4: 0.090670, l5: 0.174391, l6: 0.372876\n",
      "\n",
      "[epoch: 393/400, batch: 568/1000, ite: 51947] train loss: 1.1139, accuracy: 95.7336%, tar: 0.0198 \n",
      "l0: 0.018247, l1: 0.019464, l2: 0.026309, l3: 0.041780, l4: 0.077080, l5: 0.191333, l6: 0.428412\n",
      "\n",
      "[epoch: 393/400, batch: 576/1000, ite: 51948] train loss: 1.1140, accuracy: 94.5872%, tar: 0.0198 \n",
      "l0: 0.022765, l1: 0.024362, l2: 0.033938, l3: 0.053137, l4: 0.094292, l5: 0.208677, l6: 0.485930\n",
      "\n",
      "[epoch: 393/400, batch: 584/1000, ite: 51949] train loss: 1.1142, accuracy: 93.4226%, tar: 0.0198 \n",
      "l0: 0.013392, l1: 0.014571, l2: 0.022068, l3: 0.037708, l4: 0.063838, l5: 0.120635, l6: 0.317252\n",
      "\n",
      "[epoch: 393/400, batch: 592/1000, ite: 51950] train loss: 1.1141, accuracy: 96.4539%, tar: 0.0198 \n",
      "l0: 0.023043, l1: 0.024781, l2: 0.035904, l3: 0.056370, l4: 0.099933, l5: 0.209701, l6: 0.427067\n",
      "\n",
      "[epoch: 393/400, batch: 600/1000, ite: 51951] train loss: 1.1142, accuracy: 94.2823%, tar: 0.0198 \n",
      "l0: 0.024872, l1: 0.026861, l2: 0.037595, l3: 0.067798, l4: 0.131177, l5: 0.242310, l6: 0.465889\n",
      "\n",
      "[epoch: 393/400, batch: 608/1000, ite: 51952] train loss: 1.1143, accuracy: 93.4873%, tar: 0.0198 \n",
      "l0: 0.020607, l1: 0.021316, l2: 0.029289, l3: 0.044070, l4: 0.074320, l5: 0.150133, l6: 0.341797\n",
      "\n",
      "[epoch: 393/400, batch: 616/1000, ite: 51953] train loss: 1.1143, accuracy: 94.7754%, tar: 0.0198 \n",
      "l0: 0.024263, l1: 0.026102, l2: 0.036566, l3: 0.057484, l4: 0.109071, l5: 0.207755, l6: 0.447924\n",
      "\n",
      "[epoch: 393/400, batch: 624/1000, ite: 51954] train loss: 1.1144, accuracy: 94.5912%, tar: 0.0198 \n",
      "l0: 0.018492, l1: 0.020856, l2: 0.031234, l3: 0.056194, l4: 0.116405, l5: 0.207865, l6: 0.365581\n",
      "\n",
      "[epoch: 393/400, batch: 632/1000, ite: 51955] train loss: 1.1145, accuracy: 95.7622%, tar: 0.0198 \n",
      "l0: 0.017108, l1: 0.018873, l2: 0.027962, l3: 0.042766, l4: 0.074104, l5: 0.142304, l6: 0.272823\n",
      "\n",
      "[epoch: 393/400, batch: 640/1000, ite: 51956] train loss: 1.1143, accuracy: 96.4548%, tar: 0.0198 \n",
      "l0: 0.022253, l1: 0.023154, l2: 0.030220, l3: 0.045615, l4: 0.087227, l5: 0.196428, l6: 0.395006\n",
      "\n",
      "[epoch: 393/400, batch: 648/1000, ite: 51957] train loss: 1.1144, accuracy: 94.3896%, tar: 0.0198 \n",
      "l0: 0.017722, l1: 0.018397, l2: 0.024694, l3: 0.036934, l4: 0.057915, l5: 0.114771, l6: 0.266199\n",
      "\n",
      "[epoch: 393/400, batch: 656/1000, ite: 51958] train loss: 1.1142, accuracy: 95.6996%, tar: 0.0198 \n",
      "l0: 0.022462, l1: 0.023877, l2: 0.030830, l3: 0.046911, l4: 0.083736, l5: 0.166602, l6: 0.394431\n",
      "\n",
      "[epoch: 393/400, batch: 664/1000, ite: 51959] train loss: 1.1142, accuracy: 94.6709%, tar: 0.0198 \n",
      "l0: 0.020804, l1: 0.022350, l2: 0.030517, l3: 0.052852, l4: 0.100765, l5: 0.190213, l6: 0.397761\n",
      "\n",
      "[epoch: 393/400, batch: 672/1000, ite: 51960] train loss: 1.1143, accuracy: 94.6232%, tar: 0.0198 \n",
      "l0: 0.020373, l1: 0.023420, l2: 0.032676, l3: 0.052988, l4: 0.108962, l5: 0.209838, l6: 0.351826\n",
      "\n",
      "[epoch: 393/400, batch: 680/1000, ite: 51961] train loss: 1.1143, accuracy: 95.7231%, tar: 0.0198 \n",
      "l0: 0.022023, l1: 0.023589, l2: 0.030399, l3: 0.045207, l4: 0.086974, l5: 0.210627, l6: 0.432131\n",
      "\n",
      "[epoch: 393/400, batch: 688/1000, ite: 51962] train loss: 1.1144, accuracy: 93.9581%, tar: 0.0199 \n",
      "l0: 0.017056, l1: 0.018219, l2: 0.025467, l3: 0.038332, l4: 0.074425, l5: 0.141422, l6: 0.347775\n",
      "\n",
      "[epoch: 393/400, batch: 696/1000, ite: 51963] train loss: 1.1144, accuracy: 95.8843%, tar: 0.0198 \n",
      "l0: 0.020329, l1: 0.021641, l2: 0.029237, l3: 0.047352, l4: 0.086661, l5: 0.170317, l6: 0.305243\n",
      "\n",
      "[epoch: 393/400, batch: 704/1000, ite: 51964] train loss: 1.1143, accuracy: 95.5676%, tar: 0.0198 \n",
      "l0: 0.021365, l1: 0.022411, l2: 0.030566, l3: 0.048440, l4: 0.084490, l5: 0.166214, l6: 0.361090\n",
      "\n",
      "[epoch: 393/400, batch: 712/1000, ite: 51965] train loss: 1.1143, accuracy: 94.2663%, tar: 0.0199 \n",
      "l0: 0.019598, l1: 0.020679, l2: 0.026814, l3: 0.037678, l4: 0.065877, l5: 0.111694, l6: 0.238994\n",
      "\n",
      "[epoch: 393/400, batch: 720/1000, ite: 51966] train loss: 1.1141, accuracy: 96.2754%, tar: 0.0199 \n",
      "l0: 0.016313, l1: 0.018007, l2: 0.024681, l3: 0.039757, l4: 0.081123, l5: 0.152885, l6: 0.314180\n",
      "\n",
      "[epoch: 393/400, batch: 728/1000, ite: 51967] train loss: 1.1140, accuracy: 95.6391%, tar: 0.0198 \n",
      "l0: 0.019163, l1: 0.020881, l2: 0.028283, l3: 0.042047, l4: 0.074646, l5: 0.170723, l6: 0.340489\n",
      "\n",
      "[epoch: 393/400, batch: 736/1000, ite: 51968] train loss: 1.1140, accuracy: 95.0860%, tar: 0.0198 \n",
      "l0: 0.015412, l1: 0.016883, l2: 0.025327, l3: 0.044654, l4: 0.092997, l5: 0.180112, l6: 0.339641\n",
      "\n",
      "[epoch: 393/400, batch: 744/1000, ite: 51969] train loss: 1.1140, accuracy: 95.4644%, tar: 0.0198 \n",
      "l0: 0.021417, l1: 0.023504, l2: 0.032779, l3: 0.052953, l4: 0.108714, l5: 0.212996, l6: 0.469664\n",
      "\n",
      "[epoch: 393/400, batch: 752/1000, ite: 51970] train loss: 1.1141, accuracy: 94.3600%, tar: 0.0198 \n",
      "l0: 0.014956, l1: 0.015734, l2: 0.023562, l3: 0.040577, l4: 0.075724, l5: 0.168231, l6: 0.346500\n",
      "\n",
      "[epoch: 393/400, batch: 760/1000, ite: 51971] train loss: 1.1141, accuracy: 95.3691%, tar: 0.0198 \n",
      "l0: 0.019658, l1: 0.020925, l2: 0.027685, l3: 0.044964, l4: 0.085545, l5: 0.165662, l6: 0.340580\n",
      "\n",
      "[epoch: 393/400, batch: 768/1000, ite: 51972] train loss: 1.1140, accuracy: 94.3278%, tar: 0.0198 \n",
      "l0: 0.020206, l1: 0.022805, l2: 0.033733, l3: 0.058158, l4: 0.120240, l5: 0.230644, l6: 0.469357\n",
      "\n",
      "[epoch: 393/400, batch: 776/1000, ite: 51973] train loss: 1.1142, accuracy: 94.7280%, tar: 0.0198 \n",
      "l0: 0.020307, l1: 0.022152, l2: 0.032414, l3: 0.049146, l4: 0.091845, l5: 0.195487, l6: 0.385304\n",
      "\n",
      "[epoch: 393/400, batch: 784/1000, ite: 51974] train loss: 1.1142, accuracy: 95.1270%, tar: 0.0198 \n",
      "l0: 0.018027, l1: 0.018757, l2: 0.024861, l3: 0.037722, l4: 0.067380, l5: 0.143372, l6: 0.318024\n",
      "\n",
      "[epoch: 393/400, batch: 792/1000, ite: 51975] train loss: 1.1142, accuracy: 95.5033%, tar: 0.0198 \n",
      "l0: 0.023072, l1: 0.024722, l2: 0.035076, l3: 0.055322, l4: 0.107191, l5: 0.231276, l6: 0.449834\n",
      "\n",
      "[epoch: 393/400, batch: 800/1000, ite: 51976] train loss: 1.1143, accuracy: 93.5499%, tar: 0.0198 \n",
      "l0: 0.016511, l1: 0.017631, l2: 0.025093, l3: 0.038471, l4: 0.076828, l5: 0.173991, l6: 0.340338\n",
      "\n",
      "[epoch: 393/400, batch: 808/1000, ite: 51977] train loss: 1.1143, accuracy: 95.0251%, tar: 0.0198 \n",
      "l0: 0.019450, l1: 0.020876, l2: 0.028956, l3: 0.045533, l4: 0.092581, l5: 0.177590, l6: 0.450075\n",
      "\n",
      "[epoch: 393/400, batch: 816/1000, ite: 51978] train loss: 1.1143, accuracy: 94.7787%, tar: 0.0198 \n",
      "l0: 0.019459, l1: 0.021138, l2: 0.027940, l3: 0.045387, l4: 0.085349, l5: 0.147791, l6: 0.289753\n",
      "\n",
      "[epoch: 393/400, batch: 824/1000, ite: 51979] train loss: 1.1142, accuracy: 95.9175%, tar: 0.0198 \n",
      "l0: 0.016961, l1: 0.018482, l2: 0.027963, l3: 0.051598, l4: 0.102489, l5: 0.225908, l6: 0.395545\n",
      "\n",
      "[epoch: 393/400, batch: 832/1000, ite: 51980] train loss: 1.1143, accuracy: 94.9557%, tar: 0.0198 \n",
      "l0: 0.026051, l1: 0.027327, l2: 0.034494, l3: 0.048421, l4: 0.079124, l5: 0.159947, l6: 0.353437\n",
      "\n",
      "[epoch: 393/400, batch: 840/1000, ite: 51981] train loss: 1.1143, accuracy: 94.1145%, tar: 0.0198 \n",
      "l0: 0.015086, l1: 0.016570, l2: 0.023719, l3: 0.039205, l4: 0.073019, l5: 0.149867, l6: 0.367490\n",
      "\n",
      "[epoch: 393/400, batch: 848/1000, ite: 51982] train loss: 1.1143, accuracy: 95.2903%, tar: 0.0198 \n",
      "l0: 0.017514, l1: 0.018799, l2: 0.026104, l3: 0.043593, l4: 0.104477, l5: 0.189613, l6: 0.353889\n",
      "\n",
      "[epoch: 393/400, batch: 856/1000, ite: 51983] train loss: 1.1143, accuracy: 95.0778%, tar: 0.0198 \n",
      "l0: 0.013955, l1: 0.015232, l2: 0.021384, l3: 0.034407, l4: 0.071642, l5: 0.144108, l6: 0.357564\n",
      "\n",
      "[epoch: 393/400, batch: 864/1000, ite: 51984] train loss: 1.1142, accuracy: 95.2356%, tar: 0.0198 \n",
      "l0: 0.013490, l1: 0.014587, l2: 0.022644, l3: 0.033956, l4: 0.060429, l5: 0.152801, l6: 0.307345\n",
      "\n",
      "[epoch: 393/400, batch: 872/1000, ite: 51985] train loss: 1.1141, accuracy: 96.1399%, tar: 0.0198 \n",
      "l0: 0.024528, l1: 0.025875, l2: 0.033304, l3: 0.047397, l4: 0.097531, l5: 0.238615, l6: 0.400733\n",
      "\n",
      "[epoch: 393/400, batch: 880/1000, ite: 51986] train loss: 1.1142, accuracy: 94.3513%, tar: 0.0198 \n",
      "l0: 0.023570, l1: 0.024868, l2: 0.032201, l3: 0.048961, l4: 0.098528, l5: 0.194290, l6: 0.427831\n",
      "\n",
      "[epoch: 393/400, batch: 888/1000, ite: 51987] train loss: 1.1143, accuracy: 94.6985%, tar: 0.0198 \n",
      "l0: 0.020160, l1: 0.022564, l2: 0.033906, l3: 0.055412, l4: 0.107115, l5: 0.278248, l6: 0.535230\n",
      "\n",
      "[epoch: 393/400, batch: 896/1000, ite: 51988] train loss: 1.1145, accuracy: 93.5306%, tar: 0.0198 \n",
      "l0: 0.015286, l1: 0.016367, l2: 0.024330, l3: 0.038295, l4: 0.077909, l5: 0.150914, l6: 0.381822\n",
      "\n",
      "[epoch: 393/400, batch: 904/1000, ite: 51989] train loss: 1.1145, accuracy: 95.9046%, tar: 0.0198 \n",
      "l0: 0.020693, l1: 0.021793, l2: 0.031872, l3: 0.048541, l4: 0.097283, l5: 0.235128, l6: 0.411459\n",
      "\n",
      "[epoch: 393/400, batch: 912/1000, ite: 51990] train loss: 1.1146, accuracy: 94.9835%, tar: 0.0198 \n",
      "l0: 0.016333, l1: 0.017187, l2: 0.024078, l3: 0.035054, l4: 0.065968, l5: 0.141661, l6: 0.258479\n",
      "\n",
      "[epoch: 393/400, batch: 920/1000, ite: 51991] train loss: 1.1144, accuracy: 96.0746%, tar: 0.0198 \n",
      "l0: 0.016608, l1: 0.017667, l2: 0.023617, l3: 0.035303, l4: 0.065157, l5: 0.134077, l6: 0.321873\n",
      "\n",
      "[epoch: 393/400, batch: 928/1000, ite: 51992] train loss: 1.1143, accuracy: 95.4997%, tar: 0.0198 \n",
      "l0: 0.021592, l1: 0.022845, l2: 0.032931, l3: 0.050075, l4: 0.097615, l5: 0.188151, l6: 0.367598\n",
      "\n",
      "[epoch: 393/400, batch: 936/1000, ite: 51993] train loss: 1.1144, accuracy: 95.2038%, tar: 0.0198 \n",
      "l0: 0.015934, l1: 0.017243, l2: 0.023989, l3: 0.039070, l4: 0.080146, l5: 0.171919, l6: 0.333238\n",
      "\n",
      "[epoch: 393/400, batch: 944/1000, ite: 51994] train loss: 1.1143, accuracy: 95.6452%, tar: 0.0198 \n",
      "l0: 0.019076, l1: 0.020393, l2: 0.027889, l3: 0.041692, l4: 0.076190, l5: 0.152518, l6: 0.295990\n",
      "\n",
      "[epoch: 393/400, batch: 952/1000, ite: 51995] train loss: 1.1142, accuracy: 95.6572%, tar: 0.0198 \n",
      "l0: 0.022551, l1: 0.024383, l2: 0.034698, l3: 0.049650, l4: 0.097105, l5: 0.191355, l6: 0.422321\n",
      "\n",
      "[epoch: 393/400, batch: 960/1000, ite: 51996] train loss: 1.1143, accuracy: 94.5103%, tar: 0.0198 \n",
      "l0: 0.018772, l1: 0.020532, l2: 0.027592, l3: 0.044878, l4: 0.079321, l5: 0.148853, l6: 0.303404\n",
      "\n",
      "[epoch: 393/400, batch: 968/1000, ite: 51997] train loss: 1.1142, accuracy: 95.4141%, tar: 0.0198 \n",
      "l0: 0.022987, l1: 0.025509, l2: 0.037886, l3: 0.059700, l4: 0.115493, l5: 0.214349, l6: 0.372827\n",
      "\n",
      "[epoch: 393/400, batch: 976/1000, ite: 51998] train loss: 1.1143, accuracy: 95.3322%, tar: 0.0198 \n",
      "l0: 0.016636, l1: 0.018252, l2: 0.027362, l3: 0.047396, l4: 0.109076, l5: 0.203372, l6: 0.498225\n",
      "\n",
      "[epoch: 393/400, batch: 984/1000, ite: 51999] train loss: 1.1144, accuracy: 94.1683%, tar: 0.0198 \n",
      "l0: 0.015747, l1: 0.017329, l2: 0.025405, l3: 0.042991, l4: 0.086343, l5: 0.166022, l6: 0.364627\n",
      "\n",
      "[epoch: 393/400, batch: 992/1000, ite: 52000] train loss: 1.1144, accuracy: 94.9929%, tar: 0.0198 \n",
      "l0: 0.012725, l1: 0.013682, l2: 0.019019, l3: 0.033219, l4: 0.068327, l5: 0.129472, l6: 0.292820\n",
      "\n",
      "[epoch: 393/400, batch: 1000/1000, ite: 52001] train loss: 0.8683, accuracy: 95.9692%, tar: 0.0127 \n",
      "l0: 0.018242, l1: 0.019493, l2: 0.028078, l3: 0.043927, l4: 0.084259, l5: 0.174036, l6: 0.360987\n",
      "\n",
      "[epoch: 394/400, batch: 8/1000, ite: 52002] train loss: 0.9791, accuracy: 95.2986%, tar: 0.0155 \n",
      "l0: 0.014210, l1: 0.015869, l2: 0.023783, l3: 0.040051, l4: 0.071596, l5: 0.155038, l6: 0.335498\n",
      "\n",
      "[epoch: 394/400, batch: 16/1000, ite: 52003] train loss: 0.9842, accuracy: 95.9228%, tar: 0.0151 \n",
      "l0: 0.015986, l1: 0.017219, l2: 0.024489, l3: 0.036114, l4: 0.066061, l5: 0.132167, l6: 0.293029\n",
      "\n",
      "[epoch: 394/400, batch: 24/1000, ite: 52004] train loss: 0.9578, accuracy: 95.9657%, tar: 0.0153 \n",
      "l0: 0.020489, l1: 0.022157, l2: 0.030145, l3: 0.049044, l4: 0.094682, l5: 0.181493, l6: 0.372152\n",
      "\n",
      "[epoch: 394/400, batch: 32/1000, ite: 52005] train loss: 0.9943, accuracy: 95.2110%, tar: 0.0163 \n",
      "l0: 0.021352, l1: 0.022734, l2: 0.031816, l3: 0.053489, l4: 0.107121, l5: 0.231052, l6: 0.449983\n",
      "\n",
      "[epoch: 394/400, batch: 40/1000, ite: 52006] train loss: 1.0576, accuracy: 93.9259%, tar: 0.0172 \n",
      "l0: 0.017731, l1: 0.018936, l2: 0.026866, l3: 0.037646, l4: 0.063209, l5: 0.126731, l6: 0.268248\n",
      "\n",
      "[epoch: 394/400, batch: 48/1000, ite: 52007] train loss: 1.0258, accuracy: 95.8698%, tar: 0.0172 \n",
      "l0: 0.016401, l1: 0.018238, l2: 0.027133, l3: 0.042402, l4: 0.092274, l5: 0.220137, l6: 0.468610\n",
      "\n",
      "[epoch: 394/400, batch: 56/1000, ite: 52008] train loss: 1.0675, accuracy: 93.9768%, tar: 0.0171 \n",
      "l0: 0.022995, l1: 0.024784, l2: 0.036242, l3: 0.062846, l4: 0.123853, l5: 0.245243, l6: 0.516226\n",
      "\n",
      "[epoch: 394/400, batch: 64/1000, ite: 52009] train loss: 1.1212, accuracy: 93.0168%, tar: 0.0178 \n",
      "l0: 0.025488, l1: 0.026746, l2: 0.035231, l3: 0.053897, l4: 0.109749, l5: 0.241611, l6: 0.481079\n",
      "\n",
      "[epoch: 394/400, batch: 72/1000, ite: 52010] train loss: 1.1546, accuracy: 94.0228%, tar: 0.0186 \n",
      "l0: 0.013258, l1: 0.014445, l2: 0.020342, l3: 0.030336, l4: 0.051720, l5: 0.127475, l6: 0.255379\n",
      "\n",
      "[epoch: 394/400, batch: 80/1000, ite: 52011] train loss: 1.1194, accuracy: 96.5179%, tar: 0.0181 \n",
      "l0: 0.021982, l1: 0.023666, l2: 0.034123, l3: 0.055130, l4: 0.093705, l5: 0.171416, l6: 0.389233\n",
      "\n",
      "[epoch: 394/400, batch: 88/1000, ite: 52012] train loss: 1.1245, accuracy: 94.3073%, tar: 0.0184 \n",
      "l0: 0.014693, l1: 0.016225, l2: 0.024415, l3: 0.041219, l4: 0.085380, l5: 0.177885, l6: 0.397536\n",
      "\n",
      "[epoch: 394/400, batch: 96/1000, ite: 52013] train loss: 1.1268, accuracy: 95.4311%, tar: 0.0181 \n",
      "l0: 0.025800, l1: 0.027912, l2: 0.038404, l3: 0.059718, l4: 0.145439, l5: 0.334219, l6: 0.618977\n",
      "\n",
      "[epoch: 394/400, batch: 104/1000, ite: 52014] train loss: 1.1803, accuracy: 92.2045%, tar: 0.0187 \n",
      "l0: 0.019905, l1: 0.021873, l2: 0.030773, l3: 0.048202, l4: 0.096552, l5: 0.205445, l6: 0.467921\n",
      "\n",
      "[epoch: 394/400, batch: 112/1000, ite: 52015] train loss: 1.1928, accuracy: 94.2895%, tar: 0.0188 \n",
      "l0: 0.018386, l1: 0.019333, l2: 0.025047, l3: 0.035212, l4: 0.066544, l5: 0.126858, l6: 0.303209\n",
      "\n",
      "[epoch: 394/400, batch: 120/1000, ite: 52016] train loss: 1.1745, accuracy: 95.9990%, tar: 0.0187 \n",
      "l0: 0.015792, l1: 0.016848, l2: 0.023174, l3: 0.036851, l4: 0.081588, l5: 0.158591, l6: 0.310822\n",
      "\n",
      "[epoch: 394/400, batch: 128/1000, ite: 52017] train loss: 1.1619, accuracy: 95.6922%, tar: 0.0186 \n",
      "l0: 0.018936, l1: 0.019998, l2: 0.027402, l3: 0.043686, l4: 0.075060, l5: 0.153269, l6: 0.291231\n",
      "\n",
      "[epoch: 394/400, batch: 136/1000, ite: 52018] train loss: 1.1486, accuracy: 95.2328%, tar: 0.0186 \n",
      "l0: 0.017244, l1: 0.018475, l2: 0.026163, l3: 0.040587, l4: 0.067139, l5: 0.138691, l6: 0.329661\n",
      "\n",
      "[epoch: 394/400, batch: 144/1000, ite: 52019] train loss: 1.1391, accuracy: 95.9570%, tar: 0.0185 \n",
      "l0: 0.019099, l1: 0.020451, l2: 0.027900, l3: 0.041887, l4: 0.080636, l5: 0.209249, l6: 0.448395\n",
      "\n",
      "[epoch: 394/400, batch: 152/1000, ite: 52020] train loss: 1.1476, accuracy: 93.8275%, tar: 0.0185 \n",
      "l0: 0.023674, l1: 0.026403, l2: 0.038247, l3: 0.054974, l4: 0.102760, l5: 0.197233, l6: 0.392240\n",
      "\n",
      "[epoch: 394/400, batch: 160/1000, ite: 52021] train loss: 1.1515, accuracy: 94.8859%, tar: 0.0188 \n",
      "l0: 0.021037, l1: 0.022383, l2: 0.031059, l3: 0.046850, l4: 0.090728, l5: 0.199292, l6: 0.512532\n",
      "\n",
      "[epoch: 394/400, batch: 168/1000, ite: 52022] train loss: 1.1645, accuracy: 93.3866%, tar: 0.0189 \n",
      "l0: 0.013995, l1: 0.015590, l2: 0.025279, l3: 0.044834, l4: 0.086174, l5: 0.177385, l6: 0.369761\n",
      "\n",
      "[epoch: 394/400, batch: 176/1000, ite: 52023] train loss: 1.1618, accuracy: 96.2137%, tar: 0.0187 \n",
      "l0: 0.021970, l1: 0.023257, l2: 0.031493, l3: 0.049240, l4: 0.094286, l5: 0.179771, l6: 0.445014\n",
      "\n",
      "[epoch: 394/400, batch: 184/1000, ite: 52024] train loss: 1.1673, accuracy: 93.3622%, tar: 0.0188 \n",
      "l0: 0.013880, l1: 0.015143, l2: 0.023579, l3: 0.037903, l4: 0.069966, l5: 0.141424, l6: 0.282920\n",
      "\n",
      "[epoch: 394/400, batch: 192/1000, ite: 52025] train loss: 1.1556, accuracy: 96.2743%, tar: 0.0186 \n",
      "l0: 0.021623, l1: 0.022569, l2: 0.029528, l3: 0.048388, l4: 0.094105, l5: 0.202149, l6: 0.420734\n",
      "\n",
      "[epoch: 394/400, batch: 200/1000, ite: 52026] train loss: 1.1598, accuracy: 94.0406%, tar: 0.0187 \n",
      "l0: 0.018049, l1: 0.019823, l2: 0.031417, l3: 0.049464, l4: 0.087780, l5: 0.179358, l6: 0.410659\n",
      "\n",
      "[epoch: 394/400, batch: 208/1000, ite: 52027] train loss: 1.1620, accuracy: 94.8705%, tar: 0.0187 \n",
      "l0: 0.024343, l1: 0.026218, l2: 0.034579, l3: 0.048507, l4: 0.083045, l5: 0.142722, l6: 0.290153\n",
      "\n",
      "[epoch: 394/400, batch: 216/1000, ite: 52028] train loss: 1.1542, accuracy: 95.4768%, tar: 0.0189 \n",
      "l0: 0.021818, l1: 0.024290, l2: 0.034833, l3: 0.061927, l4: 0.134889, l5: 0.268108, l6: 0.492773\n",
      "\n",
      "[epoch: 394/400, batch: 224/1000, ite: 52029] train loss: 1.1672, accuracy: 93.7151%, tar: 0.0190 \n",
      "l0: 0.018730, l1: 0.020345, l2: 0.026505, l3: 0.040670, l4: 0.070780, l5: 0.152275, l6: 0.296564\n",
      "\n",
      "[epoch: 394/400, batch: 232/1000, ite: 52030] train loss: 1.1597, accuracy: 95.5790%, tar: 0.0190 \n",
      "l0: 0.020481, l1: 0.021573, l2: 0.029714, l3: 0.047525, l4: 0.087913, l5: 0.180084, l6: 0.383063\n",
      "\n",
      "[epoch: 394/400, batch: 240/1000, ite: 52031] train loss: 1.1598, accuracy: 94.5756%, tar: 0.0190 \n",
      "l0: 0.017524, l1: 0.018719, l2: 0.026386, l3: 0.044637, l4: 0.083638, l5: 0.160792, l6: 0.392140\n",
      "\n",
      "[epoch: 394/400, batch: 248/1000, ite: 52032] train loss: 1.1593, accuracy: 94.8647%, tar: 0.0190 \n",
      "l0: 0.016137, l1: 0.017509, l2: 0.024599, l3: 0.037904, l4: 0.069438, l5: 0.139804, l6: 0.340588\n",
      "\n",
      "[epoch: 394/400, batch: 256/1000, ite: 52033] train loss: 1.1542, accuracy: 96.1337%, tar: 0.0189 \n",
      "l0: 0.019854, l1: 0.021045, l2: 0.029729, l3: 0.046235, l4: 0.083087, l5: 0.146572, l6: 0.350181\n",
      "\n",
      "[epoch: 394/400, batch: 264/1000, ite: 52034] train loss: 1.1513, accuracy: 95.5063%, tar: 0.0189 \n",
      "l0: 0.022100, l1: 0.024749, l2: 0.036078, l3: 0.061299, l4: 0.122621, l5: 0.219585, l6: 0.353868\n",
      "\n",
      "[epoch: 394/400, batch: 272/1000, ite: 52035] train loss: 1.1527, accuracy: 95.0867%, tar: 0.0190 \n",
      "l0: 0.019876, l1: 0.021049, l2: 0.029069, l3: 0.044152, l4: 0.078611, l5: 0.180475, l6: 0.375428\n",
      "\n",
      "[epoch: 394/400, batch: 280/1000, ite: 52036] train loss: 1.1520, accuracy: 94.4012%, tar: 0.0191 \n",
      "l0: 0.012433, l1: 0.013735, l2: 0.019865, l3: 0.030911, l4: 0.055694, l5: 0.104953, l6: 0.238399\n",
      "\n",
      "[epoch: 394/400, batch: 288/1000, ite: 52037] train loss: 1.1403, accuracy: 96.9669%, tar: 0.0189 \n",
      "l0: 0.015873, l1: 0.017215, l2: 0.024904, l3: 0.035706, l4: 0.063943, l5: 0.116514, l6: 0.228940\n",
      "\n",
      "[epoch: 394/400, batch: 296/1000, ite: 52038] train loss: 1.1298, accuracy: 96.6403%, tar: 0.0188 \n",
      "l0: 0.016023, l1: 0.016631, l2: 0.023286, l3: 0.034382, l4: 0.060108, l5: 0.105834, l6: 0.245256\n",
      "\n",
      "[epoch: 394/400, batch: 304/1000, ite: 52039] train loss: 1.1201, accuracy: 96.1756%, tar: 0.0187 \n",
      "l0: 0.020127, l1: 0.021895, l2: 0.030164, l3: 0.048615, l4: 0.101773, l5: 0.214426, l6: 0.417955\n",
      "\n",
      "[epoch: 394/400, batch: 312/1000, ite: 52040] train loss: 1.1240, accuracy: 94.7976%, tar: 0.0188 \n",
      "l0: 0.015563, l1: 0.016436, l2: 0.024140, l3: 0.042035, l4: 0.077739, l5: 0.151721, l6: 0.270349\n",
      "\n",
      "[epoch: 394/400, batch: 320/1000, ite: 52041] train loss: 1.1177, accuracy: 95.7961%, tar: 0.0187 \n",
      "l0: 0.016936, l1: 0.017945, l2: 0.025110, l3: 0.038839, l4: 0.067614, l5: 0.116912, l6: 0.264874\n",
      "\n",
      "[epoch: 394/400, batch: 328/1000, ite: 52042] train loss: 1.1105, accuracy: 95.9691%, tar: 0.0186 \n",
      "l0: 0.016540, l1: 0.017642, l2: 0.024434, l3: 0.036015, l4: 0.068224, l5: 0.129538, l6: 0.347760\n",
      "\n",
      "[epoch: 394/400, batch: 336/1000, ite: 52043] train loss: 1.1077, accuracy: 95.2161%, tar: 0.0186 \n",
      "l0: 0.019769, l1: 0.021277, l2: 0.030030, l3: 0.046881, l4: 0.083559, l5: 0.174005, l6: 0.361449\n",
      "\n",
      "[epoch: 394/400, batch: 344/1000, ite: 52044] train loss: 1.1075, accuracy: 94.7729%, tar: 0.0186 \n",
      "l0: 0.020785, l1: 0.022196, l2: 0.029785, l3: 0.042952, l4: 0.088966, l5: 0.202728, l6: 0.378167\n",
      "\n",
      "[epoch: 394/400, batch: 352/1000, ite: 52045] train loss: 1.1088, accuracy: 94.7715%, tar: 0.0187 \n",
      "l0: 0.017391, l1: 0.018974, l2: 0.026851, l3: 0.041733, l4: 0.077767, l5: 0.166005, l6: 0.306648\n",
      "\n",
      "[epoch: 394/400, batch: 360/1000, ite: 52046] train loss: 1.1057, accuracy: 95.3240%, tar: 0.0186 \n",
      "l0: 0.018537, l1: 0.019409, l2: 0.027010, l3: 0.040145, l4: 0.069528, l5: 0.156075, l6: 0.328550\n",
      "\n",
      "[epoch: 394/400, batch: 368/1000, ite: 52047] train loss: 1.1033, accuracy: 95.0831%, tar: 0.0186 \n",
      "l0: 0.015914, l1: 0.017144, l2: 0.024326, l3: 0.038200, l4: 0.079193, l5: 0.199978, l6: 0.363621\n",
      "\n",
      "[epoch: 394/400, batch: 376/1000, ite: 52048] train loss: 1.1033, accuracy: 95.0018%, tar: 0.0186 \n",
      "l0: 0.018730, l1: 0.019995, l2: 0.027424, l3: 0.042693, l4: 0.079827, l5: 0.182604, l6: 0.319396\n",
      "\n",
      "[epoch: 394/400, batch: 384/1000, ite: 52049] train loss: 1.1015, accuracy: 95.7563%, tar: 0.0186 \n",
      "l0: 0.017563, l1: 0.018437, l2: 0.024133, l3: 0.037216, l4: 0.062927, l5: 0.131379, l6: 0.304182\n",
      "\n",
      "[epoch: 394/400, batch: 392/1000, ite: 52050] train loss: 1.0974, accuracy: 95.6198%, tar: 0.0186 \n",
      "l0: 0.020868, l1: 0.022179, l2: 0.027541, l3: 0.041925, l4: 0.082306, l5: 0.190847, l6: 0.393004\n",
      "\n",
      "[epoch: 394/400, batch: 400/1000, ite: 52051] train loss: 1.0990, accuracy: 94.5133%, tar: 0.0186 \n",
      "l0: 0.017432, l1: 0.018652, l2: 0.025098, l3: 0.034883, l4: 0.061474, l5: 0.128690, l6: 0.271038\n",
      "\n",
      "[epoch: 394/400, batch: 408/1000, ite: 52052] train loss: 1.0939, accuracy: 95.9822%, tar: 0.0186 \n",
      "l0: 0.014190, l1: 0.015371, l2: 0.020940, l3: 0.033415, l4: 0.062321, l5: 0.130979, l6: 0.307496\n",
      "\n",
      "[epoch: 394/400, batch: 416/1000, ite: 52053] train loss: 1.0903, accuracy: 96.2367%, tar: 0.0185 \n",
      "l0: 0.016333, l1: 0.017996, l2: 0.027422, l3: 0.049596, l4: 0.102502, l5: 0.201093, l6: 0.332044\n",
      "\n",
      "[epoch: 394/400, batch: 424/1000, ite: 52054] train loss: 1.0901, accuracy: 95.9814%, tar: 0.0185 \n",
      "l0: 0.016743, l1: 0.017932, l2: 0.025172, l3: 0.040643, l4: 0.081791, l5: 0.162268, l6: 0.325852\n",
      "\n",
      "[epoch: 394/400, batch: 432/1000, ite: 52055] train loss: 1.0884, accuracy: 95.0704%, tar: 0.0184 \n",
      "l0: 0.019177, l1: 0.021271, l2: 0.032393, l3: 0.053444, l4: 0.097622, l5: 0.205169, l6: 0.460610\n",
      "\n",
      "[epoch: 394/400, batch: 440/1000, ite: 52056] train loss: 1.0931, accuracy: 94.5950%, tar: 0.0184 \n",
      "l0: 0.017052, l1: 0.018523, l2: 0.025041, l3: 0.040448, l4: 0.083254, l5: 0.186520, l6: 0.437135\n",
      "\n",
      "[epoch: 394/400, batch: 448/1000, ite: 52057] train loss: 1.0959, accuracy: 94.1239%, tar: 0.0184 \n",
      "l0: 0.022725, l1: 0.024246, l2: 0.034142, l3: 0.050994, l4: 0.091188, l5: 0.193536, l6: 0.396155\n",
      "\n",
      "[epoch: 394/400, batch: 456/1000, ite: 52058] train loss: 1.0980, accuracy: 95.0049%, tar: 0.0185 \n",
      "l0: 0.020587, l1: 0.022384, l2: 0.030336, l3: 0.052755, l4: 0.094004, l5: 0.181995, l6: 0.355885\n",
      "\n",
      "[epoch: 394/400, batch: 464/1000, ite: 52059] train loss: 1.0983, accuracy: 95.0495%, tar: 0.0185 \n",
      "l0: 0.016288, l1: 0.017091, l2: 0.024768, l3: 0.043749, l4: 0.080866, l5: 0.157226, l6: 0.301426\n",
      "\n",
      "[epoch: 394/400, batch: 472/1000, ite: 52060] train loss: 1.0957, accuracy: 95.7013%, tar: 0.0185 \n",
      "l0: 0.016319, l1: 0.017168, l2: 0.023493, l3: 0.033666, l4: 0.054285, l5: 0.097011, l6: 0.247009\n",
      "\n",
      "[epoch: 394/400, batch: 480/1000, ite: 52061] train loss: 1.0899, accuracy: 96.2652%, tar: 0.0185 \n",
      "l0: 0.017666, l1: 0.019162, l2: 0.028847, l3: 0.048199, l4: 0.085392, l5: 0.172741, l6: 0.335886\n",
      "\n",
      "[epoch: 394/400, batch: 488/1000, ite: 52062] train loss: 1.0892, accuracy: 95.4760%, tar: 0.0184 \n",
      "l0: 0.015206, l1: 0.016772, l2: 0.024786, l3: 0.035430, l4: 0.063625, l5: 0.129971, l6: 0.277511\n",
      "\n",
      "[epoch: 394/400, batch: 496/1000, ite: 52063] train loss: 1.0853, accuracy: 96.4038%, tar: 0.0184 \n",
      "l0: 0.021207, l1: 0.022941, l2: 0.032509, l3: 0.052665, l4: 0.098756, l5: 0.194244, l6: 0.409716\n",
      "\n",
      "[epoch: 394/400, batch: 504/1000, ite: 52064] train loss: 1.0879, accuracy: 94.6798%, tar: 0.0184 \n",
      "l0: 0.014758, l1: 0.015571, l2: 0.022852, l3: 0.036413, l4: 0.070190, l5: 0.152376, l6: 0.307070\n",
      "\n",
      "[epoch: 394/400, batch: 512/1000, ite: 52065] train loss: 1.0854, accuracy: 95.6918%, tar: 0.0184 \n",
      "l0: 0.020356, l1: 0.021798, l2: 0.031807, l3: 0.052494, l4: 0.102612, l5: 0.213179, l6: 0.422969\n",
      "\n",
      "[epoch: 394/400, batch: 520/1000, ite: 52066] train loss: 1.0885, accuracy: 93.9784%, tar: 0.0184 \n",
      "l0: 0.020320, l1: 0.021777, l2: 0.029835, l3: 0.047459, l4: 0.086726, l5: 0.165166, l6: 0.371010\n",
      "\n",
      "[epoch: 394/400, batch: 528/1000, ite: 52067] train loss: 1.0890, accuracy: 95.0010%, tar: 0.0184 \n",
      "l0: 0.018295, l1: 0.019774, l2: 0.026801, l3: 0.043979, l4: 0.077858, l5: 0.155303, l6: 0.321447\n",
      "\n",
      "[epoch: 394/400, batch: 536/1000, ite: 52068] train loss: 1.0875, accuracy: 95.6599%, tar: 0.0184 \n",
      "l0: 0.016765, l1: 0.019043, l2: 0.030372, l3: 0.051713, l4: 0.103198, l5: 0.228999, l6: 0.403810\n",
      "\n",
      "[epoch: 394/400, batch: 544/1000, ite: 52069] train loss: 1.0900, accuracy: 94.4573%, tar: 0.0184 \n",
      "l0: 0.017267, l1: 0.018921, l2: 0.027572, l3: 0.042850, l4: 0.067618, l5: 0.130462, l6: 0.271732\n",
      "\n",
      "[epoch: 394/400, batch: 552/1000, ite: 52070] train loss: 1.0866, accuracy: 96.2558%, tar: 0.0184 \n",
      "l0: 0.019021, l1: 0.020426, l2: 0.028386, l3: 0.042530, l4: 0.081918, l5: 0.192598, l6: 0.425907\n",
      "\n",
      "[epoch: 394/400, batch: 560/1000, ite: 52071] train loss: 1.0888, accuracy: 94.6485%, tar: 0.0184 \n",
      "l0: 0.018391, l1: 0.021013, l2: 0.030863, l3: 0.052016, l4: 0.109358, l5: 0.305171, l6: 0.527027\n",
      "\n",
      "[epoch: 394/400, batch: 568/1000, ite: 52072] train loss: 1.0957, accuracy: 94.0293%, tar: 0.0184 \n",
      "l0: 0.018015, l1: 0.019494, l2: 0.026132, l3: 0.040388, l4: 0.075601, l5: 0.196734, l6: 0.428420\n",
      "\n",
      "[epoch: 394/400, batch: 576/1000, ite: 52073] train loss: 1.0977, accuracy: 94.1802%, tar: 0.0184 \n",
      "l0: 0.019646, l1: 0.020803, l2: 0.027522, l3: 0.038057, l4: 0.069381, l5: 0.136878, l6: 0.319463\n",
      "\n",
      "[epoch: 394/400, batch: 584/1000, ite: 52074] train loss: 1.0958, accuracy: 95.1060%, tar: 0.0184 \n",
      "l0: 0.020421, l1: 0.022678, l2: 0.032975, l3: 0.059305, l4: 0.116461, l5: 0.233856, l6: 0.444321\n",
      "\n",
      "[epoch: 394/400, batch: 592/1000, ite: 52075] train loss: 1.0996, accuracy: 93.8591%, tar: 0.0184 \n",
      "l0: 0.021132, l1: 0.021967, l2: 0.029959, l3: 0.042836, l4: 0.073493, l5: 0.131428, l6: 0.252310\n",
      "\n",
      "[epoch: 394/400, batch: 600/1000, ite: 52076] train loss: 1.0960, accuracy: 95.8949%, tar: 0.0185 \n",
      "l0: 0.015154, l1: 0.016566, l2: 0.022485, l3: 0.036977, l4: 0.071271, l5: 0.152993, l6: 0.314817\n",
      "\n",
      "[epoch: 394/400, batch: 608/1000, ite: 52077] train loss: 1.0941, accuracy: 96.0141%, tar: 0.0184 \n",
      "l0: 0.015139, l1: 0.016809, l2: 0.024514, l3: 0.047043, l4: 0.117858, l5: 0.258098, l6: 0.521762\n",
      "\n",
      "[epoch: 394/400, batch: 616/1000, ite: 52078] train loss: 1.0996, accuracy: 94.5304%, tar: 0.0184 \n",
      "l0: 0.019484, l1: 0.020753, l2: 0.027965, l3: 0.043904, l4: 0.082679, l5: 0.180812, l6: 0.379246\n",
      "\n",
      "[epoch: 394/400, batch: 624/1000, ite: 52079] train loss: 1.1000, accuracy: 95.0030%, tar: 0.0184 \n",
      "l0: 0.017549, l1: 0.019416, l2: 0.027930, l3: 0.045112, l4: 0.102764, l5: 0.257392, l6: 0.605166\n",
      "\n",
      "[epoch: 394/400, batch: 632/1000, ite: 52080] train loss: 1.1074, accuracy: 93.4068%, tar: 0.0184 \n",
      "l0: 0.023593, l1: 0.024989, l2: 0.032243, l3: 0.049065, l4: 0.082757, l5: 0.140438, l6: 0.323263\n",
      "\n",
      "[epoch: 394/400, batch: 640/1000, ite: 52081] train loss: 1.1061, accuracy: 94.6566%, tar: 0.0185 \n",
      "l0: 0.018602, l1: 0.020374, l2: 0.029211, l3: 0.049413, l4: 0.097897, l5: 0.199757, l6: 0.405984\n",
      "\n",
      "[epoch: 394/400, batch: 648/1000, ite: 52082] train loss: 1.1076, accuracy: 94.9595%, tar: 0.0185 \n",
      "l0: 0.017763, l1: 0.018437, l2: 0.025886, l3: 0.035372, l4: 0.060258, l5: 0.123819, l6: 0.232112\n",
      "\n",
      "[epoch: 394/400, batch: 656/1000, ite: 52083] train loss: 1.1032, accuracy: 96.6518%, tar: 0.0185 \n",
      "l0: 0.019639, l1: 0.021264, l2: 0.031774, l3: 0.048200, l4: 0.082581, l5: 0.197547, l6: 0.403121\n",
      "\n",
      "[epoch: 394/400, batch: 664/1000, ite: 52084] train loss: 1.1045, accuracy: 95.5238%, tar: 0.0185 \n",
      "l0: 0.011967, l1: 0.012853, l2: 0.017067, l3: 0.025741, l4: 0.048963, l5: 0.099566, l6: 0.217848\n",
      "\n",
      "[epoch: 394/400, batch: 672/1000, ite: 52085] train loss: 1.0992, accuracy: 96.9160%, tar: 0.0184 \n",
      "l0: 0.018296, l1: 0.020171, l2: 0.032360, l3: 0.057884, l4: 0.106498, l5: 0.191077, l6: 0.389912\n",
      "\n",
      "[epoch: 394/400, batch: 680/1000, ite: 52086] train loss: 1.1005, accuracy: 94.9967%, tar: 0.0184 \n",
      "l0: 0.018835, l1: 0.019687, l2: 0.026689, l3: 0.040099, l4: 0.067940, l5: 0.140177, l6: 0.356595\n",
      "\n",
      "[epoch: 394/400, batch: 688/1000, ite: 52087] train loss: 1.0997, accuracy: 95.0536%, tar: 0.0184 \n",
      "l0: 0.014976, l1: 0.016147, l2: 0.022830, l3: 0.038621, l4: 0.074900, l5: 0.155402, l6: 0.277181\n",
      "\n",
      "[epoch: 394/400, batch: 704/1000, ite: 52089] train loss: 1.0989, accuracy: 96.0352%, tar: 0.0184 \n",
      "l0: 0.016816, l1: 0.017656, l2: 0.022460, l3: 0.032696, l4: 0.057532, l5: 0.128625, l6: 0.285797\n",
      "\n",
      "[epoch: 394/400, batch: 712/1000, ite: 52090] train loss: 1.0962, accuracy: 95.6971%, tar: 0.0184 \n",
      "l0: 0.017419, l1: 0.019202, l2: 0.028615, l3: 0.047595, l4: 0.093730, l5: 0.171073, l6: 0.303781\n",
      "\n",
      "[epoch: 394/400, batch: 720/1000, ite: 52091] train loss: 1.0950, accuracy: 95.4042%, tar: 0.0184 \n",
      "l0: 0.018655, l1: 0.020380, l2: 0.030244, l3: 0.050072, l4: 0.114560, l5: 0.235008, l6: 0.428844\n",
      "\n",
      "[epoch: 394/400, batch: 728/1000, ite: 52092] train loss: 1.0975, accuracy: 94.4228%, tar: 0.0184 \n",
      "l0: 0.020396, l1: 0.022121, l2: 0.030785, l3: 0.050986, l4: 0.098482, l5: 0.201300, l6: 0.442995\n",
      "\n",
      "[epoch: 394/400, batch: 736/1000, ite: 52093] train loss: 1.0998, accuracy: 94.0433%, tar: 0.0184 \n",
      "l0: 0.018525, l1: 0.019374, l2: 0.027006, l3: 0.040519, l4: 0.076765, l5: 0.164575, l6: 0.352348\n",
      "\n",
      "[epoch: 394/400, batch: 744/1000, ite: 52094] train loss: 1.0994, accuracy: 95.0178%, tar: 0.0184 \n",
      "l0: 0.019052, l1: 0.020362, l2: 0.027822, l3: 0.044147, l4: 0.090714, l5: 0.224234, l6: 0.524356\n",
      "\n",
      "[epoch: 394/400, batch: 752/1000, ite: 52095] train loss: 1.1034, accuracy: 93.5567%, tar: 0.0184 \n",
      "l0: 0.016004, l1: 0.018193, l2: 0.027941, l3: 0.045651, l4: 0.084423, l5: 0.172417, l6: 0.370873\n",
      "\n",
      "[epoch: 394/400, batch: 760/1000, ite: 52096] train loss: 1.1034, accuracy: 95.5244%, tar: 0.0184 \n",
      "l0: 0.017879, l1: 0.019325, l2: 0.024707, l3: 0.035856, l4: 0.070711, l5: 0.136785, l6: 0.319650\n",
      "\n",
      "[epoch: 394/400, batch: 768/1000, ite: 52097] train loss: 1.1019, accuracy: 95.3742%, tar: 0.0184 \n",
      "l0: 0.021101, l1: 0.022329, l2: 0.031786, l3: 0.047412, l4: 0.082177, l5: 0.160546, l6: 0.300723\n",
      "\n",
      "[epoch: 394/400, batch: 776/1000, ite: 52098] train loss: 1.1005, accuracy: 95.6313%, tar: 0.0184 \n",
      "l0: 0.018118, l1: 0.019471, l2: 0.027987, l3: 0.045122, l4: 0.099790, l5: 0.205205, l6: 0.379191\n",
      "\n",
      "[epoch: 394/400, batch: 784/1000, ite: 52099] train loss: 1.1013, accuracy: 95.5855%, tar: 0.0184 \n",
      "l0: 0.017478, l1: 0.019014, l2: 0.026821, l3: 0.041301, l4: 0.091874, l5: 0.199018, l6: 0.421614\n",
      "\n",
      "[epoch: 394/400, batch: 792/1000, ite: 52100] train loss: 1.1027, accuracy: 94.3969%, tar: 0.0184 \n",
      "l0: 0.017411, l1: 0.019023, l2: 0.027746, l3: 0.047093, l4: 0.095575, l5: 0.193775, l6: 0.431021\n",
      "\n",
      "[epoch: 394/400, batch: 800/1000, ite: 52101] train loss: 1.1043, accuracy: 94.8655%, tar: 0.0184 \n",
      "l0: 0.018319, l1: 0.019778, l2: 0.027829, l3: 0.044378, l4: 0.091039, l5: 0.187267, l6: 0.376267\n",
      "\n",
      "[epoch: 394/400, batch: 808/1000, ite: 52102] train loss: 1.1047, accuracy: 94.8980%, tar: 0.0184 \n",
      "l0: 0.015380, l1: 0.016072, l2: 0.021659, l3: 0.031970, l4: 0.052586, l5: 0.114879, l6: 0.238961\n",
      "\n",
      "[epoch: 394/400, batch: 816/1000, ite: 52103] train loss: 1.1011, accuracy: 96.4455%, tar: 0.0183 \n",
      "l0: 0.019584, l1: 0.020946, l2: 0.028477, l3: 0.045055, l4: 0.086071, l5: 0.183294, l6: 0.411456\n",
      "\n",
      "[epoch: 394/400, batch: 824/1000, ite: 52104] train loss: 1.1021, accuracy: 94.1928%, tar: 0.0184 \n",
      "l0: 0.018274, l1: 0.020006, l2: 0.028903, l3: 0.048535, l4: 0.134218, l5: 0.264115, l6: 0.441336\n",
      "\n",
      "[epoch: 394/400, batch: 832/1000, ite: 52105] train loss: 1.1050, accuracy: 95.0977%, tar: 0.0184 \n",
      "l0: 0.023785, l1: 0.025283, l2: 0.035251, l3: 0.057150, l4: 0.110264, l5: 0.258066, l6: 0.488725\n",
      "\n",
      "[epoch: 394/400, batch: 840/1000, ite: 52106] train loss: 1.1086, accuracy: 93.5666%, tar: 0.0184 \n",
      "l0: 0.016407, l1: 0.018310, l2: 0.026750, l3: 0.043330, l4: 0.082997, l5: 0.197760, l6: 0.390703\n",
      "\n",
      "[epoch: 394/400, batch: 848/1000, ite: 52107] train loss: 1.1092, accuracy: 95.1437%, tar: 0.0184 \n",
      "l0: 0.025143, l1: 0.027767, l2: 0.038724, l3: 0.058965, l4: 0.113352, l5: 0.247966, l6: 0.472508\n",
      "\n",
      "[epoch: 394/400, batch: 856/1000, ite: 52108] train loss: 1.1124, accuracy: 93.8788%, tar: 0.0185 \n",
      "l0: 0.020984, l1: 0.021823, l2: 0.028649, l3: 0.043906, l4: 0.083129, l5: 0.157772, l6: 0.328936\n",
      "\n",
      "[epoch: 394/400, batch: 864/1000, ite: 52109] train loss: 1.1116, accuracy: 95.7472%, tar: 0.0185 \n",
      "l0: 0.017768, l1: 0.018909, l2: 0.026203, l3: 0.041880, l4: 0.082030, l5: 0.176761, l6: 0.374698\n",
      "\n",
      "[epoch: 394/400, batch: 872/1000, ite: 52110] train loss: 1.1116, accuracy: 94.7961%, tar: 0.0185 \n",
      "l0: 0.018732, l1: 0.020557, l2: 0.027535, l3: 0.041876, l4: 0.074096, l5: 0.205601, l6: 0.400862\n",
      "\n",
      "[epoch: 394/400, batch: 880/1000, ite: 52111] train loss: 1.1124, accuracy: 94.5367%, tar: 0.0185 \n",
      "l0: 0.015915, l1: 0.017471, l2: 0.024642, l3: 0.039469, l4: 0.073090, l5: 0.145761, l6: 0.287966\n",
      "\n",
      "[epoch: 394/400, batch: 888/1000, ite: 52112] train loss: 1.1104, accuracy: 96.4017%, tar: 0.0184 \n",
      "l0: 0.017930, l1: 0.019185, l2: 0.027940, l3: 0.042978, l4: 0.075743, l5: 0.133515, l6: 0.222145\n",
      "\n",
      "[epoch: 394/400, batch: 896/1000, ite: 52113] train loss: 1.1074, accuracy: 96.4207%, tar: 0.0184 \n",
      "l0: 0.021737, l1: 0.023458, l2: 0.032146, l3: 0.053194, l4: 0.106860, l5: 0.215199, l6: 0.408949\n",
      "\n",
      "[epoch: 394/400, batch: 904/1000, ite: 52114] train loss: 1.1089, accuracy: 94.3224%, tar: 0.0185 \n",
      "l0: 0.016662, l1: 0.018713, l2: 0.024793, l3: 0.041406, l4: 0.084660, l5: 0.176480, l6: 0.357570\n",
      "\n",
      "[epoch: 394/400, batch: 912/1000, ite: 52115] train loss: 1.1086, accuracy: 95.7160%, tar: 0.0185 \n",
      "l0: 0.019341, l1: 0.020100, l2: 0.025567, l3: 0.039246, l4: 0.066775, l5: 0.127926, l6: 0.273931\n",
      "\n",
      "[epoch: 394/400, batch: 920/1000, ite: 52116] train loss: 1.1064, accuracy: 95.6931%, tar: 0.0185 \n",
      "l0: 0.024490, l1: 0.026187, l2: 0.034085, l3: 0.046560, l4: 0.080516, l5: 0.183146, l6: 0.403035\n",
      "\n",
      "[epoch: 394/400, batch: 928/1000, ite: 52117] train loss: 1.1072, accuracy: 93.7683%, tar: 0.0185 \n",
      "l0: 0.021187, l1: 0.022736, l2: 0.030453, l3: 0.044923, l4: 0.085380, l5: 0.162170, l6: 0.300699\n",
      "\n",
      "[epoch: 394/400, batch: 936/1000, ite: 52118] train loss: 1.1061, accuracy: 95.6392%, tar: 0.0185 \n",
      "l0: 0.019506, l1: 0.020508, l2: 0.027483, l3: 0.041666, l4: 0.069563, l5: 0.138450, l6: 0.323578\n",
      "\n",
      "[epoch: 394/400, batch: 944/1000, ite: 52119] train loss: 1.1049, accuracy: 95.4831%, tar: 0.0185 \n",
      "l0: 0.020816, l1: 0.021784, l2: 0.029166, l3: 0.042247, l4: 0.076026, l5: 0.169607, l6: 0.345334\n",
      "\n",
      "[epoch: 394/400, batch: 952/1000, ite: 52120] train loss: 1.1045, accuracy: 95.2295%, tar: 0.0186 \n",
      "l0: 0.017645, l1: 0.018744, l2: 0.027597, l3: 0.042952, l4: 0.082648, l5: 0.229941, l6: 0.530025\n",
      "\n",
      "[epoch: 394/400, batch: 960/1000, ite: 52121] train loss: 1.1076, accuracy: 94.4249%, tar: 0.0186 \n",
      "l0: 0.020897, l1: 0.022725, l2: 0.031329, l3: 0.047303, l4: 0.088120, l5: 0.179748, l6: 0.359423\n",
      "\n",
      "[epoch: 394/400, batch: 968/1000, ite: 52122] train loss: 1.1077, accuracy: 95.2529%, tar: 0.0186 \n",
      "l0: 0.014165, l1: 0.014573, l2: 0.020426, l3: 0.028953, l4: 0.054834, l5: 0.113844, l6: 0.243145\n",
      "\n",
      "[epoch: 394/400, batch: 976/1000, ite: 52123] train loss: 1.1046, accuracy: 96.5765%, tar: 0.0185 \n",
      "l0: 0.018413, l1: 0.019680, l2: 0.027905, l3: 0.041639, l4: 0.074276, l5: 0.145057, l6: 0.327794\n",
      "\n",
      "[epoch: 394/400, batch: 984/1000, ite: 52124] train loss: 1.1037, accuracy: 95.4050%, tar: 0.0185 \n",
      "l0: 0.029153, l1: 0.030920, l2: 0.043216, l3: 0.063374, l4: 0.104559, l5: 0.184516, l6: 0.421196\n",
      "\n",
      "[epoch: 394/400, batch: 992/1000, ite: 52125] train loss: 1.1052, accuracy: 93.6603%, tar: 0.0186 \n",
      "l0: 0.016905, l1: 0.018142, l2: 0.024271, l3: 0.038696, l4: 0.081711, l5: 0.146395, l6: 0.309327\n",
      "\n",
      "[epoch: 394/400, batch: 1000/1000, ite: 52126] train loss: 1.1040, accuracy: 95.7236%, tar: 0.0186 \n",
      "l0: 0.017946, l1: 0.018843, l2: 0.025334, l3: 0.038684, l4: 0.071438, l5: 0.146647, l6: 0.417309\n",
      "\n",
      "[epoch: 395/400, batch: 8/1000, ite: 52127] train loss: 1.1044, accuracy: 94.5121%, tar: 0.0186 \n",
      "l0: 0.019838, l1: 0.022291, l2: 0.032588, l3: 0.049113, l4: 0.089901, l5: 0.230867, l6: 0.549127\n",
      "\n",
      "[epoch: 395/400, batch: 16/1000, ite: 52128] train loss: 1.1078, accuracy: 94.5292%, tar: 0.0186 \n",
      "l0: 0.015629, l1: 0.017429, l2: 0.026870, l3: 0.044825, l4: 0.076513, l5: 0.144344, l6: 0.279882\n",
      "\n",
      "[epoch: 395/400, batch: 24/1000, ite: 52129] train loss: 1.1062, accuracy: 96.4616%, tar: 0.0186 \n",
      "l0: 0.022600, l1: 0.024393, l2: 0.035779, l3: 0.055606, l4: 0.105221, l5: 0.249990, l6: 0.480601\n",
      "\n",
      "[epoch: 395/400, batch: 32/1000, ite: 52130] train loss: 1.1089, accuracy: 94.0204%, tar: 0.0186 \n",
      "l0: 0.017230, l1: 0.018418, l2: 0.025018, l3: 0.039574, l4: 0.079362, l5: 0.192900, l6: 0.359227\n",
      "\n",
      "[epoch: 395/400, batch: 40/1000, ite: 52131] train loss: 1.1088, accuracy: 95.3945%, tar: 0.0186 \n",
      "l0: 0.022154, l1: 0.024614, l2: 0.036936, l3: 0.066849, l4: 0.155337, l5: 0.339724, l6: 0.635792\n",
      "\n",
      "[epoch: 395/400, batch: 48/1000, ite: 52132] train loss: 1.1148, accuracy: 92.4736%, tar: 0.0186 \n",
      "l0: 0.018600, l1: 0.020095, l2: 0.027565, l3: 0.045026, l4: 0.082515, l5: 0.175489, l6: 0.350595\n",
      "\n",
      "[epoch: 395/400, batch: 56/1000, ite: 52133] train loss: 1.1145, accuracy: 95.0211%, tar: 0.0186 \n",
      "l0: 0.022606, l1: 0.024490, l2: 0.034271, l3: 0.052115, l4: 0.092250, l5: 0.202208, l6: 0.413735\n",
      "\n",
      "[epoch: 395/400, batch: 64/1000, ite: 52134] train loss: 1.1156, accuracy: 94.5714%, tar: 0.0187 \n",
      "l0: 0.016283, l1: 0.017666, l2: 0.024253, l3: 0.034885, l4: 0.059510, l5: 0.108375, l6: 0.231360\n",
      "\n",
      "[epoch: 395/400, batch: 72/1000, ite: 52135] train loss: 1.1127, accuracy: 96.9254%, tar: 0.0187 \n",
      "l0: 0.018991, l1: 0.021458, l2: 0.030693, l3: 0.054065, l4: 0.113899, l5: 0.242893, l6: 0.514096\n",
      "\n",
      "[epoch: 395/400, batch: 80/1000, ite: 52136] train loss: 1.1157, accuracy: 93.7335%, tar: 0.0187 \n",
      "l0: 0.016651, l1: 0.018102, l2: 0.026593, l3: 0.045340, l4: 0.111697, l5: 0.185014, l6: 0.317143\n",
      "\n",
      "[epoch: 395/400, batch: 88/1000, ite: 52137] train loss: 1.1151, accuracy: 96.3499%, tar: 0.0186 \n",
      "l0: 0.018202, l1: 0.020003, l2: 0.030043, l3: 0.053022, l4: 0.113487, l5: 0.222192, l6: 0.415800\n",
      "\n",
      "[epoch: 395/400, batch: 96/1000, ite: 52138] train loss: 1.1164, accuracy: 94.6288%, tar: 0.0186 \n",
      "l0: 0.024861, l1: 0.026694, l2: 0.036837, l3: 0.056725, l4: 0.116859, l5: 0.215691, l6: 0.358655\n",
      "\n",
      "[epoch: 395/400, batch: 104/1000, ite: 52139] train loss: 1.1170, accuracy: 95.3823%, tar: 0.0187 \n",
      "l0: 0.015144, l1: 0.017486, l2: 0.026456, l3: 0.048899, l4: 0.089422, l5: 0.159383, l6: 0.347645\n",
      "\n",
      "[epoch: 395/400, batch: 112/1000, ite: 52140] train loss: 1.1166, accuracy: 95.1802%, tar: 0.0187 \n",
      "l0: 0.019439, l1: 0.020493, l2: 0.026825, l3: 0.041179, l4: 0.079045, l5: 0.161128, l6: 0.335425\n",
      "\n",
      "[epoch: 395/400, batch: 120/1000, ite: 52141] train loss: 1.1159, accuracy: 94.9439%, tar: 0.0187 \n",
      "l0: 0.016536, l1: 0.017824, l2: 0.024711, l3: 0.039159, l4: 0.076153, l5: 0.173772, l6: 0.335142\n",
      "\n",
      "[epoch: 395/400, batch: 128/1000, ite: 52142] train loss: 1.1152, accuracy: 95.2001%, tar: 0.0186 \n",
      "l0: 0.018978, l1: 0.020723, l2: 0.028081, l3: 0.041277, l4: 0.077251, l5: 0.168125, l6: 0.339307\n",
      "\n",
      "[epoch: 395/400, batch: 136/1000, ite: 52143] train loss: 1.1147, accuracy: 95.4640%, tar: 0.0186 \n",
      "l0: 0.015686, l1: 0.017768, l2: 0.026801, l3: 0.043561, l4: 0.080976, l5: 0.148093, l6: 0.264267\n",
      "\n",
      "[epoch: 395/400, batch: 144/1000, ite: 52144] train loss: 1.1129, accuracy: 96.7241%, tar: 0.0186 \n",
      "l0: 0.022488, l1: 0.023788, l2: 0.030774, l3: 0.044836, l4: 0.085020, l5: 0.168984, l6: 0.338144\n",
      "\n",
      "[epoch: 395/400, batch: 152/1000, ite: 52145] train loss: 1.1125, accuracy: 95.4794%, tar: 0.0187 \n",
      "l0: 0.019524, l1: 0.020973, l2: 0.031248, l3: 0.050852, l4: 0.101726, l5: 0.219569, l6: 0.435239\n",
      "\n",
      "[epoch: 395/400, batch: 160/1000, ite: 52146] train loss: 1.1139, accuracy: 94.3802%, tar: 0.0187 \n",
      "l0: 0.019604, l1: 0.020530, l2: 0.028526, l3: 0.043023, l4: 0.074675, l5: 0.148866, l6: 0.308574\n",
      "\n",
      "[epoch: 395/400, batch: 168/1000, ite: 52147] train loss: 1.1129, accuracy: 95.1571%, tar: 0.0187 \n",
      "l0: 0.016972, l1: 0.018154, l2: 0.024226, l3: 0.035094, l4: 0.060523, l5: 0.115680, l6: 0.223448\n",
      "\n",
      "[epoch: 395/400, batch: 176/1000, ite: 52148] train loss: 1.1102, accuracy: 96.5275%, tar: 0.0187 \n",
      "l0: 0.017551, l1: 0.019049, l2: 0.028594, l3: 0.043792, l4: 0.082122, l5: 0.159347, l6: 0.326001\n",
      "\n",
      "[epoch: 395/400, batch: 184/1000, ite: 52149] train loss: 1.1095, accuracy: 95.4138%, tar: 0.0186 \n",
      "l0: 0.017689, l1: 0.018865, l2: 0.026508, l3: 0.036761, l4: 0.065618, l5: 0.147425, l6: 0.338457\n",
      "\n",
      "[epoch: 395/400, batch: 192/1000, ite: 52150] train loss: 1.1088, accuracy: 95.4369%, tar: 0.0186 \n",
      "l0: 0.018698, l1: 0.019422, l2: 0.025876, l3: 0.038577, l4: 0.070027, l5: 0.126304, l6: 0.339620\n",
      "\n",
      "[epoch: 395/400, batch: 200/1000, ite: 52151] train loss: 1.1079, accuracy: 95.9550%, tar: 0.0186 \n",
      "l0: 0.021039, l1: 0.021959, l2: 0.028619, l3: 0.043854, l4: 0.087747, l5: 0.186550, l6: 0.345402\n",
      "\n",
      "[epoch: 395/400, batch: 208/1000, ite: 52152] train loss: 1.1077, accuracy: 94.9428%, tar: 0.0187 \n",
      "l0: 0.019454, l1: 0.020881, l2: 0.026715, l3: 0.042732, l4: 0.070274, l5: 0.124900, l6: 0.274940\n",
      "\n",
      "[epoch: 395/400, batch: 216/1000, ite: 52153] train loss: 1.1061, accuracy: 96.2289%, tar: 0.0187 \n",
      "l0: 0.026687, l1: 0.028035, l2: 0.037631, l3: 0.052866, l4: 0.089384, l5: 0.194214, l6: 0.442984\n",
      "\n",
      "[epoch: 395/400, batch: 224/1000, ite: 52154] train loss: 1.1075, accuracy: 94.1459%, tar: 0.0187 \n",
      "l0: 0.019642, l1: 0.020983, l2: 0.028680, l3: 0.042383, l4: 0.072352, l5: 0.151077, l6: 0.345732\n",
      "\n",
      "[epoch: 395/400, batch: 232/1000, ite: 52155] train loss: 1.1070, accuracy: 95.1952%, tar: 0.0187 \n",
      "l0: 0.018574, l1: 0.020189, l2: 0.029724, l3: 0.048975, l4: 0.097158, l5: 0.221277, l6: 0.428726\n",
      "\n",
      "[epoch: 395/400, batch: 240/1000, ite: 52156] train loss: 1.1082, accuracy: 94.5948%, tar: 0.0187 \n",
      "l0: 0.022265, l1: 0.024176, l2: 0.032930, l3: 0.048828, l4: 0.091110, l5: 0.195192, l6: 0.406233\n",
      "\n",
      "[epoch: 395/400, batch: 248/1000, ite: 52157] train loss: 1.1089, accuracy: 94.6871%, tar: 0.0187 \n",
      "l0: 0.023219, l1: 0.023978, l2: 0.033561, l3: 0.049995, l4: 0.103768, l5: 0.253608, l6: 0.439839\n",
      "\n",
      "[epoch: 395/400, batch: 256/1000, ite: 52158] train loss: 1.1106, accuracy: 93.7747%, tar: 0.0188 \n",
      "l0: 0.019910, l1: 0.021209, l2: 0.029783, l3: 0.047955, l4: 0.096963, l5: 0.191467, l6: 0.376346\n",
      "\n",
      "[epoch: 395/400, batch: 264/1000, ite: 52159] train loss: 1.1109, accuracy: 95.2289%, tar: 0.0188 \n",
      "l0: 0.022321, l1: 0.023767, l2: 0.032297, l3: 0.048949, l4: 0.085464, l5: 0.184025, l6: 0.459633\n",
      "\n",
      "[epoch: 395/400, batch: 272/1000, ite: 52160] train loss: 1.1122, accuracy: 94.0566%, tar: 0.0188 \n",
      "l0: 0.018400, l1: 0.020141, l2: 0.029671, l3: 0.048815, l4: 0.094828, l5: 0.203374, l6: 0.379390\n",
      "\n",
      "[epoch: 395/400, batch: 280/1000, ite: 52161] train loss: 1.1126, accuracy: 94.9934%, tar: 0.0188 \n",
      "l0: 0.020041, l1: 0.020929, l2: 0.028994, l3: 0.044702, l4: 0.072860, l5: 0.124759, l6: 0.308457\n",
      "\n",
      "[epoch: 395/400, batch: 288/1000, ite: 52162] train loss: 1.1115, accuracy: 95.2960%, tar: 0.0188 \n",
      "l0: 0.019835, l1: 0.021064, l2: 0.028914, l3: 0.044500, l4: 0.080377, l5: 0.170646, l6: 0.376358\n",
      "\n",
      "[epoch: 395/400, batch: 296/1000, ite: 52163] train loss: 1.1116, accuracy: 94.5480%, tar: 0.0188 \n",
      "l0: 0.015938, l1: 0.016801, l2: 0.024805, l3: 0.037189, l4: 0.065364, l5: 0.137509, l6: 0.293697\n",
      "\n",
      "[epoch: 395/400, batch: 304/1000, ite: 52164] train loss: 1.1102, accuracy: 96.2177%, tar: 0.0188 \n",
      "l0: 0.025059, l1: 0.026262, l2: 0.034637, l3: 0.052125, l4: 0.094131, l5: 0.205807, l6: 0.460303\n",
      "\n",
      "[epoch: 395/400, batch: 312/1000, ite: 52165] train loss: 1.1117, accuracy: 93.9350%, tar: 0.0188 \n",
      "l0: 0.022478, l1: 0.024571, l2: 0.034499, l3: 0.052371, l4: 0.117342, l5: 0.285301, l6: 0.559795\n",
      "\n",
      "[epoch: 395/400, batch: 320/1000, ite: 52166] train loss: 1.1151, accuracy: 93.1044%, tar: 0.0189 \n",
      "l0: 0.017009, l1: 0.018105, l2: 0.024013, l3: 0.034884, l4: 0.068175, l5: 0.139703, l6: 0.340435\n",
      "\n",
      "[epoch: 395/400, batch: 328/1000, ite: 52167] train loss: 1.1143, accuracy: 95.5249%, tar: 0.0188 \n",
      "l0: 0.025054, l1: 0.026441, l2: 0.036985, l3: 0.057842, l4: 0.105209, l5: 0.209076, l6: 0.429623\n",
      "\n",
      "[epoch: 395/400, batch: 336/1000, ite: 52168] train loss: 1.1155, accuracy: 93.0263%, tar: 0.0189 \n",
      "l0: 0.013860, l1: 0.015318, l2: 0.021363, l3: 0.035994, l4: 0.077051, l5: 0.163202, l6: 0.349415\n",
      "\n",
      "[epoch: 395/400, batch: 344/1000, ite: 52169] train loss: 1.1150, accuracy: 95.7472%, tar: 0.0189 \n",
      "l0: 0.017976, l1: 0.019101, l2: 0.027044, l3: 0.041824, l4: 0.075626, l5: 0.149926, l6: 0.302452\n",
      "\n",
      "[epoch: 395/400, batch: 352/1000, ite: 52170] train loss: 1.1140, accuracy: 95.6498%, tar: 0.0188 \n",
      "l0: 0.021194, l1: 0.022951, l2: 0.032550, l3: 0.050492, l4: 0.101739, l5: 0.229528, l6: 0.482067\n",
      "\n",
      "[epoch: 395/400, batch: 360/1000, ite: 52171] train loss: 1.1159, accuracy: 94.0174%, tar: 0.0189 \n",
      "l0: 0.016980, l1: 0.018161, l2: 0.024511, l3: 0.036172, l4: 0.066885, l5: 0.119093, l6: 0.277455\n",
      "\n",
      "[epoch: 395/400, batch: 368/1000, ite: 52172] train loss: 1.1143, accuracy: 96.1936%, tar: 0.0188 \n",
      "l0: 0.018735, l1: 0.019919, l2: 0.026276, l3: 0.037807, l4: 0.064621, l5: 0.121343, l6: 0.263276\n",
      "\n",
      "[epoch: 395/400, batch: 376/1000, ite: 52173] train loss: 1.1126, accuracy: 96.0817%, tar: 0.0188 \n",
      "l0: 0.018816, l1: 0.020161, l2: 0.025547, l3: 0.039007, l4: 0.070805, l5: 0.139658, l6: 0.289748\n",
      "\n",
      "[epoch: 395/400, batch: 384/1000, ite: 52174] train loss: 1.1113, accuracy: 95.5399%, tar: 0.0188 \n",
      "l0: 0.018633, l1: 0.020170, l2: 0.027538, l3: 0.045503, l4: 0.081196, l5: 0.150078, l6: 0.290519\n",
      "\n",
      "[epoch: 395/400, batch: 392/1000, ite: 52175] train loss: 1.1103, accuracy: 95.2206%, tar: 0.0188 \n",
      "l0: 0.016721, l1: 0.018486, l2: 0.026237, l3: 0.046251, l4: 0.102254, l5: 0.185788, l6: 0.427397\n",
      "\n",
      "[epoch: 395/400, batch: 400/1000, ite: 52176] train loss: 1.1111, accuracy: 94.8559%, tar: 0.0188 \n",
      "l0: 0.016848, l1: 0.018098, l2: 0.024938, l3: 0.040236, l4: 0.075916, l5: 0.157782, l6: 0.354767\n",
      "\n",
      "[epoch: 395/400, batch: 408/1000, ite: 52177] train loss: 1.1108, accuracy: 95.5332%, tar: 0.0188 \n",
      "l0: 0.021220, l1: 0.022535, l2: 0.033243, l3: 0.048163, l4: 0.094345, l5: 0.202971, l6: 0.450399\n",
      "\n",
      "[epoch: 395/400, batch: 416/1000, ite: 52178] train loss: 1.1120, accuracy: 94.2572%, tar: 0.0188 \n",
      "l0: 0.019117, l1: 0.020613, l2: 0.029705, l3: 0.048563, l4: 0.084123, l5: 0.146088, l6: 0.309355\n",
      "\n",
      "[epoch: 395/400, batch: 424/1000, ite: 52179] train loss: 1.1112, accuracy: 95.0722%, tar: 0.0188 \n",
      "l0: 0.017147, l1: 0.017918, l2: 0.024726, l3: 0.037273, l4: 0.070554, l5: 0.151329, l6: 0.285499\n",
      "\n",
      "[epoch: 395/400, batch: 432/1000, ite: 52180] train loss: 1.1100, accuracy: 95.8645%, tar: 0.0188 \n",
      "l0: 0.020622, l1: 0.021791, l2: 0.028139, l3: 0.042338, l4: 0.080859, l5: 0.166980, l6: 0.330644\n",
      "\n",
      "[epoch: 395/400, batch: 440/1000, ite: 52181] train loss: 1.1095, accuracy: 95.1165%, tar: 0.0188 \n",
      "l0: 0.022374, l1: 0.023899, l2: 0.033381, l3: 0.051106, l4: 0.090135, l5: 0.188923, l6: 0.426305\n",
      "\n",
      "[epoch: 395/400, batch: 448/1000, ite: 52182] train loss: 1.1104, accuracy: 94.0947%, tar: 0.0189 \n",
      "l0: 0.016405, l1: 0.017877, l2: 0.027244, l3: 0.047809, l4: 0.125903, l5: 0.241382, l6: 0.415064\n",
      "\n",
      "[epoch: 395/400, batch: 456/1000, ite: 52183] train loss: 1.1115, accuracy: 94.5654%, tar: 0.0188 \n",
      "l0: 0.017723, l1: 0.019266, l2: 0.028635, l3: 0.047250, l4: 0.087874, l5: 0.173049, l6: 0.331197\n",
      "\n",
      "[epoch: 395/400, batch: 464/1000, ite: 52184] train loss: 1.1111, accuracy: 95.8259%, tar: 0.0188 \n",
      "l0: 0.018601, l1: 0.019587, l2: 0.026373, l3: 0.038741, l4: 0.073066, l5: 0.169203, l6: 0.335714\n",
      "\n",
      "[epoch: 395/400, batch: 472/1000, ite: 52185] train loss: 1.1106, accuracy: 95.1897%, tar: 0.0188 \n",
      "l0: 0.019721, l1: 0.021029, l2: 0.027471, l3: 0.041852, l4: 0.075532, l5: 0.165240, l6: 0.367532\n",
      "\n",
      "[epoch: 395/400, batch: 480/1000, ite: 52186] train loss: 1.1105, accuracy: 95.2479%, tar: 0.0188 \n",
      "l0: 0.024552, l1: 0.027158, l2: 0.038823, l3: 0.072041, l4: 0.140536, l5: 0.287030, l6: 0.517690\n",
      "\n",
      "[epoch: 395/400, batch: 488/1000, ite: 52187] train loss: 1.1133, accuracy: 94.1900%, tar: 0.0189 \n",
      "l0: 0.017664, l1: 0.019570, l2: 0.029425, l3: 0.048815, l4: 0.095532, l5: 0.162036, l6: 0.268615\n",
      "\n",
      "[epoch: 395/400, batch: 496/1000, ite: 52188] train loss: 1.1122, accuracy: 96.1704%, tar: 0.0189 \n",
      "l0: 0.018637, l1: 0.019517, l2: 0.024580, l3: 0.037735, l4: 0.061864, l5: 0.121759, l6: 0.292670\n",
      "\n",
      "[epoch: 395/400, batch: 504/1000, ite: 52189] train loss: 1.1109, accuracy: 95.3447%, tar: 0.0189 \n",
      "l0: 0.019246, l1: 0.020105, l2: 0.025157, l3: 0.036373, l4: 0.057997, l5: 0.122423, l6: 0.290708\n",
      "\n",
      "[epoch: 395/400, batch: 512/1000, ite: 52190] train loss: 1.1097, accuracy: 95.5032%, tar: 0.0189 \n",
      "l0: 0.016097, l1: 0.017821, l2: 0.026885, l3: 0.048770, l4: 0.090205, l5: 0.177065, l6: 0.413886\n",
      "\n",
      "[epoch: 395/400, batch: 520/1000, ite: 52191] train loss: 1.1102, accuracy: 95.7129%, tar: 0.0189 \n",
      "l0: 0.024427, l1: 0.025675, l2: 0.034453, l3: 0.052340, l4: 0.086583, l5: 0.171967, l6: 0.399724\n",
      "\n",
      "[epoch: 395/400, batch: 528/1000, ite: 52192] train loss: 1.1106, accuracy: 93.7283%, tar: 0.0189 \n",
      "l0: 0.027061, l1: 0.028604, l2: 0.037281, l3: 0.060582, l4: 0.131397, l5: 0.240293, l6: 0.426365\n",
      "\n",
      "[epoch: 395/400, batch: 536/1000, ite: 52193] train loss: 1.1120, accuracy: 93.9925%, tar: 0.0189 \n",
      "l0: 0.021139, l1: 0.023111, l2: 0.034616, l3: 0.057859, l4: 0.109476, l5: 0.221671, l6: 0.472141\n",
      "\n",
      "[epoch: 395/400, batch: 544/1000, ite: 52194] train loss: 1.1136, accuracy: 93.8277%, tar: 0.0189 \n",
      "l0: 0.020659, l1: 0.021772, l2: 0.031600, l3: 0.051321, l4: 0.089558, l5: 0.160351, l6: 0.310134\n",
      "\n",
      "[epoch: 395/400, batch: 552/1000, ite: 52195] train loss: 1.1130, accuracy: 95.8045%, tar: 0.0189 \n",
      "l0: 0.021188, l1: 0.022209, l2: 0.029564, l3: 0.044824, l4: 0.081747, l5: 0.212471, l6: 0.401891\n",
      "\n",
      "[epoch: 395/400, batch: 560/1000, ite: 52196] train loss: 1.1136, accuracy: 94.1973%, tar: 0.0190 \n",
      "l0: 0.022817, l1: 0.024455, l2: 0.031992, l3: 0.051445, l4: 0.105885, l5: 0.203787, l6: 0.412708\n",
      "\n",
      "[epoch: 395/400, batch: 568/1000, ite: 52197] train loss: 1.1143, accuracy: 94.1025%, tar: 0.0190 \n",
      "l0: 0.020861, l1: 0.022310, l2: 0.028822, l3: 0.043794, l4: 0.089941, l5: 0.150027, l6: 0.322635\n",
      "\n",
      "[epoch: 395/400, batch: 576/1000, ite: 52198] train loss: 1.1138, accuracy: 95.9832%, tar: 0.0190 \n",
      "l0: 0.016736, l1: 0.018841, l2: 0.027683, l3: 0.044841, l4: 0.082242, l5: 0.155367, l6: 0.290621\n",
      "\n",
      "[epoch: 395/400, batch: 584/1000, ite: 52199] train loss: 1.1128, accuracy: 96.2651%, tar: 0.0190 \n",
      "l0: 0.015961, l1: 0.017146, l2: 0.024576, l3: 0.038256, l4: 0.097454, l5: 0.180772, l6: 0.363246\n",
      "\n",
      "[epoch: 395/400, batch: 592/1000, ite: 52200] train loss: 1.1128, accuracy: 95.3791%, tar: 0.0190 \n",
      "l0: 0.020496, l1: 0.022031, l2: 0.030372, l3: 0.045101, l4: 0.077372, l5: 0.166139, l6: 0.373533\n",
      "\n",
      "[epoch: 395/400, batch: 600/1000, ite: 52201] train loss: 1.1128, accuracy: 94.8842%, tar: 0.0190 \n",
      "l0: 0.018971, l1: 0.020165, l2: 0.027932, l3: 0.041902, l4: 0.078106, l5: 0.178783, l6: 0.407421\n",
      "\n",
      "[epoch: 395/400, batch: 608/1000, ite: 52202] train loss: 1.1132, accuracy: 94.9321%, tar: 0.0190 \n",
      "l0: 0.018942, l1: 0.020172, l2: 0.027038, l3: 0.043294, l4: 0.088582, l5: 0.194402, l6: 0.375174\n",
      "\n",
      "[epoch: 395/400, batch: 616/1000, ite: 52203] train loss: 1.1133, accuracy: 94.9692%, tar: 0.0190 \n",
      "l0: 0.017581, l1: 0.019482, l2: 0.027862, l3: 0.045424, l4: 0.091603, l5: 0.197039, l6: 0.408970\n",
      "\n",
      "[epoch: 395/400, batch: 624/1000, ite: 52204] train loss: 1.1138, accuracy: 95.3446%, tar: 0.0190 \n",
      "l0: 0.020027, l1: 0.022188, l2: 0.030951, l3: 0.051133, l4: 0.097168, l5: 0.195855, l6: 0.353231\n",
      "\n",
      "[epoch: 395/400, batch: 632/1000, ite: 52205] train loss: 1.1139, accuracy: 95.2306%, tar: 0.0190 \n",
      "l0: 0.015882, l1: 0.016918, l2: 0.024517, l3: 0.038405, l4: 0.069122, l5: 0.148931, l6: 0.324304\n",
      "\n",
      "[epoch: 395/400, batch: 640/1000, ite: 52206] train loss: 1.1132, accuracy: 95.0454%, tar: 0.0189 \n",
      "l0: 0.012290, l1: 0.013014, l2: 0.019053, l3: 0.030929, l4: 0.059488, l5: 0.119122, l6: 0.218792\n",
      "\n",
      "[epoch: 395/400, batch: 648/1000, ite: 52207] train loss: 1.1111, accuracy: 96.8829%, tar: 0.0189 \n",
      "l0: 0.014559, l1: 0.015415, l2: 0.024702, l3: 0.042314, l4: 0.078880, l5: 0.142537, l6: 0.251950\n",
      "\n",
      "[epoch: 395/400, batch: 656/1000, ite: 52208] train loss: 1.1098, accuracy: 96.2330%, tar: 0.0189 \n",
      "l0: 0.016245, l1: 0.017416, l2: 0.023376, l3: 0.036793, l4: 0.076068, l5: 0.137869, l6: 0.264245\n",
      "\n",
      "[epoch: 395/400, batch: 664/1000, ite: 52209] train loss: 1.1085, accuracy: 96.1761%, tar: 0.0189 \n",
      "l0: 0.018951, l1: 0.020396, l2: 0.027134, l3: 0.045817, l4: 0.094219, l5: 0.188454, l6: 0.401311\n",
      "\n",
      "[epoch: 395/400, batch: 672/1000, ite: 52210] train loss: 1.1089, accuracy: 94.8907%, tar: 0.0189 \n",
      "l0: 0.023458, l1: 0.024750, l2: 0.031899, l3: 0.047670, l4: 0.091533, l5: 0.210895, l6: 0.399672\n",
      "\n",
      "[epoch: 395/400, batch: 680/1000, ite: 52211] train loss: 1.1095, accuracy: 94.3643%, tar: 0.0189 \n",
      "l0: 0.015621, l1: 0.016882, l2: 0.024387, l3: 0.037005, l4: 0.071759, l5: 0.148026, l6: 0.273645\n",
      "\n",
      "[epoch: 395/400, batch: 688/1000, ite: 52212] train loss: 1.1083, accuracy: 96.0640%, tar: 0.0189 \n",
      "l0: 0.016008, l1: 0.016923, l2: 0.023995, l3: 0.038860, l4: 0.064280, l5: 0.126422, l6: 0.255124\n",
      "\n",
      "[epoch: 395/400, batch: 696/1000, ite: 52213] train loss: 1.1069, accuracy: 96.1317%, tar: 0.0189 \n",
      "l0: 0.018529, l1: 0.020323, l2: 0.029355, l3: 0.042920, l4: 0.080668, l5: 0.177928, l6: 0.386261\n",
      "\n",
      "[epoch: 395/400, batch: 704/1000, ite: 52214] train loss: 1.1071, accuracy: 95.5274%, tar: 0.0189 \n",
      "l0: 0.013976, l1: 0.015693, l2: 0.024216, l3: 0.036374, l4: 0.068091, l5: 0.147161, l6: 0.354687\n",
      "\n",
      "[epoch: 395/400, batch: 712/1000, ite: 52215] train loss: 1.1067, accuracy: 95.7936%, tar: 0.0189 \n",
      "l0: 0.018012, l1: 0.018923, l2: 0.024321, l3: 0.037843, l4: 0.065894, l5: 0.134918, l6: 0.318004\n",
      "\n",
      "[epoch: 395/400, batch: 720/1000, ite: 52216] train loss: 1.1059, accuracy: 95.2292%, tar: 0.0188 \n",
      "l0: 0.017767, l1: 0.018375, l2: 0.022416, l3: 0.035964, l4: 0.060597, l5: 0.144052, l6: 0.312989\n",
      "\n",
      "[epoch: 395/400, batch: 728/1000, ite: 52217] train loss: 1.1051, accuracy: 95.4973%, tar: 0.0188 \n",
      "l0: 0.018006, l1: 0.019053, l2: 0.027108, l3: 0.040696, l4: 0.077974, l5: 0.178263, l6: 0.373549\n",
      "\n",
      "[epoch: 395/400, batch: 736/1000, ite: 52218] train loss: 1.1052, accuracy: 95.2271%, tar: 0.0188 \n",
      "l0: 0.020215, l1: 0.021733, l2: 0.030000, l3: 0.047936, l4: 0.093924, l5: 0.213012, l6: 0.408781\n",
      "\n",
      "[epoch: 395/400, batch: 744/1000, ite: 52219] train loss: 1.1058, accuracy: 94.2673%, tar: 0.0188 \n",
      "l0: 0.016314, l1: 0.017312, l2: 0.025560, l3: 0.040911, l4: 0.083468, l5: 0.194060, l6: 0.392817\n",
      "\n",
      "[epoch: 395/400, batch: 752/1000, ite: 52220] train loss: 1.1061, accuracy: 94.0669%, tar: 0.0188 \n",
      "l0: 0.014229, l1: 0.015484, l2: 0.022321, l3: 0.036251, l4: 0.065731, l5: 0.120843, l6: 0.354677\n",
      "\n",
      "[epoch: 395/400, batch: 760/1000, ite: 52221] train loss: 1.1055, accuracy: 94.7268%, tar: 0.0188 \n",
      "l0: 0.019112, l1: 0.020069, l2: 0.026985, l3: 0.041500, l4: 0.080511, l5: 0.173412, l6: 0.301540\n",
      "\n",
      "[epoch: 395/400, batch: 768/1000, ite: 52222] train loss: 1.1049, accuracy: 95.0467%, tar: 0.0188 \n",
      "l0: 0.024032, l1: 0.025303, l2: 0.032686, l3: 0.047324, l4: 0.080736, l5: 0.174914, l6: 0.364433\n",
      "\n",
      "[epoch: 395/400, batch: 776/1000, ite: 52223] train loss: 1.1050, accuracy: 94.6367%, tar: 0.0188 \n",
      "l0: 0.014739, l1: 0.015634, l2: 0.021797, l3: 0.032064, l4: 0.054274, l5: 0.112988, l6: 0.360157\n",
      "\n",
      "[epoch: 395/400, batch: 784/1000, ite: 52224] train loss: 1.1044, accuracy: 95.6279%, tar: 0.0188 \n",
      "l0: 0.014683, l1: 0.016556, l2: 0.025061, l3: 0.047706, l4: 0.095958, l5: 0.190034, l6: 0.378925\n",
      "\n",
      "[epoch: 395/400, batch: 792/1000, ite: 52225] train loss: 1.1046, accuracy: 95.7788%, tar: 0.0188 \n",
      "l0: 0.020357, l1: 0.021765, l2: 0.029483, l3: 0.045491, l4: 0.081759, l5: 0.182966, l6: 0.378875\n",
      "\n",
      "[epoch: 395/400, batch: 800/1000, ite: 52226] train loss: 1.1048, accuracy: 95.4742%, tar: 0.0188 \n",
      "l0: 0.023336, l1: 0.024530, l2: 0.034176, l3: 0.051396, l4: 0.087701, l5: 0.193088, l6: 0.355969\n",
      "\n",
      "[epoch: 395/400, batch: 808/1000, ite: 52227] train loss: 1.1049, accuracy: 94.9458%, tar: 0.0188 \n",
      "l0: 0.021396, l1: 0.022744, l2: 0.030623, l3: 0.047068, l4: 0.096491, l5: 0.211469, l6: 0.382251\n",
      "\n",
      "[epoch: 395/400, batch: 816/1000, ite: 52228] train loss: 1.1053, accuracy: 95.4097%, tar: 0.0188 \n",
      "l0: 0.018352, l1: 0.020517, l2: 0.027390, l3: 0.042996, l4: 0.084689, l5: 0.189987, l6: 0.377282\n",
      "\n",
      "[epoch: 395/400, batch: 824/1000, ite: 52229] train loss: 1.1054, accuracy: 95.4775%, tar: 0.0188 \n",
      "l0: 0.018221, l1: 0.019286, l2: 0.026483, l3: 0.041464, l4: 0.078965, l5: 0.135042, l6: 0.305741\n",
      "\n",
      "[epoch: 395/400, batch: 832/1000, ite: 52230] train loss: 1.1047, accuracy: 95.8214%, tar: 0.0188 \n",
      "l0: 0.022841, l1: 0.024775, l2: 0.035199, l3: 0.055069, l4: 0.100768, l5: 0.225217, l6: 0.468570\n",
      "\n",
      "[epoch: 395/400, batch: 840/1000, ite: 52231] train loss: 1.1060, accuracy: 94.2493%, tar: 0.0189 \n",
      "l0: 0.023092, l1: 0.024546, l2: 0.031939, l3: 0.047048, l4: 0.091186, l5: 0.171710, l6: 0.386478\n",
      "\n",
      "[epoch: 395/400, batch: 848/1000, ite: 52232] train loss: 1.1062, accuracy: 94.2082%, tar: 0.0189 \n",
      "l0: 0.025331, l1: 0.026961, l2: 0.037552, l3: 0.057987, l4: 0.105838, l5: 0.226409, l6: 0.463890\n",
      "\n",
      "[epoch: 395/400, batch: 856/1000, ite: 52233] train loss: 1.1075, accuracy: 93.7740%, tar: 0.0189 \n",
      "l0: 0.016264, l1: 0.017153, l2: 0.024592, l3: 0.039471, l4: 0.070519, l5: 0.129416, l6: 0.307438\n",
      "\n",
      "[epoch: 395/400, batch: 864/1000, ite: 52234] train loss: 1.1067, accuracy: 96.3628%, tar: 0.0189 \n",
      "l0: 0.017840, l1: 0.018615, l2: 0.024806, l3: 0.038770, l4: 0.076070, l5: 0.165387, l6: 0.379655\n",
      "\n",
      "[epoch: 395/400, batch: 872/1000, ite: 52235] train loss: 1.1067, accuracy: 94.9447%, tar: 0.0189 \n",
      "l0: 0.020228, l1: 0.020810, l2: 0.025688, l3: 0.034619, l4: 0.063885, l5: 0.137291, l6: 0.322354\n",
      "\n",
      "[epoch: 395/400, batch: 880/1000, ite: 52236] train loss: 1.1060, accuracy: 95.1968%, tar: 0.0189 \n",
      "l0: 0.019794, l1: 0.020775, l2: 0.029542, l3: 0.044987, l4: 0.081142, l5: 0.161337, l6: 0.458649\n",
      "\n",
      "[epoch: 395/400, batch: 888/1000, ite: 52237] train loss: 1.1068, accuracy: 93.8877%, tar: 0.0189 \n",
      "l0: 0.019381, l1: 0.020512, l2: 0.028698, l3: 0.042804, l4: 0.072053, l5: 0.159296, l6: 0.313152\n",
      "\n",
      "[epoch: 395/400, batch: 896/1000, ite: 52238] train loss: 1.1062, accuracy: 95.7398%, tar: 0.0189 \n",
      "l0: 0.016438, l1: 0.017513, l2: 0.023996, l3: 0.035811, l4: 0.062481, l5: 0.131572, l6: 0.279928\n",
      "\n",
      "[epoch: 395/400, batch: 904/1000, ite: 52239] train loss: 1.1052, accuracy: 95.8438%, tar: 0.0189 \n",
      "l0: 0.021947, l1: 0.022473, l2: 0.030285, l3: 0.043199, l4: 0.075149, l5: 0.144154, l6: 0.321387\n",
      "\n",
      "[epoch: 395/400, batch: 912/1000, ite: 52240] train loss: 1.1046, accuracy: 95.1549%, tar: 0.0189 \n",
      "l0: 0.018722, l1: 0.020143, l2: 0.028421, l3: 0.041916, l4: 0.077655, l5: 0.181956, l6: 0.358028\n",
      "\n",
      "[epoch: 395/400, batch: 920/1000, ite: 52241] train loss: 1.1046, accuracy: 94.5494%, tar: 0.0189 \n",
      "l0: 0.015223, l1: 0.015999, l2: 0.022093, l3: 0.034626, l4: 0.061898, l5: 0.112431, l6: 0.252141\n",
      "\n",
      "[epoch: 395/400, batch: 928/1000, ite: 52242] train loss: 1.1032, accuracy: 95.8595%, tar: 0.0189 \n",
      "l0: 0.015842, l1: 0.017281, l2: 0.026159, l3: 0.038931, l4: 0.087120, l5: 0.175603, l6: 0.302013\n",
      "\n",
      "[epoch: 395/400, batch: 936/1000, ite: 52243] train loss: 1.1026, accuracy: 96.3354%, tar: 0.0189 \n",
      "l0: 0.014605, l1: 0.015360, l2: 0.020392, l3: 0.030623, l4: 0.049734, l5: 0.091645, l6: 0.229486\n",
      "\n",
      "[epoch: 395/400, batch: 944/1000, ite: 52244] train loss: 1.1009, accuracy: 96.1623%, tar: 0.0189 \n",
      "l0: 0.021434, l1: 0.022481, l2: 0.029360, l3: 0.044356, l4: 0.081588, l5: 0.167683, l6: 0.428850\n",
      "\n",
      "[epoch: 395/400, batch: 952/1000, ite: 52245] train loss: 1.1014, accuracy: 94.3584%, tar: 0.0189 \n",
      "l0: 0.015621, l1: 0.016890, l2: 0.024152, l3: 0.039665, l4: 0.081910, l5: 0.198744, l6: 0.409901\n",
      "\n",
      "[epoch: 395/400, batch: 960/1000, ite: 52246] train loss: 1.1018, accuracy: 94.5889%, tar: 0.0188 \n",
      "l0: 0.022213, l1: 0.024579, l2: 0.032807, l3: 0.049643, l4: 0.083611, l5: 0.179683, l6: 0.401437\n",
      "\n",
      "[epoch: 395/400, batch: 968/1000, ite: 52247] train loss: 1.1022, accuracy: 94.9900%, tar: 0.0189 \n",
      "l0: 0.018915, l1: 0.020178, l2: 0.027709, l3: 0.038901, l4: 0.067339, l5: 0.134675, l6: 0.295226\n",
      "\n",
      "[epoch: 395/400, batch: 976/1000, ite: 52248] train loss: 1.1014, accuracy: 95.4204%, tar: 0.0189 \n",
      "l0: 0.016361, l1: 0.018059, l2: 0.027958, l3: 0.044650, l4: 0.085127, l5: 0.168517, l6: 0.363272\n",
      "\n",
      "[epoch: 395/400, batch: 984/1000, ite: 52249] train loss: 1.1014, accuracy: 95.6727%, tar: 0.0189 \n",
      "l0: 0.029903, l1: 0.032305, l2: 0.044785, l3: 0.068410, l4: 0.151566, l5: 0.349171, l6: 0.700776\n",
      "\n",
      "[epoch: 395/400, batch: 992/1000, ite: 52250] train loss: 1.1053, accuracy: 91.4539%, tar: 0.0189 \n",
      "l0: 0.016919, l1: 0.018247, l2: 0.027612, l3: 0.042636, l4: 0.080905, l5: 0.162788, l6: 0.302669\n",
      "\n",
      "[epoch: 395/400, batch: 1000/1000, ite: 52251] train loss: 1.1047, accuracy: 95.7774%, tar: 0.0189 \n",
      "l0: 0.019478, l1: 0.020615, l2: 0.028281, l3: 0.041715, l4: 0.075137, l5: 0.163981, l6: 0.345003\n",
      "\n",
      "[epoch: 396/400, batch: 8/1000, ite: 52252] train loss: 1.1045, accuracy: 95.2144%, tar: 0.0189 \n",
      "l0: 0.017033, l1: 0.018485, l2: 0.028033, l3: 0.044955, l4: 0.078502, l5: 0.159231, l6: 0.312375\n",
      "\n",
      "[epoch: 396/400, batch: 16/1000, ite: 52253] train loss: 1.1039, accuracy: 95.9958%, tar: 0.0189 \n",
      "l0: 0.018041, l1: 0.018939, l2: 0.027114, l3: 0.039340, l4: 0.075335, l5: 0.198978, l6: 0.406585\n",
      "\n",
      "[epoch: 396/400, batch: 24/1000, ite: 52254] train loss: 1.1043, accuracy: 94.8181%, tar: 0.0189 \n",
      "l0: 0.020655, l1: 0.021635, l2: 0.031117, l3: 0.049877, l4: 0.090533, l5: 0.179913, l6: 0.348605\n",
      "\n",
      "[epoch: 396/400, batch: 32/1000, ite: 52255] train loss: 1.1043, accuracy: 95.0305%, tar: 0.0189 \n",
      "l0: 0.017685, l1: 0.019683, l2: 0.027377, l3: 0.042004, l4: 0.079472, l5: 0.184006, l6: 0.390972\n",
      "\n",
      "[epoch: 396/400, batch: 40/1000, ite: 52256] train loss: 1.1045, accuracy: 94.9370%, tar: 0.0189 \n",
      "l0: 0.012642, l1: 0.013443, l2: 0.019574, l3: 0.030964, l4: 0.060930, l5: 0.157156, l6: 0.332621\n",
      "\n",
      "[epoch: 396/400, batch: 48/1000, ite: 52257] train loss: 1.1039, accuracy: 95.9954%, tar: 0.0189 \n",
      "l0: 0.018881, l1: 0.020883, l2: 0.029621, l3: 0.053894, l4: 0.118408, l5: 0.217971, l6: 0.433860\n",
      "\n",
      "[epoch: 396/400, batch: 56/1000, ite: 52258] train loss: 1.1048, accuracy: 94.1194%, tar: 0.0189 \n",
      "l0: 0.017580, l1: 0.018460, l2: 0.025994, l3: 0.040701, l4: 0.070140, l5: 0.136276, l6: 0.259153\n",
      "\n",
      "[epoch: 396/400, batch: 64/1000, ite: 52259] train loss: 1.1038, accuracy: 95.6263%, tar: 0.0189 \n",
      "l0: 0.019199, l1: 0.020237, l2: 0.028715, l3: 0.048972, l4: 0.093173, l5: 0.175783, l6: 0.367008\n",
      "\n",
      "[epoch: 396/400, batch: 72/1000, ite: 52260] train loss: 1.1038, accuracy: 94.3623%, tar: 0.0189 \n",
      "l0: 0.018966, l1: 0.021348, l2: 0.031061, l3: 0.055970, l4: 0.126824, l5: 0.252359, l6: 0.523641\n",
      "\n",
      "[epoch: 396/400, batch: 80/1000, ite: 52261] train loss: 1.1056, accuracy: 94.1158%, tar: 0.0189 \n",
      "l0: 0.021016, l1: 0.022569, l2: 0.030799, l3: 0.049168, l4: 0.083524, l5: 0.168974, l6: 0.369302\n",
      "\n",
      "[epoch: 396/400, batch: 88/1000, ite: 52262] train loss: 1.1056, accuracy: 94.4548%, tar: 0.0189 \n",
      "l0: 0.017093, l1: 0.018441, l2: 0.026589, l3: 0.045977, l4: 0.119064, l5: 0.244161, l6: 0.422637\n",
      "\n",
      "[epoch: 396/400, batch: 96/1000, ite: 52263] train loss: 1.1064, accuracy: 94.3941%, tar: 0.0189 \n",
      "l0: 0.021893, l1: 0.023537, l2: 0.031208, l3: 0.044990, l4: 0.085442, l5: 0.177186, l6: 0.327775\n",
      "\n",
      "[epoch: 396/400, batch: 104/1000, ite: 52264] train loss: 1.1062, accuracy: 95.3170%, tar: 0.0189 \n",
      "l0: 0.019241, l1: 0.020709, l2: 0.028641, l3: 0.044304, l4: 0.090162, l5: 0.191952, l6: 0.446892\n",
      "\n",
      "[epoch: 396/400, batch: 112/1000, ite: 52265] train loss: 1.1069, accuracy: 94.5063%, tar: 0.0189 \n",
      "l0: 0.019695, l1: 0.022047, l2: 0.032867, l3: 0.054564, l4: 0.133979, l5: 0.276019, l6: 0.525998\n",
      "\n",
      "[epoch: 396/400, batch: 120/1000, ite: 52266] train loss: 1.1087, accuracy: 93.9973%, tar: 0.0189 \n",
      "l0: 0.014709, l1: 0.015737, l2: 0.022133, l3: 0.034412, l4: 0.067008, l5: 0.123268, l6: 0.291986\n",
      "\n",
      "[epoch: 396/400, batch: 128/1000, ite: 52267] train loss: 1.1078, accuracy: 95.8934%, tar: 0.0189 \n",
      "l0: 0.015810, l1: 0.017901, l2: 0.027523, l3: 0.046130, l4: 0.102526, l5: 0.215575, l6: 0.464514\n",
      "\n",
      "[epoch: 396/400, batch: 136/1000, ite: 52268] train loss: 1.1087, accuracy: 94.8927%, tar: 0.0188 \n",
      "l0: 0.019216, l1: 0.021355, l2: 0.030097, l3: 0.044906, l4: 0.082350, l5: 0.169028, l6: 0.359679\n",
      "\n",
      "[epoch: 396/400, batch: 144/1000, ite: 52269] train loss: 1.1086, accuracy: 95.2305%, tar: 0.0188 \n",
      "l0: 0.018345, l1: 0.019428, l2: 0.026307, l3: 0.039549, l4: 0.071609, l5: 0.160793, l6: 0.435641\n",
      "\n",
      "[epoch: 396/400, batch: 152/1000, ite: 52270] train loss: 1.1090, accuracy: 94.8601%, tar: 0.0188 \n",
      "l0: 0.017723, l1: 0.018853, l2: 0.025234, l3: 0.036943, l4: 0.062659, l5: 0.115389, l6: 0.304285\n",
      "\n",
      "[epoch: 396/400, batch: 160/1000, ite: 52271] train loss: 1.1082, accuracy: 95.5030%, tar: 0.0188 \n",
      "l0: 0.019902, l1: 0.021998, l2: 0.031825, l3: 0.048469, l4: 0.096489, l5: 0.218870, l6: 0.404743\n",
      "\n",
      "[epoch: 396/400, batch: 168/1000, ite: 52272] train loss: 1.1087, accuracy: 94.9965%, tar: 0.0188 \n",
      "l0: 0.020447, l1: 0.022464, l2: 0.031943, l3: 0.050652, l4: 0.100928, l5: 0.222802, l6: 0.476252\n",
      "\n",
      "[epoch: 396/400, batch: 176/1000, ite: 52273] train loss: 1.1097, accuracy: 94.5727%, tar: 0.0189 \n",
      "l0: 0.014778, l1: 0.016006, l2: 0.021733, l3: 0.032369, l4: 0.056546, l5: 0.092933, l6: 0.213844\n",
      "\n",
      "[epoch: 396/400, batch: 184/1000, ite: 52274] train loss: 1.1081, accuracy: 96.6333%, tar: 0.0188 \n",
      "l0: 0.023823, l1: 0.025522, l2: 0.036445, l3: 0.054319, l4: 0.114414, l5: 0.300349, l6: 0.588496\n",
      "\n",
      "[epoch: 396/400, batch: 192/1000, ite: 52275] train loss: 1.1104, accuracy: 92.4285%, tar: 0.0189 \n",
      "l0: 0.023117, l1: 0.024528, l2: 0.032879, l3: 0.050757, l4: 0.098575, l5: 0.200024, l6: 0.408195\n",
      "\n",
      "[epoch: 396/400, batch: 200/1000, ite: 52276] train loss: 1.1109, accuracy: 94.2806%, tar: 0.0189 \n",
      "l0: 0.020963, l1: 0.022808, l2: 0.034793, l3: 0.059268, l4: 0.121083, l5: 0.201168, l6: 0.391264\n",
      "\n",
      "[epoch: 396/400, batch: 208/1000, ite: 52277] train loss: 1.1114, accuracy: 95.4243%, tar: 0.0189 \n",
      "l0: 0.020482, l1: 0.021610, l2: 0.027565, l3: 0.041535, l4: 0.078942, l5: 0.150969, l6: 0.351392\n",
      "\n",
      "[epoch: 396/400, batch: 216/1000, ite: 52278] train loss: 1.1111, accuracy: 94.7288%, tar: 0.0189 \n",
      "l0: 0.022699, l1: 0.023951, l2: 0.032378, l3: 0.046461, l4: 0.082044, l5: 0.176362, l6: 0.374753\n",
      "\n",
      "[epoch: 396/400, batch: 224/1000, ite: 52279] train loss: 1.1112, accuracy: 94.6029%, tar: 0.0189 \n",
      "l0: 0.020280, l1: 0.022209, l2: 0.032542, l3: 0.053820, l4: 0.105179, l5: 0.263448, l6: 0.447727\n",
      "\n",
      "[epoch: 396/400, batch: 232/1000, ite: 52280] train loss: 1.1122, accuracy: 94.4962%, tar: 0.0189 \n",
      "l0: 0.016985, l1: 0.018505, l2: 0.026667, l3: 0.039272, l4: 0.063931, l5: 0.110868, l6: 0.345497\n",
      "\n",
      "[epoch: 396/400, batch: 240/1000, ite: 52281] train loss: 1.1117, accuracy: 96.0982%, tar: 0.0189 \n",
      "l0: 0.018603, l1: 0.019975, l2: 0.027555, l3: 0.042581, l4: 0.076380, l5: 0.154810, l6: 0.345416\n",
      "\n",
      "[epoch: 396/400, batch: 248/1000, ite: 52282] train loss: 1.1114, accuracy: 95.2472%, tar: 0.0189 \n",
      "l0: 0.016602, l1: 0.018142, l2: 0.023845, l3: 0.037722, l4: 0.067132, l5: 0.132852, l6: 0.263158\n",
      "\n",
      "[epoch: 396/400, batch: 256/1000, ite: 52283] train loss: 1.1105, accuracy: 96.3058%, tar: 0.0189 \n",
      "l0: 0.019444, l1: 0.020385, l2: 0.026728, l3: 0.038234, l4: 0.062782, l5: 0.128830, l6: 0.315624\n",
      "\n",
      "[epoch: 396/400, batch: 264/1000, ite: 52284] train loss: 1.1098, accuracy: 95.2651%, tar: 0.0189 \n",
      "l0: 0.019734, l1: 0.021152, l2: 0.029205, l3: 0.042840, l4: 0.080178, l5: 0.179607, l6: 0.465499\n",
      "\n",
      "[epoch: 396/400, batch: 272/1000, ite: 52285] train loss: 1.1105, accuracy: 94.0847%, tar: 0.0189 \n",
      "l0: 0.021303, l1: 0.023417, l2: 0.032323, l3: 0.051014, l4: 0.093099, l5: 0.189822, l6: 0.355401\n",
      "\n",
      "[epoch: 396/400, batch: 280/1000, ite: 52286] train loss: 1.1105, accuracy: 96.0045%, tar: 0.0189 \n",
      "l0: 0.021682, l1: 0.024002, l2: 0.033246, l3: 0.050396, l4: 0.104421, l5: 0.237293, l6: 0.449735\n",
      "\n",
      "[epoch: 396/400, batch: 288/1000, ite: 52287] train loss: 1.1114, accuracy: 94.6130%, tar: 0.0189 \n",
      "l0: 0.025352, l1: 0.027033, l2: 0.035974, l3: 0.053698, l4: 0.104261, l5: 0.201009, l6: 0.364125\n",
      "\n",
      "[epoch: 396/400, batch: 296/1000, ite: 52288] train loss: 1.1116, accuracy: 94.0653%, tar: 0.0189 \n",
      "l0: 0.017989, l1: 0.019119, l2: 0.025789, l3: 0.038434, l4: 0.071515, l5: 0.176220, l6: 0.385304\n",
      "\n",
      "[epoch: 396/400, batch: 304/1000, ite: 52289] train loss: 1.1117, accuracy: 94.9879%, tar: 0.0189 \n",
      "l0: 0.013504, l1: 0.014340, l2: 0.020178, l3: 0.031708, l4: 0.064406, l5: 0.124210, l6: 0.285443\n",
      "\n",
      "[epoch: 396/400, batch: 312/1000, ite: 52290] train loss: 1.1107, accuracy: 96.2522%, tar: 0.0189 \n",
      "l0: 0.022410, l1: 0.023565, l2: 0.034997, l3: 0.055898, l4: 0.113911, l5: 0.215565, l6: 0.399348\n",
      "\n",
      "[epoch: 396/400, batch: 320/1000, ite: 52291] train loss: 1.1113, accuracy: 94.4549%, tar: 0.0189 \n",
      "l0: 0.020143, l1: 0.021109, l2: 0.027342, l3: 0.041119, l4: 0.081198, l5: 0.171103, l6: 0.370189\n",
      "\n",
      "[epoch: 396/400, batch: 328/1000, ite: 52292] train loss: 1.1113, accuracy: 94.4817%, tar: 0.0189 \n",
      "l0: 0.017742, l1: 0.018794, l2: 0.026060, l3: 0.039918, l4: 0.080950, l5: 0.183980, l6: 0.383685\n",
      "\n",
      "[epoch: 396/400, batch: 336/1000, ite: 52293] train loss: 1.1114, accuracy: 94.5530%, tar: 0.0189 \n",
      "l0: 0.018173, l1: 0.019225, l2: 0.026908, l3: 0.044100, l4: 0.091734, l5: 0.173091, l6: 0.345144\n",
      "\n",
      "[epoch: 396/400, batch: 344/1000, ite: 52294] train loss: 1.1112, accuracy: 95.3789%, tar: 0.0189 \n",
      "l0: 0.016322, l1: 0.017689, l2: 0.025890, l3: 0.037653, l4: 0.062649, l5: 0.118001, l6: 0.241773\n",
      "\n",
      "[epoch: 396/400, batch: 352/1000, ite: 52295] train loss: 1.1100, accuracy: 96.5994%, tar: 0.0189 \n",
      "l0: 0.026048, l1: 0.027546, l2: 0.035369, l3: 0.051755, l4: 0.096728, l5: 0.208505, l6: 0.403947\n",
      "\n",
      "[epoch: 396/400, batch: 360/1000, ite: 52296] train loss: 1.1105, accuracy: 94.2602%, tar: 0.0189 \n",
      "l0: 0.022112, l1: 0.024252, l2: 0.034346, l3: 0.054537, l4: 0.112805, l5: 0.243843, l6: 0.464308\n",
      "\n",
      "[epoch: 396/400, batch: 368/1000, ite: 52297] train loss: 1.1116, accuracy: 94.1837%, tar: 0.0189 \n",
      "l0: 0.018805, l1: 0.019688, l2: 0.026702, l3: 0.038238, l4: 0.066513, l5: 0.156880, l6: 0.256832\n",
      "\n",
      "[epoch: 396/400, batch: 376/1000, ite: 52298] train loss: 1.1107, accuracy: 95.9695%, tar: 0.0189 \n",
      "l0: 0.023666, l1: 0.025190, l2: 0.034113, l3: 0.052337, l4: 0.108761, l5: 0.243151, l6: 0.560776\n",
      "\n",
      "[epoch: 396/400, batch: 384/1000, ite: 52299] train loss: 1.1123, accuracy: 93.2932%, tar: 0.0190 \n",
      "l0: 0.019882, l1: 0.021038, l2: 0.028713, l3: 0.046508, l4: 0.088400, l5: 0.172465, l6: 0.403577\n",
      "\n",
      "[epoch: 396/400, batch: 392/1000, ite: 52300] train loss: 1.1126, accuracy: 93.9419%, tar: 0.0190 \n",
      "l0: 0.020989, l1: 0.022977, l2: 0.031790, l3: 0.048983, l4: 0.100398, l5: 0.224586, l6: 0.502963\n",
      "\n",
      "[epoch: 396/400, batch: 400/1000, ite: 52301] train loss: 1.1138, accuracy: 93.7814%, tar: 0.0190 \n",
      "l0: 0.019065, l1: 0.020225, l2: 0.025967, l3: 0.039465, l4: 0.080903, l5: 0.140114, l6: 0.296131\n",
      "\n",
      "[epoch: 396/400, batch: 408/1000, ite: 52302] train loss: 1.1131, accuracy: 96.1898%, tar: 0.0190 \n",
      "l0: 0.018525, l1: 0.019450, l2: 0.024277, l3: 0.037000, l4: 0.065464, l5: 0.124621, l6: 0.298262\n",
      "\n",
      "[epoch: 396/400, batch: 416/1000, ite: 52303] train loss: 1.1124, accuracy: 96.0951%, tar: 0.0190 \n",
      "l0: 0.018085, l1: 0.019442, l2: 0.025588, l3: 0.037874, l4: 0.072889, l5: 0.165548, l6: 0.354171\n",
      "\n",
      "[epoch: 396/400, batch: 424/1000, ite: 52304] train loss: 1.1122, accuracy: 95.0673%, tar: 0.0190 \n",
      "l0: 0.017337, l1: 0.018709, l2: 0.027070, l3: 0.044848, l4: 0.086312, l5: 0.172772, l6: 0.340194\n",
      "\n",
      "[epoch: 396/400, batch: 432/1000, ite: 52305] train loss: 1.1120, accuracy: 95.7703%, tar: 0.0190 \n",
      "l0: 0.017050, l1: 0.018091, l2: 0.024347, l3: 0.035608, l4: 0.060725, l5: 0.108561, l6: 0.245317\n",
      "\n",
      "[epoch: 396/400, batch: 440/1000, ite: 52306] train loss: 1.1108, accuracy: 96.5509%, tar: 0.0190 \n",
      "l0: 0.020157, l1: 0.021857, l2: 0.031883, l3: 0.053604, l4: 0.105958, l5: 0.195861, l6: 0.480199\n",
      "\n",
      "[epoch: 396/400, batch: 448/1000, ite: 52307] train loss: 1.1117, accuracy: 94.5301%, tar: 0.0190 \n",
      "l0: 0.015925, l1: 0.016962, l2: 0.022795, l3: 0.031997, l4: 0.050470, l5: 0.101329, l6: 0.203761\n",
      "\n",
      "[epoch: 396/400, batch: 456/1000, ite: 52308] train loss: 1.1102, accuracy: 96.4931%, tar: 0.0189 \n",
      "l0: 0.022974, l1: 0.024275, l2: 0.032914, l3: 0.053071, l4: 0.100487, l5: 0.212195, l6: 0.382522\n",
      "\n",
      "[epoch: 396/400, batch: 464/1000, ite: 52309] train loss: 1.1106, accuracy: 94.4130%, tar: 0.0190 \n",
      "l0: 0.020990, l1: 0.021856, l2: 0.028765, l3: 0.043267, l4: 0.078865, l5: 0.173393, l6: 0.346608\n",
      "\n",
      "[epoch: 396/400, batch: 472/1000, ite: 52310] train loss: 1.1104, accuracy: 94.7681%, tar: 0.0190 \n",
      "l0: 0.016616, l1: 0.018141, l2: 0.023617, l3: 0.035173, l4: 0.076756, l5: 0.137871, l6: 0.308397\n",
      "\n",
      "[epoch: 396/400, batch: 480/1000, ite: 52311] train loss: 1.1098, accuracy: 96.2723%, tar: 0.0190 \n",
      "l0: 0.017385, l1: 0.018784, l2: 0.026925, l3: 0.041757, l4: 0.082401, l5: 0.174348, l6: 0.417813\n",
      "\n",
      "[epoch: 396/400, batch: 488/1000, ite: 52312] train loss: 1.1101, accuracy: 94.7038%, tar: 0.0190 \n",
      "l0: 0.020165, l1: 0.021622, l2: 0.029216, l3: 0.046734, l4: 0.088327, l5: 0.196963, l6: 0.370930\n",
      "\n",
      "[epoch: 396/400, batch: 496/1000, ite: 52313] train loss: 1.1102, accuracy: 94.7833%, tar: 0.0190 \n",
      "l0: 0.018810, l1: 0.019618, l2: 0.026562, l3: 0.037822, l4: 0.070043, l5: 0.149951, l6: 0.290852\n",
      "\n",
      "[epoch: 396/400, batch: 504/1000, ite: 52314] train loss: 1.1096, accuracy: 95.1719%, tar: 0.0190 \n",
      "l0: 0.017819, l1: 0.019308, l2: 0.028063, l3: 0.043702, l4: 0.076314, l5: 0.161840, l6: 0.381103\n",
      "\n",
      "[epoch: 396/400, batch: 512/1000, ite: 52315] train loss: 1.1096, accuracy: 95.2335%, tar: 0.0190 \n",
      "l0: 0.017744, l1: 0.018910, l2: 0.025806, l3: 0.036511, l4: 0.070407, l5: 0.131356, l6: 0.252960\n",
      "\n",
      "[epoch: 396/400, batch: 520/1000, ite: 52316] train loss: 1.1086, accuracy: 96.1553%, tar: 0.0190 \n",
      "l0: 0.018940, l1: 0.020365, l2: 0.027081, l3: 0.040114, l4: 0.079184, l5: 0.163663, l6: 0.414966\n",
      "\n",
      "[epoch: 396/400, batch: 528/1000, ite: 52317] train loss: 1.1089, accuracy: 94.9247%, tar: 0.0190 \n",
      "l0: 0.018485, l1: 0.019832, l2: 0.027375, l3: 0.045164, l4: 0.089821, l5: 0.182467, l6: 0.395446\n",
      "\n",
      "[epoch: 396/400, batch: 536/1000, ite: 52318] train loss: 1.1091, accuracy: 94.9494%, tar: 0.0189 \n",
      "l0: 0.024226, l1: 0.025767, l2: 0.034856, l3: 0.052659, l4: 0.102820, l5: 0.222653, l6: 0.402550\n",
      "\n",
      "[epoch: 396/400, batch: 544/1000, ite: 52319] train loss: 1.1096, accuracy: 94.2073%, tar: 0.0190 \n",
      "l0: 0.019555, l1: 0.020657, l2: 0.026648, l3: 0.038776, l4: 0.065481, l5: 0.117733, l6: 0.245720\n",
      "\n",
      "[epoch: 396/400, batch: 552/1000, ite: 52320] train loss: 1.1085, accuracy: 95.9260%, tar: 0.0190 \n",
      "l0: 0.017019, l1: 0.017791, l2: 0.023596, l3: 0.034710, l4: 0.064336, l5: 0.129334, l6: 0.269567\n",
      "\n",
      "[epoch: 396/400, batch: 560/1000, ite: 52321] train loss: 1.1077, accuracy: 95.8256%, tar: 0.0190 \n",
      "l0: 0.019795, l1: 0.022499, l2: 0.033425, l3: 0.050537, l4: 0.085064, l5: 0.167151, l6: 0.342852\n",
      "\n",
      "[epoch: 396/400, batch: 568/1000, ite: 52322] train loss: 1.1076, accuracy: 95.6057%, tar: 0.0190 \n",
      "l0: 0.020322, l1: 0.022106, l2: 0.031478, l3: 0.046549, l4: 0.092316, l5: 0.199649, l6: 0.390608\n",
      "\n",
      "[epoch: 396/400, batch: 576/1000, ite: 52323] train loss: 1.1078, accuracy: 95.3085%, tar: 0.0190 \n",
      "l0: 0.019582, l1: 0.020784, l2: 0.027638, l3: 0.043005, l4: 0.076735, l5: 0.157981, l6: 0.293118\n",
      "\n",
      "[epoch: 396/400, batch: 584/1000, ite: 52324] train loss: 1.1073, accuracy: 95.7664%, tar: 0.0190 \n",
      "l0: 0.013847, l1: 0.014436, l2: 0.019928, l3: 0.030310, l4: 0.064020, l5: 0.132049, l6: 0.346149\n",
      "\n",
      "[epoch: 396/400, batch: 592/1000, ite: 52325] train loss: 1.1069, accuracy: 95.7915%, tar: 0.0190 \n",
      "l0: 0.020642, l1: 0.022400, l2: 0.032717, l3: 0.052958, l4: 0.093755, l5: 0.204144, l6: 0.407763\n",
      "\n",
      "[epoch: 396/400, batch: 600/1000, ite: 52326] train loss: 1.1073, accuracy: 94.4104%, tar: 0.0190 \n",
      "l0: 0.020439, l1: 0.021669, l2: 0.028677, l3: 0.044977, l4: 0.094029, l5: 0.226210, l6: 0.427497\n",
      "\n",
      "[epoch: 396/400, batch: 608/1000, ite: 52327] train loss: 1.1078, accuracy: 93.6958%, tar: 0.0190 \n",
      "l0: 0.013146, l1: 0.014451, l2: 0.020489, l3: 0.040166, l4: 0.088122, l5: 0.149144, l6: 0.288291\n",
      "\n",
      "[epoch: 396/400, batch: 616/1000, ite: 52328] train loss: 1.1072, accuracy: 96.4035%, tar: 0.0189 \n",
      "l0: 0.017156, l1: 0.018825, l2: 0.027000, l3: 0.039863, l4: 0.077964, l5: 0.184453, l6: 0.454783\n",
      "\n",
      "[epoch: 396/400, batch: 624/1000, ite: 52329] train loss: 1.1077, accuracy: 95.1154%, tar: 0.0189 \n",
      "l0: 0.022277, l1: 0.023417, l2: 0.032505, l3: 0.050900, l4: 0.096174, l5: 0.215641, l6: 0.484943\n",
      "\n",
      "[epoch: 396/400, batch: 632/1000, ite: 52330] train loss: 1.1087, accuracy: 94.2206%, tar: 0.0190 \n",
      "l0: 0.015206, l1: 0.016089, l2: 0.024167, l3: 0.036108, l4: 0.060915, l5: 0.119305, l6: 0.247438\n",
      "\n",
      "[epoch: 396/400, batch: 640/1000, ite: 52331] train loss: 1.1077, accuracy: 96.6468%, tar: 0.0189 \n",
      "l0: 0.022433, l1: 0.023466, l2: 0.031308, l3: 0.046835, l4: 0.089610, l5: 0.151005, l6: 0.330979\n",
      "\n",
      "[epoch: 396/400, batch: 648/1000, ite: 52332] train loss: 1.1074, accuracy: 94.9689%, tar: 0.0190 \n",
      "l0: 0.022137, l1: 0.023841, l2: 0.030678, l3: 0.050422, l4: 0.119743, l5: 0.234812, l6: 0.433073\n",
      "\n",
      "[epoch: 396/400, batch: 656/1000, ite: 52333] train loss: 1.1082, accuracy: 94.2867%, tar: 0.0190 \n",
      "l0: 0.019727, l1: 0.020598, l2: 0.026423, l3: 0.040463, l4: 0.077109, l5: 0.170605, l6: 0.356726\n",
      "\n",
      "[epoch: 396/400, batch: 664/1000, ite: 52334] train loss: 1.1080, accuracy: 95.1071%, tar: 0.0190 \n",
      "l0: 0.018231, l1: 0.019368, l2: 0.025804, l3: 0.039333, l4: 0.074883, l5: 0.189861, l6: 0.367658\n",
      "\n",
      "[epoch: 396/400, batch: 672/1000, ite: 52335] train loss: 1.1080, accuracy: 94.7544%, tar: 0.0190 \n",
      "l0: 0.021354, l1: 0.022796, l2: 0.031235, l3: 0.053472, l4: 0.102344, l5: 0.202581, l6: 0.449002\n",
      "\n",
      "[epoch: 396/400, batch: 680/1000, ite: 52336] train loss: 1.1087, accuracy: 95.0563%, tar: 0.0190 \n",
      "l0: 0.017020, l1: 0.018080, l2: 0.024296, l3: 0.036677, l4: 0.069101, l5: 0.150053, l6: 0.373659\n",
      "\n",
      "[epoch: 396/400, batch: 688/1000, ite: 52337] train loss: 1.1086, accuracy: 95.1011%, tar: 0.0190 \n",
      "l0: 0.028088, l1: 0.031568, l2: 0.046556, l3: 0.076613, l4: 0.137436, l5: 0.249206, l6: 0.437946\n",
      "\n",
      "[epoch: 396/400, batch: 696/1000, ite: 52338] train loss: 1.1096, accuracy: 94.2703%, tar: 0.0190 \n",
      "l0: 0.018825, l1: 0.020389, l2: 0.029505, l3: 0.045099, l4: 0.083873, l5: 0.183067, l6: 0.391186\n",
      "\n",
      "[epoch: 396/400, batch: 704/1000, ite: 52339] train loss: 1.1097, accuracy: 94.7115%, tar: 0.0190 \n",
      "l0: 0.014357, l1: 0.015373, l2: 0.021500, l3: 0.033579, l4: 0.064553, l5: 0.123928, l6: 0.320455\n",
      "\n",
      "[epoch: 396/400, batch: 712/1000, ite: 52340] train loss: 1.1092, accuracy: 95.4839%, tar: 0.0190 \n",
      "l0: 0.019251, l1: 0.020371, l2: 0.027964, l3: 0.043658, l4: 0.074926, l5: 0.146187, l6: 0.357874\n",
      "\n",
      "[epoch: 396/400, batch: 720/1000, ite: 52341] train loss: 1.1090, accuracy: 94.9133%, tar: 0.0190 \n",
      "l0: 0.016303, l1: 0.018802, l2: 0.028503, l3: 0.045548, l4: 0.084755, l5: 0.188032, l6: 0.421733\n",
      "\n",
      "[epoch: 396/400, batch: 728/1000, ite: 52342] train loss: 1.1093, accuracy: 95.4182%, tar: 0.0190 \n",
      "l0: 0.015313, l1: 0.016485, l2: 0.023698, l3: 0.034700, l4: 0.058597, l5: 0.132188, l6: 0.290571\n",
      "\n",
      "[epoch: 396/400, batch: 736/1000, ite: 52343] train loss: 1.1086, accuracy: 95.7538%, tar: 0.0190 \n",
      "l0: 0.022344, l1: 0.024489, l2: 0.036815, l3: 0.059743, l4: 0.117574, l5: 0.206505, l6: 0.380991\n",
      "\n",
      "[epoch: 396/400, batch: 744/1000, ite: 52344] train loss: 1.1090, accuracy: 95.4058%, tar: 0.0190 \n",
      "l0: 0.023021, l1: 0.024301, l2: 0.031283, l3: 0.047830, l4: 0.092571, l5: 0.180661, l6: 0.416222\n",
      "\n",
      "[epoch: 396/400, batch: 752/1000, ite: 52345] train loss: 1.1094, accuracy: 93.6380%, tar: 0.0190 \n",
      "l0: 0.024204, l1: 0.026210, l2: 0.037480, l3: 0.057188, l4: 0.097834, l5: 0.189809, l6: 0.396039\n",
      "\n",
      "[epoch: 396/400, batch: 760/1000, ite: 52346] train loss: 1.1097, accuracy: 94.4422%, tar: 0.0190 \n",
      "l0: 0.017380, l1: 0.017918, l2: 0.025241, l3: 0.036636, l4: 0.061567, l5: 0.120538, l6: 0.280823\n",
      "\n",
      "[epoch: 396/400, batch: 768/1000, ite: 52347] train loss: 1.1090, accuracy: 95.3408%, tar: 0.0190 \n",
      "l0: 0.019047, l1: 0.020552, l2: 0.028736, l3: 0.042828, l4: 0.074474, l5: 0.148000, l6: 0.350549\n",
      "\n",
      "[epoch: 396/400, batch: 776/1000, ite: 52348] train loss: 1.1087, accuracy: 94.9034%, tar: 0.0190 \n",
      "l0: 0.018054, l1: 0.019105, l2: 0.025918, l3: 0.040808, l4: 0.069759, l5: 0.147942, l6: 0.306069\n",
      "\n",
      "[epoch: 396/400, batch: 784/1000, ite: 52349] train loss: 1.1083, accuracy: 95.4141%, tar: 0.0190 \n",
      "l0: 0.021290, l1: 0.022852, l2: 0.031020, l3: 0.049238, l4: 0.100561, l5: 0.206131, l6: 0.426014\n",
      "\n",
      "[epoch: 396/400, batch: 792/1000, ite: 52350] train loss: 1.1088, accuracy: 94.7374%, tar: 0.0190 \n",
      "l0: 0.011770, l1: 0.013062, l2: 0.017032, l3: 0.025654, l4: 0.047605, l5: 0.113117, l6: 0.274099\n",
      "\n",
      "[epoch: 396/400, batch: 800/1000, ite: 52351] train loss: 1.1078, accuracy: 96.4479%, tar: 0.0190 \n",
      "l0: 0.017030, l1: 0.017656, l2: 0.025460, l3: 0.039245, l4: 0.072393, l5: 0.155231, l6: 0.336177\n",
      "\n",
      "[epoch: 396/400, batch: 808/1000, ite: 52352] train loss: 1.1075, accuracy: 95.8079%, tar: 0.0190 \n",
      "l0: 0.022169, l1: 0.023498, l2: 0.031405, l3: 0.048030, l4: 0.085295, l5: 0.216601, l6: 0.439319\n",
      "\n",
      "[epoch: 396/400, batch: 816/1000, ite: 52353] train loss: 1.1081, accuracy: 94.4856%, tar: 0.0190 \n",
      "l0: 0.024938, l1: 0.026699, l2: 0.036350, l3: 0.055815, l4: 0.143371, l5: 0.285327, l6: 0.600469\n",
      "\n",
      "[epoch: 396/400, batch: 824/1000, ite: 52354] train loss: 1.1099, accuracy: 92.7071%, tar: 0.0190 \n",
      "l0: 0.016903, l1: 0.017974, l2: 0.023423, l3: 0.033055, l4: 0.058043, l5: 0.110062, l6: 0.233040\n",
      "\n",
      "[epoch: 396/400, batch: 832/1000, ite: 52355] train loss: 1.1089, accuracy: 96.1459%, tar: 0.0190 \n",
      "l0: 0.015262, l1: 0.016443, l2: 0.022740, l3: 0.038309, l4: 0.062618, l5: 0.123261, l6: 0.299217\n",
      "\n",
      "[epoch: 396/400, batch: 840/1000, ite: 52356] train loss: 1.1082, accuracy: 96.3805%, tar: 0.0190 \n",
      "l0: 0.019420, l1: 0.021089, l2: 0.029679, l3: 0.046871, l4: 0.082038, l5: 0.153597, l6: 0.430231\n",
      "\n",
      "[epoch: 396/400, batch: 848/1000, ite: 52357] train loss: 1.1085, accuracy: 94.7789%, tar: 0.0190 \n",
      "l0: 0.017293, l1: 0.019424, l2: 0.027939, l3: 0.046683, l4: 0.099743, l5: 0.212433, l6: 0.458679\n",
      "\n",
      "[epoch: 396/400, batch: 856/1000, ite: 52358] train loss: 1.1092, accuracy: 94.6194%, tar: 0.0190 \n",
      "l0: 0.018314, l1: 0.019243, l2: 0.027155, l3: 0.043951, l4: 0.075661, l5: 0.148999, l6: 0.329945\n",
      "\n",
      "[epoch: 396/400, batch: 864/1000, ite: 52359] train loss: 1.1089, accuracy: 95.8500%, tar: 0.0190 \n",
      "l0: 0.019073, l1: 0.020732, l2: 0.030250, l3: 0.046772, l4: 0.092061, l5: 0.189240, l6: 0.421233\n",
      "\n",
      "[epoch: 396/400, batch: 872/1000, ite: 52360] train loss: 1.1093, accuracy: 95.1025%, tar: 0.0190 \n",
      "l0: 0.014247, l1: 0.016132, l2: 0.026139, l3: 0.048473, l4: 0.100003, l5: 0.165781, l6: 0.347347\n",
      "\n",
      "[epoch: 396/400, batch: 880/1000, ite: 52361] train loss: 1.1091, accuracy: 96.2487%, tar: 0.0190 \n",
      "l0: 0.018420, l1: 0.019849, l2: 0.028338, l3: 0.044307, l4: 0.074056, l5: 0.160757, l6: 0.312711\n",
      "\n",
      "[epoch: 396/400, batch: 888/1000, ite: 52362] train loss: 1.1087, accuracy: 95.3525%, tar: 0.0190 \n",
      "l0: 0.020054, l1: 0.021426, l2: 0.030938, l3: 0.052709, l4: 0.096487, l5: 0.234082, l6: 0.491453\n",
      "\n",
      "[epoch: 396/400, batch: 896/1000, ite: 52363] train loss: 1.1097, accuracy: 94.1714%, tar: 0.0190 \n",
      "l0: 0.018056, l1: 0.019150, l2: 0.025563, l3: 0.037459, l4: 0.065863, l5: 0.132215, l6: 0.260911\n",
      "\n",
      "[epoch: 396/400, batch: 904/1000, ite: 52364] train loss: 1.1089, accuracy: 96.3286%, tar: 0.0190 \n",
      "l0: 0.018963, l1: 0.020101, l2: 0.028439, l3: 0.040733, l4: 0.071987, l5: 0.138386, l6: 0.397297\n",
      "\n",
      "[epoch: 396/400, batch: 912/1000, ite: 52365] train loss: 1.1089, accuracy: 95.6722%, tar: 0.0190 \n",
      "l0: 0.011859, l1: 0.012859, l2: 0.018059, l3: 0.028157, l4: 0.049429, l5: 0.093516, l6: 0.231240\n",
      "\n",
      "[epoch: 396/400, batch: 920/1000, ite: 52366] train loss: 1.1077, accuracy: 96.9157%, tar: 0.0189 \n",
      "l0: 0.017219, l1: 0.018287, l2: 0.026328, l3: 0.039308, l4: 0.069953, l5: 0.147660, l6: 0.313595\n",
      "\n",
      "[epoch: 396/400, batch: 928/1000, ite: 52367] train loss: 1.1073, accuracy: 95.4323%, tar: 0.0189 \n",
      "l0: 0.022338, l1: 0.023510, l2: 0.031578, l3: 0.048482, l4: 0.088677, l5: 0.193970, l6: 0.349668\n",
      "\n",
      "[epoch: 396/400, batch: 936/1000, ite: 52368] train loss: 1.1073, accuracy: 94.7358%, tar: 0.0189 \n",
      "l0: 0.015684, l1: 0.016535, l2: 0.023160, l3: 0.032749, l4: 0.054885, l5: 0.110570, l6: 0.219258\n",
      "\n",
      "[epoch: 396/400, batch: 944/1000, ite: 52369] train loss: 1.1062, accuracy: 96.7598%, tar: 0.0189 \n",
      "l0: 0.020587, l1: 0.022671, l2: 0.032677, l3: 0.053452, l4: 0.104866, l5: 0.207081, l6: 0.424736\n",
      "\n",
      "[epoch: 396/400, batch: 952/1000, ite: 52370] train loss: 1.1067, accuracy: 94.4194%, tar: 0.0189 \n",
      "l0: 0.020161, l1: 0.021583, l2: 0.028751, l3: 0.044083, l4: 0.085515, l5: 0.190323, l6: 0.380953\n",
      "\n",
      "[epoch: 396/400, batch: 960/1000, ite: 52371] train loss: 1.1068, accuracy: 94.7821%, tar: 0.0189 \n",
      "l0: 0.022553, l1: 0.024228, l2: 0.036384, l3: 0.059236, l4: 0.113780, l5: 0.278514, l6: 0.507341\n",
      "\n",
      "[epoch: 396/400, batch: 968/1000, ite: 52372] train loss: 1.1080, accuracy: 94.0908%, tar: 0.0190 \n",
      "l0: 0.019927, l1: 0.021105, l2: 0.028528, l3: 0.045072, l4: 0.080488, l5: 0.156801, l6: 0.275792\n",
      "\n",
      "[epoch: 396/400, batch: 976/1000, ite: 52373] train loss: 1.1074, accuracy: 95.6273%, tar: 0.0190 \n",
      "l0: 0.019234, l1: 0.020683, l2: 0.029628, l3: 0.051750, l4: 0.087674, l5: 0.155536, l6: 0.315760\n",
      "\n",
      "[epoch: 396/400, batch: 984/1000, ite: 52374] train loss: 1.1071, accuracy: 95.4176%, tar: 0.0190 \n",
      "l0: 0.026140, l1: 0.028458, l2: 0.036673, l3: 0.052477, l4: 0.087119, l5: 0.180662, l6: 0.383532\n",
      "\n",
      "[epoch: 396/400, batch: 992/1000, ite: 52375] train loss: 1.1074, accuracy: 94.6177%, tar: 0.0190 \n",
      "l0: 0.022017, l1: 0.023529, l2: 0.031482, l3: 0.047270, l4: 0.084760, l5: 0.182693, l6: 0.394770\n",
      "\n",
      "[epoch: 396/400, batch: 1000/1000, ite: 52376] train loss: 1.1076, accuracy: 94.5187%, tar: 0.0190 \n",
      "l0: 0.015293, l1: 0.016720, l2: 0.026139, l3: 0.045291, l4: 0.103060, l5: 0.184545, l6: 0.322396\n",
      "\n",
      "[epoch: 397/400, batch: 8/1000, ite: 52377] train loss: 1.1074, accuracy: 95.5312%, tar: 0.0190 \n",
      "l0: 0.019473, l1: 0.021071, l2: 0.026578, l3: 0.038910, l4: 0.062607, l5: 0.127489, l6: 0.298409\n",
      "\n",
      "[epoch: 397/400, batch: 16/1000, ite: 52378] train loss: 1.1068, accuracy: 95.6204%, tar: 0.0190 \n",
      "l0: 0.023025, l1: 0.024201, l2: 0.031177, l3: 0.042639, l4: 0.074937, l5: 0.150083, l6: 0.337999\n",
      "\n",
      "[epoch: 397/400, batch: 24/1000, ite: 52379] train loss: 1.1066, accuracy: 94.6713%, tar: 0.0190 \n",
      "l0: 0.016099, l1: 0.017379, l2: 0.025128, l3: 0.038434, l4: 0.075123, l5: 0.153446, l6: 0.339098\n",
      "\n",
      "[epoch: 397/400, batch: 32/1000, ite: 52380] train loss: 1.1063, accuracy: 95.1853%, tar: 0.0190 \n",
      "l0: 0.012687, l1: 0.013994, l2: 0.020565, l3: 0.032952, l4: 0.060969, l5: 0.146879, l6: 0.277753\n",
      "\n",
      "[epoch: 397/400, batch: 40/1000, ite: 52381] train loss: 1.1056, accuracy: 96.5304%, tar: 0.0190 \n",
      "l0: 0.018781, l1: 0.019764, l2: 0.026399, l3: 0.037646, l4: 0.062997, l5: 0.124752, l6: 0.312764\n",
      "\n",
      "[epoch: 397/400, batch: 48/1000, ite: 52382] train loss: 1.1052, accuracy: 95.4306%, tar: 0.0190 \n",
      "l0: 0.018348, l1: 0.019711, l2: 0.030031, l3: 0.048100, l4: 0.087053, l5: 0.166287, l6: 0.296389\n",
      "\n",
      "[epoch: 397/400, batch: 56/1000, ite: 52383] train loss: 1.1048, accuracy: 95.7153%, tar: 0.0190 \n",
      "l0: 0.032854, l1: 0.035866, l2: 0.049014, l3: 0.077835, l4: 0.169595, l5: 0.350905, l6: 0.602047\n",
      "\n",
      "[epoch: 397/400, batch: 64/1000, ite: 52384] train loss: 1.1069, accuracy: 92.0004%, tar: 0.0190 \n",
      "l0: 0.017877, l1: 0.019035, l2: 0.024699, l3: 0.043840, l4: 0.083696, l5: 0.152140, l6: 0.295111\n",
      "\n",
      "[epoch: 397/400, batch: 72/1000, ite: 52385] train loss: 1.1065, accuracy: 95.7991%, tar: 0.0190 \n",
      "l0: 0.017078, l1: 0.018438, l2: 0.025927, l3: 0.041572, l4: 0.078116, l5: 0.192143, l6: 0.378052\n",
      "\n",
      "[epoch: 397/400, batch: 80/1000, ite: 52386] train loss: 1.1065, accuracy: 95.4114%, tar: 0.0190 \n",
      "l0: 0.015125, l1: 0.016045, l2: 0.023322, l3: 0.037355, l4: 0.073288, l5: 0.178360, l6: 0.372922\n",
      "\n",
      "[epoch: 397/400, batch: 88/1000, ite: 52387] train loss: 1.1065, accuracy: 95.5880%, tar: 0.0190 \n",
      "l0: 0.017720, l1: 0.019386, l2: 0.029535, l3: 0.048937, l4: 0.103776, l5: 0.226088, l6: 0.456933\n",
      "\n",
      "[epoch: 397/400, batch: 96/1000, ite: 52388] train loss: 1.1071, accuracy: 94.4956%, tar: 0.0190 \n",
      "l0: 0.019390, l1: 0.020514, l2: 0.030108, l3: 0.049309, l4: 0.102707, l5: 0.204934, l6: 0.418547\n",
      "\n",
      "[epoch: 397/400, batch: 104/1000, ite: 52389] train loss: 1.1076, accuracy: 95.0683%, tar: 0.0190 \n",
      "l0: 0.022796, l1: 0.023370, l2: 0.030841, l3: 0.041102, l4: 0.076801, l5: 0.146888, l6: 0.339423\n",
      "\n",
      "[epoch: 397/400, batch: 112/1000, ite: 52390] train loss: 1.1073, accuracy: 95.2155%, tar: 0.0190 \n",
      "l0: 0.017478, l1: 0.018758, l2: 0.027611, l3: 0.044041, l4: 0.075593, l5: 0.144945, l6: 0.337304\n",
      "\n",
      "[epoch: 397/400, batch: 120/1000, ite: 52391] train loss: 1.1071, accuracy: 95.1210%, tar: 0.0190 \n",
      "l0: 0.019310, l1: 0.020743, l2: 0.026974, l3: 0.041276, l4: 0.085215, l5: 0.192597, l6: 0.404166\n",
      "\n",
      "[epoch: 397/400, batch: 128/1000, ite: 52392] train loss: 1.1073, accuracy: 94.4199%, tar: 0.0190 \n",
      "l0: 0.013318, l1: 0.014389, l2: 0.020352, l3: 0.031778, l4: 0.056229, l5: 0.101636, l6: 0.235670\n",
      "\n",
      "[epoch: 397/400, batch: 136/1000, ite: 52393] train loss: 1.1063, accuracy: 96.4310%, tar: 0.0190 \n",
      "l0: 0.019583, l1: 0.020639, l2: 0.027642, l3: 0.039837, l4: 0.072488, l5: 0.159834, l6: 0.360048\n",
      "\n",
      "[epoch: 397/400, batch: 144/1000, ite: 52394] train loss: 1.1062, accuracy: 95.3078%, tar: 0.0190 \n",
      "l0: 0.014549, l1: 0.015746, l2: 0.021762, l3: 0.032418, l4: 0.058336, l5: 0.135506, l6: 0.259889\n",
      "\n",
      "[epoch: 397/400, batch: 152/1000, ite: 52395] train loss: 1.1054, accuracy: 96.3324%, tar: 0.0190 \n",
      "l0: 0.016841, l1: 0.018863, l2: 0.028644, l3: 0.052853, l4: 0.111375, l5: 0.211435, l6: 0.478822\n",
      "\n",
      "[epoch: 397/400, batch: 160/1000, ite: 52396] train loss: 1.1062, accuracy: 95.1996%, tar: 0.0190 \n",
      "l0: 0.017646, l1: 0.019112, l2: 0.027205, l3: 0.041367, l4: 0.088961, l5: 0.200033, l6: 0.397417\n",
      "\n",
      "[epoch: 397/400, batch: 168/1000, ite: 52397] train loss: 1.1064, accuracy: 94.9507%, tar: 0.0189 \n",
      "l0: 0.022825, l1: 0.023806, l2: 0.032907, l3: 0.045979, l4: 0.077419, l5: 0.154030, l6: 0.322307\n",
      "\n",
      "[epoch: 397/400, batch: 176/1000, ite: 52398] train loss: 1.1061, accuracy: 95.1882%, tar: 0.0190 \n",
      "l0: 0.024739, l1: 0.026410, l2: 0.036212, l3: 0.051594, l4: 0.095615, l5: 0.212941, l6: 0.422167\n",
      "\n",
      "[epoch: 397/400, batch: 184/1000, ite: 52399] train loss: 1.1066, accuracy: 94.2654%, tar: 0.0190 \n",
      "l0: 0.019520, l1: 0.020980, l2: 0.027663, l3: 0.039725, l4: 0.076149, l5: 0.177102, l6: 0.311790\n",
      "\n",
      "[epoch: 397/400, batch: 192/1000, ite: 52400] train loss: 1.1063, accuracy: 95.6254%, tar: 0.0190 \n",
      "l0: 0.016988, l1: 0.017750, l2: 0.024020, l3: 0.033548, l4: 0.057544, l5: 0.101501, l6: 0.232665\n",
      "\n",
      "[epoch: 397/400, batch: 200/1000, ite: 52401] train loss: 1.1054, accuracy: 96.1469%, tar: 0.0190 \n",
      "l0: 0.019262, l1: 0.021270, l2: 0.030215, l3: 0.049999, l4: 0.118848, l5: 0.266547, l6: 0.488908\n",
      "\n",
      "[epoch: 397/400, batch: 208/1000, ite: 52402] train loss: 1.1063, accuracy: 94.2852%, tar: 0.0190 \n",
      "l0: 0.011620, l1: 0.012434, l2: 0.019078, l3: 0.027717, l4: 0.049161, l5: 0.098955, l6: 0.268787\n",
      "\n",
      "[epoch: 397/400, batch: 216/1000, ite: 52403] train loss: 1.1054, accuracy: 96.6643%, tar: 0.0190 \n",
      "l0: 0.014407, l1: 0.015665, l2: 0.023897, l3: 0.036815, l4: 0.058079, l5: 0.111862, l6: 0.276742\n",
      "\n",
      "[epoch: 397/400, batch: 224/1000, ite: 52404] train loss: 1.1047, accuracy: 96.2177%, tar: 0.0189 \n",
      "l0: 0.020277, l1: 0.021712, l2: 0.030275, l3: 0.049031, l4: 0.103507, l5: 0.214217, l6: 0.427618\n",
      "\n",
      "[epoch: 397/400, batch: 232/1000, ite: 52405] train loss: 1.1052, accuracy: 94.6617%, tar: 0.0189 \n",
      "l0: 0.017513, l1: 0.018645, l2: 0.026199, l3: 0.041550, l4: 0.073635, l5: 0.172063, l6: 0.402877\n",
      "\n",
      "[epoch: 397/400, batch: 240/1000, ite: 52406] train loss: 1.1053, accuracy: 94.5887%, tar: 0.0189 \n",
      "l0: 0.015830, l1: 0.018271, l2: 0.030272, l3: 0.054168, l4: 0.117734, l5: 0.220657, l6: 0.501576\n",
      "\n",
      "[epoch: 397/400, batch: 248/1000, ite: 52407] train loss: 1.1062, accuracy: 95.2180%, tar: 0.0189 \n",
      "l0: 0.018193, l1: 0.020205, l2: 0.028892, l3: 0.046987, l4: 0.087770, l5: 0.202966, l6: 0.452999\n",
      "\n",
      "[epoch: 397/400, batch: 256/1000, ite: 52408] train loss: 1.1067, accuracy: 94.2531%, tar: 0.0189 \n",
      "l0: 0.024783, l1: 0.026171, l2: 0.037313, l3: 0.056273, l4: 0.092179, l5: 0.187203, l6: 0.339085\n",
      "\n",
      "[epoch: 397/400, batch: 264/1000, ite: 52409] train loss: 1.1067, accuracy: 94.7149%, tar: 0.0189 \n",
      "l0: 0.021812, l1: 0.024145, l2: 0.033269, l3: 0.054274, l4: 0.105286, l5: 0.207599, l6: 0.398880\n",
      "\n",
      "[epoch: 397/400, batch: 272/1000, ite: 52410] train loss: 1.1071, accuracy: 95.0364%, tar: 0.0190 \n",
      "l0: 0.018871, l1: 0.020216, l2: 0.026984, l3: 0.040935, l4: 0.071929, l5: 0.144758, l6: 0.320993\n",
      "\n",
      "[epoch: 397/400, batch: 280/1000, ite: 52411] train loss: 1.1067, accuracy: 95.3283%, tar: 0.0190 \n",
      "l0: 0.024128, l1: 0.026244, l2: 0.037187, l3: 0.057275, l4: 0.092471, l5: 0.176045, l6: 0.392461\n",
      "\n",
      "[epoch: 397/400, batch: 288/1000, ite: 52412] train loss: 1.1069, accuracy: 94.5292%, tar: 0.0190 \n",
      "l0: 0.019461, l1: 0.021151, l2: 0.029260, l3: 0.051663, l4: 0.118956, l5: 0.256451, l6: 0.512071\n",
      "\n",
      "[epoch: 397/400, batch: 296/1000, ite: 52413] train loss: 1.1080, accuracy: 93.2639%, tar: 0.0190 \n",
      "l0: 0.016080, l1: 0.017669, l2: 0.027188, l3: 0.044190, l4: 0.088576, l5: 0.183487, l6: 0.383000\n",
      "\n",
      "[epoch: 397/400, batch: 304/1000, ite: 52414] train loss: 1.1081, accuracy: 94.7916%, tar: 0.0190 \n",
      "l0: 0.024851, l1: 0.026706, l2: 0.036183, l3: 0.055924, l4: 0.110648, l5: 0.219252, l6: 0.401247\n",
      "\n",
      "[epoch: 397/400, batch: 312/1000, ite: 52415] train loss: 1.1085, accuracy: 94.6491%, tar: 0.0190 \n",
      "l0: 0.019783, l1: 0.021584, l2: 0.030543, l3: 0.045209, l4: 0.082753, l5: 0.154628, l6: 0.273501\n",
      "\n",
      "[epoch: 397/400, batch: 320/1000, ite: 52416] train loss: 1.1080, accuracy: 95.9112%, tar: 0.0190 \n",
      "l0: 0.020419, l1: 0.021990, l2: 0.031934, l3: 0.050202, l4: 0.081808, l5: 0.151284, l6: 0.273873\n",
      "\n",
      "[epoch: 397/400, batch: 328/1000, ite: 52417] train loss: 1.1075, accuracy: 96.2425%, tar: 0.0190 \n",
      "l0: 0.014675, l1: 0.015457, l2: 0.021380, l3: 0.034883, l4: 0.064678, l5: 0.126778, l6: 0.253915\n",
      "\n",
      "[epoch: 397/400, batch: 336/1000, ite: 52418] train loss: 1.1068, accuracy: 96.5280%, tar: 0.0190 \n",
      "l0: 0.024800, l1: 0.026263, l2: 0.034849, l3: 0.046721, l4: 0.074181, l5: 0.175409, l6: 0.343868\n",
      "\n",
      "[epoch: 397/400, batch: 344/1000, ite: 52419] train loss: 1.1067, accuracy: 95.0862%, tar: 0.0190 \n",
      "l0: 0.022746, l1: 0.024980, l2: 0.035130, l3: 0.055168, l4: 0.116526, l5: 0.279563, l6: 0.509362\n",
      "\n",
      "[epoch: 397/400, batch: 352/1000, ite: 52420] train loss: 1.1077, accuracy: 93.8545%, tar: 0.0190 \n",
      "l0: 0.017603, l1: 0.019247, l2: 0.027760, l3: 0.046644, l4: 0.093641, l5: 0.165006, l6: 0.374443\n",
      "\n",
      "[epoch: 397/400, batch: 360/1000, ite: 52421] train loss: 1.1078, accuracy: 95.9882%, tar: 0.0190 \n",
      "l0: 0.016494, l1: 0.018125, l2: 0.024499, l3: 0.041847, l4: 0.078949, l5: 0.163605, l6: 0.392966\n",
      "\n",
      "[epoch: 397/400, batch: 368/1000, ite: 52422] train loss: 1.1078, accuracy: 96.0573%, tar: 0.0190 \n",
      "l0: 0.018312, l1: 0.019745, l2: 0.028797, l3: 0.046185, l4: 0.087085, l5: 0.195193, l6: 0.376775\n",
      "\n",
      "[epoch: 397/400, batch: 376/1000, ite: 52423] train loss: 1.1079, accuracy: 94.8278%, tar: 0.0190 \n",
      "l0: 0.015413, l1: 0.016124, l2: 0.021785, l3: 0.031314, l4: 0.055205, l5: 0.096771, l6: 0.207385\n",
      "\n",
      "[epoch: 397/400, batch: 384/1000, ite: 52424] train loss: 1.1068, accuracy: 96.5938%, tar: 0.0190 \n",
      "l0: 0.018092, l1: 0.020536, l2: 0.031190, l3: 0.048924, l4: 0.087459, l5: 0.183081, l6: 0.394446\n",
      "\n",
      "[epoch: 397/400, batch: 392/1000, ite: 52425] train loss: 1.1070, accuracy: 95.4215%, tar: 0.0190 \n",
      "l0: 0.017077, l1: 0.018418, l2: 0.026276, l3: 0.042249, l4: 0.077655, l5: 0.148376, l6: 0.285105\n",
      "\n",
      "[epoch: 397/400, batch: 400/1000, ite: 52426] train loss: 1.1065, accuracy: 95.5378%, tar: 0.0190 \n",
      "l0: 0.015984, l1: 0.017129, l2: 0.021337, l3: 0.036755, l4: 0.067543, l5: 0.134261, l6: 0.236393\n",
      "\n",
      "[epoch: 397/400, batch: 408/1000, ite: 52427] train loss: 1.1058, accuracy: 96.4734%, tar: 0.0190 \n",
      "l0: 0.013700, l1: 0.014882, l2: 0.022641, l3: 0.037229, l4: 0.071250, l5: 0.175086, l6: 0.322774\n",
      "\n",
      "[epoch: 397/400, batch: 416/1000, ite: 52428] train loss: 1.1055, accuracy: 96.2728%, tar: 0.0189 \n",
      "l0: 0.024510, l1: 0.025761, l2: 0.035939, l3: 0.056567, l4: 0.107554, l5: 0.226684, l6: 0.526951\n",
      "\n",
      "[epoch: 397/400, batch: 424/1000, ite: 52429] train loss: 1.1065, accuracy: 92.9151%, tar: 0.0190 \n",
      "l0: 0.016806, l1: 0.018588, l2: 0.025757, l3: 0.039951, l4: 0.072622, l5: 0.178348, l6: 0.333005\n",
      "\n",
      "[epoch: 397/400, batch: 432/1000, ite: 52430] train loss: 1.1063, accuracy: 95.5742%, tar: 0.0190 \n",
      "l0: 0.022076, l1: 0.023768, l2: 0.033583, l3: 0.051423, l4: 0.096653, l5: 0.225288, l6: 0.507401\n",
      "\n",
      "[epoch: 397/400, batch: 440/1000, ite: 52431] train loss: 1.1071, accuracy: 93.1148%, tar: 0.0190 \n",
      "l0: 0.021528, l1: 0.023405, l2: 0.033349, l3: 0.051767, l4: 0.101639, l5: 0.215640, l6: 0.425100\n",
      "\n",
      "[epoch: 397/400, batch: 448/1000, ite: 52432] train loss: 1.1076, accuracy: 94.4066%, tar: 0.0190 \n",
      "l0: 0.029556, l1: 0.031095, l2: 0.043350, l3: 0.072401, l4: 0.150322, l5: 0.344843, l6: 0.710957\n",
      "\n",
      "[epoch: 397/400, batch: 456/1000, ite: 52433] train loss: 1.1099, accuracy: 90.3397%, tar: 0.0190 \n",
      "l0: 0.015789, l1: 0.017017, l2: 0.023020, l3: 0.037034, l4: 0.073318, l5: 0.184987, l6: 0.364051\n",
      "\n",
      "[epoch: 397/400, batch: 464/1000, ite: 52434] train loss: 1.1098, accuracy: 94.7867%, tar: 0.0190 \n",
      "l0: 0.015199, l1: 0.016993, l2: 0.024370, l3: 0.038044, l4: 0.081957, l5: 0.156198, l6: 0.305490\n",
      "\n",
      "[epoch: 397/400, batch: 472/1000, ite: 52435] train loss: 1.1094, accuracy: 96.3100%, tar: 0.0190 \n",
      "l0: 0.019506, l1: 0.020853, l2: 0.028782, l3: 0.045850, l4: 0.088869, l5: 0.166014, l6: 0.363545\n",
      "\n",
      "[epoch: 397/400, batch: 480/1000, ite: 52436] train loss: 1.1094, accuracy: 94.7500%, tar: 0.0190 \n",
      "l0: 0.022014, l1: 0.023809, l2: 0.031204, l3: 0.052804, l4: 0.105209, l5: 0.231437, l6: 0.446170\n",
      "\n",
      "[epoch: 397/400, batch: 488/1000, ite: 52437] train loss: 1.1100, accuracy: 93.6577%, tar: 0.0190 \n",
      "l0: 0.018261, l1: 0.019183, l2: 0.026153, l3: 0.038217, l4: 0.066171, l5: 0.151210, l6: 0.346345\n",
      "\n",
      "[epoch: 397/400, batch: 496/1000, ite: 52438] train loss: 1.1098, accuracy: 95.2804%, tar: 0.0190 \n",
      "l0: 0.015938, l1: 0.016789, l2: 0.022418, l3: 0.034016, l4: 0.065863, l5: 0.157777, l6: 0.304260\n",
      "\n",
      "[epoch: 397/400, batch: 504/1000, ite: 52439] train loss: 1.1093, accuracy: 96.1308%, tar: 0.0190 \n",
      "l0: 0.015375, l1: 0.016359, l2: 0.023008, l3: 0.033811, l4: 0.056293, l5: 0.104006, l6: 0.235506\n",
      "\n",
      "[epoch: 397/400, batch: 512/1000, ite: 52440] train loss: 1.1085, accuracy: 96.3241%, tar: 0.0190 \n",
      "l0: 0.023227, l1: 0.024058, l2: 0.032082, l3: 0.046171, l4: 0.073747, l5: 0.161162, l6: 0.416416\n",
      "\n",
      "[epoch: 397/400, batch: 520/1000, ite: 52441] train loss: 1.1087, accuracy: 94.0303%, tar: 0.0190 \n",
      "l0: 0.021722, l1: 0.023268, l2: 0.033442, l3: 0.052877, l4: 0.093808, l5: 0.200641, l6: 0.397361\n",
      "\n",
      "[epoch: 397/400, batch: 528/1000, ite: 52442] train loss: 1.1089, accuracy: 94.5428%, tar: 0.0190 \n",
      "l0: 0.021251, l1: 0.023342, l2: 0.036289, l3: 0.056136, l4: 0.113831, l5: 0.225806, l6: 0.438196\n",
      "\n",
      "[epoch: 397/400, batch: 536/1000, ite: 52443] train loss: 1.1095, accuracy: 94.4257%, tar: 0.0190 \n",
      "l0: 0.021246, l1: 0.022459, l2: 0.030233, l3: 0.049563, l4: 0.112989, l5: 0.215115, l6: 0.394253\n",
      "\n",
      "[epoch: 397/400, batch: 544/1000, ite: 52444] train loss: 1.1098, accuracy: 94.4425%, tar: 0.0190 \n",
      "l0: 0.016241, l1: 0.017529, l2: 0.025143, l3: 0.040916, l4: 0.082329, l5: 0.204798, l6: 0.390670\n",
      "\n",
      "[epoch: 397/400, batch: 552/1000, ite: 52445] train loss: 1.1099, accuracy: 95.5986%, tar: 0.0190 \n",
      "l0: 0.016352, l1: 0.017700, l2: 0.024158, l3: 0.037298, l4: 0.075677, l5: 0.156257, l6: 0.325792\n",
      "\n",
      "[epoch: 397/400, batch: 560/1000, ite: 52446] train loss: 1.1096, accuracy: 95.3026%, tar: 0.0190 \n",
      "l0: 0.018627, l1: 0.019869, l2: 0.027043, l3: 0.041686, l4: 0.075275, l5: 0.151196, l6: 0.329626\n",
      "\n",
      "[epoch: 397/400, batch: 568/1000, ite: 52447] train loss: 1.1094, accuracy: 95.3139%, tar: 0.0190 \n",
      "l0: 0.019440, l1: 0.020994, l2: 0.029312, l3: 0.042617, l4: 0.080779, l5: 0.164606, l6: 0.354810\n",
      "\n",
      "[epoch: 397/400, batch: 576/1000, ite: 52448] train loss: 1.1093, accuracy: 95.2731%, tar: 0.0190 \n",
      "l0: 0.016770, l1: 0.018431, l2: 0.027199, l3: 0.043125, l4: 0.076263, l5: 0.139244, l6: 0.254554\n",
      "\n",
      "[epoch: 397/400, batch: 584/1000, ite: 52449] train loss: 1.1087, accuracy: 96.2208%, tar: 0.0190 \n",
      "l0: 0.016858, l1: 0.018101, l2: 0.027724, l3: 0.041810, l4: 0.074123, l5: 0.171754, l6: 0.398351\n",
      "\n",
      "[epoch: 397/400, batch: 592/1000, ite: 52450] train loss: 1.1088, accuracy: 94.9681%, tar: 0.0190 \n",
      "l0: 0.014300, l1: 0.014792, l2: 0.020041, l3: 0.029235, l4: 0.050257, l5: 0.100902, l6: 0.251298\n",
      "\n",
      "[epoch: 397/400, batch: 600/1000, ite: 52451] train loss: 1.1079, accuracy: 96.3370%, tar: 0.0190 \n",
      "l0: 0.019981, l1: 0.021231, l2: 0.029128, l3: 0.043194, l4: 0.075253, l5: 0.152243, l6: 0.348230\n",
      "\n",
      "[epoch: 397/400, batch: 608/1000, ite: 52452] train loss: 1.1078, accuracy: 95.2886%, tar: 0.0190 \n",
      "l0: 0.016494, l1: 0.017218, l2: 0.024248, l3: 0.038305, l4: 0.082459, l5: 0.174088, l6: 0.327343\n",
      "\n",
      "[epoch: 397/400, batch: 616/1000, ite: 52453] train loss: 1.1076, accuracy: 95.5871%, tar: 0.0190 \n",
      "l0: 0.020797, l1: 0.022878, l2: 0.033073, l3: 0.048854, l4: 0.088832, l5: 0.184267, l6: 0.386956\n",
      "\n",
      "[epoch: 397/400, batch: 624/1000, ite: 52454] train loss: 1.1077, accuracy: 95.6226%, tar: 0.0190 \n",
      "l0: 0.018149, l1: 0.019491, l2: 0.026160, l3: 0.040979, l4: 0.084290, l5: 0.147440, l6: 0.304545\n",
      "\n",
      "[epoch: 397/400, batch: 632/1000, ite: 52455] train loss: 1.1074, accuracy: 95.2526%, tar: 0.0190 \n",
      "l0: 0.020746, l1: 0.023009, l2: 0.031885, l3: 0.054622, l4: 0.102811, l5: 0.225320, l6: 0.439825\n",
      "\n",
      "[epoch: 397/400, batch: 640/1000, ite: 52456] train loss: 1.1079, accuracy: 94.6635%, tar: 0.0190 \n",
      "l0: 0.020053, l1: 0.022430, l2: 0.032537, l3: 0.056743, l4: 0.115670, l5: 0.234949, l6: 0.462522\n",
      "\n",
      "[epoch: 397/400, batch: 648/1000, ite: 52457] train loss: 1.1085, accuracy: 94.0252%, tar: 0.0190 \n",
      "l0: 0.017452, l1: 0.019240, l2: 0.028317, l3: 0.047276, l4: 0.099065, l5: 0.216180, l6: 0.424677\n",
      "\n",
      "[epoch: 397/400, batch: 656/1000, ite: 52458] train loss: 1.1089, accuracy: 95.0442%, tar: 0.0190 \n",
      "l0: 0.025412, l1: 0.027235, l2: 0.036071, l3: 0.058451, l4: 0.119768, l5: 0.252786, l6: 0.510340\n",
      "\n",
      "[epoch: 397/400, batch: 664/1000, ite: 52459] train loss: 1.1099, accuracy: 92.5453%, tar: 0.0190 \n",
      "l0: 0.017950, l1: 0.019372, l2: 0.027032, l3: 0.039052, l4: 0.071879, l5: 0.149075, l6: 0.326499\n",
      "\n",
      "[epoch: 397/400, batch: 672/1000, ite: 52460] train loss: 1.1096, accuracy: 95.2775%, tar: 0.0190 \n",
      "l0: 0.024112, l1: 0.025451, l2: 0.034892, l3: 0.051583, l4: 0.096297, l5: 0.218405, l6: 0.437920\n",
      "\n",
      "[epoch: 397/400, batch: 680/1000, ite: 52461] train loss: 1.1101, accuracy: 94.7305%, tar: 0.0190 \n",
      "l0: 0.014959, l1: 0.016074, l2: 0.022110, l3: 0.031026, l4: 0.047767, l5: 0.077815, l6: 0.167133\n",
      "\n",
      "[epoch: 397/400, batch: 688/1000, ite: 52462] train loss: 1.1089, accuracy: 97.2399%, tar: 0.0190 \n",
      "l0: 0.013959, l1: 0.015610, l2: 0.023435, l3: 0.039810, l4: 0.101228, l5: 0.205531, l6: 0.387122\n",
      "\n",
      "[epoch: 397/400, batch: 696/1000, ite: 52463] train loss: 1.1090, accuracy: 95.5774%, tar: 0.0190 \n",
      "l0: 0.016840, l1: 0.018964, l2: 0.028008, l3: 0.049255, l4: 0.098898, l5: 0.206343, l6: 0.369515\n",
      "\n",
      "[epoch: 397/400, batch: 704/1000, ite: 52464] train loss: 1.1091, accuracy: 95.2443%, tar: 0.0190 \n",
      "l0: 0.022142, l1: 0.024012, l2: 0.032238, l3: 0.050458, l4: 0.095830, l5: 0.200230, l6: 0.441483\n",
      "\n",
      "[epoch: 397/400, batch: 712/1000, ite: 52465] train loss: 1.1095, accuracy: 94.4114%, tar: 0.0190 \n",
      "l0: 0.020089, l1: 0.021604, l2: 0.030876, l3: 0.051218, l4: 0.090749, l5: 0.190512, l6: 0.445955\n",
      "\n",
      "[epoch: 397/400, batch: 720/1000, ite: 52466] train loss: 1.1100, accuracy: 94.8031%, tar: 0.0190 \n",
      "l0: 0.019847, l1: 0.020781, l2: 0.028675, l3: 0.045108, l4: 0.083022, l5: 0.158777, l6: 0.352100\n",
      "\n",
      "[epoch: 397/400, batch: 728/1000, ite: 52467] train loss: 1.1099, accuracy: 94.9060%, tar: 0.0190 \n",
      "l0: 0.020785, l1: 0.023345, l2: 0.035018, l3: 0.066304, l4: 0.131620, l5: 0.280494, l6: 0.452020\n",
      "\n",
      "[epoch: 397/400, batch: 736/1000, ite: 52468] train loss: 1.1106, accuracy: 93.6283%, tar: 0.0190 \n",
      "l0: 0.018712, l1: 0.019873, l2: 0.026885, l3: 0.038793, l4: 0.064615, l5: 0.126842, l6: 0.306372\n",
      "\n",
      "[epoch: 397/400, batch: 744/1000, ite: 52469] train loss: 1.1102, accuracy: 95.5479%, tar: 0.0190 \n",
      "l0: 0.020425, l1: 0.021502, l2: 0.027807, l3: 0.041358, l4: 0.071089, l5: 0.140461, l6: 0.382318\n",
      "\n",
      "[epoch: 397/400, batch: 752/1000, ite: 52470] train loss: 1.1102, accuracy: 94.5937%, tar: 0.0190 \n",
      "l0: 0.017568, l1: 0.018711, l2: 0.025810, l3: 0.037750, l4: 0.067600, l5: 0.116391, l6: 0.244432\n",
      "\n",
      "[epoch: 397/400, batch: 760/1000, ite: 52471] train loss: 1.1094, accuracy: 96.1139%, tar: 0.0190 \n",
      "l0: 0.016189, l1: 0.017098, l2: 0.022982, l3: 0.035544, l4: 0.065615, l5: 0.132015, l6: 0.308101\n",
      "\n",
      "[epoch: 397/400, batch: 768/1000, ite: 52472] train loss: 1.1090, accuracy: 95.2701%, tar: 0.0190 \n",
      "l0: 0.017523, l1: 0.018503, l2: 0.025347, l3: 0.040517, l4: 0.073498, l5: 0.143259, l6: 0.310649\n",
      "\n",
      "[epoch: 397/400, batch: 776/1000, ite: 52473] train loss: 1.1087, accuracy: 95.4042%, tar: 0.0190 \n",
      "l0: 0.022618, l1: 0.023797, l2: 0.031986, l3: 0.049828, l4: 0.102608, l5: 0.212477, l6: 0.484990\n",
      "\n",
      "[epoch: 397/400, batch: 784/1000, ite: 52474] train loss: 1.1093, accuracy: 93.3108%, tar: 0.0190 \n",
      "l0: 0.019041, l1: 0.021077, l2: 0.031933, l3: 0.056059, l4: 0.099251, l5: 0.175554, l6: 0.374986\n",
      "\n",
      "[epoch: 397/400, batch: 792/1000, ite: 52475] train loss: 1.1094, accuracy: 95.5417%, tar: 0.0190 \n",
      "l0: 0.015650, l1: 0.016665, l2: 0.024488, l3: 0.038203, l4: 0.073226, l5: 0.164526, l6: 0.355172\n",
      "\n",
      "[epoch: 397/400, batch: 800/1000, ite: 52476] train loss: 1.1093, accuracy: 95.0893%, tar: 0.0190 \n",
      "l0: 0.015250, l1: 0.016525, l2: 0.022954, l3: 0.036082, l4: 0.061362, l5: 0.123888, l6: 0.316890\n",
      "\n",
      "[epoch: 397/400, batch: 808/1000, ite: 52477] train loss: 1.1089, accuracy: 95.9812%, tar: 0.0190 \n",
      "l0: 0.021820, l1: 0.023012, l2: 0.030404, l3: 0.048367, l4: 0.081295, l5: 0.147532, l6: 0.314101\n",
      "\n",
      "[epoch: 397/400, batch: 816/1000, ite: 52478] train loss: 1.1086, accuracy: 94.6929%, tar: 0.0190 \n",
      "l0: 0.016061, l1: 0.017399, l2: 0.024693, l3: 0.039361, l4: 0.066053, l5: 0.158295, l6: 0.394125\n",
      "\n",
      "[epoch: 397/400, batch: 824/1000, ite: 52479] train loss: 1.1086, accuracy: 95.0157%, tar: 0.0190 \n",
      "l0: 0.021416, l1: 0.023481, l2: 0.030886, l3: 0.042734, l4: 0.071582, l5: 0.142581, l6: 0.313479\n",
      "\n",
      "[epoch: 397/400, batch: 832/1000, ite: 52480] train loss: 1.1083, accuracy: 96.2036%, tar: 0.0190 \n",
      "l0: 0.015117, l1: 0.015839, l2: 0.021425, l3: 0.029837, l4: 0.055058, l5: 0.115800, l6: 0.412897\n",
      "\n",
      "[epoch: 397/400, batch: 840/1000, ite: 52481] train loss: 1.1083, accuracy: 94.9291%, tar: 0.0190 \n",
      "l0: 0.016825, l1: 0.018123, l2: 0.024981, l3: 0.040403, l4: 0.081619, l5: 0.169043, l6: 0.341306\n",
      "\n",
      "[epoch: 397/400, batch: 848/1000, ite: 52482] train loss: 1.1081, accuracy: 95.0501%, tar: 0.0190 \n",
      "l0: 0.016175, l1: 0.017783, l2: 0.025439, l3: 0.042175, l4: 0.091673, l5: 0.236442, l6: 0.432485\n",
      "\n",
      "[epoch: 397/400, batch: 856/1000, ite: 52483] train loss: 1.1085, accuracy: 95.4000%, tar: 0.0189 \n",
      "l0: 0.018607, l1: 0.019150, l2: 0.025084, l3: 0.038009, l4: 0.070113, l5: 0.140829, l6: 0.287682\n",
      "\n",
      "[epoch: 397/400, batch: 864/1000, ite: 52484] train loss: 1.1080, accuracy: 95.1328%, tar: 0.0189 \n",
      "l0: 0.017146, l1: 0.017757, l2: 0.023633, l3: 0.033652, l4: 0.057463, l5: 0.100167, l6: 0.225864\n",
      "\n",
      "[epoch: 397/400, batch: 872/1000, ite: 52485] train loss: 1.1072, accuracy: 96.5518%, tar: 0.0189 \n",
      "l0: 0.017556, l1: 0.018863, l2: 0.026436, l3: 0.040812, l4: 0.075523, l5: 0.166428, l6: 0.302856\n",
      "\n",
      "[epoch: 397/400, batch: 880/1000, ite: 52486] train loss: 1.1069, accuracy: 95.7920%, tar: 0.0189 \n",
      "l0: 0.021602, l1: 0.022915, l2: 0.031845, l3: 0.047874, l4: 0.088170, l5: 0.200664, l6: 0.447250\n",
      "\n",
      "[epoch: 397/400, batch: 888/1000, ite: 52487] train loss: 1.1073, accuracy: 93.6873%, tar: 0.0189 \n",
      "l0: 0.017631, l1: 0.018685, l2: 0.025458, l3: 0.041532, l4: 0.069028, l5: 0.169641, l6: 0.370365\n",
      "\n",
      "[epoch: 397/400, batch: 896/1000, ite: 52488] train loss: 1.1072, accuracy: 95.0080%, tar: 0.0189 \n",
      "l0: 0.016438, l1: 0.018383, l2: 0.027386, l3: 0.046128, l4: 0.093472, l5: 0.193875, l6: 0.372266\n",
      "\n",
      "[epoch: 397/400, batch: 904/1000, ite: 52489] train loss: 1.1073, accuracy: 95.5224%, tar: 0.0189 \n",
      "l0: 0.022044, l1: 0.024011, l2: 0.032836, l3: 0.052172, l4: 0.105737, l5: 0.220475, l6: 0.505313\n",
      "\n",
      "[epoch: 397/400, batch: 912/1000, ite: 52490] train loss: 1.1081, accuracy: 94.6018%, tar: 0.0189 \n",
      "l0: 0.020106, l1: 0.021408, l2: 0.030363, l3: 0.044378, l4: 0.084593, l5: 0.169082, l6: 0.322077\n",
      "\n",
      "[epoch: 397/400, batch: 920/1000, ite: 52491] train loss: 1.1079, accuracy: 94.8356%, tar: 0.0189 \n",
      "l0: 0.022247, l1: 0.023604, l2: 0.032949, l3: 0.048646, l4: 0.100213, l5: 0.154538, l6: 0.302520\n",
      "\n",
      "[epoch: 397/400, batch: 928/1000, ite: 52492] train loss: 1.1076, accuracy: 95.0333%, tar: 0.0190 \n",
      "l0: 0.014816, l1: 0.016127, l2: 0.024088, l3: 0.040757, l4: 0.069335, l5: 0.132654, l6: 0.301353\n",
      "\n",
      "[epoch: 397/400, batch: 936/1000, ite: 52493] train loss: 1.1072, accuracy: 96.4623%, tar: 0.0189 \n",
      "l0: 0.015506, l1: 0.016566, l2: 0.021930, l3: 0.034372, l4: 0.066502, l5: 0.131787, l6: 0.368119\n",
      "\n",
      "[epoch: 397/400, batch: 944/1000, ite: 52494] train loss: 1.1071, accuracy: 95.4036%, tar: 0.0189 \n",
      "l0: 0.013720, l1: 0.014791, l2: 0.020678, l3: 0.032102, l4: 0.063283, l5: 0.136010, l6: 0.272632\n",
      "\n",
      "[epoch: 397/400, batch: 952/1000, ite: 52495] train loss: 1.1065, accuracy: 96.3112%, tar: 0.0189 \n",
      "l0: 0.023818, l1: 0.026660, l2: 0.036788, l3: 0.055456, l4: 0.109880, l5: 0.234332, l6: 0.472722\n",
      "\n",
      "[epoch: 397/400, batch: 960/1000, ite: 52496] train loss: 1.1072, accuracy: 93.8961%, tar: 0.0189 \n",
      "l0: 0.015889, l1: 0.016570, l2: 0.021757, l3: 0.032545, l4: 0.055804, l5: 0.118755, l6: 0.291178\n",
      "\n",
      "[epoch: 397/400, batch: 968/1000, ite: 52497] train loss: 1.1066, accuracy: 95.5867%, tar: 0.0189 \n",
      "l0: 0.017279, l1: 0.018048, l2: 0.023972, l3: 0.035033, l4: 0.056093, l5: 0.097240, l6: 0.200732\n",
      "\n",
      "[epoch: 397/400, batch: 976/1000, ite: 52498] train loss: 1.1057, accuracy: 96.4758%, tar: 0.0189 \n",
      "l0: 0.019902, l1: 0.021852, l2: 0.032885, l3: 0.058681, l4: 0.126230, l5: 0.263713, l6: 0.609186\n",
      "\n",
      "[epoch: 397/400, batch: 984/1000, ite: 52499] train loss: 1.1070, accuracy: 93.2371%, tar: 0.0189 \n",
      "l0: 0.017719, l1: 0.018886, l2: 0.027312, l3: 0.044731, l4: 0.078168, l5: 0.152014, l6: 0.319359\n",
      "\n",
      "[epoch: 397/400, batch: 992/1000, ite: 52500] train loss: 1.1068, accuracy: 95.1365%, tar: 0.0189 \n",
      "l0: 0.018536, l1: 0.020368, l2: 0.027353, l3: 0.043365, l4: 0.099300, l5: 0.171425, l6: 0.348847\n",
      "\n",
      "[epoch: 397/400, batch: 1000/1000, ite: 52501] train loss: 1.1067, accuracy: 95.5481%, tar: 0.0189 \n",
      "l0: 0.017679, l1: 0.019017, l2: 0.028910, l3: 0.052189, l4: 0.102416, l5: 0.199761, l6: 0.400092\n",
      "\n",
      "[epoch: 398/400, batch: 8/1000, ite: 52502] train loss: 1.1069, accuracy: 94.7869%, tar: 0.0189 \n",
      "l0: 0.016147, l1: 0.018023, l2: 0.026655, l3: 0.044699, l4: 0.089485, l5: 0.178879, l6: 0.362844\n",
      "\n",
      "[epoch: 398/400, batch: 16/1000, ite: 52503] train loss: 1.1069, accuracy: 94.8131%, tar: 0.0189 \n",
      "l0: 0.014731, l1: 0.016231, l2: 0.024717, l3: 0.040229, l4: 0.080525, l5: 0.158875, l6: 0.297496\n",
      "\n",
      "[epoch: 398/400, batch: 24/1000, ite: 52504] train loss: 1.1066, accuracy: 96.3283%, tar: 0.0189 \n",
      "l0: 0.017363, l1: 0.018661, l2: 0.027608, l3: 0.041695, l4: 0.070865, l5: 0.119525, l6: 0.319540\n",
      "\n",
      "[epoch: 398/400, batch: 32/1000, ite: 52505] train loss: 1.1063, accuracy: 95.7200%, tar: 0.0189 \n",
      "l0: 0.016865, l1: 0.018279, l2: 0.025069, l3: 0.039162, l4: 0.073561, l5: 0.176879, l6: 0.344616\n",
      "\n",
      "[epoch: 398/400, batch: 40/1000, ite: 52506] train loss: 1.1061, accuracy: 95.1696%, tar: 0.0189 \n",
      "l0: 0.016784, l1: 0.017809, l2: 0.023696, l3: 0.038679, l4: 0.081283, l5: 0.178641, l6: 0.371836\n",
      "\n",
      "[epoch: 398/400, batch: 48/1000, ite: 52507] train loss: 1.1061, accuracy: 94.7583%, tar: 0.0189 \n",
      "l0: 0.024497, l1: 0.026050, l2: 0.034825, l3: 0.049924, l4: 0.084470, l5: 0.170911, l6: 0.381308\n",
      "\n",
      "[epoch: 398/400, batch: 56/1000, ite: 52508] train loss: 1.1062, accuracy: 94.4296%, tar: 0.0189 \n",
      "l0: 0.023439, l1: 0.025525, l2: 0.038231, l3: 0.059865, l4: 0.100495, l5: 0.207561, l6: 0.369425\n",
      "\n",
      "[epoch: 398/400, batch: 64/1000, ite: 52509] train loss: 1.1064, accuracy: 94.5090%, tar: 0.0189 \n",
      "l0: 0.020716, l1: 0.022307, l2: 0.031194, l3: 0.048986, l4: 0.094692, l5: 0.214429, l6: 0.394697\n",
      "\n",
      "[epoch: 398/400, batch: 72/1000, ite: 52510] train loss: 1.1066, accuracy: 94.4494%, tar: 0.0189 \n",
      "l0: 0.021694, l1: 0.023430, l2: 0.031081, l3: 0.051406, l4: 0.105583, l5: 0.197857, l6: 0.383906\n",
      "\n",
      "[epoch: 398/400, batch: 80/1000, ite: 52511] train loss: 1.1068, accuracy: 94.5472%, tar: 0.0189 \n",
      "l0: 0.014855, l1: 0.015836, l2: 0.020926, l3: 0.031823, l4: 0.052908, l5: 0.106532, l6: 0.301601\n",
      "\n",
      "[epoch: 398/400, batch: 88/1000, ite: 52512] train loss: 1.1063, accuracy: 95.8347%, tar: 0.0189 \n",
      "l0: 0.018836, l1: 0.020002, l2: 0.027617, l3: 0.039211, l4: 0.073330, l5: 0.141031, l6: 0.296020\n",
      "\n",
      "[epoch: 398/400, batch: 96/1000, ite: 52513] train loss: 1.1059, accuracy: 95.9065%, tar: 0.0189 \n",
      "l0: 0.024249, l1: 0.026638, l2: 0.036453, l3: 0.058652, l4: 0.118378, l5: 0.229033, l6: 0.452404\n",
      "\n",
      "[epoch: 398/400, batch: 104/1000, ite: 52514] train loss: 1.1065, accuracy: 94.9632%, tar: 0.0189 \n",
      "l0: 0.018334, l1: 0.019820, l2: 0.029635, l3: 0.047867, l4: 0.092238, l5: 0.198222, l6: 0.416548\n",
      "\n",
      "[epoch: 398/400, batch: 112/1000, ite: 52515] train loss: 1.1068, accuracy: 94.9244%, tar: 0.0189 \n",
      "l0: 0.015626, l1: 0.017411, l2: 0.027524, l3: 0.047432, l4: 0.091263, l5: 0.202516, l6: 0.377544\n",
      "\n",
      "[epoch: 398/400, batch: 120/1000, ite: 52516] train loss: 1.1069, accuracy: 95.5677%, tar: 0.0189 \n",
      "l0: 0.019233, l1: 0.020971, l2: 0.028060, l3: 0.045664, l4: 0.071416, l5: 0.162141, l6: 0.346215\n",
      "\n",
      "[epoch: 398/400, batch: 128/1000, ite: 52517] train loss: 1.1067, accuracy: 96.2322%, tar: 0.0189 \n",
      "l0: 0.018193, l1: 0.019189, l2: 0.026859, l3: 0.037645, l4: 0.078195, l5: 0.187210, l6: 0.350431\n",
      "\n",
      "[epoch: 398/400, batch: 136/1000, ite: 52518] train loss: 1.1067, accuracy: 95.4468%, tar: 0.0189 \n",
      "l0: 0.015485, l1: 0.016747, l2: 0.024196, l3: 0.042865, l4: 0.092958, l5: 0.182490, l6: 0.302426\n",
      "\n",
      "[epoch: 398/400, batch: 144/1000, ite: 52519] train loss: 1.1064, accuracy: 95.8399%, tar: 0.0189 \n",
      "l0: 0.022185, l1: 0.023699, l2: 0.034643, l3: 0.053287, l4: 0.091412, l5: 0.218099, l6: 0.460497\n",
      "\n",
      "[epoch: 398/400, batch: 152/1000, ite: 52520] train loss: 1.1069, accuracy: 93.9007%, tar: 0.0189 \n",
      "l0: 0.016650, l1: 0.017208, l2: 0.022678, l3: 0.031089, l4: 0.054694, l5: 0.098884, l6: 0.219060\n",
      "\n",
      "[epoch: 398/400, batch: 160/1000, ite: 52521] train loss: 1.1061, accuracy: 96.1671%, tar: 0.0189 \n",
      "l0: 0.022041, l1: 0.023318, l2: 0.029922, l3: 0.044555, l4: 0.074379, l5: 0.177368, l6: 0.370383\n",
      "\n",
      "[epoch: 398/400, batch: 168/1000, ite: 52522] train loss: 1.1061, accuracy: 94.2603%, tar: 0.0189 \n",
      "l0: 0.019936, l1: 0.021198, l2: 0.028949, l3: 0.044054, l4: 0.075386, l5: 0.157928, l6: 0.319411\n",
      "\n",
      "[epoch: 398/400, batch: 176/1000, ite: 52523] train loss: 1.1059, accuracy: 94.8347%, tar: 0.0189 \n",
      "l0: 0.017090, l1: 0.018356, l2: 0.025735, l3: 0.043076, l4: 0.074921, l5: 0.138866, l6: 0.295799\n",
      "\n",
      "[epoch: 398/400, batch: 184/1000, ite: 52524] train loss: 1.1055, accuracy: 96.0008%, tar: 0.0189 \n",
      "l0: 0.013938, l1: 0.014506, l2: 0.020713, l3: 0.031911, l4: 0.060210, l5: 0.153064, l6: 0.294314\n",
      "\n",
      "[epoch: 398/400, batch: 192/1000, ite: 52525] train loss: 1.1051, accuracy: 96.2803%, tar: 0.0189 \n",
      "l0: 0.019877, l1: 0.021827, l2: 0.029566, l3: 0.047747, l4: 0.083937, l5: 0.149672, l6: 0.292529\n",
      "\n",
      "[epoch: 398/400, batch: 200/1000, ite: 52526] train loss: 1.1048, accuracy: 96.1778%, tar: 0.0189 \n",
      "l0: 0.016660, l1: 0.018363, l2: 0.026343, l3: 0.045639, l4: 0.090595, l5: 0.191244, l6: 0.350081\n",
      "\n",
      "[epoch: 398/400, batch: 208/1000, ite: 52527] train loss: 1.1047, accuracy: 95.5080%, tar: 0.0189 \n",
      "l0: 0.015517, l1: 0.017056, l2: 0.026313, l3: 0.040697, l4: 0.069484, l5: 0.139198, l6: 0.371788\n",
      "\n",
      "[epoch: 398/400, batch: 216/1000, ite: 52528] train loss: 1.1046, accuracy: 95.8315%, tar: 0.0189 \n",
      "l0: 0.012169, l1: 0.013350, l2: 0.019200, l3: 0.030491, l4: 0.060061, l5: 0.147756, l6: 0.275078\n",
      "\n",
      "[epoch: 398/400, batch: 224/1000, ite: 52529] train loss: 1.1041, accuracy: 95.7904%, tar: 0.0189 \n",
      "l0: 0.024019, l1: 0.025795, l2: 0.035580, l3: 0.051816, l4: 0.093701, l5: 0.204091, l6: 0.461458\n",
      "\n",
      "[epoch: 398/400, batch: 232/1000, ite: 52530] train loss: 1.1046, accuracy: 93.4909%, tar: 0.0189 \n",
      "l0: 0.018588, l1: 0.019579, l2: 0.027153, l3: 0.038967, l4: 0.070652, l5: 0.144021, l6: 0.354571\n",
      "\n",
      "[epoch: 398/400, batch: 240/1000, ite: 52531] train loss: 1.1045, accuracy: 95.2303%, tar: 0.0189 \n",
      "l0: 0.017707, l1: 0.018886, l2: 0.024293, l3: 0.038232, l4: 0.068697, l5: 0.140247, l6: 0.311762\n",
      "\n",
      "[epoch: 398/400, batch: 248/1000, ite: 52532] train loss: 1.1042, accuracy: 95.6520%, tar: 0.0189 \n",
      "l0: 0.020849, l1: 0.022592, l2: 0.032197, l3: 0.047559, l4: 0.087829, l5: 0.194929, l6: 0.464659\n",
      "\n",
      "[epoch: 398/400, batch: 280/1000, ite: 52536] train loss: 1.1053, accuracy: 95.6855%, tar: 0.0189 \n",
      "l0: 0.017018, l1: 0.018290, l2: 0.026805, l3: 0.039496, l4: 0.065575, l5: 0.113484, l6: 0.224401\n",
      "\n",
      "[epoch: 398/400, batch: 288/1000, ite: 52537] train loss: 1.1046, accuracy: 96.9073%, tar: 0.0189 \n",
      "l0: 0.018292, l1: 0.019407, l2: 0.028138, l3: 0.046426, l4: 0.086391, l5: 0.187983, l6: 0.406279\n",
      "\n",
      "[epoch: 398/400, batch: 296/1000, ite: 52538] train loss: 1.1048, accuracy: 95.2487%, tar: 0.0189 \n",
      "l0: 0.018712, l1: 0.020143, l2: 0.026105, l3: 0.038326, l4: 0.074899, l5: 0.162943, l6: 0.331601\n",
      "\n",
      "[epoch: 398/400, batch: 304/1000, ite: 52539] train loss: 1.1046, accuracy: 94.9420%, tar: 0.0189 \n",
      "l0: 0.023877, l1: 0.025202, l2: 0.032680, l3: 0.046851, l4: 0.081917, l5: 0.156729, l6: 0.331877\n",
      "\n",
      "[epoch: 398/400, batch: 312/1000, ite: 52540] train loss: 1.1045, accuracy: 95.1022%, tar: 0.0189 \n",
      "l0: 0.016655, l1: 0.017843, l2: 0.025326, l3: 0.039709, l4: 0.071707, l5: 0.173198, l6: 0.317705\n",
      "\n",
      "[epoch: 398/400, batch: 320/1000, ite: 52541] train loss: 1.1042, accuracy: 95.8713%, tar: 0.0189 \n",
      "l0: 0.017545, l1: 0.019278, l2: 0.028443, l3: 0.043246, l4: 0.091229, l5: 0.212647, l6: 0.469439\n",
      "\n",
      "[epoch: 398/400, batch: 328/1000, ite: 52542] train loss: 1.1047, accuracy: 94.4965%, tar: 0.0189 \n",
      "l0: 0.018399, l1: 0.020619, l2: 0.029985, l3: 0.048665, l4: 0.100217, l5: 0.242992, l6: 0.395594\n",
      "\n",
      "[epoch: 398/400, batch: 336/1000, ite: 52543] train loss: 1.1050, accuracy: 95.3688%, tar: 0.0189 \n",
      "l0: 0.019778, l1: 0.021711, l2: 0.029693, l3: 0.045200, l4: 0.078904, l5: 0.175822, l6: 0.307148\n",
      "\n",
      "[epoch: 398/400, batch: 344/1000, ite: 52544] train loss: 1.1048, accuracy: 95.9051%, tar: 0.0189 \n",
      "l0: 0.018860, l1: 0.020095, l2: 0.027917, l3: 0.040919, l4: 0.100864, l5: 0.185618, l6: 0.347369\n",
      "\n",
      "[epoch: 398/400, batch: 352/1000, ite: 52545] train loss: 1.1047, accuracy: 94.7852%, tar: 0.0189 \n",
      "l0: 0.021196, l1: 0.022839, l2: 0.030532, l3: 0.046159, l4: 0.085428, l5: 0.161142, l6: 0.327933\n",
      "\n",
      "[epoch: 398/400, batch: 360/1000, ite: 52546] train loss: 1.1046, accuracy: 94.8297%, tar: 0.0189 \n",
      "l0: 0.015423, l1: 0.016261, l2: 0.022373, l3: 0.032664, l4: 0.054742, l5: 0.111689, l6: 0.209512\n",
      "\n",
      "[epoch: 398/400, batch: 368/1000, ite: 52547] train loss: 1.1038, accuracy: 96.7035%, tar: 0.0189 \n",
      "l0: 0.013835, l1: 0.014829, l2: 0.021991, l3: 0.043727, l4: 0.083629, l5: 0.170374, l6: 0.333668\n",
      "\n",
      "[epoch: 398/400, batch: 376/1000, ite: 52548] train loss: 1.1037, accuracy: 95.8452%, tar: 0.0189 \n",
      "l0: 0.017233, l1: 0.018004, l2: 0.024791, l3: 0.036108, l4: 0.060684, l5: 0.124103, l6: 0.311685\n",
      "\n",
      "[epoch: 398/400, batch: 384/1000, ite: 52549] train loss: 1.1033, accuracy: 95.8377%, tar: 0.0189 \n",
      "l0: 0.019259, l1: 0.020386, l2: 0.029779, l3: 0.048512, l4: 0.090171, l5: 0.180507, l6: 0.298767\n",
      "\n",
      "[epoch: 398/400, batch: 392/1000, ite: 52550] train loss: 1.1031, accuracy: 95.3782%, tar: 0.0189 \n",
      "l0: 0.015233, l1: 0.016450, l2: 0.022701, l3: 0.038674, l4: 0.074049, l5: 0.160240, l6: 0.364604\n",
      "\n",
      "[epoch: 398/400, batch: 400/1000, ite: 52551] train loss: 1.1030, accuracy: 94.9696%, tar: 0.0189 \n",
      "l0: 0.014570, l1: 0.015624, l2: 0.022086, l3: 0.031187, l4: 0.058388, l5: 0.127031, l6: 0.315508\n",
      "\n",
      "[epoch: 398/400, batch: 408/1000, ite: 52552] train loss: 1.1027, accuracy: 95.9584%, tar: 0.0189 \n",
      "l0: 0.013205, l1: 0.014361, l2: 0.021021, l3: 0.031682, l4: 0.065735, l5: 0.142311, l6: 0.302768\n",
      "\n",
      "[epoch: 398/400, batch: 416/1000, ite: 52553] train loss: 1.1023, accuracy: 95.9208%, tar: 0.0189 \n",
      "l0: 0.014028, l1: 0.014991, l2: 0.021092, l3: 0.034581, l4: 0.067076, l5: 0.126240, l6: 0.294056\n",
      "\n",
      "[epoch: 398/400, batch: 424/1000, ite: 52554] train loss: 1.1018, accuracy: 96.3060%, tar: 0.0189 \n",
      "l0: 0.016551, l1: 0.017468, l2: 0.024416, l3: 0.037198, l4: 0.060998, l5: 0.110821, l6: 0.261584\n",
      "\n",
      "[epoch: 398/400, batch: 432/1000, ite: 52555] train loss: 1.1013, accuracy: 96.5614%, tar: 0.0188 \n",
      "l0: 0.020625, l1: 0.021122, l2: 0.027139, l3: 0.039048, l4: 0.064860, l5: 0.120027, l6: 0.309924\n",
      "\n",
      "[epoch: 398/400, batch: 440/1000, ite: 52556] train loss: 1.1010, accuracy: 95.0017%, tar: 0.0189 \n",
      "l0: 0.020344, l1: 0.021858, l2: 0.031503, l3: 0.051227, l4: 0.128040, l5: 0.247880, l6: 0.501190\n",
      "\n",
      "[epoch: 398/400, batch: 448/1000, ite: 52557] train loss: 1.1017, accuracy: 94.0992%, tar: 0.0189 \n",
      "l0: 0.020095, l1: 0.020991, l2: 0.029765, l3: 0.047381, l4: 0.095327, l5: 0.227999, l6: 0.408765\n",
      "\n",
      "[epoch: 398/400, batch: 456/1000, ite: 52558] train loss: 1.1020, accuracy: 94.7104%, tar: 0.0189 \n",
      "l0: 0.016823, l1: 0.018684, l2: 0.029084, l3: 0.051567, l4: 0.099476, l5: 0.248244, l6: 0.420610\n",
      "\n",
      "[epoch: 398/400, batch: 464/1000, ite: 52559] train loss: 1.1024, accuracy: 94.9000%, tar: 0.0189 \n",
      "l0: 0.020799, l1: 0.021754, l2: 0.029762, l3: 0.045415, l4: 0.093080, l5: 0.186177, l6: 0.445696\n",
      "\n",
      "[epoch: 398/400, batch: 472/1000, ite: 52560] train loss: 1.1027, accuracy: 93.6064%, tar: 0.0189 \n",
      "l0: 0.012485, l1: 0.013987, l2: 0.020699, l3: 0.032983, l4: 0.103950, l5: 0.180514, l6: 0.339483\n",
      "\n",
      "[epoch: 398/400, batch: 480/1000, ite: 52561] train loss: 1.1026, accuracy: 96.3129%, tar: 0.0188 \n",
      "l0: 0.017457, l1: 0.019309, l2: 0.027252, l3: 0.042859, l4: 0.086535, l5: 0.163998, l6: 0.306209\n",
      "\n",
      "[epoch: 398/400, batch: 488/1000, ite: 52562] train loss: 1.1024, accuracy: 95.7236%, tar: 0.0188 \n",
      "l0: 0.013902, l1: 0.014996, l2: 0.019715, l3: 0.030047, l4: 0.058362, l5: 0.099196, l6: 0.186567\n",
      "\n",
      "[epoch: 398/400, batch: 496/1000, ite: 52563] train loss: 1.1015, accuracy: 96.8080%, tar: 0.0188 \n",
      "l0: 0.017211, l1: 0.019498, l2: 0.028793, l3: 0.054099, l4: 0.116821, l5: 0.247458, l6: 0.447717\n",
      "\n",
      "[epoch: 398/400, batch: 504/1000, ite: 52564] train loss: 1.1020, accuracy: 95.2239%, tar: 0.0188 \n",
      "l0: 0.017931, l1: 0.018796, l2: 0.026167, l3: 0.038137, l4: 0.063737, l5: 0.121120, l6: 0.288836\n",
      "\n",
      "[epoch: 398/400, batch: 512/1000, ite: 52565] train loss: 1.1016, accuracy: 95.4830%, tar: 0.0188 \n",
      "l0: 0.020974, l1: 0.022000, l2: 0.031324, l3: 0.046904, l4: 0.076459, l5: 0.158442, l6: 0.355119\n",
      "\n",
      "[epoch: 398/400, batch: 520/1000, ite: 52566] train loss: 1.1015, accuracy: 94.5163%, tar: 0.0188 \n",
      "l0: 0.017860, l1: 0.019591, l2: 0.027612, l3: 0.045504, l4: 0.086588, l5: 0.191049, l6: 0.398306\n",
      "\n",
      "[epoch: 398/400, batch: 528/1000, ite: 52567] train loss: 1.1017, accuracy: 95.3379%, tar: 0.0188 \n",
      "l0: 0.027958, l1: 0.029494, l2: 0.037354, l3: 0.057795, l4: 0.106652, l5: 0.237282, l6: 0.501736\n",
      "\n",
      "[epoch: 398/400, batch: 536/1000, ite: 52568] train loss: 1.1024, accuracy: 92.9365%, tar: 0.0188 \n",
      "l0: 0.017227, l1: 0.018877, l2: 0.027509, l3: 0.041323, l4: 0.081606, l5: 0.192382, l6: 0.418674\n",
      "\n",
      "[epoch: 398/400, batch: 544/1000, ite: 52569] train loss: 1.1026, accuracy: 95.7480%, tar: 0.0188 \n",
      "l0: 0.022936, l1: 0.024231, l2: 0.033586, l3: 0.053191, l4: 0.107574, l5: 0.220028, l6: 0.569279\n",
      "\n",
      "[epoch: 398/400, batch: 552/1000, ite: 52570] train loss: 1.1035, accuracy: 92.8670%, tar: 0.0189 \n",
      "l0: 0.019660, l1: 0.021057, l2: 0.028844, l3: 0.042430, l4: 0.071435, l5: 0.153480, l6: 0.312682\n",
      "\n",
      "[epoch: 398/400, batch: 560/1000, ite: 52571] train loss: 1.1032, accuracy: 95.3252%, tar: 0.0189 \n",
      "l0: 0.022581, l1: 0.024554, l2: 0.034941, l3: 0.058344, l4: 0.099598, l5: 0.200011, l6: 0.391664\n",
      "\n",
      "[epoch: 398/400, batch: 568/1000, ite: 52572] train loss: 1.1034, accuracy: 94.2321%, tar: 0.0189 \n",
      "l0: 0.016680, l1: 0.018278, l2: 0.025978, l3: 0.044957, l4: 0.093730, l5: 0.168692, l6: 0.359901\n",
      "\n",
      "[epoch: 398/400, batch: 576/1000, ite: 52573] train loss: 1.1034, accuracy: 95.7307%, tar: 0.0189 \n",
      "l0: 0.018900, l1: 0.020346, l2: 0.029001, l3: 0.043525, l4: 0.088735, l5: 0.175307, l6: 0.393114\n",
      "\n",
      "[epoch: 398/400, batch: 584/1000, ite: 52574] train loss: 1.1035, accuracy: 94.9342%, tar: 0.0189 \n",
      "l0: 0.017485, l1: 0.019131, l2: 0.027587, l3: 0.045704, l4: 0.080724, l5: 0.153796, l6: 0.383396\n",
      "\n",
      "[epoch: 398/400, batch: 592/1000, ite: 52575] train loss: 1.1035, accuracy: 95.5139%, tar: 0.0189 \n",
      "l0: 0.021941, l1: 0.024231, l2: 0.035709, l3: 0.055614, l4: 0.100821, l5: 0.256941, l6: 0.529353\n",
      "\n",
      "[epoch: 398/400, batch: 600/1000, ite: 52576] train loss: 1.1043, accuracy: 93.6757%, tar: 0.0189 \n",
      "l0: 0.017936, l1: 0.019620, l2: 0.027229, l3: 0.043737, l4: 0.084607, l5: 0.157446, l6: 0.334099\n",
      "\n",
      "[epoch: 398/400, batch: 608/1000, ite: 52577] train loss: 1.1041, accuracy: 95.1939%, tar: 0.0189 \n",
      "l0: 0.025278, l1: 0.027413, l2: 0.040514, l3: 0.065040, l4: 0.134066, l5: 0.270847, l6: 0.555138\n",
      "\n",
      "[epoch: 398/400, batch: 616/1000, ite: 52578] train loss: 1.1051, accuracy: 93.2194%, tar: 0.0189 \n",
      "l0: 0.012475, l1: 0.014131, l2: 0.022484, l3: 0.040132, l4: 0.096959, l5: 0.190397, l6: 0.384451\n",
      "\n",
      "[epoch: 398/400, batch: 624/1000, ite: 52579] train loss: 1.1052, accuracy: 96.1038%, tar: 0.0189 \n",
      "l0: 0.023128, l1: 0.024655, l2: 0.033513, l3: 0.046794, l4: 0.087665, l5: 0.195361, l6: 0.382989\n",
      "\n",
      "[epoch: 398/400, batch: 632/1000, ite: 52580] train loss: 1.1053, accuracy: 94.8372%, tar: 0.0189 \n",
      "l0: 0.018138, l1: 0.019803, l2: 0.030505, l3: 0.048667, l4: 0.105936, l5: 0.205130, l6: 0.493558\n",
      "\n",
      "[epoch: 398/400, batch: 640/1000, ite: 52581] train loss: 1.1059, accuracy: 94.4071%, tar: 0.0189 \n",
      "l0: 0.019568, l1: 0.020769, l2: 0.030274, l3: 0.048063, l4: 0.094210, l5: 0.205972, l6: 0.399992\n",
      "\n",
      "[epoch: 398/400, batch: 648/1000, ite: 52582] train loss: 1.1061, accuracy: 94.5387%, tar: 0.0189 \n",
      "l0: 0.017520, l1: 0.018765, l2: 0.024742, l3: 0.034801, l4: 0.074001, l5: 0.142548, l6: 0.314893\n",
      "\n",
      "[epoch: 398/400, batch: 656/1000, ite: 52583] train loss: 1.1058, accuracy: 95.8180%, tar: 0.0189 \n",
      "l0: 0.022436, l1: 0.023897, l2: 0.033866, l3: 0.047208, l4: 0.091688, l5: 0.202626, l6: 0.399604\n",
      "\n",
      "[epoch: 398/400, batch: 664/1000, ite: 52584] train loss: 1.1060, accuracy: 94.3954%, tar: 0.0189 \n",
      "l0: 0.024286, l1: 0.025786, l2: 0.033839, l3: 0.049486, l4: 0.089592, l5: 0.232697, l6: 0.472791\n",
      "\n",
      "[epoch: 398/400, batch: 672/1000, ite: 52585] train loss: 1.1065, accuracy: 93.7884%, tar: 0.0189 \n",
      "l0: 0.023415, l1: 0.024895, l2: 0.032343, l3: 0.050264, l4: 0.096078, l5: 0.185923, l6: 0.356407\n",
      "\n",
      "[epoch: 398/400, batch: 680/1000, ite: 52586] train loss: 1.1066, accuracy: 94.3540%, tar: 0.0189 \n",
      "l0: 0.017103, l1: 0.017931, l2: 0.024830, l3: 0.036666, l4: 0.063294, l5: 0.128380, l6: 0.274854\n",
      "\n",
      "[epoch: 398/400, batch: 688/1000, ite: 52587] train loss: 1.1061, accuracy: 96.0341%, tar: 0.0189 \n",
      "l0: 0.018103, l1: 0.019329, l2: 0.027362, l3: 0.046823, l4: 0.092784, l5: 0.197372, l6: 0.410110\n",
      "\n",
      "[epoch: 398/400, batch: 696/1000, ite: 52588] train loss: 1.1063, accuracy: 94.8836%, tar: 0.0189 \n",
      "l0: 0.021593, l1: 0.023139, l2: 0.031331, l3: 0.046925, l4: 0.084610, l5: 0.163211, l6: 0.373068\n",
      "\n",
      "[epoch: 398/400, batch: 704/1000, ite: 52589] train loss: 1.1063, accuracy: 95.1183%, tar: 0.0189 \n",
      "l0: 0.024570, l1: 0.026339, l2: 0.036631, l3: 0.054785, l4: 0.096389, l5: 0.197836, l6: 0.441277\n",
      "\n",
      "[epoch: 398/400, batch: 712/1000, ite: 52590] train loss: 1.1067, accuracy: 94.0803%, tar: 0.0189 \n",
      "l0: 0.020150, l1: 0.022008, l2: 0.031375, l3: 0.045045, l4: 0.088651, l5: 0.211401, l6: 0.432980\n",
      "\n",
      "[epoch: 398/400, batch: 720/1000, ite: 52591] train loss: 1.1070, accuracy: 94.6395%, tar: 0.0189 \n",
      "l0: 0.019421, l1: 0.020400, l2: 0.027875, l3: 0.042566, l4: 0.092002, l5: 0.202341, l6: 0.388255\n",
      "\n",
      "[epoch: 398/400, batch: 728/1000, ite: 52592] train loss: 1.1071, accuracy: 94.8777%, tar: 0.0189 \n",
      "l0: 0.018664, l1: 0.019686, l2: 0.027149, l3: 0.044399, l4: 0.081000, l5: 0.199193, l6: 0.407436\n",
      "\n",
      "[epoch: 398/400, batch: 736/1000, ite: 52593] train loss: 1.1073, accuracy: 94.3004%, tar: 0.0189 \n",
      "l0: 0.018396, l1: 0.019559, l2: 0.026256, l3: 0.040026, l4: 0.070393, l5: 0.139881, l6: 0.356248\n",
      "\n",
      "[epoch: 398/400, batch: 744/1000, ite: 52594] train loss: 1.1072, accuracy: 94.8250%, tar: 0.0189 \n",
      "l0: 0.019516, l1: 0.020442, l2: 0.027783, l3: 0.042315, l4: 0.076012, l5: 0.153428, l6: 0.327130\n",
      "\n",
      "[epoch: 398/400, batch: 752/1000, ite: 52595] train loss: 1.1070, accuracy: 94.9824%, tar: 0.0189 \n",
      "l0: 0.023312, l1: 0.024628, l2: 0.032267, l3: 0.049738, l4: 0.089072, l5: 0.179145, l6: 0.419276\n",
      "\n",
      "[epoch: 398/400, batch: 760/1000, ite: 52596] train loss: 1.1072, accuracy: 94.4576%, tar: 0.0189 \n",
      "l0: 0.022632, l1: 0.024396, l2: 0.032081, l3: 0.049501, l4: 0.090473, l5: 0.218403, l6: 0.436134\n",
      "\n",
      "[epoch: 398/400, batch: 768/1000, ite: 52597] train loss: 1.1076, accuracy: 94.5061%, tar: 0.0189 \n",
      "l0: 0.014887, l1: 0.016057, l2: 0.023439, l3: 0.043312, l4: 0.087871, l5: 0.180843, l6: 0.334481\n",
      "\n",
      "[epoch: 398/400, batch: 776/1000, ite: 52598] train loss: 1.1074, accuracy: 95.5342%, tar: 0.0189 \n",
      "l0: 0.019232, l1: 0.021121, l2: 0.031903, l3: 0.054464, l4: 0.099977, l5: 0.179760, l6: 0.326828\n",
      "\n",
      "[epoch: 398/400, batch: 784/1000, ite: 52599] train loss: 1.1074, accuracy: 95.4467%, tar: 0.0189 \n",
      "l0: 0.019133, l1: 0.020811, l2: 0.030938, l3: 0.047951, l4: 0.089729, l5: 0.210925, l6: 0.451041\n",
      "\n",
      "[epoch: 398/400, batch: 792/1000, ite: 52600] train loss: 1.1077, accuracy: 94.4885%, tar: 0.0189 \n",
      "l0: 0.017519, l1: 0.018667, l2: 0.024564, l3: 0.037264, l4: 0.072035, l5: 0.144479, l6: 0.274324\n",
      "\n",
      "[epoch: 398/400, batch: 800/1000, ite: 52601] train loss: 1.1073, accuracy: 95.8470%, tar: 0.0189 \n",
      "l0: 0.017063, l1: 0.018968, l2: 0.028413, l3: 0.050299, l4: 0.100006, l5: 0.185957, l6: 0.361963\n",
      "\n",
      "[epoch: 398/400, batch: 808/1000, ite: 52602] train loss: 1.1074, accuracy: 95.6125%, tar: 0.0189 \n",
      "l0: 0.019563, l1: 0.022215, l2: 0.031939, l3: 0.054352, l4: 0.105081, l5: 0.213583, l6: 0.451494\n",
      "\n",
      "[epoch: 398/400, batch: 816/1000, ite: 52603] train loss: 1.1078, accuracy: 94.6142%, tar: 0.0189 \n",
      "l0: 0.017788, l1: 0.019275, l2: 0.026817, l3: 0.041934, l4: 0.075470, l5: 0.143144, l6: 0.337492\n",
      "\n",
      "[epoch: 398/400, batch: 824/1000, ite: 52604] train loss: 1.1076, accuracy: 95.6977%, tar: 0.0189 \n",
      "l0: 0.019015, l1: 0.019990, l2: 0.026696, l3: 0.041234, l4: 0.079412, l5: 0.170432, l6: 0.276030\n",
      "\n",
      "[epoch: 398/400, batch: 832/1000, ite: 52605] train loss: 1.1073, accuracy: 96.2257%, tar: 0.0189 \n",
      "l0: 0.018411, l1: 0.020661, l2: 0.027798, l3: 0.042108, l4: 0.073670, l5: 0.146678, l6: 0.318921\n",
      "\n",
      "[epoch: 398/400, batch: 840/1000, ite: 52606] train loss: 1.1070, accuracy: 96.4641%, tar: 0.0189 \n",
      "l0: 0.023907, l1: 0.025811, l2: 0.037007, l3: 0.060252, l4: 0.117965, l5: 0.254548, l6: 0.485065\n",
      "\n",
      "[epoch: 398/400, batch: 848/1000, ite: 52607] train loss: 1.1077, accuracy: 93.1814%, tar: 0.0189 \n",
      "l0: 0.019929, l1: 0.021417, l2: 0.028583, l3: 0.040761, l4: 0.073736, l5: 0.154029, l6: 0.340808\n",
      "\n",
      "[epoch: 398/400, batch: 856/1000, ite: 52608] train loss: 1.1075, accuracy: 95.4920%, tar: 0.0189 \n",
      "l0: 0.018401, l1: 0.019899, l2: 0.026565, l3: 0.039507, l4: 0.074283, l5: 0.175069, l6: 0.352903\n",
      "\n",
      "[epoch: 398/400, batch: 864/1000, ite: 52609] train loss: 1.1075, accuracy: 95.1829%, tar: 0.0189 \n",
      "l0: 0.018525, l1: 0.019819, l2: 0.026939, l3: 0.041882, l4: 0.075847, l5: 0.174710, l6: 0.378834\n",
      "\n",
      "[epoch: 398/400, batch: 872/1000, ite: 52610] train loss: 1.1075, accuracy: 94.2945%, tar: 0.0189 \n",
      "l0: 0.019220, l1: 0.019892, l2: 0.026297, l3: 0.038964, l4: 0.066079, l5: 0.139013, l6: 0.318043\n",
      "\n",
      "[epoch: 398/400, batch: 880/1000, ite: 52611] train loss: 1.1072, accuracy: 95.4058%, tar: 0.0189 \n",
      "l0: 0.016443, l1: 0.017019, l2: 0.021026, l3: 0.030909, l4: 0.056860, l5: 0.119608, l6: 0.291526\n",
      "\n",
      "[epoch: 398/400, batch: 888/1000, ite: 52612] train loss: 1.1068, accuracy: 95.5931%, tar: 0.0189 \n",
      "l0: 0.022543, l1: 0.024398, l2: 0.032369, l3: 0.050451, l4: 0.094217, l5: 0.184963, l6: 0.374112\n",
      "\n",
      "[epoch: 398/400, batch: 896/1000, ite: 52613] train loss: 1.1069, accuracy: 95.0189%, tar: 0.0189 \n",
      "l0: 0.015294, l1: 0.016332, l2: 0.021732, l3: 0.035036, l4: 0.065404, l5: 0.127973, l6: 0.260307\n",
      "\n",
      "[epoch: 398/400, batch: 904/1000, ite: 52614] train loss: 1.1064, accuracy: 95.9331%, tar: 0.0189 \n",
      "l0: 0.022006, l1: 0.023163, l2: 0.032164, l3: 0.047816, l4: 0.073122, l5: 0.121351, l6: 0.301445\n",
      "\n",
      "[epoch: 398/400, batch: 912/1000, ite: 52615] train loss: 1.1061, accuracy: 95.3974%, tar: 0.0189 \n",
      "l0: 0.016712, l1: 0.018402, l2: 0.026300, l3: 0.040126, l4: 0.080719, l5: 0.178489, l6: 0.355423\n",
      "\n",
      "[epoch: 398/400, batch: 920/1000, ite: 52616] train loss: 1.1061, accuracy: 95.5039%, tar: 0.0189 \n",
      "l0: 0.016118, l1: 0.017182, l2: 0.024596, l3: 0.040033, l4: 0.082193, l5: 0.210508, l6: 0.377616\n",
      "\n",
      "[epoch: 398/400, batch: 928/1000, ite: 52617] train loss: 1.1061, accuracy: 94.7201%, tar: 0.0189 \n",
      "l0: 0.019198, l1: 0.020478, l2: 0.028794, l3: 0.044937, l4: 0.085062, l5: 0.182439, l6: 0.411012\n",
      "\n",
      "[epoch: 398/400, batch: 936/1000, ite: 52618] train loss: 1.1063, accuracy: 94.3881%, tar: 0.0189 \n",
      "l0: 0.021771, l1: 0.022526, l2: 0.030350, l3: 0.045221, l4: 0.082998, l5: 0.165976, l6: 0.329137\n",
      "\n",
      "[epoch: 398/400, batch: 944/1000, ite: 52619] train loss: 1.1062, accuracy: 94.7798%, tar: 0.0189 \n",
      "l0: 0.020893, l1: 0.022128, l2: 0.030448, l3: 0.048744, l4: 0.084621, l5: 0.150438, l6: 0.312323\n",
      "\n",
      "[epoch: 398/400, batch: 952/1000, ite: 52620] train loss: 1.1060, accuracy: 94.9514%, tar: 0.0189 \n",
      "l0: 0.019734, l1: 0.022160, l2: 0.032560, l3: 0.055425, l4: 0.096837, l5: 0.199800, l6: 0.483651\n",
      "\n",
      "[epoch: 398/400, batch: 960/1000, ite: 52621] train loss: 1.1064, accuracy: 95.1576%, tar: 0.0189 \n",
      "l0: 0.018369, l1: 0.019345, l2: 0.026059, l3: 0.038800, l4: 0.063897, l5: 0.126592, l6: 0.284378\n",
      "\n",
      "[epoch: 398/400, batch: 968/1000, ite: 52622] train loss: 1.1060, accuracy: 95.6849%, tar: 0.0189 \n",
      "l0: 0.018156, l1: 0.019622, l2: 0.027984, l3: 0.042055, l4: 0.090501, l5: 0.178085, l6: 0.380396\n",
      "\n",
      "[epoch: 398/400, batch: 976/1000, ite: 52623] train loss: 1.1061, accuracy: 95.1254%, tar: 0.0189 \n",
      "l0: 0.019545, l1: 0.021484, l2: 0.030472, l3: 0.049539, l4: 0.100904, l5: 0.185253, l6: 0.402510\n",
      "\n",
      "[epoch: 398/400, batch: 984/1000, ite: 52624] train loss: 1.1062, accuracy: 94.9557%, tar: 0.0189 \n",
      "l0: 0.022274, l1: 0.023954, l2: 0.033793, l3: 0.053470, l4: 0.106525, l5: 0.226397, l6: 0.537806\n",
      "\n",
      "[epoch: 398/400, batch: 992/1000, ite: 52625] train loss: 1.1069, accuracy: 93.0263%, tar: 0.0189 \n",
      "l0: 0.017258, l1: 0.018413, l2: 0.025428, l3: 0.038626, l4: 0.069320, l5: 0.133266, l6: 0.280638\n",
      "\n",
      "[epoch: 398/400, batch: 1000/1000, ite: 52626] train loss: 1.1066, accuracy: 96.2159%, tar: 0.0189 \n",
      "l0: 0.020095, l1: 0.021244, l2: 0.029561, l3: 0.045039, l4: 0.089827, l5: 0.199035, l6: 0.407865\n",
      "\n",
      "[epoch: 399/400, batch: 8/1000, ite: 52627] train loss: 1.1067, accuracy: 94.1833%, tar: 0.0189 \n",
      "l0: 0.011898, l1: 0.013045, l2: 0.018394, l3: 0.027024, l4: 0.047307, l5: 0.104821, l6: 0.208703\n",
      "\n",
      "[epoch: 399/400, batch: 16/1000, ite: 52628] train loss: 1.1060, accuracy: 96.8664%, tar: 0.0189 \n",
      "l0: 0.016240, l1: 0.018212, l2: 0.025940, l3: 0.038985, l4: 0.079273, l5: 0.188856, l6: 0.348169\n",
      "\n",
      "[epoch: 399/400, batch: 24/1000, ite: 52629] train loss: 1.1059, accuracy: 95.8064%, tar: 0.0189 \n",
      "l0: 0.023016, l1: 0.024217, l2: 0.032975, l3: 0.050353, l4: 0.086657, l5: 0.184999, l6: 0.388679\n",
      "\n",
      "[epoch: 399/400, batch: 32/1000, ite: 52630] train loss: 1.1061, accuracy: 94.1715%, tar: 0.0189 \n",
      "l0: 0.016598, l1: 0.018153, l2: 0.026972, l3: 0.041395, l4: 0.076318, l5: 0.188689, l6: 0.369930\n",
      "\n",
      "[epoch: 399/400, batch: 40/1000, ite: 52631] train loss: 1.1061, accuracy: 95.5673%, tar: 0.0189 \n",
      "l0: 0.017378, l1: 0.020330, l2: 0.031760, l3: 0.049746, l4: 0.090887, l5: 0.173924, l6: 0.367389\n",
      "\n",
      "[epoch: 399/400, batch: 48/1000, ite: 52632] train loss: 1.1061, accuracy: 95.7911%, tar: 0.0189 \n",
      "l0: 0.016800, l1: 0.017956, l2: 0.024588, l3: 0.041421, l4: 0.078039, l5: 0.163267, l6: 0.310894\n",
      "\n",
      "[epoch: 399/400, batch: 56/1000, ite: 52633] train loss: 1.1059, accuracy: 95.7549%, tar: 0.0189 \n",
      "l0: 0.016805, l1: 0.017811, l2: 0.025207, l3: 0.041202, l4: 0.078248, l5: 0.172216, l6: 0.368409\n",
      "\n",
      "[epoch: 399/400, batch: 64/1000, ite: 52634] train loss: 1.1059, accuracy: 95.3122%, tar: 0.0189 \n",
      "l0: 0.019439, l1: 0.020490, l2: 0.027123, l3: 0.043097, l4: 0.087757, l5: 0.175598, l6: 0.328236\n",
      "\n",
      "[epoch: 399/400, batch: 72/1000, ite: 52635] train loss: 1.1057, accuracy: 94.9856%, tar: 0.0189 \n",
      "l0: 0.016313, l1: 0.016846, l2: 0.024086, l3: 0.034774, l4: 0.062551, l5: 0.118613, l6: 0.245940\n",
      "\n",
      "[epoch: 399/400, batch: 80/1000, ite: 52636] train loss: 1.1052, accuracy: 95.9201%, tar: 0.0189 \n",
      "l0: 0.017476, l1: 0.019480, l2: 0.027546, l3: 0.042979, l4: 0.094674, l5: 0.193196, l6: 0.375388\n",
      "\n",
      "[epoch: 399/400, batch: 88/1000, ite: 52637] train loss: 1.1053, accuracy: 95.4593%, tar: 0.0189 \n",
      "l0: 0.021645, l1: 0.023368, l2: 0.030694, l3: 0.048604, l4: 0.091657, l5: 0.192809, l6: 0.446388\n",
      "\n",
      "[epoch: 399/400, batch: 96/1000, ite: 52638] train loss: 1.1056, accuracy: 93.6116%, tar: 0.0189 \n",
      "l0: 0.021943, l1: 0.023261, l2: 0.034422, l3: 0.053425, l4: 0.098109, l5: 0.190255, l6: 0.441285\n",
      "\n",
      "[epoch: 399/400, batch: 104/1000, ite: 52639] train loss: 1.1059, accuracy: 94.1248%, tar: 0.0189 \n",
      "l0: 0.019794, l1: 0.022534, l2: 0.030087, l3: 0.043533, l4: 0.075955, l5: 0.136069, l6: 0.266596\n",
      "\n",
      "[epoch: 399/400, batch: 112/1000, ite: 52640] train loss: 1.1055, accuracy: 96.7940%, tar: 0.0189 \n",
      "l0: 0.019863, l1: 0.020729, l2: 0.028077, l3: 0.043899, l4: 0.080692, l5: 0.178028, l6: 0.467532\n",
      "\n",
      "[epoch: 399/400, batch: 120/1000, ite: 52641] train loss: 1.1058, accuracy: 94.2627%, tar: 0.0189 \n",
      "l0: 0.025331, l1: 0.026523, l2: 0.036202, l3: 0.050902, l4: 0.090029, l5: 0.255020, l6: 0.522567\n",
      "\n",
      "[epoch: 399/400, batch: 128/1000, ite: 52642] train loss: 1.1065, accuracy: 92.9309%, tar: 0.0189 \n",
      "l0: 0.022516, l1: 0.024040, l2: 0.032614, l3: 0.048303, l4: 0.097717, l5: 0.211026, l6: 0.464526\n",
      "\n",
      "[epoch: 399/400, batch: 136/1000, ite: 52643] train loss: 1.1069, accuracy: 93.8748%, tar: 0.0189 \n",
      "l0: 0.015152, l1: 0.016914, l2: 0.024857, l3: 0.040840, l4: 0.074724, l5: 0.145796, l6: 0.298627\n",
      "\n",
      "[epoch: 399/400, batch: 144/1000, ite: 52644] train loss: 1.1066, accuracy: 96.0944%, tar: 0.0189 \n",
      "l0: 0.013839, l1: 0.015055, l2: 0.020257, l3: 0.030336, l4: 0.053711, l5: 0.114761, l6: 0.254488\n",
      "\n",
      "[epoch: 399/400, batch: 152/1000, ite: 52645] train loss: 1.1060, accuracy: 96.4325%, tar: 0.0189 \n",
      "l0: 0.015907, l1: 0.017448, l2: 0.026859, l3: 0.044702, l4: 0.083198, l5: 0.161219, l6: 0.399547\n",
      "\n",
      "[epoch: 399/400, batch: 160/1000, ite: 52646] train loss: 1.1061, accuracy: 95.1048%, tar: 0.0189 \n",
      "l0: 0.021561, l1: 0.023512, l2: 0.031841, l3: 0.051716, l4: 0.094440, l5: 0.201032, l6: 0.458169\n",
      "\n",
      "[epoch: 399/400, batch: 168/1000, ite: 52647] train loss: 1.1065, accuracy: 94.5437%, tar: 0.0189 \n",
      "l0: 0.014697, l1: 0.015800, l2: 0.022407, l3: 0.035270, l4: 0.059673, l5: 0.104294, l6: 0.211977\n",
      "\n",
      "[epoch: 399/400, batch: 176/1000, ite: 52648] train loss: 1.1058, accuracy: 96.2842%, tar: 0.0189 \n",
      "l0: 0.015387, l1: 0.016664, l2: 0.024707, l3: 0.041342, l4: 0.078519, l5: 0.182956, l6: 0.367964\n",
      "\n",
      "[epoch: 399/400, batch: 184/1000, ite: 52649] train loss: 1.1058, accuracy: 95.8253%, tar: 0.0189 \n",
      "l0: 0.017148, l1: 0.018125, l2: 0.026402, l3: 0.041681, l4: 0.076675, l5: 0.175393, l6: 0.395289\n",
      "\n",
      "[epoch: 399/400, batch: 192/1000, ite: 52650] train loss: 1.1059, accuracy: 95.0573%, tar: 0.0189 \n",
      "l0: 0.017191, l1: 0.018493, l2: 0.023999, l3: 0.038599, l4: 0.072360, l5: 0.144811, l6: 0.291371\n",
      "\n",
      "[epoch: 399/400, batch: 200/1000, ite: 52651] train loss: 1.1055, accuracy: 95.4080%, tar: 0.0189 \n",
      "l0: 0.013731, l1: 0.014853, l2: 0.021042, l3: 0.031828, l4: 0.060780, l5: 0.129504, l6: 0.297372\n",
      "\n",
      "[epoch: 399/400, batch: 208/1000, ite: 52652] train loss: 1.1052, accuracy: 96.1862%, tar: 0.0189 \n",
      "l0: 0.020794, l1: 0.022408, l2: 0.031748, l3: 0.053778, l4: 0.102571, l5: 0.255558, l6: 0.535893\n",
      "\n",
      "[epoch: 399/400, batch: 216/1000, ite: 52653] train loss: 1.1059, accuracy: 93.2197%, tar: 0.0189 \n",
      "l0: 0.028172, l1: 0.030309, l2: 0.040923, l3: 0.063424, l4: 0.118371, l5: 0.252002, l6: 0.581303\n",
      "\n",
      "[epoch: 399/400, batch: 224/1000, ite: 52654] train loss: 1.1068, accuracy: 92.1689%, tar: 0.0189 \n",
      "l0: 0.016422, l1: 0.017318, l2: 0.026189, l3: 0.040544, l4: 0.071402, l5: 0.131955, l6: 0.331611\n",
      "\n",
      "[epoch: 399/400, batch: 232/1000, ite: 52655] train loss: 1.1066, accuracy: 95.7747%, tar: 0.0189 \n",
      "l0: 0.014925, l1: 0.015924, l2: 0.022413, l3: 0.036839, l4: 0.063992, l5: 0.140134, l6: 0.306703\n",
      "\n",
      "[epoch: 399/400, batch: 240/1000, ite: 52656] train loss: 1.1063, accuracy: 96.2381%, tar: 0.0189 \n",
      "l0: 0.017499, l1: 0.018895, l2: 0.027589, l3: 0.043794, l4: 0.076401, l5: 0.146701, l6: 0.368457\n",
      "\n",
      "[epoch: 399/400, batch: 248/1000, ite: 52657] train loss: 1.1062, accuracy: 94.5292%, tar: 0.0189 \n",
      "l0: 0.015626, l1: 0.017117, l2: 0.025263, l3: 0.041349, l4: 0.093248, l5: 0.179717, l6: 0.326576\n",
      "\n",
      "[epoch: 399/400, batch: 256/1000, ite: 52658] train loss: 1.1061, accuracy: 96.0871%, tar: 0.0189 \n",
      "l0: 0.019574, l1: 0.021586, l2: 0.032623, l3: 0.049566, l4: 0.086051, l5: 0.193392, l6: 0.365133\n",
      "\n",
      "[epoch: 399/400, batch: 264/1000, ite: 52659] train loss: 1.1061, accuracy: 95.7056%, tar: 0.0189 \n",
      "l0: 0.017104, l1: 0.018091, l2: 0.023615, l3: 0.032115, l4: 0.055505, l5: 0.096177, l6: 0.244171\n",
      "\n",
      "[epoch: 399/400, batch: 272/1000, ite: 52660] train loss: 1.1056, accuracy: 95.9264%, tar: 0.0189 \n",
      "l0: 0.020733, l1: 0.022591, l2: 0.033177, l3: 0.054263, l4: 0.115320, l5: 0.242150, l6: 0.480819\n",
      "\n",
      "[epoch: 399/400, batch: 280/1000, ite: 52661] train loss: 1.1061, accuracy: 94.2517%, tar: 0.0189 \n",
      "l0: 0.020489, l1: 0.022733, l2: 0.035671, l3: 0.061526, l4: 0.106395, l5: 0.192483, l6: 0.336171\n",
      "\n",
      "[epoch: 399/400, batch: 288/1000, ite: 52662] train loss: 1.1061, accuracy: 95.3357%, tar: 0.0189 \n",
      "l0: 0.019098, l1: 0.021600, l2: 0.030974, l3: 0.048832, l4: 0.094099, l5: 0.171010, l6: 0.354096\n",
      "\n",
      "[epoch: 399/400, batch: 296/1000, ite: 52663] train loss: 1.1061, accuracy: 95.6415%, tar: 0.0189 \n",
      "l0: 0.014734, l1: 0.016136, l2: 0.022903, l3: 0.044971, l4: 0.082431, l5: 0.152985, l6: 0.328998\n",
      "\n",
      "[epoch: 399/400, batch: 304/1000, ite: 52664] train loss: 1.1060, accuracy: 96.2405%, tar: 0.0189 \n",
      "l0: 0.014540, l1: 0.016087, l2: 0.024011, l3: 0.037419, l4: 0.068287, l5: 0.144236, l6: 0.319341\n",
      "\n",
      "[epoch: 399/400, batch: 312/1000, ite: 52665] train loss: 1.1057, accuracy: 95.9821%, tar: 0.0189 \n",
      "l0: 0.022100, l1: 0.023967, l2: 0.033763, l3: 0.050257, l4: 0.104845, l5: 0.221269, l6: 0.405636\n",
      "\n",
      "[epoch: 399/400, batch: 320/1000, ite: 52666] train loss: 1.1060, accuracy: 94.4077%, tar: 0.0189 \n",
      "l0: 0.016539, l1: 0.017481, l2: 0.024774, l3: 0.037418, l4: 0.066416, l5: 0.124290, l6: 0.295178\n",
      "\n",
      "[epoch: 399/400, batch: 328/1000, ite: 52667] train loss: 1.1056, accuracy: 95.7548%, tar: 0.0189 \n",
      "l0: 0.015985, l1: 0.016950, l2: 0.024140, l3: 0.036445, l4: 0.058703, l5: 0.097435, l6: 0.242678\n",
      "\n",
      "[epoch: 399/400, batch: 336/1000, ite: 52668] train loss: 1.1051, accuracy: 96.2010%, tar: 0.0189 \n",
      "l0: 0.012755, l1: 0.013999, l2: 0.021482, l3: 0.035968, l4: 0.068049, l5: 0.156402, l6: 0.414625\n",
      "\n",
      "[epoch: 399/400, batch: 344/1000, ite: 52669] train loss: 1.1051, accuracy: 95.6264%, tar: 0.0189 \n",
      "l0: 0.017118, l1: 0.018459, l2: 0.025074, l3: 0.041199, l4: 0.078060, l5: 0.161231, l6: 0.293797\n",
      "\n",
      "[epoch: 399/400, batch: 352/1000, ite: 52670] train loss: 1.1049, accuracy: 95.6949%, tar: 0.0189 \n",
      "l0: 0.016966, l1: 0.018113, l2: 0.025532, l3: 0.038235, l4: 0.066373, l5: 0.132636, l6: 0.313423\n",
      "\n",
      "[epoch: 399/400, batch: 360/1000, ite: 52671] train loss: 1.1046, accuracy: 95.6332%, tar: 0.0188 \n",
      "l0: 0.021376, l1: 0.024048, l2: 0.036131, l3: 0.062379, l4: 0.119280, l5: 0.241802, l6: 0.442404\n",
      "\n",
      "[epoch: 399/400, batch: 368/1000, ite: 52672] train loss: 1.1051, accuracy: 95.0090%, tar: 0.0189 \n",
      "l0: 0.021374, l1: 0.023088, l2: 0.029868, l3: 0.046296, l4: 0.085295, l5: 0.200245, l6: 0.435394\n",
      "\n",
      "[epoch: 399/400, batch: 376/1000, ite: 52673] train loss: 1.1053, accuracy: 94.6401%, tar: 0.0189 \n",
      "l0: 0.023766, l1: 0.024729, l2: 0.033480, l3: 0.052284, l4: 0.101991, l5: 0.194172, l6: 0.351946\n",
      "\n",
      "[epoch: 399/400, batch: 384/1000, ite: 52674] train loss: 1.1054, accuracy: 94.5273%, tar: 0.0189 \n",
      "l0: 0.016476, l1: 0.018234, l2: 0.026587, l3: 0.046537, l4: 0.123416, l5: 0.234809, l6: 0.424632\n",
      "\n",
      "[epoch: 399/400, batch: 392/1000, ite: 52675] train loss: 1.1057, accuracy: 95.5458%, tar: 0.0189 \n",
      "l0: 0.017048, l1: 0.017989, l2: 0.024452, l3: 0.041151, l4: 0.079686, l5: 0.158671, l6: 0.337899\n",
      "\n",
      "[epoch: 399/400, batch: 400/1000, ite: 52676] train loss: 1.1055, accuracy: 95.6828%, tar: 0.0189 \n",
      "l0: 0.021321, l1: 0.022728, l2: 0.030789, l3: 0.048061, l4: 0.083521, l5: 0.185829, l6: 0.397864\n",
      "\n",
      "[epoch: 399/400, batch: 408/1000, ite: 52677] train loss: 1.1057, accuracy: 94.1303%, tar: 0.0189 \n",
      "l0: 0.018317, l1: 0.019848, l2: 0.029728, l3: 0.047989, l4: 0.087216, l5: 0.167554, l6: 0.410042\n",
      "\n",
      "[epoch: 399/400, batch: 416/1000, ite: 52678] train loss: 1.1058, accuracy: 95.1042%, tar: 0.0189 \n",
      "l0: 0.022031, l1: 0.023661, l2: 0.031396, l3: 0.052061, l4: 0.098620, l5: 0.203056, l6: 0.441796\n",
      "\n",
      "[epoch: 399/400, batch: 424/1000, ite: 52679] train loss: 1.1061, accuracy: 94.0380%, tar: 0.0189 \n",
      "l0: 0.020620, l1: 0.021823, l2: 0.029538, l3: 0.042287, l4: 0.081739, l5: 0.187018, l6: 0.388719\n",
      "\n",
      "[epoch: 399/400, batch: 432/1000, ite: 52680] train loss: 1.1062, accuracy: 93.9887%, tar: 0.0189 \n",
      "l0: 0.024680, l1: 0.026655, l2: 0.034596, l3: 0.058192, l4: 0.135458, l5: 0.308676, l6: 0.539470\n",
      "\n",
      "[epoch: 399/400, batch: 440/1000, ite: 52681] train loss: 1.1070, accuracy: 92.9985%, tar: 0.0189 \n",
      "l0: 0.019490, l1: 0.020260, l2: 0.028113, l3: 0.041759, l4: 0.070001, l5: 0.121252, l6: 0.262979\n",
      "\n",
      "[epoch: 399/400, batch: 448/1000, ite: 52682] train loss: 1.1066, accuracy: 95.2152%, tar: 0.0189 \n",
      "l0: 0.020757, l1: 0.022423, l2: 0.032813, l3: 0.056858, l4: 0.112336, l5: 0.224260, l6: 0.395645\n",
      "\n",
      "[epoch: 399/400, batch: 456/1000, ite: 52683] train loss: 1.1069, accuracy: 94.1340%, tar: 0.0189 \n",
      "l0: 0.020622, l1: 0.021798, l2: 0.030136, l3: 0.046837, l4: 0.089641, l5: 0.178517, l6: 0.338296\n",
      "\n",
      "[epoch: 399/400, batch: 464/1000, ite: 52684] train loss: 1.1068, accuracy: 95.4666%, tar: 0.0189 \n",
      "l0: 0.019684, l1: 0.020776, l2: 0.027130, l3: 0.042236, l4: 0.077517, l5: 0.155961, l6: 0.382148\n",
      "\n",
      "[epoch: 399/400, batch: 472/1000, ite: 52685] train loss: 1.1068, accuracy: 94.3483%, tar: 0.0189 \n",
      "l0: 0.015675, l1: 0.016811, l2: 0.022813, l3: 0.035351, l4: 0.065876, l5: 0.158630, l6: 0.323200\n",
      "\n",
      "[epoch: 399/400, batch: 480/1000, ite: 52686] train loss: 1.1066, accuracy: 95.6927%, tar: 0.0189 \n",
      "l0: 0.023295, l1: 0.026093, l2: 0.038691, l3: 0.065986, l4: 0.133544, l5: 0.253760, l6: 0.445475\n",
      "\n",
      "[epoch: 399/400, batch: 488/1000, ite: 52687] train loss: 1.1071, accuracy: 94.6490%, tar: 0.0189 \n",
      "l0: 0.020446, l1: 0.021411, l2: 0.025652, l3: 0.036417, l4: 0.068266, l5: 0.138861, l6: 0.328057\n",
      "\n",
      "[epoch: 399/400, batch: 496/1000, ite: 52688] train loss: 1.1069, accuracy: 95.2837%, tar: 0.0189 \n",
      "l0: 0.018863, l1: 0.020056, l2: 0.026138, l3: 0.036065, l4: 0.062875, l5: 0.124100, l6: 0.296829\n",
      "\n",
      "[epoch: 399/400, batch: 504/1000, ite: 52689] train loss: 1.1066, accuracy: 96.2730%, tar: 0.0189 \n",
      "l0: 0.017842, l1: 0.018925, l2: 0.026708, l3: 0.044615, l4: 0.094828, l5: 0.239496, l6: 0.575530\n",
      "\n",
      "[epoch: 399/400, batch: 512/1000, ite: 52690] train loss: 1.1073, accuracy: 92.8726%, tar: 0.0189 \n",
      "l0: 0.023890, l1: 0.026338, l2: 0.036529, l3: 0.057180, l4: 0.118192, l5: 0.236952, l6: 0.452672\n",
      "\n",
      "[epoch: 399/400, batch: 520/1000, ite: 52691] train loss: 1.1077, accuracy: 93.5343%, tar: 0.0189 \n",
      "l0: 0.021759, l1: 0.023961, l2: 0.034019, l3: 0.055062, l4: 0.118830, l5: 0.268760, l6: 0.481060\n",
      "\n",
      "[epoch: 399/400, batch: 528/1000, ite: 52692] train loss: 1.1082, accuracy: 94.8263%, tar: 0.0189 \n",
      "l0: 0.016885, l1: 0.017684, l2: 0.024238, l3: 0.035950, l4: 0.065536, l5: 0.136569, l6: 0.319503\n",
      "\n",
      "[epoch: 399/400, batch: 536/1000, ite: 52693] train loss: 1.1080, accuracy: 95.1745%, tar: 0.0189 \n",
      "l0: 0.021286, l1: 0.023193, l2: 0.034009, l3: 0.052428, l4: 0.098902, l5: 0.209846, l6: 0.383576\n",
      "\n",
      "[epoch: 399/400, batch: 544/1000, ite: 52694] train loss: 1.1082, accuracy: 95.3028%, tar: 0.0189 \n",
      "l0: 0.019098, l1: 0.020928, l2: 0.033431, l3: 0.056648, l4: 0.128424, l5: 0.248323, l6: 0.433347\n",
      "\n",
      "[epoch: 399/400, batch: 552/1000, ite: 52695] train loss: 1.1085, accuracy: 94.6578%, tar: 0.0189 \n",
      "l0: 0.017190, l1: 0.018468, l2: 0.026414, l3: 0.038658, l4: 0.077384, l5: 0.167489, l6: 0.324750\n",
      "\n",
      "[epoch: 399/400, batch: 560/1000, ite: 52696] train loss: 1.1084, accuracy: 95.5290%, tar: 0.0189 \n",
      "l0: 0.021992, l1: 0.023056, l2: 0.031688, l3: 0.052059, l4: 0.100110, l5: 0.201055, l6: 0.348169\n",
      "\n",
      "[epoch: 399/400, batch: 568/1000, ite: 52697] train loss: 1.1084, accuracy: 94.5241%, tar: 0.0189 \n",
      "l0: 0.016307, l1: 0.017289, l2: 0.026565, l3: 0.044286, l4: 0.087141, l5: 0.181022, l6: 0.350305\n",
      "\n",
      "[epoch: 399/400, batch: 576/1000, ite: 52698] train loss: 1.1084, accuracy: 95.3886%, tar: 0.0189 \n",
      "l0: 0.016674, l1: 0.018184, l2: 0.027030, l3: 0.040394, l4: 0.069872, l5: 0.130383, l6: 0.240290\n",
      "\n",
      "[epoch: 399/400, batch: 584/1000, ite: 52699] train loss: 1.1079, accuracy: 96.7848%, tar: 0.0189 \n",
      "l0: 0.017257, l1: 0.018295, l2: 0.025661, l3: 0.040050, l4: 0.071865, l5: 0.158521, l6: 0.378703\n",
      "\n",
      "[epoch: 399/400, batch: 592/1000, ite: 52700] train loss: 1.1079, accuracy: 94.9591%, tar: 0.0189 \n",
      "l0: 0.020460, l1: 0.021626, l2: 0.030219, l3: 0.049493, l4: 0.109690, l5: 0.205981, l6: 0.387328\n",
      "\n",
      "[epoch: 399/400, batch: 600/1000, ite: 52701] train loss: 1.1080, accuracy: 94.4472%, tar: 0.0189 \n",
      "l0: 0.020329, l1: 0.021781, l2: 0.030426, l3: 0.050729, l4: 0.108061, l5: 0.226194, l6: 0.458022\n",
      "\n",
      "[epoch: 399/400, batch: 608/1000, ite: 52702] train loss: 1.1084, accuracy: 93.9160%, tar: 0.0189 \n",
      "l0: 0.022999, l1: 0.024252, l2: 0.032993, l3: 0.048606, l4: 0.084966, l5: 0.202674, l6: 0.497470\n",
      "\n",
      "[epoch: 399/400, batch: 616/1000, ite: 52703] train loss: 1.1088, accuracy: 93.4714%, tar: 0.0189 \n",
      "l0: 0.019343, l1: 0.020949, l2: 0.028453, l3: 0.042382, l4: 0.080340, l5: 0.167170, l6: 0.335974\n",
      "\n",
      "[epoch: 399/400, batch: 624/1000, ite: 52704] train loss: 1.1087, accuracy: 94.8588%, tar: 0.0189 \n",
      "l0: 0.019255, l1: 0.021141, l2: 0.029627, l3: 0.046228, l4: 0.095708, l5: 0.192398, l6: 0.413451\n",
      "\n",
      "[epoch: 399/400, batch: 632/1000, ite: 52705] train loss: 1.1089, accuracy: 95.3593%, tar: 0.0189 \n",
      "l0: 0.018708, l1: 0.020581, l2: 0.029156, l3: 0.045852, l4: 0.086379, l5: 0.169829, l6: 0.372719\n",
      "\n",
      "[epoch: 399/400, batch: 640/1000, ite: 52706] train loss: 1.1089, accuracy: 94.8081%, tar: 0.0189 \n",
      "l0: 0.021108, l1: 0.022828, l2: 0.031233, l3: 0.049158, l4: 0.095084, l5: 0.209198, l6: 0.430773\n",
      "\n",
      "[epoch: 399/400, batch: 648/1000, ite: 52707] train loss: 1.1092, accuracy: 94.2823%, tar: 0.0189 \n",
      "l0: 0.016442, l1: 0.017595, l2: 0.024688, l3: 0.036701, l4: 0.070951, l5: 0.134120, l6: 0.294679\n",
      "\n",
      "[epoch: 399/400, batch: 656/1000, ite: 52708] train loss: 1.1089, accuracy: 95.2995%, tar: 0.0189 \n",
      "l0: 0.018131, l1: 0.019387, l2: 0.028534, l3: 0.045739, l4: 0.087329, l5: 0.171897, l6: 0.357427\n",
      "\n",
      "[epoch: 399/400, batch: 664/1000, ite: 52709] train loss: 1.1088, accuracy: 95.4512%, tar: 0.0189 \n",
      "l0: 0.018262, l1: 0.019886, l2: 0.029615, l3: 0.049758, l4: 0.095243, l5: 0.181894, l6: 0.370146\n",
      "\n",
      "[epoch: 399/400, batch: 672/1000, ite: 52710] train loss: 1.1089, accuracy: 95.3016%, tar: 0.0189 \n",
      "l0: 0.015980, l1: 0.017533, l2: 0.027488, l3: 0.045176, l4: 0.086836, l5: 0.174434, l6: 0.364547\n",
      "\n",
      "[epoch: 399/400, batch: 680/1000, ite: 52711] train loss: 1.1089, accuracy: 95.5035%, tar: 0.0189 \n",
      "l0: 0.015749, l1: 0.016879, l2: 0.023117, l3: 0.035233, l4: 0.061094, l5: 0.130990, l6: 0.318367\n",
      "\n",
      "[epoch: 399/400, batch: 688/1000, ite: 52712] train loss: 1.1086, accuracy: 95.5149%, tar: 0.0189 \n",
      "l0: 0.016691, l1: 0.018471, l2: 0.027643, l3: 0.049283, l4: 0.107011, l5: 0.198145, l6: 0.417735\n",
      "\n",
      "[epoch: 399/400, batch: 696/1000, ite: 52713] train loss: 1.1088, accuracy: 95.1458%, tar: 0.0189 \n",
      "l0: 0.020845, l1: 0.022314, l2: 0.029762, l3: 0.045194, l4: 0.090862, l5: 0.200148, l6: 0.450117\n",
      "\n",
      "[epoch: 399/400, batch: 704/1000, ite: 52714] train loss: 1.1091, accuracy: 94.4635%, tar: 0.0189 \n",
      "l0: 0.018553, l1: 0.019924, l2: 0.028012, l3: 0.042007, l4: 0.074830, l5: 0.136801, l6: 0.271518\n",
      "\n",
      "[epoch: 399/400, batch: 712/1000, ite: 52715] train loss: 1.1087, accuracy: 95.8412%, tar: 0.0189 \n",
      "l0: 0.018099, l1: 0.019304, l2: 0.026483, l3: 0.039947, l4: 0.074909, l5: 0.168343, l6: 0.356807\n",
      "\n",
      "[epoch: 399/400, batch: 720/1000, ite: 52716] train loss: 1.1087, accuracy: 95.1558%, tar: 0.0189 \n",
      "l0: 0.022194, l1: 0.023613, l2: 0.030462, l3: 0.041909, l4: 0.067736, l5: 0.120601, l6: 0.276675\n",
      "\n",
      "[epoch: 399/400, batch: 728/1000, ite: 52717] train loss: 1.1083, accuracy: 95.7361%, tar: 0.0189 \n",
      "l0: 0.018274, l1: 0.019512, l2: 0.025586, l3: 0.040505, l4: 0.082014, l5: 0.203659, l6: 0.405162\n",
      "\n",
      "[epoch: 399/400, batch: 736/1000, ite: 52718] train loss: 1.1084, accuracy: 94.3758%, tar: 0.0189 \n",
      "l0: 0.016738, l1: 0.018347, l2: 0.025108, l3: 0.038065, l4: 0.063477, l5: 0.149934, l6: 0.360645\n",
      "\n",
      "[epoch: 399/400, batch: 744/1000, ite: 52719] train loss: 1.1083, accuracy: 95.3779%, tar: 0.0189 \n",
      "l0: 0.019279, l1: 0.020541, l2: 0.026980, l3: 0.040553, l4: 0.071288, l5: 0.154205, l6: 0.340866\n",
      "\n",
      "[epoch: 399/400, batch: 752/1000, ite: 52720] train loss: 1.1082, accuracy: 95.0752%, tar: 0.0189 \n",
      "l0: 0.014314, l1: 0.015521, l2: 0.021039, l3: 0.031655, l4: 0.054658, l5: 0.122565, l6: 0.290550\n",
      "\n",
      "[epoch: 399/400, batch: 760/1000, ite: 52721] train loss: 1.1078, accuracy: 96.2129%, tar: 0.0189 \n",
      "l0: 0.014866, l1: 0.015709, l2: 0.020287, l3: 0.030476, l4: 0.058580, l5: 0.131334, l6: 0.281777\n",
      "\n",
      "[epoch: 399/400, batch: 768/1000, ite: 52722] train loss: 1.1075, accuracy: 95.9989%, tar: 0.0189 \n",
      "l0: 0.017138, l1: 0.019166, l2: 0.028808, l3: 0.047236, l4: 0.090327, l5: 0.195884, l6: 0.346360\n",
      "\n",
      "[epoch: 399/400, batch: 776/1000, ite: 52723] train loss: 1.1074, accuracy: 95.6799%, tar: 0.0189 \n",
      "l0: 0.020873, l1: 0.022414, l2: 0.032398, l3: 0.061657, l4: 0.134694, l5: 0.256126, l6: 0.439463\n",
      "\n",
      "[epoch: 399/400, batch: 784/1000, ite: 52724] train loss: 1.1079, accuracy: 93.8092%, tar: 0.0189 \n",
      "l0: 0.014401, l1: 0.015918, l2: 0.022608, l3: 0.040360, l4: 0.082131, l5: 0.171745, l6: 0.338776\n",
      "\n",
      "[epoch: 399/400, batch: 792/1000, ite: 52725] train loss: 1.1077, accuracy: 95.9897%, tar: 0.0189 \n",
      "l0: 0.016335, l1: 0.017811, l2: 0.025741, l3: 0.040766, l4: 0.078010, l5: 0.177735, l6: 0.383243\n",
      "\n",
      "[epoch: 399/400, batch: 800/1000, ite: 52726] train loss: 1.1078, accuracy: 95.2017%, tar: 0.0189 \n",
      "l0: 0.017475, l1: 0.018925, l2: 0.028375, l3: 0.051307, l4: 0.111850, l5: 0.234839, l6: 0.424389\n",
      "\n",
      "[epoch: 399/400, batch: 808/1000, ite: 52727] train loss: 1.1081, accuracy: 94.4905%, tar: 0.0189 \n",
      "l0: 0.020976, l1: 0.023031, l2: 0.032015, l3: 0.049530, l4: 0.105449, l5: 0.242267, l6: 0.476291\n",
      "\n",
      "[epoch: 399/400, batch: 816/1000, ite: 52728] train loss: 1.1085, accuracy: 93.5330%, tar: 0.0189 \n",
      "l0: 0.015563, l1: 0.016451, l2: 0.023121, l3: 0.036281, l4: 0.065939, l5: 0.152586, l6: 0.357846\n",
      "\n",
      "[epoch: 399/400, batch: 824/1000, ite: 52729] train loss: 1.1084, accuracy: 95.1737%, tar: 0.0189 \n",
      "l0: 0.017058, l1: 0.018212, l2: 0.025300, l3: 0.038402, l4: 0.068947, l5: 0.148150, l6: 0.337448\n",
      "\n",
      "[epoch: 399/400, batch: 832/1000, ite: 52730] train loss: 1.1082, accuracy: 95.6038%, tar: 0.0189 \n",
      "l0: 0.017937, l1: 0.018909, l2: 0.025218, l3: 0.038809, l4: 0.072473, l5: 0.165372, l6: 0.356211\n",
      "\n",
      "[epoch: 399/400, batch: 840/1000, ite: 52731] train loss: 1.1082, accuracy: 94.7462%, tar: 0.0189 \n",
      "l0: 0.013849, l1: 0.014778, l2: 0.019271, l3: 0.026973, l4: 0.045772, l5: 0.088747, l6: 0.198691\n",
      "\n",
      "[epoch: 399/400, batch: 848/1000, ite: 52732] train loss: 1.1075, accuracy: 96.8897%, tar: 0.0189 \n",
      "l0: 0.014111, l1: 0.015560, l2: 0.023247, l3: 0.044510, l4: 0.080933, l5: 0.158411, l6: 0.329215\n",
      "\n",
      "[epoch: 399/400, batch: 856/1000, ite: 52733] train loss: 1.1073, accuracy: 95.6956%, tar: 0.0188 \n",
      "l0: 0.017287, l1: 0.018540, l2: 0.024382, l3: 0.036345, l4: 0.066269, l5: 0.138271, l6: 0.278937\n",
      "\n",
      "[epoch: 399/400, batch: 864/1000, ite: 52734] train loss: 1.1070, accuracy: 95.7067%, tar: 0.0188 \n",
      "l0: 0.017783, l1: 0.019442, l2: 0.025553, l3: 0.038530, l4: 0.073362, l5: 0.151291, l6: 0.298077\n",
      "\n",
      "[epoch: 399/400, batch: 872/1000, ite: 52735] train loss: 1.1068, accuracy: 95.8584%, tar: 0.0188 \n",
      "l0: 0.018504, l1: 0.019434, l2: 0.024182, l3: 0.034979, l4: 0.063158, l5: 0.127997, l6: 0.267237\n",
      "\n",
      "[epoch: 399/400, batch: 880/1000, ite: 52736] train loss: 1.1064, accuracy: 95.6630%, tar: 0.0188 \n",
      "l0: 0.015700, l1: 0.016759, l2: 0.024479, l3: 0.040457, l4: 0.075651, l5: 0.143881, l6: 0.333706\n",
      "\n",
      "[epoch: 399/400, batch: 888/1000, ite: 52737] train loss: 1.1062, accuracy: 95.5477%, tar: 0.0188 \n",
      "l0: 0.023530, l1: 0.024416, l2: 0.032755, l3: 0.049469, l4: 0.085386, l5: 0.199246, l6: 0.434541\n",
      "\n",
      "[epoch: 399/400, batch: 896/1000, ite: 52738] train loss: 1.1065, accuracy: 93.3399%, tar: 0.0188 \n",
      "l0: 0.018147, l1: 0.020066, l2: 0.028432, l3: 0.044307, l4: 0.080581, l5: 0.190670, l6: 0.439965\n",
      "\n",
      "[epoch: 399/400, batch: 904/1000, ite: 52739] train loss: 1.1067, accuracy: 94.6292%, tar: 0.0188 \n",
      "l0: 0.018015, l1: 0.018836, l2: 0.026189, l3: 0.040251, l4: 0.071825, l5: 0.138118, l6: 0.282963\n",
      "\n",
      "[epoch: 399/400, batch: 912/1000, ite: 52740] train loss: 1.1064, accuracy: 95.5660%, tar: 0.0188 \n",
      "l0: 0.022900, l1: 0.026429, l2: 0.038515, l3: 0.066465, l4: 0.121606, l5: 0.214362, l6: 0.419559\n",
      "\n",
      "[epoch: 399/400, batch: 920/1000, ite: 52741] train loss: 1.1067, accuracy: 95.4091%, tar: 0.0189 \n",
      "l0: 0.016538, l1: 0.017589, l2: 0.025234, l3: 0.037931, l4: 0.072416, l5: 0.153278, l6: 0.326218\n",
      "\n",
      "[epoch: 399/400, batch: 928/1000, ite: 52742] train loss: 1.1065, accuracy: 95.6148%, tar: 0.0188 \n",
      "l0: 0.014005, l1: 0.014533, l2: 0.020432, l3: 0.029456, l4: 0.049910, l5: 0.097659, l6: 0.199143\n",
      "\n",
      "[epoch: 399/400, batch: 936/1000, ite: 52743] train loss: 1.1058, accuracy: 96.8560%, tar: 0.0188 \n",
      "l0: 0.019982, l1: 0.020952, l2: 0.028016, l3: 0.040963, l4: 0.073296, l5: 0.165340, l6: 0.376478\n",
      "\n",
      "[epoch: 399/400, batch: 944/1000, ite: 52744] train loss: 1.1058, accuracy: 94.6452%, tar: 0.0188 \n",
      "l0: 0.018518, l1: 0.019994, l2: 0.029065, l3: 0.039147, l4: 0.069853, l5: 0.128900, l6: 0.269533\n",
      "\n",
      "[epoch: 399/400, batch: 952/1000, ite: 52745] train loss: 1.1055, accuracy: 96.7057%, tar: 0.0188 \n",
      "l0: 0.018242, l1: 0.019767, l2: 0.029478, l3: 0.048055, l4: 0.095535, l5: 0.251462, l6: 0.507143\n",
      "\n",
      "[epoch: 399/400, batch: 960/1000, ite: 52746] train loss: 1.1060, accuracy: 93.6823%, tar: 0.0188 \n",
      "l0: 0.013480, l1: 0.015015, l2: 0.020747, l3: 0.032632, l4: 0.063221, l5: 0.148880, l6: 0.327892\n",
      "\n",
      "[epoch: 399/400, batch: 968/1000, ite: 52747] train loss: 1.1058, accuracy: 95.9476%, tar: 0.0188 \n",
      "l0: 0.014564, l1: 0.015491, l2: 0.021977, l3: 0.033132, l4: 0.055679, l5: 0.118652, l6: 0.283801\n",
      "\n",
      "[epoch: 399/400, batch: 976/1000, ite: 52748] train loss: 1.1055, accuracy: 96.5934%, tar: 0.0188 \n",
      "l0: 0.017441, l1: 0.018761, l2: 0.028060, l3: 0.046330, l4: 0.091401, l5: 0.184123, l6: 0.398551\n",
      "\n",
      "[epoch: 399/400, batch: 984/1000, ite: 52749] train loss: 1.1056, accuracy: 94.9083%, tar: 0.0188 \n",
      "l0: 0.021375, l1: 0.022608, l2: 0.030722, l3: 0.046310, l4: 0.095325, l5: 0.211739, l6: 0.416816\n",
      "\n",
      "[epoch: 399/400, batch: 992/1000, ite: 52750] train loss: 1.1058, accuracy: 94.4006%, tar: 0.0188 \n",
      "l0: 0.021658, l1: 0.023191, l2: 0.032851, l3: 0.054995, l4: 0.111379, l5: 0.221254, l6: 0.424187\n",
      "\n",
      "[epoch: 399/400, batch: 1000/1000, ite: 52751] train loss: 1.1061, accuracy: 95.0156%, tar: 0.0188 \n",
      "l0: 0.015477, l1: 0.016795, l2: 0.023812, l3: 0.038695, l4: 0.068497, l5: 0.132996, l6: 0.292559\n",
      "\n",
      "[epoch: 400/400, batch: 8/1000, ite: 52752] train loss: 1.1058, accuracy: 96.5065%, tar: 0.0188 \n",
      "l0: 0.026156, l1: 0.028234, l2: 0.040390, l3: 0.065067, l4: 0.133804, l5: 0.329187, l6: 0.617234\n",
      "\n",
      "[epoch: 400/400, batch: 16/1000, ite: 52753] train loss: 1.1068, accuracy: 92.1910%, tar: 0.0188 \n",
      "l0: 0.020558, l1: 0.021949, l2: 0.029897, l3: 0.047594, l4: 0.094925, l5: 0.208201, l6: 0.434367\n",
      "\n",
      "[epoch: 400/400, batch: 24/1000, ite: 52754] train loss: 1.1070, accuracy: 93.7816%, tar: 0.0188 \n",
      "l0: 0.015207, l1: 0.016237, l2: 0.020703, l3: 0.031445, l4: 0.059150, l5: 0.121083, l6: 0.250923\n",
      "\n",
      "[epoch: 400/400, batch: 32/1000, ite: 52755] train loss: 1.1066, accuracy: 96.3823%, tar: 0.0188 \n",
      "l0: 0.019126, l1: 0.021313, l2: 0.031167, l3: 0.047295, l4: 0.091657, l5: 0.199308, l6: 0.393686\n",
      "\n",
      "[epoch: 400/400, batch: 40/1000, ite: 52756] train loss: 1.1067, accuracy: 94.3287%, tar: 0.0188 \n",
      "l0: 0.020375, l1: 0.021782, l2: 0.028526, l3: 0.042277, l4: 0.086066, l5: 0.196164, l6: 0.367512\n",
      "\n",
      "[epoch: 400/400, batch: 48/1000, ite: 52757] train loss: 1.1067, accuracy: 94.5147%, tar: 0.0188 \n",
      "l0: 0.014907, l1: 0.016028, l2: 0.023578, l3: 0.033912, l4: 0.060675, l5: 0.131352, l6: 0.293254\n",
      "\n",
      "[epoch: 400/400, batch: 56/1000, ite: 52758] train loss: 1.1064, accuracy: 96.1874%, tar: 0.0188 \n",
      "l0: 0.015803, l1: 0.017095, l2: 0.025971, l3: 0.038832, l4: 0.065878, l5: 0.136597, l6: 0.266766\n",
      "\n",
      "[epoch: 400/400, batch: 64/1000, ite: 52759] train loss: 1.1060, accuracy: 96.2318%, tar: 0.0188 \n",
      "l0: 0.018280, l1: 0.019764, l2: 0.027863, l3: 0.045623, l4: 0.098965, l5: 0.200070, l6: 0.476075\n",
      "\n",
      "[epoch: 400/400, batch: 72/1000, ite: 52760] train loss: 1.1064, accuracy: 93.7445%, tar: 0.0188 \n",
      "l0: 0.016996, l1: 0.018390, l2: 0.028092, l3: 0.046382, l4: 0.086861, l5: 0.187580, l6: 0.352555\n",
      "\n",
      "[epoch: 400/400, batch: 80/1000, ite: 52761] train loss: 1.1064, accuracy: 94.6640%, tar: 0.0188 \n",
      "l0: 0.014813, l1: 0.015647, l2: 0.021746, l3: 0.031846, l4: 0.057515, l5: 0.125601, l6: 0.298098\n",
      "\n",
      "[epoch: 400/400, batch: 88/1000, ite: 52762] train loss: 1.1061, accuracy: 95.9167%, tar: 0.0188 \n",
      "l0: 0.013400, l1: 0.014491, l2: 0.020693, l3: 0.031333, l4: 0.054885, l5: 0.132906, l6: 0.295357\n",
      "\n",
      "[epoch: 400/400, batch: 96/1000, ite: 52763] train loss: 1.1057, accuracy: 96.1464%, tar: 0.0188 \n",
      "l0: 0.014607, l1: 0.015665, l2: 0.023342, l3: 0.035916, l4: 0.060430, l5: 0.132947, l6: 0.315009\n",
      "\n",
      "[epoch: 400/400, batch: 104/1000, ite: 52764] train loss: 1.1055, accuracy: 96.2769%, tar: 0.0188 \n",
      "l0: 0.014854, l1: 0.016019, l2: 0.023776, l3: 0.039933, l4: 0.080170, l5: 0.194951, l6: 0.425268\n",
      "\n",
      "[epoch: 400/400, batch: 112/1000, ite: 52765] train loss: 1.1056, accuracy: 94.8257%, tar: 0.0188 \n",
      "l0: 0.014583, l1: 0.015810, l2: 0.021936, l3: 0.033091, l4: 0.063550, l5: 0.144630, l6: 0.308134\n",
      "\n",
      "[epoch: 400/400, batch: 120/1000, ite: 52766] train loss: 1.1054, accuracy: 95.6537%, tar: 0.0188 \n",
      "l0: 0.016812, l1: 0.019095, l2: 0.029401, l3: 0.045973, l4: 0.081754, l5: 0.168303, l6: 0.342525\n",
      "\n",
      "[epoch: 400/400, batch: 128/1000, ite: 52767] train loss: 1.1053, accuracy: 95.4631%, tar: 0.0188 \n",
      "l0: 0.019051, l1: 0.021114, l2: 0.028973, l3: 0.048730, l4: 0.103417, l5: 0.216868, l6: 0.469046\n",
      "\n",
      "[epoch: 400/400, batch: 136/1000, ite: 52768] train loss: 1.1057, accuracy: 94.8247%, tar: 0.0188 \n",
      "l0: 0.017060, l1: 0.018649, l2: 0.027909, l3: 0.045963, l4: 0.079356, l5: 0.146633, l6: 0.344249\n",
      "\n",
      "[epoch: 400/400, batch: 144/1000, ite: 52769] train loss: 1.1056, accuracy: 95.2353%, tar: 0.0188 \n",
      "l0: 0.016218, l1: 0.018155, l2: 0.025128, l3: 0.040382, l4: 0.091554, l5: 0.204258, l6: 0.358173\n",
      "\n",
      "[epoch: 400/400, batch: 152/1000, ite: 52770] train loss: 1.1056, accuracy: 95.4378%, tar: 0.0188 \n",
      "l0: 0.024925, l1: 0.026372, l2: 0.033989, l3: 0.050189, l4: 0.099280, l5: 0.183252, l6: 0.429599\n",
      "\n",
      "[epoch: 400/400, batch: 160/1000, ite: 52771] train loss: 1.1058, accuracy: 93.3337%, tar: 0.0188 \n",
      "l0: 0.017023, l1: 0.018315, l2: 0.028134, l3: 0.046282, l4: 0.089566, l5: 0.205557, l6: 0.361384\n",
      "\n",
      "[epoch: 400/400, batch: 168/1000, ite: 52772] train loss: 1.1058, accuracy: 95.3387%, tar: 0.0188 \n",
      "l0: 0.016038, l1: 0.017878, l2: 0.027109, l3: 0.041247, l4: 0.084544, l5: 0.192029, l6: 0.372104\n",
      "\n",
      "[epoch: 400/400, batch: 176/1000, ite: 52773] train loss: 1.1059, accuracy: 95.8109%, tar: 0.0188 \n",
      "l0: 0.017291, l1: 0.018253, l2: 0.026224, l3: 0.040568, l4: 0.078081, l5: 0.180208, l6: 0.372278\n",
      "\n",
      "[epoch: 400/400, batch: 184/1000, ite: 52774] train loss: 1.1059, accuracy: 94.6918%, tar: 0.0188 \n",
      "l0: 0.018224, l1: 0.019631, l2: 0.025793, l3: 0.037366, l4: 0.061697, l5: 0.127021, l6: 0.365753\n",
      "\n",
      "[epoch: 400/400, batch: 192/1000, ite: 52775] train loss: 1.1058, accuracy: 95.6101%, tar: 0.0188 \n",
      "l0: 0.014540, l1: 0.015673, l2: 0.022761, l3: 0.037112, l4: 0.073229, l5: 0.158837, l6: 0.397409\n",
      "\n",
      "[epoch: 400/400, batch: 200/1000, ite: 52776] train loss: 1.1058, accuracy: 95.2100%, tar: 0.0188 \n",
      "l0: 0.015015, l1: 0.016009, l2: 0.022082, l3: 0.033112, l4: 0.058962, l5: 0.118761, l6: 0.265431\n",
      "\n",
      "[epoch: 400/400, batch: 208/1000, ite: 52777] train loss: 1.1054, accuracy: 95.7994%, tar: 0.0188 \n",
      "l0: 0.022853, l1: 0.024681, l2: 0.033958, l3: 0.052440, l4: 0.123416, l5: 0.237119, l6: 0.423904\n",
      "\n",
      "[epoch: 400/400, batch: 216/1000, ite: 52778] train loss: 1.1057, accuracy: 94.5707%, tar: 0.0188 \n",
      "l0: 0.012054, l1: 0.013468, l2: 0.019951, l3: 0.034224, l4: 0.076832, l5: 0.149271, l6: 0.282829\n",
      "\n",
      "[epoch: 400/400, batch: 224/1000, ite: 52779] train loss: 1.1054, accuracy: 96.0342%, tar: 0.0188 \n",
      "l0: 0.017831, l1: 0.019367, l2: 0.026255, l3: 0.040475, l4: 0.076317, l5: 0.168260, l6: 0.345578\n",
      "\n",
      "[epoch: 400/400, batch: 232/1000, ite: 52780] train loss: 1.1053, accuracy: 95.6085%, tar: 0.0188 \n",
      "l0: 0.016678, l1: 0.017812, l2: 0.028064, l3: 0.045795, l4: 0.086003, l5: 0.194623, l6: 0.421400\n",
      "\n",
      "[epoch: 400/400, batch: 240/1000, ite: 52781] train loss: 1.1055, accuracy: 94.7882%, tar: 0.0188 \n",
      "l0: 0.015671, l1: 0.016195, l2: 0.021763, l3: 0.037078, l4: 0.072183, l5: 0.134837, l6: 0.310600\n",
      "\n",
      "[epoch: 400/400, batch: 248/1000, ite: 52782] train loss: 1.1053, accuracy: 95.3994%, tar: 0.0188 \n",
      "l0: 0.016756, l1: 0.018153, l2: 0.027266, l3: 0.042390, l4: 0.078117, l5: 0.154920, l6: 0.296638\n",
      "\n",
      "[epoch: 400/400, batch: 256/1000, ite: 52783] train loss: 1.1050, accuracy: 95.7024%, tar: 0.0188 \n",
      "l0: 0.015661, l1: 0.017419, l2: 0.024897, l3: 0.037160, l4: 0.071026, l5: 0.177517, l6: 0.340999\n",
      "\n",
      "[epoch: 400/400, batch: 264/1000, ite: 52784] train loss: 1.1049, accuracy: 95.8962%, tar: 0.0188 \n",
      "l0: 0.016778, l1: 0.018901, l2: 0.027190, l3: 0.047615, l4: 0.099980, l5: 0.206967, l6: 0.428852\n",
      "\n",
      "[epoch: 400/400, batch: 272/1000, ite: 52785] train loss: 1.1052, accuracy: 94.8964%, tar: 0.0188 \n",
      "l0: 0.017827, l1: 0.019413, l2: 0.028600, l3: 0.046256, l4: 0.092011, l5: 0.172460, l6: 0.340662\n",
      "\n",
      "[epoch: 400/400, batch: 280/1000, ite: 52786] train loss: 1.1051, accuracy: 95.3108%, tar: 0.0188 \n",
      "l0: 0.024933, l1: 0.027475, l2: 0.040126, l3: 0.066297, l4: 0.112945, l5: 0.205551, l6: 0.348116\n",
      "\n",
      "[epoch: 400/400, batch: 288/1000, ite: 52787] train loss: 1.1052, accuracy: 95.6610%, tar: 0.0188 \n",
      "l0: 0.017274, l1: 0.018299, l2: 0.023993, l3: 0.033930, l4: 0.061947, l5: 0.140871, l6: 0.365604\n",
      "\n",
      "[epoch: 400/400, batch: 296/1000, ite: 52788] train loss: 1.1051, accuracy: 95.2821%, tar: 0.0188 \n",
      "l0: 0.019114, l1: 0.021908, l2: 0.033570, l3: 0.053963, l4: 0.088720, l5: 0.172275, l6: 0.340052\n",
      "\n",
      "[epoch: 400/400, batch: 304/1000, ite: 52789] train loss: 1.1051, accuracy: 96.2953%, tar: 0.0188 \n",
      "l0: 0.018660, l1: 0.020151, l2: 0.027343, l3: 0.044520, l4: 0.083633, l5: 0.174623, l6: 0.381932\n",
      "\n",
      "[epoch: 400/400, batch: 312/1000, ite: 52790] train loss: 1.1051, accuracy: 94.7778%, tar: 0.0188 \n",
      "l0: 0.015365, l1: 0.016366, l2: 0.023201, l3: 0.034957, l4: 0.058838, l5: 0.106385, l6: 0.275439\n",
      "\n",
      "[epoch: 400/400, batch: 320/1000, ite: 52791] train loss: 1.1047, accuracy: 96.5072%, tar: 0.0188 \n",
      "l0: 0.018510, l1: 0.019949, l2: 0.028402, l3: 0.040921, l4: 0.078216, l5: 0.169159, l6: 0.336680\n",
      "\n",
      "[epoch: 400/400, batch: 328/1000, ite: 52792] train loss: 1.1046, accuracy: 95.6530%, tar: 0.0188 \n",
      "l0: 0.013233, l1: 0.014750, l2: 0.020350, l3: 0.032024, l4: 0.060774, l5: 0.126772, l6: 0.275938\n",
      "\n",
      "[epoch: 400/400, batch: 336/1000, ite: 52793] train loss: 1.1043, accuracy: 96.4099%, tar: 0.0188 \n",
      "l0: 0.022300, l1: 0.024870, l2: 0.035825, l3: 0.062166, l4: 0.122013, l5: 0.259951, l6: 0.478612\n",
      "\n",
      "[epoch: 400/400, batch: 344/1000, ite: 52794] train loss: 1.1048, accuracy: 93.8887%, tar: 0.0188 \n",
      "l0: 0.014980, l1: 0.016084, l2: 0.022786, l3: 0.040387, l4: 0.073762, l5: 0.149245, l6: 0.305028\n",
      "\n",
      "[epoch: 400/400, batch: 352/1000, ite: 52795] train loss: 1.1045, accuracy: 95.3396%, tar: 0.0188 \n",
      "l0: 0.016784, l1: 0.018606, l2: 0.028113, l3: 0.049497, l4: 0.111775, l5: 0.241666, l6: 0.378145\n",
      "\n",
      "[epoch: 400/400, batch: 360/1000, ite: 52796] train loss: 1.1047, accuracy: 95.4842%, tar: 0.0187 \n",
      "l0: 0.016961, l1: 0.018227, l2: 0.026905, l3: 0.040603, l4: 0.071403, l5: 0.158820, l6: 0.332972\n",
      "\n",
      "[epoch: 400/400, batch: 368/1000, ite: 52797] train loss: 1.1046, accuracy: 95.1058%, tar: 0.0187 \n",
      "l0: 0.017571, l1: 0.019430, l2: 0.026865, l3: 0.045262, l4: 0.088366, l5: 0.194823, l6: 0.352500\n",
      "\n",
      "[epoch: 400/400, batch: 376/1000, ite: 52798] train loss: 1.1045, accuracy: 95.3880%, tar: 0.0187 \n",
      "l0: 0.014257, l1: 0.015145, l2: 0.023761, l3: 0.036713, l4: 0.068448, l5: 0.148115, l6: 0.326442\n",
      "\n",
      "[epoch: 400/400, batch: 384/1000, ite: 52799] train loss: 1.1044, accuracy: 95.7195%, tar: 0.0187 \n",
      "l0: 0.016989, l1: 0.018991, l2: 0.028454, l3: 0.045085, l4: 0.099065, l5: 0.187745, l6: 0.318373\n",
      "\n",
      "[epoch: 400/400, batch: 392/1000, ite: 52800] train loss: 1.1043, accuracy: 96.1676%, tar: 0.0187 \n",
      "l0: 0.014314, l1: 0.015243, l2: 0.022174, l3: 0.036261, l4: 0.069513, l5: 0.132320, l6: 0.273238\n",
      "\n",
      "[epoch: 400/400, batch: 400/1000, ite: 52801] train loss: 1.1040, accuracy: 96.1497%, tar: 0.0187 \n",
      "l0: 0.017231, l1: 0.018332, l2: 0.026462, l3: 0.040431, l4: 0.075441, l5: 0.189382, l6: 0.396395\n",
      "\n",
      "[epoch: 400/400, batch: 408/1000, ite: 52802] train loss: 1.1040, accuracy: 94.2735%, tar: 0.0187 \n",
      "l0: 0.014415, l1: 0.015736, l2: 0.023838, l3: 0.034391, l4: 0.063759, l5: 0.120796, l6: 0.258153\n",
      "\n",
      "[epoch: 400/400, batch: 416/1000, ite: 52803] train loss: 1.1036, accuracy: 96.6001%, tar: 0.0187 \n",
      "l0: 0.020720, l1: 0.022146, l2: 0.030420, l3: 0.047404, l4: 0.081570, l5: 0.164909, l6: 0.371799\n",
      "\n",
      "[epoch: 400/400, batch: 424/1000, ite: 52804] train loss: 1.1036, accuracy: 94.9037%, tar: 0.0187 \n",
      "l0: 0.015836, l1: 0.017015, l2: 0.023284, l3: 0.036075, l4: 0.064792, l5: 0.132845, l6: 0.316650\n",
      "\n",
      "[epoch: 400/400, batch: 432/1000, ite: 52805] train loss: 1.1034, accuracy: 95.7894%, tar: 0.0187 \n",
      "l0: 0.016885, l1: 0.018649, l2: 0.028087, l3: 0.049204, l4: 0.106946, l5: 0.224939, l6: 0.416992\n",
      "\n",
      "[epoch: 400/400, batch: 440/1000, ite: 52806] train loss: 1.1036, accuracy: 94.6644%, tar: 0.0187 \n",
      "l0: 0.024391, l1: 0.026152, l2: 0.035932, l3: 0.054685, l4: 0.099117, l5: 0.295430, l6: 0.577187\n",
      "\n",
      "[epoch: 400/400, batch: 448/1000, ite: 52807] train loss: 1.1044, accuracy: 91.9181%, tar: 0.0187 \n",
      "l0: 0.020529, l1: 0.022235, l2: 0.030214, l3: 0.043901, l4: 0.086708, l5: 0.193753, l6: 0.394535\n",
      "\n",
      "[epoch: 400/400, batch: 456/1000, ite: 52808] train loss: 1.1045, accuracy: 94.6386%, tar: 0.0187 \n",
      "l0: 0.021875, l1: 0.022519, l2: 0.030579, l3: 0.049514, l4: 0.105287, l5: 0.239541, l6: 0.426920\n",
      "\n",
      "[epoch: 400/400, batch: 464/1000, ite: 52809] train loss: 1.1048, accuracy: 94.2077%, tar: 0.0187 \n",
      "l0: 0.024171, l1: 0.026559, l2: 0.035618, l3: 0.052607, l4: 0.100120, l5: 0.219134, l6: 0.363994\n",
      "\n",
      "[epoch: 400/400, batch: 472/1000, ite: 52810] train loss: 1.1049, accuracy: 95.2712%, tar: 0.0187 \n",
      "l0: 0.015823, l1: 0.016928, l2: 0.024199, l3: 0.039782, l4: 0.072476, l5: 0.136056, l6: 0.298088\n",
      "\n",
      "[epoch: 400/400, batch: 480/1000, ite: 52811] train loss: 1.1046, accuracy: 95.7525%, tar: 0.0187 \n",
      "l0: 0.023876, l1: 0.027980, l2: 0.043312, l3: 0.078987, l4: 0.163139, l5: 0.300046, l6: 0.502517\n",
      "\n",
      "[epoch: 400/400, batch: 488/1000, ite: 52812] train loss: 1.1053, accuracy: 94.0698%, tar: 0.0187 \n",
      "l0: 0.015711, l1: 0.016378, l2: 0.021173, l3: 0.032045, l4: 0.057191, l5: 0.133796, l6: 0.282554\n",
      "\n",
      "[epoch: 400/400, batch: 496/1000, ite: 52813] train loss: 1.1049, accuracy: 95.6719%, tar: 0.0187 \n",
      "l0: 0.017943, l1: 0.019274, l2: 0.029796, l3: 0.046762, l4: 0.092294, l5: 0.203140, l6: 0.406804\n",
      "\n",
      "[epoch: 400/400, batch: 504/1000, ite: 52814] train loss: 1.1051, accuracy: 94.0154%, tar: 0.0187 \n",
      "l0: 0.015522, l1: 0.016836, l2: 0.025233, l3: 0.047311, l4: 0.087822, l5: 0.146506, l6: 0.301442\n",
      "\n",
      "[epoch: 400/400, batch: 512/1000, ite: 52815] train loss: 1.1049, accuracy: 96.2869%, tar: 0.0187 \n",
      "l0: 0.017191, l1: 0.018099, l2: 0.024755, l3: 0.039359, l4: 0.073705, l5: 0.145966, l6: 0.254278\n",
      "\n",
      "[epoch: 400/400, batch: 520/1000, ite: 52816] train loss: 1.1046, accuracy: 95.8828%, tar: 0.0187 \n",
      "l0: 0.017108, l1: 0.018041, l2: 0.026511, l3: 0.039420, l4: 0.067027, l5: 0.132419, l6: 0.261568\n",
      "\n",
      "[epoch: 400/400, batch: 528/1000, ite: 52817] train loss: 1.1042, accuracy: 95.5869%, tar: 0.0187 \n",
      "l0: 0.016503, l1: 0.018271, l2: 0.028977, l3: 0.056126, l4: 0.113523, l5: 0.235734, l6: 0.380014\n",
      "\n",
      "[epoch: 400/400, batch: 536/1000, ite: 52818] train loss: 1.1044, accuracy: 95.2044%, tar: 0.0187 \n",
      "l0: 0.018485, l1: 0.019620, l2: 0.027124, l3: 0.044811, l4: 0.102060, l5: 0.183668, l6: 0.335849\n",
      "\n",
      "[epoch: 400/400, batch: 544/1000, ite: 52819] train loss: 1.1043, accuracy: 94.6911%, tar: 0.0187 \n",
      "l0: 0.019812, l1: 0.021227, l2: 0.027918, l3: 0.039745, l4: 0.069445, l5: 0.146385, l6: 0.284166\n",
      "\n",
      "[epoch: 400/400, batch: 552/1000, ite: 52820] train loss: 1.1041, accuracy: 95.5283%, tar: 0.0187 \n",
      "l0: 0.017068, l1: 0.018025, l2: 0.022805, l3: 0.032165, l4: 0.062901, l5: 0.120010, l6: 0.276393\n",
      "\n",
      "[epoch: 400/400, batch: 560/1000, ite: 52821] train loss: 1.1038, accuracy: 95.9347%, tar: 0.0187 \n",
      "l0: 0.018285, l1: 0.020167, l2: 0.031423, l3: 0.060929, l4: 0.114007, l5: 0.209273, l6: 0.363505\n",
      "\n",
      "[epoch: 400/400, batch: 568/1000, ite: 52822] train loss: 1.1039, accuracy: 95.6998%, tar: 0.0187 \n",
      "l0: 0.017523, l1: 0.018684, l2: 0.025648, l3: 0.041410, l4: 0.075817, l5: 0.161522, l6: 0.303754\n",
      "\n",
      "[epoch: 400/400, batch: 576/1000, ite: 52823] train loss: 1.1037, accuracy: 95.9846%, tar: 0.0187 \n",
      "l0: 0.015815, l1: 0.016536, l2: 0.022316, l3: 0.034400, l4: 0.061389, l5: 0.138846, l6: 0.299045\n",
      "\n",
      "[epoch: 400/400, batch: 584/1000, ite: 52824] train loss: 1.1034, accuracy: 95.3070%, tar: 0.0187 \n",
      "l0: 0.018493, l1: 0.019910, l2: 0.028736, l3: 0.043679, l4: 0.078358, l5: 0.198251, l6: 0.413416\n",
      "\n",
      "[epoch: 400/400, batch: 592/1000, ite: 52825] train loss: 1.1035, accuracy: 94.7607%, tar: 0.0187 \n",
      "l0: 0.015012, l1: 0.016950, l2: 0.026139, l3: 0.041855, l4: 0.087065, l5: 0.190877, l6: 0.450743\n",
      "\n",
      "[epoch: 400/400, batch: 600/1000, ite: 52826] train loss: 1.1038, accuracy: 94.9775%, tar: 0.0187 \n",
      "l0: 0.018159, l1: 0.019531, l2: 0.028173, l3: 0.044035, l4: 0.083781, l5: 0.158460, l6: 0.419992\n",
      "\n",
      "[epoch: 400/400, batch: 608/1000, ite: 52827] train loss: 1.1039, accuracy: 94.5542%, tar: 0.0187 \n",
      "l0: 0.025394, l1: 0.026082, l2: 0.032144, l3: 0.046304, l4: 0.080878, l5: 0.179522, l6: 0.353200\n",
      "\n",
      "[epoch: 400/400, batch: 616/1000, ite: 52828] train loss: 1.1039, accuracy: 94.2997%, tar: 0.0187 \n",
      "l0: 0.019900, l1: 0.021865, l2: 0.030096, l3: 0.048453, l4: 0.090458, l5: 0.204915, l6: 0.446842\n",
      "\n",
      "[epoch: 400/400, batch: 624/1000, ite: 52829] train loss: 1.1041, accuracy: 94.1597%, tar: 0.0187 \n",
      "l0: 0.020644, l1: 0.022142, l2: 0.030207, l3: 0.042382, l4: 0.070658, l5: 0.141459, l6: 0.389248\n",
      "\n",
      "[epoch: 400/400, batch: 632/1000, ite: 52830] train loss: 1.1041, accuracy: 94.9825%, tar: 0.0187 \n",
      "l0: 0.017228, l1: 0.018568, l2: 0.027418, l3: 0.037956, l4: 0.067341, l5: 0.141327, l6: 0.314130\n",
      "\n",
      "[epoch: 400/400, batch: 640/1000, ite: 52831] train loss: 1.1039, accuracy: 96.3548%, tar: 0.0187 \n",
      "l0: 0.018609, l1: 0.020234, l2: 0.027712, l3: 0.044024, l4: 0.089637, l5: 0.192484, l6: 0.464387\n",
      "\n",
      "[epoch: 400/400, batch: 648/1000, ite: 52832] train loss: 1.1042, accuracy: 94.0309%, tar: 0.0187 \n",
      "l0: 0.019341, l1: 0.021371, l2: 0.028911, l3: 0.044925, l4: 0.090312, l5: 0.185114, l6: 0.477730\n",
      "\n",
      "[epoch: 400/400, batch: 656/1000, ite: 52833] train loss: 1.1045, accuracy: 94.0153%, tar: 0.0187 \n",
      "l0: 0.018482, l1: 0.019745, l2: 0.027257, l3: 0.045461, l4: 0.103191, l5: 0.194495, l6: 0.358994\n",
      "\n",
      "[epoch: 400/400, batch: 664/1000, ite: 52834] train loss: 1.1045, accuracy: 94.7936%, tar: 0.0187 \n",
      "l0: 0.018076, l1: 0.019850, l2: 0.028568, l3: 0.043749, l4: 0.081751, l5: 0.156519, l6: 0.377312\n",
      "\n",
      "[epoch: 400/400, batch: 672/1000, ite: 52835] train loss: 1.1045, accuracy: 95.2766%, tar: 0.0187 \n",
      "l0: 0.017700, l1: 0.018826, l2: 0.026144, l3: 0.040985, l4: 0.074099, l5: 0.156378, l6: 0.326450\n",
      "\n",
      "[epoch: 400/400, batch: 680/1000, ite: 52836] train loss: 1.1044, accuracy: 95.4089%, tar: 0.0187 \n",
      "l0: 0.019141, l1: 0.020146, l2: 0.027331, l3: 0.046662, l4: 0.117850, l5: 0.225161, l6: 0.390008\n",
      "\n",
      "[epoch: 400/400, batch: 688/1000, ite: 52837] train loss: 1.1045, accuracy: 94.4359%, tar: 0.0187 \n",
      "l0: 0.014846, l1: 0.015696, l2: 0.022321, l3: 0.032401, l4: 0.055831, l5: 0.113350, l6: 0.300190\n",
      "\n",
      "[epoch: 400/400, batch: 696/1000, ite: 52838] train loss: 1.1042, accuracy: 96.1014%, tar: 0.0187 \n",
      "l0: 0.023428, l1: 0.024947, l2: 0.032373, l3: 0.047440, l4: 0.083689, l5: 0.162701, l6: 0.331912\n",
      "\n",
      "[epoch: 400/400, batch: 704/1000, ite: 52839] train loss: 1.1042, accuracy: 95.3196%, tar: 0.0187 \n",
      "l0: 0.016839, l1: 0.018216, l2: 0.025418, l3: 0.038994, l4: 0.070715, l5: 0.162910, l6: 0.344732\n",
      "\n",
      "[epoch: 400/400, batch: 712/1000, ite: 52840] train loss: 1.1041, accuracy: 94.8104%, tar: 0.0187 \n",
      "l0: 0.021010, l1: 0.022328, l2: 0.029999, l3: 0.044360, l4: 0.085981, l5: 0.221207, l6: 0.421425\n",
      "\n",
      "[epoch: 400/400, batch: 720/1000, ite: 52841] train loss: 1.1043, accuracy: 94.2697%, tar: 0.0187 \n",
      "l0: 0.014019, l1: 0.016207, l2: 0.022927, l3: 0.036179, l4: 0.067454, l5: 0.154069, l6: 0.355548\n",
      "\n",
      "[epoch: 400/400, batch: 728/1000, ite: 52842] train loss: 1.1042, accuracy: 97.2587%, tar: 0.0187 \n",
      "l0: 0.018078, l1: 0.020090, l2: 0.027857, l3: 0.046597, l4: 0.108651, l5: 0.184859, l6: 0.422666\n",
      "\n",
      "[epoch: 400/400, batch: 736/1000, ite: 52843] train loss: 1.1044, accuracy: 94.8239%, tar: 0.0187 \n",
      "l0: 0.018899, l1: 0.020399, l2: 0.028477, l3: 0.044857, l4: 0.082212, l5: 0.162823, l6: 0.389239\n",
      "\n",
      "[epoch: 400/400, batch: 744/1000, ite: 52844] train loss: 1.1044, accuracy: 94.7560%, tar: 0.0187 \n",
      "l0: 0.019481, l1: 0.021878, l2: 0.036282, l3: 0.059980, l4: 0.112417, l5: 0.190121, l6: 0.380244\n",
      "\n",
      "[epoch: 400/400, batch: 752/1000, ite: 52845] train loss: 1.1045, accuracy: 95.8763%, tar: 0.0187 \n",
      "l0: 0.023432, l1: 0.023971, l2: 0.032960, l3: 0.049894, l4: 0.087773, l5: 0.199220, l6: 0.482106\n",
      "\n",
      "[epoch: 400/400, batch: 760/1000, ite: 52846] train loss: 1.1049, accuracy: 93.5221%, tar: 0.0187 \n",
      "l0: 0.017380, l1: 0.017718, l2: 0.022998, l3: 0.035306, l4: 0.061774, l5: 0.121845, l6: 0.257979\n",
      "\n",
      "[epoch: 400/400, batch: 768/1000, ite: 52847] train loss: 1.1045, accuracy: 95.6938%, tar: 0.0187 \n",
      "l0: 0.013681, l1: 0.014823, l2: 0.021365, l3: 0.034260, l4: 0.060815, l5: 0.123389, l6: 0.225822\n",
      "\n",
      "[epoch: 400/400, batch: 776/1000, ite: 52848] train loss: 1.1040, accuracy: 96.7792%, tar: 0.0187 \n",
      "l0: 0.015979, l1: 0.017101, l2: 0.024625, l3: 0.041342, l4: 0.096631, l5: 0.204650, l6: 0.364687\n",
      "\n",
      "[epoch: 400/400, batch: 784/1000, ite: 52849] train loss: 1.1041, accuracy: 95.4692%, tar: 0.0187 \n",
      "l0: 0.021259, l1: 0.022611, l2: 0.029470, l3: 0.044079, l4: 0.080046, l5: 0.168470, l6: 0.340546\n",
      "\n",
      "[epoch: 400/400, batch: 792/1000, ite: 52850] train loss: 1.1040, accuracy: 95.2420%, tar: 0.0187 \n",
      "l0: 0.016390, l1: 0.016783, l2: 0.023818, l3: 0.037456, l4: 0.065281, l5: 0.137608, l6: 0.329627\n",
      "\n",
      "[epoch: 400/400, batch: 800/1000, ite: 52851] train loss: 1.1038, accuracy: 95.6055%, tar: 0.0187 \n",
      "l0: 0.018511, l1: 0.020226, l2: 0.029675, l3: 0.046961, l4: 0.084764, l5: 0.151768, l6: 0.327097\n",
      "\n",
      "[epoch: 400/400, batch: 808/1000, ite: 52852] train loss: 1.1037, accuracy: 95.9461%, tar: 0.0187 \n",
      "l0: 0.014862, l1: 0.016956, l2: 0.025258, l3: 0.043137, l4: 0.080475, l5: 0.144818, l6: 0.346771\n",
      "\n",
      "[epoch: 400/400, batch: 816/1000, ite: 52853] train loss: 1.1036, accuracy: 95.7695%, tar: 0.0187 \n",
      "l0: 0.021908, l1: 0.022857, l2: 0.030300, l3: 0.045549, l4: 0.079473, l5: 0.161068, l6: 0.411059\n",
      "\n",
      "[epoch: 400/400, batch: 824/1000, ite: 52854] train loss: 1.1037, accuracy: 94.0650%, tar: 0.0187 \n",
      "l0: 0.020588, l1: 0.022483, l2: 0.031764, l3: 0.049293, l4: 0.100232, l5: 0.232508, l6: 0.468353\n",
      "\n",
      "[epoch: 400/400, batch: 832/1000, ite: 52855] train loss: 1.1041, accuracy: 93.9563%, tar: 0.0187 \n",
      "l0: 0.021269, l1: 0.023005, l2: 0.031491, l3: 0.046233, l4: 0.079128, l5: 0.166049, l6: 0.417851\n",
      "\n",
      "[epoch: 400/400, batch: 840/1000, ite: 52856] train loss: 1.1042, accuracy: 94.5152%, tar: 0.0187 \n",
      "l0: 0.019662, l1: 0.020896, l2: 0.030337, l3: 0.050552, l4: 0.098677, l5: 0.193200, l6: 0.341816\n",
      "\n",
      "[epoch: 400/400, batch: 848/1000, ite: 52857] train loss: 1.1042, accuracy: 95.2133%, tar: 0.0187 \n",
      "l0: 0.018312, l1: 0.019976, l2: 0.026938, l3: 0.041918, l4: 0.086782, l5: 0.188368, l6: 0.429987\n",
      "\n",
      "[epoch: 400/400, batch: 856/1000, ite: 52858] train loss: 1.1044, accuracy: 94.4290%, tar: 0.0187 \n",
      "l0: 0.018072, l1: 0.019104, l2: 0.025420, l3: 0.040857, l4: 0.081770, l5: 0.197941, l6: 0.348408\n",
      "\n",
      "[epoch: 400/400, batch: 864/1000, ite: 52859] train loss: 1.1043, accuracy: 94.9197%, tar: 0.0187 \n",
      "l0: 0.023437, l1: 0.025163, l2: 0.033108, l3: 0.050245, l4: 0.089015, l5: 0.185250, l6: 0.401281\n",
      "\n",
      "[epoch: 400/400, batch: 872/1000, ite: 52860] train loss: 1.1045, accuracy: 94.5275%, tar: 0.0187 \n",
      "l0: 0.024264, l1: 0.025693, l2: 0.035205, l3: 0.052820, l4: 0.099717, l5: 0.213666, l6: 0.460465\n",
      "\n",
      "[epoch: 400/400, batch: 880/1000, ite: 52861] train loss: 1.1048, accuracy: 93.6951%, tar: 0.0187 \n",
      "l0: 0.018368, l1: 0.019906, l2: 0.027081, l3: 0.041267, l4: 0.092472, l5: 0.191118, l6: 0.393594\n",
      "\n",
      "[epoch: 400/400, batch: 888/1000, ite: 52862] train loss: 1.1049, accuracy: 95.6231%, tar: 0.0187 \n",
      "l0: 0.017102, l1: 0.018738, l2: 0.025615, l3: 0.040990, l4: 0.075492, l5: 0.143020, l6: 0.266268\n",
      "\n",
      "[epoch: 400/400, batch: 896/1000, ite: 52863] train loss: 1.1046, accuracy: 96.3850%, tar: 0.0187 \n",
      "l0: 0.016138, l1: 0.017324, l2: 0.024037, l3: 0.039667, l4: 0.087580, l5: 0.172222, l6: 0.335406\n",
      "\n",
      "[epoch: 400/400, batch: 904/1000, ite: 52864] train loss: 1.1045, accuracy: 94.8848%, tar: 0.0187 \n",
      "l0: 0.017944, l1: 0.019055, l2: 0.028017, l3: 0.044541, l4: 0.084333, l5: 0.170851, l6: 0.413996\n",
      "\n",
      "[epoch: 400/400, batch: 912/1000, ite: 52865] train loss: 1.1046, accuracy: 95.3956%, tar: 0.0187 \n",
      "l0: 0.017123, l1: 0.018485, l2: 0.026550, l3: 0.043055, l4: 0.087302, l5: 0.194048, l6: 0.456287\n",
      "\n",
      "[epoch: 400/400, batch: 920/1000, ite: 52866] train loss: 1.1048, accuracy: 94.6836%, tar: 0.0187 \n",
      "l0: 0.018654, l1: 0.020103, l2: 0.027870, l3: 0.042721, l4: 0.079721, l5: 0.167199, l6: 0.321304\n",
      "\n",
      "[epoch: 400/400, batch: 928/1000, ite: 52867] train loss: 1.1047, accuracy: 95.0671%, tar: 0.0187 \n",
      "l0: 0.013459, l1: 0.014251, l2: 0.020231, l3: 0.037328, l4: 0.072467, l5: 0.145435, l6: 0.272943\n",
      "\n",
      "[epoch: 400/400, batch: 936/1000, ite: 52868] train loss: 1.1044, accuracy: 96.1384%, tar: 0.0187 \n",
      "l0: 0.019030, l1: 0.019921, l2: 0.026901, l3: 0.038226, l4: 0.070660, l5: 0.137635, l6: 0.293876\n",
      "\n",
      "[epoch: 400/400, batch: 944/1000, ite: 52869] train loss: 1.1042, accuracy: 95.4431%, tar: 0.0187 \n",
      "l0: 0.023213, l1: 0.025958, l2: 0.035010, l3: 0.054574, l4: 0.100013, l5: 0.187776, l6: 0.429330\n",
      "\n",
      "[epoch: 400/400, batch: 952/1000, ite: 52870] train loss: 1.1044, accuracy: 94.9279%, tar: 0.0187 \n",
      "l0: 0.020005, l1: 0.020963, l2: 0.029471, l3: 0.046542, l4: 0.089733, l5: 0.237783, l6: 0.427044\n",
      "\n",
      "[epoch: 400/400, batch: 960/1000, ite: 52871] train loss: 1.1046, accuracy: 93.4342%, tar: 0.0187 \n",
      "l0: 0.021567, l1: 0.023349, l2: 0.033007, l3: 0.052597, l4: 0.104019, l5: 0.199737, l6: 0.408198\n",
      "\n",
      "[epoch: 400/400, batch: 968/1000, ite: 52872] train loss: 1.1048, accuracy: 94.4608%, tar: 0.0187 \n",
      "l0: 0.023714, l1: 0.024915, l2: 0.034941, l3: 0.051324, l4: 0.093552, l5: 0.182029, l6: 0.352209\n",
      "\n",
      "[epoch: 400/400, batch: 976/1000, ite: 52873] train loss: 1.1048, accuracy: 94.6193%, tar: 0.0187 \n",
      "l0: 0.019103, l1: 0.020597, l2: 0.028637, l3: 0.048958, l4: 0.099348, l5: 0.189502, l6: 0.446845\n",
      "\n",
      "[epoch: 400/400, batch: 984/1000, ite: 52874] train loss: 1.1050, accuracy: 94.9528%, tar: 0.0187 \n",
      "l0: 0.019392, l1: 0.020873, l2: 0.028518, l3: 0.043737, l4: 0.073067, l5: 0.145518, l6: 0.277123\n",
      "\n",
      "[epoch: 400/400, batch: 992/1000, ite: 52875] train loss: 1.1048, accuracy: 96.0146%, tar: 0.0187 \n",
      "l0: 0.021132, l1: 0.022233, l2: 0.028681, l3: 0.041777, l4: 0.082512, l5: 0.171931, l6: 0.403499\n",
      "\n",
      "[epoch: 400/400, batch: 1000/1000, ite: 52876] train loss: 1.1049, accuracy: 94.7620%, tar: 0.0187 \n",
      "-------------Congratulations! Training Done!!!-------------\n"
     ]
    }
   ],
   "source": [
    "# ------- 5. training process --------\n",
    "print(\"---start training...\")\n",
    "ite_num = 43626\n",
    "running_loss = 0.0\n",
    "running_tar_loss = 0.0\n",
    "ite_num4val = 0\n",
    "top_100_acc = []\n",
    "\n",
    "\n",
    "for epoch in range(0, epoch_num):\n",
    "    net.train()\n",
    "\n",
    "    for i, data in enumerate(salobj_dataloader):\n",
    "        ite_num = ite_num + 1\n",
    "        ite_num4val = ite_num4val + 1\n",
    "\n",
    "        inputs, labels = data['image'], data['label']\n",
    "\n",
    "        inputs = inputs.type(torch.FloatTensor)\n",
    "        labels = labels.type(torch.FloatTensor)\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if torch.cuda.is_available():\n",
    "            inputs_v, labels_v = Variable(inputs.cuda(), requires_grad=False), Variable(labels.cuda(),\n",
    "                                                                                        requires_grad=False)\n",
    "        else:\n",
    "            inputs_v, labels_v = Variable(inputs, requires_grad=False), Variable(labels, requires_grad=False)\n",
    "\n",
    "        # y zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        d0, d1, d2, d3, d4, d5, d6, d7 = net(inputs_v)\n",
    "        loss2, loss, acc = muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, d7, labels_v)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # # print statistics\n",
    "        running_loss += loss.data\n",
    "        running_tar_loss += loss2.data\n",
    "\n",
    "        # del temporary outputs and loss\n",
    "        del d0, d1, d2, d3, d4, d5, d6, d7, loss2, loss\n",
    "\n",
    "        # print(\"ite_num4val: \", ite_num4val)\n",
    "\n",
    "        print(f\"[epoch: {epoch + 1}/{epoch_num}, batch: {(i + 1) * batch_size_train}/{train_num}, ite: {ite_num}] train loss: {format(running_loss / ite_num4val, '.4f')}, accuracy: {format(acc * 100, '.4f')}%, tar: {format(running_tar_loss / ite_num4val, '.4f')} \")\n",
    "\n",
    "        if ite_num % 2000 == 0:  # save model every 2000 iterations\n",
    "\n",
    "            torch.save(net.state_dict(), model_dir + \"basnet_bsi_itr_%d_train_%3f_tar_%3f.pth\" % (ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val))\n",
    "            running_loss = 0.0\n",
    "            running_tar_loss = 0.0\n",
    "            net.train()  # resume train\n",
    "            ite_num4val = 0\n",
    "        \n",
    "        if epoch + 1 >= 400:\n",
    "            top_100_acc.append(acc * 100)\n",
    "\n",
    "print('-------------Congratulations! Training Done!!!-------------')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SODtraining.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0695f33655af490e9c7a41df37b36431": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e54cc196908a4cb49aa49dc5aac7778f",
      "placeholder": "​",
      "style": "IPY_MODEL_e49af9a0bf4343d887c9a1fa7c568b06",
      "value": " 83.3M/83.3M [00:01&lt;00:00, 70.6MB/s]"
     }
    },
    "1d796ffde8ac43dd93a991be4a710df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb6bd39c44054d859ba3a199c63d94d5",
       "IPY_MODEL_0695f33655af490e9c7a41df37b36431"
      ],
      "layout": "IPY_MODEL_cc56d20ea8d8484892ec15b0c703f43c"
     }
    },
    "6b0fb610fdb64262be5900045a8e51c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c998593c747e4840bd352f2d7ccdf7a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cc56d20ea8d8484892ec15b0c703f43c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e49af9a0bf4343d887c9a1fa7c568b06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e54cc196908a4cb49aa49dc5aac7778f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb6bd39c44054d859ba3a199c63d94d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b0fb610fdb64262be5900045a8e51c9",
      "max": 87306240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c998593c747e4840bd352f2d7ccdf7a3",
      "value": 87306240
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
