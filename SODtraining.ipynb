{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SODtraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d796ffde8ac43dd93a991be4a710df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cc56d20ea8d8484892ec15b0c703f43c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb6bd39c44054d859ba3a199c63d94d5",
              "IPY_MODEL_0695f33655af490e9c7a41df37b36431"
            ]
          }
        },
        "cc56d20ea8d8484892ec15b0c703f43c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb6bd39c44054d859ba3a199c63d94d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c998593c747e4840bd352f2d7ccdf7a3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87306240,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87306240,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b0fb610fdb64262be5900045a8e51c9"
          }
        },
        "0695f33655af490e9c7a41df37b36431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e49af9a0bf4343d887c9a1fa7c568b06",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 83.3M/83.3M [00:01&lt;00:00, 70.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e54cc196908a4cb49aa49dc5aac7778f"
          }
        },
        "c998593c747e4840bd352f2d7ccdf7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b0fb610fdb64262be5900045a8e51c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e49af9a0bf4343d887c9a1fa7c568b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e54cc196908a4cb49aa49dc5aac7778f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSL2ErH4SvOZ",
        "outputId": "7cc83edb-7160-452e-baaf-014f46c1731b"
      },
      "source": [
        "!git clone https://github.com/n00bmaster68/ApplyingSODinAutoLabelling\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ApplyingSODinAutoLabelling'...\n",
            "remote: Enumerating objects: 2093, done.\u001b[K\n",
            "remote: Counting objects: 100% (2093/2093), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2073/2073), done.\u001b[K\n",
            "remote: Total 2093 (delta 20), reused 2077 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2093/2093), 75.11 MiB | 47.62 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjqxfTA1XGU3",
        "outputId": "8812c0fe-55a0-46e3-f50d-add18ee630da"
      },
      "source": [
        "#check whether device has GPU\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-dcd37850-a4f3-4c92-8d32-ccd8921c8825)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKJksXRPSxvA"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as standard_transforms\n",
        "\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from ApplyingSODinAutoLabelling.data_loader import Rescale\n",
        "from ApplyingSODinAutoLabelling.data_loader import RescaleT\n",
        "from ApplyingSODinAutoLabelling.data_loader import RandomCrop\n",
        "from ApplyingSODinAutoLabelling.data_loader import CenterCrop\n",
        "from ApplyingSODinAutoLabelling.data_loader import ToTensor\n",
        "from ApplyingSODinAutoLabelling.data_loader import ToTensorLab\n",
        "from ApplyingSODinAutoLabelling.data_loader import SalObjDataset\n",
        "\n",
        "from ApplyingSODinAutoLabelling.model import BASNet\n",
        "\n",
        "import ApplyingSODinAutoLabelling.deletable.pytorch_ssim as pytorch_ssim\n",
        "import ApplyingSODinAutoLabelling.deletable.pytorch_iou as pytorch_iou"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN6sGAEGTvJr",
        "outputId": "72cfe343-0cac-4362-b636-27fd8bb7c79a"
      },
      "source": [
        "# ------- 1. define loss function --------\n",
        "\n",
        "bce_loss = nn.BCELoss(size_average=True)\n",
        "ssim_loss = pytorch_ssim.SSIM(window_size=11,size_average=True)\n",
        "iou_loss = pytorch_iou.IOU(size_average=True)\n",
        "\n",
        "def bce_ssim_loss(pred,target):\n",
        "\n",
        "\tbce_out = bce_loss(pred,target)\n",
        "\tssim_out = 1 - ssim_loss(pred,target)\n",
        "\tiou_out = iou_loss(pred,target)\n",
        "\n",
        "\tloss = bce_out + ssim_out + iou_out\n",
        "\treturn loss, ssim_out\n",
        "\n",
        "def muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, d7, labels_v):\n",
        "  loss0, ssim0 = bce_ssim_loss(d0,labels_v)\n",
        "  loss1, ssim1 = bce_ssim_loss(d1,labels_v)\n",
        "  loss2, ssim2 = bce_ssim_loss(d2,labels_v)\n",
        "  loss3, ssim3 = bce_ssim_loss(d3,labels_v)\n",
        "  loss4, ssim4 = bce_ssim_loss(d4,labels_v)\n",
        "  loss5, ssim5 = bce_ssim_loss(d5,labels_v)\n",
        "  loss6, ssim6 = bce_ssim_loss(d6,labels_v)\n",
        "  loss7, ssim7 = bce_ssim_loss(d7,labels_v)\n",
        "\n",
        "  acc = (ssim0 + ssim1 + ssim2 + ssim3 + ssim4 + ssim5 + ssim6 + ssim7) / 8\n",
        "  \n",
        "  loss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6 + loss7\n",
        "  print(\"l0: %3f, l1: %3f, l2: %3f, l3: %3f, l4: %3f, l5: %3f, l6: %3f\\n\"%(loss0.data,loss1.data,loss2.data,loss3.data,loss4.data,loss5.data,loss6.data))\n",
        "  \n",
        "  return loss0, loss, 1 - acc"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NH-ofMLTvSX",
        "outputId": "d2d523e7-2c6c-4de2-8d80-797f81a37a2c"
      },
      "source": [
        "# ------- 2. set the directory of training dataset --------\n",
        "\n",
        "data_dir = 'ApplyingSODinAutoLabelling/train_data/'\n",
        "tra_image_dir = 'DUTS/DUTS-TR/DUTS-TR/im_aug/'\n",
        "tra_label_dir = 'DUTS/DUTS-TR/DUTS-TR/gt_aug/'\n",
        "\n",
        "image_ext = '.jpg'\n",
        "label_ext = '.png'\n",
        "\n",
        "model_dir = \"ApplyingSODinAutoLabelling/saved_models/basnet_bsi/\"\n",
        "\n",
        "\n",
        "epoch_num = 100000\n",
        "batch_size_train = 8 \n",
        "batch_size_val = 1\n",
        "train_num = 0\n",
        "val_num = 0\n",
        "\n",
        "tra_img_name_list = glob.glob(data_dir + tra_image_dir + '*' + image_ext)\n",
        "\n",
        "tra_lbl_name_list = []\n",
        "for img_path in tra_img_name_list:\n",
        "\timg_name = img_path.split(\"/\")[-1]\n",
        "\n",
        "\taaa = img_name.split(\".\")\n",
        "\tbbb = aaa[0:-1]\n",
        "\timidx = bbb[0]\n",
        "\tfor i in range(1,len(bbb)):\n",
        "\t\timidx = imidx + \".\" + bbb[i]\n",
        "\n",
        "\ttra_lbl_name_list.append(data_dir + tra_label_dir + imidx + label_ext)\n",
        "\n",
        "print(\"---\")\n",
        "print(\"train images: \", len(tra_img_name_list))\n",
        "print(\"train labels: \", len(tra_lbl_name_list))\n",
        "print(\"---\")\n",
        "\n",
        "train_num = len(tra_img_name_list)\n",
        "\n",
        "salobj_dataset = SalObjDataset(\n",
        "    img_name_list=tra_img_name_list,\n",
        "    lbl_name_list=tra_lbl_name_list,\n",
        "    transform=transforms.Compose([\n",
        "        RescaleT(256),\n",
        "        RandomCrop(224),\n",
        "        ToTensorLab(flag=0)]))\n",
        "salobj_dataloader = DataLoader(salobj_dataset, batch_size=batch_size_train, shuffle=True, num_workers=1)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---\n",
            "train images:  1000\n",
            "train labels:  1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNL4AVnSTvYv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "1d796ffde8ac43dd93a991be4a710df9",
            "cc56d20ea8d8484892ec15b0c703f43c",
            "fb6bd39c44054d859ba3a199c63d94d5",
            "0695f33655af490e9c7a41df37b36431",
            "c998593c747e4840bd352f2d7ccdf7a3",
            "6b0fb610fdb64262be5900045a8e51c9",
            "e49af9a0bf4343d887c9a1fa7c568b06",
            "e54cc196908a4cb49aa49dc5aac7778f"
          ]
        },
        "outputId": "866a6755-1d4c-4f15-b4e8-2c4b2ed51824"
      },
      "source": [
        "# ------- 3. define model --------\n",
        "# define the net\n",
        "net = BASNet(3, 1)\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d796ffde8ac43dd93a991be4a710df9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHfoce-xTveR",
        "outputId": "3c3bb38a-fc40-4383-fd95-094ef1593c67"
      },
      "source": [
        "# ------- 4. define optimizer --------\n",
        "print(\"---define optimizer...\")\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---define optimizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMrCr4J9TvjK",
        "outputId": "91227037-fc14-4c02-8135-0557fb9a7c36"
      },
      "source": [
        "# ------- 5. training process --------\n",
        "print(\"---start training...\")\n",
        "ite_num = 0\n",
        "running_loss = 0.0\n",
        "running_tar_loss = 0.0\n",
        "ite_num4val = 0\n",
        "\n",
        "for epoch in range(0, epoch_num):\n",
        "    net.train()\n",
        "\n",
        "    for i, data in enumerate(salobj_dataloader):\n",
        "        ite_num = ite_num + 1\n",
        "        ite_num4val = ite_num4val + 1\n",
        "\n",
        "        inputs, labels = data['image'], data['label']\n",
        "\n",
        "        inputs = inputs.type(torch.FloatTensor)\n",
        "        labels = labels.type(torch.FloatTensor)\n",
        "\n",
        "        # wrap them in Variable\n",
        "        if torch.cuda.is_available():\n",
        "            inputs_v, labels_v = Variable(inputs.cuda(), requires_grad=False), Variable(labels.cuda(),\n",
        "                                                                                        requires_grad=False)\n",
        "        else:\n",
        "            inputs_v, labels_v = Variable(inputs, requires_grad=False), Variable(labels, requires_grad=False)\n",
        "\n",
        "        # y zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        d0, d1, d2, d3, d4, d5, d6, d7 = net(inputs_v)\n",
        "        loss2, loss, acc = muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, d7, labels_v)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # # print statistics\n",
        "        running_loss += loss.data\n",
        "        running_tar_loss += loss2.data\n",
        "\n",
        "        # del temporary outputs and loss\n",
        "        del d0, d1, d2, d3, d4, d5, d6, d7, loss2, loss\n",
        "\n",
        "        # print(\"ite_num4val: \", ite_num4val)\n",
        "\n",
        "        print(f\"[epoch: {epoch + 1}/{epoch_num}, batch: {(i + 1) * batch_size_train}/{train_num}, ite: {ite_num}] train loss: {format(running_loss / ite_num4val, '.4f')}, accuracy: {format(acc * 100, '.4f')}%, tar: {format(running_tar_loss / ite_num4val, '.4f')} \")\n",
        "\n",
        "        if ite_num % 2000 == 0:  # save model every 2000 iterations\n",
        "\n",
        "            torch.save(net.state_dict(), model_dir + \"basnet_bsi_itr_%d_train_%3f_tar_%3f.pth\" % (ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val))\n",
        "            running_loss = 0.0\n",
        "            running_tar_loss = 0.0\n",
        "            net.train()  # resume train\n",
        "            ite_num4val = 0\n",
        "\n",
        "print('-------------Congratulations! Training Done!!!-------------')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---start training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "l0: 0.080788, l1: 0.083053, l2: 0.089892, l3: 0.107807, l4: 0.152371, l5: 0.241569, l6: 0.435864\n",
            "\n",
            "[epoch: 106/100000, batch: 184/1000, ite: 13148] train loss: 2.0245, accuracy: 93.6807%, tar: 0.1100 \n",
            "l0: 0.079113, l1: 0.079982, l2: 0.087575, l3: 0.102774, l4: 0.135701, l5: 0.234230, l6: 0.451056\n",
            "\n",
            "[epoch: 106/100000, batch: 192/1000, ite: 13149] train loss: 2.0242, accuracy: 92.4243%, tar: 0.1099 \n",
            "l0: 0.100674, l1: 0.101122, l2: 0.110897, l3: 0.127574, l4: 0.175083, l5: 0.253529, l6: 0.430277\n",
            "\n",
            "[epoch: 106/100000, batch: 200/1000, ite: 13150] train loss: 2.0239, accuracy: 94.1453%, tar: 0.1099 \n",
            "l0: 0.088659, l1: 0.090110, l2: 0.102864, l3: 0.129852, l4: 0.186513, l5: 0.295943, l6: 0.513983\n",
            "\n",
            "[epoch: 106/100000, batch: 208/1000, ite: 13151] train loss: 2.0239, accuracy: 91.5995%, tar: 0.1099 \n",
            "l0: 0.101521, l1: 0.103117, l2: 0.112431, l3: 0.132467, l4: 0.177560, l5: 0.278480, l6: 0.471155\n",
            "\n",
            "[epoch: 106/100000, batch: 216/1000, ite: 13152] train loss: 2.0237, accuracy: 92.1534%, tar: 0.1099 \n",
            "l0: 0.090544, l1: 0.091147, l2: 0.099938, l3: 0.123385, l4: 0.158440, l5: 0.237961, l6: 0.435568\n",
            "\n",
            "[epoch: 106/100000, batch: 224/1000, ite: 13153] train loss: 2.0234, accuracy: 92.0800%, tar: 0.1099 \n",
            "l0: 0.116922, l1: 0.118494, l2: 0.133904, l3: 0.166878, l4: 0.259081, l5: 0.458330, l6: 0.742121\n",
            "\n",
            "[epoch: 106/100000, batch: 232/1000, ite: 13154] train loss: 2.0240, accuracy: 88.7426%, tar: 0.1099 \n",
            "l0: 0.071821, l1: 0.072581, l2: 0.081418, l3: 0.104694, l4: 0.153390, l5: 0.220137, l6: 0.378135\n",
            "\n",
            "[epoch: 106/100000, batch: 240/1000, ite: 13155] train loss: 2.0235, accuracy: 93.2338%, tar: 0.1099 \n",
            "l0: 0.096852, l1: 0.097305, l2: 0.104994, l3: 0.125535, l4: 0.180538, l5: 0.288604, l6: 0.470965\n",
            "\n",
            "[epoch: 106/100000, batch: 248/1000, ite: 13156] train loss: 2.0234, accuracy: 91.8775%, tar: 0.1099 \n",
            "l0: 0.089036, l1: 0.090237, l2: 0.101314, l3: 0.134138, l4: 0.205361, l5: 0.344307, l6: 0.521157\n",
            "\n",
            "[epoch: 106/100000, batch: 256/1000, ite: 13157] train loss: 2.0234, accuracy: 91.3872%, tar: 0.1098 \n",
            "l0: 0.076858, l1: 0.077683, l2: 0.087919, l3: 0.115780, l4: 0.161776, l5: 0.236656, l6: 0.416516\n",
            "\n",
            "[epoch: 106/100000, batch: 264/1000, ite: 13158] train loss: 2.0230, accuracy: 93.0626%, tar: 0.1098 \n",
            "l0: 0.093692, l1: 0.094799, l2: 0.102766, l3: 0.120571, l4: 0.156709, l5: 0.229305, l6: 0.382578\n",
            "\n",
            "[epoch: 106/100000, batch: 272/1000, ite: 13159] train loss: 2.0226, accuracy: 92.9060%, tar: 0.1098 \n",
            "l0: 0.114611, l1: 0.114871, l2: 0.125161, l3: 0.151447, l4: 0.208322, l5: 0.366561, l6: 0.598592\n",
            "\n",
            "[epoch: 106/100000, batch: 280/1000, ite: 13160] train loss: 2.0228, accuracy: 89.2160%, tar: 0.1098 \n",
            "l0: 0.091716, l1: 0.093231, l2: 0.106566, l3: 0.139625, l4: 0.204607, l5: 0.307282, l6: 0.514773\n",
            "\n",
            "[epoch: 106/100000, batch: 288/1000, ite: 13161] train loss: 2.0228, accuracy: 92.1771%, tar: 0.1098 \n",
            "l0: 0.074627, l1: 0.076150, l2: 0.083056, l3: 0.102826, l4: 0.152166, l5: 0.256314, l6: 0.459167\n",
            "\n",
            "[epoch: 106/100000, batch: 296/1000, ite: 13162] train loss: 2.0225, accuracy: 93.1103%, tar: 0.1098 \n",
            "l0: 0.074927, l1: 0.076318, l2: 0.085796, l3: 0.109281, l4: 0.154352, l5: 0.233771, l6: 0.416911\n",
            "\n",
            "[epoch: 106/100000, batch: 304/1000, ite: 13163] train loss: 2.0221, accuracy: 93.0327%, tar: 0.1097 \n",
            "l0: 0.115674, l1: 0.115451, l2: 0.124933, l3: 0.146449, l4: 0.183521, l5: 0.274762, l6: 0.445531\n",
            "\n",
            "[epoch: 106/100000, batch: 312/1000, ite: 13164] train loss: 2.0219, accuracy: 91.4775%, tar: 0.1097 \n",
            "l0: 0.093711, l1: 0.094045, l2: 0.100935, l3: 0.126180, l4: 0.179424, l5: 0.269234, l6: 0.432577\n",
            "\n",
            "[epoch: 106/100000, batch: 320/1000, ite: 13165] train loss: 2.0217, accuracy: 92.5047%, tar: 0.1097 \n",
            "l0: 0.089993, l1: 0.090774, l2: 0.101699, l3: 0.119801, l4: 0.184168, l5: 0.306838, l6: 0.505444\n",
            "\n",
            "[epoch: 106/100000, batch: 328/1000, ite: 13166] train loss: 2.0216, accuracy: 92.0930%, tar: 0.1097 \n",
            "l0: 0.080567, l1: 0.081822, l2: 0.091863, l3: 0.113156, l4: 0.165508, l5: 0.246919, l6: 0.445120\n",
            "\n",
            "[epoch: 106/100000, batch: 336/1000, ite: 13167] train loss: 2.0213, accuracy: 92.0188%, tar: 0.1097 \n",
            "l0: 0.108546, l1: 0.109481, l2: 0.116738, l3: 0.137546, l4: 0.178754, l5: 0.240182, l6: 0.401573\n",
            "\n",
            "[epoch: 106/100000, batch: 344/1000, ite: 13168] train loss: 2.0210, accuracy: 92.2842%, tar: 0.1097 \n",
            "l0: 0.113093, l1: 0.114700, l2: 0.129782, l3: 0.169982, l4: 0.266982, l5: 0.436543, l6: 0.679765\n",
            "\n",
            "[epoch: 106/100000, batch: 352/1000, ite: 13169] train loss: 2.0215, accuracy: 90.8605%, tar: 0.1097 \n",
            "l0: 0.108974, l1: 0.110727, l2: 0.120797, l3: 0.153577, l4: 0.225482, l5: 0.350112, l6: 0.551037\n",
            "\n",
            "[epoch: 106/100000, batch: 360/1000, ite: 13170] train loss: 2.0217, accuracy: 91.6129%, tar: 0.1097 \n",
            "l0: 0.113515, l1: 0.114216, l2: 0.125735, l3: 0.146718, l4: 0.200647, l5: 0.335712, l6: 0.634366\n",
            "\n",
            "[epoch: 106/100000, batch: 368/1000, ite: 13171] train loss: 2.0219, accuracy: 89.3689%, tar: 0.1097 \n",
            "l0: 0.091546, l1: 0.091945, l2: 0.101137, l3: 0.119675, l4: 0.180466, l5: 0.280567, l6: 0.474880\n",
            "\n",
            "[epoch: 106/100000, batch: 376/1000, ite: 13172] train loss: 2.0217, accuracy: 91.7238%, tar: 0.1097 \n",
            "l0: 0.067059, l1: 0.067882, l2: 0.076975, l3: 0.094995, l4: 0.131965, l5: 0.208647, l6: 0.406752\n",
            "\n",
            "[epoch: 106/100000, batch: 384/1000, ite: 13173] train loss: 2.0212, accuracy: 93.2519%, tar: 0.1096 \n",
            "l0: 0.085265, l1: 0.085698, l2: 0.096687, l3: 0.121857, l4: 0.177202, l5: 0.285107, l6: 0.474546\n",
            "\n",
            "[epoch: 106/100000, batch: 392/1000, ite: 13174] train loss: 2.0210, accuracy: 91.5579%, tar: 0.1096 \n",
            "l0: 0.107098, l1: 0.108432, l2: 0.118823, l3: 0.138421, l4: 0.181493, l5: 0.298279, l6: 0.539981\n",
            "\n",
            "[epoch: 106/100000, batch: 400/1000, ite: 13175] train loss: 2.0210, accuracy: 91.1918%, tar: 0.1096 \n",
            "l0: 0.118196, l1: 0.119740, l2: 0.129914, l3: 0.161672, l4: 0.227440, l5: 0.335195, l6: 0.518129\n",
            "\n",
            "[epoch: 106/100000, batch: 408/1000, ite: 13176] train loss: 2.0211, accuracy: 91.4662%, tar: 0.1096 \n",
            "l0: 0.102233, l1: 0.103177, l2: 0.114032, l3: 0.138893, l4: 0.183811, l5: 0.288753, l6: 0.506428\n",
            "\n",
            "[epoch: 106/100000, batch: 416/1000, ite: 13177] train loss: 2.0211, accuracy: 91.2464%, tar: 0.1096 \n",
            "l0: 0.095325, l1: 0.096677, l2: 0.104106, l3: 0.123331, l4: 0.158141, l5: 0.274965, l6: 0.494734\n",
            "\n",
            "[epoch: 106/100000, batch: 424/1000, ite: 13178] train loss: 2.0209, accuracy: 91.4699%, tar: 0.1096 \n",
            "l0: 0.069540, l1: 0.070916, l2: 0.080732, l3: 0.102344, l4: 0.145962, l5: 0.238145, l6: 0.396206\n",
            "\n",
            "[epoch: 106/100000, batch: 432/1000, ite: 13179] train loss: 2.0205, accuracy: 93.5993%, tar: 0.1096 \n",
            "l0: 0.075278, l1: 0.075982, l2: 0.084834, l3: 0.105712, l4: 0.152490, l5: 0.241837, l6: 0.420066\n",
            "\n",
            "[epoch: 106/100000, batch: 440/1000, ite: 13180] train loss: 2.0201, accuracy: 93.3262%, tar: 0.1095 \n",
            "l0: 0.076265, l1: 0.077561, l2: 0.086677, l3: 0.106325, l4: 0.155719, l5: 0.260083, l6: 0.421445\n",
            "\n",
            "[epoch: 106/100000, batch: 448/1000, ite: 13181] train loss: 2.0197, accuracy: 93.3800%, tar: 0.1095 \n",
            "l0: 0.078729, l1: 0.081173, l2: 0.091054, l3: 0.118288, l4: 0.175679, l5: 0.279658, l6: 0.435734\n",
            "\n",
            "[epoch: 106/100000, batch: 456/1000, ite: 13182] train loss: 2.0195, accuracy: 92.8781%, tar: 0.1095 \n",
            "l0: 0.091462, l1: 0.093523, l2: 0.100538, l3: 0.118969, l4: 0.163517, l5: 0.249230, l6: 0.466753\n",
            "\n",
            "[epoch: 106/100000, batch: 464/1000, ite: 13183] train loss: 2.0192, accuracy: 92.0012%, tar: 0.1095 \n",
            "l0: 0.117718, l1: 0.119635, l2: 0.131280, l3: 0.164279, l4: 0.238678, l5: 0.326546, l6: 0.526020\n",
            "\n",
            "[epoch: 106/100000, batch: 472/1000, ite: 13184] train loss: 2.0193, accuracy: 91.0987%, tar: 0.1095 \n",
            "l0: 0.085931, l1: 0.087464, l2: 0.096952, l3: 0.124729, l4: 0.178913, l5: 0.273581, l6: 0.403135\n",
            "\n",
            "[epoch: 106/100000, batch: 480/1000, ite: 13185] train loss: 2.0190, accuracy: 92.7957%, tar: 0.1094 \n",
            "l0: 0.117160, l1: 0.118857, l2: 0.132346, l3: 0.153473, l4: 0.203337, l5: 0.336469, l6: 0.634970\n",
            "\n",
            "[epoch: 106/100000, batch: 488/1000, ite: 13186] train loss: 2.0193, accuracy: 90.4341%, tar: 0.1095 \n",
            "l0: 0.121307, l1: 0.122380, l2: 0.130414, l3: 0.150161, l4: 0.189391, l5: 0.281603, l6: 0.454876\n",
            "\n",
            "[epoch: 106/100000, batch: 496/1000, ite: 13187] train loss: 2.0192, accuracy: 91.5608%, tar: 0.1095 \n",
            "l0: 0.083069, l1: 0.083905, l2: 0.092107, l3: 0.117876, l4: 0.174015, l5: 0.280600, l6: 0.512098\n",
            "\n",
            "[epoch: 106/100000, batch: 504/1000, ite: 13188] train loss: 2.0191, accuracy: 90.9367%, tar: 0.1094 \n",
            "l0: 0.116156, l1: 0.116648, l2: 0.122913, l3: 0.140349, l4: 0.178641, l5: 0.267824, l6: 0.434048\n",
            "\n",
            "[epoch: 106/100000, batch: 512/1000, ite: 13189] train loss: 2.0189, accuracy: 92.4416%, tar: 0.1094 \n",
            "l0: 0.100297, l1: 0.102264, l2: 0.110465, l3: 0.130438, l4: 0.184721, l5: 0.301613, l6: 0.497292\n",
            "\n",
            "[epoch: 106/100000, batch: 520/1000, ite: 13190] train loss: 2.0188, accuracy: 91.8124%, tar: 0.1094 \n",
            "l0: 0.115693, l1: 0.115993, l2: 0.124059, l3: 0.144873, l4: 0.194450, l5: 0.270257, l6: 0.423665\n",
            "\n",
            "[epoch: 106/100000, batch: 528/1000, ite: 13191] train loss: 2.0187, accuracy: 92.2576%, tar: 0.1094 \n",
            "l0: 0.102379, l1: 0.103049, l2: 0.108277, l3: 0.134886, l4: 0.187983, l5: 0.279620, l6: 0.447723\n",
            "\n",
            "[epoch: 106/100000, batch: 536/1000, ite: 13192] train loss: 2.0185, accuracy: 92.6726%, tar: 0.1094 \n",
            "l0: 0.092223, l1: 0.093540, l2: 0.105241, l3: 0.132339, l4: 0.188149, l5: 0.332053, l6: 0.574967\n",
            "\n",
            "[epoch: 106/100000, batch: 544/1000, ite: 13193] train loss: 2.0186, accuracy: 90.2404%, tar: 0.1094 \n",
            "l0: 0.092176, l1: 0.092587, l2: 0.100651, l3: 0.120630, l4: 0.180851, l5: 0.284545, l6: 0.491405\n",
            "\n",
            "[epoch: 106/100000, batch: 552/1000, ite: 13194] train loss: 2.0184, accuracy: 91.9657%, tar: 0.1094 \n",
            "l0: 0.079324, l1: 0.080367, l2: 0.091832, l3: 0.115357, l4: 0.166702, l5: 0.283953, l6: 0.552428\n",
            "\n",
            "[epoch: 106/100000, batch: 560/1000, ite: 13195] train loss: 2.0184, accuracy: 92.6818%, tar: 0.1094 \n",
            "l0: 0.107218, l1: 0.108714, l2: 0.117163, l3: 0.141749, l4: 0.194334, l5: 0.306369, l6: 0.467189\n",
            "\n",
            "[epoch: 106/100000, batch: 568/1000, ite: 13196] train loss: 2.0183, accuracy: 90.7071%, tar: 0.1094 \n",
            "l0: 0.081439, l1: 0.081815, l2: 0.095110, l3: 0.130990, l4: 0.214327, l5: 0.346209, l6: 0.589041\n",
            "\n",
            "[epoch: 106/100000, batch: 576/1000, ite: 13197] train loss: 2.0184, accuracy: 90.0681%, tar: 0.1094 \n",
            "l0: 0.082595, l1: 0.083727, l2: 0.092693, l3: 0.110212, l4: 0.146757, l5: 0.205873, l6: 0.353463\n",
            "\n",
            "[epoch: 106/100000, batch: 584/1000, ite: 13198] train loss: 2.0179, accuracy: 93.4572%, tar: 0.1093 \n",
            "l0: 0.114954, l1: 0.115707, l2: 0.123727, l3: 0.146213, l4: 0.200652, l5: 0.278595, l6: 0.454798\n",
            "\n",
            "[epoch: 106/100000, batch: 592/1000, ite: 13199] train loss: 2.0178, accuracy: 92.1552%, tar: 0.1093 \n",
            "l0: 0.085591, l1: 0.086448, l2: 0.095665, l3: 0.124242, l4: 0.176701, l5: 0.271411, l6: 0.457677\n",
            "\n",
            "[epoch: 106/100000, batch: 600/1000, ite: 13200] train loss: 2.0175, accuracy: 91.5861%, tar: 0.1093 \n",
            "l0: 0.083684, l1: 0.085506, l2: 0.092372, l3: 0.114231, l4: 0.177899, l5: 0.284125, l6: 0.409101\n",
            "\n",
            "[epoch: 106/100000, batch: 608/1000, ite: 13201] train loss: 2.0173, accuracy: 92.0976%, tar: 0.1093 \n",
            "l0: 0.119221, l1: 0.120882, l2: 0.132833, l3: 0.160426, l4: 0.229768, l5: 0.369971, l6: 0.652409\n",
            "\n",
            "[epoch: 106/100000, batch: 616/1000, ite: 13202] train loss: 2.0176, accuracy: 90.5652%, tar: 0.1093 \n",
            "l0: 0.105515, l1: 0.107304, l2: 0.118070, l3: 0.142882, l4: 0.189744, l5: 0.294540, l6: 0.490010\n",
            "\n",
            "[epoch: 106/100000, batch: 624/1000, ite: 13203] train loss: 2.0175, accuracy: 90.6471%, tar: 0.1093 \n",
            "l0: 0.085075, l1: 0.085596, l2: 0.092974, l3: 0.107879, l4: 0.146163, l5: 0.216814, l6: 0.372392\n",
            "\n",
            "[epoch: 106/100000, batch: 632/1000, ite: 13204] train loss: 2.0171, accuracy: 92.6406%, tar: 0.1093 \n",
            "l0: 0.120300, l1: 0.121837, l2: 0.130892, l3: 0.158169, l4: 0.207968, l5: 0.385307, l6: 0.569663\n",
            "\n",
            "[epoch: 106/100000, batch: 640/1000, ite: 13205] train loss: 2.0173, accuracy: 91.6642%, tar: 0.1093 \n",
            "l0: 0.069904, l1: 0.071848, l2: 0.081633, l3: 0.100522, l4: 0.146655, l5: 0.233888, l6: 0.390104\n",
            "\n",
            "[epoch: 106/100000, batch: 648/1000, ite: 13206] train loss: 2.0169, accuracy: 93.7802%, tar: 0.1093 \n",
            "l0: 0.098773, l1: 0.099054, l2: 0.107878, l3: 0.134561, l4: 0.179002, l5: 0.258665, l6: 0.400531\n",
            "\n",
            "[epoch: 106/100000, batch: 656/1000, ite: 13207] train loss: 2.0166, accuracy: 91.2111%, tar: 0.1093 \n",
            "l0: 0.093893, l1: 0.095053, l2: 0.101597, l3: 0.122101, l4: 0.173502, l5: 0.293626, l6: 0.527618\n",
            "\n",
            "[epoch: 106/100000, batch: 664/1000, ite: 13208] train loss: 2.0165, accuracy: 92.7974%, tar: 0.1092 \n",
            "l0: 0.097837, l1: 0.098976, l2: 0.106881, l3: 0.129282, l4: 0.174761, l5: 0.267972, l6: 0.441063\n",
            "\n",
            "[epoch: 106/100000, batch: 672/1000, ite: 13209] train loss: 2.0163, accuracy: 92.0833%, tar: 0.1092 \n",
            "l0: 0.100367, l1: 0.102128, l2: 0.111697, l3: 0.132780, l4: 0.178086, l5: 0.265517, l6: 0.439297\n",
            "\n",
            "[epoch: 106/100000, batch: 680/1000, ite: 13210] train loss: 2.0161, accuracy: 91.6499%, tar: 0.1092 \n",
            "l0: 0.115865, l1: 0.118107, l2: 0.128997, l3: 0.160697, l4: 0.221914, l5: 0.319476, l6: 0.519603\n",
            "\n",
            "[epoch: 106/100000, batch: 688/1000, ite: 13211] train loss: 2.0162, accuracy: 91.1686%, tar: 0.1092 \n",
            "l0: 0.094462, l1: 0.095595, l2: 0.105928, l3: 0.126802, l4: 0.194799, l5: 0.288353, l6: 0.556902\n",
            "\n",
            "[epoch: 106/100000, batch: 696/1000, ite: 13212] train loss: 2.0162, accuracy: 91.3595%, tar: 0.1092 \n",
            "l0: 0.093239, l1: 0.093451, l2: 0.100800, l3: 0.119532, l4: 0.178169, l5: 0.267146, l6: 0.517895\n",
            "\n",
            "[epoch: 106/100000, batch: 704/1000, ite: 13213] train loss: 2.0161, accuracy: 92.0085%, tar: 0.1092 \n",
            "l0: 0.079367, l1: 0.081392, l2: 0.086946, l3: 0.105295, l4: 0.141288, l5: 0.219024, l6: 0.327167\n",
            "\n",
            "[epoch: 106/100000, batch: 712/1000, ite: 13214] train loss: 2.0156, accuracy: 93.8798%, tar: 0.1092 \n",
            "l0: 0.083328, l1: 0.083360, l2: 0.091087, l3: 0.115814, l4: 0.165057, l5: 0.259173, l6: 0.404039\n",
            "\n",
            "[epoch: 106/100000, batch: 720/1000, ite: 13215] train loss: 2.0152, accuracy: 93.4716%, tar: 0.1092 \n",
            "l0: 0.074910, l1: 0.075262, l2: 0.083193, l3: 0.101411, l4: 0.138275, l5: 0.230909, l6: 0.351713\n",
            "\n",
            "[epoch: 106/100000, batch: 728/1000, ite: 13216] train loss: 2.0147, accuracy: 93.4300%, tar: 0.1091 \n",
            "l0: 0.107007, l1: 0.108786, l2: 0.118316, l3: 0.147570, l4: 0.217826, l5: 0.358587, l6: 0.670138\n",
            "\n",
            "[epoch: 106/100000, batch: 736/1000, ite: 13217] train loss: 2.0151, accuracy: 91.1654%, tar: 0.1091 \n",
            "l0: 0.114151, l1: 0.117311, l2: 0.126294, l3: 0.155432, l4: 0.207033, l5: 0.293627, l6: 0.470812\n",
            "\n",
            "[epoch: 106/100000, batch: 744/1000, ite: 13218] train loss: 2.0150, accuracy: 92.2868%, tar: 0.1091 \n",
            "l0: 0.093690, l1: 0.095357, l2: 0.100835, l3: 0.118524, l4: 0.154848, l5: 0.248968, l6: 0.427175\n",
            "\n",
            "[epoch: 106/100000, batch: 752/1000, ite: 13219] train loss: 2.0147, accuracy: 92.1856%, tar: 0.1091 \n",
            "l0: 0.090325, l1: 0.091824, l2: 0.102749, l3: 0.120903, l4: 0.167829, l5: 0.282269, l6: 0.515824\n",
            "\n",
            "[epoch: 106/100000, batch: 760/1000, ite: 13220] train loss: 2.0146, accuracy: 90.7672%, tar: 0.1091 \n",
            "l0: 0.098077, l1: 0.098746, l2: 0.108013, l3: 0.135715, l4: 0.189107, l5: 0.308296, l6: 0.523262\n",
            "\n",
            "[epoch: 106/100000, batch: 768/1000, ite: 13221] train loss: 2.0146, accuracy: 91.6720%, tar: 0.1091 \n",
            "l0: 0.102264, l1: 0.103694, l2: 0.115364, l3: 0.142293, l4: 0.207137, l5: 0.338818, l6: 0.552537\n",
            "\n",
            "[epoch: 106/100000, batch: 776/1000, ite: 13222] train loss: 2.0147, accuracy: 90.7416%, tar: 0.1091 \n",
            "l0: 0.077096, l1: 0.077668, l2: 0.087972, l3: 0.111010, l4: 0.163237, l5: 0.294026, l6: 0.509826\n",
            "\n",
            "[epoch: 106/100000, batch: 784/1000, ite: 13223] train loss: 2.0145, accuracy: 92.2013%, tar: 0.1091 \n",
            "l0: 0.065671, l1: 0.066632, l2: 0.073252, l3: 0.092703, l4: 0.127132, l5: 0.227683, l6: 0.382244\n",
            "\n",
            "[epoch: 106/100000, batch: 792/1000, ite: 13224] train loss: 2.0141, accuracy: 93.6409%, tar: 0.1090 \n",
            "l0: 0.093313, l1: 0.094458, l2: 0.105383, l3: 0.132636, l4: 0.191985, l5: 0.314668, l6: 0.592337\n",
            "\n",
            "[epoch: 106/100000, batch: 800/1000, ite: 13225] train loss: 2.0141, accuracy: 90.8371%, tar: 0.1090 \n",
            "l0: 0.106742, l1: 0.107811, l2: 0.120639, l3: 0.152681, l4: 0.225354, l5: 0.362532, l6: 0.565861\n",
            "\n",
            "[epoch: 106/100000, batch: 808/1000, ite: 13226] train loss: 2.0143, accuracy: 90.2273%, tar: 0.1090 \n",
            "l0: 0.094302, l1: 0.096795, l2: 0.105220, l3: 0.128816, l4: 0.179255, l5: 0.286570, l6: 0.516734\n",
            "\n",
            "[epoch: 106/100000, batch: 816/1000, ite: 13227] train loss: 2.0142, accuracy: 91.4243%, tar: 0.1090 \n",
            "l0: 0.082159, l1: 0.084239, l2: 0.095359, l3: 0.115050, l4: 0.156089, l5: 0.254751, l6: 0.411717\n",
            "\n",
            "[epoch: 106/100000, batch: 824/1000, ite: 13228] train loss: 2.0139, accuracy: 93.1114%, tar: 0.1090 \n",
            "l0: 0.076923, l1: 0.077934, l2: 0.086385, l3: 0.106246, l4: 0.139153, l5: 0.223748, l6: 0.465301\n",
            "\n",
            "[epoch: 106/100000, batch: 832/1000, ite: 13229] train loss: 2.0136, accuracy: 91.8365%, tar: 0.1090 \n",
            "l0: 0.082605, l1: 0.083388, l2: 0.095111, l3: 0.118411, l4: 0.173926, l5: 0.295583, l6: 0.487606\n",
            "\n",
            "[epoch: 106/100000, batch: 840/1000, ite: 13230] train loss: 2.0135, accuracy: 91.0544%, tar: 0.1089 \n",
            "l0: 0.096695, l1: 0.097266, l2: 0.106546, l3: 0.125291, l4: 0.165803, l5: 0.278972, l6: 0.491205\n",
            "\n",
            "[epoch: 106/100000, batch: 848/1000, ite: 13231] train loss: 2.0133, accuracy: 91.7984%, tar: 0.1089 \n",
            "l0: 0.100657, l1: 0.100214, l2: 0.108984, l3: 0.134154, l4: 0.202489, l5: 0.308646, l6: 0.472999\n",
            "\n",
            "[epoch: 106/100000, batch: 856/1000, ite: 13232] train loss: 2.0133, accuracy: 91.8142%, tar: 0.1089 \n",
            "l0: 0.100516, l1: 0.101195, l2: 0.110077, l3: 0.133339, l4: 0.183218, l5: 0.289041, l6: 0.501277\n",
            "\n",
            "[epoch: 106/100000, batch: 864/1000, ite: 13233] train loss: 2.0132, accuracy: 91.9711%, tar: 0.1089 \n",
            "l0: 0.087907, l1: 0.089173, l2: 0.100051, l3: 0.129610, l4: 0.188059, l5: 0.307020, l6: 0.498559\n",
            "\n",
            "[epoch: 106/100000, batch: 872/1000, ite: 13234] train loss: 2.0131, accuracy: 92.4089%, tar: 0.1089 \n",
            "l0: 0.074006, l1: 0.074779, l2: 0.084501, l3: 0.107011, l4: 0.153282, l5: 0.249295, l6: 0.490872\n",
            "\n",
            "[epoch: 106/100000, batch: 880/1000, ite: 13235] train loss: 2.0129, accuracy: 92.7806%, tar: 0.1089 \n",
            "l0: 0.107815, l1: 0.108921, l2: 0.114848, l3: 0.132826, l4: 0.190865, l5: 0.303117, l6: 0.501010\n",
            "\n",
            "[epoch: 106/100000, batch: 888/1000, ite: 13236] train loss: 2.0128, accuracy: 92.3496%, tar: 0.1089 \n",
            "l0: 0.076981, l1: 0.077473, l2: 0.086330, l3: 0.107613, l4: 0.158034, l5: 0.245138, l6: 0.436103\n",
            "\n",
            "[epoch: 106/100000, batch: 896/1000, ite: 13237] train loss: 2.0125, accuracy: 93.3377%, tar: 0.1088 \n",
            "l0: 0.074816, l1: 0.075987, l2: 0.085334, l3: 0.112493, l4: 0.168054, l5: 0.252737, l6: 0.486898\n",
            "\n",
            "[epoch: 106/100000, batch: 904/1000, ite: 13238] train loss: 2.0123, accuracy: 93.0805%, tar: 0.1088 \n",
            "l0: 0.083074, l1: 0.084549, l2: 0.093172, l3: 0.116438, l4: 0.168743, l5: 0.264919, l6: 0.421596\n",
            "\n",
            "[epoch: 106/100000, batch: 912/1000, ite: 13239] train loss: 2.0120, accuracy: 92.9573%, tar: 0.1088 \n",
            "l0: 0.080010, l1: 0.081023, l2: 0.090432, l3: 0.112647, l4: 0.155401, l5: 0.236343, l6: 0.442244\n",
            "\n",
            "[epoch: 106/100000, batch: 920/1000, ite: 13240] train loss: 2.0118, accuracy: 91.8844%, tar: 0.1088 \n",
            "l0: 0.071297, l1: 0.072703, l2: 0.082509, l3: 0.110015, l4: 0.160950, l5: 0.258702, l6: 0.468962\n",
            "\n",
            "[epoch: 106/100000, batch: 928/1000, ite: 13241] train loss: 2.0115, accuracy: 91.3324%, tar: 0.1087 \n",
            "l0: 0.072438, l1: 0.072922, l2: 0.081268, l3: 0.097432, l4: 0.136581, l5: 0.214273, l6: 0.378942\n",
            "\n",
            "[epoch: 106/100000, batch: 936/1000, ite: 13242] train loss: 2.0110, accuracy: 93.5174%, tar: 0.1087 \n",
            "l0: 0.101077, l1: 0.101907, l2: 0.109644, l3: 0.127398, l4: 0.178022, l5: 0.270083, l6: 0.438109\n",
            "\n",
            "[epoch: 106/100000, batch: 944/1000, ite: 13243] train loss: 2.0108, accuracy: 91.5276%, tar: 0.1087 \n",
            "l0: 0.102106, l1: 0.102649, l2: 0.111229, l3: 0.137692, l4: 0.186918, l5: 0.324339, l6: 0.563502\n",
            "\n",
            "[epoch: 106/100000, batch: 952/1000, ite: 13244] train loss: 2.0109, accuracy: 92.1742%, tar: 0.1087 \n",
            "l0: 0.090260, l1: 0.091708, l2: 0.101331, l3: 0.130936, l4: 0.198155, l5: 0.285315, l6: 0.442418\n",
            "\n",
            "[epoch: 106/100000, batch: 960/1000, ite: 13245] train loss: 2.0107, accuracy: 92.9792%, tar: 0.1087 \n",
            "l0: 0.068977, l1: 0.071133, l2: 0.082973, l3: 0.114065, l4: 0.164584, l5: 0.260528, l6: 0.515951\n",
            "\n",
            "[epoch: 106/100000, batch: 968/1000, ite: 13246] train loss: 2.0105, accuracy: 91.9843%, tar: 0.1086 \n",
            "l0: 0.085920, l1: 0.085661, l2: 0.094032, l3: 0.116337, l4: 0.169623, l5: 0.267493, l6: 0.466583\n",
            "\n",
            "[epoch: 106/100000, batch: 976/1000, ite: 13247] train loss: 2.0103, accuracy: 92.4775%, tar: 0.1086 \n",
            "l0: 0.101653, l1: 0.102980, l2: 0.109628, l3: 0.132426, l4: 0.175190, l5: 0.261941, l6: 0.413674\n",
            "\n",
            "[epoch: 106/100000, batch: 984/1000, ite: 13248] train loss: 2.0101, accuracy: 92.5935%, tar: 0.1086 \n",
            "l0: 0.106487, l1: 0.107476, l2: 0.115543, l3: 0.142592, l4: 0.199844, l5: 0.299202, l6: 0.605283\n",
            "\n",
            "[epoch: 106/100000, batch: 992/1000, ite: 13249] train loss: 2.0102, accuracy: 89.7870%, tar: 0.1086 \n",
            "l0: 0.082635, l1: 0.083631, l2: 0.093327, l3: 0.117929, l4: 0.171082, l5: 0.274794, l6: 0.426302\n",
            "\n",
            "[epoch: 106/100000, batch: 1000/1000, ite: 13250] train loss: 2.0100, accuracy: 92.5775%, tar: 0.1086 \n",
            "l0: 0.058908, l1: 0.059992, l2: 0.069376, l3: 0.093918, l4: 0.133833, l5: 0.228814, l6: 0.411780\n",
            "\n",
            "[epoch: 107/100000, batch: 8/1000, ite: 13251] train loss: 2.0095, accuracy: 93.3975%, tar: 0.1086 \n",
            "l0: 0.101570, l1: 0.101530, l2: 0.107699, l3: 0.124819, l4: 0.158815, l5: 0.229275, l6: 0.367267\n",
            "\n",
            "[epoch: 107/100000, batch: 16/1000, ite: 13252] train loss: 2.0091, accuracy: 93.6432%, tar: 0.1086 \n",
            "l0: 0.090667, l1: 0.091283, l2: 0.100840, l3: 0.118560, l4: 0.155860, l5: 0.237255, l6: 0.361310\n",
            "\n",
            "[epoch: 107/100000, batch: 24/1000, ite: 13253] train loss: 2.0087, accuracy: 92.9633%, tar: 0.1085 \n",
            "l0: 0.084648, l1: 0.085014, l2: 0.094038, l3: 0.114561, l4: 0.153444, l5: 0.225965, l6: 0.373731\n",
            "\n",
            "[epoch: 107/100000, batch: 32/1000, ite: 13254] train loss: 2.0083, accuracy: 92.5743%, tar: 0.1085 \n",
            "l0: 0.090835, l1: 0.091634, l2: 0.099295, l3: 0.126869, l4: 0.179959, l5: 0.282713, l6: 0.543407\n",
            "\n",
            "[epoch: 107/100000, batch: 40/1000, ite: 13255] train loss: 2.0083, accuracy: 92.2923%, tar: 0.1085 \n",
            "l0: 0.067479, l1: 0.068345, l2: 0.078511, l3: 0.101289, l4: 0.155595, l5: 0.253484, l6: 0.452294\n",
            "\n",
            "[epoch: 107/100000, batch: 48/1000, ite: 13256] train loss: 2.0080, accuracy: 92.5590%, tar: 0.1085 \n",
            "l0: 0.067786, l1: 0.068174, l2: 0.077004, l3: 0.099527, l4: 0.134652, l5: 0.220713, l6: 0.379095\n",
            "\n",
            "[epoch: 107/100000, batch: 56/1000, ite: 13257] train loss: 2.0075, accuracy: 92.6570%, tar: 0.1084 \n",
            "l0: 0.079324, l1: 0.081361, l2: 0.093528, l3: 0.123026, l4: 0.189342, l5: 0.271176, l6: 0.459083\n",
            "\n",
            "[epoch: 107/100000, batch: 64/1000, ite: 13258] train loss: 2.0073, accuracy: 93.1550%, tar: 0.1084 \n",
            "l0: 0.075214, l1: 0.076523, l2: 0.086209, l3: 0.109821, l4: 0.154507, l5: 0.256794, l6: 0.509025\n",
            "\n",
            "[epoch: 107/100000, batch: 72/1000, ite: 13259] train loss: 2.0072, accuracy: 91.7972%, tar: 0.1084 \n",
            "l0: 0.080306, l1: 0.081955, l2: 0.091441, l3: 0.115439, l4: 0.169126, l5: 0.317208, l6: 0.565862\n",
            "\n",
            "[epoch: 107/100000, batch: 80/1000, ite: 13260] train loss: 2.0072, accuracy: 90.6069%, tar: 0.1084 \n",
            "l0: 0.071225, l1: 0.072298, l2: 0.079840, l3: 0.099122, l4: 0.149049, l5: 0.270050, l6: 0.427581\n",
            "\n",
            "[epoch: 107/100000, batch: 88/1000, ite: 13261] train loss: 2.0068, accuracy: 92.7302%, tar: 0.1083 \n",
            "l0: 0.093167, l1: 0.093854, l2: 0.104454, l3: 0.129397, l4: 0.193465, l5: 0.325371, l6: 0.554130\n",
            "\n",
            "[epoch: 107/100000, batch: 96/1000, ite: 13262] train loss: 2.0069, accuracy: 90.4570%, tar: 0.1083 \n",
            "l0: 0.093078, l1: 0.094585, l2: 0.102831, l3: 0.126015, l4: 0.194879, l5: 0.303816, l6: 0.483880\n",
            "\n",
            "[epoch: 107/100000, batch: 104/1000, ite: 13263] train loss: 2.0068, accuracy: 91.4248%, tar: 0.1083 \n",
            "l0: 0.065426, l1: 0.065931, l2: 0.074676, l3: 0.095337, l4: 0.140490, l5: 0.240925, l6: 0.399855\n",
            "\n",
            "[epoch: 107/100000, batch: 112/1000, ite: 13264] train loss: 2.0064, accuracy: 94.0546%, tar: 0.1083 \n",
            "l0: 0.083826, l1: 0.084925, l2: 0.096793, l3: 0.118931, l4: 0.179027, l5: 0.309840, l6: 0.603219\n",
            "\n",
            "[epoch: 107/100000, batch: 120/1000, ite: 13265] train loss: 2.0064, accuracy: 91.5500%, tar: 0.1083 \n",
            "l0: 0.111916, l1: 0.112778, l2: 0.123437, l3: 0.149867, l4: 0.203239, l5: 0.307698, l6: 0.500543\n",
            "\n",
            "[epoch: 107/100000, batch: 128/1000, ite: 13266] train loss: 2.0064, accuracy: 90.8488%, tar: 0.1083 \n",
            "l0: 0.098823, l1: 0.099764, l2: 0.107388, l3: 0.131494, l4: 0.181289, l5: 0.271051, l6: 0.494108\n",
            "\n",
            "[epoch: 107/100000, batch: 136/1000, ite: 13267] train loss: 2.0064, accuracy: 91.1353%, tar: 0.1083 \n",
            "l0: 0.079856, l1: 0.081541, l2: 0.087141, l3: 0.108562, l4: 0.152634, l5: 0.232767, l6: 0.392695\n",
            "\n",
            "[epoch: 107/100000, batch: 144/1000, ite: 13268] train loss: 2.0060, accuracy: 92.5457%, tar: 0.1082 \n",
            "l0: 0.094553, l1: 0.095491, l2: 0.106098, l3: 0.135816, l4: 0.199599, l5: 0.327862, l6: 0.518231\n",
            "\n",
            "[epoch: 107/100000, batch: 152/1000, ite: 13269] train loss: 2.0060, accuracy: 91.9516%, tar: 0.1082 \n",
            "l0: 0.068846, l1: 0.070571, l2: 0.080981, l3: 0.106945, l4: 0.159078, l5: 0.283223, l6: 0.511820\n",
            "\n",
            "[epoch: 107/100000, batch: 160/1000, ite: 13270] train loss: 2.0058, accuracy: 93.2467%, tar: 0.1082 \n",
            "l0: 0.072877, l1: 0.072842, l2: 0.080481, l3: 0.102020, l4: 0.136793, l5: 0.208412, l6: 0.385795\n",
            "\n",
            "[epoch: 107/100000, batch: 168/1000, ite: 13271] train loss: 2.0054, accuracy: 93.6821%, tar: 0.1082 \n",
            "l0: 0.101367, l1: 0.100582, l2: 0.109218, l3: 0.132862, l4: 0.203058, l5: 0.315104, l6: 0.503818\n",
            "\n",
            "[epoch: 107/100000, batch: 176/1000, ite: 13272] train loss: 2.0054, accuracy: 91.5822%, tar: 0.1082 \n",
            "l0: 0.099248, l1: 0.100583, l2: 0.111856, l3: 0.139125, l4: 0.203848, l5: 0.343234, l6: 0.555601\n",
            "\n",
            "[epoch: 107/100000, batch: 184/1000, ite: 13273] train loss: 2.0054, accuracy: 91.2381%, tar: 0.1082 \n",
            "l0: 0.113712, l1: 0.114740, l2: 0.126150, l3: 0.153151, l4: 0.217081, l5: 0.343011, l6: 0.625853\n",
            "\n",
            "[epoch: 107/100000, batch: 192/1000, ite: 13274] train loss: 2.0057, accuracy: 90.2359%, tar: 0.1082 \n",
            "l0: 0.099467, l1: 0.100730, l2: 0.108016, l3: 0.132406, l4: 0.201107, l5: 0.317421, l6: 0.483225\n",
            "\n",
            "[epoch: 107/100000, batch: 200/1000, ite: 13275] train loss: 2.0056, accuracy: 91.1097%, tar: 0.1082 \n",
            "l0: 0.098405, l1: 0.100636, l2: 0.107533, l3: 0.131407, l4: 0.190814, l5: 0.286625, l6: 0.511014\n",
            "\n",
            "[epoch: 107/100000, batch: 208/1000, ite: 13276] train loss: 2.0056, accuracy: 93.0484%, tar: 0.1081 \n",
            "l0: 0.090027, l1: 0.092177, l2: 0.100094, l3: 0.117887, l4: 0.171685, l5: 0.276998, l6: 0.467666\n",
            "\n",
            "[epoch: 107/100000, batch: 216/1000, ite: 13277] train loss: 2.0054, accuracy: 92.2245%, tar: 0.1081 \n",
            "l0: 0.075200, l1: 0.076225, l2: 0.087452, l3: 0.116046, l4: 0.174946, l5: 0.297046, l6: 0.503904\n",
            "\n",
            "[epoch: 107/100000, batch: 224/1000, ite: 13278] train loss: 2.0053, accuracy: 91.5589%, tar: 0.1081 \n",
            "l0: 0.065076, l1: 0.066341, l2: 0.073896, l3: 0.094604, l4: 0.148808, l5: 0.213596, l6: 0.369604\n",
            "\n",
            "[epoch: 107/100000, batch: 232/1000, ite: 13279] train loss: 2.0048, accuracy: 94.4423%, tar: 0.1081 \n",
            "l0: 0.087161, l1: 0.088494, l2: 0.094691, l3: 0.114516, l4: 0.162198, l5: 0.237140, l6: 0.391764\n",
            "\n",
            "[epoch: 107/100000, batch: 240/1000, ite: 13280] train loss: 2.0045, accuracy: 92.3618%, tar: 0.1081 \n",
            "l0: 0.095795, l1: 0.095854, l2: 0.105264, l3: 0.127904, l4: 0.187610, l5: 0.301800, l6: 0.459504\n",
            "\n",
            "[epoch: 107/100000, batch: 248/1000, ite: 13281] train loss: 2.0043, accuracy: 92.4943%, tar: 0.1080 \n",
            "l0: 0.078254, l1: 0.078131, l2: 0.087335, l3: 0.109012, l4: 0.168542, l5: 0.309842, l6: 0.496823\n",
            "\n",
            "[epoch: 107/100000, batch: 256/1000, ite: 13282] train loss: 2.0042, accuracy: 91.6422%, tar: 0.1080 \n",
            "l0: 0.073911, l1: 0.074591, l2: 0.084842, l3: 0.107450, l4: 0.142806, l5: 0.210798, l6: 0.395627\n",
            "\n",
            "[epoch: 107/100000, batch: 264/1000, ite: 13283] train loss: 2.0038, accuracy: 93.0510%, tar: 0.1080 \n",
            "l0: 0.089048, l1: 0.089391, l2: 0.100080, l3: 0.129786, l4: 0.194289, l5: 0.327060, l6: 0.543901\n",
            "\n",
            "[epoch: 107/100000, batch: 272/1000, ite: 13284] train loss: 2.0038, accuracy: 91.8597%, tar: 0.1080 \n",
            "l0: 0.097604, l1: 0.098171, l2: 0.107993, l3: 0.130826, l4: 0.184803, l5: 0.274721, l6: 0.441888\n",
            "\n",
            "[epoch: 107/100000, batch: 280/1000, ite: 13285] train loss: 2.0037, accuracy: 93.4779%, tar: 0.1080 \n",
            "l0: 0.085929, l1: 0.086398, l2: 0.095364, l3: 0.116704, l4: 0.163514, l5: 0.239869, l6: 0.527626\n",
            "\n",
            "[epoch: 107/100000, batch: 288/1000, ite: 13286] train loss: 2.0035, accuracy: 91.7054%, tar: 0.1080 \n",
            "l0: 0.055103, l1: 0.055178, l2: 0.061963, l3: 0.079308, l4: 0.110932, l5: 0.179874, l6: 0.355515\n",
            "\n",
            "[epoch: 107/100000, batch: 296/1000, ite: 13287] train loss: 2.0030, accuracy: 93.4253%, tar: 0.1079 \n",
            "l0: 0.088313, l1: 0.090098, l2: 0.097245, l3: 0.118260, l4: 0.149221, l5: 0.212368, l6: 0.376169\n",
            "\n",
            "[epoch: 107/100000, batch: 304/1000, ite: 13288] train loss: 2.0026, accuracy: 93.3398%, tar: 0.1079 \n",
            "l0: 0.057649, l1: 0.058780, l2: 0.065406, l3: 0.080095, l4: 0.110460, l5: 0.177157, l6: 0.363046\n",
            "\n",
            "[epoch: 107/100000, batch: 312/1000, ite: 13289] train loss: 2.0020, accuracy: 94.3245%, tar: 0.1079 \n",
            "l0: 0.099816, l1: 0.101096, l2: 0.110209, l3: 0.129891, l4: 0.174774, l5: 0.247505, l6: 0.455847\n",
            "\n",
            "[epoch: 107/100000, batch: 320/1000, ite: 13290] train loss: 2.0018, accuracy: 90.9801%, tar: 0.1079 \n",
            "l0: 0.097502, l1: 0.099876, l2: 0.108030, l3: 0.132571, l4: 0.177891, l5: 0.250710, l6: 0.407137\n",
            "\n",
            "[epoch: 107/100000, batch: 328/1000, ite: 13291] train loss: 2.0016, accuracy: 93.8458%, tar: 0.1078 \n",
            "l0: 0.121674, l1: 0.122088, l2: 0.130021, l3: 0.153873, l4: 0.200747, l5: 0.311084, l6: 0.476310\n",
            "\n",
            "[epoch: 107/100000, batch: 336/1000, ite: 13292] train loss: 2.0016, accuracy: 91.7288%, tar: 0.1079 \n",
            "l0: 0.072167, l1: 0.073506, l2: 0.084274, l3: 0.115357, l4: 0.180558, l5: 0.265554, l6: 0.422858\n",
            "\n",
            "[epoch: 107/100000, batch: 344/1000, ite: 13293] train loss: 2.0013, accuracy: 94.2430%, tar: 0.1078 \n",
            "l0: 0.097554, l1: 0.098567, l2: 0.105344, l3: 0.127337, l4: 0.170822, l5: 0.244976, l6: 0.400001\n",
            "\n",
            "[epoch: 107/100000, batch: 352/1000, ite: 13294] train loss: 2.0010, accuracy: 92.6166%, tar: 0.1078 \n",
            "l0: 0.114792, l1: 0.116012, l2: 0.125512, l3: 0.145536, l4: 0.199123, l5: 0.322456, l6: 0.535110\n",
            "\n",
            "[epoch: 107/100000, batch: 360/1000, ite: 13295] train loss: 2.0011, accuracy: 92.0863%, tar: 0.1078 \n",
            "l0: 0.129365, l1: 0.130858, l2: 0.140278, l3: 0.165943, l4: 0.228014, l5: 0.354031, l6: 0.584371\n",
            "\n",
            "[epoch: 107/100000, batch: 368/1000, ite: 13296] train loss: 2.0013, accuracy: 90.3913%, tar: 0.1078 \n",
            "l0: 0.076142, l1: 0.077810, l2: 0.085790, l3: 0.112877, l4: 0.174515, l5: 0.280835, l6: 0.465639\n",
            "\n",
            "[epoch: 107/100000, batch: 376/1000, ite: 13297] train loss: 2.0011, accuracy: 93.1545%, tar: 0.1078 \n",
            "l0: 0.091399, l1: 0.092644, l2: 0.101052, l3: 0.120057, l4: 0.162689, l5: 0.262811, l6: 0.472415\n",
            "\n",
            "[epoch: 107/100000, batch: 384/1000, ite: 13298] train loss: 2.0010, accuracy: 92.8776%, tar: 0.1078 \n",
            "l0: 0.083910, l1: 0.085283, l2: 0.094256, l3: 0.122445, l4: 0.177840, l5: 0.316753, l6: 0.516822\n",
            "\n",
            "[epoch: 107/100000, batch: 392/1000, ite: 13299] train loss: 2.0009, accuracy: 90.1729%, tar: 0.1078 \n",
            "l0: 0.089845, l1: 0.091622, l2: 0.098764, l3: 0.117969, l4: 0.159772, l5: 0.243740, l6: 0.386709\n",
            "\n",
            "[epoch: 107/100000, batch: 400/1000, ite: 13300] train loss: 2.0006, accuracy: 92.2550%, tar: 0.1078 \n",
            "l0: 0.088261, l1: 0.089426, l2: 0.097250, l3: 0.118388, l4: 0.160937, l5: 0.266032, l6: 0.490193\n",
            "\n",
            "[epoch: 107/100000, batch: 408/1000, ite: 13301] train loss: 2.0004, accuracy: 90.9872%, tar: 0.1078 \n",
            "l0: 0.073338, l1: 0.073694, l2: 0.080980, l3: 0.096824, l4: 0.144230, l5: 0.230187, l6: 0.374293\n",
            "\n",
            "[epoch: 107/100000, batch: 416/1000, ite: 13302] train loss: 2.0000, accuracy: 93.5473%, tar: 0.1077 \n",
            "l0: 0.073965, l1: 0.074880, l2: 0.086678, l3: 0.115343, l4: 0.181101, l5: 0.329310, l6: 0.587611\n",
            "\n",
            "[epoch: 107/100000, batch: 424/1000, ite: 13303] train loss: 2.0000, accuracy: 91.5005%, tar: 0.1077 \n",
            "l0: 0.085910, l1: 0.086637, l2: 0.096089, l3: 0.115869, l4: 0.154350, l5: 0.237770, l6: 0.437647\n",
            "\n",
            "[epoch: 107/100000, batch: 432/1000, ite: 13304] train loss: 1.9998, accuracy: 93.1917%, tar: 0.1077 \n",
            "l0: 0.097493, l1: 0.097940, l2: 0.109515, l3: 0.144127, l4: 0.229199, l5: 0.373392, l6: 0.585818\n",
            "\n",
            "[epoch: 107/100000, batch: 440/1000, ite: 13305] train loss: 1.9999, accuracy: 90.2332%, tar: 0.1077 \n",
            "l0: 0.078314, l1: 0.079828, l2: 0.087326, l3: 0.106918, l4: 0.148547, l5: 0.241917, l6: 0.399987\n",
            "\n",
            "[epoch: 107/100000, batch: 448/1000, ite: 13306] train loss: 1.9996, accuracy: 93.1424%, tar: 0.1077 \n",
            "l0: 0.067836, l1: 0.069212, l2: 0.076901, l3: 0.097441, l4: 0.128900, l5: 0.181723, l6: 0.332526\n",
            "\n",
            "[epoch: 107/100000, batch: 456/1000, ite: 13307] train loss: 1.9991, accuracy: 94.2103%, tar: 0.1076 \n",
            "l0: 0.098897, l1: 0.099952, l2: 0.111393, l3: 0.139345, l4: 0.197078, l5: 0.311285, l6: 0.598411\n",
            "\n",
            "[epoch: 107/100000, batch: 464/1000, ite: 13308] train loss: 1.9992, accuracy: 91.4195%, tar: 0.1076 \n",
            "l0: 0.080730, l1: 0.081891, l2: 0.090774, l3: 0.114274, l4: 0.165195, l5: 0.244247, l6: 0.418012\n",
            "\n",
            "[epoch: 107/100000, batch: 472/1000, ite: 13309] train loss: 1.9989, accuracy: 92.4768%, tar: 0.1076 \n",
            "l0: 0.072992, l1: 0.074205, l2: 0.082043, l3: 0.100021, l4: 0.145785, l5: 0.255083, l6: 0.423489\n",
            "\n",
            "[epoch: 107/100000, batch: 480/1000, ite: 13310] train loss: 1.9986, accuracy: 92.1244%, tar: 0.1076 \n",
            "l0: 0.088866, l1: 0.089493, l2: 0.096748, l3: 0.116982, l4: 0.151836, l5: 0.225856, l6: 0.377740\n",
            "\n",
            "[epoch: 107/100000, batch: 488/1000, ite: 13311] train loss: 1.9982, accuracy: 92.6937%, tar: 0.1076 \n",
            "l0: 0.088584, l1: 0.090008, l2: 0.101908, l3: 0.124780, l4: 0.173031, l5: 0.293105, l6: 0.591729\n",
            "\n",
            "[epoch: 107/100000, batch: 496/1000, ite: 13312] train loss: 1.9982, accuracy: 90.0717%, tar: 0.1075 \n",
            "l0: 0.094907, l1: 0.097184, l2: 0.108451, l3: 0.130587, l4: 0.178818, l5: 0.284605, l6: 0.485544\n",
            "\n",
            "[epoch: 107/100000, batch: 504/1000, ite: 13313] train loss: 1.9981, accuracy: 92.5803%, tar: 0.1075 \n",
            "l0: 0.110689, l1: 0.111827, l2: 0.122592, l3: 0.147486, l4: 0.200568, l5: 0.269920, l6: 0.402437\n",
            "\n",
            "[epoch: 107/100000, batch: 512/1000, ite: 13314] train loss: 1.9980, accuracy: 92.3868%, tar: 0.1075 \n",
            "l0: 0.084201, l1: 0.084506, l2: 0.091952, l3: 0.113986, l4: 0.153752, l5: 0.269748, l6: 0.501073\n",
            "\n",
            "[epoch: 107/100000, batch: 520/1000, ite: 13315] train loss: 1.9978, accuracy: 91.1957%, tar: 0.1075 \n",
            "l0: 0.107807, l1: 0.110144, l2: 0.118765, l3: 0.142764, l4: 0.189888, l5: 0.272363, l6: 0.455873\n",
            "\n",
            "[epoch: 107/100000, batch: 528/1000, ite: 13316] train loss: 1.9977, accuracy: 92.1624%, tar: 0.1075 \n",
            "l0: 0.065946, l1: 0.066417, l2: 0.076084, l3: 0.103212, l4: 0.168889, l5: 0.293606, l6: 0.522684\n",
            "\n",
            "[epoch: 107/100000, batch: 536/1000, ite: 13317] train loss: 1.9976, accuracy: 92.3675%, tar: 0.1075 \n",
            "l0: 0.118567, l1: 0.119215, l2: 0.127309, l3: 0.152250, l4: 0.213042, l5: 0.334952, l6: 0.556204\n",
            "\n",
            "[epoch: 107/100000, batch: 544/1000, ite: 13318] train loss: 1.9977, accuracy: 91.0678%, tar: 0.1075 \n",
            "l0: 0.093029, l1: 0.094553, l2: 0.104392, l3: 0.135559, l4: 0.218139, l5: 0.399909, l6: 0.665749\n",
            "\n",
            "[epoch: 107/100000, batch: 552/1000, ite: 13319] train loss: 1.9980, accuracy: 89.9596%, tar: 0.1075 \n",
            "l0: 0.104767, l1: 0.104800, l2: 0.114468, l3: 0.140632, l4: 0.192740, l5: 0.305706, l6: 0.568198\n",
            "\n",
            "[epoch: 107/100000, batch: 560/1000, ite: 13320] train loss: 1.9981, accuracy: 90.0283%, tar: 0.1075 \n",
            "l0: 0.111896, l1: 0.112291, l2: 0.123900, l3: 0.150434, l4: 0.206071, l5: 0.321071, l6: 0.590667\n",
            "\n",
            "[epoch: 107/100000, batch: 568/1000, ite: 13321] train loss: 1.9982, accuracy: 91.0796%, tar: 0.1075 \n",
            "l0: 0.085705, l1: 0.086107, l2: 0.094480, l3: 0.115738, l4: 0.153845, l5: 0.229850, l6: 0.380189\n",
            "\n",
            "[epoch: 107/100000, batch: 576/1000, ite: 13322] train loss: 1.9979, accuracy: 94.0222%, tar: 0.1075 \n",
            "l0: 0.079477, l1: 0.081302, l2: 0.091210, l3: 0.114082, l4: 0.172605, l5: 0.289136, l6: 0.476560\n",
            "\n",
            "[epoch: 107/100000, batch: 584/1000, ite: 13323] train loss: 1.9977, accuracy: 91.7292%, tar: 0.1074 \n",
            "l0: 0.089075, l1: 0.089967, l2: 0.097666, l3: 0.122323, l4: 0.166689, l5: 0.267958, l6: 0.590563\n",
            "\n",
            "[epoch: 107/100000, batch: 592/1000, ite: 13324] train loss: 1.9978, accuracy: 91.3347%, tar: 0.1074 \n",
            "l0: 0.094791, l1: 0.096816, l2: 0.104937, l3: 0.120546, l4: 0.172753, l5: 0.258546, l6: 0.434782\n",
            "\n",
            "[epoch: 107/100000, batch: 600/1000, ite: 13325] train loss: 1.9975, accuracy: 91.6806%, tar: 0.1074 \n",
            "l0: 0.065176, l1: 0.067407, l2: 0.078204, l3: 0.099705, l4: 0.136914, l5: 0.218791, l6: 0.394227\n",
            "\n",
            "[epoch: 107/100000, batch: 608/1000, ite: 13326] train loss: 1.9971, accuracy: 92.5366%, tar: 0.1074 \n",
            "l0: 0.087883, l1: 0.089849, l2: 0.096836, l3: 0.117368, l4: 0.158825, l5: 0.251834, l6: 0.412172\n",
            "\n",
            "[epoch: 107/100000, batch: 616/1000, ite: 13327] train loss: 1.9968, accuracy: 93.2278%, tar: 0.1074 \n",
            "l0: 0.095515, l1: 0.095559, l2: 0.105700, l3: 0.137537, l4: 0.203865, l5: 0.305291, l6: 0.524746\n",
            "\n",
            "[epoch: 107/100000, batch: 624/1000, ite: 13328] train loss: 1.9969, accuracy: 92.1446%, tar: 0.1074 \n",
            "l0: 0.067289, l1: 0.067450, l2: 0.077835, l3: 0.094212, l4: 0.150576, l5: 0.281067, l6: 0.532041\n",
            "\n",
            "[epoch: 107/100000, batch: 632/1000, ite: 13329] train loss: 1.9967, accuracy: 92.8729%, tar: 0.1073 \n",
            "l0: 0.082102, l1: 0.083342, l2: 0.092467, l3: 0.120685, l4: 0.166709, l5: 0.256504, l6: 0.374182\n",
            "\n",
            "[epoch: 107/100000, batch: 640/1000, ite: 13330] train loss: 1.9964, accuracy: 92.9786%, tar: 0.1073 \n",
            "l0: 0.112606, l1: 0.114290, l2: 0.123328, l3: 0.145613, l4: 0.207821, l5: 0.321534, l6: 0.532899\n",
            "\n",
            "[epoch: 107/100000, batch: 648/1000, ite: 13331] train loss: 1.9964, accuracy: 91.2211%, tar: 0.1073 \n",
            "l0: 0.107216, l1: 0.108204, l2: 0.121206, l3: 0.150079, l4: 0.225197, l5: 0.371517, l6: 0.602666\n",
            "\n",
            "[epoch: 107/100000, batch: 656/1000, ite: 13332] train loss: 1.9966, accuracy: 90.4188%, tar: 0.1073 \n",
            "l0: 0.063113, l1: 0.063660, l2: 0.071717, l3: 0.086925, l4: 0.130824, l5: 0.189738, l6: 0.332419\n",
            "\n",
            "[epoch: 107/100000, batch: 664/1000, ite: 13333] train loss: 1.9961, accuracy: 94.7409%, tar: 0.1073 \n",
            "l0: 0.101455, l1: 0.101020, l2: 0.108034, l3: 0.131613, l4: 0.189253, l5: 0.289755, l6: 0.463083\n",
            "\n",
            "[epoch: 107/100000, batch: 672/1000, ite: 13334] train loss: 1.9960, accuracy: 92.3016%, tar: 0.1073 \n",
            "l0: 0.088600, l1: 0.089018, l2: 0.102482, l3: 0.135970, l4: 0.202166, l5: 0.339858, l6: 0.617180\n",
            "\n",
            "[epoch: 107/100000, batch: 680/1000, ite: 13335] train loss: 1.9961, accuracy: 91.2391%, tar: 0.1073 \n",
            "l0: 0.099111, l1: 0.099736, l2: 0.109463, l3: 0.139755, l4: 0.195404, l5: 0.282383, l6: 0.582239\n",
            "\n",
            "[epoch: 107/100000, batch: 688/1000, ite: 13336] train loss: 1.9962, accuracy: 91.8456%, tar: 0.1073 \n",
            "l0: 0.081872, l1: 0.084324, l2: 0.093677, l3: 0.118760, l4: 0.156890, l5: 0.253125, l6: 0.460867\n",
            "\n",
            "[epoch: 107/100000, batch: 696/1000, ite: 13337] train loss: 1.9960, accuracy: 92.8182%, tar: 0.1072 \n",
            "l0: 0.063625, l1: 0.065949, l2: 0.072286, l3: 0.090022, l4: 0.131883, l5: 0.210839, l6: 0.423061\n",
            "\n",
            "[epoch: 107/100000, batch: 704/1000, ite: 13338] train loss: 1.9956, accuracy: 92.4132%, tar: 0.1072 \n",
            "l0: 0.091427, l1: 0.091692, l2: 0.101330, l3: 0.121403, l4: 0.169042, l5: 0.260004, l6: 0.534799\n",
            "\n",
            "[epoch: 107/100000, batch: 712/1000, ite: 13339] train loss: 1.9956, accuracy: 91.1145%, tar: 0.1072 \n",
            "l0: 0.073758, l1: 0.074593, l2: 0.082359, l3: 0.101141, l4: 0.153121, l5: 0.226164, l6: 0.386990\n",
            "\n",
            "[epoch: 107/100000, batch: 720/1000, ite: 13340] train loss: 1.9952, accuracy: 93.6196%, tar: 0.1072 \n",
            "l0: 0.091683, l1: 0.092767, l2: 0.100438, l3: 0.121737, l4: 0.181294, l5: 0.291933, l6: 0.493314\n",
            "\n",
            "[epoch: 107/100000, batch: 728/1000, ite: 13341] train loss: 1.9951, accuracy: 92.4451%, tar: 0.1072 \n",
            "l0: 0.095807, l1: 0.097008, l2: 0.106830, l3: 0.133049, l4: 0.182368, l5: 0.303921, l6: 0.497800\n",
            "\n",
            "[epoch: 107/100000, batch: 736/1000, ite: 13342] train loss: 1.9951, accuracy: 90.9836%, tar: 0.1072 \n",
            "l0: 0.081755, l1: 0.082357, l2: 0.089451, l3: 0.106748, l4: 0.142935, l5: 0.221883, l6: 0.379773\n",
            "\n",
            "[epoch: 107/100000, batch: 744/1000, ite: 13343] train loss: 1.9947, accuracy: 93.0882%, tar: 0.1071 \n",
            "l0: 0.092874, l1: 0.094005, l2: 0.103078, l3: 0.130656, l4: 0.198049, l5: 0.338837, l6: 0.572536\n",
            "\n",
            "[epoch: 107/100000, batch: 752/1000, ite: 13344] train loss: 1.9948, accuracy: 91.3870%, tar: 0.1071 \n",
            "l0: 0.090776, l1: 0.091788, l2: 0.101272, l3: 0.127445, l4: 0.191423, l5: 0.329813, l6: 0.574351\n",
            "\n",
            "[epoch: 107/100000, batch: 760/1000, ite: 13345] train loss: 1.9948, accuracy: 91.3027%, tar: 0.1071 \n",
            "l0: 0.111220, l1: 0.111296, l2: 0.122432, l3: 0.150669, l4: 0.209286, l5: 0.348297, l6: 0.556477\n",
            "\n",
            "[epoch: 107/100000, batch: 768/1000, ite: 13346] train loss: 1.9949, accuracy: 91.1587%, tar: 0.1071 \n",
            "l0: 0.143413, l1: 0.144185, l2: 0.155007, l3: 0.178139, l4: 0.241519, l5: 0.353219, l6: 0.525517\n",
            "\n",
            "[epoch: 107/100000, batch: 776/1000, ite: 13347] train loss: 1.9952, accuracy: 91.1472%, tar: 0.1071 \n",
            "l0: 0.070107, l1: 0.071813, l2: 0.085655, l3: 0.110098, l4: 0.155486, l5: 0.267226, l6: 0.465934\n",
            "\n",
            "[epoch: 107/100000, batch: 784/1000, ite: 13348] train loss: 1.9949, accuracy: 92.9306%, tar: 0.1071 \n",
            "l0: 0.068035, l1: 0.069258, l2: 0.077642, l3: 0.098000, l4: 0.136657, l5: 0.227236, l6: 0.389891\n",
            "\n",
            "[epoch: 107/100000, batch: 792/1000, ite: 13349] train loss: 1.9946, accuracy: 94.0480%, tar: 0.1071 \n",
            "l0: 0.103257, l1: 0.104497, l2: 0.110081, l3: 0.129132, l4: 0.176172, l5: 0.268002, l6: 0.446110\n",
            "\n",
            "[epoch: 107/100000, batch: 800/1000, ite: 13350] train loss: 1.9944, accuracy: 92.9494%, tar: 0.1071 \n",
            "l0: 0.095126, l1: 0.095945, l2: 0.107293, l3: 0.132391, l4: 0.184453, l5: 0.315930, l6: 0.467466\n",
            "\n",
            "[epoch: 107/100000, batch: 808/1000, ite: 13351] train loss: 1.9943, accuracy: 92.9777%, tar: 0.1071 \n",
            "l0: 0.085154, l1: 0.086199, l2: 0.094284, l3: 0.111058, l4: 0.155637, l5: 0.238661, l6: 0.396821\n",
            "\n",
            "[epoch: 107/100000, batch: 816/1000, ite: 13352] train loss: 1.9940, accuracy: 92.7340%, tar: 0.1071 \n",
            "l0: 0.098070, l1: 0.099339, l2: 0.109414, l3: 0.140404, l4: 0.214145, l5: 0.352964, l6: 0.549662\n",
            "\n",
            "[epoch: 107/100000, batch: 824/1000, ite: 13353] train loss: 1.9941, accuracy: 92.0278%, tar: 0.1071 \n",
            "l0: 0.087281, l1: 0.088630, l2: 0.099422, l3: 0.124687, l4: 0.187174, l5: 0.279042, l6: 0.455795\n",
            "\n",
            "[epoch: 107/100000, batch: 832/1000, ite: 13354] train loss: 1.9939, accuracy: 91.4530%, tar: 0.1070 \n",
            "l0: 0.096684, l1: 0.097766, l2: 0.109887, l3: 0.138437, l4: 0.211585, l5: 0.385015, l6: 0.665951\n",
            "\n",
            "[epoch: 107/100000, batch: 840/1000, ite: 13355] train loss: 1.9942, accuracy: 90.3744%, tar: 0.1070 \n",
            "l0: 0.074842, l1: 0.075353, l2: 0.082151, l3: 0.103248, l4: 0.150819, l5: 0.247792, l6: 0.408668\n",
            "\n",
            "[epoch: 107/100000, batch: 848/1000, ite: 13356] train loss: 1.9939, accuracy: 92.4206%, tar: 0.1070 \n",
            "l0: 0.063272, l1: 0.063468, l2: 0.075261, l3: 0.097504, l4: 0.143121, l5: 0.248910, l6: 0.438715\n",
            "\n",
            "[epoch: 107/100000, batch: 856/1000, ite: 13357] train loss: 1.9936, accuracy: 93.3522%, tar: 0.1070 \n",
            "l0: 0.083267, l1: 0.085540, l2: 0.094904, l3: 0.114642, l4: 0.156462, l5: 0.222976, l6: 0.398375\n",
            "\n",
            "[epoch: 107/100000, batch: 864/1000, ite: 13358] train loss: 1.9933, accuracy: 92.5079%, tar: 0.1070 \n",
            "l0: 0.145163, l1: 0.148283, l2: 0.161363, l3: 0.194544, l4: 0.274709, l5: 0.425460, l6: 0.640465\n",
            "\n",
            "[epoch: 107/100000, batch: 872/1000, ite: 13359] train loss: 1.9937, accuracy: 89.1737%, tar: 0.1070 \n",
            "l0: 0.092918, l1: 0.094511, l2: 0.102119, l3: 0.130211, l4: 0.198788, l5: 0.348771, l6: 0.591134\n",
            "\n",
            "[epoch: 107/100000, batch: 880/1000, ite: 13360] train loss: 1.9938, accuracy: 92.1891%, tar: 0.1070 \n",
            "l0: 0.095065, l1: 0.096537, l2: 0.104922, l3: 0.125140, l4: 0.166727, l5: 0.246077, l6: 0.418667\n",
            "\n",
            "[epoch: 107/100000, batch: 888/1000, ite: 13361] train loss: 1.9936, accuracy: 92.3391%, tar: 0.1070 \n",
            "l0: 0.071385, l1: 0.072120, l2: 0.078358, l3: 0.092048, l4: 0.122064, l5: 0.175357, l6: 0.320554\n",
            "\n",
            "[epoch: 107/100000, batch: 896/1000, ite: 13362] train loss: 1.9931, accuracy: 94.1039%, tar: 0.1069 \n",
            "l0: 0.082059, l1: 0.083014, l2: 0.091738, l3: 0.114609, l4: 0.172101, l5: 0.270170, l6: 0.547015\n",
            "\n",
            "[epoch: 107/100000, batch: 904/1000, ite: 13363] train loss: 1.9930, accuracy: 91.8840%, tar: 0.1069 \n",
            "l0: 0.080841, l1: 0.082582, l2: 0.095049, l3: 0.127049, l4: 0.196128, l5: 0.303063, l6: 0.522223\n",
            "\n",
            "[epoch: 107/100000, batch: 912/1000, ite: 13364] train loss: 1.9930, accuracy: 91.5591%, tar: 0.1069 \n",
            "l0: 0.132025, l1: 0.132808, l2: 0.141555, l3: 0.167160, l4: 0.225658, l5: 0.302225, l6: 0.475650\n",
            "\n",
            "[epoch: 107/100000, batch: 920/1000, ite: 13365] train loss: 1.9930, accuracy: 90.8016%, tar: 0.1069 \n",
            "l0: 0.097960, l1: 0.100309, l2: 0.107170, l3: 0.130950, l4: 0.181092, l5: 0.268791, l6: 0.458215\n",
            "\n",
            "[epoch: 107/100000, batch: 928/1000, ite: 13366] train loss: 1.9929, accuracy: 92.1463%, tar: 0.1069 \n",
            "l0: 0.131304, l1: 0.131109, l2: 0.143449, l3: 0.176791, l4: 0.248823, l5: 0.387360, l6: 0.549305\n",
            "\n",
            "[epoch: 107/100000, batch: 936/1000, ite: 13367] train loss: 1.9931, accuracy: 89.7386%, tar: 0.1069 \n",
            "l0: 0.099102, l1: 0.100634, l2: 0.108630, l3: 0.129258, l4: 0.173236, l5: 0.270901, l6: 0.442509\n",
            "\n",
            "[epoch: 107/100000, batch: 944/1000, ite: 13368] train loss: 1.9930, accuracy: 92.6837%, tar: 0.1069 \n",
            "l0: 0.110290, l1: 0.110904, l2: 0.120999, l3: 0.147596, l4: 0.198636, l5: 0.283475, l6: 0.523821\n",
            "\n",
            "[epoch: 107/100000, batch: 952/1000, ite: 13369] train loss: 1.9930, accuracy: 90.7927%, tar: 0.1069 \n",
            "l0: 0.082437, l1: 0.082939, l2: 0.095346, l3: 0.125410, l4: 0.200773, l5: 0.320570, l6: 0.603582\n",
            "\n",
            "[epoch: 107/100000, batch: 960/1000, ite: 13370] train loss: 1.9930, accuracy: 91.5347%, tar: 0.1069 \n",
            "l0: 0.100804, l1: 0.102006, l2: 0.117315, l3: 0.164037, l4: 0.268440, l5: 0.527495, l6: 0.742455\n",
            "\n",
            "[epoch: 107/100000, batch: 968/1000, ite: 13371] train loss: 1.9936, accuracy: 90.0225%, tar: 0.1069 \n",
            "l0: 0.121108, l1: 0.123062, l2: 0.132474, l3: 0.161562, l4: 0.240814, l5: 0.354000, l6: 0.579819\n",
            "\n",
            "[epoch: 107/100000, batch: 976/1000, ite: 13372] train loss: 1.9938, accuracy: 89.4253%, tar: 0.1069 \n",
            "l0: 0.109782, l1: 0.110411, l2: 0.122376, l3: 0.146318, l4: 0.194421, l5: 0.276346, l6: 0.490983\n",
            "\n",
            "[epoch: 107/100000, batch: 984/1000, ite: 13373] train loss: 1.9938, accuracy: 90.9207%, tar: 0.1069 \n",
            "l0: 0.117903, l1: 0.119685, l2: 0.130185, l3: 0.152796, l4: 0.206262, l5: 0.290097, l6: 0.485324\n",
            "\n",
            "[epoch: 107/100000, batch: 992/1000, ite: 13374] train loss: 1.9938, accuracy: 92.2523%, tar: 0.1069 \n",
            "l0: 0.068339, l1: 0.068864, l2: 0.077181, l3: 0.092516, l4: 0.131436, l5: 0.215090, l6: 0.365626\n",
            "\n",
            "[epoch: 107/100000, batch: 1000/1000, ite: 13375] train loss: 1.9933, accuracy: 93.3589%, tar: 0.1069 \n",
            "l0: 0.085791, l1: 0.087039, l2: 0.097137, l3: 0.123578, l4: 0.175446, l5: 0.286130, l6: 0.504012\n",
            "\n",
            "[epoch: 108/100000, batch: 8/1000, ite: 13376] train loss: 1.9932, accuracy: 92.1109%, tar: 0.1069 \n",
            "l0: 0.106678, l1: 0.107061, l2: 0.114980, l3: 0.128040, l4: 0.159490, l5: 0.247954, l6: 0.424283\n",
            "\n",
            "[epoch: 108/100000, batch: 16/1000, ite: 13377] train loss: 1.9931, accuracy: 92.7647%, tar: 0.1069 \n",
            "l0: 0.071175, l1: 0.072322, l2: 0.080016, l3: 0.094803, l4: 0.133523, l5: 0.203893, l6: 0.347610\n",
            "\n",
            "[epoch: 108/100000, batch: 24/1000, ite: 13378] train loss: 1.9926, accuracy: 93.6592%, tar: 0.1069 \n",
            "l0: 0.115726, l1: 0.116478, l2: 0.124808, l3: 0.151678, l4: 0.206979, l5: 0.302393, l6: 0.496664\n",
            "\n",
            "[epoch: 108/100000, batch: 32/1000, ite: 13379] train loss: 1.9926, accuracy: 92.3849%, tar: 0.1069 \n",
            "l0: 0.114130, l1: 0.115253, l2: 0.122651, l3: 0.143310, l4: 0.195868, l5: 0.274031, l6: 0.462944\n",
            "\n",
            "[epoch: 108/100000, batch: 40/1000, ite: 13380] train loss: 1.9925, accuracy: 92.0844%, tar: 0.1069 \n",
            "l0: 0.099642, l1: 0.100386, l2: 0.109278, l3: 0.137787, l4: 0.186748, l5: 0.270314, l6: 0.464933\n",
            "\n",
            "[epoch: 108/100000, batch: 48/1000, ite: 13381] train loss: 1.9924, accuracy: 92.7209%, tar: 0.1069 \n",
            "l0: 0.093936, l1: 0.095870, l2: 0.104619, l3: 0.127088, l4: 0.169381, l5: 0.285007, l6: 0.449957\n",
            "\n",
            "[epoch: 108/100000, batch: 56/1000, ite: 13382] train loss: 1.9922, accuracy: 92.6032%, tar: 0.1069 \n",
            "l0: 0.103199, l1: 0.104897, l2: 0.113914, l3: 0.140485, l4: 0.201195, l5: 0.334331, l6: 0.598016\n",
            "\n",
            "[epoch: 108/100000, batch: 64/1000, ite: 13383] train loss: 1.9924, accuracy: 89.8392%, tar: 0.1069 \n",
            "l0: 0.099485, l1: 0.101199, l2: 0.115556, l3: 0.141787, l4: 0.207273, l5: 0.315103, l6: 0.517536\n",
            "\n",
            "[epoch: 108/100000, batch: 72/1000, ite: 13384] train loss: 1.9924, accuracy: 91.5171%, tar: 0.1069 \n",
            "l0: 0.114390, l1: 0.114234, l2: 0.126020, l3: 0.150550, l4: 0.215586, l5: 0.356929, l6: 0.643508\n",
            "\n",
            "[epoch: 108/100000, batch: 80/1000, ite: 13385] train loss: 1.9927, accuracy: 90.9797%, tar: 0.1069 \n",
            "l0: 0.054474, l1: 0.055953, l2: 0.063572, l3: 0.078479, l4: 0.126128, l5: 0.218860, l6: 0.363099\n",
            "\n",
            "[epoch: 108/100000, batch: 88/1000, ite: 13386] train loss: 1.9922, accuracy: 94.7514%, tar: 0.1068 \n",
            "l0: 0.112782, l1: 0.114402, l2: 0.121931, l3: 0.141598, l4: 0.176906, l5: 0.256418, l6: 0.449076\n",
            "\n",
            "[epoch: 108/100000, batch: 96/1000, ite: 13387] train loss: 1.9921, accuracy: 91.1364%, tar: 0.1068 \n",
            "l0: 0.089022, l1: 0.090304, l2: 0.100464, l3: 0.122056, l4: 0.173612, l5: 0.278074, l6: 0.494004\n",
            "\n",
            "[epoch: 108/100000, batch: 104/1000, ite: 13388] train loss: 1.9920, accuracy: 91.5398%, tar: 0.1068 \n",
            "l0: 0.083693, l1: 0.085069, l2: 0.094440, l3: 0.119125, l4: 0.166038, l5: 0.258428, l6: 0.381087\n",
            "\n",
            "[epoch: 108/100000, batch: 112/1000, ite: 13389] train loss: 1.9917, accuracy: 92.7246%, tar: 0.1068 \n",
            "l0: 0.077279, l1: 0.077708, l2: 0.083839, l3: 0.109442, l4: 0.155502, l5: 0.245522, l6: 0.417833\n",
            "\n",
            "[epoch: 108/100000, batch: 120/1000, ite: 13390] train loss: 1.9914, accuracy: 93.6423%, tar: 0.1068 \n",
            "l0: 0.098168, l1: 0.099446, l2: 0.110633, l3: 0.130235, l4: 0.185789, l5: 0.283527, l6: 0.482613\n",
            "\n",
            "[epoch: 108/100000, batch: 128/1000, ite: 13391] train loss: 1.9913, accuracy: 91.6560%, tar: 0.1068 \n",
            "l0: 0.088621, l1: 0.089453, l2: 0.097521, l3: 0.118203, l4: 0.179000, l5: 0.295115, l6: 0.538143\n",
            "\n",
            "[epoch: 108/100000, batch: 136/1000, ite: 13392] train loss: 1.9913, accuracy: 91.8871%, tar: 0.1068 \n",
            "l0: 0.091082, l1: 0.092147, l2: 0.101289, l3: 0.126393, l4: 0.170207, l5: 0.275700, l6: 0.441724\n",
            "\n",
            "[epoch: 108/100000, batch: 144/1000, ite: 13393] train loss: 1.9911, accuracy: 92.3722%, tar: 0.1067 \n",
            "l0: 0.091190, l1: 0.092468, l2: 0.103902, l3: 0.129639, l4: 0.183007, l5: 0.309685, l6: 0.518479\n",
            "\n",
            "[epoch: 108/100000, batch: 152/1000, ite: 13394] train loss: 1.9911, accuracy: 91.4499%, tar: 0.1067 \n",
            "l0: 0.076575, l1: 0.077461, l2: 0.085714, l3: 0.110943, l4: 0.186763, l5: 0.289125, l6: 0.491025\n",
            "\n",
            "[epoch: 108/100000, batch: 160/1000, ite: 13395] train loss: 1.9910, accuracy: 92.5574%, tar: 0.1067 \n",
            "l0: 0.100694, l1: 0.101814, l2: 0.108645, l3: 0.126420, l4: 0.168379, l5: 0.256995, l6: 0.483618\n",
            "\n",
            "[epoch: 108/100000, batch: 168/1000, ite: 13396] train loss: 1.9908, accuracy: 91.3371%, tar: 0.1067 \n",
            "l0: 0.083415, l1: 0.084954, l2: 0.094990, l3: 0.115391, l4: 0.161614, l5: 0.263876, l6: 0.463055\n",
            "\n",
            "[epoch: 108/100000, batch: 176/1000, ite: 13397] train loss: 1.9907, accuracy: 91.3927%, tar: 0.1067 \n",
            "l0: 0.075586, l1: 0.076446, l2: 0.084628, l3: 0.110572, l4: 0.159907, l5: 0.252778, l6: 0.483422\n",
            "\n",
            "[epoch: 108/100000, batch: 184/1000, ite: 13398] train loss: 1.9905, accuracy: 92.7705%, tar: 0.1067 \n",
            "l0: 0.114004, l1: 0.115772, l2: 0.128831, l3: 0.160444, l4: 0.240658, l5: 0.392021, l6: 0.634845\n",
            "\n",
            "[epoch: 108/100000, batch: 192/1000, ite: 13399] train loss: 1.9908, accuracy: 88.7993%, tar: 0.1067 \n",
            "l0: 0.063728, l1: 0.064415, l2: 0.074960, l3: 0.096895, l4: 0.141063, l5: 0.198589, l6: 0.356730\n",
            "\n",
            "[epoch: 108/100000, batch: 200/1000, ite: 13400] train loss: 1.9903, accuracy: 94.2513%, tar: 0.1066 \n",
            "l0: 0.084062, l1: 0.084686, l2: 0.093499, l3: 0.110331, l4: 0.155745, l5: 0.265811, l6: 0.474902\n",
            "\n",
            "[epoch: 108/100000, batch: 208/1000, ite: 13401] train loss: 1.9902, accuracy: 92.2949%, tar: 0.1066 \n",
            "l0: 0.071303, l1: 0.072141, l2: 0.083911, l3: 0.113510, l4: 0.171578, l5: 0.279843, l6: 0.475963\n",
            "\n",
            "[epoch: 108/100000, batch: 216/1000, ite: 13402] train loss: 1.9900, accuracy: 91.9486%, tar: 0.1066 \n",
            "l0: 0.076700, l1: 0.077908, l2: 0.089256, l3: 0.112565, l4: 0.176139, l5: 0.283927, l6: 0.537953\n",
            "\n",
            "[epoch: 108/100000, batch: 224/1000, ite: 13403] train loss: 1.9899, accuracy: 91.8529%, tar: 0.1066 \n",
            "l0: 0.118261, l1: 0.119826, l2: 0.129409, l3: 0.150518, l4: 0.205471, l5: 0.333358, l6: 0.555488\n",
            "\n",
            "[epoch: 108/100000, batch: 232/1000, ite: 13404] train loss: 1.9901, accuracy: 90.8813%, tar: 0.1066 \n",
            "l0: 0.060265, l1: 0.060371, l2: 0.067554, l3: 0.079976, l4: 0.109366, l5: 0.167192, l6: 0.298624\n",
            "\n",
            "[epoch: 108/100000, batch: 240/1000, ite: 13405] train loss: 1.9895, accuracy: 94.8624%, tar: 0.1066 \n",
            "l0: 0.074896, l1: 0.076880, l2: 0.088124, l3: 0.121454, l4: 0.189623, l5: 0.333191, l6: 0.579396\n",
            "\n",
            "[epoch: 108/100000, batch: 248/1000, ite: 13406] train loss: 1.9895, accuracy: 93.1092%, tar: 0.1065 \n",
            "l0: 0.068137, l1: 0.069227, l2: 0.081452, l3: 0.108809, l4: 0.160669, l5: 0.262147, l6: 0.440606\n",
            "\n",
            "[epoch: 108/100000, batch: 256/1000, ite: 13407] train loss: 1.9892, accuracy: 92.8190%, tar: 0.1065 \n",
            "l0: 0.064802, l1: 0.065062, l2: 0.072760, l3: 0.087650, l4: 0.124495, l5: 0.219441, l6: 0.392208\n",
            "\n",
            "[epoch: 108/100000, batch: 264/1000, ite: 13408] train loss: 1.9888, accuracy: 92.6843%, tar: 0.1065 \n",
            "l0: 0.114613, l1: 0.115078, l2: 0.122481, l3: 0.145993, l4: 0.201416, l5: 0.296407, l6: 0.475354\n",
            "\n",
            "[epoch: 108/100000, batch: 272/1000, ite: 13409] train loss: 1.9888, accuracy: 93.5792%, tar: 0.1065 \n",
            "l0: 0.099744, l1: 0.100811, l2: 0.107629, l3: 0.129219, l4: 0.175240, l5: 0.268209, l6: 0.516731\n",
            "\n",
            "[epoch: 108/100000, batch: 280/1000, ite: 13410] train loss: 1.9888, accuracy: 92.1588%, tar: 0.1065 \n",
            "l0: 0.101388, l1: 0.101802, l2: 0.109403, l3: 0.128658, l4: 0.179638, l5: 0.263823, l6: 0.481599\n",
            "\n",
            "[epoch: 108/100000, batch: 288/1000, ite: 13411] train loss: 1.9887, accuracy: 91.8632%, tar: 0.1065 \n",
            "l0: 0.074708, l1: 0.075951, l2: 0.084645, l3: 0.109127, l4: 0.156968, l5: 0.252910, l6: 0.438139\n",
            "\n",
            "[epoch: 108/100000, batch: 296/1000, ite: 13412] train loss: 1.9884, accuracy: 92.3286%, tar: 0.1064 \n",
            "l0: 0.141197, l1: 0.142604, l2: 0.152670, l3: 0.177245, l4: 0.235902, l5: 0.341465, l6: 0.495545\n",
            "\n",
            "[epoch: 108/100000, batch: 304/1000, ite: 13413] train loss: 1.9885, accuracy: 91.2751%, tar: 0.1065 \n",
            "l0: 0.089460, l1: 0.090796, l2: 0.098708, l3: 0.123751, l4: 0.183128, l5: 0.331717, l6: 0.590259\n",
            "\n",
            "[epoch: 108/100000, batch: 312/1000, ite: 13414] train loss: 1.9886, accuracy: 89.9076%, tar: 0.1065 \n",
            "l0: 0.090478, l1: 0.091264, l2: 0.100511, l3: 0.124622, l4: 0.167467, l5: 0.244504, l6: 0.438753\n",
            "\n",
            "[epoch: 108/100000, batch: 320/1000, ite: 13415] train loss: 1.9884, accuracy: 92.0543%, tar: 0.1064 \n",
            "l0: 0.077751, l1: 0.079316, l2: 0.090508, l3: 0.117001, l4: 0.172044, l5: 0.296579, l6: 0.516650\n",
            "\n",
            "[epoch: 108/100000, batch: 328/1000, ite: 13416] train loss: 1.9883, accuracy: 92.1957%, tar: 0.1064 \n",
            "l0: 0.092803, l1: 0.092886, l2: 0.100515, l3: 0.119385, l4: 0.161487, l5: 0.278236, l6: 0.534889\n",
            "\n",
            "[epoch: 108/100000, batch: 336/1000, ite: 13417] train loss: 1.9883, accuracy: 91.3866%, tar: 0.1064 \n",
            "l0: 0.075130, l1: 0.076269, l2: 0.084846, l3: 0.103278, l4: 0.149923, l5: 0.237183, l6: 0.431310\n",
            "\n",
            "[epoch: 108/100000, batch: 344/1000, ite: 13418] train loss: 1.9880, accuracy: 92.1430%, tar: 0.1064 \n",
            "l0: 0.054950, l1: 0.056678, l2: 0.065015, l3: 0.087895, l4: 0.116035, l5: 0.181946, l6: 0.311674\n",
            "\n",
            "[epoch: 108/100000, batch: 352/1000, ite: 13419] train loss: 1.9874, accuracy: 93.4015%, tar: 0.1064 \n",
            "l0: 0.096472, l1: 0.097191, l2: 0.103994, l3: 0.123733, l4: 0.168643, l5: 0.254685, l6: 0.475501\n",
            "\n",
            "[epoch: 108/100000, batch: 360/1000, ite: 13420] train loss: 1.9873, accuracy: 91.6562%, tar: 0.1064 \n",
            "l0: 0.074068, l1: 0.075008, l2: 0.085653, l3: 0.108809, l4: 0.159194, l5: 0.235653, l6: 0.417149\n",
            "\n",
            "[epoch: 108/100000, batch: 368/1000, ite: 13421] train loss: 1.9870, accuracy: 93.0868%, tar: 0.1063 \n",
            "l0: 0.084402, l1: 0.085099, l2: 0.092292, l3: 0.111582, l4: 0.157003, l5: 0.246199, l6: 0.491360\n",
            "\n",
            "[epoch: 108/100000, batch: 376/1000, ite: 13422] train loss: 1.9869, accuracy: 91.6157%, tar: 0.1063 \n",
            "l0: 0.085859, l1: 0.086272, l2: 0.095672, l3: 0.119095, l4: 0.165650, l5: 0.282838, l6: 0.485170\n",
            "\n",
            "[epoch: 108/100000, batch: 384/1000, ite: 13423] train loss: 1.9868, accuracy: 91.3587%, tar: 0.1063 \n",
            "l0: 0.106811, l1: 0.107335, l2: 0.116748, l3: 0.138691, l4: 0.195477, l5: 0.299814, l6: 0.540846\n",
            "\n",
            "[epoch: 108/100000, batch: 392/1000, ite: 13424] train loss: 1.9868, accuracy: 90.7355%, tar: 0.1063 \n",
            "l0: 0.078253, l1: 0.079969, l2: 0.087667, l3: 0.107686, l4: 0.137498, l5: 0.226792, l6: 0.423526\n",
            "\n",
            "[epoch: 108/100000, batch: 400/1000, ite: 13425] train loss: 1.9865, accuracy: 93.2623%, tar: 0.1063 \n",
            "l0: 0.078902, l1: 0.080816, l2: 0.086728, l3: 0.105485, l4: 0.140797, l5: 0.240659, l6: 0.391171\n",
            "\n",
            "[epoch: 108/100000, batch: 408/1000, ite: 13426] train loss: 1.9862, accuracy: 92.8699%, tar: 0.1063 \n",
            "l0: 0.090583, l1: 0.091582, l2: 0.102790, l3: 0.131277, l4: 0.183201, l5: 0.292443, l6: 0.488256\n",
            "\n",
            "[epoch: 108/100000, batch: 416/1000, ite: 13427] train loss: 1.9861, accuracy: 92.5070%, tar: 0.1063 \n",
            "l0: 0.084356, l1: 0.086235, l2: 0.098039, l3: 0.127133, l4: 0.183773, l5: 0.261483, l6: 0.459300\n",
            "\n",
            "[epoch: 108/100000, batch: 424/1000, ite: 13428] train loss: 1.9859, accuracy: 93.1668%, tar: 0.1062 \n",
            "l0: 0.065023, l1: 0.065270, l2: 0.074041, l3: 0.095866, l4: 0.144967, l5: 0.238539, l6: 0.430581\n",
            "\n",
            "[epoch: 108/100000, batch: 432/1000, ite: 13429] train loss: 1.9856, accuracy: 93.3291%, tar: 0.1062 \n",
            "l0: 0.088037, l1: 0.089793, l2: 0.097468, l3: 0.117707, l4: 0.166998, l5: 0.245165, l6: 0.394438\n",
            "\n",
            "[epoch: 108/100000, batch: 440/1000, ite: 13430] train loss: 1.9853, accuracy: 93.2849%, tar: 0.1062 \n",
            "l0: 0.088074, l1: 0.088906, l2: 0.099081, l3: 0.129533, l4: 0.197209, l5: 0.334649, l6: 0.533324\n",
            "\n",
            "[epoch: 108/100000, batch: 448/1000, ite: 13431] train loss: 1.9854, accuracy: 91.8608%, tar: 0.1062 \n",
            "l0: 0.083418, l1: 0.084156, l2: 0.089683, l3: 0.102335, l4: 0.138355, l5: 0.210496, l6: 0.360023\n",
            "\n",
            "[epoch: 108/100000, batch: 456/1000, ite: 13432] train loss: 1.9850, accuracy: 93.8960%, tar: 0.1062 \n",
            "l0: 0.100799, l1: 0.100599, l2: 0.112382, l3: 0.134759, l4: 0.186458, l5: 0.273331, l6: 0.464744\n",
            "\n",
            "[epoch: 108/100000, batch: 464/1000, ite: 13433] train loss: 1.9849, accuracy: 91.8737%, tar: 0.1062 \n",
            "l0: 0.116009, l1: 0.116690, l2: 0.124970, l3: 0.142487, l4: 0.180460, l5: 0.281921, l6: 0.446167\n",
            "\n",
            "[epoch: 108/100000, batch: 472/1000, ite: 13434] train loss: 1.9848, accuracy: 91.8961%, tar: 0.1062 \n",
            "l0: 0.063275, l1: 0.063597, l2: 0.071655, l3: 0.096139, l4: 0.147454, l5: 0.214712, l6: 0.420973\n",
            "\n",
            "[epoch: 108/100000, batch: 480/1000, ite: 13435] train loss: 1.9845, accuracy: 94.0409%, tar: 0.1061 \n",
            "l0: 0.101731, l1: 0.103414, l2: 0.110211, l3: 0.129231, l4: 0.174275, l5: 0.272268, l6: 0.524269\n",
            "\n",
            "[epoch: 108/100000, batch: 488/1000, ite: 13436] train loss: 1.9844, accuracy: 91.7496%, tar: 0.1061 \n",
            "l0: 0.085394, l1: 0.086063, l2: 0.094914, l3: 0.116033, l4: 0.158439, l5: 0.249658, l6: 0.423263\n",
            "\n",
            "[epoch: 108/100000, batch: 496/1000, ite: 13437] train loss: 1.9842, accuracy: 92.9262%, tar: 0.1061 \n",
            "l0: 0.077806, l1: 0.078096, l2: 0.089888, l3: 0.117444, l4: 0.189335, l5: 0.325886, l6: 0.600370\n",
            "\n",
            "[epoch: 108/100000, batch: 504/1000, ite: 13438] train loss: 1.9843, accuracy: 90.8860%, tar: 0.1061 \n",
            "l0: 0.084741, l1: 0.086716, l2: 0.092861, l3: 0.114421, l4: 0.180565, l5: 0.241226, l6: 0.415392\n",
            "\n",
            "[epoch: 108/100000, batch: 512/1000, ite: 13439] train loss: 1.9840, accuracy: 93.5461%, tar: 0.1061 \n",
            "l0: 0.096617, l1: 0.098024, l2: 0.108932, l3: 0.132367, l4: 0.177143, l5: 0.266666, l6: 0.487702\n",
            "\n",
            "[epoch: 108/100000, batch: 520/1000, ite: 13440] train loss: 1.9839, accuracy: 91.7865%, tar: 0.1061 \n",
            "l0: 0.084463, l1: 0.087747, l2: 0.100162, l3: 0.139108, l4: 0.224677, l5: 0.320735, l6: 0.608156\n",
            "\n",
            "[epoch: 108/100000, batch: 528/1000, ite: 13441] train loss: 1.9841, accuracy: 92.6765%, tar: 0.1061 \n",
            "l0: 0.108043, l1: 0.108832, l2: 0.121218, l3: 0.147214, l4: 0.198353, l5: 0.277096, l6: 0.449548\n",
            "\n",
            "[epoch: 108/100000, batch: 536/1000, ite: 13442] train loss: 1.9840, accuracy: 91.4539%, tar: 0.1061 \n",
            "l0: 0.081864, l1: 0.082654, l2: 0.089311, l3: 0.114765, l4: 0.158688, l5: 0.233521, l6: 0.461778\n",
            "\n",
            "[epoch: 108/100000, batch: 544/1000, ite: 13443] train loss: 1.9838, accuracy: 93.2821%, tar: 0.1061 \n",
            "l0: 0.134116, l1: 0.136152, l2: 0.145540, l3: 0.178603, l4: 0.237475, l5: 0.312270, l6: 0.494649\n",
            "\n",
            "[epoch: 108/100000, batch: 552/1000, ite: 13444] train loss: 1.9839, accuracy: 91.7547%, tar: 0.1061 \n",
            "l0: 0.114760, l1: 0.117284, l2: 0.129090, l3: 0.155552, l4: 0.236006, l5: 0.413354, l6: 0.716001\n",
            "\n",
            "[epoch: 108/100000, batch: 560/1000, ite: 13445] train loss: 1.9843, accuracy: 89.2797%, tar: 0.1061 \n",
            "l0: 0.083970, l1: 0.085205, l2: 0.092905, l3: 0.116968, l4: 0.161357, l5: 0.241418, l6: 0.392611\n",
            "\n",
            "[epoch: 108/100000, batch: 568/1000, ite: 13446] train loss: 1.9840, accuracy: 92.6218%, tar: 0.1061 \n",
            "l0: 0.103409, l1: 0.105445, l2: 0.114794, l3: 0.137251, l4: 0.194459, l5: 0.301022, l6: 0.452688\n",
            "\n",
            "[epoch: 108/100000, batch: 576/1000, ite: 13447] train loss: 1.9840, accuracy: 91.3141%, tar: 0.1061 \n",
            "l0: 0.085935, l1: 0.086381, l2: 0.094155, l3: 0.116657, l4: 0.170064, l5: 0.271833, l6: 0.428066\n",
            "\n",
            "[epoch: 108/100000, batch: 584/1000, ite: 13448] train loss: 1.9838, accuracy: 92.3160%, tar: 0.1060 \n",
            "l0: 0.092701, l1: 0.093503, l2: 0.102175, l3: 0.121387, l4: 0.176431, l5: 0.267599, l6: 0.471182\n",
            "\n",
            "[epoch: 108/100000, batch: 592/1000, ite: 13449] train loss: 1.9836, accuracy: 91.2426%, tar: 0.1060 \n",
            "l0: 0.063732, l1: 0.065351, l2: 0.074174, l3: 0.095598, l4: 0.127691, l5: 0.177312, l6: 0.370476\n",
            "\n",
            "[epoch: 108/100000, batch: 600/1000, ite: 13450] train loss: 1.9832, accuracy: 94.3467%, tar: 0.1060 \n",
            "l0: 0.107479, l1: 0.109745, l2: 0.116405, l3: 0.151571, l4: 0.250713, l5: 0.384685, l6: 0.585450\n",
            "\n",
            "[epoch: 108/100000, batch: 608/1000, ite: 13451] train loss: 1.9834, accuracy: 92.3647%, tar: 0.1060 \n",
            "l0: 0.077522, l1: 0.078482, l2: 0.088747, l3: 0.109556, l4: 0.156833, l5: 0.267925, l6: 0.448217\n",
            "\n",
            "[epoch: 108/100000, batch: 616/1000, ite: 13452] train loss: 1.9832, accuracy: 92.5234%, tar: 0.1060 \n",
            "l0: 0.074899, l1: 0.076560, l2: 0.089232, l3: 0.132022, l4: 0.194075, l5: 0.293870, l6: 0.502424\n",
            "\n",
            "[epoch: 108/100000, batch: 624/1000, ite: 13453] train loss: 1.9831, accuracy: 93.2821%, tar: 0.1060 \n",
            "l0: 0.096212, l1: 0.097401, l2: 0.107835, l3: 0.129420, l4: 0.175819, l5: 0.278684, l6: 0.453693\n",
            "\n",
            "[epoch: 108/100000, batch: 632/1000, ite: 13454] train loss: 1.9830, accuracy: 93.0859%, tar: 0.1060 \n",
            "l0: 0.129938, l1: 0.130954, l2: 0.143530, l3: 0.175736, l4: 0.242886, l5: 0.374885, l6: 0.575294\n",
            "\n",
            "[epoch: 108/100000, batch: 640/1000, ite: 13455] train loss: 1.9832, accuracy: 89.6031%, tar: 0.1060 \n",
            "l0: 0.076274, l1: 0.077770, l2: 0.085337, l3: 0.104257, l4: 0.147283, l5: 0.239410, l6: 0.417892\n",
            "\n",
            "[epoch: 108/100000, batch: 648/1000, ite: 13456] train loss: 1.9830, accuracy: 92.4412%, tar: 0.1060 \n",
            "l0: 0.077520, l1: 0.078686, l2: 0.087705, l3: 0.109950, l4: 0.177774, l5: 0.264385, l6: 0.433935\n",
            "\n",
            "[epoch: 108/100000, batch: 656/1000, ite: 13457] train loss: 1.9827, accuracy: 92.9438%, tar: 0.1059 \n",
            "l0: 0.072301, l1: 0.074139, l2: 0.081436, l3: 0.100817, l4: 0.148436, l5: 0.225231, l6: 0.346503\n",
            "\n",
            "[epoch: 108/100000, batch: 664/1000, ite: 13458] train loss: 1.9823, accuracy: 93.4337%, tar: 0.1059 \n",
            "l0: 0.091627, l1: 0.093080, l2: 0.100827, l3: 0.118728, l4: 0.163594, l5: 0.256853, l6: 0.441966\n",
            "\n",
            "[epoch: 108/100000, batch: 672/1000, ite: 13459] train loss: 1.9822, accuracy: 91.8939%, tar: 0.1059 \n",
            "l0: 0.085140, l1: 0.086591, l2: 0.095383, l3: 0.114798, l4: 0.166318, l5: 0.271327, l6: 0.536620\n",
            "\n",
            "[epoch: 108/100000, batch: 680/1000, ite: 13460] train loss: 1.9821, accuracy: 92.7259%, tar: 0.1059 \n",
            "l0: 0.098383, l1: 0.099719, l2: 0.110921, l3: 0.142381, l4: 0.202413, l5: 0.305069, l6: 0.523753\n",
            "\n",
            "[epoch: 108/100000, batch: 688/1000, ite: 13461] train loss: 1.9821, accuracy: 91.6407%, tar: 0.1059 \n",
            "l0: 0.124747, l1: 0.125128, l2: 0.135859, l3: 0.158709, l4: 0.207246, l5: 0.372496, l6: 0.647785\n",
            "\n",
            "[epoch: 108/100000, batch: 696/1000, ite: 13462] train loss: 1.9824, accuracy: 88.3745%, tar: 0.1059 \n",
            "l0: 0.087299, l1: 0.088231, l2: 0.100043, l3: 0.128105, l4: 0.202106, l5: 0.324301, l6: 0.515717\n",
            "\n",
            "[epoch: 108/100000, batch: 704/1000, ite: 13463] train loss: 1.9824, accuracy: 91.9922%, tar: 0.1059 \n",
            "l0: 0.146236, l1: 0.147269, l2: 0.157808, l3: 0.183951, l4: 0.262972, l5: 0.441656, l6: 0.673810\n",
            "\n",
            "[epoch: 108/100000, batch: 712/1000, ite: 13464] train loss: 1.9829, accuracy: 87.9596%, tar: 0.1059 \n",
            "l0: 0.100926, l1: 0.101918, l2: 0.111112, l3: 0.137726, l4: 0.199348, l5: 0.358225, l6: 0.550603\n",
            "\n",
            "[epoch: 108/100000, batch: 720/1000, ite: 13465] train loss: 1.9830, accuracy: 90.7808%, tar: 0.1059 \n",
            "l0: 0.070458, l1: 0.071401, l2: 0.078769, l3: 0.102181, l4: 0.139449, l5: 0.217275, l6: 0.351906\n",
            "\n",
            "[epoch: 108/100000, batch: 728/1000, ite: 13466] train loss: 1.9826, accuracy: 93.4193%, tar: 0.1059 \n",
            "l0: 0.069446, l1: 0.071813, l2: 0.082232, l3: 0.104127, l4: 0.165873, l5: 0.293186, l6: 0.452642\n",
            "\n",
            "[epoch: 108/100000, batch: 736/1000, ite: 13467] train loss: 1.9824, accuracy: 92.3172%, tar: 0.1059 \n",
            "l0: 0.085429, l1: 0.085991, l2: 0.096058, l3: 0.123334, l4: 0.183888, l5: 0.289762, l6: 0.490198\n",
            "\n",
            "[epoch: 108/100000, batch: 744/1000, ite: 13468] train loss: 1.9823, accuracy: 92.5460%, tar: 0.1058 \n",
            "l0: 0.094480, l1: 0.096116, l2: 0.103049, l3: 0.127989, l4: 0.181863, l5: 0.305753, l6: 0.474695\n",
            "\n",
            "[epoch: 108/100000, batch: 752/1000, ite: 13469] train loss: 1.9822, accuracy: 91.9893%, tar: 0.1058 \n",
            "l0: 0.090190, l1: 0.090271, l2: 0.099928, l3: 0.118623, l4: 0.171738, l5: 0.275899, l6: 0.394950\n",
            "\n",
            "[epoch: 108/100000, batch: 760/1000, ite: 13470] train loss: 1.9820, accuracy: 92.4817%, tar: 0.1058 \n",
            "l0: 0.101131, l1: 0.102401, l2: 0.113808, l3: 0.146054, l4: 0.234634, l5: 0.379829, l6: 0.632163\n",
            "\n",
            "[epoch: 108/100000, batch: 768/1000, ite: 13471] train loss: 1.9822, accuracy: 90.2670%, tar: 0.1058 \n",
            "l0: 0.101107, l1: 0.102177, l2: 0.111280, l3: 0.130612, l4: 0.179194, l5: 0.271862, l6: 0.539161\n",
            "\n",
            "[epoch: 108/100000, batch: 776/1000, ite: 13472] train loss: 1.9822, accuracy: 91.1648%, tar: 0.1058 \n",
            "l0: 0.077431, l1: 0.079000, l2: 0.087354, l3: 0.101803, l4: 0.144045, l5: 0.220694, l6: 0.398455\n",
            "\n",
            "[epoch: 108/100000, batch: 784/1000, ite: 13473] train loss: 1.9819, accuracy: 92.4942%, tar: 0.1058 \n",
            "l0: 0.087189, l1: 0.087218, l2: 0.097226, l3: 0.116413, l4: 0.160546, l5: 0.251830, l6: 0.401574\n",
            "\n",
            "[epoch: 108/100000, batch: 792/1000, ite: 13474] train loss: 1.9817, accuracy: 92.5615%, tar: 0.1058 \n",
            "l0: 0.090851, l1: 0.090766, l2: 0.101490, l3: 0.130118, l4: 0.185853, l5: 0.287125, l6: 0.478797\n",
            "\n",
            "[epoch: 108/100000, batch: 800/1000, ite: 13475] train loss: 1.9816, accuracy: 92.8630%, tar: 0.1058 \n",
            "l0: 0.123044, l1: 0.124505, l2: 0.136615, l3: 0.165328, l4: 0.246692, l5: 0.378624, l6: 0.596134\n",
            "\n",
            "[epoch: 108/100000, batch: 808/1000, ite: 13476] train loss: 1.9818, accuracy: 89.9159%, tar: 0.1058 \n",
            "l0: 0.078687, l1: 0.080430, l2: 0.091987, l3: 0.116916, l4: 0.173649, l5: 0.326855, l6: 0.568406\n",
            "\n",
            "[epoch: 108/100000, batch: 816/1000, ite: 13477] train loss: 1.9818, accuracy: 92.1687%, tar: 0.1058 \n",
            "l0: 0.098198, l1: 0.099098, l2: 0.106015, l3: 0.132499, l4: 0.200741, l5: 0.340076, l6: 0.513692\n",
            "\n",
            "[epoch: 108/100000, batch: 824/1000, ite: 13478] train loss: 1.9819, accuracy: 91.6666%, tar: 0.1058 \n",
            "l0: 0.086671, l1: 0.089030, l2: 0.098594, l3: 0.118698, l4: 0.161482, l5: 0.244218, l6: 0.433861\n",
            "\n",
            "[epoch: 108/100000, batch: 832/1000, ite: 13479] train loss: 1.9817, accuracy: 92.8436%, tar: 0.1058 \n",
            "l0: 0.073067, l1: 0.073228, l2: 0.080274, l3: 0.100323, l4: 0.152282, l5: 0.233434, l6: 0.413515\n",
            "\n",
            "[epoch: 108/100000, batch: 840/1000, ite: 13480] train loss: 1.9814, accuracy: 93.2782%, tar: 0.1057 \n",
            "l0: 0.076609, l1: 0.077877, l2: 0.084968, l3: 0.111275, l4: 0.149971, l5: 0.279203, l6: 0.541880\n",
            "\n",
            "[epoch: 108/100000, batch: 848/1000, ite: 13481] train loss: 1.9813, accuracy: 91.9939%, tar: 0.1057 \n",
            "l0: 0.166784, l1: 0.168965, l2: 0.175411, l3: 0.203665, l4: 0.277212, l5: 0.431122, l6: 0.747010\n",
            "\n",
            "[epoch: 108/100000, batch: 856/1000, ite: 13482] train loss: 1.9819, accuracy: 89.0607%, tar: 0.1058 \n",
            "l0: 0.090059, l1: 0.090886, l2: 0.099516, l3: 0.130574, l4: 0.202237, l5: 0.286971, l6: 0.491625\n",
            "\n",
            "[epoch: 108/100000, batch: 864/1000, ite: 13483] train loss: 1.9818, accuracy: 92.9444%, tar: 0.1057 \n",
            "l0: 0.068065, l1: 0.069048, l2: 0.078803, l3: 0.093999, l4: 0.123719, l5: 0.211722, l6: 0.437703\n",
            "\n",
            "[epoch: 108/100000, batch: 872/1000, ite: 13484] train loss: 1.9815, accuracy: 93.0325%, tar: 0.1057 \n",
            "l0: 0.071195, l1: 0.072780, l2: 0.082895, l3: 0.105064, l4: 0.154610, l5: 0.260282, l6: 0.465933\n",
            "\n",
            "[epoch: 108/100000, batch: 880/1000, ite: 13485] train loss: 1.9813, accuracy: 92.2751%, tar: 0.1057 \n",
            "l0: 0.095873, l1: 0.097565, l2: 0.107073, l3: 0.127754, l4: 0.188339, l5: 0.286607, l6: 0.481997\n",
            "\n",
            "[epoch: 108/100000, batch: 888/1000, ite: 13486] train loss: 1.9812, accuracy: 92.3816%, tar: 0.1057 \n",
            "l0: 0.098005, l1: 0.098838, l2: 0.106390, l3: 0.128248, l4: 0.180270, l5: 0.290201, l6: 0.561956\n",
            "\n",
            "[epoch: 108/100000, batch: 896/1000, ite: 13487] train loss: 1.9813, accuracy: 90.8937%, tar: 0.1057 \n",
            "l0: 0.085169, l1: 0.087083, l2: 0.097131, l3: 0.123468, l4: 0.180947, l5: 0.318304, l6: 0.542120\n",
            "\n",
            "[epoch: 108/100000, batch: 904/1000, ite: 13488] train loss: 1.9813, accuracy: 91.0802%, tar: 0.1057 \n",
            "l0: 0.092121, l1: 0.092611, l2: 0.102809, l3: 0.133287, l4: 0.203161, l5: 0.316524, l6: 0.561205\n",
            "\n",
            "[epoch: 108/100000, batch: 912/1000, ite: 13489] train loss: 1.9813, accuracy: 91.2606%, tar: 0.1057 \n",
            "l0: 0.098649, l1: 0.098746, l2: 0.109653, l3: 0.145502, l4: 0.206775, l5: 0.300069, l6: 0.474037\n",
            "\n",
            "[epoch: 108/100000, batch: 920/1000, ite: 13490] train loss: 1.9813, accuracy: 92.1939%, tar: 0.1057 \n",
            "l0: 0.112983, l1: 0.114969, l2: 0.122663, l3: 0.142944, l4: 0.176485, l5: 0.249606, l6: 0.398447\n",
            "\n",
            "[epoch: 108/100000, batch: 928/1000, ite: 13491] train loss: 1.9811, accuracy: 92.1273%, tar: 0.1057 \n",
            "l0: 0.080054, l1: 0.080711, l2: 0.087684, l3: 0.107790, l4: 0.159160, l5: 0.235355, l6: 0.396486\n",
            "\n",
            "[epoch: 108/100000, batch: 936/1000, ite: 13492] train loss: 1.9808, accuracy: 92.4137%, tar: 0.1056 \n",
            "l0: 0.101502, l1: 0.102960, l2: 0.113343, l3: 0.139466, l4: 0.187882, l5: 0.276974, l6: 0.499076\n",
            "\n",
            "[epoch: 108/100000, batch: 944/1000, ite: 13493] train loss: 1.9808, accuracy: 92.1664%, tar: 0.1056 \n",
            "l0: 0.102576, l1: 0.103589, l2: 0.114214, l3: 0.135046, l4: 0.171241, l5: 0.275345, l6: 0.464139\n",
            "\n",
            "[epoch: 108/100000, batch: 952/1000, ite: 13494] train loss: 1.9807, accuracy: 91.5295%, tar: 0.1056 \n",
            "l0: 0.112134, l1: 0.114127, l2: 0.121086, l3: 0.138266, l4: 0.175750, l5: 0.263182, l6: 0.415926\n",
            "\n",
            "[epoch: 108/100000, batch: 960/1000, ite: 13495] train loss: 1.9805, accuracy: 91.3950%, tar: 0.1056 \n",
            "l0: 0.097290, l1: 0.098232, l2: 0.110353, l3: 0.141312, l4: 0.206214, l5: 0.346444, l6: 0.588360\n",
            "\n",
            "[epoch: 108/100000, batch: 968/1000, ite: 13496] train loss: 1.9806, accuracy: 90.9715%, tar: 0.1056 \n",
            "l0: 0.084565, l1: 0.085993, l2: 0.098596, l3: 0.134750, l4: 0.196088, l5: 0.289774, l6: 0.456113\n",
            "\n",
            "[epoch: 108/100000, batch: 976/1000, ite: 13497] train loss: 1.9805, accuracy: 92.9613%, tar: 0.1056 \n",
            "l0: 0.070612, l1: 0.071307, l2: 0.080150, l3: 0.107443, l4: 0.169779, l5: 0.286187, l6: 0.464282\n",
            "\n",
            "[epoch: 108/100000, batch: 984/1000, ite: 13498] train loss: 1.9804, accuracy: 91.6952%, tar: 0.1056 \n",
            "l0: 0.089746, l1: 0.089197, l2: 0.100414, l3: 0.125621, l4: 0.189423, l5: 0.299542, l6: 0.533353\n",
            "\n",
            "[epoch: 108/100000, batch: 992/1000, ite: 13499] train loss: 1.9803, accuracy: 91.6730%, tar: 0.1056 \n",
            "l0: 0.129250, l1: 0.132076, l2: 0.145557, l3: 0.170674, l4: 0.254370, l5: 0.375522, l6: 0.635087\n",
            "\n",
            "[epoch: 108/100000, batch: 1000/1000, ite: 13500] train loss: 1.9807, accuracy: 91.0654%, tar: 0.1056 \n",
            "l0: 0.101710, l1: 0.101962, l2: 0.109769, l3: 0.127810, l4: 0.173957, l5: 0.271665, l6: 0.510729\n",
            "\n",
            "[epoch: 109/100000, batch: 8/1000, ite: 13501] train loss: 1.9806, accuracy: 91.4845%, tar: 0.1056 \n",
            "l0: 0.105391, l1: 0.106507, l2: 0.115696, l3: 0.141308, l4: 0.193383, l5: 0.336584, l6: 0.590355\n",
            "\n",
            "[epoch: 109/100000, batch: 16/1000, ite: 13502] train loss: 1.9808, accuracy: 90.0349%, tar: 0.1056 \n",
            "l0: 0.068353, l1: 0.069342, l2: 0.077461, l3: 0.098113, l4: 0.139558, l5: 0.206198, l6: 0.364758\n",
            "\n",
            "[epoch: 109/100000, batch: 24/1000, ite: 13503] train loss: 1.9804, accuracy: 92.9482%, tar: 0.1056 \n",
            "l0: 0.091935, l1: 0.092876, l2: 0.101548, l3: 0.129058, l4: 0.172467, l5: 0.250952, l6: 0.411221\n",
            "\n",
            "[epoch: 109/100000, batch: 32/1000, ite: 13504] train loss: 1.9802, accuracy: 93.2370%, tar: 0.1056 \n",
            "l0: 0.087539, l1: 0.088757, l2: 0.101198, l3: 0.126179, l4: 0.184279, l5: 0.325306, l6: 0.546864\n",
            "\n",
            "[epoch: 109/100000, batch: 40/1000, ite: 13505] train loss: 1.9802, accuracy: 92.0021%, tar: 0.1056 \n",
            "l0: 0.125456, l1: 0.125977, l2: 0.132735, l3: 0.154471, l4: 0.215960, l5: 0.339823, l6: 0.556420\n",
            "\n",
            "[epoch: 109/100000, batch: 48/1000, ite: 13506] train loss: 1.9803, accuracy: 90.4967%, tar: 0.1056 \n",
            "l0: 0.097559, l1: 0.098791, l2: 0.108818, l3: 0.134050, l4: 0.184260, l5: 0.293921, l6: 0.525434\n",
            "\n",
            "[epoch: 109/100000, batch: 56/1000, ite: 13507] train loss: 1.9803, accuracy: 91.4642%, tar: 0.1056 \n",
            "l0: 0.088418, l1: 0.090031, l2: 0.100041, l3: 0.129827, l4: 0.184019, l5: 0.283877, l6: 0.520459\n",
            "\n",
            "[epoch: 109/100000, batch: 64/1000, ite: 13508] train loss: 1.9803, accuracy: 92.7589%, tar: 0.1056 \n",
            "l0: 0.086833, l1: 0.086919, l2: 0.096245, l3: 0.115646, l4: 0.157060, l5: 0.248709, l6: 0.443296\n",
            "\n",
            "[epoch: 109/100000, batch: 72/1000, ite: 13509] train loss: 1.9801, accuracy: 92.5146%, tar: 0.1055 \n",
            "l0: 0.105255, l1: 0.107001, l2: 0.117497, l3: 0.145966, l4: 0.195360, l5: 0.296494, l6: 0.490044\n",
            "\n",
            "[epoch: 109/100000, batch: 80/1000, ite: 13510] train loss: 1.9801, accuracy: 91.7141%, tar: 0.1055 \n",
            "l0: 0.085464, l1: 0.086600, l2: 0.096111, l3: 0.117844, l4: 0.162264, l5: 0.263259, l6: 0.512377\n",
            "\n",
            "[epoch: 109/100000, batch: 88/1000, ite: 13511] train loss: 1.9800, accuracy: 91.3262%, tar: 0.1055 \n",
            "l0: 0.057859, l1: 0.058218, l2: 0.068294, l3: 0.087338, l4: 0.136342, l5: 0.206853, l6: 0.417968\n",
            "\n",
            "[epoch: 109/100000, batch: 96/1000, ite: 13512] train loss: 1.9796, accuracy: 93.8422%, tar: 0.1055 \n",
            "l0: 0.078596, l1: 0.080477, l2: 0.091108, l3: 0.119634, l4: 0.165220, l5: 0.258873, l6: 0.433269\n",
            "\n",
            "[epoch: 109/100000, batch: 104/1000, ite: 13513] train loss: 1.9794, accuracy: 91.7659%, tar: 0.1055 \n",
            "l0: 0.094043, l1: 0.095009, l2: 0.105587, l3: 0.135893, l4: 0.213969, l5: 0.341250, l6: 0.604896\n",
            "\n",
            "[epoch: 109/100000, batch: 112/1000, ite: 13514] train loss: 1.9796, accuracy: 91.6572%, tar: 0.1055 \n",
            "l0: 0.084424, l1: 0.085550, l2: 0.096194, l3: 0.118054, l4: 0.177285, l5: 0.257560, l6: 0.457071\n",
            "\n",
            "[epoch: 109/100000, batch: 120/1000, ite: 13515] train loss: 1.9794, accuracy: 92.6996%, tar: 0.1055 \n",
            "l0: 0.098697, l1: 0.099669, l2: 0.112174, l3: 0.145922, l4: 0.223129, l5: 0.353118, l6: 0.564790\n",
            "\n",
            "[epoch: 109/100000, batch: 128/1000, ite: 13516] train loss: 1.9795, accuracy: 89.9534%, tar: 0.1055 \n",
            "l0: 0.081505, l1: 0.082675, l2: 0.093437, l3: 0.124838, l4: 0.203043, l5: 0.315145, l6: 0.583380\n",
            "\n",
            "[epoch: 109/100000, batch: 136/1000, ite: 13517] train loss: 1.9796, accuracy: 90.4943%, tar: 0.1054 \n",
            "l0: 0.065167, l1: 0.065850, l2: 0.075283, l3: 0.100288, l4: 0.150950, l5: 0.244624, l6: 0.478724\n",
            "\n",
            "[epoch: 109/100000, batch: 144/1000, ite: 13518] train loss: 1.9794, accuracy: 91.8695%, tar: 0.1054 \n",
            "l0: 0.087601, l1: 0.087949, l2: 0.097881, l3: 0.119966, l4: 0.176246, l5: 0.257186, l6: 0.427026\n",
            "\n",
            "[epoch: 109/100000, batch: 152/1000, ite: 13519] train loss: 1.9792, accuracy: 92.2556%, tar: 0.1054 \n",
            "l0: 0.090894, l1: 0.092440, l2: 0.105130, l3: 0.136569, l4: 0.197404, l5: 0.306233, l6: 0.592008\n",
            "\n",
            "[epoch: 109/100000, batch: 160/1000, ite: 13520] train loss: 1.9793, accuracy: 91.5545%, tar: 0.1054 \n",
            "l0: 0.090473, l1: 0.091914, l2: 0.101804, l3: 0.124679, l4: 0.165218, l5: 0.255530, l6: 0.470721\n",
            "\n",
            "[epoch: 109/100000, batch: 168/1000, ite: 13521] train loss: 1.9791, accuracy: 91.5528%, tar: 0.1054 \n",
            "l0: 0.087351, l1: 0.088979, l2: 0.099211, l3: 0.124708, l4: 0.182747, l5: 0.290539, l6: 0.468975\n",
            "\n",
            "[epoch: 109/100000, batch: 176/1000, ite: 13522] train loss: 1.9790, accuracy: 93.2883%, tar: 0.1054 \n",
            "l0: 0.078230, l1: 0.078642, l2: 0.085466, l3: 0.102937, l4: 0.134816, l5: 0.209648, l6: 0.398516\n",
            "\n",
            "[epoch: 109/100000, batch: 184/1000, ite: 13523] train loss: 1.9787, accuracy: 92.4399%, tar: 0.1053 \n",
            "l0: 0.118678, l1: 0.121643, l2: 0.134086, l3: 0.167868, l4: 0.240641, l5: 0.382243, l6: 0.707195\n",
            "\n",
            "[epoch: 109/100000, batch: 192/1000, ite: 13524] train loss: 1.9791, accuracy: 91.6225%, tar: 0.1054 \n",
            "l0: 0.162867, l1: 0.162773, l2: 0.170513, l3: 0.198418, l4: 0.276693, l5: 0.412818, l6: 0.613556\n",
            "\n",
            "[epoch: 109/100000, batch: 200/1000, ite: 13525] train loss: 1.9795, accuracy: 88.8415%, tar: 0.1054 \n",
            "l0: 0.081563, l1: 0.082314, l2: 0.092292, l3: 0.122413, l4: 0.182733, l5: 0.290418, l6: 0.490607\n",
            "\n",
            "[epoch: 109/100000, batch: 208/1000, ite: 13526] train loss: 1.9794, accuracy: 92.5666%, tar: 0.1054 \n",
            "l0: 0.078177, l1: 0.079506, l2: 0.089975, l3: 0.119969, l4: 0.170086, l5: 0.282935, l6: 0.499130\n",
            "\n",
            "[epoch: 109/100000, batch: 216/1000, ite: 13527] train loss: 1.9793, accuracy: 91.8180%, tar: 0.1054 \n",
            "l0: 0.061819, l1: 0.062419, l2: 0.069880, l3: 0.086569, l4: 0.118424, l5: 0.198783, l6: 0.364283\n",
            "\n",
            "[epoch: 109/100000, batch: 224/1000, ite: 13528] train loss: 1.9789, accuracy: 93.6190%, tar: 0.1053 \n",
            "l0: 0.095463, l1: 0.096904, l2: 0.108298, l3: 0.139543, l4: 0.218629, l5: 0.329856, l6: 0.584949\n",
            "\n",
            "[epoch: 109/100000, batch: 232/1000, ite: 13529] train loss: 1.9790, accuracy: 91.4358%, tar: 0.1053 \n",
            "l0: 0.125065, l1: 0.126005, l2: 0.134890, l3: 0.160903, l4: 0.227785, l5: 0.336564, l6: 0.493607\n",
            "\n",
            "[epoch: 109/100000, batch: 240/1000, ite: 13530] train loss: 1.9791, accuracy: 91.6244%, tar: 0.1053 \n",
            "l0: 0.061269, l1: 0.061558, l2: 0.070329, l3: 0.099715, l4: 0.160352, l5: 0.214993, l6: 0.362182\n",
            "\n",
            "[epoch: 109/100000, batch: 248/1000, ite: 13531] train loss: 1.9787, accuracy: 94.5869%, tar: 0.1053 \n",
            "l0: 0.168966, l1: 0.170653, l2: 0.186140, l3: 0.219359, l4: 0.286818, l5: 0.442503, l6: 0.669343\n",
            "\n",
            "[epoch: 109/100000, batch: 256/1000, ite: 13532] train loss: 1.9792, accuracy: 89.3355%, tar: 0.1054 \n",
            "l0: 0.077508, l1: 0.078615, l2: 0.087651, l3: 0.110605, l4: 0.154379, l5: 0.243541, l6: 0.455794\n",
            "\n",
            "[epoch: 109/100000, batch: 264/1000, ite: 13533] train loss: 1.9790, accuracy: 92.3413%, tar: 0.1053 \n",
            "l0: 0.100962, l1: 0.101742, l2: 0.110090, l3: 0.135291, l4: 0.193793, l5: 0.296439, l6: 0.499794\n",
            "\n",
            "[epoch: 109/100000, batch: 272/1000, ite: 13534] train loss: 1.9790, accuracy: 91.5768%, tar: 0.1053 \n",
            "l0: 0.070823, l1: 0.071886, l2: 0.080614, l3: 0.103418, l4: 0.145955, l5: 0.237245, l6: 0.360147\n",
            "\n",
            "[epoch: 109/100000, batch: 280/1000, ite: 13535] train loss: 1.9787, accuracy: 93.6115%, tar: 0.1053 \n",
            "l0: 0.089757, l1: 0.090949, l2: 0.101813, l3: 0.137126, l4: 0.204249, l5: 0.323417, l6: 0.530708\n",
            "\n",
            "[epoch: 109/100000, batch: 288/1000, ite: 13536] train loss: 1.9787, accuracy: 90.5031%, tar: 0.1053 \n",
            "l0: 0.070583, l1: 0.072195, l2: 0.081477, l3: 0.099763, l4: 0.131946, l5: 0.198944, l6: 0.308612\n",
            "\n",
            "[epoch: 109/100000, batch: 296/1000, ite: 13537] train loss: 1.9782, accuracy: 94.4989%, tar: 0.1053 \n",
            "l0: 0.096201, l1: 0.097059, l2: 0.105726, l3: 0.125358, l4: 0.186724, l5: 0.315177, l6: 0.541089\n",
            "\n",
            "[epoch: 109/100000, batch: 304/1000, ite: 13538] train loss: 1.9782, accuracy: 91.6825%, tar: 0.1053 \n",
            "l0: 0.087206, l1: 0.088778, l2: 0.098147, l3: 0.123531, l4: 0.198850, l5: 0.300432, l6: 0.483982\n",
            "\n",
            "[epoch: 109/100000, batch: 312/1000, ite: 13539] train loss: 1.9782, accuracy: 92.0873%, tar: 0.1053 \n",
            "l0: 0.092848, l1: 0.094783, l2: 0.103163, l3: 0.124822, l4: 0.172402, l5: 0.245421, l6: 0.392909\n",
            "\n",
            "[epoch: 109/100000, batch: 320/1000, ite: 13540] train loss: 1.9779, accuracy: 92.6159%, tar: 0.1053 \n",
            "l0: 0.073033, l1: 0.074284, l2: 0.084252, l3: 0.109364, l4: 0.162254, l5: 0.233571, l6: 0.406562\n",
            "\n",
            "[epoch: 109/100000, batch: 328/1000, ite: 13541] train loss: 1.9776, accuracy: 92.8665%, tar: 0.1052 \n",
            "l0: 0.122939, l1: 0.123046, l2: 0.135838, l3: 0.167407, l4: 0.223787, l5: 0.319210, l6: 0.525323\n",
            "\n",
            "[epoch: 109/100000, batch: 336/1000, ite: 13542] train loss: 1.9778, accuracy: 91.2119%, tar: 0.1052 \n",
            "l0: 0.067445, l1: 0.068985, l2: 0.074995, l3: 0.091912, l4: 0.132681, l5: 0.201285, l6: 0.323447\n",
            "\n",
            "[epoch: 109/100000, batch: 344/1000, ite: 13543] train loss: 1.9773, accuracy: 94.0708%, tar: 0.1052 \n",
            "l0: 0.079653, l1: 0.081560, l2: 0.087712, l3: 0.107136, l4: 0.143455, l5: 0.215767, l6: 0.400800\n",
            "\n",
            "[epoch: 109/100000, batch: 352/1000, ite: 13544] train loss: 1.9770, accuracy: 92.7893%, tar: 0.1052 \n",
            "l0: 0.093204, l1: 0.094032, l2: 0.107240, l3: 0.138525, l4: 0.202949, l5: 0.354850, l6: 0.553079\n",
            "\n",
            "[epoch: 109/100000, batch: 360/1000, ite: 13545] train loss: 1.9771, accuracy: 91.8510%, tar: 0.1052 \n",
            "l0: 0.096693, l1: 0.097917, l2: 0.107288, l3: 0.129995, l4: 0.190686, l5: 0.291671, l6: 0.504481\n",
            "\n",
            "[epoch: 109/100000, batch: 368/1000, ite: 13546] train loss: 1.9771, accuracy: 90.8047%, tar: 0.1052 \n",
            "l0: 0.081661, l1: 0.082635, l2: 0.089043, l3: 0.105801, l4: 0.144856, l5: 0.216303, l6: 0.374785\n",
            "\n",
            "[epoch: 109/100000, batch: 376/1000, ite: 13547] train loss: 1.9767, accuracy: 93.0262%, tar: 0.1052 \n",
            "l0: 0.078014, l1: 0.077997, l2: 0.085688, l3: 0.108353, l4: 0.150752, l5: 0.241808, l6: 0.423901\n",
            "\n",
            "[epoch: 109/100000, batch: 384/1000, ite: 13548] train loss: 1.9765, accuracy: 92.7676%, tar: 0.1052 \n",
            "l0: 0.078219, l1: 0.080385, l2: 0.093576, l3: 0.125479, l4: 0.198463, l5: 0.330779, l6: 0.587526\n",
            "\n",
            "[epoch: 109/100000, batch: 392/1000, ite: 13549] train loss: 1.9766, accuracy: 91.4124%, tar: 0.1051 \n",
            "l0: 0.066527, l1: 0.066693, l2: 0.076438, l3: 0.090333, l4: 0.129028, l5: 0.213164, l6: 0.400456\n",
            "\n",
            "[epoch: 109/100000, batch: 400/1000, ite: 13550] train loss: 1.9762, accuracy: 93.8272%, tar: 0.1051 \n",
            "l0: 0.079349, l1: 0.079810, l2: 0.088211, l3: 0.111632, l4: 0.156821, l5: 0.269849, l6: 0.457093\n",
            "\n",
            "[epoch: 109/100000, batch: 408/1000, ite: 13551] train loss: 1.9761, accuracy: 92.0323%, tar: 0.1051 \n",
            "l0: 0.087139, l1: 0.088786, l2: 0.096397, l3: 0.120188, l4: 0.181524, l5: 0.266442, l6: 0.422871\n",
            "\n",
            "[epoch: 109/100000, batch: 416/1000, ite: 13552] train loss: 1.9759, accuracy: 93.5542%, tar: 0.1051 \n",
            "l0: 0.122098, l1: 0.122724, l2: 0.130233, l3: 0.154907, l4: 0.226789, l5: 0.366830, l6: 0.552367\n",
            "\n",
            "[epoch: 109/100000, batch: 424/1000, ite: 13553] train loss: 1.9760, accuracy: 89.7043%, tar: 0.1051 \n",
            "l0: 0.058240, l1: 0.059270, l2: 0.066982, l3: 0.089410, l4: 0.126704, l5: 0.200224, l6: 0.328286\n",
            "\n",
            "[epoch: 109/100000, batch: 432/1000, ite: 13554] train loss: 1.9756, accuracy: 93.5745%, tar: 0.1051 \n",
            "l0: 0.091188, l1: 0.091985, l2: 0.099577, l3: 0.120864, l4: 0.157103, l5: 0.240425, l6: 0.383608\n",
            "\n",
            "[epoch: 109/100000, batch: 440/1000, ite: 13555] train loss: 1.9753, accuracy: 92.6705%, tar: 0.1051 \n",
            "l0: 0.091796, l1: 0.093611, l2: 0.105046, l3: 0.138827, l4: 0.206844, l5: 0.299904, l6: 0.456609\n",
            "\n",
            "[epoch: 109/100000, batch: 448/1000, ite: 13556] train loss: 1.9752, accuracy: 92.8433%, tar: 0.1050 \n",
            "l0: 0.095201, l1: 0.095504, l2: 0.106996, l3: 0.132075, l4: 0.188414, l5: 0.293714, l6: 0.464413\n",
            "\n",
            "[epoch: 109/100000, batch: 456/1000, ite: 13557] train loss: 1.9751, accuracy: 91.5575%, tar: 0.1050 \n",
            "l0: 0.080008, l1: 0.081476, l2: 0.090479, l3: 0.113241, l4: 0.173668, l5: 0.264382, l6: 0.480529\n",
            "\n",
            "[epoch: 109/100000, batch: 464/1000, ite: 13558] train loss: 1.9750, accuracy: 90.9368%, tar: 0.1050 \n",
            "l0: 0.097727, l1: 0.098439, l2: 0.104865, l3: 0.130261, l4: 0.186141, l5: 0.282866, l6: 0.465598\n",
            "\n",
            "[epoch: 109/100000, batch: 472/1000, ite: 13559] train loss: 1.9749, accuracy: 93.0863%, tar: 0.1050 \n",
            "l0: 0.114324, l1: 0.115325, l2: 0.127047, l3: 0.153639, l4: 0.221510, l5: 0.333625, l6: 0.591760\n",
            "\n",
            "[epoch: 109/100000, batch: 480/1000, ite: 13560] train loss: 1.9751, accuracy: 91.2749%, tar: 0.1050 \n",
            "l0: 0.112881, l1: 0.114399, l2: 0.122632, l3: 0.145861, l4: 0.199536, l5: 0.339234, l6: 0.557016\n",
            "\n",
            "[epoch: 109/100000, batch: 488/1000, ite: 13561] train loss: 1.9752, accuracy: 89.4575%, tar: 0.1050 \n",
            "l0: 0.077254, l1: 0.077830, l2: 0.086806, l3: 0.107178, l4: 0.162890, l5: 0.291795, l6: 0.464799\n",
            "\n",
            "[epoch: 109/100000, batch: 496/1000, ite: 13562] train loss: 1.9751, accuracy: 92.2806%, tar: 0.1050 \n",
            "l0: 0.093130, l1: 0.094760, l2: 0.104417, l3: 0.132654, l4: 0.191252, l5: 0.297867, l6: 0.522273\n",
            "\n",
            "[epoch: 109/100000, batch: 504/1000, ite: 13563] train loss: 1.9750, accuracy: 91.5173%, tar: 0.1050 \n",
            "l0: 0.085463, l1: 0.087203, l2: 0.096903, l3: 0.118330, l4: 0.171896, l5: 0.276861, l6: 0.484273\n",
            "\n",
            "[epoch: 109/100000, batch: 512/1000, ite: 13564] train loss: 1.9749, accuracy: 91.8326%, tar: 0.1050 \n",
            "l0: 0.091032, l1: 0.091782, l2: 0.101897, l3: 0.118188, l4: 0.151262, l5: 0.213335, l6: 0.375442\n",
            "\n",
            "[epoch: 109/100000, batch: 520/1000, ite: 13565] train loss: 1.9747, accuracy: 93.7311%, tar: 0.1050 \n",
            "l0: 0.099418, l1: 0.100717, l2: 0.107306, l3: 0.119956, l4: 0.147105, l5: 0.226654, l6: 0.391940\n",
            "\n",
            "[epoch: 109/100000, batch: 528/1000, ite: 13566] train loss: 1.9744, accuracy: 92.2773%, tar: 0.1050 \n",
            "l0: 0.072107, l1: 0.072838, l2: 0.081697, l3: 0.103438, l4: 0.143607, l5: 0.233340, l6: 0.400899\n",
            "\n",
            "[epoch: 109/100000, batch: 536/1000, ite: 13567] train loss: 1.9741, accuracy: 93.7655%, tar: 0.1050 \n",
            "l0: 0.092681, l1: 0.094448, l2: 0.104626, l3: 0.133671, l4: 0.216059, l5: 0.354678, l6: 0.598088\n",
            "\n",
            "[epoch: 109/100000, batch: 544/1000, ite: 13568] train loss: 1.9743, accuracy: 90.2572%, tar: 0.1050 \n",
            "l0: 0.089802, l1: 0.090950, l2: 0.102145, l3: 0.127834, l4: 0.174107, l5: 0.237250, l6: 0.419899\n",
            "\n",
            "[epoch: 109/100000, batch: 552/1000, ite: 13569] train loss: 1.9741, accuracy: 93.0756%, tar: 0.1049 \n",
            "l0: 0.097592, l1: 0.097567, l2: 0.111943, l3: 0.141410, l4: 0.217091, l5: 0.374680, l6: 0.586717\n",
            "\n",
            "[epoch: 109/100000, batch: 560/1000, ite: 13570] train loss: 1.9742, accuracy: 91.3120%, tar: 0.1049 \n",
            "l0: 0.096960, l1: 0.097449, l2: 0.104785, l3: 0.123394, l4: 0.180577, l5: 0.278338, l6: 0.458379\n",
            "\n",
            "[epoch: 109/100000, batch: 568/1000, ite: 13571] train loss: 1.9741, accuracy: 91.3847%, tar: 0.1049 \n",
            "l0: 0.085021, l1: 0.085570, l2: 0.092262, l3: 0.116772, l4: 0.166019, l5: 0.300475, l6: 0.450187\n",
            "\n",
            "[epoch: 109/100000, batch: 576/1000, ite: 13572] train loss: 1.9740, accuracy: 92.4810%, tar: 0.1049 \n",
            "l0: 0.114805, l1: 0.116657, l2: 0.127584, l3: 0.159214, l4: 0.231583, l5: 0.380198, l6: 0.597405\n",
            "\n",
            "[epoch: 109/100000, batch: 584/1000, ite: 13573] train loss: 1.9742, accuracy: 91.7135%, tar: 0.1049 \n",
            "l0: 0.096917, l1: 0.098745, l2: 0.107010, l3: 0.131099, l4: 0.182591, l5: 0.303127, l6: 0.582508\n",
            "\n",
            "[epoch: 109/100000, batch: 592/1000, ite: 13574] train loss: 1.9742, accuracy: 90.9447%, tar: 0.1049 \n",
            "l0: 0.074898, l1: 0.075592, l2: 0.085147, l3: 0.108941, l4: 0.159702, l5: 0.275355, l6: 0.471519\n",
            "\n",
            "[epoch: 109/100000, batch: 600/1000, ite: 13575] train loss: 1.9741, accuracy: 92.3171%, tar: 0.1049 \n",
            "l0: 0.082404, l1: 0.083825, l2: 0.091440, l3: 0.102141, l4: 0.129785, l5: 0.202902, l6: 0.379328\n",
            "\n",
            "[epoch: 109/100000, batch: 608/1000, ite: 13576] train loss: 1.9738, accuracy: 93.7541%, tar: 0.1049 \n",
            "l0: 0.074991, l1: 0.075521, l2: 0.080046, l3: 0.100399, l4: 0.144452, l5: 0.221467, l6: 0.390164\n",
            "\n",
            "[epoch: 109/100000, batch: 616/1000, ite: 13577] train loss: 1.9734, accuracy: 93.9465%, tar: 0.1049 \n",
            "l0: 0.091685, l1: 0.092377, l2: 0.104441, l3: 0.126300, l4: 0.174111, l5: 0.273357, l6: 0.465482\n",
            "\n",
            "[epoch: 109/100000, batch: 624/1000, ite: 13578] train loss: 1.9733, accuracy: 91.8761%, tar: 0.1049 \n",
            "l0: 0.116127, l1: 0.117286, l2: 0.131092, l3: 0.166397, l4: 0.240970, l5: 0.368864, l6: 0.557645\n",
            "\n",
            "[epoch: 109/100000, batch: 632/1000, ite: 13579] train loss: 1.9735, accuracy: 91.2519%, tar: 0.1049 \n",
            "l0: 0.115777, l1: 0.116762, l2: 0.127418, l3: 0.156792, l4: 0.214575, l5: 0.341328, l6: 0.597245\n",
            "\n",
            "[epoch: 109/100000, batch: 640/1000, ite: 13580] train loss: 1.9737, accuracy: 90.6882%, tar: 0.1049 \n",
            "l0: 0.072129, l1: 0.073163, l2: 0.078511, l3: 0.091644, l4: 0.126996, l5: 0.200222, l6: 0.385347\n",
            "\n",
            "[epoch: 109/100000, batch: 648/1000, ite: 13581] train loss: 1.9734, accuracy: 92.8471%, tar: 0.1049 \n",
            "l0: 0.088835, l1: 0.089159, l2: 0.098085, l3: 0.116895, l4: 0.161004, l5: 0.248380, l6: 0.481168\n",
            "\n",
            "[epoch: 109/100000, batch: 656/1000, ite: 13582] train loss: 1.9732, accuracy: 91.7660%, tar: 0.1048 \n",
            "l0: 0.086875, l1: 0.086460, l2: 0.095612, l3: 0.118480, l4: 0.169887, l5: 0.269229, l6: 0.440264\n",
            "\n",
            "[epoch: 109/100000, batch: 664/1000, ite: 13583] train loss: 1.9731, accuracy: 91.8727%, tar: 0.1048 \n",
            "l0: 0.085006, l1: 0.086980, l2: 0.095374, l3: 0.109646, l4: 0.146371, l5: 0.254541, l6: 0.436210\n",
            "\n",
            "[epoch: 109/100000, batch: 672/1000, ite: 13584] train loss: 1.9729, accuracy: 92.1142%, tar: 0.1048 \n",
            "l0: 0.137187, l1: 0.141674, l2: 0.158663, l3: 0.183400, l4: 0.245291, l5: 0.357716, l6: 0.613180\n",
            "\n",
            "[epoch: 109/100000, batch: 680/1000, ite: 13585] train loss: 1.9732, accuracy: 91.8325%, tar: 0.1048 \n",
            "l0: 0.081698, l1: 0.083092, l2: 0.090205, l3: 0.110992, l4: 0.143192, l5: 0.223502, l6: 0.379106\n",
            "\n",
            "[epoch: 109/100000, batch: 688/1000, ite: 13586] train loss: 1.9729, accuracy: 93.5521%, tar: 0.1048 \n",
            "l0: 0.093399, l1: 0.094716, l2: 0.101855, l3: 0.119040, l4: 0.162319, l5: 0.259652, l6: 0.424747\n",
            "\n",
            "[epoch: 109/100000, batch: 696/1000, ite: 13587] train loss: 1.9727, accuracy: 93.1025%, tar: 0.1048 \n",
            "l0: 0.089302, l1: 0.089808, l2: 0.097294, l3: 0.122002, l4: 0.175167, l5: 0.312242, l6: 0.484581\n",
            "\n",
            "[epoch: 109/100000, batch: 704/1000, ite: 13588] train loss: 1.9726, accuracy: 93.3590%, tar: 0.1048 \n",
            "l0: 0.099388, l1: 0.100197, l2: 0.111943, l3: 0.139288, l4: 0.222278, l5: 0.369590, l6: 0.582034\n",
            "\n",
            "[epoch: 109/100000, batch: 712/1000, ite: 13589] train loss: 1.9728, accuracy: 91.2043%, tar: 0.1048 \n",
            "l0: 0.084737, l1: 0.085587, l2: 0.093605, l3: 0.118382, l4: 0.169048, l5: 0.237196, l6: 0.389059\n",
            "\n",
            "[epoch: 109/100000, batch: 720/1000, ite: 13590] train loss: 1.9725, accuracy: 93.2788%, tar: 0.1048 \n",
            "l0: 0.054485, l1: 0.055516, l2: 0.061181, l3: 0.078459, l4: 0.114746, l5: 0.200945, l6: 0.377558\n",
            "\n",
            "[epoch: 109/100000, batch: 728/1000, ite: 13591] train loss: 1.9721, accuracy: 93.6588%, tar: 0.1048 \n",
            "l0: 0.062395, l1: 0.063223, l2: 0.072108, l3: 0.097712, l4: 0.157629, l5: 0.248156, l6: 0.396995\n",
            "\n",
            "[epoch: 109/100000, batch: 736/1000, ite: 13592] train loss: 1.9718, accuracy: 93.4787%, tar: 0.1047 \n",
            "l0: 0.110306, l1: 0.111040, l2: 0.118698, l3: 0.136720, l4: 0.185326, l5: 0.293140, l6: 0.468889\n",
            "\n",
            "[epoch: 109/100000, batch: 744/1000, ite: 13593] train loss: 1.9718, accuracy: 92.1621%, tar: 0.1047 \n",
            "l0: 0.114771, l1: 0.116107, l2: 0.127489, l3: 0.167284, l4: 0.255207, l5: 0.398585, l6: 0.633965\n",
            "\n",
            "[epoch: 109/100000, batch: 752/1000, ite: 13594] train loss: 1.9720, accuracy: 91.1382%, tar: 0.1047 \n",
            "l0: 0.080837, l1: 0.079575, l2: 0.087186, l3: 0.108914, l4: 0.172653, l5: 0.250967, l6: 0.427294\n",
            "\n",
            "[epoch: 109/100000, batch: 760/1000, ite: 13595] train loss: 1.9718, accuracy: 92.4156%, tar: 0.1047 \n",
            "l0: 0.083544, l1: 0.085744, l2: 0.096623, l3: 0.125900, l4: 0.190171, l5: 0.295208, l6: 0.506443\n",
            "\n",
            "[epoch: 109/100000, batch: 768/1000, ite: 13596] train loss: 1.9718, accuracy: 92.5310%, tar: 0.1047 \n",
            "l0: 0.076887, l1: 0.078406, l2: 0.084928, l3: 0.105257, l4: 0.165214, l5: 0.260715, l6: 0.398022\n",
            "\n",
            "[epoch: 109/100000, batch: 776/1000, ite: 13597] train loss: 1.9715, accuracy: 93.0656%, tar: 0.1047 \n",
            "l0: 0.088392, l1: 0.088713, l2: 0.093609, l3: 0.108377, l4: 0.137380, l5: 0.218401, l6: 0.370184\n",
            "\n",
            "[epoch: 109/100000, batch: 784/1000, ite: 13598] train loss: 1.9712, accuracy: 93.1173%, tar: 0.1047 \n",
            "l0: 0.107999, l1: 0.108824, l2: 0.120393, l3: 0.148591, l4: 0.199383, l5: 0.320431, l6: 0.478504\n",
            "\n",
            "[epoch: 109/100000, batch: 792/1000, ite: 13599] train loss: 1.9712, accuracy: 91.4047%, tar: 0.1047 \n",
            "l0: 0.082738, l1: 0.084260, l2: 0.093522, l3: 0.113975, l4: 0.151440, l5: 0.240887, l6: 0.439655\n",
            "\n",
            "[epoch: 109/100000, batch: 800/1000, ite: 13600] train loss: 1.9710, accuracy: 92.0852%, tar: 0.1047 \n",
            "l0: 0.101446, l1: 0.103262, l2: 0.111623, l3: 0.135086, l4: 0.186664, l5: 0.320177, l6: 0.478652\n",
            "\n",
            "[epoch: 109/100000, batch: 808/1000, ite: 13601] train loss: 1.9710, accuracy: 91.8967%, tar: 0.1047 \n",
            "l0: 0.094040, l1: 0.094661, l2: 0.102263, l3: 0.116503, l4: 0.152110, l5: 0.245592, l6: 0.420145\n",
            "\n",
            "[epoch: 109/100000, batch: 816/1000, ite: 13602] train loss: 1.9708, accuracy: 92.1859%, tar: 0.1047 \n",
            "l0: 0.107435, l1: 0.108795, l2: 0.119466, l3: 0.149441, l4: 0.220466, l5: 0.375498, l6: 0.574239\n",
            "\n",
            "[epoch: 109/100000, batch: 824/1000, ite: 13603] train loss: 1.9709, accuracy: 90.1115%, tar: 0.1047 \n",
            "l0: 0.088394, l1: 0.087636, l2: 0.095944, l3: 0.118387, l4: 0.167873, l5: 0.289186, l6: 0.503190\n",
            "\n",
            "[epoch: 109/100000, batch: 832/1000, ite: 13604] train loss: 1.9709, accuracy: 91.0351%, tar: 0.1047 \n",
            "l0: 0.067225, l1: 0.068475, l2: 0.077078, l3: 0.102214, l4: 0.153713, l5: 0.260067, l6: 0.439874\n",
            "\n",
            "[epoch: 109/100000, batch: 840/1000, ite: 13605] train loss: 1.9706, accuracy: 92.0586%, tar: 0.1046 \n",
            "l0: 0.076101, l1: 0.077830, l2: 0.083846, l3: 0.100805, l4: 0.144303, l5: 0.227246, l6: 0.447399\n",
            "\n",
            "[epoch: 109/100000, batch: 848/1000, ite: 13606] train loss: 1.9704, accuracy: 92.4317%, tar: 0.1046 \n",
            "l0: 0.081225, l1: 0.082456, l2: 0.095426, l3: 0.125515, l4: 0.186640, l5: 0.332214, l6: 0.531938\n",
            "\n",
            "[epoch: 109/100000, batch: 856/1000, ite: 13607] train loss: 1.9704, accuracy: 92.7337%, tar: 0.1046 \n",
            "l0: 0.092849, l1: 0.093797, l2: 0.105102, l3: 0.122536, l4: 0.170937, l5: 0.282283, l6: 0.488806\n",
            "\n",
            "[epoch: 109/100000, batch: 864/1000, ite: 13608] train loss: 1.9704, accuracy: 92.1811%, tar: 0.1046 \n",
            "l0: 0.084634, l1: 0.086257, l2: 0.095076, l3: 0.118992, l4: 0.164193, l5: 0.275882, l6: 0.436931\n",
            "\n",
            "[epoch: 109/100000, batch: 872/1000, ite: 13609] train loss: 1.9702, accuracy: 92.6378%, tar: 0.1046 \n",
            "l0: 0.077057, l1: 0.078428, l2: 0.086808, l3: 0.108109, l4: 0.154591, l5: 0.313503, l6: 0.489860\n",
            "\n",
            "[epoch: 109/100000, batch: 880/1000, ite: 13610] train loss: 1.9701, accuracy: 92.5309%, tar: 0.1046 \n",
            "l0: 0.111374, l1: 0.111845, l2: 0.120780, l3: 0.139379, l4: 0.178743, l5: 0.268903, l6: 0.490400\n",
            "\n",
            "[epoch: 109/100000, batch: 888/1000, ite: 13611] train loss: 1.9701, accuracy: 90.8471%, tar: 0.1046 \n",
            "l0: 0.084958, l1: 0.088641, l2: 0.096643, l3: 0.124756, l4: 0.185162, l5: 0.311796, l6: 0.450710\n",
            "\n",
            "[epoch: 109/100000, batch: 896/1000, ite: 13612] train loss: 1.9700, accuracy: 92.9513%, tar: 0.1046 \n",
            "l0: 0.060501, l1: 0.061559, l2: 0.070666, l3: 0.090161, l4: 0.128296, l5: 0.218036, l6: 0.391411\n",
            "\n",
            "[epoch: 109/100000, batch: 904/1000, ite: 13613] train loss: 1.9696, accuracy: 93.0352%, tar: 0.1045 \n",
            "l0: 0.154411, l1: 0.158562, l2: 0.174425, l3: 0.223850, l4: 0.307980, l5: 0.472873, l6: 0.791625\n",
            "\n",
            "[epoch: 109/100000, batch: 912/1000, ite: 13614] train loss: 1.9703, accuracy: 88.5711%, tar: 0.1046 \n",
            "l0: 0.098243, l1: 0.100585, l2: 0.110458, l3: 0.140779, l4: 0.201133, l5: 0.321574, l6: 0.507541\n",
            "\n",
            "[epoch: 109/100000, batch: 920/1000, ite: 13615] train loss: 1.9703, accuracy: 90.6580%, tar: 0.1046 \n",
            "l0: 0.110287, l1: 0.111601, l2: 0.119249, l3: 0.142252, l4: 0.205488, l5: 0.317670, l6: 0.497259\n",
            "\n",
            "[epoch: 109/100000, batch: 928/1000, ite: 13616] train loss: 1.9704, accuracy: 91.4442%, tar: 0.1046 \n",
            "l0: 0.098583, l1: 0.100301, l2: 0.110145, l3: 0.130769, l4: 0.199321, l5: 0.319742, l6: 0.615784\n",
            "\n",
            "[epoch: 109/100000, batch: 936/1000, ite: 13617] train loss: 1.9705, accuracy: 91.0062%, tar: 0.1046 \n",
            "l0: 0.103220, l1: 0.104126, l2: 0.111128, l3: 0.131740, l4: 0.178507, l5: 0.285693, l6: 0.484775\n",
            "\n",
            "[epoch: 109/100000, batch: 944/1000, ite: 13618] train loss: 1.9704, accuracy: 91.7302%, tar: 0.1046 \n",
            "l0: 0.108023, l1: 0.109714, l2: 0.114286, l3: 0.126332, l4: 0.155423, l5: 0.233807, l6: 0.407615\n",
            "\n",
            "[epoch: 109/100000, batch: 952/1000, ite: 13619] train loss: 1.9702, accuracy: 92.9128%, tar: 0.1046 \n",
            "l0: 0.066613, l1: 0.067229, l2: 0.075739, l3: 0.090304, l4: 0.138880, l5: 0.224907, l6: 0.418099\n",
            "\n",
            "[epoch: 109/100000, batch: 960/1000, ite: 13620] train loss: 1.9699, accuracy: 92.4457%, tar: 0.1045 \n",
            "l0: 0.113475, l1: 0.114343, l2: 0.122839, l3: 0.150872, l4: 0.205091, l5: 0.346780, l6: 0.527544\n",
            "\n",
            "[epoch: 109/100000, batch: 968/1000, ite: 13621] train loss: 1.9700, accuracy: 89.8895%, tar: 0.1045 \n",
            "l0: 0.074817, l1: 0.078064, l2: 0.086079, l3: 0.113134, l4: 0.146295, l5: 0.247548, l6: 0.436532\n",
            "\n",
            "[epoch: 109/100000, batch: 976/1000, ite: 13622] train loss: 1.9698, accuracy: 94.3704%, tar: 0.1045 \n",
            "l0: 0.116365, l1: 0.117280, l2: 0.131769, l3: 0.158981, l4: 0.218536, l5: 0.345207, l6: 0.628738\n",
            "\n",
            "[epoch: 109/100000, batch: 984/1000, ite: 13623] train loss: 1.9701, accuracy: 90.9454%, tar: 0.1045 \n",
            "l0: 0.078734, l1: 0.079327, l2: 0.090928, l3: 0.125770, l4: 0.182756, l5: 0.317541, l6: 0.526960\n",
            "\n",
            "[epoch: 109/100000, batch: 992/1000, ite: 13624] train loss: 1.9701, accuracy: 92.0105%, tar: 0.1045 \n",
            "l0: 0.067621, l1: 0.067725, l2: 0.076879, l3: 0.091688, l4: 0.123036, l5: 0.200750, l6: 0.380986\n",
            "\n",
            "[epoch: 109/100000, batch: 1000/1000, ite: 13625] train loss: 1.9697, accuracy: 94.5737%, tar: 0.1045 \n",
            "l0: 0.146419, l1: 0.147589, l2: 0.155430, l3: 0.168393, l4: 0.221707, l5: 0.312051, l6: 0.544782\n",
            "\n",
            "[epoch: 110/100000, batch: 8/1000, ite: 13626] train loss: 1.9699, accuracy: 90.2742%, tar: 0.1045 \n",
            "l0: 0.084391, l1: 0.085984, l2: 0.095599, l3: 0.119830, l4: 0.165958, l5: 0.278221, l6: 0.459329\n",
            "\n",
            "[epoch: 110/100000, batch: 16/1000, ite: 13627] train loss: 1.9697, accuracy: 91.5698%, tar: 0.1045 \n",
            "l0: 0.108224, l1: 0.110702, l2: 0.121513, l3: 0.146699, l4: 0.213982, l5: 0.337910, l6: 0.566164\n",
            "\n",
            "[epoch: 110/100000, batch: 24/1000, ite: 13628] train loss: 1.9699, accuracy: 90.3863%, tar: 0.1045 \n",
            "l0: 0.130755, l1: 0.132207, l2: 0.140458, l3: 0.173326, l4: 0.254725, l5: 0.366225, l6: 0.617150\n",
            "\n",
            "[epoch: 110/100000, batch: 32/1000, ite: 13629] train loss: 1.9701, accuracy: 91.0542%, tar: 0.1045 \n",
            "l0: 0.052617, l1: 0.052118, l2: 0.061393, l3: 0.081789, l4: 0.119689, l5: 0.188937, l6: 0.355364\n",
            "\n",
            "[epoch: 110/100000, batch: 40/1000, ite: 13630] train loss: 1.9697, accuracy: 93.9569%, tar: 0.1045 \n",
            "l0: 0.117526, l1: 0.118806, l2: 0.128303, l3: 0.153178, l4: 0.221201, l5: 0.351567, l6: 0.566913\n",
            "\n",
            "[epoch: 110/100000, batch: 48/1000, ite: 13631] train loss: 1.9699, accuracy: 90.1736%, tar: 0.1045 \n",
            "l0: 0.110853, l1: 0.110866, l2: 0.118876, l3: 0.139734, l4: 0.186393, l5: 0.277902, l6: 0.487626\n",
            "\n",
            "[epoch: 110/100000, batch: 56/1000, ite: 13632] train loss: 1.9698, accuracy: 90.9489%, tar: 0.1045 \n",
            "l0: 0.091733, l1: 0.091668, l2: 0.101421, l3: 0.125394, l4: 0.180456, l5: 0.273823, l6: 0.459173\n",
            "\n",
            "[epoch: 110/100000, batch: 64/1000, ite: 13633] train loss: 1.9697, accuracy: 91.6583%, tar: 0.1045 \n",
            "l0: 0.118146, l1: 0.118681, l2: 0.131730, l3: 0.158910, l4: 0.234037, l5: 0.388609, l6: 0.589558\n",
            "\n",
            "[epoch: 110/100000, batch: 72/1000, ite: 13634] train loss: 1.9700, accuracy: 90.6922%, tar: 0.1045 \n",
            "l0: 0.092681, l1: 0.093998, l2: 0.102529, l3: 0.131165, l4: 0.198674, l5: 0.289289, l6: 0.440491\n",
            "\n",
            "[epoch: 110/100000, batch: 80/1000, ite: 13635] train loss: 1.9699, accuracy: 92.3845%, tar: 0.1045 \n",
            "l0: 0.082880, l1: 0.084022, l2: 0.093319, l3: 0.117136, l4: 0.178150, l5: 0.286145, l6: 0.506425\n",
            "\n",
            "[epoch: 110/100000, batch: 88/1000, ite: 13636] train loss: 1.9698, accuracy: 91.8236%, tar: 0.1045 \n",
            "l0: 0.075706, l1: 0.077769, l2: 0.087874, l3: 0.110690, l4: 0.149378, l5: 0.240008, l6: 0.428542\n",
            "\n",
            "[epoch: 110/100000, batch: 96/1000, ite: 13637] train loss: 1.9696, accuracy: 92.9279%, tar: 0.1045 \n",
            "l0: 0.094437, l1: 0.095949, l2: 0.104527, l3: 0.132617, l4: 0.199222, l5: 0.320332, l6: 0.546791\n",
            "\n",
            "[epoch: 110/100000, batch: 104/1000, ite: 13638] train loss: 1.9696, accuracy: 91.0006%, tar: 0.1045 \n",
            "l0: 0.100493, l1: 0.102160, l2: 0.107023, l3: 0.126380, l4: 0.160091, l5: 0.249976, l6: 0.380925\n",
            "\n",
            "[epoch: 110/100000, batch: 112/1000, ite: 13639] train loss: 1.9694, accuracy: 92.2042%, tar: 0.1045 \n",
            "l0: 0.091316, l1: 0.094048, l2: 0.102755, l3: 0.126132, l4: 0.171233, l5: 0.257965, l6: 0.388946\n",
            "\n",
            "[epoch: 110/100000, batch: 120/1000, ite: 13640] train loss: 1.9692, accuracy: 94.6356%, tar: 0.1045 \n",
            "l0: 0.085453, l1: 0.086302, l2: 0.096015, l3: 0.119031, l4: 0.164897, l5: 0.265564, l6: 0.496856\n",
            "\n",
            "[epoch: 110/100000, batch: 128/1000, ite: 13641] train loss: 1.9691, accuracy: 91.7604%, tar: 0.1044 \n",
            "l0: 0.063795, l1: 0.064489, l2: 0.073507, l3: 0.092425, l4: 0.136246, l5: 0.228280, l6: 0.398246\n",
            "\n",
            "[epoch: 110/100000, batch: 136/1000, ite: 13642] train loss: 1.9688, accuracy: 92.8809%, tar: 0.1044 \n",
            "l0: 0.094682, l1: 0.096077, l2: 0.107093, l3: 0.130191, l4: 0.193790, l5: 0.324440, l6: 0.527061\n",
            "\n",
            "[epoch: 110/100000, batch: 144/1000, ite: 13643] train loss: 1.9688, accuracy: 92.0279%, tar: 0.1044 \n",
            "l0: 0.066146, l1: 0.067484, l2: 0.076782, l3: 0.106076, l4: 0.145296, l5: 0.264359, l6: 0.450873\n",
            "\n",
            "[epoch: 110/100000, batch: 152/1000, ite: 13644] train loss: 1.9686, accuracy: 93.3348%, tar: 0.1044 \n",
            "l0: 0.085481, l1: 0.086437, l2: 0.094258, l3: 0.114936, l4: 0.169646, l5: 0.258741, l6: 0.449538\n",
            "\n",
            "[epoch: 110/100000, batch: 160/1000, ite: 13645] train loss: 1.9684, accuracy: 92.1787%, tar: 0.1044 \n",
            "l0: 0.095727, l1: 0.096842, l2: 0.104128, l3: 0.123649, l4: 0.163110, l5: 0.230570, l6: 0.417332\n",
            "\n",
            "[epoch: 110/100000, batch: 168/1000, ite: 13646] train loss: 1.9682, accuracy: 92.2189%, tar: 0.1044 \n",
            "l0: 0.089232, l1: 0.089544, l2: 0.098846, l3: 0.117765, l4: 0.164708, l5: 0.279106, l6: 0.523749\n",
            "\n",
            "[epoch: 110/100000, batch: 176/1000, ite: 13647] train loss: 1.9682, accuracy: 92.3388%, tar: 0.1044 \n",
            "l0: 0.092638, l1: 0.093614, l2: 0.101489, l3: 0.121647, l4: 0.173410, l5: 0.275468, l6: 0.491083\n",
            "\n",
            "[epoch: 110/100000, batch: 184/1000, ite: 13648] train loss: 1.9681, accuracy: 92.7290%, tar: 0.1044 \n",
            "l0: 0.107770, l1: 0.108717, l2: 0.121997, l3: 0.148758, l4: 0.220503, l5: 0.331333, l6: 0.566138\n",
            "\n",
            "[epoch: 110/100000, batch: 192/1000, ite: 13649] train loss: 1.9682, accuracy: 91.2005%, tar: 0.1044 \n",
            "l0: 0.076794, l1: 0.077021, l2: 0.082745, l3: 0.099581, l4: 0.137672, l5: 0.206576, l6: 0.372949\n",
            "\n",
            "[epoch: 110/100000, batch: 200/1000, ite: 13650] train loss: 1.9679, accuracy: 93.7313%, tar: 0.1043 \n",
            "l0: 0.083530, l1: 0.085017, l2: 0.097226, l3: 0.126825, l4: 0.176920, l5: 0.278625, l6: 0.468579\n",
            "\n",
            "[epoch: 110/100000, batch: 208/1000, ite: 13651] train loss: 1.9678, accuracy: 91.9391%, tar: 0.1043 \n",
            "l0: 0.056531, l1: 0.057739, l2: 0.065926, l3: 0.086110, l4: 0.127307, l5: 0.197240, l6: 0.394455\n",
            "\n",
            "[epoch: 110/100000, batch: 216/1000, ite: 13652] train loss: 1.9674, accuracy: 93.6575%, tar: 0.1043 \n",
            "l0: 0.071454, l1: 0.072399, l2: 0.079917, l3: 0.096729, l4: 0.138652, l5: 0.235970, l6: 0.399187\n",
            "\n",
            "[epoch: 110/100000, batch: 224/1000, ite: 13653] train loss: 1.9671, accuracy: 93.9104%, tar: 0.1043 \n",
            "l0: 0.112579, l1: 0.113232, l2: 0.123510, l3: 0.149899, l4: 0.213265, l5: 0.316050, l6: 0.533359\n",
            "\n",
            "[epoch: 110/100000, batch: 232/1000, ite: 13654] train loss: 1.9672, accuracy: 91.0213%, tar: 0.1043 \n",
            "l0: 0.096768, l1: 0.096718, l2: 0.104861, l3: 0.125952, l4: 0.176809, l5: 0.258645, l6: 0.449463\n",
            "\n",
            "[epoch: 110/100000, batch: 240/1000, ite: 13655] train loss: 1.9671, accuracy: 92.4837%, tar: 0.1043 \n",
            "l0: 0.078999, l1: 0.080089, l2: 0.087280, l3: 0.102877, l4: 0.120525, l5: 0.177250, l6: 0.334664\n",
            "\n",
            "[epoch: 110/100000, batch: 248/1000, ite: 13656] train loss: 1.9667, accuracy: 93.0062%, tar: 0.1043 \n",
            "l0: 0.080937, l1: 0.082837, l2: 0.092714, l3: 0.116488, l4: 0.177824, l5: 0.322293, l6: 0.571827\n",
            "\n",
            "[epoch: 110/100000, batch: 256/1000, ite: 13657] train loss: 1.9667, accuracy: 92.6900%, tar: 0.1042 \n",
            "l0: 0.077561, l1: 0.078864, l2: 0.087699, l3: 0.113288, l4: 0.161980, l5: 0.255162, l6: 0.409424\n",
            "\n",
            "[epoch: 110/100000, batch: 264/1000, ite: 13658] train loss: 1.9665, accuracy: 93.1157%, tar: 0.1042 \n",
            "l0: 0.082751, l1: 0.083551, l2: 0.093793, l3: 0.117024, l4: 0.167780, l5: 0.275924, l6: 0.434864\n",
            "\n",
            "[epoch: 110/100000, batch: 272/1000, ite: 13659] train loss: 1.9664, accuracy: 92.2934%, tar: 0.1042 \n",
            "l0: 0.076466, l1: 0.078093, l2: 0.088563, l3: 0.114949, l4: 0.178217, l5: 0.286453, l6: 0.465863\n",
            "\n",
            "[epoch: 110/100000, batch: 280/1000, ite: 13660] train loss: 1.9662, accuracy: 92.8398%, tar: 0.1042 \n",
            "l0: 0.057654, l1: 0.059700, l2: 0.066262, l3: 0.086401, l4: 0.127050, l5: 0.197925, l6: 0.336060\n",
            "\n",
            "[epoch: 110/100000, batch: 288/1000, ite: 13661] train loss: 1.9658, accuracy: 93.7768%, tar: 0.1042 \n",
            "l0: 0.097083, l1: 0.098568, l2: 0.111105, l3: 0.143858, l4: 0.218312, l5: 0.295088, l6: 0.554483\n",
            "\n",
            "[epoch: 110/100000, batch: 296/1000, ite: 13662] train loss: 1.9659, accuracy: 92.5493%, tar: 0.1042 \n",
            "l0: 0.076501, l1: 0.077907, l2: 0.088884, l3: 0.113858, l4: 0.182109, l5: 0.300371, l6: 0.532909\n",
            "\n",
            "[epoch: 110/100000, batch: 304/1000, ite: 13663] train loss: 1.9659, accuracy: 91.5166%, tar: 0.1042 \n",
            "l0: 0.078038, l1: 0.078933, l2: 0.086782, l3: 0.108547, l4: 0.161415, l5: 0.263321, l6: 0.486420\n",
            "\n",
            "[epoch: 110/100000, batch: 312/1000, ite: 13664] train loss: 1.9657, accuracy: 92.6865%, tar: 0.1041 \n",
            "l0: 0.060975, l1: 0.061759, l2: 0.065348, l3: 0.077709, l4: 0.108838, l5: 0.175753, l6: 0.295713\n",
            "\n",
            "[epoch: 110/100000, batch: 320/1000, ite: 13665] train loss: 1.9652, accuracy: 95.0375%, tar: 0.1041 \n",
            "l0: 0.068624, l1: 0.069509, l2: 0.078489, l3: 0.099841, l4: 0.147182, l5: 0.243016, l6: 0.433165\n",
            "\n",
            "[epoch: 110/100000, batch: 328/1000, ite: 13666] train loss: 1.9650, accuracy: 93.1851%, tar: 0.1041 \n",
            "l0: 0.078649, l1: 0.079601, l2: 0.087423, l3: 0.100745, l4: 0.139089, l5: 0.225738, l6: 0.378812\n",
            "\n",
            "[epoch: 110/100000, batch: 336/1000, ite: 13667] train loss: 1.9647, accuracy: 93.2612%, tar: 0.1041 \n",
            "l0: 0.101902, l1: 0.103260, l2: 0.112148, l3: 0.135983, l4: 0.184762, l5: 0.285041, l6: 0.536121\n",
            "\n",
            "[epoch: 110/100000, batch: 344/1000, ite: 13668] train loss: 1.9647, accuracy: 90.5518%, tar: 0.1041 \n",
            "l0: 0.102972, l1: 0.103978, l2: 0.110483, l3: 0.133430, l4: 0.182067, l5: 0.286399, l6: 0.455830\n",
            "\n",
            "[epoch: 110/100000, batch: 352/1000, ite: 13669] train loss: 1.9646, accuracy: 92.0550%, tar: 0.1041 \n",
            "l0: 0.146966, l1: 0.148955, l2: 0.157719, l3: 0.177818, l4: 0.238595, l5: 0.406112, l6: 0.671600\n",
            "\n",
            "[epoch: 110/100000, batch: 360/1000, ite: 13670] train loss: 1.9650, accuracy: 87.5110%, tar: 0.1041 \n",
            "l0: 0.080002, l1: 0.081541, l2: 0.087999, l3: 0.108505, l4: 0.160262, l5: 0.248862, l6: 0.496421\n",
            "\n",
            "[epoch: 110/100000, batch: 368/1000, ite: 13671] train loss: 1.9649, accuracy: 91.7070%, tar: 0.1041 \n",
            "l0: 0.092814, l1: 0.093748, l2: 0.101886, l3: 0.122073, l4: 0.179148, l5: 0.279755, l6: 0.496537\n",
            "\n",
            "[epoch: 110/100000, batch: 376/1000, ite: 13672] train loss: 1.9649, accuracy: 91.8126%, tar: 0.1041 \n",
            "l0: 0.116664, l1: 0.121779, l2: 0.130339, l3: 0.160558, l4: 0.244020, l5: 0.404754, l6: 0.672350\n",
            "\n",
            "[epoch: 110/100000, batch: 384/1000, ite: 13673] train loss: 1.9652, accuracy: 90.8338%, tar: 0.1041 \n",
            "l0: 0.106620, l1: 0.107254, l2: 0.117908, l3: 0.146280, l4: 0.212965, l5: 0.325827, l6: 0.498979\n",
            "\n",
            "[epoch: 110/100000, batch: 392/1000, ite: 13674] train loss: 1.9652, accuracy: 90.1646%, tar: 0.1041 \n",
            "l0: 0.070421, l1: 0.070892, l2: 0.080449, l3: 0.097720, l4: 0.133591, l5: 0.223110, l6: 0.428337\n",
            "\n",
            "[epoch: 110/100000, batch: 400/1000, ite: 13675] train loss: 1.9650, accuracy: 92.9631%, tar: 0.1041 \n",
            "l0: 0.071089, l1: 0.072116, l2: 0.079590, l3: 0.101179, l4: 0.140003, l5: 0.210284, l6: 0.387345\n",
            "\n",
            "[epoch: 110/100000, batch: 408/1000, ite: 13676] train loss: 1.9647, accuracy: 94.5231%, tar: 0.1040 \n",
            "l0: 0.107086, l1: 0.109172, l2: 0.118166, l3: 0.146657, l4: 0.201169, l5: 0.341248, l6: 0.531870\n",
            "\n",
            "[epoch: 110/100000, batch: 416/1000, ite: 13677] train loss: 1.9647, accuracy: 91.9203%, tar: 0.1040 \n",
            "l0: 0.091981, l1: 0.093252, l2: 0.099211, l3: 0.118720, l4: 0.154429, l5: 0.211594, l6: 0.356510\n",
            "\n",
            "[epoch: 110/100000, batch: 424/1000, ite: 13678] train loss: 1.9644, accuracy: 93.8245%, tar: 0.1040 \n",
            "l0: 0.092945, l1: 0.094132, l2: 0.107628, l3: 0.140032, l4: 0.206480, l5: 0.353401, l6: 0.597893\n",
            "\n",
            "[epoch: 110/100000, batch: 432/1000, ite: 13679] train loss: 1.9646, accuracy: 89.9728%, tar: 0.1040 \n",
            "l0: 0.092212, l1: 0.093290, l2: 0.103863, l3: 0.127524, l4: 0.184860, l5: 0.311991, l6: 0.474510\n",
            "\n",
            "[epoch: 110/100000, batch: 440/1000, ite: 13680] train loss: 1.9645, accuracy: 92.4535%, tar: 0.1040 \n",
            "l0: 0.091286, l1: 0.092920, l2: 0.102177, l3: 0.130250, l4: 0.183042, l5: 0.281800, l6: 0.481763\n",
            "\n",
            "[epoch: 110/100000, batch: 448/1000, ite: 13681] train loss: 1.9644, accuracy: 91.4722%, tar: 0.1040 \n",
            "l0: 0.076855, l1: 0.078519, l2: 0.085861, l3: 0.102785, l4: 0.131822, l5: 0.215396, l6: 0.367445\n",
            "\n",
            "[epoch: 110/100000, batch: 456/1000, ite: 13682] train loss: 1.9641, accuracy: 92.7230%, tar: 0.1040 \n",
            "l0: 0.087631, l1: 0.088154, l2: 0.095746, l3: 0.121287, l4: 0.167307, l5: 0.248165, l6: 0.471204\n",
            "\n",
            "[epoch: 110/100000, batch: 464/1000, ite: 13683] train loss: 1.9640, accuracy: 93.4503%, tar: 0.1040 \n",
            "l0: 0.116917, l1: 0.117715, l2: 0.127540, l3: 0.160459, l4: 0.221201, l5: 0.293133, l6: 0.456570\n",
            "\n",
            "[epoch: 110/100000, batch: 472/1000, ite: 13684] train loss: 1.9640, accuracy: 91.7993%, tar: 0.1040 \n",
            "l0: 0.090017, l1: 0.091062, l2: 0.099111, l3: 0.121687, l4: 0.190538, l5: 0.289784, l6: 0.508209\n",
            "\n",
            "[epoch: 110/100000, batch: 480/1000, ite: 13685] train loss: 1.9640, accuracy: 91.5707%, tar: 0.1040 \n",
            "l0: 0.075800, l1: 0.075562, l2: 0.083125, l3: 0.109771, l4: 0.154931, l5: 0.220497, l6: 0.388288\n",
            "\n",
            "[epoch: 110/100000, batch: 488/1000, ite: 13686] train loss: 1.9637, accuracy: 93.4922%, tar: 0.1040 \n",
            "l0: 0.064512, l1: 0.064887, l2: 0.073617, l3: 0.097749, l4: 0.156900, l5: 0.249717, l6: 0.375199\n",
            "\n",
            "[epoch: 110/100000, batch: 496/1000, ite: 13687] train loss: 1.9634, accuracy: 94.2797%, tar: 0.1040 \n",
            "l0: 0.107268, l1: 0.108536, l2: 0.118383, l3: 0.145253, l4: 0.197296, l5: 0.307975, l6: 0.475749\n",
            "\n",
            "[epoch: 110/100000, batch: 504/1000, ite: 13688] train loss: 1.9634, accuracy: 91.8732%, tar: 0.1040 \n",
            "l0: 0.086976, l1: 0.087996, l2: 0.095900, l3: 0.125501, l4: 0.200035, l5: 0.306278, l6: 0.512690\n",
            "\n",
            "[epoch: 110/100000, batch: 512/1000, ite: 13689] train loss: 1.9633, accuracy: 91.2764%, tar: 0.1039 \n",
            "l0: 0.079912, l1: 0.081314, l2: 0.091711, l3: 0.119462, l4: 0.171779, l5: 0.301354, l6: 0.492630\n",
            "\n",
            "[epoch: 110/100000, batch: 520/1000, ite: 13690] train loss: 1.9633, accuracy: 92.0847%, tar: 0.1039 \n",
            "l0: 0.084008, l1: 0.085530, l2: 0.095744, l3: 0.124454, l4: 0.168509, l5: 0.268441, l6: 0.532852\n",
            "\n",
            "[epoch: 110/100000, batch: 528/1000, ite: 13691] train loss: 1.9632, accuracy: 92.1129%, tar: 0.1039 \n",
            "l0: 0.081260, l1: 0.082069, l2: 0.090335, l3: 0.109196, l4: 0.159016, l5: 0.280991, l6: 0.475287\n",
            "\n",
            "[epoch: 110/100000, batch: 536/1000, ite: 13692] train loss: 1.9631, accuracy: 93.2409%, tar: 0.1039 \n",
            "l0: 0.071537, l1: 0.072347, l2: 0.081630, l3: 0.102147, l4: 0.149684, l5: 0.233744, l6: 0.401629\n",
            "\n",
            "[epoch: 110/100000, batch: 544/1000, ite: 13693] train loss: 1.9628, accuracy: 92.4878%, tar: 0.1039 \n",
            "l0: 0.101441, l1: 0.102246, l2: 0.113379, l3: 0.143027, l4: 0.195367, l5: 0.315072, l6: 0.507220\n",
            "\n",
            "[epoch: 110/100000, batch: 552/1000, ite: 13694] train loss: 1.9628, accuracy: 90.6849%, tar: 0.1039 \n",
            "l0: 0.087603, l1: 0.089161, l2: 0.098298, l3: 0.120462, l4: 0.164167, l5: 0.250290, l6: 0.420132\n",
            "\n",
            "[epoch: 110/100000, batch: 560/1000, ite: 13695] train loss: 1.9627, accuracy: 93.3504%, tar: 0.1039 \n",
            "l0: 0.108554, l1: 0.109690, l2: 0.119137, l3: 0.146573, l4: 0.198663, l5: 0.301187, l6: 0.529377\n",
            "\n",
            "[epoch: 110/100000, batch: 568/1000, ite: 13696] train loss: 1.9627, accuracy: 92.0574%, tar: 0.1039 \n",
            "l0: 0.103509, l1: 0.104838, l2: 0.114722, l3: 0.141252, l4: 0.210937, l5: 0.357002, l6: 0.611569\n",
            "\n",
            "[epoch: 110/100000, batch: 576/1000, ite: 13697] train loss: 1.9629, accuracy: 89.9778%, tar: 0.1039 \n",
            "l0: 0.100627, l1: 0.101222, l2: 0.112881, l3: 0.136126, l4: 0.196585, l5: 0.311042, l6: 0.537407\n",
            "\n",
            "[epoch: 110/100000, batch: 584/1000, ite: 13698] train loss: 1.9629, accuracy: 91.5090%, tar: 0.1039 \n",
            "l0: 0.106358, l1: 0.107517, l2: 0.118402, l3: 0.148893, l4: 0.202207, l5: 0.301752, l6: 0.509643\n",
            "\n",
            "[epoch: 110/100000, batch: 592/1000, ite: 13699] train loss: 1.9629, accuracy: 91.5142%, tar: 0.1039 \n",
            "l0: 0.112858, l1: 0.115092, l2: 0.128600, l3: 0.157250, l4: 0.221099, l5: 0.340769, l6: 0.548349\n",
            "\n",
            "[epoch: 110/100000, batch: 600/1000, ite: 13700] train loss: 1.9630, accuracy: 91.4989%, tar: 0.1039 \n",
            "l0: 0.087511, l1: 0.088581, l2: 0.098171, l3: 0.129590, l4: 0.210555, l5: 0.315973, l6: 0.520370\n",
            "\n",
            "[epoch: 110/100000, batch: 608/1000, ite: 13701] train loss: 1.9630, accuracy: 91.5192%, tar: 0.1039 \n",
            "l0: 0.096219, l1: 0.098749, l2: 0.103708, l3: 0.119228, l4: 0.139909, l5: 0.201639, l6: 0.344329\n",
            "\n",
            "[epoch: 110/100000, batch: 616/1000, ite: 13702] train loss: 1.9628, accuracy: 92.3952%, tar: 0.1039 \n",
            "l0: 0.085906, l1: 0.086785, l2: 0.095083, l3: 0.114259, l4: 0.153387, l5: 0.248393, l6: 0.535945\n",
            "\n",
            "[epoch: 110/100000, batch: 624/1000, ite: 13703] train loss: 1.9627, accuracy: 90.9668%, tar: 0.1039 \n",
            "l0: 0.073485, l1: 0.074407, l2: 0.080908, l3: 0.104120, l4: 0.153006, l5: 0.221150, l6: 0.379533\n",
            "\n",
            "[epoch: 110/100000, batch: 632/1000, ite: 13704] train loss: 1.9624, accuracy: 92.9757%, tar: 0.1038 \n",
            "l0: 0.086270, l1: 0.088455, l2: 0.101760, l3: 0.133175, l4: 0.203329, l5: 0.331874, l6: 0.534457\n",
            "\n",
            "[epoch: 110/100000, batch: 640/1000, ite: 13705] train loss: 1.9624, accuracy: 92.4164%, tar: 0.1038 \n",
            "l0: 0.088231, l1: 0.089711, l2: 0.096637, l3: 0.120674, l4: 0.171976, l5: 0.256240, l6: 0.442034\n",
            "\n",
            "[epoch: 110/100000, batch: 648/1000, ite: 13706] train loss: 1.9623, accuracy: 92.3294%, tar: 0.1038 \n",
            "l0: 0.090797, l1: 0.092817, l2: 0.105035, l3: 0.128498, l4: 0.187850, l5: 0.296591, l6: 0.521898\n",
            "\n",
            "[epoch: 110/100000, batch: 656/1000, ite: 13707] train loss: 1.9623, accuracy: 91.6784%, tar: 0.1038 \n",
            "l0: 0.099099, l1: 0.099287, l2: 0.107138, l3: 0.126508, l4: 0.174134, l5: 0.287825, l6: 0.538133\n",
            "\n",
            "[epoch: 110/100000, batch: 664/1000, ite: 13708] train loss: 1.9623, accuracy: 90.5553%, tar: 0.1038 \n",
            "l0: 0.055487, l1: 0.056819, l2: 0.065544, l3: 0.086393, l4: 0.139119, l5: 0.221499, l6: 0.422686\n",
            "\n",
            "[epoch: 110/100000, batch: 672/1000, ite: 13709] train loss: 1.9620, accuracy: 93.3712%, tar: 0.1038 \n",
            "l0: 0.117688, l1: 0.119089, l2: 0.132155, l3: 0.177059, l4: 0.256839, l5: 0.373683, l6: 0.582871\n",
            "\n",
            "[epoch: 110/100000, batch: 680/1000, ite: 13710] train loss: 1.9622, accuracy: 91.6100%, tar: 0.1038 \n",
            "l0: 0.070592, l1: 0.072900, l2: 0.082581, l3: 0.109038, l4: 0.171412, l5: 0.255442, l6: 0.428085\n",
            "\n",
            "[epoch: 110/100000, batch: 688/1000, ite: 13711] train loss: 1.9620, accuracy: 92.3144%, tar: 0.1038 \n",
            "l0: 0.072063, l1: 0.073631, l2: 0.081811, l3: 0.097968, l4: 0.139732, l5: 0.222231, l6: 0.374099\n",
            "\n",
            "[epoch: 110/100000, batch: 696/1000, ite: 13712] train loss: 1.9617, accuracy: 93.5658%, tar: 0.1038 \n",
            "l0: 0.079753, l1: 0.081327, l2: 0.089506, l3: 0.113827, l4: 0.168515, l5: 0.255667, l6: 0.478670\n",
            "\n",
            "[epoch: 110/100000, batch: 704/1000, ite: 13713] train loss: 1.9616, accuracy: 93.4417%, tar: 0.1037 \n",
            "l0: 0.095147, l1: 0.096150, l2: 0.106426, l3: 0.135798, l4: 0.194289, l5: 0.323684, l6: 0.541486\n",
            "\n",
            "[epoch: 110/100000, batch: 712/1000, ite: 13714] train loss: 1.9616, accuracy: 91.0632%, tar: 0.1037 \n",
            "l0: 0.090611, l1: 0.091084, l2: 0.102830, l3: 0.130336, l4: 0.192190, l5: 0.321431, l6: 0.523761\n",
            "\n",
            "[epoch: 110/100000, batch: 720/1000, ite: 13715] train loss: 1.9617, accuracy: 91.5200%, tar: 0.1037 \n",
            "l0: 0.100316, l1: 0.102683, l2: 0.115987, l3: 0.152338, l4: 0.201194, l5: 0.318861, l6: 0.605767\n",
            "\n",
            "[epoch: 110/100000, batch: 728/1000, ite: 13716] train loss: 1.9618, accuracy: 90.8902%, tar: 0.1037 \n",
            "l0: 0.062900, l1: 0.063967, l2: 0.075541, l3: 0.094926, l4: 0.132859, l5: 0.199649, l6: 0.360806\n",
            "\n",
            "[epoch: 110/100000, batch: 736/1000, ite: 13717] train loss: 1.9614, accuracy: 93.8534%, tar: 0.1037 \n",
            "l0: 0.083762, l1: 0.085315, l2: 0.093953, l3: 0.118773, l4: 0.185785, l5: 0.307606, l6: 0.520901\n",
            "\n",
            "[epoch: 110/100000, batch: 744/1000, ite: 13718] train loss: 1.9614, accuracy: 92.4353%, tar: 0.1037 \n",
            "l0: 0.063237, l1: 0.064639, l2: 0.073426, l3: 0.091339, l4: 0.133373, l5: 0.222234, l6: 0.372471\n",
            "\n",
            "[epoch: 110/100000, batch: 752/1000, ite: 13719] train loss: 1.9611, accuracy: 93.4879%, tar: 0.1037 \n",
            "l0: 0.098698, l1: 0.100053, l2: 0.109991, l3: 0.137705, l4: 0.188952, l5: 0.277697, l6: 0.488434\n",
            "\n",
            "[epoch: 110/100000, batch: 760/1000, ite: 13720] train loss: 1.9611, accuracy: 91.7464%, tar: 0.1037 \n",
            "l0: 0.079321, l1: 0.080067, l2: 0.085489, l3: 0.099393, l4: 0.141428, l5: 0.257094, l6: 0.490149\n",
            "\n",
            "[epoch: 110/100000, batch: 768/1000, ite: 13721] train loss: 1.9609, accuracy: 91.5019%, tar: 0.1036 \n",
            "l0: 0.126423, l1: 0.127430, l2: 0.137683, l3: 0.156200, l4: 0.209080, l5: 0.305381, l6: 0.469254\n",
            "\n",
            "[epoch: 110/100000, batch: 776/1000, ite: 13722] train loss: 1.9609, accuracy: 92.1972%, tar: 0.1037 \n",
            "l0: 0.114948, l1: 0.115058, l2: 0.125204, l3: 0.151091, l4: 0.215378, l5: 0.335093, l6: 0.552037\n",
            "\n",
            "[epoch: 110/100000, batch: 784/1000, ite: 13723] train loss: 1.9611, accuracy: 90.3376%, tar: 0.1037 \n",
            "l0: 0.067229, l1: 0.067983, l2: 0.075820, l3: 0.094310, l4: 0.131104, l5: 0.232449, l6: 0.388702\n",
            "\n",
            "[epoch: 110/100000, batch: 792/1000, ite: 13724] train loss: 1.9608, accuracy: 93.2681%, tar: 0.1036 \n",
            "l0: 0.065676, l1: 0.066093, l2: 0.073701, l3: 0.093507, l4: 0.133724, l5: 0.201158, l6: 0.376554\n",
            "\n",
            "[epoch: 110/100000, batch: 800/1000, ite: 13725] train loss: 1.9604, accuracy: 93.9386%, tar: 0.1036 \n",
            "l0: 0.141055, l1: 0.142393, l2: 0.153637, l3: 0.189215, l4: 0.259975, l5: 0.373794, l6: 0.690415\n",
            "\n",
            "[epoch: 110/100000, batch: 808/1000, ite: 13726] train loss: 1.9608, accuracy: 88.0579%, tar: 0.1036 \n",
            "l0: 0.057664, l1: 0.058560, l2: 0.064307, l3: 0.081686, l4: 0.112652, l5: 0.174543, l6: 0.326411\n",
            "\n",
            "[epoch: 110/100000, batch: 816/1000, ite: 13727] train loss: 1.9604, accuracy: 93.6439%, tar: 0.1036 \n",
            "l0: 0.072405, l1: 0.075047, l2: 0.080991, l3: 0.102056, l4: 0.141257, l5: 0.231611, l6: 0.429345\n",
            "\n",
            "[epoch: 110/100000, batch: 824/1000, ite: 13728] train loss: 1.9602, accuracy: 93.4141%, tar: 0.1036 \n",
            "l0: 0.095787, l1: 0.097028, l2: 0.103302, l3: 0.123286, l4: 0.171736, l5: 0.223973, l6: 0.361101\n",
            "\n",
            "[epoch: 110/100000, batch: 832/1000, ite: 13729] train loss: 1.9599, accuracy: 93.4040%, tar: 0.1036 \n",
            "l0: 0.091007, l1: 0.092545, l2: 0.102978, l3: 0.135726, l4: 0.197463, l5: 0.306880, l6: 0.458967\n",
            "\n",
            "[epoch: 110/100000, batch: 840/1000, ite: 13730] train loss: 1.9599, accuracy: 92.7524%, tar: 0.1036 \n",
            "l0: 0.082712, l1: 0.083663, l2: 0.089727, l3: 0.111102, l4: 0.155397, l5: 0.239550, l6: 0.407917\n",
            "\n",
            "[epoch: 110/100000, batch: 848/1000, ite: 13731] train loss: 1.9597, accuracy: 93.0496%, tar: 0.1036 \n",
            "l0: 0.086872, l1: 0.087965, l2: 0.094639, l3: 0.116211, l4: 0.166120, l5: 0.260187, l6: 0.485475\n",
            "\n",
            "[epoch: 110/100000, batch: 856/1000, ite: 13732] train loss: 1.9596, accuracy: 92.6328%, tar: 0.1036 \n",
            "l0: 0.067274, l1: 0.068723, l2: 0.077126, l3: 0.098393, l4: 0.137019, l5: 0.240364, l6: 0.481030\n",
            "\n",
            "[epoch: 110/100000, batch: 864/1000, ite: 13733] train loss: 1.9594, accuracy: 93.3512%, tar: 0.1035 \n",
            "l0: 0.083761, l1: 0.084308, l2: 0.090703, l3: 0.114974, l4: 0.169795, l5: 0.268718, l6: 0.464857\n",
            "\n",
            "[epoch: 110/100000, batch: 872/1000, ite: 13734] train loss: 1.9593, accuracy: 91.5885%, tar: 0.1035 \n",
            "l0: 0.082140, l1: 0.082395, l2: 0.094090, l3: 0.119132, l4: 0.173744, l5: 0.252833, l6: 0.467636\n",
            "\n",
            "[epoch: 110/100000, batch: 880/1000, ite: 13735] train loss: 1.9591, accuracy: 92.2218%, tar: 0.1035 \n",
            "l0: 0.077004, l1: 0.078279, l2: 0.086009, l3: 0.101575, l4: 0.136286, l5: 0.219967, l6: 0.430950\n",
            "\n",
            "[epoch: 110/100000, batch: 888/1000, ite: 13736] train loss: 1.9589, accuracy: 93.1524%, tar: 0.1035 \n",
            "l0: 0.083649, l1: 0.085153, l2: 0.094562, l3: 0.118846, l4: 0.169345, l5: 0.263353, l6: 0.446764\n",
            "\n",
            "[epoch: 110/100000, batch: 896/1000, ite: 13737] train loss: 1.9588, accuracy: 92.6823%, tar: 0.1035 \n",
            "l0: 0.095708, l1: 0.096935, l2: 0.109029, l3: 0.134549, l4: 0.189978, l5: 0.302010, l6: 0.473964\n",
            "\n",
            "[epoch: 110/100000, batch: 904/1000, ite: 13738] train loss: 1.9587, accuracy: 92.8389%, tar: 0.1035 \n",
            "l0: 0.151585, l1: 0.153826, l2: 0.164212, l3: 0.193037, l4: 0.244540, l5: 0.347164, l6: 0.568315\n",
            "\n",
            "[epoch: 110/100000, batch: 912/1000, ite: 13739] train loss: 1.9590, accuracy: 90.2033%, tar: 0.1035 \n",
            "l0: 0.082801, l1: 0.083625, l2: 0.091394, l3: 0.121984, l4: 0.204451, l5: 0.318303, l6: 0.466728\n",
            "\n",
            "[epoch: 110/100000, batch: 920/1000, ite: 13740] train loss: 1.9589, accuracy: 92.9077%, tar: 0.1035 \n",
            "l0: 0.076970, l1: 0.078329, l2: 0.086237, l3: 0.109426, l4: 0.155255, l5: 0.229911, l6: 0.396078\n",
            "\n",
            "[epoch: 110/100000, batch: 928/1000, ite: 13741] train loss: 1.9587, accuracy: 92.6171%, tar: 0.1035 \n",
            "l0: 0.083546, l1: 0.084273, l2: 0.094327, l3: 0.121227, l4: 0.173933, l5: 0.300428, l6: 0.518558\n",
            "\n",
            "[epoch: 110/100000, batch: 936/1000, ite: 13742] train loss: 1.9586, accuracy: 92.3075%, tar: 0.1035 \n",
            "l0: 0.083268, l1: 0.083354, l2: 0.095433, l3: 0.119504, l4: 0.172423, l5: 0.252811, l6: 0.383223\n",
            "\n",
            "[epoch: 110/100000, batch: 944/1000, ite: 13743] train loss: 1.9584, accuracy: 93.5977%, tar: 0.1035 \n",
            "l0: 0.083073, l1: 0.083483, l2: 0.089859, l3: 0.104304, l4: 0.134311, l5: 0.220881, l6: 0.384946\n",
            "\n",
            "[epoch: 110/100000, batch: 952/1000, ite: 13744] train loss: 1.9581, accuracy: 93.2093%, tar: 0.1035 \n",
            "l0: 0.109180, l1: 0.111197, l2: 0.124234, l3: 0.155140, l4: 0.217270, l5: 0.311458, l6: 0.531530\n",
            "\n",
            "[epoch: 110/100000, batch: 960/1000, ite: 13745] train loss: 1.9582, accuracy: 90.9755%, tar: 0.1035 \n",
            "l0: 0.082618, l1: 0.082706, l2: 0.096096, l3: 0.123698, l4: 0.180491, l5: 0.315275, l6: 0.616186\n",
            "\n",
            "[epoch: 110/100000, batch: 968/1000, ite: 13746] train loss: 1.9583, accuracy: 90.7093%, tar: 0.1034 \n",
            "l0: 0.079989, l1: 0.079784, l2: 0.086518, l3: 0.106823, l4: 0.159949, l5: 0.248410, l6: 0.383374\n",
            "\n",
            "[epoch: 110/100000, batch: 976/1000, ite: 13747] train loss: 1.9581, accuracy: 92.4362%, tar: 0.1034 \n",
            "l0: 0.110493, l1: 0.111933, l2: 0.124363, l3: 0.154283, l4: 0.223673, l5: 0.397439, l6: 0.602038\n",
            "\n",
            "[epoch: 110/100000, batch: 984/1000, ite: 13748] train loss: 1.9583, accuracy: 90.4045%, tar: 0.1034 \n",
            "l0: 0.093596, l1: 0.094022, l2: 0.102797, l3: 0.134483, l4: 0.222017, l5: 0.349986, l6: 0.541915\n",
            "\n",
            "[epoch: 110/100000, batch: 992/1000, ite: 13749] train loss: 1.9584, accuracy: 89.9385%, tar: 0.1034 \n",
            "l0: 0.111253, l1: 0.113426, l2: 0.124868, l3: 0.149716, l4: 0.206573, l5: 0.364384, l6: 0.616238\n",
            "\n",
            "[epoch: 110/100000, batch: 1000/1000, ite: 13750] train loss: 1.9586, accuracy: 91.1887%, tar: 0.1034 \n",
            "l0: 0.082305, l1: 0.084866, l2: 0.094011, l3: 0.121807, l4: 0.180543, l5: 0.293544, l6: 0.492798\n",
            "\n",
            "[epoch: 111/100000, batch: 8/1000, ite: 13751] train loss: 1.9585, accuracy: 92.4872%, tar: 0.1034 \n",
            "l0: 0.077102, l1: 0.078056, l2: 0.085230, l3: 0.105982, l4: 0.138310, l5: 0.199203, l6: 0.313280\n",
            "\n",
            "[epoch: 111/100000, batch: 16/1000, ite: 13752] train loss: 1.9581, accuracy: 93.6647%, tar: 0.1034 \n",
            "l0: 0.078489, l1: 0.078633, l2: 0.087969, l3: 0.109731, l4: 0.149092, l5: 0.248857, l6: 0.439057\n",
            "\n",
            "[epoch: 111/100000, batch: 24/1000, ite: 13753] train loss: 1.9579, accuracy: 92.4334%, tar: 0.1034 \n",
            "l0: 0.100579, l1: 0.103118, l2: 0.109076, l3: 0.135965, l4: 0.205088, l5: 0.277585, l6: 0.442635\n",
            "\n",
            "[epoch: 111/100000, batch: 32/1000, ite: 13754] train loss: 1.9579, accuracy: 93.1935%, tar: 0.1034 \n",
            "l0: 0.076477, l1: 0.077750, l2: 0.086031, l3: 0.109129, l4: 0.176885, l5: 0.304857, l6: 0.519911\n",
            "\n",
            "[epoch: 111/100000, batch: 40/1000, ite: 13755] train loss: 1.9578, accuracy: 91.4580%, tar: 0.1034 \n",
            "l0: 0.098658, l1: 0.100114, l2: 0.110348, l3: 0.140055, l4: 0.208126, l5: 0.356245, l6: 0.586611\n",
            "\n",
            "[epoch: 111/100000, batch: 48/1000, ite: 13756] train loss: 1.9579, accuracy: 90.2898%, tar: 0.1034 \n",
            "l0: 0.099722, l1: 0.101208, l2: 0.109560, l3: 0.131613, l4: 0.196352, l5: 0.331587, l6: 0.590981\n",
            "\n",
            "[epoch: 111/100000, batch: 56/1000, ite: 13757] train loss: 1.9580, accuracy: 91.1188%, tar: 0.1034 \n",
            "l0: 0.096516, l1: 0.097479, l2: 0.109438, l3: 0.143741, l4: 0.220352, l5: 0.364854, l6: 0.622801\n",
            "\n",
            "[epoch: 111/100000, batch: 64/1000, ite: 13758] train loss: 1.9582, accuracy: 90.6604%, tar: 0.1034 \n",
            "l0: 0.093304, l1: 0.095675, l2: 0.108393, l3: 0.140617, l4: 0.207141, l5: 0.314060, l6: 0.526686\n",
            "\n",
            "[epoch: 111/100000, batch: 72/1000, ite: 13759] train loss: 1.9583, accuracy: 92.1645%, tar: 0.1034 \n",
            "l0: 0.085103, l1: 0.085928, l2: 0.094104, l3: 0.114935, l4: 0.164221, l5: 0.267333, l6: 0.479399\n",
            "\n",
            "[epoch: 111/100000, batch: 80/1000, ite: 13760] train loss: 1.9582, accuracy: 91.6995%, tar: 0.1034 \n",
            "l0: 0.067816, l1: 0.069232, l2: 0.078255, l3: 0.103224, l4: 0.147399, l5: 0.242560, l6: 0.404611\n",
            "\n",
            "[epoch: 111/100000, batch: 88/1000, ite: 13761] train loss: 1.9579, accuracy: 93.6023%, tar: 0.1033 \n",
            "l0: 0.082136, l1: 0.083044, l2: 0.092409, l3: 0.124410, l4: 0.197338, l5: 0.304545, l6: 0.540971\n",
            "\n",
            "[epoch: 111/100000, batch: 96/1000, ite: 13762] train loss: 1.9579, accuracy: 91.2881%, tar: 0.1033 \n",
            "l0: 0.070851, l1: 0.071018, l2: 0.078863, l3: 0.095871, l4: 0.138020, l5: 0.229884, l6: 0.421179\n",
            "\n",
            "[epoch: 111/100000, batch: 104/1000, ite: 13763] train loss: 1.9577, accuracy: 92.8478%, tar: 0.1033 \n",
            "l0: 0.075305, l1: 0.075983, l2: 0.085519, l3: 0.110198, l4: 0.153213, l5: 0.241041, l6: 0.441271\n",
            "\n",
            "[epoch: 111/100000, batch: 112/1000, ite: 13764] train loss: 1.9575, accuracy: 92.2716%, tar: 0.1033 \n",
            "l0: 0.123622, l1: 0.125047, l2: 0.133102, l3: 0.154000, l4: 0.203356, l5: 0.287346, l6: 0.507144\n",
            "\n",
            "[epoch: 111/100000, batch: 120/1000, ite: 13765] train loss: 1.9576, accuracy: 91.4173%, tar: 0.1033 \n",
            "l0: 0.112632, l1: 0.114240, l2: 0.123479, l3: 0.146197, l4: 0.192600, l5: 0.310911, l6: 0.540872\n",
            "\n",
            "[epoch: 111/100000, batch: 128/1000, ite: 13766] train loss: 1.9576, accuracy: 90.7078%, tar: 0.1033 \n",
            "l0: 0.077804, l1: 0.077966, l2: 0.091198, l3: 0.116951, l4: 0.174184, l5: 0.274121, l6: 0.490416\n",
            "\n",
            "[epoch: 111/100000, batch: 136/1000, ite: 13767] train loss: 1.9575, accuracy: 91.6583%, tar: 0.1033 \n",
            "l0: 0.082187, l1: 0.084058, l2: 0.092617, l3: 0.112813, l4: 0.163629, l5: 0.266719, l6: 0.497344\n",
            "\n",
            "[epoch: 111/100000, batch: 144/1000, ite: 13768] train loss: 1.9574, accuracy: 91.4292%, tar: 0.1033 \n",
            "l0: 0.089592, l1: 0.089983, l2: 0.097922, l3: 0.115999, l4: 0.139353, l5: 0.186897, l6: 0.371292\n",
            "\n",
            "[epoch: 111/100000, batch: 152/1000, ite: 13769] train loss: 1.9572, accuracy: 94.1950%, tar: 0.1033 \n",
            "l0: 0.082783, l1: 0.083466, l2: 0.092651, l3: 0.114816, l4: 0.175137, l5: 0.281397, l6: 0.475776\n",
            "\n",
            "[epoch: 111/100000, batch: 160/1000, ite: 13770] train loss: 1.9571, accuracy: 93.2161%, tar: 0.1033 \n",
            "l0: 0.080477, l1: 0.082097, l2: 0.090211, l3: 0.120888, l4: 0.172182, l5: 0.248549, l6: 0.440552\n",
            "\n",
            "[epoch: 111/100000, batch: 168/1000, ite: 13771] train loss: 1.9569, accuracy: 92.8443%, tar: 0.1032 \n",
            "l0: 0.083013, l1: 0.084087, l2: 0.094737, l3: 0.118196, l4: 0.178410, l5: 0.292186, l6: 0.493886\n",
            "\n",
            "[epoch: 111/100000, batch: 176/1000, ite: 13772] train loss: 1.9568, accuracy: 91.3278%, tar: 0.1032 \n",
            "l0: 0.108846, l1: 0.109762, l2: 0.120485, l3: 0.148562, l4: 0.218022, l5: 0.340632, l6: 0.538687\n",
            "\n",
            "[epoch: 111/100000, batch: 184/1000, ite: 13773] train loss: 1.9569, accuracy: 91.6230%, tar: 0.1032 \n",
            "l0: 0.074356, l1: 0.075531, l2: 0.086061, l3: 0.108652, l4: 0.168260, l5: 0.300994, l6: 0.466004\n",
            "\n",
            "[epoch: 111/100000, batch: 192/1000, ite: 13774] train loss: 1.9568, accuracy: 92.5501%, tar: 0.1032 \n",
            "l0: 0.137128, l1: 0.139247, l2: 0.151991, l3: 0.187371, l4: 0.254365, l5: 0.421115, l6: 0.733733\n",
            "\n",
            "[epoch: 111/100000, batch: 200/1000, ite: 13775] train loss: 1.9573, accuracy: 90.1995%, tar: 0.1032 \n",
            "l0: 0.082321, l1: 0.083556, l2: 0.094933, l3: 0.114026, l4: 0.154761, l5: 0.260940, l6: 0.485760\n",
            "\n",
            "[epoch: 111/100000, batch: 208/1000, ite: 13776] train loss: 1.9572, accuracy: 92.5507%, tar: 0.1032 \n",
            "l0: 0.062652, l1: 0.063340, l2: 0.069850, l3: 0.088426, l4: 0.126761, l5: 0.201300, l6: 0.368701\n",
            "\n",
            "[epoch: 111/100000, batch: 216/1000, ite: 13777] train loss: 1.9568, accuracy: 94.1192%, tar: 0.1032 \n",
            "l0: 0.059207, l1: 0.059905, l2: 0.067818, l3: 0.085758, l4: 0.124616, l5: 0.200232, l6: 0.361666\n",
            "\n",
            "[epoch: 111/100000, batch: 224/1000, ite: 13778] train loss: 1.9565, accuracy: 93.4149%, tar: 0.1032 \n",
            "l0: 0.086722, l1: 0.088141, l2: 0.098204, l3: 0.113750, l4: 0.148748, l5: 0.227708, l6: 0.415772\n",
            "\n",
            "[epoch: 111/100000, batch: 232/1000, ite: 13779] train loss: 1.9563, accuracy: 92.3156%, tar: 0.1032 \n",
            "l0: 0.124044, l1: 0.125764, l2: 0.131875, l3: 0.150207, l4: 0.201050, l5: 0.283456, l6: 0.421021\n",
            "\n",
            "[epoch: 111/100000, batch: 240/1000, ite: 13780] train loss: 1.9562, accuracy: 91.9998%, tar: 0.1032 \n",
            "l0: 0.080957, l1: 0.083587, l2: 0.092511, l3: 0.107294, l4: 0.155012, l5: 0.244651, l6: 0.468140\n",
            "\n",
            "[epoch: 111/100000, batch: 248/1000, ite: 13781] train loss: 1.9561, accuracy: 92.2770%, tar: 0.1032 \n",
            "l0: 0.112978, l1: 0.114884, l2: 0.124092, l3: 0.143772, l4: 0.190193, l5: 0.290718, l6: 0.496688\n",
            "\n",
            "[epoch: 111/100000, batch: 256/1000, ite: 13782] train loss: 1.9561, accuracy: 91.0444%, tar: 0.1032 \n",
            "l0: 0.065157, l1: 0.065588, l2: 0.073068, l3: 0.087437, l4: 0.120120, l5: 0.174324, l6: 0.308277\n",
            "\n",
            "[epoch: 111/100000, batch: 264/1000, ite: 13783] train loss: 1.9557, accuracy: 93.6843%, tar: 0.1032 \n",
            "l0: 0.073434, l1: 0.074598, l2: 0.084046, l3: 0.112896, l4: 0.176061, l5: 0.268565, l6: 0.409270\n",
            "\n",
            "[epoch: 111/100000, batch: 272/1000, ite: 13784] train loss: 1.9555, accuracy: 92.3074%, tar: 0.1031 \n",
            "l0: 0.085031, l1: 0.085979, l2: 0.093552, l3: 0.124225, l4: 0.187919, l5: 0.306040, l6: 0.496657\n",
            "\n",
            "[epoch: 111/100000, batch: 280/1000, ite: 13785] train loss: 1.9555, accuracy: 90.4111%, tar: 0.1031 \n",
            "l0: 0.084488, l1: 0.085888, l2: 0.094216, l3: 0.110623, l4: 0.153160, l5: 0.238385, l6: 0.416667\n",
            "\n",
            "[epoch: 111/100000, batch: 288/1000, ite: 13786] train loss: 1.9553, accuracy: 92.2257%, tar: 0.1031 \n",
            "l0: 0.086790, l1: 0.087107, l2: 0.095233, l3: 0.114598, l4: 0.174796, l5: 0.289831, l6: 0.472147\n",
            "\n",
            "[epoch: 111/100000, batch: 296/1000, ite: 13787] train loss: 1.9552, accuracy: 93.0410%, tar: 0.1031 \n",
            "l0: 0.081797, l1: 0.083078, l2: 0.093420, l3: 0.111144, l4: 0.159511, l5: 0.255011, l6: 0.412139\n",
            "\n",
            "[epoch: 111/100000, batch: 304/1000, ite: 13788] train loss: 1.9550, accuracy: 92.7967%, tar: 0.1031 \n",
            "l0: 0.091217, l1: 0.092415, l2: 0.100403, l3: 0.122387, l4: 0.171799, l5: 0.247568, l6: 0.388313\n",
            "\n",
            "[epoch: 111/100000, batch: 312/1000, ite: 13789] train loss: 1.9548, accuracy: 92.9849%, tar: 0.1031 \n",
            "l0: 0.110909, l1: 0.112608, l2: 0.122997, l3: 0.144460, l4: 0.182286, l5: 0.276791, l6: 0.480281\n",
            "\n",
            "[epoch: 111/100000, batch: 320/1000, ite: 13790] train loss: 1.9548, accuracy: 90.8511%, tar: 0.1031 \n",
            "l0: 0.111105, l1: 0.112386, l2: 0.126845, l3: 0.157141, l4: 0.224736, l5: 0.352996, l6: 0.552059\n",
            "\n",
            "[epoch: 111/100000, batch: 328/1000, ite: 13791] train loss: 1.9549, accuracy: 91.3799%, tar: 0.1031 \n",
            "l0: 0.099352, l1: 0.100290, l2: 0.110393, l3: 0.134109, l4: 0.176766, l5: 0.280884, l6: 0.547010\n",
            "\n",
            "[epoch: 111/100000, batch: 336/1000, ite: 13792] train loss: 1.9549, accuracy: 91.7343%, tar: 0.1031 \n",
            "l0: 0.090101, l1: 0.091078, l2: 0.097675, l3: 0.120460, l4: 0.169873, l5: 0.282704, l6: 0.467871\n",
            "\n",
            "[epoch: 111/100000, batch: 344/1000, ite: 13793] train loss: 1.9549, accuracy: 91.6145%, tar: 0.1031 \n",
            "l0: 0.067669, l1: 0.068872, l2: 0.078669, l3: 0.105699, l4: 0.166657, l5: 0.276130, l6: 0.417646\n",
            "\n",
            "[epoch: 111/100000, batch: 352/1000, ite: 13794] train loss: 1.9547, accuracy: 93.6717%, tar: 0.1031 \n",
            "l0: 0.087217, l1: 0.088964, l2: 0.095343, l3: 0.128595, l4: 0.193886, l5: 0.326151, l6: 0.576574\n",
            "\n",
            "[epoch: 111/100000, batch: 360/1000, ite: 13795] train loss: 1.9547, accuracy: 92.0309%, tar: 0.1031 \n",
            "l0: 0.103560, l1: 0.104709, l2: 0.112772, l3: 0.136285, l4: 0.172909, l5: 0.271816, l6: 0.441204\n",
            "\n",
            "[epoch: 111/100000, batch: 368/1000, ite: 13796] train loss: 1.9547, accuracy: 92.4286%, tar: 0.1031 \n",
            "l0: 0.075043, l1: 0.075817, l2: 0.083529, l3: 0.107372, l4: 0.145221, l5: 0.211841, l6: 0.373154\n",
            "\n",
            "[epoch: 111/100000, batch: 376/1000, ite: 13797] train loss: 1.9544, accuracy: 93.3720%, tar: 0.1030 \n",
            "l0: 0.099694, l1: 0.100655, l2: 0.110080, l3: 0.138417, l4: 0.192753, l5: 0.287193, l6: 0.456661\n",
            "\n",
            "[epoch: 111/100000, batch: 384/1000, ite: 13798] train loss: 1.9543, accuracy: 91.7248%, tar: 0.1030 \n",
            "l0: 0.083389, l1: 0.084715, l2: 0.093235, l3: 0.114936, l4: 0.161007, l5: 0.270021, l6: 0.482886\n",
            "\n",
            "[epoch: 111/100000, batch: 392/1000, ite: 13799] train loss: 1.9542, accuracy: 91.4198%, tar: 0.1030 \n",
            "l0: 0.070120, l1: 0.070974, l2: 0.078614, l3: 0.102901, l4: 0.145488, l5: 0.225160, l6: 0.375005\n",
            "\n",
            "[epoch: 111/100000, batch: 400/1000, ite: 13800] train loss: 1.9540, accuracy: 92.2897%, tar: 0.1030 \n",
            "l0: 0.081433, l1: 0.082772, l2: 0.087890, l3: 0.114361, l4: 0.141521, l5: 0.192136, l6: 0.330305\n",
            "\n",
            "[epoch: 111/100000, batch: 408/1000, ite: 13801] train loss: 1.9536, accuracy: 93.7079%, tar: 0.1030 \n",
            "l0: 0.091821, l1: 0.093843, l2: 0.103421, l3: 0.134300, l4: 0.187544, l5: 0.242762, l6: 0.399846\n",
            "\n",
            "[epoch: 111/100000, batch: 416/1000, ite: 13802] train loss: 1.9535, accuracy: 93.9508%, tar: 0.1030 \n",
            "l0: 0.090794, l1: 0.092687, l2: 0.101906, l3: 0.124896, l4: 0.176673, l5: 0.260821, l6: 0.411810\n",
            "\n",
            "[epoch: 111/100000, batch: 424/1000, ite: 13803] train loss: 1.9533, accuracy: 93.5222%, tar: 0.1030 \n",
            "l0: 0.108774, l1: 0.106814, l2: 0.113616, l3: 0.141607, l4: 0.190284, l5: 0.297174, l6: 0.516842\n",
            "\n",
            "[epoch: 111/100000, batch: 432/1000, ite: 13804] train loss: 1.9533, accuracy: 91.8554%, tar: 0.1030 \n",
            "l0: 0.077353, l1: 0.077858, l2: 0.084339, l3: 0.105985, l4: 0.154055, l5: 0.262536, l6: 0.499747\n",
            "\n",
            "[epoch: 111/100000, batch: 440/1000, ite: 13805] train loss: 1.9532, accuracy: 91.1931%, tar: 0.1030 \n",
            "l0: 0.107201, l1: 0.109293, l2: 0.116993, l3: 0.152402, l4: 0.221741, l5: 0.337568, l6: 0.628456\n",
            "\n",
            "[epoch: 111/100000, batch: 448/1000, ite: 13806] train loss: 1.9534, accuracy: 90.9266%, tar: 0.1030 \n",
            "l0: 0.084597, l1: 0.085510, l2: 0.092349, l3: 0.109055, l4: 0.148112, l5: 0.224971, l6: 0.365662\n",
            "\n",
            "[epoch: 111/100000, batch: 456/1000, ite: 13807] train loss: 1.9532, accuracy: 93.1252%, tar: 0.1030 \n",
            "l0: 0.101637, l1: 0.101845, l2: 0.110241, l3: 0.139684, l4: 0.206656, l5: 0.318470, l6: 0.595199\n",
            "\n",
            "[epoch: 111/100000, batch: 464/1000, ite: 13808] train loss: 1.9533, accuracy: 90.8895%, tar: 0.1030 \n",
            "l0: 0.090285, l1: 0.091797, l2: 0.105333, l3: 0.134098, l4: 0.199961, l5: 0.331483, l6: 0.502564\n",
            "\n",
            "[epoch: 111/100000, batch: 472/1000, ite: 13809] train loss: 1.9533, accuracy: 92.5477%, tar: 0.1030 \n",
            "l0: 0.092450, l1: 0.093243, l2: 0.100507, l3: 0.125962, l4: 0.192391, l5: 0.273514, l6: 0.464024\n",
            "\n",
            "[epoch: 111/100000, batch: 480/1000, ite: 13810] train loss: 1.9532, accuracy: 92.9980%, tar: 0.1030 \n",
            "l0: 0.085762, l1: 0.086918, l2: 0.096967, l3: 0.117512, l4: 0.173967, l5: 0.286088, l6: 0.527235\n",
            "\n",
            "[epoch: 111/100000, batch: 488/1000, ite: 13811] train loss: 1.9532, accuracy: 91.0297%, tar: 0.1029 \n",
            "l0: 0.079189, l1: 0.080599, l2: 0.089699, l3: 0.114138, l4: 0.169389, l5: 0.245447, l6: 0.401395\n",
            "\n",
            "[epoch: 111/100000, batch: 496/1000, ite: 13812] train loss: 1.9530, accuracy: 93.6430%, tar: 0.1029 \n",
            "l0: 0.081478, l1: 0.082440, l2: 0.090416, l3: 0.113177, l4: 0.161454, l5: 0.274043, l6: 0.510699\n",
            "\n",
            "[epoch: 111/100000, batch: 504/1000, ite: 13813] train loss: 1.9529, accuracy: 91.7084%, tar: 0.1029 \n",
            "l0: 0.054142, l1: 0.055110, l2: 0.061751, l3: 0.086006, l4: 0.133237, l5: 0.246873, l6: 0.425374\n",
            "\n",
            "[epoch: 111/100000, batch: 512/1000, ite: 13814] train loss: 1.9527, accuracy: 92.8013%, tar: 0.1029 \n",
            "l0: 0.094023, l1: 0.095587, l2: 0.106015, l3: 0.125364, l4: 0.191519, l5: 0.328407, l6: 0.538423\n",
            "\n",
            "[epoch: 111/100000, batch: 520/1000, ite: 13815] train loss: 1.9527, accuracy: 91.3449%, tar: 0.1029 \n",
            "l0: 0.104600, l1: 0.106072, l2: 0.116291, l3: 0.153420, l4: 0.215001, l5: 0.319814, l6: 0.518154\n",
            "\n",
            "[epoch: 111/100000, batch: 528/1000, ite: 13816] train loss: 1.9528, accuracy: 92.2072%, tar: 0.1029 \n",
            "l0: 0.077037, l1: 0.078817, l2: 0.089535, l3: 0.110299, l4: 0.169535, l5: 0.298169, l6: 0.482874\n",
            "\n",
            "[epoch: 111/100000, batch: 536/1000, ite: 13817] train loss: 1.9527, accuracy: 92.8675%, tar: 0.1029 \n",
            "l0: 0.103662, l1: 0.104269, l2: 0.112083, l3: 0.133161, l4: 0.191284, l5: 0.302685, l6: 0.505059\n",
            "\n",
            "[epoch: 111/100000, batch: 544/1000, ite: 13818] train loss: 1.9527, accuracy: 91.7106%, tar: 0.1029 \n",
            "l0: 0.090290, l1: 0.091369, l2: 0.100389, l3: 0.124175, l4: 0.175465, l5: 0.266172, l6: 0.493919\n",
            "\n",
            "[epoch: 111/100000, batch: 552/1000, ite: 13819] train loss: 1.9527, accuracy: 90.8898%, tar: 0.1029 \n",
            "l0: 0.076099, l1: 0.077271, l2: 0.083724, l3: 0.102689, l4: 0.143222, l5: 0.225835, l6: 0.372568\n",
            "\n",
            "[epoch: 111/100000, batch: 560/1000, ite: 13820] train loss: 1.9524, accuracy: 94.0783%, tar: 0.1029 \n",
            "l0: 0.072470, l1: 0.073475, l2: 0.080756, l3: 0.099781, l4: 0.147182, l5: 0.244562, l6: 0.456742\n",
            "\n",
            "[epoch: 111/100000, batch: 568/1000, ite: 13821] train loss: 1.9522, accuracy: 92.5499%, tar: 0.1028 \n",
            "l0: 0.093353, l1: 0.094823, l2: 0.104109, l3: 0.127053, l4: 0.178563, l5: 0.290332, l6: 0.540578\n",
            "\n",
            "[epoch: 111/100000, batch: 576/1000, ite: 13822] train loss: 1.9522, accuracy: 90.4425%, tar: 0.1028 \n",
            "l0: 0.092921, l1: 0.094559, l2: 0.101850, l3: 0.122405, l4: 0.155525, l5: 0.261428, l6: 0.448946\n",
            "\n",
            "[epoch: 111/100000, batch: 584/1000, ite: 13823] train loss: 1.9521, accuracy: 92.0028%, tar: 0.1028 \n",
            "l0: 0.098334, l1: 0.099303, l2: 0.112132, l3: 0.144929, l4: 0.218078, l5: 0.380854, l6: 0.613937\n",
            "\n",
            "[epoch: 111/100000, batch: 592/1000, ite: 13824] train loss: 1.9523, accuracy: 90.2523%, tar: 0.1028 \n",
            "l0: 0.114586, l1: 0.115755, l2: 0.128152, l3: 0.156026, l4: 0.219323, l5: 0.373268, l6: 0.571945\n",
            "\n",
            "[epoch: 111/100000, batch: 600/1000, ite: 13825] train loss: 1.9525, accuracy: 90.9571%, tar: 0.1028 \n",
            "l0: 0.072413, l1: 0.072294, l2: 0.077932, l3: 0.098465, l4: 0.138694, l5: 0.203691, l6: 0.366048\n",
            "\n",
            "[epoch: 111/100000, batch: 608/1000, ite: 13826] train loss: 1.9522, accuracy: 93.1005%, tar: 0.1028 \n",
            "l0: 0.074503, l1: 0.075694, l2: 0.082943, l3: 0.099138, l4: 0.136785, l5: 0.200410, l6: 0.423761\n",
            "\n",
            "[epoch: 111/100000, batch: 616/1000, ite: 13827] train loss: 1.9519, accuracy: 92.8972%, tar: 0.1028 \n",
            "l0: 0.070553, l1: 0.071070, l2: 0.081406, l3: 0.104921, l4: 0.141391, l5: 0.232750, l6: 0.430759\n",
            "\n",
            "[epoch: 111/100000, batch: 624/1000, ite: 13828] train loss: 1.9517, accuracy: 91.9105%, tar: 0.1028 \n",
            "l0: 0.109906, l1: 0.111340, l2: 0.120255, l3: 0.146676, l4: 0.213189, l5: 0.368999, l6: 0.616360\n",
            "\n",
            "[epoch: 111/100000, batch: 632/1000, ite: 13829] train loss: 1.9519, accuracy: 90.4358%, tar: 0.1028 \n",
            "l0: 0.069575, l1: 0.069936, l2: 0.079723, l3: 0.099599, l4: 0.145230, l5: 0.219203, l6: 0.352666\n",
            "\n",
            "[epoch: 111/100000, batch: 640/1000, ite: 13830] train loss: 1.9516, accuracy: 93.3012%, tar: 0.1028 \n",
            "l0: 0.084757, l1: 0.086427, l2: 0.097784, l3: 0.132424, l4: 0.200611, l5: 0.302053, l6: 0.486937\n",
            "\n",
            "[epoch: 111/100000, batch: 648/1000, ite: 13831] train loss: 1.9516, accuracy: 93.5245%, tar: 0.1028 \n",
            "l0: 0.081087, l1: 0.081678, l2: 0.092183, l3: 0.108776, l4: 0.146735, l5: 0.248413, l6: 0.524611\n",
            "\n",
            "[epoch: 111/100000, batch: 656/1000, ite: 13832] train loss: 1.9515, accuracy: 91.8349%, tar: 0.1027 \n",
            "l0: 0.128325, l1: 0.128601, l2: 0.139037, l3: 0.162467, l4: 0.234841, l5: 0.379242, l6: 0.575715\n",
            "\n",
            "[epoch: 111/100000, batch: 664/1000, ite: 13833] train loss: 1.9517, accuracy: 92.2506%, tar: 0.1028 \n",
            "l0: 0.111785, l1: 0.112637, l2: 0.127393, l3: 0.161611, l4: 0.255147, l5: 0.385948, l6: 0.680149\n",
            "\n",
            "[epoch: 111/100000, batch: 672/1000, ite: 13834] train loss: 1.9520, accuracy: 89.8803%, tar: 0.1028 \n",
            "l0: 0.064995, l1: 0.066510, l2: 0.077625, l3: 0.111419, l4: 0.194064, l5: 0.343149, l6: 0.497562\n",
            "\n",
            "[epoch: 111/100000, batch: 680/1000, ite: 13835] train loss: 1.9520, accuracy: 93.4048%, tar: 0.1027 \n",
            "l0: 0.075890, l1: 0.077443, l2: 0.089853, l3: 0.118912, l4: 0.181178, l5: 0.326271, l6: 0.550999\n",
            "\n",
            "[epoch: 111/100000, batch: 688/1000, ite: 13836] train loss: 1.9520, accuracy: 91.9135%, tar: 0.1027 \n",
            "l0: 0.094879, l1: 0.096228, l2: 0.103226, l3: 0.126886, l4: 0.181402, l5: 0.291392, l6: 0.553382\n",
            "\n",
            "[epoch: 111/100000, batch: 696/1000, ite: 13837] train loss: 1.9520, accuracy: 91.5846%, tar: 0.1027 \n",
            "l0: 0.119694, l1: 0.120498, l2: 0.130911, l3: 0.155554, l4: 0.243185, l5: 0.363101, l6: 0.571073\n",
            "\n",
            "[epoch: 111/100000, batch: 704/1000, ite: 13838] train loss: 1.9522, accuracy: 91.5309%, tar: 0.1027 \n",
            "l0: 0.071132, l1: 0.073093, l2: 0.082606, l3: 0.102103, l4: 0.151327, l5: 0.229038, l6: 0.440789\n",
            "\n",
            "[epoch: 111/100000, batch: 712/1000, ite: 13839] train loss: 1.9520, accuracy: 92.6989%, tar: 0.1027 \n",
            "l0: 0.065685, l1: 0.067834, l2: 0.076346, l3: 0.091361, l4: 0.129812, l5: 0.192510, l6: 0.368575\n",
            "\n",
            "[epoch: 111/100000, batch: 720/1000, ite: 13840] train loss: 1.9517, accuracy: 93.0269%, tar: 0.1027 \n",
            "l0: 0.103709, l1: 0.105261, l2: 0.117274, l3: 0.138107, l4: 0.189657, l5: 0.288588, l6: 0.509791\n",
            "\n",
            "[epoch: 111/100000, batch: 728/1000, ite: 13841] train loss: 1.9517, accuracy: 91.5061%, tar: 0.1027 \n",
            "l0: 0.084300, l1: 0.084952, l2: 0.094163, l3: 0.120559, l4: 0.186880, l5: 0.288600, l6: 0.555976\n",
            "\n",
            "[epoch: 111/100000, batch: 736/1000, ite: 13842] train loss: 1.9517, accuracy: 91.6669%, tar: 0.1027 \n",
            "l0: 0.091061, l1: 0.093723, l2: 0.100228, l3: 0.113377, l4: 0.152179, l5: 0.231097, l6: 0.361411\n",
            "\n",
            "[epoch: 111/100000, batch: 744/1000, ite: 13843] train loss: 1.9514, accuracy: 92.1941%, tar: 0.1027 \n",
            "l0: 0.126005, l1: 0.127269, l2: 0.138554, l3: 0.171061, l4: 0.242438, l5: 0.387577, l6: 0.599944\n",
            "\n",
            "[epoch: 111/100000, batch: 752/1000, ite: 13844] train loss: 1.9517, accuracy: 90.3607%, tar: 0.1027 \n",
            "l0: 0.108417, l1: 0.109285, l2: 0.118993, l3: 0.135952, l4: 0.180824, l5: 0.263066, l6: 0.420359\n",
            "\n",
            "[epoch: 111/100000, batch: 760/1000, ite: 13845] train loss: 1.9516, accuracy: 92.0626%, tar: 0.1027 \n",
            "l0: 0.105362, l1: 0.105128, l2: 0.113563, l3: 0.138317, l4: 0.196635, l5: 0.289323, l6: 0.514940\n",
            "\n",
            "[epoch: 111/100000, batch: 768/1000, ite: 13846] train loss: 1.9516, accuracy: 91.8964%, tar: 0.1027 \n",
            "l0: 0.097126, l1: 0.099776, l2: 0.108044, l3: 0.134408, l4: 0.204267, l5: 0.313765, l6: 0.474015\n",
            "\n",
            "[epoch: 111/100000, batch: 776/1000, ite: 13847] train loss: 1.9516, accuracy: 91.8673%, tar: 0.1027 \n",
            "l0: 0.075101, l1: 0.075726, l2: 0.086952, l3: 0.114534, l4: 0.168219, l5: 0.317306, l6: 0.531915\n",
            "\n",
            "[epoch: 111/100000, batch: 784/1000, ite: 13848] train loss: 1.9516, accuracy: 91.6305%, tar: 0.1027 \n",
            "l0: 0.070238, l1: 0.072178, l2: 0.081412, l3: 0.104430, l4: 0.146345, l5: 0.266898, l6: 0.513709\n",
            "\n",
            "[epoch: 111/100000, batch: 792/1000, ite: 13849] train loss: 1.9514, accuracy: 91.9477%, tar: 0.1027 \n",
            "l0: 0.091537, l1: 0.092711, l2: 0.099760, l3: 0.120317, l4: 0.161571, l5: 0.253266, l6: 0.423181\n",
            "\n",
            "[epoch: 111/100000, batch: 800/1000, ite: 13850] train loss: 1.9513, accuracy: 92.1957%, tar: 0.1027 \n",
            "l0: 0.088223, l1: 0.089314, l2: 0.100021, l3: 0.122610, l4: 0.158985, l5: 0.247058, l6: 0.426547\n",
            "\n",
            "[epoch: 111/100000, batch: 808/1000, ite: 13851] train loss: 1.9511, accuracy: 93.2690%, tar: 0.1027 \n",
            "l0: 0.084323, l1: 0.085173, l2: 0.095158, l3: 0.115940, l4: 0.173752, l5: 0.262683, l6: 0.417519\n",
            "\n",
            "[epoch: 111/100000, batch: 816/1000, ite: 13852] train loss: 1.9510, accuracy: 93.5850%, tar: 0.1026 \n",
            "l0: 0.072903, l1: 0.074063, l2: 0.082956, l3: 0.099197, l4: 0.146763, l5: 0.214023, l6: 0.370700\n",
            "\n",
            "[epoch: 111/100000, batch: 824/1000, ite: 13853] train loss: 1.9507, accuracy: 93.8381%, tar: 0.1026 \n",
            "l0: 0.083445, l1: 0.083329, l2: 0.092563, l3: 0.114252, l4: 0.162107, l5: 0.261510, l6: 0.433729\n",
            "\n",
            "[epoch: 111/100000, batch: 832/1000, ite: 13854] train loss: 1.9505, accuracy: 92.5060%, tar: 0.1026 \n",
            "l0: 0.099320, l1: 0.100150, l2: 0.109702, l3: 0.126477, l4: 0.169350, l5: 0.257401, l6: 0.494072\n",
            "\n",
            "[epoch: 111/100000, batch: 840/1000, ite: 13855] train loss: 1.9505, accuracy: 91.2729%, tar: 0.1026 \n",
            "l0: 0.056191, l1: 0.056644, l2: 0.062483, l3: 0.080606, l4: 0.111726, l5: 0.172545, l6: 0.281788\n",
            "\n",
            "[epoch: 111/100000, batch: 848/1000, ite: 13856] train loss: 1.9500, accuracy: 94.7561%, tar: 0.1026 \n",
            "l0: 0.080139, l1: 0.081292, l2: 0.087891, l3: 0.110032, l4: 0.155347, l5: 0.252057, l6: 0.449542\n",
            "\n",
            "[epoch: 111/100000, batch: 856/1000, ite: 13857] train loss: 1.9499, accuracy: 92.6447%, tar: 0.1026 \n",
            "l0: 0.052433, l1: 0.052639, l2: 0.059675, l3: 0.077699, l4: 0.119567, l5: 0.186361, l6: 0.350038\n",
            "\n",
            "[epoch: 111/100000, batch: 864/1000, ite: 13858] train loss: 1.9495, accuracy: 94.4962%, tar: 0.1025 \n",
            "l0: 0.110517, l1: 0.111352, l2: 0.118855, l3: 0.140274, l4: 0.194913, l5: 0.291616, l6: 0.459553\n",
            "\n",
            "[epoch: 111/100000, batch: 872/1000, ite: 13859] train loss: 1.9495, accuracy: 91.8605%, tar: 0.1026 \n",
            "l0: 0.084164, l1: 0.084203, l2: 0.091700, l3: 0.103282, l4: 0.137808, l5: 0.203145, l6: 0.356561\n",
            "\n",
            "[epoch: 111/100000, batch: 880/1000, ite: 13860] train loss: 1.9492, accuracy: 93.5196%, tar: 0.1025 \n",
            "l0: 0.111739, l1: 0.112450, l2: 0.118031, l3: 0.137148, l4: 0.193301, l5: 0.317238, l6: 0.511030\n",
            "\n",
            "[epoch: 111/100000, batch: 888/1000, ite: 13861] train loss: 1.9492, accuracy: 91.3595%, tar: 0.1025 \n",
            "l0: 0.091169, l1: 0.092842, l2: 0.107234, l3: 0.140139, l4: 0.208700, l5: 0.332527, l6: 0.605885\n",
            "\n",
            "[epoch: 111/100000, batch: 896/1000, ite: 13862] train loss: 1.9494, accuracy: 91.2810%, tar: 0.1025 \n",
            "l0: 0.111531, l1: 0.111661, l2: 0.122859, l3: 0.138892, l4: 0.185855, l5: 0.317173, l6: 0.501047\n",
            "\n",
            "[epoch: 111/100000, batch: 904/1000, ite: 13863] train loss: 1.9494, accuracy: 91.4152%, tar: 0.1025 \n",
            "l0: 0.076431, l1: 0.077525, l2: 0.085912, l3: 0.105880, l4: 0.153596, l5: 0.254711, l6: 0.485700\n",
            "\n",
            "[epoch: 111/100000, batch: 912/1000, ite: 13864] train loss: 1.9493, accuracy: 91.9368%, tar: 0.1025 \n",
            "l0: 0.068311, l1: 0.069737, l2: 0.081085, l3: 0.110861, l4: 0.171545, l5: 0.306243, l6: 0.529568\n",
            "\n",
            "[epoch: 111/100000, batch: 920/1000, ite: 13865] train loss: 1.9492, accuracy: 91.5118%, tar: 0.1025 \n",
            "l0: 0.099318, l1: 0.100062, l2: 0.112323, l3: 0.138604, l4: 0.206623, l5: 0.336721, l6: 0.620345\n",
            "\n",
            "[epoch: 111/100000, batch: 928/1000, ite: 13866] train loss: 1.9494, accuracy: 90.3876%, tar: 0.1025 \n",
            "l0: 0.096417, l1: 0.097270, l2: 0.105587, l3: 0.131646, l4: 0.194522, l5: 0.395831, l6: 0.701920\n",
            "\n",
            "[epoch: 111/100000, batch: 936/1000, ite: 13867] train loss: 1.9496, accuracy: 90.1404%, tar: 0.1025 \n",
            "l0: 0.090719, l1: 0.091418, l2: 0.101605, l3: 0.127277, l4: 0.177290, l5: 0.245576, l6: 0.446821\n",
            "\n",
            "[epoch: 111/100000, batch: 944/1000, ite: 13868] train loss: 1.9495, accuracy: 91.6546%, tar: 0.1025 \n",
            "l0: 0.087163, l1: 0.089252, l2: 0.098255, l3: 0.124882, l4: 0.187143, l5: 0.278861, l6: 0.437342\n",
            "\n",
            "[epoch: 111/100000, batch: 952/1000, ite: 13869] train loss: 1.9494, accuracy: 92.3609%, tar: 0.1025 \n",
            "l0: 0.103881, l1: 0.104815, l2: 0.112303, l3: 0.134571, l4: 0.187476, l5: 0.273219, l6: 0.452904\n",
            "\n",
            "[epoch: 111/100000, batch: 960/1000, ite: 13870] train loss: 1.9493, accuracy: 90.7510%, tar: 0.1025 \n",
            "l0: 0.070450, l1: 0.071777, l2: 0.080334, l3: 0.098086, l4: 0.125560, l5: 0.180422, l6: 0.307946\n",
            "\n",
            "[epoch: 111/100000, batch: 968/1000, ite: 13871] train loss: 1.9490, accuracy: 94.5240%, tar: 0.1025 \n",
            "l0: 0.047038, l1: 0.048238, l2: 0.056024, l3: 0.081757, l4: 0.125194, l5: 0.214525, l6: 0.347339\n",
            "\n",
            "[epoch: 111/100000, batch: 976/1000, ite: 13872] train loss: 1.9486, accuracy: 94.8472%, tar: 0.1025 \n",
            "l0: 0.080009, l1: 0.080852, l2: 0.089433, l3: 0.107922, l4: 0.157369, l5: 0.243115, l6: 0.529725\n",
            "\n",
            "[epoch: 111/100000, batch: 984/1000, ite: 13873] train loss: 1.9485, accuracy: 93.3773%, tar: 0.1024 \n",
            "l0: 0.095966, l1: 0.096903, l2: 0.104545, l3: 0.130599, l4: 0.194177, l5: 0.302245, l6: 0.555995\n",
            "\n",
            "[epoch: 111/100000, batch: 992/1000, ite: 13874] train loss: 1.9486, accuracy: 90.3367%, tar: 0.1024 \n",
            "l0: 0.122701, l1: 0.122994, l2: 0.132374, l3: 0.155349, l4: 0.202522, l5: 0.313409, l6: 0.521038\n",
            "\n",
            "[epoch: 111/100000, batch: 1000/1000, ite: 13875] train loss: 1.9487, accuracy: 91.3426%, tar: 0.1024 \n",
            "l0: 0.104297, l1: 0.105580, l2: 0.115554, l3: 0.152158, l4: 0.199806, l5: 0.272521, l6: 0.439915\n",
            "\n",
            "[epoch: 112/100000, batch: 8/1000, ite: 13876] train loss: 1.9486, accuracy: 91.9597%, tar: 0.1024 \n",
            "l0: 0.074395, l1: 0.075797, l2: 0.083223, l3: 0.104652, l4: 0.149104, l5: 0.248157, l6: 0.414296\n",
            "\n",
            "[epoch: 112/100000, batch: 16/1000, ite: 13877] train loss: 1.9484, accuracy: 93.8611%, tar: 0.1024 \n",
            "l0: 0.109332, l1: 0.111795, l2: 0.122339, l3: 0.154999, l4: 0.213359, l5: 0.323807, l6: 0.551301\n",
            "\n",
            "[epoch: 112/100000, batch: 24/1000, ite: 13878] train loss: 1.9485, accuracy: 92.3945%, tar: 0.1024 \n",
            "l0: 0.074435, l1: 0.076040, l2: 0.083588, l3: 0.106677, l4: 0.149945, l5: 0.227331, l6: 0.384626\n",
            "\n",
            "[epoch: 112/100000, batch: 32/1000, ite: 13879] train loss: 1.9483, accuracy: 92.9314%, tar: 0.1024 \n",
            "l0: 0.083350, l1: 0.085161, l2: 0.096436, l3: 0.120230, l4: 0.183358, l5: 0.295801, l6: 0.522553\n",
            "\n",
            "[epoch: 112/100000, batch: 40/1000, ite: 13880] train loss: 1.9482, accuracy: 90.7935%, tar: 0.1024 \n",
            "l0: 0.097606, l1: 0.099133, l2: 0.109009, l3: 0.124786, l4: 0.163932, l5: 0.227289, l6: 0.371221\n",
            "\n",
            "[epoch: 112/100000, batch: 48/1000, ite: 13881] train loss: 1.9480, accuracy: 92.0773%, tar: 0.1024 \n",
            "l0: 0.089169, l1: 0.089851, l2: 0.098133, l3: 0.120447, l4: 0.153771, l5: 0.239309, l6: 0.391641\n",
            "\n",
            "[epoch: 112/100000, batch: 56/1000, ite: 13882] train loss: 1.9478, accuracy: 92.8091%, tar: 0.1024 \n",
            "l0: 0.092276, l1: 0.092901, l2: 0.099643, l3: 0.121900, l4: 0.187797, l5: 0.280342, l6: 0.431125\n",
            "\n",
            "[epoch: 112/100000, batch: 64/1000, ite: 13883] train loss: 1.9477, accuracy: 92.4349%, tar: 0.1024 \n",
            "l0: 0.084732, l1: 0.084677, l2: 0.095398, l3: 0.110967, l4: 0.153467, l5: 0.256484, l6: 0.451665\n",
            "\n",
            "[epoch: 112/100000, batch: 72/1000, ite: 13884] train loss: 1.9476, accuracy: 92.8458%, tar: 0.1024 \n",
            "l0: 0.109935, l1: 0.110181, l2: 0.120427, l3: 0.147490, l4: 0.212033, l5: 0.327212, l6: 0.526250\n",
            "\n",
            "[epoch: 112/100000, batch: 80/1000, ite: 13885] train loss: 1.9477, accuracy: 91.0979%, tar: 0.1024 \n",
            "l0: 0.064361, l1: 0.065389, l2: 0.073845, l3: 0.096721, l4: 0.140098, l5: 0.201736, l6: 0.395686\n",
            "\n",
            "[epoch: 112/100000, batch: 88/1000, ite: 13886] train loss: 1.9474, accuracy: 93.1034%, tar: 0.1024 \n",
            "l0: 0.064997, l1: 0.065079, l2: 0.073754, l3: 0.091604, l4: 0.138936, l5: 0.225993, l6: 0.415799\n",
            "\n",
            "[epoch: 112/100000, batch: 96/1000, ite: 13887] train loss: 1.9472, accuracy: 93.8813%, tar: 0.1023 \n",
            "l0: 0.072447, l1: 0.074064, l2: 0.081797, l3: 0.105146, l4: 0.165932, l5: 0.266831, l6: 0.430765\n",
            "\n",
            "[epoch: 112/100000, batch: 104/1000, ite: 13888] train loss: 1.9470, accuracy: 93.0971%, tar: 0.1023 \n",
            "l0: 0.090338, l1: 0.091785, l2: 0.098380, l3: 0.120219, l4: 0.157402, l5: 0.242114, l6: 0.387585\n",
            "\n",
            "[epoch: 112/100000, batch: 112/1000, ite: 13889] train loss: 1.9468, accuracy: 93.5231%, tar: 0.1023 \n",
            "l0: 0.105679, l1: 0.105733, l2: 0.115259, l3: 0.142672, l4: 0.220706, l5: 0.361302, l6: 0.610514\n",
            "\n",
            "[epoch: 112/100000, batch: 120/1000, ite: 13890] train loss: 1.9470, accuracy: 90.3040%, tar: 0.1023 \n",
            "l0: 0.076433, l1: 0.078302, l2: 0.087499, l3: 0.112348, l4: 0.163431, l5: 0.259058, l6: 0.440171\n",
            "\n",
            "[epoch: 112/100000, batch: 128/1000, ite: 13891] train loss: 1.9468, accuracy: 92.2041%, tar: 0.1023 \n",
            "l0: 0.077139, l1: 0.078672, l2: 0.087809, l3: 0.111004, l4: 0.163557, l5: 0.260579, l6: 0.504958\n",
            "\n",
            "[epoch: 112/100000, batch: 136/1000, ite: 13892] train loss: 1.9467, accuracy: 92.0771%, tar: 0.1023 \n",
            "l0: 0.079547, l1: 0.081171, l2: 0.093203, l3: 0.121587, l4: 0.190170, l5: 0.317295, l6: 0.491236\n",
            "\n",
            "[epoch: 112/100000, batch: 144/1000, ite: 13893] train loss: 1.9467, accuracy: 91.9095%, tar: 0.1023 \n",
            "l0: 0.112538, l1: 0.114955, l2: 0.126079, l3: 0.157333, l4: 0.229922, l5: 0.394287, l6: 0.655128\n",
            "\n",
            "[epoch: 112/100000, batch: 152/1000, ite: 13894] train loss: 1.9469, accuracy: 89.7099%, tar: 0.1023 \n",
            "l0: 0.062208, l1: 0.062946, l2: 0.072842, l3: 0.100790, l4: 0.152715, l5: 0.255232, l6: 0.444413\n",
            "\n",
            "[epoch: 112/100000, batch: 160/1000, ite: 13895] train loss: 1.9468, accuracy: 93.0897%, tar: 0.1023 \n",
            "l0: 0.096199, l1: 0.096773, l2: 0.103397, l3: 0.123687, l4: 0.173174, l5: 0.284283, l6: 0.495754\n",
            "\n",
            "[epoch: 112/100000, batch: 168/1000, ite: 13896] train loss: 1.9467, accuracy: 90.7250%, tar: 0.1023 \n",
            "l0: 0.068547, l1: 0.069580, l2: 0.078867, l3: 0.096489, l4: 0.129906, l5: 0.195227, l6: 0.315069\n",
            "\n",
            "[epoch: 112/100000, batch: 176/1000, ite: 13897] train loss: 1.9464, accuracy: 94.2059%, tar: 0.1023 \n",
            "l0: 0.081637, l1: 0.082610, l2: 0.092205, l3: 0.117821, l4: 0.188245, l5: 0.292913, l6: 0.464615\n",
            "\n",
            "[epoch: 112/100000, batch: 184/1000, ite: 13898] train loss: 1.9463, accuracy: 92.0277%, tar: 0.1022 \n",
            "l0: 0.079667, l1: 0.080154, l2: 0.089917, l3: 0.111672, l4: 0.158396, l5: 0.243276, l6: 0.400352\n",
            "\n",
            "[epoch: 112/100000, batch: 192/1000, ite: 13899] train loss: 1.9461, accuracy: 92.8408%, tar: 0.1022 \n",
            "l0: 0.080627, l1: 0.082429, l2: 0.092711, l3: 0.115038, l4: 0.179971, l5: 0.268272, l6: 0.445968\n",
            "\n",
            "[epoch: 112/100000, batch: 200/1000, ite: 13900] train loss: 1.9460, accuracy: 92.6359%, tar: 0.1022 \n",
            "l0: 0.070221, l1: 0.071029, l2: 0.077858, l3: 0.100594, l4: 0.143366, l5: 0.228876, l6: 0.410130\n",
            "\n",
            "[epoch: 112/100000, batch: 208/1000, ite: 13901] train loss: 1.9457, accuracy: 92.5292%, tar: 0.1022 \n",
            "l0: 0.083910, l1: 0.082538, l2: 0.091652, l3: 0.122715, l4: 0.196740, l5: 0.330492, l6: 0.560334\n",
            "\n",
            "[epoch: 112/100000, batch: 216/1000, ite: 13902] train loss: 1.9458, accuracy: 93.5175%, tar: 0.1022 \n",
            "l0: 0.078743, l1: 0.079392, l2: 0.087707, l3: 0.110920, l4: 0.166969, l5: 0.257257, l6: 0.482169\n",
            "\n",
            "[epoch: 112/100000, batch: 224/1000, ite: 13903] train loss: 1.9457, accuracy: 92.9575%, tar: 0.1022 \n",
            "l0: 0.077985, l1: 0.078736, l2: 0.086343, l3: 0.107746, l4: 0.152334, l5: 0.226433, l6: 0.404806\n",
            "\n",
            "[epoch: 112/100000, batch: 232/1000, ite: 13904] train loss: 1.9455, accuracy: 94.0730%, tar: 0.1022 \n",
            "l0: 0.081320, l1: 0.082578, l2: 0.091901, l3: 0.119124, l4: 0.175416, l5: 0.262669, l6: 0.508381\n",
            "\n",
            "[epoch: 112/100000, batch: 240/1000, ite: 13905] train loss: 1.9454, accuracy: 93.5044%, tar: 0.1022 \n",
            "l0: 0.057473, l1: 0.058350, l2: 0.065730, l3: 0.080743, l4: 0.110723, l5: 0.185515, l6: 0.372427\n",
            "\n",
            "[epoch: 112/100000, batch: 248/1000, ite: 13906] train loss: 1.9451, accuracy: 93.7130%, tar: 0.1021 \n",
            "l0: 0.100333, l1: 0.102863, l2: 0.115699, l3: 0.150610, l4: 0.203147, l5: 0.326617, l6: 0.508834\n",
            "\n",
            "[epoch: 112/100000, batch: 256/1000, ite: 13907] train loss: 1.9451, accuracy: 90.9687%, tar: 0.1021 \n",
            "l0: 0.102992, l1: 0.104583, l2: 0.116812, l3: 0.151533, l4: 0.233173, l5: 0.386826, l6: 0.551645\n",
            "\n",
            "[epoch: 112/100000, batch: 264/1000, ite: 13908] train loss: 1.9452, accuracy: 90.8893%, tar: 0.1021 \n",
            "l0: 0.090286, l1: 0.091625, l2: 0.102180, l3: 0.122841, l4: 0.188896, l5: 0.292348, l6: 0.477999\n",
            "\n",
            "[epoch: 112/100000, batch: 272/1000, ite: 13909] train loss: 1.9452, accuracy: 92.7552%, tar: 0.1021 \n",
            "l0: 0.053859, l1: 0.054439, l2: 0.060192, l3: 0.075679, l4: 0.119530, l5: 0.228037, l6: 0.399667\n",
            "\n",
            "[epoch: 112/100000, batch: 280/1000, ite: 13910] train loss: 1.9449, accuracy: 93.5240%, tar: 0.1021 \n",
            "l0: 0.112145, l1: 0.113305, l2: 0.125157, l3: 0.150343, l4: 0.205666, l5: 0.339737, l6: 0.649555\n",
            "\n",
            "[epoch: 112/100000, batch: 288/1000, ite: 13911] train loss: 1.9451, accuracy: 89.8395%, tar: 0.1021 \n",
            "l0: 0.104833, l1: 0.106949, l2: 0.115571, l3: 0.138701, l4: 0.180998, l5: 0.267038, l6: 0.415685\n",
            "\n",
            "[epoch: 112/100000, batch: 296/1000, ite: 13912] train loss: 1.9450, accuracy: 91.9722%, tar: 0.1021 \n",
            "l0: 0.080979, l1: 0.081639, l2: 0.090461, l3: 0.116713, l4: 0.176221, l5: 0.278696, l6: 0.513004\n",
            "\n",
            "[epoch: 112/100000, batch: 304/1000, ite: 13913] train loss: 1.9450, accuracy: 91.5720%, tar: 0.1021 \n",
            "l0: 0.092929, l1: 0.093807, l2: 0.104555, l3: 0.128026, l4: 0.184797, l5: 0.294406, l6: 0.474075\n",
            "\n",
            "[epoch: 112/100000, batch: 312/1000, ite: 13914] train loss: 1.9449, accuracy: 91.6786%, tar: 0.1021 \n",
            "l0: 0.124760, l1: 0.126441, l2: 0.139624, l3: 0.158447, l4: 0.225260, l5: 0.361054, l6: 0.575887\n",
            "\n",
            "[epoch: 112/100000, batch: 320/1000, ite: 13915] train loss: 1.9451, accuracy: 90.3064%, tar: 0.1021 \n",
            "l0: 0.087152, l1: 0.089456, l2: 0.100684, l3: 0.121805, l4: 0.166266, l5: 0.236095, l6: 0.422913\n",
            "\n",
            "[epoch: 112/100000, batch: 328/1000, ite: 13916] train loss: 1.9449, accuracy: 92.9576%, tar: 0.1021 \n",
            "l0: 0.092787, l1: 0.094863, l2: 0.102843, l3: 0.120182, l4: 0.163123, l5: 0.245366, l6: 0.432088\n",
            "\n",
            "[epoch: 112/100000, batch: 336/1000, ite: 13917] train loss: 1.9448, accuracy: 92.9599%, tar: 0.1021 \n",
            "l0: 0.095345, l1: 0.096408, l2: 0.104697, l3: 0.126666, l4: 0.160487, l5: 0.245113, l6: 0.413094\n",
            "\n",
            "[epoch: 112/100000, batch: 344/1000, ite: 13918] train loss: 1.9446, accuracy: 91.4878%, tar: 0.1021 \n",
            "l0: 0.121126, l1: 0.122255, l2: 0.125501, l3: 0.136960, l4: 0.177837, l5: 0.257510, l6: 0.463897\n",
            "\n",
            "[epoch: 112/100000, batch: 352/1000, ite: 13919] train loss: 1.9446, accuracy: 90.8391%, tar: 0.1021 \n",
            "l0: 0.089372, l1: 0.090624, l2: 0.100589, l3: 0.124448, l4: 0.195082, l5: 0.316778, l6: 0.553138\n",
            "\n",
            "[epoch: 112/100000, batch: 360/1000, ite: 13920] train loss: 1.9446, accuracy: 92.3717%, tar: 0.1021 \n",
            "l0: 0.110707, l1: 0.111346, l2: 0.120705, l3: 0.148001, l4: 0.220143, l5: 0.348473, l6: 0.571537\n",
            "\n",
            "[epoch: 112/100000, batch: 368/1000, ite: 13921] train loss: 1.9448, accuracy: 91.1291%, tar: 0.1021 \n",
            "l0: 0.103353, l1: 0.104753, l2: 0.116103, l3: 0.146275, l4: 0.223341, l5: 0.374563, l6: 0.567611\n",
            "\n",
            "[epoch: 112/100000, batch: 376/1000, ite: 13922] train loss: 1.9449, accuracy: 90.0609%, tar: 0.1021 \n",
            "l0: 0.093052, l1: 0.094962, l2: 0.102945, l3: 0.122684, l4: 0.168150, l5: 0.284601, l6: 0.482982\n",
            "\n",
            "[epoch: 112/100000, batch: 384/1000, ite: 13923] train loss: 1.9449, accuracy: 92.6534%, tar: 0.1021 \n",
            "l0: 0.126930, l1: 0.127758, l2: 0.133293, l3: 0.161560, l4: 0.214740, l5: 0.325799, l6: 0.552082\n",
            "\n",
            "[epoch: 112/100000, batch: 392/1000, ite: 13924] train loss: 1.9450, accuracy: 91.0702%, tar: 0.1021 \n",
            "l0: 0.065993, l1: 0.067552, l2: 0.078510, l3: 0.107053, l4: 0.163342, l5: 0.263198, l6: 0.486028\n",
            "\n",
            "[epoch: 112/100000, batch: 400/1000, ite: 13925] train loss: 1.9449, accuracy: 92.0993%, tar: 0.1021 \n",
            "l0: 0.077041, l1: 0.077839, l2: 0.089197, l3: 0.118013, l4: 0.173353, l5: 0.267575, l6: 0.453485\n",
            "\n",
            "[epoch: 112/100000, batch: 408/1000, ite: 13926] train loss: 1.9448, accuracy: 91.8648%, tar: 0.1021 \n",
            "l0: 0.091501, l1: 0.095168, l2: 0.105717, l3: 0.127374, l4: 0.176159, l5: 0.258137, l6: 0.414493\n",
            "\n",
            "[epoch: 112/100000, batch: 416/1000, ite: 13927] train loss: 1.9446, accuracy: 92.9436%, tar: 0.1021 \n",
            "l0: 0.084788, l1: 0.085563, l2: 0.092918, l3: 0.115815, l4: 0.162811, l5: 0.249683, l6: 0.416094\n",
            "\n",
            "[epoch: 112/100000, batch: 424/1000, ite: 13928] train loss: 1.9445, accuracy: 92.5745%, tar: 0.1021 \n",
            "l0: 0.068831, l1: 0.070293, l2: 0.079749, l3: 0.098857, l4: 0.152214, l5: 0.256200, l6: 0.411598\n",
            "\n",
            "[epoch: 112/100000, batch: 432/1000, ite: 13929] train loss: 1.9443, accuracy: 93.4791%, tar: 0.1020 \n",
            "l0: 0.086095, l1: 0.086861, l2: 0.095163, l3: 0.125125, l4: 0.179023, l5: 0.259813, l6: 0.441081\n",
            "\n",
            "[epoch: 112/100000, batch: 440/1000, ite: 13930] train loss: 1.9442, accuracy: 92.7065%, tar: 0.1020 \n",
            "l0: 0.094009, l1: 0.093929, l2: 0.103151, l3: 0.125329, l4: 0.167233, l5: 0.258771, l6: 0.456946\n",
            "\n",
            "[epoch: 112/100000, batch: 448/1000, ite: 13931] train loss: 1.9441, accuracy: 91.9449%, tar: 0.1020 \n",
            "l0: 0.079836, l1: 0.080689, l2: 0.092860, l3: 0.115237, l4: 0.163768, l5: 0.269451, l6: 0.464254\n",
            "\n",
            "[epoch: 112/100000, batch: 456/1000, ite: 13932] train loss: 1.9440, accuracy: 92.5319%, tar: 0.1020 \n",
            "l0: 0.089391, l1: 0.090366, l2: 0.102164, l3: 0.118866, l4: 0.166405, l5: 0.268001, l6: 0.538622\n",
            "\n",
            "[epoch: 112/100000, batch: 464/1000, ite: 13933] train loss: 1.9439, accuracy: 90.4800%, tar: 0.1020 \n",
            "l0: 0.073128, l1: 0.074674, l2: 0.083325, l3: 0.109454, l4: 0.150308, l5: 0.241988, l6: 0.498255\n",
            "\n",
            "[epoch: 112/100000, batch: 472/1000, ite: 13934] train loss: 1.9438, accuracy: 92.3560%, tar: 0.1020 \n",
            "l0: 0.091824, l1: 0.091163, l2: 0.099197, l3: 0.121172, l4: 0.162491, l5: 0.232999, l6: 0.421476\n",
            "\n",
            "[epoch: 112/100000, batch: 480/1000, ite: 13935] train loss: 1.9437, accuracy: 93.4865%, tar: 0.1020 \n",
            "l0: 0.084170, l1: 0.085410, l2: 0.093457, l3: 0.113520, l4: 0.164205, l5: 0.274323, l6: 0.547246\n",
            "\n",
            "[epoch: 112/100000, batch: 488/1000, ite: 13936] train loss: 1.9437, accuracy: 91.1656%, tar: 0.1020 \n",
            "l0: 0.068040, l1: 0.068816, l2: 0.074411, l3: 0.092732, l4: 0.140992, l5: 0.210965, l6: 0.420084\n",
            "\n",
            "[epoch: 112/100000, batch: 496/1000, ite: 13937] train loss: 1.9434, accuracy: 93.2468%, tar: 0.1020 \n",
            "l0: 0.084785, l1: 0.085454, l2: 0.094163, l3: 0.118633, l4: 0.163197, l5: 0.253112, l6: 0.428111\n",
            "\n",
            "[epoch: 112/100000, batch: 504/1000, ite: 13938] train loss: 1.9433, accuracy: 92.4271%, tar: 0.1020 \n",
            "l0: 0.102549, l1: 0.102706, l2: 0.110755, l3: 0.131958, l4: 0.180625, l5: 0.266137, l6: 0.454372\n",
            "\n",
            "[epoch: 112/100000, batch: 512/1000, ite: 13939] train loss: 1.9432, accuracy: 92.1445%, tar: 0.1020 \n",
            "l0: 0.083543, l1: 0.085131, l2: 0.094834, l3: 0.115388, l4: 0.167179, l5: 0.281180, l6: 0.463184\n",
            "\n",
            "[epoch: 112/100000, batch: 520/1000, ite: 13940] train loss: 1.9431, accuracy: 92.4821%, tar: 0.1019 \n",
            "l0: 0.070635, l1: 0.071701, l2: 0.079394, l3: 0.098786, l4: 0.142659, l5: 0.229184, l6: 0.405699\n",
            "\n",
            "[epoch: 112/100000, batch: 528/1000, ite: 13941] train loss: 1.9429, accuracy: 93.2512%, tar: 0.1019 \n",
            "l0: 0.080145, l1: 0.080052, l2: 0.086519, l3: 0.103583, l4: 0.137392, l5: 0.242325, l6: 0.378128\n",
            "\n",
            "[epoch: 112/100000, batch: 536/1000, ite: 13942] train loss: 1.9427, accuracy: 92.6953%, tar: 0.1019 \n",
            "l0: 0.091195, l1: 0.092075, l2: 0.103884, l3: 0.131702, l4: 0.186302, l5: 0.287229, l6: 0.438975\n",
            "\n",
            "[epoch: 112/100000, batch: 544/1000, ite: 13943] train loss: 1.9426, accuracy: 92.4917%, tar: 0.1019 \n",
            "l0: 0.085240, l1: 0.086474, l2: 0.094877, l3: 0.114649, l4: 0.170093, l5: 0.263065, l6: 0.496067\n",
            "\n",
            "[epoch: 112/100000, batch: 552/1000, ite: 13944] train loss: 1.9425, accuracy: 92.2623%, tar: 0.1019 \n",
            "l0: 0.102414, l1: 0.104152, l2: 0.110619, l3: 0.127741, l4: 0.163756, l5: 0.265800, l6: 0.417567\n",
            "\n",
            "[epoch: 112/100000, batch: 560/1000, ite: 13945] train loss: 1.9424, accuracy: 91.9987%, tar: 0.1019 \n",
            "l0: 0.100057, l1: 0.099330, l2: 0.111303, l3: 0.138058, l4: 0.197550, l5: 0.302019, l6: 0.536729\n",
            "\n",
            "[epoch: 112/100000, batch: 568/1000, ite: 13946] train loss: 1.9424, accuracy: 91.5112%, tar: 0.1019 \n",
            "l0: 0.126998, l1: 0.127774, l2: 0.133531, l3: 0.152528, l4: 0.205474, l5: 0.324763, l6: 0.569469\n",
            "\n",
            "[epoch: 112/100000, batch: 576/1000, ite: 13947] train loss: 1.9426, accuracy: 91.0945%, tar: 0.1019 \n",
            "l0: 0.090838, l1: 0.090943, l2: 0.097987, l3: 0.114320, l4: 0.164790, l5: 0.254002, l6: 0.413408\n",
            "\n",
            "[epoch: 112/100000, batch: 584/1000, ite: 13948] train loss: 1.9424, accuracy: 92.0462%, tar: 0.1019 \n",
            "l0: 0.111207, l1: 0.113720, l2: 0.119725, l3: 0.136360, l4: 0.168748, l5: 0.232083, l6: 0.415563\n",
            "\n",
            "[epoch: 112/100000, batch: 592/1000, ite: 13949] train loss: 1.9423, accuracy: 91.9048%, tar: 0.1019 \n",
            "l0: 0.089794, l1: 0.090605, l2: 0.099342, l3: 0.127613, l4: 0.168771, l5: 0.275118, l6: 0.494470\n",
            "\n",
            "[epoch: 112/100000, batch: 600/1000, ite: 13950] train loss: 1.9423, accuracy: 91.8604%, tar: 0.1019 \n",
            "l0: 0.059217, l1: 0.060492, l2: 0.066223, l3: 0.076259, l4: 0.102152, l5: 0.155868, l6: 0.292614\n",
            "\n",
            "[epoch: 112/100000, batch: 608/1000, ite: 13951] train loss: 1.9418, accuracy: 94.1897%, tar: 0.1019 \n",
            "l0: 0.097757, l1: 0.098475, l2: 0.108152, l3: 0.131542, l4: 0.204130, l5: 0.372685, l6: 0.616418\n",
            "\n",
            "[epoch: 112/100000, batch: 616/1000, ite: 13952] train loss: 1.9420, accuracy: 92.0499%, tar: 0.1019 \n",
            "l0: 0.090452, l1: 0.091288, l2: 0.099711, l3: 0.122680, l4: 0.184343, l5: 0.270343, l6: 0.477477\n",
            "\n",
            "[epoch: 112/100000, batch: 624/1000, ite: 13953] train loss: 1.9419, accuracy: 92.7088%, tar: 0.1019 \n",
            "l0: 0.073186, l1: 0.073528, l2: 0.083656, l3: 0.102848, l4: 0.138689, l5: 0.231211, l6: 0.438486\n",
            "\n",
            "[epoch: 112/100000, batch: 632/1000, ite: 13954] train loss: 1.9417, accuracy: 93.3112%, tar: 0.1019 \n",
            "l0: 0.072494, l1: 0.072180, l2: 0.082271, l3: 0.115389, l4: 0.202570, l5: 0.341892, l6: 0.527704\n",
            "\n",
            "[epoch: 112/100000, batch: 640/1000, ite: 13955] train loss: 1.9417, accuracy: 91.8075%, tar: 0.1018 \n",
            "l0: 0.105105, l1: 0.105905, l2: 0.114303, l3: 0.140218, l4: 0.198575, l5: 0.330270, l6: 0.627094\n",
            "\n",
            "[epoch: 112/100000, batch: 648/1000, ite: 13956] train loss: 1.9419, accuracy: 90.3717%, tar: 0.1019 \n",
            "l0: 0.079839, l1: 0.081653, l2: 0.089625, l3: 0.114858, l4: 0.156101, l5: 0.242829, l6: 0.390222\n",
            "\n",
            "[epoch: 112/100000, batch: 656/1000, ite: 13957] train loss: 1.9417, accuracy: 93.3474%, tar: 0.1018 \n",
            "l0: 0.092208, l1: 0.093675, l2: 0.102616, l3: 0.126646, l4: 0.193459, l5: 0.311389, l6: 0.545194\n",
            "\n",
            "[epoch: 112/100000, batch: 664/1000, ite: 13958] train loss: 1.9417, accuracy: 90.9668%, tar: 0.1018 \n",
            "l0: 0.103797, l1: 0.104827, l2: 0.118468, l3: 0.143264, l4: 0.199652, l5: 0.363714, l6: 0.618472\n",
            "\n",
            "[epoch: 112/100000, batch: 672/1000, ite: 13959] train loss: 1.9419, accuracy: 89.6991%, tar: 0.1018 \n",
            "l0: 0.063435, l1: 0.064570, l2: 0.074340, l3: 0.101295, l4: 0.169193, l5: 0.249786, l6: 0.517624\n",
            "\n",
            "[epoch: 112/100000, batch: 680/1000, ite: 13960] train loss: 1.9418, accuracy: 93.6994%, tar: 0.1018 \n",
            "l0: 0.085820, l1: 0.087913, l2: 0.095312, l3: 0.115573, l4: 0.157730, l5: 0.242320, l6: 0.387208\n",
            "\n",
            "[epoch: 112/100000, batch: 688/1000, ite: 13961] train loss: 1.9416, accuracy: 94.0548%, tar: 0.1018 \n",
            "l0: 0.076049, l1: 0.077497, l2: 0.085223, l3: 0.107363, l4: 0.158662, l5: 0.279513, l6: 0.510102\n",
            "\n",
            "[epoch: 112/100000, batch: 696/1000, ite: 13962] train loss: 1.9416, accuracy: 91.7156%, tar: 0.1018 \n",
            "l0: 0.085485, l1: 0.086677, l2: 0.099342, l3: 0.127144, l4: 0.181841, l5: 0.275088, l6: 0.431387\n",
            "\n",
            "[epoch: 112/100000, batch: 704/1000, ite: 13963] train loss: 1.9415, accuracy: 92.9418%, tar: 0.1018 \n",
            "l0: 0.139781, l1: 0.141719, l2: 0.154902, l3: 0.188214, l4: 0.259506, l5: 0.363269, l6: 0.542557\n",
            "\n",
            "[epoch: 112/100000, batch: 712/1000, ite: 13964] train loss: 1.9417, accuracy: 90.4283%, tar: 0.1018 \n",
            "l0: 0.066842, l1: 0.067350, l2: 0.074563, l3: 0.095076, l4: 0.139095, l5: 0.256754, l6: 0.444028\n",
            "\n",
            "[epoch: 112/100000, batch: 720/1000, ite: 13965] train loss: 1.9415, accuracy: 92.5201%, tar: 0.1018 \n",
            "l0: 0.092248, l1: 0.093553, l2: 0.100602, l3: 0.126364, l4: 0.168583, l5: 0.252348, l6: 0.472448\n",
            "\n",
            "[epoch: 112/100000, batch: 728/1000, ite: 13966] train loss: 1.9414, accuracy: 92.4890%, tar: 0.1018 \n",
            "l0: 0.096304, l1: 0.097130, l2: 0.105690, l3: 0.139303, l4: 0.207201, l5: 0.315400, l6: 0.501744\n",
            "\n",
            "[epoch: 112/100000, batch: 736/1000, ite: 13967] train loss: 1.9414, accuracy: 91.9878%, tar: 0.1018 \n",
            "l0: 0.077407, l1: 0.078348, l2: 0.087479, l3: 0.115718, l4: 0.174992, l5: 0.278409, l6: 0.476213\n",
            "\n",
            "[epoch: 112/100000, batch: 744/1000, ite: 13968] train loss: 1.9413, accuracy: 91.9610%, tar: 0.1018 \n",
            "l0: 0.068860, l1: 0.070581, l2: 0.078192, l3: 0.102788, l4: 0.151243, l5: 0.251467, l6: 0.384862\n",
            "\n",
            "[epoch: 112/100000, batch: 752/1000, ite: 13969] train loss: 1.9411, accuracy: 93.6375%, tar: 0.1018 \n",
            "l0: 0.094217, l1: 0.096260, l2: 0.107817, l3: 0.137234, l4: 0.205960, l5: 0.356943, l6: 0.625745\n",
            "\n",
            "[epoch: 112/100000, batch: 760/1000, ite: 13970] train loss: 1.9412, accuracy: 89.4328%, tar: 0.1017 \n",
            "l0: 0.068045, l1: 0.068974, l2: 0.076580, l3: 0.098773, l4: 0.147501, l5: 0.222633, l6: 0.429640\n",
            "\n",
            "[epoch: 112/100000, batch: 768/1000, ite: 13971] train loss: 1.9410, accuracy: 93.5120%, tar: 0.1017 \n",
            "l0: 0.084298, l1: 0.086032, l2: 0.092242, l3: 0.107906, l4: 0.140348, l5: 0.229014, l6: 0.391988\n",
            "\n",
            "[epoch: 112/100000, batch: 776/1000, ite: 13972] train loss: 1.9408, accuracy: 94.0856%, tar: 0.1017 \n",
            "l0: 0.082122, l1: 0.083321, l2: 0.092316, l3: 0.109101, l4: 0.161434, l5: 0.251829, l6: 0.438138\n",
            "\n",
            "[epoch: 112/100000, batch: 784/1000, ite: 13973] train loss: 1.9407, accuracy: 92.2512%, tar: 0.1017 \n",
            "l0: 0.097870, l1: 0.099867, l2: 0.110225, l3: 0.144529, l4: 0.213682, l5: 0.377278, l6: 0.554615\n",
            "\n",
            "[epoch: 112/100000, batch: 792/1000, ite: 13974] train loss: 1.9408, accuracy: 93.1834%, tar: 0.1017 \n",
            "l0: 0.070096, l1: 0.071068, l2: 0.075018, l3: 0.092007, l4: 0.139251, l5: 0.206028, l6: 0.368498\n",
            "\n",
            "[epoch: 112/100000, batch: 800/1000, ite: 13975] train loss: 1.9405, accuracy: 93.2195%, tar: 0.1017 \n",
            "l0: 0.098232, l1: 0.098165, l2: 0.105872, l3: 0.126557, l4: 0.180259, l5: 0.301845, l6: 0.597157\n",
            "\n",
            "[epoch: 112/100000, batch: 808/1000, ite: 13976] train loss: 1.9406, accuracy: 90.8618%, tar: 0.1017 \n",
            "l0: 0.087235, l1: 0.089140, l2: 0.099712, l3: 0.124201, l4: 0.173246, l5: 0.266938, l6: 0.437578\n",
            "\n",
            "[epoch: 112/100000, batch: 816/1000, ite: 13977] train loss: 1.9405, accuracy: 92.3068%, tar: 0.1017 \n",
            "l0: 0.096835, l1: 0.098318, l2: 0.106288, l3: 0.128173, l4: 0.177101, l5: 0.281273, l6: 0.456631\n",
            "\n",
            "[epoch: 112/100000, batch: 824/1000, ite: 13978] train loss: 1.9404, accuracy: 91.8352%, tar: 0.1017 \n",
            "l0: 0.075504, l1: 0.076857, l2: 0.085092, l3: 0.105501, l4: 0.152168, l5: 0.247527, l6: 0.380571\n",
            "\n",
            "[epoch: 112/100000, batch: 832/1000, ite: 13979] train loss: 1.9402, accuracy: 93.6036%, tar: 0.1017 \n",
            "l0: 0.080673, l1: 0.080914, l2: 0.090247, l3: 0.111336, l4: 0.172815, l5: 0.297155, l6: 0.569709\n",
            "\n",
            "[epoch: 112/100000, batch: 840/1000, ite: 13980] train loss: 1.9402, accuracy: 90.8815%, tar: 0.1017 \n",
            "l0: 0.073136, l1: 0.073576, l2: 0.080199, l3: 0.098416, l4: 0.132426, l5: 0.205608, l6: 0.378394\n",
            "\n",
            "[epoch: 112/100000, batch: 848/1000, ite: 13981] train loss: 1.9399, accuracy: 93.5208%, tar: 0.1016 \n",
            "l0: 0.067221, l1: 0.068788, l2: 0.077586, l3: 0.096052, l4: 0.140824, l5: 0.223562, l6: 0.408014\n",
            "\n",
            "[epoch: 112/100000, batch: 856/1000, ite: 13982] train loss: 1.9397, accuracy: 93.3813%, tar: 0.1016 \n",
            "l0: 0.091726, l1: 0.091746, l2: 0.099647, l3: 0.124436, l4: 0.182639, l5: 0.282232, l6: 0.466989\n",
            "\n",
            "[epoch: 112/100000, batch: 864/1000, ite: 13983] train loss: 1.9396, accuracy: 92.8183%, tar: 0.1016 \n",
            "l0: 0.086711, l1: 0.087049, l2: 0.095093, l3: 0.116044, l4: 0.168613, l5: 0.252292, l6: 0.415730\n",
            "\n",
            "[epoch: 112/100000, batch: 872/1000, ite: 13984] train loss: 1.9395, accuracy: 92.1434%, tar: 0.1016 \n",
            "l0: 0.080334, l1: 0.080252, l2: 0.089137, l3: 0.112546, l4: 0.155748, l5: 0.267315, l6: 0.465435\n",
            "\n",
            "[epoch: 112/100000, batch: 880/1000, ite: 13985] train loss: 1.9394, accuracy: 91.9650%, tar: 0.1016 \n",
            "l0: 0.056816, l1: 0.058170, l2: 0.064885, l3: 0.085160, l4: 0.128192, l5: 0.197927, l6: 0.384268\n",
            "\n",
            "[epoch: 112/100000, batch: 888/1000, ite: 13986] train loss: 1.9391, accuracy: 93.0149%, tar: 0.1016 \n",
            "l0: 0.056757, l1: 0.057357, l2: 0.065866, l3: 0.086158, l4: 0.130173, l5: 0.210865, l6: 0.382376\n",
            "\n",
            "[epoch: 112/100000, batch: 896/1000, ite: 13987] train loss: 1.9388, accuracy: 94.6123%, tar: 0.1016 \n",
            "l0: 0.093727, l1: 0.094559, l2: 0.103611, l3: 0.125773, l4: 0.185409, l5: 0.308218, l6: 0.533042\n",
            "\n",
            "[epoch: 112/100000, batch: 904/1000, ite: 13988] train loss: 1.9388, accuracy: 91.2951%, tar: 0.1016 \n",
            "l0: 0.089288, l1: 0.090335, l2: 0.097501, l3: 0.115639, l4: 0.167870, l5: 0.248734, l6: 0.462700\n",
            "\n",
            "[epoch: 112/100000, batch: 912/1000, ite: 13989] train loss: 1.9387, accuracy: 91.6869%, tar: 0.1015 \n",
            "l0: 0.073043, l1: 0.074412, l2: 0.085778, l3: 0.110685, l4: 0.170651, l5: 0.251668, l6: 0.458452\n",
            "\n",
            "[epoch: 112/100000, batch: 920/1000, ite: 13990] train loss: 1.9386, accuracy: 92.5811%, tar: 0.1015 \n",
            "l0: 0.075346, l1: 0.076552, l2: 0.085628, l3: 0.116116, l4: 0.165988, l5: 0.259712, l6: 0.469345\n",
            "\n",
            "[epoch: 112/100000, batch: 928/1000, ite: 13991] train loss: 1.9385, accuracy: 92.6356%, tar: 0.1015 \n",
            "l0: 0.118578, l1: 0.120208, l2: 0.130151, l3: 0.155135, l4: 0.215400, l5: 0.357041, l6: 0.628128\n",
            "\n",
            "[epoch: 112/100000, batch: 936/1000, ite: 13992] train loss: 1.9387, accuracy: 90.3593%, tar: 0.1015 \n",
            "l0: 0.073239, l1: 0.073735, l2: 0.082575, l3: 0.104392, l4: 0.146368, l5: 0.241271, l6: 0.428666\n",
            "\n",
            "[epoch: 112/100000, batch: 944/1000, ite: 13993] train loss: 1.9385, accuracy: 93.3516%, tar: 0.1015 \n",
            "l0: 0.081920, l1: 0.082566, l2: 0.090414, l3: 0.117796, l4: 0.167264, l5: 0.268839, l6: 0.428951\n",
            "\n",
            "[epoch: 112/100000, batch: 952/1000, ite: 13994] train loss: 1.9384, accuracy: 92.4065%, tar: 0.1015 \n",
            "l0: 0.094494, l1: 0.095697, l2: 0.103714, l3: 0.133364, l4: 0.202063, l5: 0.305955, l6: 0.515104\n",
            "\n",
            "[epoch: 112/100000, batch: 960/1000, ite: 13995] train loss: 1.9384, accuracy: 91.5168%, tar: 0.1015 \n",
            "l0: 0.088336, l1: 0.090015, l2: 0.098237, l3: 0.119587, l4: 0.162055, l5: 0.308468, l6: 0.530269\n",
            "\n",
            "[epoch: 112/100000, batch: 968/1000, ite: 13996] train loss: 1.9384, accuracy: 92.5629%, tar: 0.1015 \n",
            "l0: 0.084942, l1: 0.085565, l2: 0.093939, l3: 0.117406, l4: 0.163195, l5: 0.275469, l6: 0.484002\n",
            "\n",
            "[epoch: 112/100000, batch: 976/1000, ite: 13997] train loss: 1.9383, accuracy: 92.7259%, tar: 0.1015 \n",
            "l0: 0.084427, l1: 0.085492, l2: 0.093172, l3: 0.114135, l4: 0.166900, l5: 0.264875, l6: 0.471764\n",
            "\n",
            "[epoch: 112/100000, batch: 984/1000, ite: 13998] train loss: 1.9382, accuracy: 92.0838%, tar: 0.1015 \n",
            "l0: 0.093568, l1: 0.094584, l2: 0.105443, l3: 0.132753, l4: 0.183073, l5: 0.277987, l6: 0.513538\n",
            "\n",
            "[epoch: 112/100000, batch: 992/1000, ite: 13999] train loss: 1.9382, accuracy: 92.1748%, tar: 0.1015 \n",
            "l0: 0.099691, l1: 0.100507, l2: 0.107183, l3: 0.135784, l4: 0.201978, l5: 0.348876, l6: 0.542339\n",
            "\n",
            "[epoch: 112/100000, batch: 1000/1000, ite: 14000] train loss: 1.9383, accuracy: 91.0160%, tar: 0.1015 \n",
            "l0: 0.060153, l1: 0.060853, l2: 0.070098, l3: 0.089423, l4: 0.132918, l5: 0.216706, l6: 0.389425\n",
            "\n",
            "[epoch: 113/100000, batch: 8/1000, ite: 14001] train loss: 1.4013, accuracy: 92.7750%, tar: 0.0602 \n",
            "l0: 0.062876, l1: 0.063131, l2: 0.071813, l3: 0.094736, l4: 0.148326, l5: 0.248329, l6: 0.433807\n",
            "\n",
            "[epoch: 113/100000, batch: 16/1000, ite: 14002] train loss: 1.4783, accuracy: 92.8992%, tar: 0.0615 \n",
            "l0: 0.147462, l1: 0.149219, l2: 0.162629, l3: 0.199759, l4: 0.279879, l5: 0.398321, l6: 0.598289\n",
            "\n",
            "[epoch: 113/100000, batch: 24/1000, ite: 14003] train loss: 1.8295, accuracy: 89.8267%, tar: 0.0902 \n",
            "l0: 0.073756, l1: 0.075317, l2: 0.082894, l3: 0.099205, l4: 0.133540, l5: 0.205203, l6: 0.361481\n",
            "\n",
            "[epoch: 113/100000, batch: 32/1000, ite: 14004] train loss: 1.7188, accuracy: 93.1676%, tar: 0.0861 \n",
            "l0: 0.095941, l1: 0.096453, l2: 0.104102, l3: 0.131538, l4: 0.189746, l5: 0.278054, l6: 0.517500\n",
            "\n",
            "[epoch: 113/100000, batch: 40/1000, ite: 14005] train loss: 1.7573, accuracy: 91.3441%, tar: 0.0880 \n",
            "l0: 0.128671, l1: 0.131240, l2: 0.142377, l3: 0.171074, l4: 0.231708, l5: 0.383869, l6: 0.650711\n",
            "\n",
            "[epoch: 113/100000, batch: 48/1000, ite: 14006] train loss: 1.8787, accuracy: 88.7382%, tar: 0.0948 \n",
            "l0: 0.067416, l1: 0.068881, l2: 0.079005, l3: 0.104411, l4: 0.150608, l5: 0.235148, l6: 0.456826\n",
            "\n",
            "[epoch: 113/100000, batch: 56/1000, ite: 14007] train loss: 1.8451, accuracy: 91.6622%, tar: 0.0909 \n",
            "l0: 0.083740, l1: 0.085593, l2: 0.095432, l3: 0.117971, l4: 0.185550, l5: 0.292212, l6: 0.476359\n",
            "\n",
            "[epoch: 113/100000, batch: 64/1000, ite: 14008] train loss: 1.8408, accuracy: 92.4812%, tar: 0.0900 \n",
            "l0: 0.058545, l1: 0.059234, l2: 0.065893, l3: 0.088425, l4: 0.142410, l5: 0.217937, l6: 0.454804\n",
            "\n",
            "[epoch: 113/100000, batch: 72/1000, ite: 14009] train loss: 1.8096, accuracy: 94.0185%, tar: 0.0865 \n",
            "l0: 0.090537, l1: 0.092878, l2: 0.103033, l3: 0.126811, l4: 0.169605, l5: 0.298612, l6: 0.510813\n",
            "\n",
            "[epoch: 113/100000, batch: 80/1000, ite: 14010] train loss: 1.8206, accuracy: 91.9597%, tar: 0.0869 \n",
            "l0: 0.067154, l1: 0.068070, l2: 0.075290, l3: 0.092663, l4: 0.128509, l5: 0.188398, l6: 0.347833\n",
            "\n",
            "[epoch: 113/100000, batch: 88/1000, ite: 14011] train loss: 1.7745, accuracy: 94.0095%, tar: 0.0851 \n",
            "l0: 0.101978, l1: 0.103936, l2: 0.111514, l3: 0.133813, l4: 0.191051, l5: 0.292331, l6: 0.476388\n",
            "\n",
            "[epoch: 113/100000, batch: 96/1000, ite: 14012] train loss: 1.7826, accuracy: 91.8009%, tar: 0.0865 \n",
            "l0: 0.056221, l1: 0.057516, l2: 0.066310, l3: 0.088445, l4: 0.134798, l5: 0.225320, l6: 0.393745\n",
            "\n",
            "[epoch: 113/100000, batch: 104/1000, ite: 14013] train loss: 1.7545, accuracy: 94.0901%, tar: 0.0842 \n",
            "l0: 0.087199, l1: 0.089216, l2: 0.098020, l3: 0.131312, l4: 0.208207, l5: 0.325275, l6: 0.569048\n",
            "\n",
            "[epoch: 113/100000, batch: 112/1000, ite: 14014] train loss: 1.7778, accuracy: 91.5714%, tar: 0.0844 \n",
            "l0: 0.103859, l1: 0.104672, l2: 0.114624, l3: 0.137888, l4: 0.200716, l5: 0.330634, l6: 0.533203\n",
            "\n",
            "[epoch: 113/100000, batch: 120/1000, ite: 14015] train loss: 1.7980, accuracy: 90.7363%, tar: 0.0857 \n",
            "l0: 0.085540, l1: 0.086414, l2: 0.092147, l3: 0.109469, l4: 0.146471, l5: 0.227946, l6: 0.405994\n",
            "\n",
            "[epoch: 113/100000, batch: 128/1000, ite: 14016] train loss: 1.7836, accuracy: 93.6767%, tar: 0.0857 \n",
            "l0: 0.072610, l1: 0.074022, l2: 0.081592, l3: 0.099206, l4: 0.142187, l5: 0.221178, l6: 0.418343\n",
            "\n",
            "[epoch: 113/100000, batch: 136/1000, ite: 14017] train loss: 1.7693, accuracy: 93.4692%, tar: 0.0849 \n",
            "l0: 0.087335, l1: 0.087881, l2: 0.097664, l3: 0.116464, l4: 0.143080, l5: 0.217094, l6: 0.359857\n",
            "\n",
            "[epoch: 113/100000, batch: 144/1000, ite: 14018] train loss: 1.7532, accuracy: 93.2570%, tar: 0.0851 \n",
            "l0: 0.112389, l1: 0.112109, l2: 0.124393, l3: 0.149578, l4: 0.217710, l5: 0.375605, l6: 0.633303\n",
            "\n",
            "[epoch: 113/100000, batch: 152/1000, ite: 14019] train loss: 1.7855, accuracy: 90.7450%, tar: 0.0865 \n",
            "l0: 0.091639, l1: 0.091680, l2: 0.102975, l3: 0.129488, l4: 0.191977, l5: 0.329190, l6: 0.579895\n",
            "\n",
            "[epoch: 113/100000, batch: 160/1000, ite: 14020] train loss: 1.8009, accuracy: 90.9299%, tar: 0.0868 \n",
            "l0: 0.107571, l1: 0.108947, l2: 0.117695, l3: 0.144739, l4: 0.209349, l5: 0.321885, l6: 0.464142\n",
            "\n",
            "[epoch: 113/100000, batch: 168/1000, ite: 14021] train loss: 1.8072, accuracy: 91.1636%, tar: 0.0877 \n",
            "l0: 0.064534, l1: 0.065081, l2: 0.076259, l3: 0.110254, l4: 0.184952, l5: 0.273330, l6: 0.472152\n",
            "\n",
            "[epoch: 113/100000, batch: 176/1000, ite: 14022] train loss: 1.8031, accuracy: 92.9793%, tar: 0.0867 \n",
            "l0: 0.111701, l1: 0.113192, l2: 0.122119, l3: 0.154068, l4: 0.227111, l5: 0.351514, l6: 0.566124\n",
            "\n",
            "[epoch: 113/100000, batch: 184/1000, ite: 14023] train loss: 1.8213, accuracy: 91.6809%, tar: 0.0878 \n",
            "l0: 0.107131, l1: 0.108286, l2: 0.118895, l3: 0.147323, l4: 0.216375, l5: 0.377462, l6: 0.660968\n",
            "\n",
            "[epoch: 113/100000, batch: 192/1000, ite: 14024] train loss: 1.8458, accuracy: 89.4417%, tar: 0.0886 \n",
            "l0: 0.127747, l1: 0.129203, l2: 0.136928, l3: 0.159267, l4: 0.218903, l5: 0.326471, l6: 0.516838\n",
            "\n",
            "[epoch: 113/100000, batch: 200/1000, ite: 14025] train loss: 1.8580, accuracy: 91.5173%, tar: 0.0901 \n",
            "l0: 0.065994, l1: 0.067482, l2: 0.073681, l3: 0.094109, l4: 0.154056, l5: 0.282958, l6: 0.465674\n",
            "\n",
            "[epoch: 113/100000, batch: 208/1000, ite: 14026] train loss: 1.8509, accuracy: 93.0855%, tar: 0.0892 \n",
            "l0: 0.071768, l1: 0.072460, l2: 0.077518, l3: 0.092529, l4: 0.128062, l5: 0.219439, l6: 0.387738\n",
            "\n",
            "[epoch: 113/100000, batch: 216/1000, ite: 14027] train loss: 1.8358, accuracy: 92.6430%, tar: 0.0886 \n",
            "l0: 0.080711, l1: 0.081533, l2: 0.090347, l3: 0.116646, l4: 0.167296, l5: 0.235842, l6: 0.373552\n",
            "\n",
            "[epoch: 113/100000, batch: 224/1000, ite: 14028] train loss: 1.8246, accuracy: 92.3186%, tar: 0.0883 \n",
            "l0: 0.092198, l1: 0.093298, l2: 0.102685, l3: 0.125573, l4: 0.175393, l5: 0.292326, l6: 0.545379\n",
            "\n",
            "[epoch: 113/100000, batch: 232/1000, ite: 14029] train loss: 1.8297, accuracy: 91.4743%, tar: 0.0884 \n",
            "l0: 0.110751, l1: 0.112414, l2: 0.120705, l3: 0.144194, l4: 0.205847, l5: 0.312192, l6: 0.481910\n",
            "\n",
            "[epoch: 113/100000, batch: 240/1000, ite: 14030] train loss: 1.8346, accuracy: 92.1325%, tar: 0.0892 \n",
            "l0: 0.084629, l1: 0.085366, l2: 0.096408, l3: 0.117233, l4: 0.167270, l5: 0.286031, l6: 0.532113\n",
            "\n",
            "[epoch: 113/100000, batch: 248/1000, ite: 14031] train loss: 1.8373, accuracy: 91.2257%, tar: 0.0890 \n",
            "l0: 0.071881, l1: 0.073335, l2: 0.079541, l3: 0.101816, l4: 0.143569, l5: 0.209933, l6: 0.344015\n",
            "\n",
            "[epoch: 113/100000, batch: 256/1000, ite: 14032] train loss: 1.8225, accuracy: 92.9402%, tar: 0.0885 \n",
            "l0: 0.070278, l1: 0.070903, l2: 0.081256, l3: 0.100343, l4: 0.137129, l5: 0.246176, l6: 0.431602\n",
            "\n",
            "[epoch: 113/100000, batch: 264/1000, ite: 14033] train loss: 1.8151, accuracy: 92.7335%, tar: 0.0879 \n",
            "l0: 0.077832, l1: 0.079031, l2: 0.086276, l3: 0.102277, l4: 0.139929, l5: 0.215746, l6: 0.401546\n",
            "\n",
            "[epoch: 113/100000, batch: 272/1000, ite: 14034] train loss: 1.8063, accuracy: 95.0391%, tar: 0.0876 \n",
            "l0: 0.100020, l1: 0.101099, l2: 0.115489, l3: 0.147456, l4: 0.242770, l5: 0.397519, l6: 0.629427\n",
            "\n",
            "[epoch: 113/100000, batch: 280/1000, ite: 14035] train loss: 1.8220, accuracy: 91.7335%, tar: 0.0880 \n",
            "l0: 0.070811, l1: 0.071681, l2: 0.078708, l3: 0.093897, l4: 0.137596, l5: 0.210658, l6: 0.362432\n",
            "\n",
            "[epoch: 113/100000, batch: 288/1000, ite: 14036] train loss: 1.8099, accuracy: 93.4708%, tar: 0.0875 \n",
            "l0: 0.088700, l1: 0.088827, l2: 0.094581, l3: 0.110357, l4: 0.147652, l5: 0.203525, l6: 0.366811\n",
            "\n",
            "[epoch: 113/100000, batch: 296/1000, ite: 14037] train loss: 1.8007, accuracy: 93.3595%, tar: 0.0875 \n",
            "l0: 0.101988, l1: 0.102890, l2: 0.113892, l3: 0.140542, l4: 0.197087, l5: 0.331850, l6: 0.497159\n",
            "\n",
            "[epoch: 113/100000, batch: 304/1000, ite: 14038] train loss: 1.8057, accuracy: 91.9068%, tar: 0.0879 \n",
            "l0: 0.090774, l1: 0.091221, l2: 0.105279, l3: 0.129587, l4: 0.192487, l5: 0.342509, l6: 0.532786\n",
            "\n",
            "[epoch: 113/100000, batch: 312/1000, ite: 14039] train loss: 1.8111, accuracy: 91.0004%, tar: 0.0880 \n",
            "l0: 0.102159, l1: 0.104392, l2: 0.116778, l3: 0.143508, l4: 0.192211, l5: 0.299576, l6: 0.462699\n",
            "\n",
            "[epoch: 113/100000, batch: 320/1000, ite: 14040] train loss: 1.8130, accuracy: 91.5056%, tar: 0.0884 \n",
            "l0: 0.091792, l1: 0.092874, l2: 0.100381, l3: 0.123495, l4: 0.158180, l5: 0.243670, l6: 0.422591\n",
            "\n",
            "[epoch: 113/100000, batch: 328/1000, ite: 14041] train loss: 1.8093, accuracy: 93.2934%, tar: 0.0884 \n",
            "l0: 0.077625, l1: 0.078972, l2: 0.092109, l3: 0.121009, l4: 0.181752, l5: 0.310211, l6: 0.548111\n",
            "\n",
            "[epoch: 113/100000, batch: 336/1000, ite: 14042] train loss: 1.8125, accuracy: 92.5630%, tar: 0.0882 \n",
            "l0: 0.109892, l1: 0.111422, l2: 0.124372, l3: 0.161950, l4: 0.222885, l5: 0.341566, l6: 0.603335\n",
            "\n",
            "[epoch: 113/100000, batch: 344/1000, ite: 14043] train loss: 1.8237, accuracy: 91.0527%, tar: 0.0887 \n",
            "l0: 0.081414, l1: 0.082141, l2: 0.094060, l3: 0.121485, l4: 0.194590, l5: 0.279635, l6: 0.511875\n",
            "\n",
            "[epoch: 113/100000, batch: 352/1000, ite: 14044] train loss: 1.8249, accuracy: 92.4567%, tar: 0.0885 \n",
            "l0: 0.077238, l1: 0.078655, l2: 0.087169, l3: 0.108430, l4: 0.178248, l5: 0.301628, l6: 0.490780\n",
            "\n",
            "[epoch: 113/100000, batch: 360/1000, ite: 14045] train loss: 1.8248, accuracy: 92.6145%, tar: 0.0883 \n",
            "l0: 0.081167, l1: 0.080897, l2: 0.086943, l3: 0.103044, l4: 0.125916, l5: 0.183065, l6: 0.369678\n",
            "\n",
            "[epoch: 113/100000, batch: 368/1000, ite: 14046] train loss: 1.8156, accuracy: 92.5385%, tar: 0.0881 \n",
            "l0: 0.083188, l1: 0.084031, l2: 0.090834, l3: 0.113577, l4: 0.159742, l5: 0.234871, l6: 0.402274\n",
            "\n",
            "[epoch: 113/100000, batch: 376/1000, ite: 14047] train loss: 1.8108, accuracy: 92.3658%, tar: 0.0880 \n",
            "l0: 0.083329, l1: 0.085240, l2: 0.095108, l3: 0.122721, l4: 0.171799, l5: 0.279247, l6: 0.513740\n",
            "\n",
            "[epoch: 113/100000, batch: 384/1000, ite: 14048] train loss: 1.8119, accuracy: 92.7958%, tar: 0.0879 \n",
            "l0: 0.066135, l1: 0.066505, l2: 0.075928, l3: 0.094775, l4: 0.137686, l5: 0.220903, l6: 0.422964\n",
            "\n",
            "[epoch: 113/100000, batch: 392/1000, ite: 14049] train loss: 1.8056, accuracy: 92.3705%, tar: 0.0875 \n",
            "l0: 0.107639, l1: 0.110273, l2: 0.122358, l3: 0.151372, l4: 0.232971, l5: 0.389675, l6: 0.653552\n",
            "\n",
            "[epoch: 113/100000, batch: 400/1000, ite: 14050] train loss: 1.8181, accuracy: 90.3019%, tar: 0.0879 \n",
            "l0: 0.070729, l1: 0.072144, l2: 0.081733, l3: 0.099752, l4: 0.148466, l5: 0.269186, l6: 0.457167\n",
            "\n",
            "[epoch: 113/100000, batch: 408/1000, ite: 14051] train loss: 1.8149, accuracy: 92.6332%, tar: 0.0875 \n",
            "l0: 0.088625, l1: 0.091061, l2: 0.100998, l3: 0.127831, l4: 0.194089, l5: 0.322415, l6: 0.494604\n",
            "\n",
            "[epoch: 113/100000, batch: 416/1000, ite: 14052] train loss: 1.8164, accuracy: 92.4412%, tar: 0.0876 \n",
            "l0: 0.078317, l1: 0.078652, l2: 0.089686, l3: 0.107329, l4: 0.147123, l5: 0.215382, l6: 0.398188\n",
            "\n",
            "[epoch: 113/100000, batch: 424/1000, ite: 14053] train loss: 1.8109, accuracy: 92.8332%, tar: 0.0874 \n",
            "l0: 0.068671, l1: 0.069236, l2: 0.079136, l3: 0.101741, l4: 0.157781, l5: 0.276258, l6: 0.408405\n",
            "\n",
            "[epoch: 113/100000, batch: 432/1000, ite: 14054] train loss: 1.8063, accuracy: 93.5701%, tar: 0.0870 \n",
            "l0: 0.072017, l1: 0.073123, l2: 0.081976, l3: 0.105296, l4: 0.172781, l5: 0.273080, l6: 0.439443\n",
            "\n",
            "[epoch: 113/100000, batch: 440/1000, ite: 14055] train loss: 1.8036, accuracy: 92.9635%, tar: 0.0868 \n",
            "l0: 0.090382, l1: 0.092270, l2: 0.101381, l3: 0.123530, l4: 0.180834, l5: 0.289514, l6: 0.478250\n",
            "\n",
            "[epoch: 113/100000, batch: 448/1000, ite: 14056] train loss: 1.8045, accuracy: 92.0796%, tar: 0.0868 \n",
            "l0: 0.070324, l1: 0.070819, l2: 0.080508, l3: 0.105963, l4: 0.146903, l5: 0.235494, l6: 0.444555\n",
            "\n",
            "[epoch: 113/100000, batch: 456/1000, ite: 14057] train loss: 1.8012, accuracy: 91.9783%, tar: 0.0865 \n",
            "l0: 0.091376, l1: 0.093022, l2: 0.102393, l3: 0.133626, l4: 0.184723, l5: 0.307508, l6: 0.450748\n",
            "\n",
            "[epoch: 113/100000, batch: 464/1000, ite: 14058] train loss: 1.8015, accuracy: 93.6110%, tar: 0.0866 \n",
            "l0: 0.066327, l1: 0.066428, l2: 0.074281, l3: 0.097757, l4: 0.133789, l5: 0.216724, l6: 0.334658\n",
            "\n",
            "[epoch: 113/100000, batch: 472/1000, ite: 14059] train loss: 1.7935, accuracy: 93.8189%, tar: 0.0863 \n",
            "l0: 0.065864, l1: 0.067612, l2: 0.076862, l3: 0.096507, l4: 0.144373, l5: 0.234846, l6: 0.443881\n",
            "\n",
            "[epoch: 113/100000, batch: 480/1000, ite: 14060] train loss: 1.7898, accuracy: 93.2872%, tar: 0.0859 \n",
            "l0: 0.068218, l1: 0.069158, l2: 0.078145, l3: 0.098800, l4: 0.144642, l5: 0.258517, l6: 0.483127\n",
            "\n",
            "[epoch: 113/100000, batch: 488/1000, ite: 14061] train loss: 1.7884, accuracy: 92.4046%, tar: 0.0856 \n",
            "l0: 0.091473, l1: 0.092316, l2: 0.103884, l3: 0.125266, l4: 0.182590, l5: 0.299706, l6: 0.508925\n",
            "\n",
            "[epoch: 113/100000, batch: 496/1000, ite: 14062] train loss: 1.7911, accuracy: 92.0064%, tar: 0.0857 \n",
            "l0: 0.088537, l1: 0.089247, l2: 0.101420, l3: 0.122575, l4: 0.183298, l5: 0.261326, l6: 0.404087\n",
            "\n",
            "[epoch: 113/100000, batch: 504/1000, ite: 14063] train loss: 1.7892, accuracy: 92.3482%, tar: 0.0858 \n",
            "l0: 0.068959, l1: 0.069627, l2: 0.077320, l3: 0.097026, l4: 0.132057, l5: 0.200791, l6: 0.354477\n",
            "\n",
            "[epoch: 113/100000, batch: 512/1000, ite: 14064] train loss: 1.7824, accuracy: 93.6483%, tar: 0.0855 \n",
            "l0: 0.071454, l1: 0.073112, l2: 0.084796, l3: 0.113234, l4: 0.183985, l5: 0.318650, l6: 0.609741\n",
            "\n",
            "[epoch: 113/100000, batch: 520/1000, ite: 14065] train loss: 1.7873, accuracy: 91.5010%, tar: 0.0853 \n",
            "l0: 0.078932, l1: 0.080431, l2: 0.089419, l3: 0.117916, l4: 0.157997, l5: 0.261177, l6: 0.483618\n",
            "\n",
            "[epoch: 113/100000, batch: 528/1000, ite: 14066] train loss: 1.7867, accuracy: 92.3974%, tar: 0.0852 \n",
            "l0: 0.060593, l1: 0.061360, l2: 0.071353, l3: 0.090413, l4: 0.129207, l5: 0.215152, l6: 0.317576\n",
            "\n",
            "[epoch: 113/100000, batch: 536/1000, ite: 14067] train loss: 1.7791, accuracy: 93.8019%, tar: 0.0848 \n",
            "l0: 0.102352, l1: 0.104097, l2: 0.113722, l3: 0.130693, l4: 0.174868, l5: 0.270592, l6: 0.480072\n",
            "\n",
            "[epoch: 113/100000, batch: 544/1000, ite: 14068] train loss: 1.7803, accuracy: 91.5154%, tar: 0.0851 \n",
            "l0: 0.079176, l1: 0.079937, l2: 0.089585, l3: 0.112474, l4: 0.142057, l5: 0.217087, l6: 0.378415\n",
            "\n",
            "[epoch: 113/100000, batch: 552/1000, ite: 14069] train loss: 1.7761, accuracy: 94.4647%, tar: 0.0850 \n",
            "l0: 0.083428, l1: 0.084737, l2: 0.096646, l3: 0.119121, l4: 0.169578, l5: 0.274757, l6: 0.476090\n",
            "\n",
            "[epoch: 113/100000, batch: 560/1000, ite: 14070] train loss: 1.7763, accuracy: 92.0948%, tar: 0.0850 \n",
            "l0: 0.072534, l1: 0.073103, l2: 0.081839, l3: 0.104768, l4: 0.167016, l5: 0.270437, l6: 0.450526\n",
            "\n",
            "[epoch: 113/100000, batch: 568/1000, ite: 14071] train loss: 1.7751, accuracy: 92.3014%, tar: 0.0848 \n",
            "l0: 0.101403, l1: 0.102301, l2: 0.112778, l3: 0.135786, l4: 0.185026, l5: 0.307814, l6: 0.487631\n",
            "\n",
            "[epoch: 113/100000, batch: 576/1000, ite: 14072] train loss: 1.7771, accuracy: 92.2431%, tar: 0.0850 \n",
            "l0: 0.075363, l1: 0.076499, l2: 0.085162, l3: 0.103439, l4: 0.148148, l5: 0.260842, l6: 0.533839\n",
            "\n",
            "[epoch: 113/100000, batch: 584/1000, ite: 14073] train loss: 1.7776, accuracy: 92.0575%, tar: 0.0849 \n",
            "l0: 0.064036, l1: 0.065032, l2: 0.070838, l3: 0.085870, l4: 0.115392, l5: 0.172876, l6: 0.299572\n",
            "\n",
            "[epoch: 113/100000, batch: 592/1000, ite: 14074] train loss: 1.7694, accuracy: 94.7793%, tar: 0.0846 \n",
            "l0: 0.080050, l1: 0.081379, l2: 0.088619, l3: 0.103390, l4: 0.138405, l5: 0.204933, l6: 0.372103\n",
            "\n",
            "[epoch: 113/100000, batch: 600/1000, ite: 14075] train loss: 1.7651, accuracy: 93.2890%, tar: 0.0846 \n",
            "l0: 0.090625, l1: 0.092419, l2: 0.098026, l3: 0.119099, l4: 0.172568, l5: 0.264669, l6: 0.418153\n",
            "\n",
            "[epoch: 113/100000, batch: 608/1000, ite: 14076] train loss: 1.7639, accuracy: 92.1266%, tar: 0.0846 \n",
            "l0: 0.070970, l1: 0.072095, l2: 0.081158, l3: 0.108975, l4: 0.159335, l5: 0.261572, l6: 0.504241\n",
            "\n",
            "[epoch: 113/100000, batch: 616/1000, ite: 14077] train loss: 1.7638, accuracy: 94.2533%, tar: 0.0845 \n",
            "l0: 0.080589, l1: 0.080993, l2: 0.092000, l3: 0.117014, l4: 0.163550, l5: 0.286819, l6: 0.504836\n",
            "\n",
            "[epoch: 113/100000, batch: 624/1000, ite: 14078] train loss: 1.7649, accuracy: 91.0663%, tar: 0.0844 \n",
            "l0: 0.067630, l1: 0.068588, l2: 0.072148, l3: 0.087460, l4: 0.117706, l5: 0.187130, l6: 0.308511\n",
            "\n",
            "[epoch: 113/100000, batch: 632/1000, ite: 14079] train loss: 1.7581, accuracy: 94.3618%, tar: 0.0842 \n",
            "l0: 0.088349, l1: 0.089842, l2: 0.100016, l3: 0.128033, l4: 0.187328, l5: 0.293626, l6: 0.482004\n",
            "\n",
            "[epoch: 113/100000, batch: 640/1000, ite: 14080] train loss: 1.7594, accuracy: 92.5912%, tar: 0.0843 \n",
            "l0: 0.095342, l1: 0.096533, l2: 0.107101, l3: 0.133272, l4: 0.181174, l5: 0.272167, l6: 0.485703\n",
            "\n",
            "[epoch: 113/100000, batch: 648/1000, ite: 14081] train loss: 1.7605, accuracy: 93.2181%, tar: 0.0844 \n",
            "l0: 0.084180, l1: 0.084140, l2: 0.093485, l3: 0.113101, l4: 0.152371, l5: 0.213420, l6: 0.355130\n",
            "\n",
            "[epoch: 113/100000, batch: 656/1000, ite: 14082] train loss: 1.7567, accuracy: 93.5941%, tar: 0.0844 \n",
            "l0: 0.072441, l1: 0.072693, l2: 0.078782, l3: 0.095661, l4: 0.133885, l5: 0.226990, l6: 0.405747\n",
            "\n",
            "[epoch: 113/100000, batch: 664/1000, ite: 14083] train loss: 1.7537, accuracy: 93.1828%, tar: 0.0843 \n",
            "l0: 0.069437, l1: 0.070556, l2: 0.080718, l3: 0.095887, l4: 0.141105, l5: 0.258052, l6: 0.428841\n",
            "\n",
            "[epoch: 113/100000, batch: 672/1000, ite: 14084] train loss: 1.7516, accuracy: 92.7251%, tar: 0.0841 \n",
            "l0: 0.077115, l1: 0.077855, l2: 0.085375, l3: 0.097407, l4: 0.137929, l5: 0.217480, l6: 0.436934\n",
            "\n",
            "[epoch: 113/100000, batch: 680/1000, ite: 14085] train loss: 1.7495, accuracy: 92.6071%, tar: 0.0840 \n",
            "l0: 0.088184, l1: 0.087918, l2: 0.099911, l3: 0.121311, l4: 0.178967, l5: 0.272930, l6: 0.479778\n",
            "\n",
            "[epoch: 113/100000, batch: 688/1000, ite: 14086] train loss: 1.7503, accuracy: 91.2835%, tar: 0.0840 \n",
            "l0: 0.092069, l1: 0.093083, l2: 0.102903, l3: 0.130650, l4: 0.203115, l5: 0.311219, l6: 0.493603\n",
            "\n",
            "[epoch: 113/100000, batch: 696/1000, ite: 14087] train loss: 1.7524, accuracy: 91.3269%, tar: 0.0841 \n",
            "l0: 0.063869, l1: 0.065456, l2: 0.073719, l3: 0.096062, l4: 0.138680, l5: 0.194041, l6: 0.301525\n",
            "\n",
            "[epoch: 113/100000, batch: 704/1000, ite: 14088] train loss: 1.7466, accuracy: 94.2603%, tar: 0.0839 \n",
            "l0: 0.083735, l1: 0.083928, l2: 0.092326, l3: 0.109711, l4: 0.158820, l5: 0.234483, l6: 0.418782\n",
            "\n",
            "[epoch: 113/100000, batch: 712/1000, ite: 14089] train loss: 1.7451, accuracy: 93.3528%, tar: 0.0839 \n",
            "l0: 0.130539, l1: 0.131381, l2: 0.141732, l3: 0.166990, l4: 0.228955, l5: 0.354973, l6: 0.652389\n",
            "\n",
            "[epoch: 113/100000, batch: 720/1000, ite: 14090] train loss: 1.7530, accuracy: 89.8948%, tar: 0.0844 \n",
            "l0: 0.097355, l1: 0.098780, l2: 0.107587, l3: 0.119930, l4: 0.143574, l5: 0.246788, l6: 0.394765\n",
            "\n",
            "[epoch: 113/100000, batch: 728/1000, ite: 14091] train loss: 1.7514, accuracy: 92.2280%, tar: 0.0846 \n",
            "l0: 0.075196, l1: 0.075664, l2: 0.083917, l3: 0.109025, l4: 0.163757, l5: 0.276059, l6: 0.431424\n",
            "\n",
            "[epoch: 113/100000, batch: 736/1000, ite: 14092] train loss: 1.7503, accuracy: 93.1362%, tar: 0.0845 \n",
            "l0: 0.072862, l1: 0.073095, l2: 0.082149, l3: 0.103732, l4: 0.148725, l5: 0.225569, l6: 0.396079\n",
            "\n",
            "[epoch: 113/100000, batch: 744/1000, ite: 14093] train loss: 1.7476, accuracy: 93.7659%, tar: 0.0843 \n",
            "l0: 0.093058, l1: 0.094232, l2: 0.103951, l3: 0.130890, l4: 0.199970, l5: 0.298310, l6: 0.585759\n",
            "\n",
            "[epoch: 113/100000, batch: 752/1000, ite: 14094] train loss: 1.7515, accuracy: 91.9953%, tar: 0.0844 \n",
            "l0: 0.094743, l1: 0.094674, l2: 0.105215, l3: 0.133648, l4: 0.189578, l5: 0.333857, l6: 0.712132\n",
            "\n",
            "[epoch: 113/100000, batch: 760/1000, ite: 14095] train loss: 1.7580, accuracy: 89.7144%, tar: 0.0845 \n",
            "l0: 0.071226, l1: 0.072217, l2: 0.082052, l3: 0.105566, l4: 0.150398, l5: 0.246712, l6: 0.428876\n",
            "\n",
            "[epoch: 113/100000, batch: 768/1000, ite: 14096] train loss: 1.7563, accuracy: 92.3388%, tar: 0.0844 \n",
            "l0: 0.075601, l1: 0.076234, l2: 0.084671, l3: 0.108425, l4: 0.162907, l5: 0.278697, l6: 0.541826\n",
            "\n",
            "[epoch: 113/100000, batch: 776/1000, ite: 14097] train loss: 1.7574, accuracy: 92.1938%, tar: 0.0843 \n",
            "l0: 0.094452, l1: 0.096141, l2: 0.107024, l3: 0.135462, l4: 0.196617, l5: 0.315087, l6: 0.591661\n",
            "\n",
            "[epoch: 113/100000, batch: 784/1000, ite: 14098] train loss: 1.7612, accuracy: 91.1118%, tar: 0.0844 \n",
            "l0: 0.132638, l1: 0.133872, l2: 0.144546, l3: 0.180112, l4: 0.292011, l5: 0.439957, l6: 0.713352\n",
            "\n",
            "[epoch: 113/100000, batch: 792/1000, ite: 14099] train loss: 1.7715, accuracy: 89.2506%, tar: 0.0849 \n",
            "l0: 0.091825, l1: 0.093626, l2: 0.105297, l3: 0.134502, l4: 0.190974, l5: 0.281377, l6: 0.528173\n",
            "\n",
            "[epoch: 113/100000, batch: 800/1000, ite: 14100] train loss: 1.7733, accuracy: 92.0564%, tar: 0.0850 \n",
            "l0: 0.093011, l1: 0.093620, l2: 0.100718, l3: 0.125833, l4: 0.185022, l5: 0.284593, l6: 0.506282\n",
            "\n",
            "[epoch: 113/100000, batch: 808/1000, ite: 14101] train loss: 1.7747, accuracy: 91.4165%, tar: 0.0850 \n",
            "l0: 0.092055, l1: 0.093472, l2: 0.100759, l3: 0.120926, l4: 0.171608, l5: 0.279437, l6: 0.516970\n",
            "\n",
            "[epoch: 113/100000, batch: 816/1000, ite: 14102] train loss: 1.7763, accuracy: 91.2351%, tar: 0.0851 \n",
            "l0: 0.070154, l1: 0.070369, l2: 0.076361, l3: 0.092345, l4: 0.137273, l5: 0.238822, l6: 0.463523\n",
            "\n",
            "[epoch: 113/100000, batch: 824/1000, ite: 14103] train loss: 1.7751, accuracy: 91.9441%, tar: 0.0850 \n",
            "l0: 0.093326, l1: 0.094821, l2: 0.103408, l3: 0.120396, l4: 0.156077, l5: 0.223184, l6: 0.384990\n",
            "\n",
            "[epoch: 113/100000, batch: 832/1000, ite: 14104] train loss: 1.7731, accuracy: 92.5382%, tar: 0.0851 \n",
            "l0: 0.101693, l1: 0.102164, l2: 0.111271, l3: 0.131633, l4: 0.187320, l5: 0.264238, l6: 0.418673\n",
            "\n",
            "[epoch: 113/100000, batch: 840/1000, ite: 14105] train loss: 1.7727, accuracy: 93.2022%, tar: 0.0852 \n",
            "l0: 0.064965, l1: 0.065942, l2: 0.076317, l3: 0.101112, l4: 0.159968, l5: 0.248912, l6: 0.533282\n",
            "\n",
            "[epoch: 113/100000, batch: 848/1000, ite: 14106] train loss: 1.7728, accuracy: 92.1253%, tar: 0.0850 \n",
            "l0: 0.093643, l1: 0.094944, l2: 0.104402, l3: 0.121986, l4: 0.177052, l5: 0.295507, l6: 0.524307\n",
            "\n",
            "[epoch: 113/100000, batch: 856/1000, ite: 14107] train loss: 1.7744, accuracy: 90.9682%, tar: 0.0851 \n",
            "l0: 0.088629, l1: 0.089564, l2: 0.099147, l3: 0.128250, l4: 0.195714, l5: 0.285739, l6: 0.499955\n",
            "\n",
            "[epoch: 113/100000, batch: 864/1000, ite: 14108] train loss: 1.7752, accuracy: 92.3578%, tar: 0.0851 \n",
            "l0: 0.063777, l1: 0.064550, l2: 0.071645, l3: 0.093103, l4: 0.135027, l5: 0.219028, l6: 0.396009\n",
            "\n",
            "[epoch: 113/100000, batch: 872/1000, ite: 14109] train loss: 1.7722, accuracy: 93.2667%, tar: 0.0849 \n",
            "l0: 0.083588, l1: 0.085493, l2: 0.095095, l3: 0.122811, l4: 0.177159, l5: 0.273745, l6: 0.450605\n",
            "\n",
            "[epoch: 113/100000, batch: 880/1000, ite: 14110] train loss: 1.7720, accuracy: 92.4911%, tar: 0.0849 \n",
            "l0: 0.076509, l1: 0.077936, l2: 0.084386, l3: 0.105664, l4: 0.149213, l5: 0.242602, l6: 0.430555\n",
            "\n",
            "[epoch: 113/100000, batch: 888/1000, ite: 14111] train loss: 1.7706, accuracy: 92.3722%, tar: 0.0848 \n",
            "l0: 0.099640, l1: 0.100864, l2: 0.116379, l3: 0.146147, l4: 0.228732, l5: 0.399479, l6: 0.682494\n",
            "\n",
            "[epoch: 113/100000, batch: 896/1000, ite: 14112] train loss: 1.7768, accuracy: 88.7930%, tar: 0.0850 \n",
            "l0: 0.079657, l1: 0.080639, l2: 0.091163, l3: 0.120831, l4: 0.181712, l5: 0.274602, l6: 0.439208\n",
            "\n",
            "[epoch: 113/100000, batch: 904/1000, ite: 14113] train loss: 1.7761, accuracy: 92.5760%, tar: 0.0849 \n",
            "l0: 0.124716, l1: 0.125868, l2: 0.137002, l3: 0.167902, l4: 0.245961, l5: 0.373181, l6: 0.628927\n",
            "\n",
            "[epoch: 113/100000, batch: 912/1000, ite: 14114] train loss: 1.7818, accuracy: 89.1140%, tar: 0.0853 \n",
            "l0: 0.113710, l1: 0.114531, l2: 0.126618, l3: 0.157937, l4: 0.227562, l5: 0.327543, l6: 0.591677\n",
            "\n",
            "[epoch: 113/100000, batch: 920/1000, ite: 14115] train loss: 1.7859, accuracy: 91.0530%, tar: 0.0855 \n",
            "l0: 0.044681, l1: 0.045272, l2: 0.049596, l3: 0.064856, l4: 0.096865, l5: 0.153263, l6: 0.299218\n",
            "\n",
            "[epoch: 113/100000, batch: 928/1000, ite: 14116] train loss: 1.7795, accuracy: 94.4408%, tar: 0.0852 \n",
            "l0: 0.102299, l1: 0.103159, l2: 0.112801, l3: 0.134748, l4: 0.183467, l5: 0.271386, l6: 0.469814\n",
            "\n",
            "[epoch: 113/100000, batch: 936/1000, ite: 14117] train loss: 1.7802, accuracy: 92.7789%, tar: 0.0853 \n",
            "l0: 0.103560, l1: 0.104507, l2: 0.114769, l3: 0.135908, l4: 0.191313, l5: 0.307829, l6: 0.530547\n",
            "\n",
            "[epoch: 113/100000, batch: 944/1000, ite: 14118] train loss: 1.7823, accuracy: 89.6815%, tar: 0.0855 \n",
            "l0: 0.101952, l1: 0.103727, l2: 0.113077, l3: 0.137299, l4: 0.214509, l5: 0.371364, l6: 0.651296\n",
            "\n",
            "[epoch: 113/100000, batch: 952/1000, ite: 14119] train loss: 1.7868, accuracy: 91.4670%, tar: 0.0856 \n",
            "l0: 0.077092, l1: 0.077952, l2: 0.087490, l3: 0.110690, l4: 0.161538, l5: 0.269095, l6: 0.521531\n",
            "\n",
            "[epoch: 113/100000, batch: 960/1000, ite: 14120] train loss: 1.7871, accuracy: 91.9946%, tar: 0.0855 \n",
            "l0: 0.068738, l1: 0.069401, l2: 0.079370, l3: 0.103528, l4: 0.162259, l5: 0.271836, l6: 0.451300\n",
            "\n",
            "[epoch: 113/100000, batch: 968/1000, ite: 14121] train loss: 1.7860, accuracy: 92.5493%, tar: 0.0854 \n",
            "l0: 0.083218, l1: 0.083765, l2: 0.094086, l3: 0.113579, l4: 0.158727, l5: 0.268635, l6: 0.453518\n",
            "\n",
            "[epoch: 113/100000, batch: 976/1000, ite: 14122] train loss: 1.7854, accuracy: 91.5609%, tar: 0.0854 \n",
            "l0: 0.077218, l1: 0.078429, l2: 0.084772, l3: 0.103908, l4: 0.148344, l5: 0.221872, l6: 0.355618\n",
            "\n",
            "[epoch: 113/100000, batch: 984/1000, ite: 14123] train loss: 1.7825, accuracy: 93.4360%, tar: 0.0853 \n",
            "l0: 0.073805, l1: 0.074845, l2: 0.084502, l3: 0.110798, l4: 0.162739, l5: 0.227181, l6: 0.366128\n",
            "\n",
            "[epoch: 113/100000, batch: 992/1000, ite: 14124] train loss: 1.7800, accuracy: 92.9260%, tar: 0.0852 \n",
            "l0: 0.102993, l1: 0.104492, l2: 0.115353, l3: 0.141595, l4: 0.194267, l5: 0.322365, l6: 0.559081\n",
            "\n",
            "[epoch: 113/100000, batch: 1000/1000, ite: 14125] train loss: 1.7826, accuracy: 90.0412%, tar: 0.0854 \n",
            "l0: 0.118524, l1: 0.120679, l2: 0.129522, l3: 0.153058, l4: 0.215627, l5: 0.358980, l6: 0.543684\n",
            "\n",
            "[epoch: 114/100000, batch: 8/1000, ite: 14126] train loss: 1.7860, accuracy: 92.7861%, tar: 0.0856 \n",
            "l0: 0.122226, l1: 0.123080, l2: 0.134472, l3: 0.163460, l4: 0.236851, l5: 0.376863, l6: 0.600417\n",
            "\n",
            "[epoch: 114/100000, batch: 16/1000, ite: 14127] train loss: 1.7905, accuracy: 89.5135%, tar: 0.0859 \n",
            "l0: 0.069075, l1: 0.071409, l2: 0.078230, l3: 0.101309, l4: 0.161377, l5: 0.268966, l6: 0.443712\n",
            "\n",
            "[epoch: 114/100000, batch: 24/1000, ite: 14128] train loss: 1.7892, accuracy: 92.7764%, tar: 0.0858 \n",
            "l0: 0.068785, l1: 0.069933, l2: 0.077055, l3: 0.095661, l4: 0.135426, l5: 0.206961, l6: 0.375044\n",
            "\n",
            "[epoch: 114/100000, batch: 32/1000, ite: 14129] train loss: 1.7863, accuracy: 93.3572%, tar: 0.0857 \n",
            "l0: 0.090434, l1: 0.091289, l2: 0.103313, l3: 0.133232, l4: 0.190759, l5: 0.317808, l6: 0.551530\n",
            "\n",
            "[epoch: 114/100000, batch: 40/1000, ite: 14130] train loss: 1.7882, accuracy: 91.5204%, tar: 0.0857 \n",
            "l0: 0.069645, l1: 0.071168, l2: 0.078976, l3: 0.098321, l4: 0.138906, l5: 0.257370, l6: 0.482346\n",
            "\n",
            "[epoch: 114/100000, batch: 48/1000, ite: 14131] train loss: 1.7873, accuracy: 92.6002%, tar: 0.0856 \n",
            "l0: 0.060631, l1: 0.060832, l2: 0.069576, l3: 0.081947, l4: 0.109721, l5: 0.185658, l6: 0.351496\n",
            "\n",
            "[epoch: 114/100000, batch: 56/1000, ite: 14132] train loss: 1.7835, accuracy: 93.6349%, tar: 0.0854 \n",
            "l0: 0.071678, l1: 0.074107, l2: 0.081534, l3: 0.101888, l4: 0.162143, l5: 0.280565, l6: 0.457337\n",
            "\n",
            "[epoch: 114/100000, batch: 64/1000, ite: 14133] train loss: 1.7828, accuracy: 92.7354%, tar: 0.0853 \n",
            "l0: 0.088891, l1: 0.089475, l2: 0.097149, l3: 0.113272, l4: 0.140340, l5: 0.222930, l6: 0.471549\n",
            "\n",
            "[epoch: 114/100000, batch: 72/1000, ite: 14134] train loss: 1.7823, accuracy: 92.1395%, tar: 0.0853 \n",
            "l0: 0.069165, l1: 0.069952, l2: 0.079921, l3: 0.099431, l4: 0.149077, l5: 0.231501, l6: 0.395269\n",
            "\n",
            "[epoch: 114/100000, batch: 80/1000, ite: 14135] train loss: 1.7802, accuracy: 93.6028%, tar: 0.0852 \n",
            "l0: 0.055698, l1: 0.056492, l2: 0.064971, l3: 0.088483, l4: 0.121143, l5: 0.187875, l6: 0.318222\n",
            "\n",
            "[epoch: 114/100000, batch: 88/1000, ite: 14136] train loss: 1.7760, accuracy: 94.3749%, tar: 0.0850 \n",
            "l0: 0.059447, l1: 0.059459, l2: 0.065631, l3: 0.086944, l4: 0.119948, l5: 0.198419, l6: 0.369088\n",
            "\n",
            "[epoch: 114/100000, batch: 96/1000, ite: 14137] train loss: 1.7728, accuracy: 94.7084%, tar: 0.0848 \n",
            "l0: 0.094222, l1: 0.095455, l2: 0.104514, l3: 0.127703, l4: 0.173517, l5: 0.274179, l6: 0.526982\n",
            "\n",
            "[epoch: 114/100000, batch: 104/1000, ite: 14138] train loss: 1.7739, accuracy: 91.0740%, tar: 0.0849 \n",
            "l0: 0.102150, l1: 0.102392, l2: 0.111460, l3: 0.134876, l4: 0.188721, l5: 0.333857, l6: 0.661824\n",
            "\n",
            "[epoch: 114/100000, batch: 112/1000, ite: 14139] train loss: 1.7776, accuracy: 90.9334%, tar: 0.0850 \n",
            "l0: 0.065403, l1: 0.065584, l2: 0.073739, l3: 0.089892, l4: 0.128489, l5: 0.204640, l6: 0.383811\n",
            "\n",
            "[epoch: 114/100000, batch: 120/1000, ite: 14140] train loss: 1.7749, accuracy: 93.4247%, tar: 0.0848 \n",
            "l0: 0.077449, l1: 0.078450, l2: 0.085815, l3: 0.099148, l4: 0.137294, l5: 0.192773, l6: 0.346269\n",
            "\n",
            "[epoch: 114/100000, batch: 128/1000, ite: 14141] train loss: 1.7720, accuracy: 93.2960%, tar: 0.0848 \n",
            "l0: 0.071782, l1: 0.072412, l2: 0.078957, l3: 0.098977, l4: 0.137830, l5: 0.218328, l6: 0.346870\n",
            "\n",
            "[epoch: 114/100000, batch: 136/1000, ite: 14142] train loss: 1.7692, accuracy: 93.7210%, tar: 0.0847 \n",
            "l0: 0.078486, l1: 0.079029, l2: 0.090264, l3: 0.109120, l4: 0.160042, l5: 0.243014, l6: 0.401589\n",
            "\n",
            "[epoch: 114/100000, batch: 144/1000, ite: 14143] train loss: 1.7678, accuracy: 92.6818%, tar: 0.0847 \n",
            "l0: 0.067501, l1: 0.067457, l2: 0.075582, l3: 0.094780, l4: 0.153849, l5: 0.226257, l6: 0.373327\n",
            "\n",
            "[epoch: 114/100000, batch: 152/1000, ite: 14144] train loss: 1.7655, accuracy: 94.3993%, tar: 0.0845 \n",
            "l0: 0.049997, l1: 0.050593, l2: 0.057801, l3: 0.074886, l4: 0.103480, l5: 0.163805, l6: 0.317724\n",
            "\n",
            "[epoch: 114/100000, batch: 160/1000, ite: 14145] train loss: 1.7612, accuracy: 93.9250%, tar: 0.0843 \n",
            "l0: 0.052799, l1: 0.054853, l2: 0.066108, l3: 0.090807, l4: 0.141494, l5: 0.253290, l6: 0.501143\n",
            "\n",
            "[epoch: 114/100000, batch: 168/1000, ite: 14146] train loss: 1.7605, accuracy: 91.9195%, tar: 0.0841 \n",
            "l0: 0.055695, l1: 0.056353, l2: 0.065975, l3: 0.089429, l4: 0.138475, l5: 0.246970, l6: 0.443558\n",
            "\n",
            "[epoch: 114/100000, batch: 176/1000, ite: 14147] train loss: 1.7590, accuracy: 93.2574%, tar: 0.0839 \n",
            "l0: 0.075963, l1: 0.077567, l2: 0.088524, l3: 0.109859, l4: 0.164969, l5: 0.283748, l6: 0.510932\n",
            "\n",
            "[epoch: 114/100000, batch: 184/1000, ite: 14148] train loss: 1.7593, accuracy: 92.0022%, tar: 0.0838 \n",
            "l0: 0.068263, l1: 0.069475, l2: 0.081323, l3: 0.115272, l4: 0.196816, l5: 0.336722, l6: 0.560078\n",
            "\n",
            "[epoch: 114/100000, batch: 192/1000, ite: 14149] train loss: 1.7608, accuracy: 90.5234%, tar: 0.0837 \n",
            "l0: 0.069240, l1: 0.070702, l2: 0.079919, l3: 0.106038, l4: 0.171660, l5: 0.262827, l6: 0.440119\n",
            "\n",
            "[epoch: 114/100000, batch: 200/1000, ite: 14150] train loss: 1.7599, accuracy: 93.2152%, tar: 0.0836 \n",
            "l0: 0.074309, l1: 0.075583, l2: 0.085450, l3: 0.105429, l4: 0.145166, l5: 0.214074, l6: 0.384547\n",
            "\n",
            "[epoch: 114/100000, batch: 208/1000, ite: 14151] train loss: 1.7580, accuracy: 92.9012%, tar: 0.0836 \n",
            "l0: 0.075971, l1: 0.075520, l2: 0.084692, l3: 0.101571, l4: 0.144799, l5: 0.231735, l6: 0.450299\n",
            "\n",
            "[epoch: 114/100000, batch: 216/1000, ite: 14152] train loss: 1.7572, accuracy: 93.4677%, tar: 0.0835 \n",
            "l0: 0.091832, l1: 0.093275, l2: 0.100649, l3: 0.120511, l4: 0.163462, l5: 0.222530, l6: 0.343774\n",
            "\n",
            "[epoch: 114/100000, batch: 224/1000, ite: 14153] train loss: 1.7554, accuracy: 94.5073%, tar: 0.0836 \n",
            "l0: 0.085616, l1: 0.086458, l2: 0.097302, l3: 0.121534, l4: 0.162643, l5: 0.292312, l6: 0.520912\n",
            "\n",
            "[epoch: 114/100000, batch: 232/1000, ite: 14154] train loss: 1.7563, accuracy: 90.5029%, tar: 0.0836 \n",
            "l0: 0.070299, l1: 0.072002, l2: 0.080358, l3: 0.106461, l4: 0.152649, l5: 0.250914, l6: 0.431327\n",
            "\n",
            "[epoch: 114/100000, batch: 240/1000, ite: 14155] train loss: 1.7554, accuracy: 92.4321%, tar: 0.0835 \n",
            "l0: 0.105852, l1: 0.106041, l2: 0.113726, l3: 0.130865, l4: 0.186486, l5: 0.266769, l6: 0.461812\n",
            "\n",
            "[epoch: 114/100000, batch: 248/1000, ite: 14156] train loss: 1.7559, accuracy: 92.8545%, tar: 0.0836 \n",
            "l0: 0.099412, l1: 0.101196, l2: 0.109142, l3: 0.135952, l4: 0.189135, l5: 0.284562, l6: 0.528930\n",
            "\n",
            "[epoch: 114/100000, batch: 256/1000, ite: 14157] train loss: 1.7574, accuracy: 91.0950%, tar: 0.0837 \n",
            "l0: 0.121852, l1: 0.123375, l2: 0.133776, l3: 0.157238, l4: 0.222958, l5: 0.351625, l6: 0.560489\n",
            "\n",
            "[epoch: 114/100000, batch: 264/1000, ite: 14158] train loss: 1.7607, accuracy: 89.4352%, tar: 0.0840 \n",
            "l0: 0.084158, l1: 0.084632, l2: 0.093773, l3: 0.115834, l4: 0.164561, l5: 0.241109, l6: 0.410714\n",
            "\n",
            "[epoch: 114/100000, batch: 272/1000, ite: 14159] train loss: 1.7597, accuracy: 93.2426%, tar: 0.0840 \n",
            "l0: 0.065110, l1: 0.065771, l2: 0.074233, l3: 0.098072, l4: 0.140282, l5: 0.235977, l6: 0.421763\n",
            "\n",
            "[epoch: 114/100000, batch: 280/1000, ite: 14160] train loss: 1.7582, accuracy: 94.0451%, tar: 0.0839 \n",
            "l0: 0.081130, l1: 0.082744, l2: 0.090303, l3: 0.107867, l4: 0.164160, l5: 0.261551, l6: 0.410054\n",
            "\n",
            "[epoch: 114/100000, batch: 288/1000, ite: 14161] train loss: 1.7573, accuracy: 93.5660%, tar: 0.0839 \n",
            "l0: 0.068341, l1: 0.069335, l2: 0.078770, l3: 0.102582, l4: 0.157397, l5: 0.267940, l6: 0.526906\n",
            "\n",
            "[epoch: 114/100000, batch: 296/1000, ite: 14162] train loss: 1.7575, accuracy: 92.1290%, tar: 0.0838 \n",
            "l0: 0.079846, l1: 0.080667, l2: 0.091641, l3: 0.118345, l4: 0.189685, l5: 0.286716, l6: 0.484482\n",
            "\n",
            "[epoch: 114/100000, batch: 304/1000, ite: 14163] train loss: 1.7577, accuracy: 91.7020%, tar: 0.0837 \n",
            "l0: 0.124303, l1: 0.126322, l2: 0.139328, l3: 0.175653, l4: 0.260329, l5: 0.410149, l6: 0.631013\n",
            "\n",
            "[epoch: 114/100000, batch: 312/1000, ite: 14164] train loss: 1.7622, accuracy: 89.0943%, tar: 0.0840 \n",
            "l0: 0.083556, l1: 0.085246, l2: 0.095564, l3: 0.119946, l4: 0.173430, l5: 0.273237, l6: 0.449426\n",
            "\n",
            "[epoch: 114/100000, batch: 320/1000, ite: 14165] train loss: 1.7620, accuracy: 91.9340%, tar: 0.0840 \n",
            "l0: 0.071876, l1: 0.073458, l2: 0.082457, l3: 0.106514, l4: 0.150778, l5: 0.251802, l6: 0.451850\n",
            "\n",
            "[epoch: 114/100000, batch: 328/1000, ite: 14166] train loss: 1.7613, accuracy: 93.4683%, tar: 0.0839 \n",
            "l0: 0.112171, l1: 0.113685, l2: 0.125672, l3: 0.155667, l4: 0.216368, l5: 0.312936, l6: 0.482029\n",
            "\n",
            "[epoch: 114/100000, batch: 336/1000, ite: 14167] train loss: 1.7628, accuracy: 92.5182%, tar: 0.0841 \n",
            "l0: 0.074213, l1: 0.075156, l2: 0.081772, l3: 0.096522, l4: 0.137330, l5: 0.235430, l6: 0.413732\n",
            "\n",
            "[epoch: 114/100000, batch: 344/1000, ite: 14168] train loss: 1.7615, accuracy: 92.3676%, tar: 0.0840 \n",
            "l0: 0.078574, l1: 0.080171, l2: 0.087655, l3: 0.110159, l4: 0.148039, l5: 0.234246, l6: 0.402762\n",
            "\n",
            "[epoch: 114/100000, batch: 352/1000, ite: 14169] train loss: 1.7601, accuracy: 93.6509%, tar: 0.0840 \n",
            "l0: 0.098354, l1: 0.099581, l2: 0.111089, l3: 0.134790, l4: 0.222837, l5: 0.408204, l6: 0.591534\n",
            "\n",
            "[epoch: 114/100000, batch: 360/1000, ite: 14170] train loss: 1.7631, accuracy: 91.1176%, tar: 0.0841 \n",
            "l0: 0.069010, l1: 0.069714, l2: 0.080699, l3: 0.111003, l4: 0.167960, l5: 0.243788, l6: 0.438768\n",
            "\n",
            "[epoch: 114/100000, batch: 368/1000, ite: 14171] train loss: 1.7624, accuracy: 93.3790%, tar: 0.0840 \n",
            "l0: 0.094481, l1: 0.095542, l2: 0.107059, l3: 0.133735, l4: 0.189918, l5: 0.317861, l6: 0.627662\n",
            "\n",
            "[epoch: 114/100000, batch: 376/1000, ite: 14172] train loss: 1.7649, accuracy: 90.5049%, tar: 0.0840 \n",
            "l0: 0.113645, l1: 0.114724, l2: 0.120792, l3: 0.149094, l4: 0.226021, l5: 0.347576, l6: 0.564265\n",
            "\n",
            "[epoch: 114/100000, batch: 384/1000, ite: 14173] train loss: 1.7675, accuracy: 90.2301%, tar: 0.0842 \n",
            "l0: 0.073242, l1: 0.073305, l2: 0.079010, l3: 0.096988, l4: 0.144593, l5: 0.241313, l6: 0.416726\n",
            "\n",
            "[epoch: 114/100000, batch: 392/1000, ite: 14174] train loss: 1.7662, accuracy: 92.8351%, tar: 0.0841 \n",
            "l0: 0.080877, l1: 0.080801, l2: 0.088337, l3: 0.102756, l4: 0.132577, l5: 0.191789, l6: 0.350669\n",
            "\n",
            "[epoch: 114/100000, batch: 400/1000, ite: 14175] train loss: 1.7640, accuracy: 93.1568%, tar: 0.0841 \n",
            "l0: 0.085916, l1: 0.086731, l2: 0.097275, l3: 0.121635, l4: 0.176140, l5: 0.284535, l6: 0.466653\n",
            "\n",
            "[epoch: 114/100000, batch: 408/1000, ite: 14176] train loss: 1.7642, accuracy: 92.5311%, tar: 0.0841 \n",
            "l0: 0.083325, l1: 0.084787, l2: 0.095687, l3: 0.122516, l4: 0.182236, l5: 0.300803, l6: 0.555297\n",
            "\n",
            "[epoch: 114/100000, batch: 416/1000, ite: 14177] train loss: 1.7655, accuracy: 90.6359%, tar: 0.0841 \n",
            "l0: 0.086006, l1: 0.087407, l2: 0.096237, l3: 0.120023, l4: 0.168629, l5: 0.234474, l6: 0.388264\n",
            "\n",
            "[epoch: 114/100000, batch: 424/1000, ite: 14178] train loss: 1.7645, accuracy: 93.3529%, tar: 0.0841 \n",
            "l0: 0.094569, l1: 0.096315, l2: 0.108975, l3: 0.133036, l4: 0.188773, l5: 0.285480, l6: 0.533397\n",
            "\n",
            "[epoch: 114/100000, batch: 432/1000, ite: 14179] train loss: 1.7656, accuracy: 91.9254%, tar: 0.0842 \n",
            "l0: 0.105983, l1: 0.107194, l2: 0.116733, l3: 0.142543, l4: 0.192494, l5: 0.276984, l6: 0.496443\n",
            "\n",
            "[epoch: 114/100000, batch: 440/1000, ite: 14180] train loss: 1.7665, accuracy: 92.5615%, tar: 0.0843 \n",
            "l0: 0.075258, l1: 0.077071, l2: 0.086064, l3: 0.104672, l4: 0.150190, l5: 0.224077, l6: 0.374711\n",
            "\n",
            "[epoch: 114/100000, batch: 448/1000, ite: 14181] train loss: 1.7649, accuracy: 93.6088%, tar: 0.0843 \n",
            "l0: 0.079353, l1: 0.080941, l2: 0.088277, l3: 0.112583, l4: 0.157346, l5: 0.244644, l6: 0.421885\n",
            "\n",
            "[epoch: 114/100000, batch: 456/1000, ite: 14182] train loss: 1.7641, accuracy: 93.8852%, tar: 0.0842 \n",
            "l0: 0.095232, l1: 0.096664, l2: 0.109707, l3: 0.149914, l4: 0.230820, l5: 0.355120, l6: 0.610503\n",
            "\n",
            "[epoch: 114/100000, batch: 464/1000, ite: 14183] train loss: 1.7668, accuracy: 91.4513%, tar: 0.0843 \n",
            "l0: 0.082265, l1: 0.083238, l2: 0.094392, l3: 0.124532, l4: 0.199369, l5: 0.341365, l6: 0.541583\n",
            "\n",
            "[epoch: 114/100000, batch: 472/1000, ite: 14184] train loss: 1.7681, accuracy: 91.9893%, tar: 0.0843 \n",
            "l0: 0.081527, l1: 0.082881, l2: 0.090832, l3: 0.112292, l4: 0.180502, l5: 0.308864, l6: 0.528494\n",
            "\n",
            "[epoch: 114/100000, batch: 480/1000, ite: 14185] train loss: 1.7689, accuracy: 91.9374%, tar: 0.0843 \n",
            "l0: 0.109118, l1: 0.109590, l2: 0.120940, l3: 0.146452, l4: 0.201011, l5: 0.344330, l6: 0.579095\n",
            "\n",
            "[epoch: 114/100000, batch: 488/1000, ite: 14186] train loss: 1.7712, accuracy: 89.9074%, tar: 0.0844 \n",
            "l0: 0.090023, l1: 0.091225, l2: 0.103703, l3: 0.130545, l4: 0.190943, l5: 0.312054, l6: 0.553929\n",
            "\n",
            "[epoch: 114/100000, batch: 496/1000, ite: 14187] train loss: 1.7727, accuracy: 91.2440%, tar: 0.0844 \n",
            "l0: 0.084815, l1: 0.089753, l2: 0.102124, l3: 0.141667, l4: 0.211293, l5: 0.324676, l6: 0.541353\n",
            "\n",
            "[epoch: 114/100000, batch: 504/1000, ite: 14188] train loss: 1.7741, accuracy: 92.9838%, tar: 0.0844 \n",
            "l0: 0.078947, l1: 0.078422, l2: 0.088198, l3: 0.116766, l4: 0.161759, l5: 0.240795, l6: 0.421719\n",
            "\n",
            "[epoch: 114/100000, batch: 512/1000, ite: 14189] train loss: 1.7732, accuracy: 92.9120%, tar: 0.0844 \n",
            "l0: 0.083202, l1: 0.084961, l2: 0.093881, l3: 0.123607, l4: 0.178666, l5: 0.261941, l6: 0.485246\n",
            "\n",
            "[epoch: 114/100000, batch: 520/1000, ite: 14190] train loss: 1.7733, accuracy: 93.1481%, tar: 0.0844 \n",
            "l0: 0.068230, l1: 0.069103, l2: 0.075275, l3: 0.093919, l4: 0.139796, l5: 0.248541, l6: 0.444092\n",
            "\n",
            "[epoch: 114/100000, batch: 528/1000, ite: 14191] train loss: 1.7723, accuracy: 92.5698%, tar: 0.0843 \n",
            "l0: 0.080513, l1: 0.081148, l2: 0.089479, l3: 0.114282, l4: 0.170461, l5: 0.275764, l6: 0.455545\n",
            "\n",
            "[epoch: 114/100000, batch: 536/1000, ite: 14192] train loss: 1.7721, accuracy: 93.3290%, tar: 0.0843 \n",
            "l0: 0.100455, l1: 0.100527, l2: 0.108387, l3: 0.132687, l4: 0.186214, l5: 0.271854, l6: 0.447232\n",
            "\n",
            "[epoch: 114/100000, batch: 544/1000, ite: 14193] train loss: 1.7723, accuracy: 92.5093%, tar: 0.0844 \n",
            "l0: 0.089471, l1: 0.090210, l2: 0.097241, l3: 0.112407, l4: 0.158634, l5: 0.269471, l6: 0.506329\n",
            "\n",
            "[epoch: 114/100000, batch: 552/1000, ite: 14194] train loss: 1.7726, accuracy: 91.3175%, tar: 0.0844 \n",
            "l0: 0.084556, l1: 0.084525, l2: 0.093924, l3: 0.121141, l4: 0.189251, l5: 0.333643, l6: 0.532154\n",
            "\n",
            "[epoch: 114/100000, batch: 560/1000, ite: 14195] train loss: 1.7737, accuracy: 90.5842%, tar: 0.0844 \n",
            "l0: 0.069434, l1: 0.069608, l2: 0.077294, l3: 0.098677, l4: 0.135757, l5: 0.253795, l6: 0.481824\n",
            "\n",
            "[epoch: 114/100000, batch: 568/1000, ite: 14196] train loss: 1.7731, accuracy: 91.8652%, tar: 0.0843 \n",
            "l0: 0.091139, l1: 0.092059, l2: 0.102247, l3: 0.121590, l4: 0.165562, l5: 0.240568, l6: 0.419980\n",
            "\n",
            "[epoch: 114/100000, batch: 576/1000, ite: 14197] train loss: 1.7724, accuracy: 92.0623%, tar: 0.0844 \n",
            "l0: 0.086858, l1: 0.088394, l2: 0.095730, l3: 0.113277, l4: 0.141442, l5: 0.238693, l6: 0.526987\n",
            "\n",
            "[epoch: 114/100000, batch: 584/1000, ite: 14198] train loss: 1.7728, accuracy: 91.9014%, tar: 0.0844 \n",
            "l0: 0.089017, l1: 0.090192, l2: 0.100103, l3: 0.121043, l4: 0.183637, l5: 0.278837, l6: 0.479452\n",
            "\n",
            "[epoch: 114/100000, batch: 592/1000, ite: 14199] train loss: 1.7731, accuracy: 92.5101%, tar: 0.0844 \n",
            "l0: 0.076495, l1: 0.077840, l2: 0.086291, l3: 0.107679, l4: 0.148337, l5: 0.226515, l6: 0.465902\n",
            "\n",
            "[epoch: 114/100000, batch: 600/1000, ite: 14200] train loss: 1.7724, accuracy: 92.2408%, tar: 0.0844 \n",
            "l0: 0.092742, l1: 0.094407, l2: 0.103131, l3: 0.129175, l4: 0.190289, l5: 0.300200, l6: 0.494902\n",
            "\n",
            "[epoch: 114/100000, batch: 608/1000, ite: 14201] train loss: 1.7731, accuracy: 92.1710%, tar: 0.0844 \n",
            "l0: 0.071284, l1: 0.072255, l2: 0.077055, l3: 0.100346, l4: 0.132778, l5: 0.236213, l6: 0.428002\n",
            "\n",
            "[epoch: 114/100000, batch: 616/1000, ite: 14202] train loss: 1.7719, accuracy: 92.6603%, tar: 0.0843 \n",
            "l0: 0.113260, l1: 0.113257, l2: 0.121327, l3: 0.146116, l4: 0.212701, l5: 0.363314, l6: 0.551154\n",
            "\n",
            "[epoch: 114/100000, batch: 624/1000, ite: 14203] train loss: 1.7739, accuracy: 91.1423%, tar: 0.0845 \n",
            "l0: 0.066880, l1: 0.067949, l2: 0.076014, l3: 0.091719, l4: 0.138874, l5: 0.205628, l6: 0.337092\n",
            "\n",
            "[epoch: 114/100000, batch: 632/1000, ite: 14204] train loss: 1.7717, accuracy: 94.5413%, tar: 0.0844 \n",
            "l0: 0.077114, l1: 0.078323, l2: 0.088200, l3: 0.112500, l4: 0.179601, l5: 0.317717, l6: 0.588723\n",
            "\n",
            "[epoch: 114/100000, batch: 640/1000, ite: 14205] train loss: 1.7730, accuracy: 91.5811%, tar: 0.0844 \n",
            "l0: 0.088656, l1: 0.090532, l2: 0.103500, l3: 0.129797, l4: 0.183433, l5: 0.304469, l6: 0.566540\n",
            "\n",
            "[epoch: 114/100000, batch: 648/1000, ite: 14206] train loss: 1.7742, accuracy: 90.7109%, tar: 0.0844 \n",
            "l0: 0.072715, l1: 0.073957, l2: 0.080189, l3: 0.095743, l4: 0.125044, l5: 0.211341, l6: 0.318995\n",
            "\n",
            "[epoch: 114/100000, batch: 656/1000, ite: 14207] train loss: 1.7719, accuracy: 93.5353%, tar: 0.0843 \n",
            "l0: 0.062422, l1: 0.063011, l2: 0.069068, l3: 0.088772, l4: 0.139074, l5: 0.212750, l6: 0.332966\n",
            "\n",
            "[epoch: 114/100000, batch: 664/1000, ite: 14208] train loss: 1.7696, accuracy: 94.2344%, tar: 0.0842 \n",
            "l0: 0.117937, l1: 0.119209, l2: 0.130396, l3: 0.155652, l4: 0.223780, l5: 0.348752, l6: 0.564593\n",
            "\n",
            "[epoch: 114/100000, batch: 672/1000, ite: 14209] train loss: 1.7718, accuracy: 90.2522%, tar: 0.0844 \n",
            "l0: 0.096985, l1: 0.097887, l2: 0.103709, l3: 0.126653, l4: 0.189105, l5: 0.286885, l6: 0.503839\n",
            "\n",
            "[epoch: 114/100000, batch: 680/1000, ite: 14210] train loss: 1.7725, accuracy: 92.5740%, tar: 0.0844 \n",
            "l0: 0.097079, l1: 0.098584, l2: 0.104964, l3: 0.123217, l4: 0.167895, l5: 0.265858, l6: 0.534778\n",
            "\n",
            "[epoch: 114/100000, batch: 688/1000, ite: 14211] train loss: 1.7733, accuracy: 91.4351%, tar: 0.0845 \n",
            "l0: 0.091281, l1: 0.093031, l2: 0.100448, l3: 0.126011, l4: 0.171098, l5: 0.277482, l6: 0.429443\n",
            "\n",
            "[epoch: 114/100000, batch: 696/1000, ite: 14212] train loss: 1.7730, accuracy: 91.7824%, tar: 0.0845 \n",
            "l0: 0.105549, l1: 0.106154, l2: 0.113916, l3: 0.136033, l4: 0.191325, l5: 0.345172, l6: 0.500630\n",
            "\n",
            "[epoch: 114/100000, batch: 704/1000, ite: 14213] train loss: 1.7741, accuracy: 91.2653%, tar: 0.0846 \n",
            "l0: 0.076608, l1: 0.078328, l2: 0.085776, l3: 0.103056, l4: 0.157867, l5: 0.281147, l6: 0.527676\n",
            "\n",
            "[epoch: 114/100000, batch: 712/1000, ite: 14214] train loss: 1.7743, accuracy: 91.5567%, tar: 0.0846 \n",
            "l0: 0.081421, l1: 0.082960, l2: 0.091093, l3: 0.112155, l4: 0.164546, l5: 0.282510, l6: 0.508512\n",
            "\n",
            "[epoch: 114/100000, batch: 720/1000, ite: 14215] train loss: 1.7746, accuracy: 92.0368%, tar: 0.0846 \n",
            "l0: 0.092546, l1: 0.094277, l2: 0.108550, l3: 0.137425, l4: 0.187926, l5: 0.315975, l6: 0.591118\n",
            "\n",
            "[epoch: 114/100000, batch: 728/1000, ite: 14216] train loss: 1.7763, accuracy: 90.1810%, tar: 0.0846 \n",
            "l0: 0.096266, l1: 0.104575, l2: 0.109606, l3: 0.122409, l4: 0.189646, l5: 0.321100, l6: 0.481392\n",
            "\n",
            "[epoch: 114/100000, batch: 736/1000, ite: 14217] train loss: 1.7769, accuracy: 93.1220%, tar: 0.0847 \n",
            "l0: 0.098776, l1: 0.099924, l2: 0.111599, l3: 0.140729, l4: 0.199297, l5: 0.327732, l6: 0.550514\n",
            "\n",
            "[epoch: 114/100000, batch: 744/1000, ite: 14218] train loss: 1.7783, accuracy: 91.2777%, tar: 0.0847 \n",
            "l0: 0.072297, l1: 0.073720, l2: 0.082922, l3: 0.109042, l4: 0.165222, l5: 0.283563, l6: 0.481258\n",
            "\n",
            "[epoch: 114/100000, batch: 752/1000, ite: 14219] train loss: 1.7782, accuracy: 92.2321%, tar: 0.0847 \n",
            "l0: 0.067930, l1: 0.068169, l2: 0.076414, l3: 0.100212, l4: 0.151993, l5: 0.260960, l6: 0.426420\n",
            "\n",
            "[epoch: 114/100000, batch: 760/1000, ite: 14220] train loss: 1.7773, accuracy: 93.5171%, tar: 0.0846 \n",
            "l0: 0.099498, l1: 0.100164, l2: 0.112117, l3: 0.137718, l4: 0.198225, l5: 0.285116, l6: 0.472147\n",
            "\n",
            "[epoch: 114/100000, batch: 768/1000, ite: 14221] train loss: 1.7777, accuracy: 92.6014%, tar: 0.0847 \n",
            "l0: 0.084075, l1: 0.085228, l2: 0.092394, l3: 0.114716, l4: 0.179527, l5: 0.286513, l6: 0.481654\n",
            "\n",
            "[epoch: 114/100000, batch: 776/1000, ite: 14222] train loss: 1.7779, accuracy: 92.5590%, tar: 0.0847 \n",
            "l0: 0.074467, l1: 0.075255, l2: 0.083737, l3: 0.109621, l4: 0.156530, l5: 0.246981, l6: 0.431127\n",
            "\n",
            "[epoch: 114/100000, batch: 784/1000, ite: 14223] train loss: 1.7772, accuracy: 92.2188%, tar: 0.0846 \n",
            "l0: 0.101061, l1: 0.102080, l2: 0.113543, l3: 0.139073, l4: 0.196779, l5: 0.277843, l6: 0.407212\n",
            "\n",
            "[epoch: 114/100000, batch: 792/1000, ite: 14224] train loss: 1.7771, accuracy: 91.8654%, tar: 0.0847 \n",
            "l0: 0.085114, l1: 0.085117, l2: 0.093610, l3: 0.116933, l4: 0.162917, l5: 0.240865, l6: 0.426574\n",
            "\n",
            "[epoch: 114/100000, batch: 800/1000, ite: 14225] train loss: 1.7766, accuracy: 92.1607%, tar: 0.0847 \n",
            "l0: 0.079737, l1: 0.080991, l2: 0.087547, l3: 0.104117, l4: 0.150981, l5: 0.229192, l6: 0.380802\n",
            "\n",
            "[epoch: 114/100000, batch: 808/1000, ite: 14226] train loss: 1.7753, accuracy: 93.5095%, tar: 0.0847 \n",
            "l0: 0.070877, l1: 0.071026, l2: 0.079961, l3: 0.104029, l4: 0.144368, l5: 0.243863, l6: 0.464040\n",
            "\n",
            "[epoch: 114/100000, batch: 816/1000, ite: 14227] train loss: 1.7747, accuracy: 92.2263%, tar: 0.0846 \n",
            "l0: 0.069435, l1: 0.069881, l2: 0.077558, l3: 0.093299, l4: 0.137059, l5: 0.249265, l6: 0.429578\n",
            "\n",
            "[epoch: 114/100000, batch: 824/1000, ite: 14228] train loss: 1.7738, accuracy: 92.5386%, tar: 0.0846 \n",
            "l0: 0.103181, l1: 0.104720, l2: 0.112171, l3: 0.137315, l4: 0.198176, l5: 0.326903, l6: 0.602536\n",
            "\n",
            "[epoch: 114/100000, batch: 832/1000, ite: 14229] train loss: 1.7755, accuracy: 89.8529%, tar: 0.0846 \n",
            "l0: 0.068617, l1: 0.069909, l2: 0.075575, l3: 0.096915, l4: 0.138940, l5: 0.218131, l6: 0.410857\n",
            "\n",
            "[epoch: 114/100000, batch: 840/1000, ite: 14230] train loss: 1.7744, accuracy: 92.7302%, tar: 0.0846 \n",
            "l0: 0.092156, l1: 0.094073, l2: 0.103090, l3: 0.122776, l4: 0.170447, l5: 0.261339, l6: 0.432649\n",
            "\n",
            "[epoch: 114/100000, batch: 848/1000, ite: 14231] train loss: 1.7741, accuracy: 92.6661%, tar: 0.0846 \n",
            "l0: 0.076749, l1: 0.078124, l2: 0.085789, l3: 0.103853, l4: 0.151260, l5: 0.229829, l6: 0.390911\n",
            "\n",
            "[epoch: 114/100000, batch: 856/1000, ite: 14232] train loss: 1.7730, accuracy: 93.4791%, tar: 0.0846 \n",
            "l0: 0.086760, l1: 0.087823, l2: 0.098899, l3: 0.121362, l4: 0.161331, l5: 0.229869, l6: 0.442195\n",
            "\n",
            "[epoch: 114/100000, batch: 864/1000, ite: 14233] train loss: 1.7726, accuracy: 92.5253%, tar: 0.0846 \n",
            "l0: 0.122356, l1: 0.122183, l2: 0.132645, l3: 0.154566, l4: 0.202971, l5: 0.299631, l6: 0.523853\n",
            "\n",
            "[epoch: 114/100000, batch: 872/1000, ite: 14234] train loss: 1.7740, accuracy: 90.9500%, tar: 0.0847 \n",
            "l0: 0.092448, l1: 0.093001, l2: 0.102573, l3: 0.127286, l4: 0.180841, l5: 0.320284, l6: 0.541499\n",
            "\n",
            "[epoch: 114/100000, batch: 880/1000, ite: 14235] train loss: 1.7750, accuracy: 90.7158%, tar: 0.0848 \n",
            "l0: 0.084768, l1: 0.085366, l2: 0.093554, l3: 0.114690, l4: 0.158591, l5: 0.241934, l6: 0.447462\n",
            "\n",
            "[epoch: 114/100000, batch: 888/1000, ite: 14236] train loss: 1.7746, accuracy: 92.9791%, tar: 0.0848 \n",
            "l0: 0.099100, l1: 0.099254, l2: 0.106552, l3: 0.118111, l4: 0.146461, l5: 0.218532, l6: 0.416795\n",
            "\n",
            "[epoch: 114/100000, batch: 896/1000, ite: 14237] train loss: 1.7739, accuracy: 92.6736%, tar: 0.0848 \n",
            "l0: 0.090476, l1: 0.091683, l2: 0.103326, l3: 0.133908, l4: 0.200256, l5: 0.323440, l6: 0.541314\n",
            "\n",
            "[epoch: 114/100000, batch: 904/1000, ite: 14238] train loss: 1.7750, accuracy: 90.8716%, tar: 0.0849 \n",
            "l0: 0.097185, l1: 0.097390, l2: 0.107440, l3: 0.133552, l4: 0.188707, l5: 0.294658, l6: 0.483899\n",
            "\n",
            "[epoch: 114/100000, batch: 912/1000, ite: 14239] train loss: 1.7755, accuracy: 91.7030%, tar: 0.0849 \n",
            "l0: 0.084664, l1: 0.085691, l2: 0.096482, l3: 0.123591, l4: 0.174297, l5: 0.271587, l6: 0.473403\n",
            "\n",
            "[epoch: 114/100000, batch: 920/1000, ite: 14240] train loss: 1.7755, accuracy: 92.6693%, tar: 0.0849 \n",
            "l0: 0.097423, l1: 0.098324, l2: 0.106706, l3: 0.130479, l4: 0.165915, l5: 0.248475, l6: 0.396830\n",
            "\n",
            "[epoch: 114/100000, batch: 928/1000, ite: 14241] train loss: 1.7750, accuracy: 92.6022%, tar: 0.0850 \n",
            "l0: 0.086586, l1: 0.087302, l2: 0.094428, l3: 0.103429, l4: 0.139783, l5: 0.215451, l6: 0.375652\n",
            "\n",
            "[epoch: 114/100000, batch: 936/1000, ite: 14242] train loss: 1.7738, accuracy: 92.8637%, tar: 0.0850 \n",
            "l0: 0.098681, l1: 0.101025, l2: 0.114160, l3: 0.138761, l4: 0.181646, l5: 0.307443, l6: 0.518718\n",
            "\n",
            "[epoch: 114/100000, batch: 944/1000, ite: 14243] train loss: 1.7746, accuracy: 91.4257%, tar: 0.0850 \n",
            "l0: 0.086440, l1: 0.088839, l2: 0.099932, l3: 0.118726, l4: 0.161486, l5: 0.285829, l6: 0.493022\n",
            "\n",
            "[epoch: 114/100000, batch: 952/1000, ite: 14244] train loss: 1.7749, accuracy: 92.6420%, tar: 0.0850 \n",
            "l0: 0.069474, l1: 0.070232, l2: 0.077954, l3: 0.097313, l4: 0.144660, l5: 0.226613, l6: 0.386162\n",
            "\n",
            "[epoch: 114/100000, batch: 960/1000, ite: 14245] train loss: 1.7736, accuracy: 94.0653%, tar: 0.0850 \n",
            "l0: 0.050109, l1: 0.050745, l2: 0.058683, l3: 0.079315, l4: 0.119440, l5: 0.214731, l6: 0.318207\n",
            "\n",
            "[epoch: 114/100000, batch: 968/1000, ite: 14246] train loss: 1.7714, accuracy: 94.0324%, tar: 0.0848 \n",
            "l0: 0.113163, l1: 0.115596, l2: 0.126716, l3: 0.152351, l4: 0.217966, l5: 0.338443, l6: 0.525754\n",
            "\n",
            "[epoch: 114/100000, batch: 976/1000, ite: 14247] train loss: 1.7727, accuracy: 91.2979%, tar: 0.0849 \n",
            "l0: 0.081060, l1: 0.082202, l2: 0.091959, l3: 0.116490, l4: 0.171120, l5: 0.264598, l6: 0.424612\n",
            "\n",
            "[epoch: 114/100000, batch: 984/1000, ite: 14248] train loss: 1.7722, accuracy: 92.9313%, tar: 0.0849 \n",
            "l0: 0.073132, l1: 0.074725, l2: 0.085844, l3: 0.113555, l4: 0.186078, l5: 0.306062, l6: 0.592867\n",
            "\n",
            "[epoch: 114/100000, batch: 992/1000, ite: 14249] train loss: 1.7732, accuracy: 92.1364%, tar: 0.0849 \n",
            "l0: 0.092061, l1: 0.092387, l2: 0.102128, l3: 0.124117, l4: 0.175741, l5: 0.296212, l6: 0.479263\n",
            "\n",
            "[epoch: 114/100000, batch: 1000/1000, ite: 14250] train loss: 1.7736, accuracy: 92.3293%, tar: 0.0849 \n",
            "l0: 0.084867, l1: 0.087883, l2: 0.101787, l3: 0.140489, l4: 0.220633, l5: 0.352655, l6: 0.563296\n",
            "\n",
            "[epoch: 115/100000, batch: 8/1000, ite: 14251] train loss: 1.7749, accuracy: 93.1570%, tar: 0.0849 \n",
            "l0: 0.089956, l1: 0.090203, l2: 0.101596, l3: 0.125997, l4: 0.187140, l5: 0.315197, l6: 0.577396\n",
            "\n",
            "[epoch: 115/100000, batch: 16/1000, ite: 14252] train loss: 1.7761, accuracy: 90.9466%, tar: 0.0849 \n",
            "l0: 0.091296, l1: 0.091838, l2: 0.102993, l3: 0.125417, l4: 0.177861, l5: 0.310130, l6: 0.501149\n",
            "\n",
            "[epoch: 115/100000, batch: 24/1000, ite: 14253] train loss: 1.7766, accuracy: 91.9061%, tar: 0.0849 \n",
            "l0: 0.084074, l1: 0.085321, l2: 0.097493, l3: 0.117102, l4: 0.172409, l5: 0.296969, l6: 0.485658\n",
            "\n",
            "[epoch: 115/100000, batch: 32/1000, ite: 14254] train loss: 1.7767, accuracy: 93.3771%, tar: 0.0849 \n",
            "l0: 0.094409, l1: 0.096045, l2: 0.106051, l3: 0.131656, l4: 0.185629, l5: 0.286835, l6: 0.585361\n",
            "\n",
            "[epoch: 115/100000, batch: 40/1000, ite: 14255] train loss: 1.7780, accuracy: 89.8317%, tar: 0.0850 \n",
            "l0: 0.067443, l1: 0.068397, l2: 0.077061, l3: 0.097000, l4: 0.134646, l5: 0.193019, l6: 0.391372\n",
            "\n",
            "[epoch: 115/100000, batch: 48/1000, ite: 14256] train loss: 1.7766, accuracy: 93.5409%, tar: 0.0849 \n",
            "l0: 0.073397, l1: 0.073362, l2: 0.080763, l3: 0.098541, l4: 0.131490, l5: 0.196433, l6: 0.350613\n",
            "\n",
            "[epoch: 115/100000, batch: 56/1000, ite: 14257] train loss: 1.7750, accuracy: 93.2472%, tar: 0.0849 \n",
            "l0: 0.067087, l1: 0.067979, l2: 0.073969, l3: 0.091386, l4: 0.131086, l5: 0.193784, l6: 0.350964\n",
            "\n",
            "[epoch: 115/100000, batch: 64/1000, ite: 14258] train loss: 1.7733, accuracy: 94.1876%, tar: 0.0848 \n",
            "l0: 0.081182, l1: 0.082381, l2: 0.092930, l3: 0.123901, l4: 0.180640, l5: 0.307371, l6: 0.513279\n",
            "\n",
            "[epoch: 115/100000, batch: 72/1000, ite: 14259] train loss: 1.7737, accuracy: 91.5939%, tar: 0.0848 \n",
            "l0: 0.077557, l1: 0.078529, l2: 0.087966, l3: 0.116194, l4: 0.171011, l5: 0.275332, l6: 0.486697\n",
            "\n",
            "[epoch: 115/100000, batch: 80/1000, ite: 14260] train loss: 1.7738, accuracy: 93.1528%, tar: 0.0848 \n",
            "l0: 0.083528, l1: 0.084049, l2: 0.092218, l3: 0.113826, l4: 0.157695, l5: 0.235683, l6: 0.415832\n",
            "\n",
            "[epoch: 115/100000, batch: 88/1000, ite: 14261] train loss: 1.7731, accuracy: 92.7126%, tar: 0.0847 \n",
            "l0: 0.061680, l1: 0.062478, l2: 0.070788, l3: 0.099079, l4: 0.147162, l5: 0.218906, l6: 0.438264\n",
            "\n",
            "[epoch: 115/100000, batch: 96/1000, ite: 14262] train loss: 1.7723, accuracy: 93.3678%, tar: 0.0847 \n",
            "l0: 0.085854, l1: 0.086637, l2: 0.101057, l3: 0.136670, l4: 0.216783, l5: 0.372852, l6: 0.590626\n",
            "\n",
            "[epoch: 115/100000, batch: 104/1000, ite: 14263] train loss: 1.7739, accuracy: 90.6320%, tar: 0.0847 \n",
            "l0: 0.072987, l1: 0.074646, l2: 0.083940, l3: 0.108316, l4: 0.167840, l5: 0.308578, l6: 0.531832\n",
            "\n",
            "[epoch: 115/100000, batch: 112/1000, ite: 14264] train loss: 1.7743, accuracy: 92.3269%, tar: 0.0846 \n",
            "l0: 0.069622, l1: 0.070383, l2: 0.077536, l3: 0.101382, l4: 0.155487, l5: 0.258065, l6: 0.435308\n",
            "\n",
            "[epoch: 115/100000, batch: 120/1000, ite: 14265] train loss: 1.7737, accuracy: 92.5270%, tar: 0.0846 \n",
            "l0: 0.083752, l1: 0.084892, l2: 0.091873, l3: 0.116605, l4: 0.170648, l5: 0.263545, l6: 0.440419\n",
            "\n",
            "[epoch: 115/100000, batch: 128/1000, ite: 14266] train loss: 1.7734, accuracy: 93.2863%, tar: 0.0846 \n",
            "l0: 0.098164, l1: 0.099072, l2: 0.110433, l3: 0.137579, l4: 0.193702, l5: 0.288062, l6: 0.475641\n",
            "\n",
            "[epoch: 115/100000, batch: 136/1000, ite: 14267] train loss: 1.7738, accuracy: 92.4768%, tar: 0.0846 \n",
            "l0: 0.088411, l1: 0.089769, l2: 0.102014, l3: 0.131638, l4: 0.189838, l5: 0.322676, l6: 0.528850\n",
            "\n",
            "[epoch: 115/100000, batch: 144/1000, ite: 14268] train loss: 1.7746, accuracy: 91.7604%, tar: 0.0846 \n",
            "l0: 0.085635, l1: 0.087053, l2: 0.097922, l3: 0.125513, l4: 0.177094, l5: 0.265813, l6: 0.478357\n",
            "\n",
            "[epoch: 115/100000, batch: 152/1000, ite: 14269] train loss: 1.7748, accuracy: 91.4182%, tar: 0.0846 \n",
            "l0: 0.067934, l1: 0.069453, l2: 0.077742, l3: 0.100211, l4: 0.132270, l5: 0.207195, l6: 0.339894\n",
            "\n",
            "[epoch: 115/100000, batch: 160/1000, ite: 14270] train loss: 1.7732, accuracy: 93.2679%, tar: 0.0846 \n",
            "l0: 0.070179, l1: 0.071592, l2: 0.077976, l3: 0.091476, l4: 0.122691, l5: 0.185337, l6: 0.302378\n",
            "\n",
            "[epoch: 115/100000, batch: 168/1000, ite: 14271] train loss: 1.7711, accuracy: 93.7153%, tar: 0.0845 \n",
            "l0: 0.081849, l1: 0.081929, l2: 0.089901, l3: 0.110917, l4: 0.164052, l5: 0.245590, l6: 0.427306\n",
            "\n",
            "[epoch: 115/100000, batch: 176/1000, ite: 14272] train loss: 1.7706, accuracy: 92.4549%, tar: 0.0845 \n",
            "l0: 0.083189, l1: 0.084842, l2: 0.089534, l3: 0.111502, l4: 0.146875, l5: 0.277365, l6: 0.467827\n",
            "\n",
            "[epoch: 115/100000, batch: 184/1000, ite: 14273] train loss: 1.7705, accuracy: 91.7548%, tar: 0.0845 \n",
            "l0: 0.062307, l1: 0.063536, l2: 0.073994, l3: 0.104224, l4: 0.171841, l5: 0.277344, l6: 0.449770\n",
            "\n",
            "[epoch: 115/100000, batch: 192/1000, ite: 14274] train loss: 1.7701, accuracy: 92.7520%, tar: 0.0844 \n",
            "l0: 0.120397, l1: 0.120424, l2: 0.127849, l3: 0.149431, l4: 0.202450, l5: 0.312894, l6: 0.569553\n",
            "\n",
            "[epoch: 115/100000, batch: 200/1000, ite: 14275] train loss: 1.7716, accuracy: 90.6580%, tar: 0.0846 \n",
            "l0: 0.100062, l1: 0.100043, l2: 0.109003, l3: 0.136484, l4: 0.209418, l5: 0.344070, l6: 0.543877\n",
            "\n",
            "[epoch: 115/100000, batch: 208/1000, ite: 14276] train loss: 1.7728, accuracy: 91.0135%, tar: 0.0846 \n",
            "l0: 0.091373, l1: 0.091661, l2: 0.103580, l3: 0.131151, l4: 0.184815, l5: 0.303898, l6: 0.522997\n",
            "\n",
            "[epoch: 115/100000, batch: 216/1000, ite: 14277] train loss: 1.7735, accuracy: 90.5914%, tar: 0.0846 \n",
            "l0: 0.099636, l1: 0.101342, l2: 0.111288, l3: 0.132652, l4: 0.184309, l5: 0.278768, l6: 0.493277\n",
            "\n",
            "[epoch: 115/100000, batch: 224/1000, ite: 14278] train loss: 1.7739, accuracy: 91.4986%, tar: 0.0847 \n",
            "l0: 0.078129, l1: 0.079034, l2: 0.084923, l3: 0.107784, l4: 0.158325, l5: 0.242274, l6: 0.424341\n",
            "\n",
            "[epoch: 115/100000, batch: 232/1000, ite: 14279] train loss: 1.7733, accuracy: 92.4289%, tar: 0.0847 \n",
            "l0: 0.083237, l1: 0.085036, l2: 0.093071, l3: 0.123502, l4: 0.162142, l5: 0.298302, l6: 0.468826\n",
            "\n",
            "[epoch: 115/100000, batch: 240/1000, ite: 14280] train loss: 1.7733, accuracy: 92.9117%, tar: 0.0847 \n",
            "l0: 0.077536, l1: 0.078931, l2: 0.088876, l3: 0.111037, l4: 0.155939, l5: 0.254892, l6: 0.429807\n",
            "\n",
            "[epoch: 115/100000, batch: 248/1000, ite: 14281] train loss: 1.7728, accuracy: 92.8552%, tar: 0.0846 \n",
            "l0: 0.069083, l1: 0.070432, l2: 0.080364, l3: 0.101008, l4: 0.154936, l5: 0.287331, l6: 0.496417\n",
            "\n",
            "[epoch: 115/100000, batch: 256/1000, ite: 14282] train loss: 1.7727, accuracy: 92.7627%, tar: 0.0846 \n",
            "l0: 0.092826, l1: 0.093293, l2: 0.103763, l3: 0.128248, l4: 0.188441, l5: 0.303376, l6: 0.537721\n",
            "\n",
            "[epoch: 115/100000, batch: 264/1000, ite: 14283] train loss: 1.7735, accuracy: 91.0106%, tar: 0.0846 \n",
            "l0: 0.077309, l1: 0.078035, l2: 0.087321, l3: 0.115759, l4: 0.165461, l5: 0.275327, l6: 0.435269\n",
            "\n",
            "[epoch: 115/100000, batch: 272/1000, ite: 14284] train loss: 1.7731, accuracy: 92.9633%, tar: 0.0846 \n",
            "l0: 0.084344, l1: 0.084578, l2: 0.091217, l3: 0.105193, l4: 0.135945, l5: 0.207633, l6: 0.375332\n",
            "\n",
            "[epoch: 115/100000, batch: 280/1000, ite: 14285] train loss: 1.7720, accuracy: 93.2402%, tar: 0.0846 \n",
            "l0: 0.073017, l1: 0.073768, l2: 0.084611, l3: 0.111502, l4: 0.177723, l5: 0.287779, l6: 0.525166\n",
            "\n",
            "[epoch: 115/100000, batch: 288/1000, ite: 14286] train loss: 1.7723, accuracy: 92.4445%, tar: 0.0845 \n",
            "l0: 0.089913, l1: 0.090633, l2: 0.099663, l3: 0.123502, l4: 0.173439, l5: 0.270852, l6: 0.435027\n",
            "\n",
            "[epoch: 115/100000, batch: 296/1000, ite: 14287] train loss: 1.7722, accuracy: 92.5105%, tar: 0.0846 \n",
            "l0: 0.092058, l1: 0.093638, l2: 0.101704, l3: 0.118179, l4: 0.164924, l5: 0.252640, l6: 0.395482\n",
            "\n",
            "[epoch: 115/100000, batch: 304/1000, ite: 14288] train loss: 1.7717, accuracy: 93.4811%, tar: 0.0846 \n",
            "l0: 0.079971, l1: 0.081232, l2: 0.090684, l3: 0.111820, l4: 0.159948, l5: 0.249705, l6: 0.440409\n",
            "\n",
            "[epoch: 115/100000, batch: 312/1000, ite: 14289] train loss: 1.7713, accuracy: 92.5789%, tar: 0.0846 \n",
            "l0: 0.084211, l1: 0.085403, l2: 0.097976, l3: 0.124932, l4: 0.178675, l5: 0.266959, l6: 0.485809\n",
            "\n",
            "[epoch: 115/100000, batch: 320/1000, ite: 14290] train loss: 1.7715, accuracy: 92.2441%, tar: 0.0846 \n",
            "l0: 0.068587, l1: 0.068917, l2: 0.074971, l3: 0.092634, l4: 0.128262, l5: 0.200615, l6: 0.332286\n",
            "\n",
            "[epoch: 115/100000, batch: 328/1000, ite: 14291] train loss: 1.7699, accuracy: 94.4374%, tar: 0.0845 \n",
            "l0: 0.106393, l1: 0.106198, l2: 0.121460, l3: 0.149604, l4: 0.239526, l5: 0.442579, l6: 0.759419\n",
            "\n",
            "[epoch: 115/100000, batch: 336/1000, ite: 14292] train loss: 1.7730, accuracy: 89.0199%, tar: 0.0846 \n",
            "l0: 0.118526, l1: 0.120346, l2: 0.132664, l3: 0.153840, l4: 0.220349, l5: 0.359507, l6: 0.522917\n",
            "\n",
            "[epoch: 115/100000, batch: 344/1000, ite: 14293] train loss: 1.7743, accuracy: 91.5688%, tar: 0.0847 \n",
            "l0: 0.075683, l1: 0.076295, l2: 0.085145, l3: 0.108291, l4: 0.153571, l5: 0.246903, l6: 0.425447\n",
            "\n",
            "[epoch: 115/100000, batch: 352/1000, ite: 14294] train loss: 1.7737, accuracy: 92.7555%, tar: 0.0847 \n",
            "l0: 0.108558, l1: 0.109576, l2: 0.119584, l3: 0.144423, l4: 0.190707, l5: 0.273470, l6: 0.448045\n",
            "\n",
            "[epoch: 115/100000, batch: 360/1000, ite: 14295] train loss: 1.7740, accuracy: 91.4889%, tar: 0.0848 \n",
            "l0: 0.095339, l1: 0.095168, l2: 0.103350, l3: 0.125032, l4: 0.175961, l5: 0.297866, l6: 0.518603\n",
            "\n",
            "[epoch: 115/100000, batch: 368/1000, ite: 14296] train loss: 1.7744, accuracy: 91.8957%, tar: 0.0848 \n",
            "l0: 0.068623, l1: 0.069370, l2: 0.079231, l3: 0.102440, l4: 0.149578, l5: 0.284977, l6: 0.517396\n",
            "\n",
            "[epoch: 115/100000, batch: 376/1000, ite: 14297] train loss: 1.7745, accuracy: 92.7042%, tar: 0.0847 \n",
            "l0: 0.095254, l1: 0.096900, l2: 0.106653, l3: 0.127786, l4: 0.166801, l5: 0.280603, l6: 0.482234\n",
            "\n",
            "[epoch: 115/100000, batch: 384/1000, ite: 14298] train loss: 1.7747, accuracy: 91.2493%, tar: 0.0848 \n",
            "l0: 0.048576, l1: 0.049274, l2: 0.053552, l3: 0.069383, l4: 0.100351, l5: 0.154519, l6: 0.300339\n",
            "\n",
            "[epoch: 115/100000, batch: 392/1000, ite: 14299] train loss: 1.7724, accuracy: 94.1122%, tar: 0.0846 \n",
            "l0: 0.082380, l1: 0.083392, l2: 0.091628, l3: 0.104903, l4: 0.142137, l5: 0.218918, l6: 0.401495\n",
            "\n",
            "[epoch: 115/100000, batch: 400/1000, ite: 14300] train loss: 1.7715, accuracy: 92.7243%, tar: 0.0846 \n",
            "l0: 0.099160, l1: 0.099825, l2: 0.105701, l3: 0.122314, l4: 0.159730, l5: 0.217021, l6: 0.352663\n",
            "\n",
            "[epoch: 115/100000, batch: 408/1000, ite: 14301] train loss: 1.7706, accuracy: 93.0102%, tar: 0.0847 \n",
            "l0: 0.080934, l1: 0.081737, l2: 0.091679, l3: 0.118057, l4: 0.180054, l5: 0.287961, l6: 0.512526\n",
            "\n",
            "[epoch: 115/100000, batch: 416/1000, ite: 14302] train loss: 1.7710, accuracy: 91.6306%, tar: 0.0847 \n",
            "l0: 0.093947, l1: 0.094711, l2: 0.103626, l3: 0.131411, l4: 0.204322, l5: 0.316085, l6: 0.534786\n",
            "\n",
            "[epoch: 115/100000, batch: 424/1000, ite: 14303] train loss: 1.7718, accuracy: 92.0674%, tar: 0.0847 \n",
            "l0: 0.068328, l1: 0.069549, l2: 0.074179, l3: 0.090674, l4: 0.127122, l5: 0.193349, l6: 0.400305\n",
            "\n",
            "[epoch: 115/100000, batch: 432/1000, ite: 14304] train loss: 1.7706, accuracy: 93.4973%, tar: 0.0847 \n",
            "l0: 0.100507, l1: 0.103248, l2: 0.112684, l3: 0.138576, l4: 0.205395, l5: 0.325597, l6: 0.470263\n",
            "\n",
            "[epoch: 115/100000, batch: 440/1000, ite: 14305] train loss: 1.7712, accuracy: 91.6983%, tar: 0.0847 \n",
            "l0: 0.077026, l1: 0.076846, l2: 0.083997, l3: 0.105739, l4: 0.148891, l5: 0.245088, l6: 0.380482\n",
            "\n",
            "[epoch: 115/100000, batch: 448/1000, ite: 14306] train loss: 1.7703, accuracy: 93.6568%, tar: 0.0847 \n",
            "l0: 0.073804, l1: 0.074464, l2: 0.083390, l3: 0.101299, l4: 0.145799, l5: 0.246639, l6: 0.486690\n",
            "\n",
            "[epoch: 115/100000, batch: 456/1000, ite: 14307] train loss: 1.7700, accuracy: 91.7205%, tar: 0.0846 \n",
            "l0: 0.085582, l1: 0.086415, l2: 0.096649, l3: 0.115802, l4: 0.153367, l5: 0.248523, l6: 0.411050\n",
            "\n",
            "[epoch: 115/100000, batch: 464/1000, ite: 14308] train loss: 1.7695, accuracy: 91.8739%, tar: 0.0846 \n",
            "l0: 0.073792, l1: 0.075225, l2: 0.082822, l3: 0.108720, l4: 0.176342, l5: 0.236876, l6: 0.383668\n",
            "\n",
            "[epoch: 115/100000, batch: 472/1000, ite: 14309] train loss: 1.7687, accuracy: 94.1481%, tar: 0.0846 \n",
            "l0: 0.083240, l1: 0.084596, l2: 0.094866, l3: 0.119690, l4: 0.180225, l5: 0.332754, l6: 0.602357\n",
            "\n",
            "[epoch: 115/100000, batch: 480/1000, ite: 14310] train loss: 1.7698, accuracy: 90.9362%, tar: 0.0846 \n",
            "l0: 0.080906, l1: 0.081217, l2: 0.087379, l3: 0.109407, l4: 0.154273, l5: 0.261691, l6: 0.476752\n",
            "\n",
            "[epoch: 115/100000, batch: 488/1000, ite: 14311] train loss: 1.7696, accuracy: 91.8305%, tar: 0.0846 \n",
            "l0: 0.117268, l1: 0.118131, l2: 0.128512, l3: 0.159301, l4: 0.219244, l5: 0.321602, l6: 0.562241\n",
            "\n",
            "[epoch: 115/100000, batch: 496/1000, ite: 14312] train loss: 1.7710, accuracy: 91.5612%, tar: 0.0847 \n",
            "l0: 0.062567, l1: 0.063601, l2: 0.072482, l3: 0.094484, l4: 0.136985, l5: 0.238945, l6: 0.467483\n",
            "\n",
            "[epoch: 115/100000, batch: 504/1000, ite: 14313] train loss: 1.7705, accuracy: 92.8433%, tar: 0.0846 \n",
            "l0: 0.086241, l1: 0.087029, l2: 0.095647, l3: 0.115820, l4: 0.168969, l5: 0.275053, l6: 0.519949\n",
            "\n",
            "[epoch: 115/100000, batch: 512/1000, ite: 14314] train loss: 1.7708, accuracy: 92.3619%, tar: 0.0846 \n",
            "l0: 0.085904, l1: 0.087018, l2: 0.099059, l3: 0.133692, l4: 0.192993, l5: 0.308469, l6: 0.497963\n",
            "\n",
            "[epoch: 115/100000, batch: 520/1000, ite: 14315] train loss: 1.7713, accuracy: 92.1131%, tar: 0.0846 \n",
            "l0: 0.094114, l1: 0.095625, l2: 0.105796, l3: 0.127055, l4: 0.174912, l5: 0.268388, l6: 0.434135\n",
            "\n",
            "[epoch: 115/100000, batch: 528/1000, ite: 14316] train loss: 1.7711, accuracy: 92.0699%, tar: 0.0847 \n",
            "l0: 0.075703, l1: 0.077724, l2: 0.088911, l3: 0.113809, l4: 0.164709, l5: 0.266470, l6: 0.432562\n",
            "\n",
            "[epoch: 115/100000, batch: 536/1000, ite: 14317] train loss: 1.7708, accuracy: 92.5592%, tar: 0.0846 \n",
            "l0: 0.097144, l1: 0.098493, l2: 0.109293, l3: 0.139014, l4: 0.208827, l5: 0.332387, l6: 0.546049\n",
            "\n",
            "[epoch: 115/100000, batch: 544/1000, ite: 14318] train loss: 1.7718, accuracy: 89.8914%, tar: 0.0847 \n",
            "l0: 0.099281, l1: 0.100215, l2: 0.109132, l3: 0.125796, l4: 0.160476, l5: 0.251307, l6: 0.451812\n",
            "\n",
            "[epoch: 115/100000, batch: 552/1000, ite: 14319] train loss: 1.7716, accuracy: 92.9563%, tar: 0.0847 \n",
            "l0: 0.069985, l1: 0.071332, l2: 0.078323, l3: 0.096573, l4: 0.139915, l5: 0.206230, l6: 0.368227\n",
            "\n",
            "[epoch: 115/100000, batch: 560/1000, ite: 14320] train loss: 1.7705, accuracy: 92.8880%, tar: 0.0847 \n",
            "l0: 0.065795, l1: 0.066431, l2: 0.075223, l3: 0.093007, l4: 0.135025, l5: 0.225628, l6: 0.415942\n",
            "\n",
            "[epoch: 115/100000, batch: 568/1000, ite: 14321] train loss: 1.7696, accuracy: 92.2605%, tar: 0.0846 \n",
            "l0: 0.060023, l1: 0.060852, l2: 0.069568, l3: 0.089434, l4: 0.131223, l5: 0.237539, l6: 0.427002\n",
            "\n",
            "[epoch: 115/100000, batch: 576/1000, ite: 14322] train loss: 1.7688, accuracy: 93.4897%, tar: 0.0845 \n",
            "l0: 0.086461, l1: 0.087598, l2: 0.097612, l3: 0.121019, l4: 0.177966, l5: 0.323852, l6: 0.527491\n",
            "\n",
            "[epoch: 115/100000, batch: 584/1000, ite: 14323] train loss: 1.7694, accuracy: 91.8389%, tar: 0.0846 \n",
            "l0: 0.066627, l1: 0.066562, l2: 0.072422, l3: 0.084618, l4: 0.107407, l5: 0.164937, l6: 0.293370\n",
            "\n",
            "[epoch: 115/100000, batch: 592/1000, ite: 14324] train loss: 1.7675, accuracy: 94.6654%, tar: 0.0845 \n",
            "l0: 0.069166, l1: 0.069297, l2: 0.076004, l3: 0.092639, l4: 0.142783, l5: 0.235708, l6: 0.426658\n",
            "\n",
            "[epoch: 115/100000, batch: 600/1000, ite: 14325] train loss: 1.7668, accuracy: 92.6935%, tar: 0.0844 \n",
            "l0: 0.112019, l1: 0.113419, l2: 0.123470, l3: 0.148735, l4: 0.208848, l5: 0.308668, l6: 0.499016\n",
            "\n",
            "[epoch: 115/100000, batch: 608/1000, ite: 14326] train loss: 1.7676, accuracy: 92.5186%, tar: 0.0845 \n",
            "l0: 0.082280, l1: 0.083720, l2: 0.093875, l3: 0.124692, l4: 0.186699, l5: 0.294821, l6: 0.558708\n",
            "\n",
            "[epoch: 115/100000, batch: 616/1000, ite: 14327] train loss: 1.7683, accuracy: 90.5693%, tar: 0.0845 \n",
            "l0: 0.085522, l1: 0.086230, l2: 0.097403, l3: 0.129701, l4: 0.197486, l5: 0.329885, l6: 0.556452\n",
            "\n",
            "[epoch: 115/100000, batch: 624/1000, ite: 14328] train loss: 1.7692, accuracy: 91.6230%, tar: 0.0845 \n",
            "l0: 0.056345, l1: 0.057831, l2: 0.066420, l3: 0.086553, l4: 0.129198, l5: 0.205768, l6: 0.342854\n",
            "\n",
            "[epoch: 115/100000, batch: 632/1000, ite: 14329] train loss: 1.7677, accuracy: 94.0934%, tar: 0.0844 \n",
            "l0: 0.073667, l1: 0.074522, l2: 0.085295, l3: 0.112040, l4: 0.173591, l5: 0.263256, l6: 0.462195\n",
            "\n",
            "[epoch: 115/100000, batch: 640/1000, ite: 14330] train loss: 1.7675, accuracy: 92.8392%, tar: 0.0844 \n",
            "l0: 0.103672, l1: 0.105594, l2: 0.115403, l3: 0.128479, l4: 0.161693, l5: 0.258416, l6: 0.445212\n",
            "\n",
            "[epoch: 115/100000, batch: 648/1000, ite: 14331] train loss: 1.7675, accuracy: 92.5785%, tar: 0.0845 \n",
            "l0: 0.061738, l1: 0.062558, l2: 0.069746, l3: 0.090134, l4: 0.135673, l5: 0.224757, l6: 0.428043\n",
            "\n",
            "[epoch: 115/100000, batch: 656/1000, ite: 14332] train loss: 1.7668, accuracy: 92.0870%, tar: 0.0844 \n",
            "l0: 0.076389, l1: 0.077300, l2: 0.088174, l3: 0.111185, l4: 0.170791, l5: 0.298626, l6: 0.518015\n",
            "\n",
            "[epoch: 115/100000, batch: 664/1000, ite: 14333] train loss: 1.7671, accuracy: 91.1329%, tar: 0.0844 \n",
            "l0: 0.057865, l1: 0.058804, l2: 0.067529, l3: 0.089796, l4: 0.138467, l5: 0.221842, l6: 0.420234\n",
            "\n",
            "[epoch: 115/100000, batch: 672/1000, ite: 14334] train loss: 1.7662, accuracy: 94.0233%, tar: 0.0843 \n",
            "l0: 0.133181, l1: 0.134914, l2: 0.149001, l3: 0.173999, l4: 0.255737, l5: 0.384013, l6: 0.595442\n",
            "\n",
            "[epoch: 115/100000, batch: 680/1000, ite: 14335] train loss: 1.7682, accuracy: 89.8267%, tar: 0.0844 \n",
            "l0: 0.071040, l1: 0.072696, l2: 0.081252, l3: 0.102229, l4: 0.140651, l5: 0.229129, l6: 0.420580\n",
            "\n",
            "[epoch: 115/100000, batch: 688/1000, ite: 14336] train loss: 1.7676, accuracy: 93.5529%, tar: 0.0844 \n",
            "l0: 0.091516, l1: 0.093041, l2: 0.102086, l3: 0.123352, l4: 0.164717, l5: 0.258459, l6: 0.464832\n",
            "\n",
            "[epoch: 115/100000, batch: 696/1000, ite: 14337] train loss: 1.7676, accuracy: 91.5146%, tar: 0.0844 \n",
            "l0: 0.082767, l1: 0.083692, l2: 0.095630, l3: 0.122108, l4: 0.176900, l5: 0.279387, l6: 0.493782\n",
            "\n",
            "[epoch: 115/100000, batch: 704/1000, ite: 14338] train loss: 1.7678, accuracy: 91.6879%, tar: 0.0844 \n",
            "l0: 0.069586, l1: 0.070150, l2: 0.082799, l3: 0.108282, l4: 0.155193, l5: 0.236698, l6: 0.421980\n",
            "\n",
            "[epoch: 115/100000, batch: 712/1000, ite: 14339] train loss: 1.7672, accuracy: 93.3350%, tar: 0.0844 \n",
            "l0: 0.070722, l1: 0.073251, l2: 0.082967, l3: 0.108214, l4: 0.178318, l5: 0.273049, l6: 0.414370\n",
            "\n",
            "[epoch: 115/100000, batch: 720/1000, ite: 14340] train loss: 1.7668, accuracy: 92.5744%, tar: 0.0843 \n",
            "l0: 0.071113, l1: 0.072543, l2: 0.079591, l3: 0.100184, l4: 0.148467, l5: 0.223955, l6: 0.400313\n",
            "\n",
            "[epoch: 115/100000, batch: 728/1000, ite: 14341] train loss: 1.7660, accuracy: 93.4661%, tar: 0.0843 \n",
            "l0: 0.070346, l1: 0.071369, l2: 0.077209, l3: 0.095160, l4: 0.141249, l5: 0.233731, l6: 0.406306\n",
            "\n",
            "[epoch: 115/100000, batch: 736/1000, ite: 14342] train loss: 1.7653, accuracy: 93.4877%, tar: 0.0843 \n",
            "l0: 0.069494, l1: 0.070485, l2: 0.078072, l3: 0.100820, l4: 0.146005, l5: 0.228161, l6: 0.399443\n",
            "\n",
            "[epoch: 115/100000, batch: 744/1000, ite: 14343] train loss: 1.7645, accuracy: 93.6139%, tar: 0.0842 \n",
            "l0: 0.096242, l1: 0.097867, l2: 0.108643, l3: 0.131157, l4: 0.162596, l5: 0.261286, l6: 0.472746\n",
            "\n",
            "[epoch: 115/100000, batch: 752/1000, ite: 14344] train loss: 1.7646, accuracy: 92.3908%, tar: 0.0842 \n",
            "l0: 0.062030, l1: 0.064433, l2: 0.074095, l3: 0.092581, l4: 0.131864, l5: 0.209150, l6: 0.351169\n",
            "\n",
            "[epoch: 115/100000, batch: 760/1000, ite: 14345] train loss: 1.7634, accuracy: 94.2454%, tar: 0.0842 \n",
            "l0: 0.068922, l1: 0.070346, l2: 0.076698, l3: 0.096796, l4: 0.151044, l5: 0.236580, l6: 0.441393\n",
            "\n",
            "[epoch: 115/100000, batch: 768/1000, ite: 14346] train loss: 1.7629, accuracy: 93.4462%, tar: 0.0841 \n",
            "l0: 0.086037, l1: 0.087406, l2: 0.095575, l3: 0.115515, l4: 0.165626, l5: 0.254119, l6: 0.413734\n",
            "\n",
            "[epoch: 115/100000, batch: 776/1000, ite: 14347] train loss: 1.7625, accuracy: 92.8834%, tar: 0.0841 \n",
            "l0: 0.067629, l1: 0.067745, l2: 0.077434, l3: 0.096064, l4: 0.137805, l5: 0.217538, l6: 0.430239\n",
            "\n",
            "[epoch: 115/100000, batch: 784/1000, ite: 14348] train loss: 1.7618, accuracy: 92.3741%, tar: 0.0841 \n",
            "l0: 0.106394, l1: 0.106983, l2: 0.117071, l3: 0.137442, l4: 0.189041, l5: 0.310590, l6: 0.531208\n",
            "\n",
            "[epoch: 115/100000, batch: 792/1000, ite: 14349] train loss: 1.7626, accuracy: 91.9103%, tar: 0.0842 \n",
            "l0: 0.082647, l1: 0.083475, l2: 0.091195, l3: 0.110664, l4: 0.164335, l5: 0.285188, l6: 0.524171\n",
            "\n",
            "[epoch: 115/100000, batch: 800/1000, ite: 14350] train loss: 1.7630, accuracy: 92.2942%, tar: 0.0842 \n",
            "l0: 0.082496, l1: 0.083975, l2: 0.091949, l3: 0.111982, l4: 0.152161, l5: 0.236800, l6: 0.388960\n",
            "\n",
            "[epoch: 115/100000, batch: 808/1000, ite: 14351] train loss: 1.7623, accuracy: 92.7694%, tar: 0.0842 \n",
            "l0: 0.080118, l1: 0.079833, l2: 0.090195, l3: 0.109005, l4: 0.151163, l5: 0.258675, l6: 0.477454\n",
            "\n",
            "[epoch: 115/100000, batch: 816/1000, ite: 14352] train loss: 1.7622, accuracy: 91.4137%, tar: 0.0841 \n",
            "l0: 0.073985, l1: 0.074455, l2: 0.084057, l3: 0.108123, l4: 0.155128, l5: 0.271699, l6: 0.527700\n",
            "\n",
            "[epoch: 115/100000, batch: 824/1000, ite: 14353] train loss: 1.7625, accuracy: 92.5234%, tar: 0.0841 \n",
            "l0: 0.095244, l1: 0.096685, l2: 0.105435, l3: 0.133592, l4: 0.178992, l5: 0.270897, l6: 0.462389\n",
            "\n",
            "[epoch: 115/100000, batch: 832/1000, ite: 14354] train loss: 1.7626, accuracy: 92.1879%, tar: 0.0841 \n",
            "l0: 0.069194, l1: 0.070387, l2: 0.074915, l3: 0.086518, l4: 0.127037, l5: 0.233173, l6: 0.423304\n",
            "\n",
            "[epoch: 115/100000, batch: 840/1000, ite: 14355] train loss: 1.7619, accuracy: 93.1941%, tar: 0.0841 \n",
            "l0: 0.083664, l1: 0.084389, l2: 0.091913, l3: 0.114550, l4: 0.158617, l5: 0.288600, l6: 0.441042\n",
            "\n",
            "[epoch: 115/100000, batch: 848/1000, ite: 14356] train loss: 1.7618, accuracy: 92.4685%, tar: 0.0841 \n",
            "l0: 0.081611, l1: 0.082080, l2: 0.093872, l3: 0.120111, l4: 0.194464, l5: 0.377985, l6: 0.634321\n",
            "\n",
            "[epoch: 115/100000, batch: 856/1000, ite: 14357] train loss: 1.7630, accuracy: 91.6309%, tar: 0.0841 \n",
            "l0: 0.072845, l1: 0.075520, l2: 0.083933, l3: 0.108062, l4: 0.171035, l5: 0.268013, l6: 0.483505\n",
            "\n",
            "[epoch: 115/100000, batch: 864/1000, ite: 14358] train loss: 1.7630, accuracy: 92.3208%, tar: 0.0841 \n",
            "l0: 0.094525, l1: 0.096451, l2: 0.104687, l3: 0.128186, l4: 0.193563, l5: 0.330732, l6: 0.537408\n",
            "\n",
            "[epoch: 115/100000, batch: 872/1000, ite: 14359] train loss: 1.7637, accuracy: 91.7272%, tar: 0.0841 \n",
            "l0: 0.066176, l1: 0.066360, l2: 0.071170, l3: 0.087906, l4: 0.116223, l5: 0.174185, l6: 0.291160\n",
            "\n",
            "[epoch: 115/100000, batch: 880/1000, ite: 14360] train loss: 1.7620, accuracy: 94.3659%, tar: 0.0840 \n",
            "l0: 0.071427, l1: 0.072711, l2: 0.084403, l3: 0.113288, l4: 0.180499, l5: 0.327264, l6: 0.514626\n",
            "\n",
            "[epoch: 115/100000, batch: 888/1000, ite: 14361] train loss: 1.7624, accuracy: 93.0992%, tar: 0.0840 \n",
            "l0: 0.104605, l1: 0.105482, l2: 0.114104, l3: 0.135323, l4: 0.189203, l5: 0.314036, l6: 0.573416\n",
            "\n",
            "[epoch: 115/100000, batch: 896/1000, ite: 14362] train loss: 1.7634, accuracy: 89.7139%, tar: 0.0841 \n",
            "l0: 0.135449, l1: 0.137414, l2: 0.152373, l3: 0.186072, l4: 0.262560, l5: 0.395307, l6: 0.716254\n",
            "\n",
            "[epoch: 115/100000, batch: 904/1000, ite: 14363] train loss: 1.7660, accuracy: 90.4512%, tar: 0.0842 \n",
            "l0: 0.069581, l1: 0.069913, l2: 0.080183, l3: 0.105297, l4: 0.169435, l5: 0.273766, l6: 0.446296\n",
            "\n",
            "[epoch: 115/100000, batch: 912/1000, ite: 14364] train loss: 1.7656, accuracy: 94.2406%, tar: 0.0842 \n",
            "l0: 0.106421, l1: 0.107386, l2: 0.116975, l3: 0.146343, l4: 0.217730, l5: 0.352849, l6: 0.607786\n",
            "\n",
            "[epoch: 115/100000, batch: 920/1000, ite: 14365] train loss: 1.7671, accuracy: 89.3850%, tar: 0.0842 \n",
            "l0: 0.071832, l1: 0.073419, l2: 0.080659, l3: 0.103849, l4: 0.158218, l5: 0.263416, l6: 0.502529\n",
            "\n",
            "[epoch: 115/100000, batch: 928/1000, ite: 14366] train loss: 1.7671, accuracy: 92.1893%, tar: 0.0842 \n",
            "l0: 0.083764, l1: 0.084331, l2: 0.092186, l3: 0.114255, l4: 0.144855, l5: 0.221264, l6: 0.448303\n",
            "\n",
            "[epoch: 115/100000, batch: 936/1000, ite: 14367] train loss: 1.7667, accuracy: 92.4587%, tar: 0.0842 \n",
            "l0: 0.062640, l1: 0.063729, l2: 0.073467, l3: 0.093873, l4: 0.145950, l5: 0.223642, l6: 0.351388\n",
            "\n",
            "[epoch: 115/100000, batch: 944/1000, ite: 14368] train loss: 1.7656, accuracy: 93.4960%, tar: 0.0841 \n",
            "l0: 0.062817, l1: 0.064299, l2: 0.072954, l3: 0.090802, l4: 0.132533, l5: 0.216961, l6: 0.430131\n",
            "\n",
            "[epoch: 115/100000, batch: 952/1000, ite: 14369] train loss: 1.7649, accuracy: 93.3082%, tar: 0.0841 \n",
            "l0: 0.083872, l1: 0.085822, l2: 0.092438, l3: 0.113845, l4: 0.171285, l5: 0.255148, l6: 0.452382\n",
            "\n",
            "[epoch: 115/100000, batch: 960/1000, ite: 14370] train loss: 1.7648, accuracy: 93.3161%, tar: 0.0841 \n",
            "l0: 0.079538, l1: 0.080966, l2: 0.088349, l3: 0.109287, l4: 0.155405, l5: 0.238720, l6: 0.375341\n",
            "\n",
            "[epoch: 115/100000, batch: 968/1000, ite: 14371] train loss: 1.7640, accuracy: 93.4753%, tar: 0.0841 \n",
            "l0: 0.075281, l1: 0.077152, l2: 0.087335, l3: 0.120254, l4: 0.198941, l5: 0.267491, l6: 0.429198\n",
            "\n",
            "[epoch: 115/100000, batch: 976/1000, ite: 14372] train loss: 1.7638, accuracy: 93.5911%, tar: 0.0840 \n",
            "l0: 0.079441, l1: 0.081444, l2: 0.091168, l3: 0.111969, l4: 0.164164, l5: 0.246983, l6: 0.445287\n",
            "\n",
            "[epoch: 115/100000, batch: 984/1000, ite: 14373] train loss: 1.7636, accuracy: 92.3952%, tar: 0.0840 \n",
            "l0: 0.072604, l1: 0.073766, l2: 0.082933, l3: 0.102748, l4: 0.151822, l5: 0.268683, l6: 0.488047\n",
            "\n",
            "[epoch: 115/100000, batch: 992/1000, ite: 14374] train loss: 1.7635, accuracy: 91.8863%, tar: 0.0840 \n",
            "l0: 0.077557, l1: 0.079182, l2: 0.087368, l3: 0.111077, l4: 0.174418, l5: 0.265374, l6: 0.454351\n",
            "\n",
            "[epoch: 115/100000, batch: 1000/1000, ite: 14375] train loss: 1.7633, accuracy: 93.3968%, tar: 0.0840 \n",
            "l0: 0.064911, l1: 0.065172, l2: 0.075000, l3: 0.102473, l4: 0.165782, l5: 0.268584, l6: 0.433046\n",
            "\n",
            "[epoch: 116/100000, batch: 8/1000, ite: 14376] train loss: 1.7629, accuracy: 92.3559%, tar: 0.0839 \n",
            "l0: 0.066981, l1: 0.068724, l2: 0.076300, l3: 0.099826, l4: 0.144742, l5: 0.222360, l6: 0.429617\n",
            "\n",
            "[epoch: 116/100000, batch: 16/1000, ite: 14377] train loss: 1.7623, accuracy: 93.0733%, tar: 0.0839 \n",
            "l0: 0.063275, l1: 0.063746, l2: 0.072715, l3: 0.089003, l4: 0.120538, l5: 0.205062, l6: 0.400145\n",
            "\n",
            "[epoch: 116/100000, batch: 24/1000, ite: 14378] train loss: 1.7613, accuracy: 93.1676%, tar: 0.0838 \n",
            "l0: 0.073460, l1: 0.074273, l2: 0.085113, l3: 0.106653, l4: 0.165066, l5: 0.309633, l6: 0.526814\n",
            "\n",
            "[epoch: 116/100000, batch: 32/1000, ite: 14379] train loss: 1.7616, accuracy: 91.2905%, tar: 0.0838 \n",
            "l0: 0.077455, l1: 0.077955, l2: 0.087221, l3: 0.111150, l4: 0.159722, l5: 0.263888, l6: 0.471129\n",
            "\n",
            "[epoch: 116/100000, batch: 40/1000, ite: 14380] train loss: 1.7615, accuracy: 92.6375%, tar: 0.0838 \n",
            "l0: 0.072738, l1: 0.073316, l2: 0.080700, l3: 0.100219, l4: 0.135654, l5: 0.202201, l6: 0.308145\n",
            "\n",
            "[epoch: 116/100000, batch: 48/1000, ite: 14381] train loss: 1.7603, accuracy: 93.7305%, tar: 0.0838 \n",
            "l0: 0.064060, l1: 0.064571, l2: 0.074604, l3: 0.099977, l4: 0.148665, l5: 0.234554, l6: 0.409733\n",
            "\n",
            "[epoch: 116/100000, batch: 56/1000, ite: 14382] train loss: 1.7596, accuracy: 93.9868%, tar: 0.0837 \n",
            "l0: 0.082723, l1: 0.084306, l2: 0.093853, l3: 0.119907, l4: 0.174775, l5: 0.262188, l6: 0.433040\n",
            "\n",
            "[epoch: 116/100000, batch: 64/1000, ite: 14383] train loss: 1.7594, accuracy: 92.9935%, tar: 0.0837 \n",
            "l0: 0.071453, l1: 0.072239, l2: 0.079067, l3: 0.093487, l4: 0.127493, l5: 0.227674, l6: 0.444772\n",
            "\n",
            "[epoch: 116/100000, batch: 72/1000, ite: 14384] train loss: 1.7589, accuracy: 94.4632%, tar: 0.0837 \n",
            "l0: 0.083285, l1: 0.085973, l2: 0.096628, l3: 0.125726, l4: 0.187496, l5: 0.337682, l6: 0.614670\n",
            "\n",
            "[epoch: 116/100000, batch: 80/1000, ite: 14385] train loss: 1.7599, accuracy: 90.2855%, tar: 0.0837 \n",
            "l0: 0.079084, l1: 0.080147, l2: 0.094805, l3: 0.123877, l4: 0.198901, l5: 0.342208, l6: 0.562711\n",
            "\n",
            "[epoch: 116/100000, batch: 88/1000, ite: 14386] train loss: 1.7607, accuracy: 90.8814%, tar: 0.0837 \n",
            "l0: 0.063213, l1: 0.064973, l2: 0.074119, l3: 0.093061, l4: 0.141946, l5: 0.232763, l6: 0.456260\n",
            "\n",
            "[epoch: 116/100000, batch: 96/1000, ite: 14387] train loss: 1.7602, accuracy: 92.9085%, tar: 0.0836 \n",
            "l0: 0.075884, l1: 0.078305, l2: 0.085242, l3: 0.102870, l4: 0.147034, l5: 0.245681, l6: 0.449968\n",
            "\n",
            "[epoch: 116/100000, batch: 104/1000, ite: 14388] train loss: 1.7599, accuracy: 93.3760%, tar: 0.0836 \n",
            "l0: 0.084039, l1: 0.084647, l2: 0.093507, l3: 0.114021, l4: 0.163022, l5: 0.260696, l6: 0.473192\n",
            "\n",
            "[epoch: 116/100000, batch: 112/1000, ite: 14389] train loss: 1.7599, accuracy: 92.5563%, tar: 0.0836 \n",
            "l0: 0.084928, l1: 0.085940, l2: 0.094534, l3: 0.112726, l4: 0.160988, l5: 0.269110, l6: 0.466160\n",
            "\n",
            "[epoch: 116/100000, batch: 120/1000, ite: 14390] train loss: 1.7598, accuracy: 92.1790%, tar: 0.0836 \n",
            "l0: 0.110803, l1: 0.113101, l2: 0.124782, l3: 0.159312, l4: 0.245416, l5: 0.380477, l6: 0.586805\n",
            "\n",
            "[epoch: 116/100000, batch: 128/1000, ite: 14391] train loss: 1.7613, accuracy: 90.9556%, tar: 0.0837 \n",
            "l0: 0.078478, l1: 0.078737, l2: 0.087024, l3: 0.108926, l4: 0.158370, l5: 0.269510, l6: 0.552659\n",
            "\n",
            "[epoch: 116/100000, batch: 136/1000, ite: 14392] train loss: 1.7616, accuracy: 91.2399%, tar: 0.0836 \n",
            "l0: 0.067897, l1: 0.068668, l2: 0.077918, l3: 0.106995, l4: 0.169975, l5: 0.329564, l6: 0.546183\n",
            "\n",
            "[epoch: 116/100000, batch: 144/1000, ite: 14393] train loss: 1.7620, accuracy: 92.9313%, tar: 0.0836 \n",
            "l0: 0.080590, l1: 0.080699, l2: 0.088345, l3: 0.108145, l4: 0.157352, l5: 0.264258, l6: 0.369791\n",
            "\n",
            "[epoch: 116/100000, batch: 152/1000, ite: 14394] train loss: 1.7614, accuracy: 93.5161%, tar: 0.0836 \n",
            "l0: 0.068734, l1: 0.069513, l2: 0.076433, l3: 0.095942, l4: 0.130040, l5: 0.226444, l6: 0.451877\n",
            "\n",
            "[epoch: 116/100000, batch: 160/1000, ite: 14395] train loss: 1.7609, accuracy: 93.4060%, tar: 0.0836 \n",
            "l0: 0.072046, l1: 0.072496, l2: 0.081684, l3: 0.101759, l4: 0.155451, l5: 0.233784, l6: 0.373637\n",
            "\n",
            "[epoch: 116/100000, batch: 168/1000, ite: 14396] train loss: 1.7602, accuracy: 92.5479%, tar: 0.0835 \n",
            "l0: 0.062387, l1: 0.063014, l2: 0.072994, l3: 0.098960, l4: 0.137367, l5: 0.230652, l6: 0.418014\n",
            "\n",
            "[epoch: 116/100000, batch: 176/1000, ite: 14397] train loss: 1.7595, accuracy: 93.7675%, tar: 0.0835 \n",
            "l0: 0.078379, l1: 0.078918, l2: 0.086027, l3: 0.101449, l4: 0.138804, l5: 0.221712, l6: 0.417939\n",
            "\n",
            "[epoch: 116/100000, batch: 184/1000, ite: 14398] train loss: 1.7590, accuracy: 92.8975%, tar: 0.0835 \n",
            "l0: 0.080337, l1: 0.081042, l2: 0.091986, l3: 0.118193, l4: 0.180308, l5: 0.337726, l6: 0.497281\n",
            "\n",
            "[epoch: 116/100000, batch: 192/1000, ite: 14399] train loss: 1.7594, accuracy: 91.6807%, tar: 0.0835 \n",
            "l0: 0.060174, l1: 0.062007, l2: 0.069533, l3: 0.083866, l4: 0.116645, l5: 0.181622, l6: 0.315645\n",
            "\n",
            "[epoch: 116/100000, batch: 200/1000, ite: 14400] train loss: 1.7580, accuracy: 94.6409%, tar: 0.0834 \n",
            "l0: 0.093936, l1: 0.093927, l2: 0.106753, l3: 0.133082, l4: 0.197577, l5: 0.358118, l6: 0.556772\n",
            "\n",
            "[epoch: 116/100000, batch: 208/1000, ite: 14401] train loss: 1.7588, accuracy: 90.9041%, tar: 0.0834 \n",
            "l0: 0.076729, l1: 0.077153, l2: 0.087572, l3: 0.117179, l4: 0.188647, l5: 0.310855, l6: 0.533185\n",
            "\n",
            "[epoch: 116/100000, batch: 216/1000, ite: 14402] train loss: 1.7592, accuracy: 92.4057%, tar: 0.0834 \n",
            "l0: 0.099959, l1: 0.100893, l2: 0.109804, l3: 0.134193, l4: 0.199825, l5: 0.288921, l6: 0.480801\n",
            "\n",
            "[epoch: 116/100000, batch: 224/1000, ite: 14403] train loss: 1.7596, accuracy: 92.8295%, tar: 0.0834 \n",
            "l0: 0.088028, l1: 0.088975, l2: 0.100698, l3: 0.127055, l4: 0.188023, l5: 0.303658, l6: 0.535754\n",
            "\n",
            "[epoch: 116/100000, batch: 232/1000, ite: 14404] train loss: 1.7601, accuracy: 91.0807%, tar: 0.0835 \n",
            "l0: 0.086515, l1: 0.087431, l2: 0.096667, l3: 0.120264, l4: 0.160921, l5: 0.284432, l6: 0.484906\n",
            "\n",
            "[epoch: 116/100000, batch: 240/1000, ite: 14405] train loss: 1.7603, accuracy: 93.2245%, tar: 0.0835 \n",
            "l0: 0.075855, l1: 0.076663, l2: 0.085203, l3: 0.103757, l4: 0.135198, l5: 0.227882, l6: 0.446513\n",
            "\n",
            "[epoch: 116/100000, batch: 248/1000, ite: 14406] train loss: 1.7599, accuracy: 92.2813%, tar: 0.0834 \n",
            "l0: 0.106531, l1: 0.107728, l2: 0.120628, l3: 0.153044, l4: 0.213600, l5: 0.369417, l6: 0.604091\n",
            "\n",
            "[epoch: 116/100000, batch: 256/1000, ite: 14407] train loss: 1.7612, accuracy: 90.6427%, tar: 0.0835 \n",
            "l0: 0.054444, l1: 0.055249, l2: 0.062333, l3: 0.076865, l4: 0.111296, l5: 0.191382, l6: 0.324615\n",
            "\n",
            "[epoch: 116/100000, batch: 264/1000, ite: 14408] train loss: 1.7599, accuracy: 94.7580%, tar: 0.0834 \n",
            "l0: 0.081566, l1: 0.081266, l2: 0.089620, l3: 0.109858, l4: 0.147232, l5: 0.242997, l6: 0.449992\n",
            "\n",
            "[epoch: 116/100000, batch: 272/1000, ite: 14409] train loss: 1.7596, accuracy: 91.9071%, tar: 0.0834 \n",
            "l0: 0.085929, l1: 0.086758, l2: 0.096875, l3: 0.111395, l4: 0.145296, l5: 0.223693, l6: 0.354445\n",
            "\n",
            "[epoch: 116/100000, batch: 280/1000, ite: 14410] train loss: 1.7589, accuracy: 92.8446%, tar: 0.0834 \n",
            "l0: 0.104795, l1: 0.105847, l2: 0.118333, l3: 0.141424, l4: 0.186006, l5: 0.276665, l6: 0.543962\n",
            "\n",
            "[epoch: 116/100000, batch: 288/1000, ite: 14411] train loss: 1.7596, accuracy: 91.0935%, tar: 0.0835 \n",
            "l0: 0.052881, l1: 0.054762, l2: 0.064031, l3: 0.084374, l4: 0.117941, l5: 0.177034, l6: 0.307861\n",
            "\n",
            "[epoch: 116/100000, batch: 296/1000, ite: 14412] train loss: 1.7581, accuracy: 94.2093%, tar: 0.0834 \n",
            "l0: 0.077239, l1: 0.077961, l2: 0.086545, l3: 0.110125, l4: 0.173442, l5: 0.288500, l6: 0.500596\n",
            "\n",
            "[epoch: 116/100000, batch: 304/1000, ite: 14413] train loss: 1.7583, accuracy: 92.6526%, tar: 0.0834 \n",
            "l0: 0.089407, l1: 0.090365, l2: 0.099093, l3: 0.126620, l4: 0.184751, l5: 0.308041, l6: 0.506074\n",
            "\n",
            "[epoch: 116/100000, batch: 312/1000, ite: 14414] train loss: 1.7587, accuracy: 92.2191%, tar: 0.0834 \n",
            "l0: 0.086684, l1: 0.088071, l2: 0.097527, l3: 0.124327, l4: 0.166981, l5: 0.266250, l6: 0.450861\n",
            "\n",
            "[epoch: 116/100000, batch: 320/1000, ite: 14415] train loss: 1.7587, accuracy: 93.0009%, tar: 0.0834 \n",
            "l0: 0.073445, l1: 0.074674, l2: 0.083969, l3: 0.107802, l4: 0.158293, l5: 0.248510, l6: 0.409248\n",
            "\n",
            "[epoch: 116/100000, batch: 328/1000, ite: 14416] train loss: 1.7582, accuracy: 92.9690%, tar: 0.0834 \n",
            "l0: 0.077835, l1: 0.079931, l2: 0.089977, l3: 0.107868, l4: 0.147447, l5: 0.225944, l6: 0.397632\n",
            "\n",
            "[epoch: 116/100000, batch: 336/1000, ite: 14417] train loss: 1.7577, accuracy: 93.2736%, tar: 0.0834 \n",
            "l0: 0.086090, l1: 0.086620, l2: 0.094161, l3: 0.106596, l4: 0.145727, l5: 0.243504, l6: 0.429034\n",
            "\n",
            "[epoch: 116/100000, batch: 344/1000, ite: 14418] train loss: 1.7573, accuracy: 93.4154%, tar: 0.0834 \n",
            "l0: 0.083639, l1: 0.084461, l2: 0.094966, l3: 0.121452, l4: 0.171632, l5: 0.278260, l6: 0.499138\n",
            "\n",
            "[epoch: 116/100000, batch: 352/1000, ite: 14419] train loss: 1.7576, accuracy: 91.4868%, tar: 0.0834 \n",
            "l0: 0.076675, l1: 0.078257, l2: 0.088031, l3: 0.111022, l4: 0.162523, l5: 0.282361, l6: 0.530058\n",
            "\n",
            "[epoch: 116/100000, batch: 360/1000, ite: 14420] train loss: 1.7578, accuracy: 91.1795%, tar: 0.0834 \n",
            "l0: 0.049522, l1: 0.050239, l2: 0.058847, l3: 0.076304, l4: 0.114683, l5: 0.194549, l6: 0.330554\n",
            "\n",
            "[epoch: 116/100000, batch: 368/1000, ite: 14421] train loss: 1.7565, accuracy: 94.5963%, tar: 0.0833 \n",
            "l0: 0.054216, l1: 0.054863, l2: 0.061515, l3: 0.077646, l4: 0.120833, l5: 0.202093, l6: 0.396278\n",
            "\n",
            "[epoch: 116/100000, batch: 376/1000, ite: 14422] train loss: 1.7555, accuracy: 93.1844%, tar: 0.0832 \n",
            "l0: 0.102393, l1: 0.103904, l2: 0.115696, l3: 0.142393, l4: 0.202613, l5: 0.346528, l6: 0.585809\n",
            "\n",
            "[epoch: 116/100000, batch: 384/1000, ite: 14423] train loss: 1.7565, accuracy: 91.5078%, tar: 0.0833 \n",
            "l0: 0.069595, l1: 0.070173, l2: 0.080233, l3: 0.104957, l4: 0.153929, l5: 0.258111, l6: 0.476222\n",
            "\n",
            "[epoch: 116/100000, batch: 392/1000, ite: 14424] train loss: 1.7564, accuracy: 93.2914%, tar: 0.0832 \n",
            "l0: 0.064699, l1: 0.064836, l2: 0.072068, l3: 0.087140, l4: 0.122581, l5: 0.218640, l6: 0.379688\n",
            "\n",
            "[epoch: 116/100000, batch: 400/1000, ite: 14425] train loss: 1.7555, accuracy: 92.9351%, tar: 0.0832 \n",
            "l0: 0.073334, l1: 0.074286, l2: 0.084439, l3: 0.110061, l4: 0.151872, l5: 0.258486, l6: 0.449441\n",
            "\n",
            "[epoch: 116/100000, batch: 408/1000, ite: 14426] train loss: 1.7553, accuracy: 92.9852%, tar: 0.0832 \n",
            "l0: 0.115151, l1: 0.116538, l2: 0.123212, l3: 0.155248, l4: 0.228154, l5: 0.341587, l6: 0.503159\n",
            "\n",
            "[epoch: 116/100000, batch: 416/1000, ite: 14427] train loss: 1.7561, accuracy: 92.2698%, tar: 0.0832 \n",
            "l0: 0.079924, l1: 0.080708, l2: 0.089278, l3: 0.109163, l4: 0.155849, l5: 0.236703, l6: 0.420981\n",
            "\n",
            "[epoch: 116/100000, batch: 424/1000, ite: 14428] train loss: 1.7557, accuracy: 92.8678%, tar: 0.0832 \n",
            "l0: 0.066448, l1: 0.066674, l2: 0.075605, l3: 0.096712, l4: 0.131463, l5: 0.216364, l6: 0.381550\n",
            "\n",
            "[epoch: 116/100000, batch: 432/1000, ite: 14429] train loss: 1.7549, accuracy: 93.2696%, tar: 0.0832 \n",
            "l0: 0.088120, l1: 0.088773, l2: 0.097076, l3: 0.116647, l4: 0.160442, l5: 0.253078, l6: 0.441032\n",
            "\n",
            "[epoch: 116/100000, batch: 440/1000, ite: 14430] train loss: 1.7548, accuracy: 92.0266%, tar: 0.0832 \n",
            "l0: 0.066643, l1: 0.068503, l2: 0.078792, l3: 0.102382, l4: 0.162410, l5: 0.292597, l6: 0.507532\n",
            "\n",
            "[epoch: 116/100000, batch: 448/1000, ite: 14431] train loss: 1.7549, accuracy: 92.2497%, tar: 0.0832 \n",
            "l0: 0.101934, l1: 0.101734, l2: 0.108987, l3: 0.127008, l4: 0.174368, l5: 0.268362, l6: 0.493784\n",
            "\n",
            "[epoch: 116/100000, batch: 456/1000, ite: 14432] train loss: 1.7551, accuracy: 92.0555%, tar: 0.0832 \n",
            "l0: 0.082361, l1: 0.082970, l2: 0.087776, l3: 0.103689, l4: 0.153254, l5: 0.233590, l6: 0.352374\n",
            "\n",
            "[epoch: 116/100000, batch: 464/1000, ite: 14433] train loss: 1.7544, accuracy: 93.4934%, tar: 0.0832 \n",
            "l0: 0.062425, l1: 0.062814, l2: 0.071371, l3: 0.087499, l4: 0.124486, l5: 0.212853, l6: 0.354645\n",
            "\n",
            "[epoch: 116/100000, batch: 472/1000, ite: 14434] train loss: 1.7535, accuracy: 94.1947%, tar: 0.0832 \n",
            "l0: 0.081420, l1: 0.082900, l2: 0.093360, l3: 0.120570, l4: 0.172861, l5: 0.265227, l6: 0.494920\n",
            "\n",
            "[epoch: 116/100000, batch: 480/1000, ite: 14435] train loss: 1.7537, accuracy: 91.9017%, tar: 0.0832 \n",
            "l0: 0.075307, l1: 0.075887, l2: 0.085171, l3: 0.110148, l4: 0.170681, l5: 0.243390, l6: 0.403772\n",
            "\n",
            "[epoch: 116/100000, batch: 488/1000, ite: 14436] train loss: 1.7532, accuracy: 92.8148%, tar: 0.0831 \n",
            "l0: 0.079794, l1: 0.081080, l2: 0.089113, l3: 0.108302, l4: 0.147964, l5: 0.225494, l6: 0.442780\n",
            "\n",
            "[epoch: 116/100000, batch: 496/1000, ite: 14437] train loss: 1.7529, accuracy: 92.4053%, tar: 0.0831 \n",
            "l0: 0.080062, l1: 0.081746, l2: 0.092882, l3: 0.117394, l4: 0.169654, l5: 0.254208, l6: 0.464228\n",
            "\n",
            "[epoch: 116/100000, batch: 504/1000, ite: 14438] train loss: 1.7529, accuracy: 92.5260%, tar: 0.0831 \n",
            "l0: 0.082649, l1: 0.083969, l2: 0.094563, l3: 0.110725, l4: 0.161498, l5: 0.275417, l6: 0.522945\n",
            "\n",
            "[epoch: 116/100000, batch: 512/1000, ite: 14439] train loss: 1.7531, accuracy: 91.2921%, tar: 0.0831 \n",
            "l0: 0.077888, l1: 0.079259, l2: 0.085917, l3: 0.100942, l4: 0.142189, l5: 0.227789, l6: 0.389674\n",
            "\n",
            "[epoch: 116/100000, batch: 520/1000, ite: 14440] train loss: 1.7525, accuracy: 92.4011%, tar: 0.0831 \n",
            "l0: 0.102710, l1: 0.104358, l2: 0.113249, l3: 0.137971, l4: 0.197318, l5: 0.323058, l6: 0.548122\n",
            "\n",
            "[epoch: 116/100000, batch: 528/1000, ite: 14441] train loss: 1.7532, accuracy: 91.2153%, tar: 0.0832 \n",
            "l0: 0.071409, l1: 0.072941, l2: 0.081140, l3: 0.107941, l4: 0.147615, l5: 0.235649, l6: 0.361242\n",
            "\n",
            "[epoch: 116/100000, batch: 536/1000, ite: 14442] train loss: 1.7525, accuracy: 92.6182%, tar: 0.0831 \n",
            "l0: 0.074791, l1: 0.076635, l2: 0.084620, l3: 0.108332, l4: 0.156958, l5: 0.233838, l6: 0.474781\n",
            "\n",
            "[epoch: 116/100000, batch: 544/1000, ite: 14443] train loss: 1.7523, accuracy: 91.9150%, tar: 0.0831 \n",
            "l0: 0.120527, l1: 0.122549, l2: 0.131123, l3: 0.158944, l4: 0.219608, l5: 0.326892, l6: 0.562110\n",
            "\n",
            "[epoch: 116/100000, batch: 552/1000, ite: 14444] train loss: 1.7534, accuracy: 90.7984%, tar: 0.0832 \n",
            "l0: 0.073549, l1: 0.073958, l2: 0.083111, l3: 0.103447, l4: 0.157068, l5: 0.252029, l6: 0.480286\n",
            "\n",
            "[epoch: 116/100000, batch: 560/1000, ite: 14445] train loss: 1.7533, accuracy: 93.1342%, tar: 0.0832 \n",
            "l0: 0.086527, l1: 0.088538, l2: 0.100231, l3: 0.129081, l4: 0.191978, l5: 0.294657, l6: 0.491874\n",
            "\n",
            "[epoch: 116/100000, batch: 568/1000, ite: 14446] train loss: 1.7536, accuracy: 92.3797%, tar: 0.0832 \n",
            "l0: 0.095609, l1: 0.096525, l2: 0.103618, l3: 0.119377, l4: 0.153062, l5: 0.258222, l6: 0.417270\n",
            "\n",
            "[epoch: 116/100000, batch: 576/1000, ite: 14447] train loss: 1.7534, accuracy: 93.7347%, tar: 0.0832 \n",
            "l0: 0.078777, l1: 0.080158, l2: 0.085890, l3: 0.105071, l4: 0.137972, l5: 0.200278, l6: 0.359249\n",
            "\n",
            "[epoch: 116/100000, batch: 584/1000, ite: 14448] train loss: 1.7526, accuracy: 93.2466%, tar: 0.0832 \n",
            "l0: 0.070218, l1: 0.071161, l2: 0.078535, l3: 0.094862, l4: 0.130623, l5: 0.212350, l6: 0.406214\n",
            "\n",
            "[epoch: 116/100000, batch: 592/1000, ite: 14449] train loss: 1.7520, accuracy: 93.3562%, tar: 0.0832 \n",
            "l0: 0.086216, l1: 0.087151, l2: 0.096575, l3: 0.115732, l4: 0.155570, l5: 0.264744, l6: 0.491198\n",
            "\n",
            "[epoch: 116/100000, batch: 600/1000, ite: 14450] train loss: 1.7521, accuracy: 91.1719%, tar: 0.0832 \n",
            "l0: 0.097424, l1: 0.099023, l2: 0.108494, l3: 0.130014, l4: 0.197808, l5: 0.331506, l6: 0.570869\n",
            "\n",
            "[epoch: 116/100000, batch: 608/1000, ite: 14451] train loss: 1.7529, accuracy: 91.1504%, tar: 0.0832 \n",
            "l0: 0.074523, l1: 0.075495, l2: 0.084561, l3: 0.104063, l4: 0.156986, l5: 0.246680, l6: 0.430705\n",
            "\n",
            "[epoch: 116/100000, batch: 616/1000, ite: 14452] train loss: 1.7526, accuracy: 92.2609%, tar: 0.0832 \n",
            "l0: 0.083288, l1: 0.084812, l2: 0.094254, l3: 0.121802, l4: 0.181214, l5: 0.285895, l6: 0.494002\n",
            "\n",
            "[epoch: 116/100000, batch: 624/1000, ite: 14453] train loss: 1.7528, accuracy: 92.7980%, tar: 0.0832 \n",
            "l0: 0.099822, l1: 0.100396, l2: 0.114730, l3: 0.145354, l4: 0.208582, l5: 0.363687, l6: 0.581405\n",
            "\n",
            "[epoch: 116/100000, batch: 632/1000, ite: 14454] train loss: 1.7538, accuracy: 91.3447%, tar: 0.0832 \n",
            "l0: 0.072436, l1: 0.073576, l2: 0.082939, l3: 0.106131, l4: 0.149779, l5: 0.255053, l6: 0.474344\n",
            "\n",
            "[epoch: 116/100000, batch: 640/1000, ite: 14455] train loss: 1.7537, accuracy: 92.8167%, tar: 0.0832 \n",
            "l0: 0.083348, l1: 0.084602, l2: 0.095471, l3: 0.121849, l4: 0.176988, l5: 0.311524, l6: 0.502356\n",
            "\n",
            "[epoch: 116/100000, batch: 648/1000, ite: 14456] train loss: 1.7540, accuracy: 92.1873%, tar: 0.0832 \n",
            "l0: 0.086348, l1: 0.086952, l2: 0.099563, l3: 0.126844, l4: 0.208803, l5: 0.349282, l6: 0.575789\n",
            "\n",
            "[epoch: 116/100000, batch: 656/1000, ite: 14457] train loss: 1.7547, accuracy: 92.9318%, tar: 0.0832 \n",
            "l0: 0.065554, l1: 0.066627, l2: 0.075584, l3: 0.104803, l4: 0.175659, l5: 0.310550, l6: 0.495245\n",
            "\n",
            "[epoch: 116/100000, batch: 664/1000, ite: 14458] train loss: 1.7548, accuracy: 92.9546%, tar: 0.0832 \n",
            "l0: 0.102505, l1: 0.103238, l2: 0.111492, l3: 0.131970, l4: 0.180648, l5: 0.333941, l6: 0.546588\n",
            "\n",
            "[epoch: 116/100000, batch: 672/1000, ite: 14459] train loss: 1.7555, accuracy: 89.4676%, tar: 0.0832 \n",
            "l0: 0.094432, l1: 0.095711, l2: 0.104827, l3: 0.127757, l4: 0.175168, l5: 0.262178, l6: 0.534512\n",
            "\n",
            "[epoch: 116/100000, batch: 680/1000, ite: 14460] train loss: 1.7559, accuracy: 91.5894%, tar: 0.0832 \n",
            "l0: 0.076112, l1: 0.077059, l2: 0.082761, l3: 0.101299, l4: 0.146543, l5: 0.230042, l6: 0.361937\n",
            "\n",
            "[epoch: 116/100000, batch: 688/1000, ite: 14461] train loss: 1.7552, accuracy: 93.1677%, tar: 0.0832 \n",
            "l0: 0.062682, l1: 0.063239, l2: 0.069875, l3: 0.089733, l4: 0.131257, l5: 0.208308, l6: 0.340778\n",
            "\n",
            "[epoch: 116/100000, batch: 696/1000, ite: 14462] train loss: 1.7542, accuracy: 93.8002%, tar: 0.0832 \n",
            "l0: 0.124942, l1: 0.127748, l2: 0.136498, l3: 0.175034, l4: 0.230150, l5: 0.335324, l6: 0.508339\n",
            "\n",
            "[epoch: 116/100000, batch: 704/1000, ite: 14463] train loss: 1.7550, accuracy: 92.9781%, tar: 0.0833 \n",
            "l0: 0.088633, l1: 0.089018, l2: 0.099000, l3: 0.125908, l4: 0.199433, l5: 0.290494, l6: 0.506730\n",
            "\n",
            "[epoch: 116/100000, batch: 712/1000, ite: 14464] train loss: 1.7554, accuracy: 92.4634%, tar: 0.0833 \n",
            "l0: 0.084997, l1: 0.086408, l2: 0.096446, l3: 0.128625, l4: 0.195897, l5: 0.303041, l6: 0.461302\n",
            "\n",
            "[epoch: 116/100000, batch: 720/1000, ite: 14465] train loss: 1.7555, accuracy: 92.5514%, tar: 0.0833 \n",
            "l0: 0.063368, l1: 0.064756, l2: 0.074484, l3: 0.100593, l4: 0.167739, l5: 0.300063, l6: 0.485137\n",
            "\n",
            "[epoch: 116/100000, batch: 728/1000, ite: 14466] train loss: 1.7555, accuracy: 92.7967%, tar: 0.0832 \n",
            "l0: 0.066009, l1: 0.066804, l2: 0.077099, l3: 0.099458, l4: 0.146197, l5: 0.230449, l6: 0.379226\n",
            "\n",
            "[epoch: 116/100000, batch: 736/1000, ite: 14467] train loss: 1.7549, accuracy: 93.5188%, tar: 0.0832 \n",
            "l0: 0.068850, l1: 0.069054, l2: 0.076892, l3: 0.094198, l4: 0.137848, l5: 0.217471, l6: 0.376566\n",
            "\n",
            "[epoch: 116/100000, batch: 744/1000, ite: 14468] train loss: 1.7541, accuracy: 93.0273%, tar: 0.0832 \n",
            "l0: 0.071511, l1: 0.071597, l2: 0.080947, l3: 0.103078, l4: 0.153203, l5: 0.222612, l6: 0.385022\n",
            "\n",
            "[epoch: 116/100000, batch: 752/1000, ite: 14469] train loss: 1.7535, accuracy: 92.7687%, tar: 0.0832 \n",
            "l0: 0.138107, l1: 0.140592, l2: 0.152753, l3: 0.187259, l4: 0.285894, l5: 0.465450, l6: 0.847806\n",
            "\n",
            "[epoch: 116/100000, batch: 760/1000, ite: 14470] train loss: 1.7563, accuracy: 87.7888%, tar: 0.0833 \n",
            "l0: 0.085808, l1: 0.087833, l2: 0.095429, l3: 0.116023, l4: 0.156260, l5: 0.243246, l6: 0.465181\n",
            "\n",
            "[epoch: 116/100000, batch: 768/1000, ite: 14471] train loss: 1.7562, accuracy: 92.2409%, tar: 0.0833 \n",
            "l0: 0.063984, l1: 0.063470, l2: 0.071139, l3: 0.089161, l4: 0.131417, l5: 0.208635, l6: 0.384610\n",
            "\n",
            "[epoch: 116/100000, batch: 776/1000, ite: 14472] train loss: 1.7555, accuracy: 93.8448%, tar: 0.0832 \n",
            "l0: 0.094775, l1: 0.095897, l2: 0.103952, l3: 0.128252, l4: 0.191703, l5: 0.300595, l6: 0.475087\n",
            "\n",
            "[epoch: 116/100000, batch: 784/1000, ite: 14473] train loss: 1.7557, accuracy: 91.9696%, tar: 0.0833 \n",
            "l0: 0.064141, l1: 0.065334, l2: 0.073919, l3: 0.093091, l4: 0.146424, l5: 0.278020, l6: 0.526281\n",
            "\n",
            "[epoch: 116/100000, batch: 792/1000, ite: 14474] train loss: 1.7558, accuracy: 91.8543%, tar: 0.0832 \n",
            "l0: 0.089257, l1: 0.089623, l2: 0.099804, l3: 0.116970, l4: 0.161546, l5: 0.244058, l6: 0.448902\n",
            "\n",
            "[epoch: 116/100000, batch: 800/1000, ite: 14475] train loss: 1.7556, accuracy: 91.7165%, tar: 0.0832 \n",
            "l0: 0.074854, l1: 0.074295, l2: 0.080568, l3: 0.097980, l4: 0.141045, l5: 0.230085, l6: 0.395184\n",
            "\n",
            "[epoch: 116/100000, batch: 808/1000, ite: 14476] train loss: 1.7551, accuracy: 93.4666%, tar: 0.0832 \n",
            "l0: 0.088923, l1: 0.090446, l2: 0.099808, l3: 0.122709, l4: 0.165258, l5: 0.277108, l6: 0.479305\n",
            "\n",
            "[epoch: 116/100000, batch: 816/1000, ite: 14477] train loss: 1.7552, accuracy: 92.2545%, tar: 0.0832 \n",
            "l0: 0.087313, l1: 0.088723, l2: 0.097692, l3: 0.113542, l4: 0.158444, l5: 0.228985, l6: 0.403477\n",
            "\n",
            "[epoch: 116/100000, batch: 824/1000, ite: 14478] train loss: 1.7549, accuracy: 92.5307%, tar: 0.0832 \n",
            "l0: 0.077509, l1: 0.079153, l2: 0.090324, l3: 0.119874, l4: 0.201243, l5: 0.323521, l6: 0.596381\n",
            "\n",
            "[epoch: 116/100000, batch: 832/1000, ite: 14479] train loss: 1.7556, accuracy: 90.1222%, tar: 0.0832 \n",
            "l0: 0.078067, l1: 0.079323, l2: 0.092149, l3: 0.123957, l4: 0.195671, l5: 0.342255, l6: 0.638375\n",
            "\n",
            "[epoch: 116/100000, batch: 840/1000, ite: 14480] train loss: 1.7565, accuracy: 91.5019%, tar: 0.0832 \n",
            "l0: 0.100382, l1: 0.101011, l2: 0.108948, l3: 0.128434, l4: 0.167770, l5: 0.218124, l6: 0.373650\n",
            "\n",
            "[epoch: 116/100000, batch: 848/1000, ite: 14481] train loss: 1.7562, accuracy: 93.1302%, tar: 0.0832 \n",
            "l0: 0.080422, l1: 0.082090, l2: 0.089001, l3: 0.107501, l4: 0.147046, l5: 0.236289, l6: 0.388584\n",
            "\n",
            "[epoch: 116/100000, batch: 856/1000, ite: 14482] train loss: 1.7557, accuracy: 93.0669%, tar: 0.0832 \n",
            "l0: 0.115094, l1: 0.116969, l2: 0.127872, l3: 0.161471, l4: 0.239146, l5: 0.408044, l6: 0.633959\n",
            "\n",
            "[epoch: 116/100000, batch: 864/1000, ite: 14483] train loss: 1.7571, accuracy: 89.7415%, tar: 0.0833 \n",
            "l0: 0.075234, l1: 0.076666, l2: 0.084025, l3: 0.110779, l4: 0.160865, l5: 0.245793, l6: 0.450685\n",
            "\n",
            "[epoch: 116/100000, batch: 872/1000, ite: 14484] train loss: 1.7569, accuracy: 92.8084%, tar: 0.0833 \n",
            "l0: 0.097349, l1: 0.099041, l2: 0.113167, l3: 0.147113, l4: 0.223672, l5: 0.362527, l6: 0.611198\n",
            "\n",
            "[epoch: 116/100000, batch: 880/1000, ite: 14485] train loss: 1.7579, accuracy: 91.0420%, tar: 0.0833 \n",
            "l0: 0.077272, l1: 0.077973, l2: 0.086282, l3: 0.107921, l4: 0.143121, l5: 0.201246, l6: 0.378923\n",
            "\n",
            "[epoch: 116/100000, batch: 888/1000, ite: 14486] train loss: 1.7573, accuracy: 93.1538%, tar: 0.0833 \n",
            "l0: 0.092568, l1: 0.092754, l2: 0.100680, l3: 0.123394, l4: 0.179648, l5: 0.271766, l6: 0.509475\n",
            "\n",
            "[epoch: 116/100000, batch: 896/1000, ite: 14487] train loss: 1.7575, accuracy: 92.5417%, tar: 0.0833 \n",
            "l0: 0.080972, l1: 0.082336, l2: 0.089072, l3: 0.106510, l4: 0.144490, l5: 0.222051, l6: 0.376253\n",
            "\n",
            "[epoch: 116/100000, batch: 904/1000, ite: 14488] train loss: 1.7569, accuracy: 92.7735%, tar: 0.0833 \n",
            "l0: 0.076082, l1: 0.078013, l2: 0.086548, l3: 0.114831, l4: 0.172810, l5: 0.283875, l6: 0.474684\n",
            "\n",
            "[epoch: 116/100000, batch: 912/1000, ite: 14489] train loss: 1.7570, accuracy: 92.9396%, tar: 0.0833 \n",
            "l0: 0.078226, l1: 0.078682, l2: 0.085329, l3: 0.106853, l4: 0.148841, l5: 0.220660, l6: 0.403208\n",
            "\n",
            "[epoch: 116/100000, batch: 920/1000, ite: 14490] train loss: 1.7565, accuracy: 92.5843%, tar: 0.0833 \n",
            "l0: 0.126052, l1: 0.126458, l2: 0.139696, l3: 0.172706, l4: 0.250792, l5: 0.427070, l6: 0.698770\n",
            "\n",
            "[epoch: 116/100000, batch: 928/1000, ite: 14491] train loss: 1.7583, accuracy: 87.9264%, tar: 0.0834 \n",
            "l0: 0.075155, l1: 0.077197, l2: 0.086979, l3: 0.113994, l4: 0.152286, l5: 0.240360, l6: 0.410106\n",
            "\n",
            "[epoch: 116/100000, batch: 936/1000, ite: 14492] train loss: 1.7580, accuracy: 92.9632%, tar: 0.0834 \n",
            "l0: 0.077190, l1: 0.078688, l2: 0.086970, l3: 0.109267, l4: 0.165264, l5: 0.264468, l6: 0.440207\n",
            "\n",
            "[epoch: 116/100000, batch: 944/1000, ite: 14493] train loss: 1.7578, accuracy: 92.4628%, tar: 0.0834 \n",
            "l0: 0.088959, l1: 0.089801, l2: 0.099831, l3: 0.121506, l4: 0.187556, l5: 0.285629, l6: 0.496857\n",
            "\n",
            "[epoch: 116/100000, batch: 952/1000, ite: 14494] train loss: 1.7580, accuracy: 92.6057%, tar: 0.0834 \n",
            "l0: 0.103037, l1: 0.103815, l2: 0.112723, l3: 0.139493, l4: 0.208131, l5: 0.300324, l6: 0.519445\n",
            "\n",
            "[epoch: 116/100000, batch: 960/1000, ite: 14495] train loss: 1.7585, accuracy: 91.5214%, tar: 0.0834 \n",
            "l0: 0.074744, l1: 0.076443, l2: 0.084608, l3: 0.115445, l4: 0.186956, l5: 0.309408, l6: 0.446755\n",
            "\n",
            "[epoch: 116/100000, batch: 968/1000, ite: 14496] train loss: 1.7585, accuracy: 93.1675%, tar: 0.0834 \n",
            "l0: 0.088995, l1: 0.090092, l2: 0.099619, l3: 0.120779, l4: 0.163378, l5: 0.250718, l6: 0.482636\n",
            "\n",
            "[epoch: 116/100000, batch: 976/1000, ite: 14497] train loss: 1.7585, accuracy: 91.6239%, tar: 0.0834 \n",
            "l0: 0.067543, l1: 0.067423, l2: 0.075373, l3: 0.098250, l4: 0.154636, l5: 0.254550, l6: 0.403459\n",
            "\n",
            "[epoch: 116/100000, batch: 984/1000, ite: 14498] train loss: 1.7581, accuracy: 93.6008%, tar: 0.0834 \n",
            "l0: 0.077106, l1: 0.078686, l2: 0.088136, l3: 0.108243, l4: 0.139436, l5: 0.214284, l6: 0.377295\n",
            "\n",
            "[epoch: 116/100000, batch: 992/1000, ite: 14499] train loss: 1.7575, accuracy: 93.0771%, tar: 0.0834 \n",
            "l0: 0.079056, l1: 0.080302, l2: 0.090004, l3: 0.112701, l4: 0.168913, l5: 0.298354, l6: 0.516092\n",
            "\n",
            "[epoch: 116/100000, batch: 1000/1000, ite: 14500] train loss: 1.7577, accuracy: 91.8160%, tar: 0.0833 \n",
            "l0: 0.075497, l1: 0.076631, l2: 0.084702, l3: 0.110315, l4: 0.175222, l5: 0.260429, l6: 0.467357\n",
            "\n",
            "[epoch: 117/100000, batch: 8/1000, ite: 14501] train loss: 1.7576, accuracy: 92.9234%, tar: 0.0833 \n",
            "l0: 0.075873, l1: 0.077376, l2: 0.084292, l3: 0.103300, l4: 0.153471, l5: 0.253382, l6: 0.416828\n",
            "\n",
            "[epoch: 117/100000, batch: 16/1000, ite: 14502] train loss: 1.7573, accuracy: 92.8521%, tar: 0.0833 \n",
            "l0: 0.090043, l1: 0.091892, l2: 0.102571, l3: 0.128254, l4: 0.188962, l5: 0.289304, l6: 0.563537\n",
            "\n",
            "[epoch: 117/100000, batch: 24/1000, ite: 14503] train loss: 1.7578, accuracy: 90.3450%, tar: 0.0833 \n",
            "l0: 0.062914, l1: 0.064336, l2: 0.073231, l3: 0.098630, l4: 0.149577, l5: 0.262231, l6: 0.449010\n",
            "\n",
            "[epoch: 117/100000, batch: 32/1000, ite: 14504] train loss: 1.7575, accuracy: 92.3692%, tar: 0.0833 \n",
            "l0: 0.099092, l1: 0.099464, l2: 0.107468, l3: 0.130503, l4: 0.175035, l5: 0.256973, l6: 0.442382\n",
            "\n",
            "[epoch: 117/100000, batch: 40/1000, ite: 14505] train loss: 1.7575, accuracy: 92.1389%, tar: 0.0833 \n",
            "l0: 0.076737, l1: 0.077032, l2: 0.087548, l3: 0.106598, l4: 0.143226, l5: 0.225391, l6: 0.369020\n",
            "\n",
            "[epoch: 117/100000, batch: 48/1000, ite: 14506] train loss: 1.7570, accuracy: 92.4061%, tar: 0.0833 \n",
            "l0: 0.066473, l1: 0.067361, l2: 0.076604, l3: 0.098285, l4: 0.141819, l5: 0.226463, l6: 0.431199\n",
            "\n",
            "[epoch: 117/100000, batch: 56/1000, ite: 14507] train loss: 1.7565, accuracy: 93.2133%, tar: 0.0833 \n",
            "l0: 0.077090, l1: 0.077806, l2: 0.085800, l3: 0.106380, l4: 0.159409, l5: 0.277232, l6: 0.442611\n",
            "\n",
            "[epoch: 117/100000, batch: 64/1000, ite: 14508] train loss: 1.7564, accuracy: 91.4044%, tar: 0.0833 \n",
            "l0: 0.077396, l1: 0.078813, l2: 0.090948, l3: 0.125474, l4: 0.205701, l5: 0.302591, l6: 0.553743\n",
            "\n",
            "[epoch: 117/100000, batch: 72/1000, ite: 14509] train loss: 1.7568, accuracy: 91.5022%, tar: 0.0832 \n",
            "l0: 0.086686, l1: 0.087571, l2: 0.095133, l3: 0.115424, l4: 0.164443, l5: 0.236115, l6: 0.450617\n",
            "\n",
            "[epoch: 117/100000, batch: 80/1000, ite: 14510] train loss: 1.7567, accuracy: 91.7778%, tar: 0.0833 \n",
            "l0: 0.075658, l1: 0.076558, l2: 0.083751, l3: 0.104088, l4: 0.157605, l5: 0.253728, l6: 0.450625\n",
            "\n",
            "[epoch: 117/100000, batch: 88/1000, ite: 14511] train loss: 1.7565, accuracy: 92.3999%, tar: 0.0832 \n",
            "l0: 0.106427, l1: 0.111721, l2: 0.122183, l3: 0.138689, l4: 0.176951, l5: 0.223352, l6: 0.317488\n",
            "\n",
            "[epoch: 117/100000, batch: 96/1000, ite: 14512] train loss: 1.7561, accuracy: 93.5268%, tar: 0.0833 \n",
            "l0: 0.079742, l1: 0.081312, l2: 0.089041, l3: 0.113938, l4: 0.172568, l5: 0.286618, l6: 0.447216\n",
            "\n",
            "[epoch: 117/100000, batch: 104/1000, ite: 14513] train loss: 1.7561, accuracy: 92.2344%, tar: 0.0833 \n",
            "l0: 0.075594, l1: 0.078226, l2: 0.084884, l3: 0.096385, l4: 0.115565, l5: 0.170783, l6: 0.347940\n",
            "\n",
            "[epoch: 117/100000, batch: 112/1000, ite: 14514] train loss: 1.7552, accuracy: 93.5928%, tar: 0.0833 \n",
            "l0: 0.079146, l1: 0.081265, l2: 0.088053, l3: 0.111326, l4: 0.163320, l5: 0.268786, l6: 0.408703\n",
            "\n",
            "[epoch: 117/100000, batch: 120/1000, ite: 14515] train loss: 1.7549, accuracy: 92.4812%, tar: 0.0833 \n",
            "l0: 0.084588, l1: 0.085724, l2: 0.096093, l3: 0.126133, l4: 0.188904, l5: 0.273696, l6: 0.477518\n",
            "\n",
            "[epoch: 117/100000, batch: 128/1000, ite: 14516] train loss: 1.7551, accuracy: 93.0063%, tar: 0.0833 \n",
            "l0: 0.121883, l1: 0.126829, l2: 0.136069, l3: 0.163749, l4: 0.226086, l5: 0.335690, l6: 0.612849\n",
            "\n",
            "[epoch: 117/100000, batch: 136/1000, ite: 14517] train loss: 1.7562, accuracy: 91.2374%, tar: 0.0833 \n",
            "l0: 0.080667, l1: 0.084133, l2: 0.093836, l3: 0.119896, l4: 0.185244, l5: 0.286673, l6: 0.469837\n",
            "\n",
            "[epoch: 117/100000, batch: 144/1000, ite: 14518] train loss: 1.7563, accuracy: 93.1340%, tar: 0.0833 \n",
            "l0: 0.062549, l1: 0.064345, l2: 0.070775, l3: 0.088767, l4: 0.146551, l5: 0.230933, l6: 0.370477\n",
            "\n",
            "[epoch: 117/100000, batch: 152/1000, ite: 14519] train loss: 1.7556, accuracy: 93.7562%, tar: 0.0833 \n",
            "l0: 0.081767, l1: 0.082911, l2: 0.094459, l3: 0.122223, l4: 0.182556, l5: 0.346562, l6: 0.585707\n",
            "\n",
            "[epoch: 117/100000, batch: 160/1000, ite: 14520] train loss: 1.7562, accuracy: 91.6584%, tar: 0.0833 \n",
            "l0: 0.088066, l1: 0.088462, l2: 0.096914, l3: 0.116143, l4: 0.151084, l5: 0.236672, l6: 0.393471\n",
            "\n",
            "[epoch: 117/100000, batch: 168/1000, ite: 14521] train loss: 1.7558, accuracy: 93.5136%, tar: 0.0833 \n",
            "l0: 0.090531, l1: 0.093497, l2: 0.104989, l3: 0.134487, l4: 0.188942, l5: 0.308125, l6: 0.585603\n",
            "\n",
            "[epoch: 117/100000, batch: 176/1000, ite: 14522] train loss: 1.7565, accuracy: 92.6204%, tar: 0.0833 \n",
            "l0: 0.147364, l1: 0.154643, l2: 0.161881, l3: 0.185106, l4: 0.238577, l5: 0.359724, l6: 0.509205\n",
            "\n",
            "[epoch: 117/100000, batch: 184/1000, ite: 14523] train loss: 1.7575, accuracy: 91.5241%, tar: 0.0834 \n",
            "l0: 0.133149, l1: 0.137172, l2: 0.141450, l3: 0.158168, l4: 0.200544, l5: 0.274474, l6: 0.469450\n",
            "\n",
            "[epoch: 117/100000, batch: 192/1000, ite: 14524] train loss: 1.7579, accuracy: 91.9180%, tar: 0.0835 \n",
            "l0: 0.192929, l1: 0.201407, l2: 0.209749, l3: 0.234196, l4: 0.281395, l5: 0.370075, l6: 0.570109\n",
            "\n",
            "[epoch: 117/100000, batch: 200/1000, ite: 14525] train loss: 1.7595, accuracy: 91.2451%, tar: 0.0837 \n",
            "l0: 0.176919, l1: 0.172679, l2: 0.184901, l3: 0.214071, l4: 0.259675, l5: 0.329211, l6: 0.519774\n",
            "\n",
            "[epoch: 117/100000, batch: 208/1000, ite: 14526] train loss: 1.7607, accuracy: 91.5170%, tar: 0.0839 \n",
            "l0: 0.131982, l1: 0.135836, l2: 0.146941, l3: 0.169858, l4: 0.229825, l5: 0.377711, l6: 0.563791\n",
            "\n",
            "[epoch: 117/100000, batch: 216/1000, ite: 14527] train loss: 1.7617, accuracy: 90.9898%, tar: 0.0840 \n",
            "l0: 0.188477, l1: 0.203541, l2: 0.216666, l3: 0.250057, l4: 0.329962, l5: 0.408646, l6: 0.643465\n",
            "\n",
            "[epoch: 117/100000, batch: 224/1000, ite: 14528] train loss: 1.7638, accuracy: 89.5594%, tar: 0.0842 \n",
            "l0: 0.096485, l1: 0.100822, l2: 0.107500, l3: 0.124540, l4: 0.161700, l5: 0.252766, l6: 0.414080\n",
            "\n",
            "[epoch: 117/100000, batch: 232/1000, ite: 14529] train loss: 1.7636, accuracy: 91.9592%, tar: 0.0842 \n",
            "l0: 0.154848, l1: 0.157410, l2: 0.170986, l3: 0.206526, l4: 0.275823, l5: 0.359893, l6: 0.566069\n",
            "\n",
            "[epoch: 117/100000, batch: 240/1000, ite: 14530] train loss: 1.7649, accuracy: 90.7632%, tar: 0.0844 \n",
            "l0: 0.201812, l1: 0.195592, l2: 0.213437, l3: 0.249453, l4: 0.279410, l5: 0.407065, l6: 0.654026\n",
            "\n",
            "[epoch: 117/100000, batch: 248/1000, ite: 14531] train loss: 1.7671, accuracy: 87.8507%, tar: 0.0846 \n",
            "l0: 0.111847, l1: 0.116944, l2: 0.125352, l3: 0.150044, l4: 0.186405, l5: 0.263782, l6: 0.466694\n",
            "\n",
            "[epoch: 117/100000, batch: 256/1000, ite: 14532] train loss: 1.7674, accuracy: 92.1683%, tar: 0.0846 \n",
            "l0: 0.136161, l1: 0.136020, l2: 0.148213, l3: 0.188303, l4: 0.281686, l5: 0.419948, l6: 0.644124\n",
            "\n",
            "[epoch: 117/100000, batch: 264/1000, ite: 14533] train loss: 1.7689, accuracy: 88.7955%, tar: 0.0847 \n",
            "l0: 0.221956, l1: 0.234484, l2: 0.234021, l3: 0.251278, l4: 0.316358, l5: 0.395248, l6: 0.516767\n",
            "\n",
            "[epoch: 117/100000, batch: 272/1000, ite: 14534] train loss: 1.7706, accuracy: 90.7702%, tar: 0.0850 \n",
            "l0: 0.145687, l1: 0.148251, l2: 0.149390, l3: 0.184908, l4: 0.246027, l5: 0.348555, l6: 0.603956\n",
            "\n",
            "[epoch: 117/100000, batch: 280/1000, ite: 14535] train loss: 1.7719, accuracy: 89.4663%, tar: 0.0851 \n",
            "l0: 0.186475, l1: 0.183598, l2: 0.196698, l3: 0.228327, l4: 0.287555, l5: 0.401504, l6: 0.516599\n",
            "\n",
            "[epoch: 117/100000, batch: 288/1000, ite: 14536] train loss: 1.7734, accuracy: 89.3876%, tar: 0.0853 \n",
            "l0: 0.108666, l1: 0.112279, l2: 0.122797, l3: 0.156877, l4: 0.221367, l5: 0.305745, l6: 0.547715\n",
            "\n",
            "[epoch: 117/100000, batch: 296/1000, ite: 14537] train loss: 1.7740, accuracy: 91.1608%, tar: 0.0853 \n",
            "l0: 0.098897, l1: 0.101626, l2: 0.113469, l3: 0.138232, l4: 0.199316, l5: 0.318784, l6: 0.488462\n",
            "\n",
            "[epoch: 117/100000, batch: 304/1000, ite: 14538] train loss: 1.7744, accuracy: 91.4215%, tar: 0.0854 \n",
            "l0: 0.153686, l1: 0.160515, l2: 0.168690, l3: 0.198693, l4: 0.274033, l5: 0.388489, l6: 0.591559\n",
            "\n",
            "[epoch: 117/100000, batch: 312/1000, ite: 14539] train loss: 1.7758, accuracy: 89.5844%, tar: 0.0855 \n",
            "l0: 0.137687, l1: 0.136568, l2: 0.143963, l3: 0.170281, l4: 0.218943, l5: 0.340341, l6: 0.560504\n",
            "\n",
            "[epoch: 117/100000, batch: 320/1000, ite: 14540] train loss: 1.7768, accuracy: 91.1197%, tar: 0.0856 \n",
            "l0: 0.507029, l1: 0.526575, l2: 0.514218, l3: 0.519049, l4: 0.569514, l5: 0.696607, l6: 0.792769\n",
            "\n",
            "[epoch: 117/100000, batch: 328/1000, ite: 14541] train loss: 1.7826, accuracy: 87.2977%, tar: 0.0864 \n",
            "l0: 0.139480, l1: 0.140315, l2: 0.161885, l3: 0.206484, l4: 0.316758, l5: 0.475218, l6: 0.647718\n",
            "\n",
            "[epoch: 117/100000, batch: 336/1000, ite: 14542] train loss: 1.7845, accuracy: 89.2695%, tar: 0.0865 \n",
            "l0: 0.209180, l1: 0.196698, l2: 0.205872, l3: 0.219994, l4: 0.247543, l5: 0.368594, l6: 0.639384\n",
            "\n",
            "[epoch: 117/100000, batch: 344/1000, ite: 14543] train loss: 1.7863, accuracy: 89.9083%, tar: 0.0867 \n",
            "l0: 0.319427, l1: 0.309114, l2: 0.321478, l3: 0.330536, l4: 0.336224, l5: 0.438085, l6: 0.693619\n",
            "\n",
            "[epoch: 117/100000, batch: 352/1000, ite: 14544] train loss: 1.7895, accuracy: 88.0028%, tar: 0.0871 \n",
            "l0: 0.311649, l1: 0.325579, l2: 0.340229, l3: 0.353766, l4: 0.339657, l5: 0.453693, l6: 0.615124\n",
            "\n",
            "[epoch: 117/100000, batch: 360/1000, ite: 14545] train loss: 1.7923, accuracy: 88.5965%, tar: 0.0875 \n",
            "l0: 0.181659, l1: 0.190697, l2: 0.203787, l3: 0.236869, l4: 0.248941, l5: 0.327403, l6: 0.548400\n",
            "\n",
            "[epoch: 117/100000, batch: 368/1000, ite: 14546] train loss: 1.7936, accuracy: 88.9336%, tar: 0.0877 \n",
            "l0: 0.227497, l1: 0.227392, l2: 0.216948, l3: 0.248833, l4: 0.280611, l5: 0.434431, l6: 0.729850\n",
            "\n",
            "[epoch: 117/100000, batch: 376/1000, ite: 14547] train loss: 1.7960, accuracy: 88.3874%, tar: 0.0879 \n",
            "l0: 0.321060, l1: 0.320990, l2: 0.300770, l3: 0.311131, l4: 0.315700, l5: 0.518351, l6: 0.802585\n",
            "\n",
            "[epoch: 117/100000, batch: 384/1000, ite: 14548] train loss: 1.7993, accuracy: 87.6340%, tar: 0.0884 \n",
            "l0: 0.538114, l1: 0.548296, l2: 0.571177, l3: 0.586469, l4: 0.630172, l5: 0.860837, l6: 1.130481\n",
            "\n",
            "[epoch: 117/100000, batch: 392/1000, ite: 14549] train loss: 1.8071, accuracy: 82.9867%, tar: 0.0892 \n",
            "l0: 0.649287, l1: 0.669155, l2: 0.702189, l3: 0.721644, l4: 0.735745, l5: 0.770947, l6: 0.883024\n",
            "\n",
            "[epoch: 117/100000, batch: 400/1000, ite: 14550] train loss: 1.8148, accuracy: 83.7673%, tar: 0.0902 \n",
            "l0: 0.492295, l1: 0.505512, l2: 0.552508, l3: 0.565415, l4: 0.590774, l5: 0.666558, l6: 0.812289\n",
            "\n",
            "[epoch: 117/100000, batch: 408/1000, ite: 14551] train loss: 1.8206, accuracy: 83.8789%, tar: 0.0909 \n",
            "l0: 0.401829, l1: 0.401756, l2: 0.409686, l3: 0.419529, l4: 0.449266, l5: 0.705493, l6: 0.849207\n",
            "\n",
            "[epoch: 117/100000, batch: 416/1000, ite: 14552] train loss: 1.8251, accuracy: 86.8347%, tar: 0.0915 \n",
            "l0: 0.563330, l1: 0.566285, l2: 0.556141, l3: 0.622410, l4: 0.727742, l5: 1.059822, l6: 0.964278\n",
            "\n",
            "[epoch: 117/100000, batch: 424/1000, ite: 14553] train loss: 1.8328, accuracy: 81.9566%, tar: 0.0924 \n",
            "l0: 0.769971, l1: 0.755958, l2: 0.711584, l3: 0.717912, l4: 0.770880, l5: 0.791007, l6: 0.855967\n",
            "\n",
            "[epoch: 117/100000, batch: 432/1000, ite: 14554] train loss: 1.8408, accuracy: 82.2872%, tar: 0.0936 \n",
            "l0: 0.659067, l1: 0.639438, l2: 0.607839, l3: 0.573223, l4: 0.663411, l5: 0.768148, l6: 0.949220\n",
            "\n",
            "[epoch: 117/100000, batch: 440/1000, ite: 14555] train loss: 1.8480, accuracy: 82.3115%, tar: 0.0946 \n",
            "l0: 0.621366, l1: 0.619333, l2: 0.605649, l3: 0.625781, l4: 0.715892, l5: 0.851203, l6: 1.243855\n",
            "\n",
            "[epoch: 117/100000, batch: 448/1000, ite: 14556] train loss: 1.8564, accuracy: 82.4053%, tar: 0.0955 \n",
            "l0: 0.430282, l1: 0.430405, l2: 0.473594, l3: 0.463911, l4: 0.516796, l5: 0.639544, l6: 0.809890\n",
            "\n",
            "[epoch: 117/100000, batch: 456/1000, ite: 14557] train loss: 1.8613, accuracy: 85.3075%, tar: 0.0961 \n",
            "l0: 0.415706, l1: 0.412298, l2: 0.436972, l3: 0.479612, l4: 0.463660, l5: 0.544180, l6: 0.782091\n",
            "\n",
            "[epoch: 117/100000, batch: 464/1000, ite: 14558] train loss: 1.8657, accuracy: 82.8816%, tar: 0.0967 \n",
            "l0: 0.430930, l1: 0.432094, l2: 0.430519, l3: 0.486932, l4: 0.497712, l5: 0.533298, l6: 0.780119\n",
            "\n",
            "[epoch: 117/100000, batch: 472/1000, ite: 14559] train loss: 1.8704, accuracy: 84.2176%, tar: 0.0973 \n",
            "l0: 0.339392, l1: 0.348279, l2: 0.356680, l3: 0.430570, l4: 0.509891, l5: 0.519653, l6: 0.829515\n",
            "\n",
            "[epoch: 117/100000, batch: 480/1000, ite: 14560] train loss: 1.8744, accuracy: 84.5911%, tar: 0.0978 \n",
            "l0: 0.480422, l1: 0.483231, l2: 0.472185, l3: 0.500295, l4: 0.504402, l5: 0.529590, l6: 0.676054\n",
            "\n",
            "[epoch: 117/100000, batch: 488/1000, ite: 14561] train loss: 1.8788, accuracy: 85.4273%, tar: 0.0984 \n",
            "l0: 0.353491, l1: 0.366294, l2: 0.380479, l3: 0.392310, l4: 0.464177, l5: 0.555051, l6: 0.740528\n",
            "\n",
            "[epoch: 117/100000, batch: 496/1000, ite: 14562] train loss: 1.8827, accuracy: 85.0082%, tar: 0.0989 \n",
            "l0: 0.633940, l1: 0.639441, l2: 0.640770, l3: 0.669020, l4: 0.736817, l5: 0.926590, l6: 1.182162\n",
            "\n",
            "[epoch: 117/100000, batch: 504/1000, ite: 14563] train loss: 1.8913, accuracy: 79.9558%, tar: 0.0998 \n",
            "l0: 0.462802, l1: 0.467164, l2: 0.459734, l3: 0.481593, l4: 0.511620, l5: 0.684949, l6: 0.844050\n",
            "\n",
            "[epoch: 117/100000, batch: 512/1000, ite: 14564] train loss: 1.8964, accuracy: 84.4239%, tar: 0.1005 \n",
            "l0: 1.040583, l1: 1.049104, l2: 1.030348, l3: 1.046353, l4: 1.048694, l5: 1.262729, l6: 1.062537\n",
            "\n",
            "[epoch: 117/100000, batch: 520/1000, ite: 14565] train loss: 1.9084, accuracy: 80.1179%, tar: 0.1021 \n",
            "l0: 0.830420, l1: 0.879846, l2: 0.930272, l3: 0.975927, l4: 1.018821, l5: 1.074133, l6: 1.296056\n",
            "\n",
            "[epoch: 117/100000, batch: 528/1000, ite: 14566] train loss: 1.9197, accuracy: 78.5302%, tar: 0.1034 \n",
            "l0: 0.392279, l1: 0.389378, l2: 0.374864, l3: 0.397092, l4: 0.438646, l5: 0.509362, l6: 0.771753\n",
            "\n",
            "[epoch: 117/100000, batch: 536/1000, ite: 14567] train loss: 1.9235, accuracy: 85.8217%, tar: 0.1039 \n",
            "l0: 0.494464, l1: 0.498294, l2: 0.521974, l3: 0.534544, l4: 0.562792, l5: 0.646769, l6: 0.762600\n",
            "\n",
            "[epoch: 117/100000, batch: 544/1000, ite: 14568] train loss: 1.9287, accuracy: 83.7139%, tar: 0.1046 \n",
            "l0: 0.845309, l1: 0.841210, l2: 0.822916, l3: 0.892698, l4: 1.007620, l5: 1.223713, l6: 1.317947\n",
            "\n",
            "[epoch: 117/100000, batch: 552/1000, ite: 14569] train loss: 1.9398, accuracy: 74.0868%, tar: 0.1059 \n",
            "l0: 0.591264, l1: 0.602355, l2: 0.611977, l3: 0.628254, l4: 0.681030, l5: 0.814555, l6: 0.780366\n",
            "\n",
            "[epoch: 117/100000, batch: 560/1000, ite: 14570] train loss: 1.9460, accuracy: 81.0602%, tar: 0.1068 \n",
            "l0: 0.691902, l1: 0.706476, l2: 0.730933, l3: 0.786061, l4: 0.881990, l5: 1.046843, l6: 1.067970\n",
            "\n",
            "[epoch: 117/100000, batch: 568/1000, ite: 14571] train loss: 1.9547, accuracy: 76.0116%, tar: 0.1078 \n",
            "l0: 0.758288, l1: 0.759393, l2: 0.768338, l3: 0.784623, l4: 0.834735, l5: 0.922659, l6: 1.175582\n",
            "\n",
            "[epoch: 117/100000, batch: 576/1000, ite: 14572] train loss: 1.9639, accuracy: 80.8466%, tar: 0.1089 \n",
            "l0: 0.848661, l1: 0.805536, l2: 0.756556, l3: 0.862273, l4: 0.873527, l5: 1.050882, l6: 1.217899\n",
            "\n",
            "[epoch: 117/100000, batch: 584/1000, ite: 14573] train loss: 1.9741, accuracy: 77.2769%, tar: 0.1102 \n",
            "l0: 0.461684, l1: 0.486415, l2: 0.490787, l3: 0.474981, l4: 0.549746, l5: 0.652152, l6: 0.831981\n",
            "\n",
            "[epoch: 117/100000, batch: 592/1000, ite: 14574] train loss: 1.9790, accuracy: 82.2535%, tar: 0.1108 \n",
            "l0: 0.754660, l1: 0.755855, l2: 0.755388, l3: 0.811584, l4: 0.851066, l5: 0.943861, l6: 1.118961\n",
            "\n",
            "[epoch: 117/100000, batch: 600/1000, ite: 14575] train loss: 1.9881, accuracy: 78.0549%, tar: 0.1120 \n",
            "l0: 0.475842, l1: 0.501007, l2: 0.516555, l3: 0.517973, l4: 0.580650, l5: 0.651956, l6: 0.780351\n",
            "\n",
            "[epoch: 117/100000, batch: 608/1000, ite: 14576] train loss: 1.9930, accuracy: 82.4014%, tar: 0.1126 \n",
            "l0: 0.504380, l1: 0.514632, l2: 0.509234, l3: 0.536158, l4: 0.610983, l5: 0.621317, l6: 0.789371\n",
            "\n",
            "[epoch: 117/100000, batch: 616/1000, ite: 14577] train loss: 1.9982, accuracy: 83.0216%, tar: 0.1133 \n",
            "l0: 0.792349, l1: 0.785964, l2: 0.782138, l3: 0.830850, l4: 0.897272, l5: 0.983324, l6: 1.167192\n",
            "\n",
            "[epoch: 117/100000, batch: 624/1000, ite: 14578] train loss: 2.0076, accuracy: 77.2069%, tar: 0.1145 \n",
            "l0: 0.530134, l1: 0.525989, l2: 0.527613, l3: 0.562879, l4: 0.616222, l5: 0.727482, l6: 0.926697\n",
            "\n",
            "[epoch: 117/100000, batch: 632/1000, ite: 14579] train loss: 2.0133, accuracy: 80.7457%, tar: 0.1152 \n",
            "l0: 0.837239, l1: 0.835962, l2: 0.855859, l3: 0.906493, l4: 0.943951, l5: 1.039284, l6: 1.249615\n",
            "\n",
            "[epoch: 117/100000, batch: 640/1000, ite: 14580] train loss: 2.0235, accuracy: 76.8869%, tar: 0.1164 \n",
            "l0: 0.404205, l1: 0.419178, l2: 0.407294, l3: 0.420098, l4: 0.471209, l5: 0.537240, l6: 0.788244\n",
            "\n",
            "[epoch: 117/100000, batch: 648/1000, ite: 14581] train loss: 2.0274, accuracy: 82.6079%, tar: 0.1169 \n",
            "l0: 0.454788, l1: 0.464295, l2: 0.464988, l3: 0.491726, l4: 0.577815, l5: 0.651856, l6: 0.955811\n",
            "\n",
            "[epoch: 117/100000, batch: 656/1000, ite: 14582] train loss: 2.0328, accuracy: 82.4940%, tar: 0.1175 \n",
            "l0: 0.666281, l1: 0.687018, l2: 0.658722, l3: 0.704296, l4: 0.747325, l5: 0.865695, l6: 0.978257\n",
            "\n",
            "[epoch: 117/100000, batch: 664/1000, ite: 14583] train loss: 2.0402, accuracy: 79.3922%, tar: 0.1184 \n",
            "l0: 1.061839, l1: 1.072145, l2: 1.024437, l3: 1.043666, l4: 1.048698, l5: 1.077373, l6: 1.171472\n",
            "\n",
            "[epoch: 117/100000, batch: 672/1000, ite: 14584] train loss: 2.0517, accuracy: 73.7990%, tar: 0.1200 \n",
            "l0: 0.691070, l1: 0.709601, l2: 0.709817, l3: 0.728185, l4: 0.802260, l5: 0.857103, l6: 1.101303\n",
            "\n",
            "[epoch: 117/100000, batch: 680/1000, ite: 14585] train loss: 2.0598, accuracy: 79.9404%, tar: 0.1210 \n",
            "l0: 0.901477, l1: 0.887215, l2: 0.949571, l3: 0.981943, l4: 1.084140, l5: 1.131303, l6: 1.156463\n",
            "\n",
            "[epoch: 117/100000, batch: 688/1000, ite: 14586] train loss: 2.0705, accuracy: 78.9454%, tar: 0.1224 \n",
            "l0: 0.993713, l1: 0.970508, l2: 1.048667, l3: 1.080271, l4: 1.173581, l5: 1.150954, l6: 1.311502\n",
            "\n",
            "[epoch: 117/100000, batch: 696/1000, ite: 14587] train loss: 2.0822, accuracy: 77.9657%, tar: 0.1238 \n",
            "l0: 0.728929, l1: 0.753666, l2: 0.756076, l3: 0.770294, l4: 0.763637, l5: 0.768797, l6: 0.998652\n",
            "\n",
            "[epoch: 117/100000, batch: 704/1000, ite: 14588] train loss: 2.0897, accuracy: 80.0010%, tar: 0.1249 \n",
            "l0: 0.425724, l1: 0.411617, l2: 0.438714, l3: 0.497757, l4: 0.576944, l5: 0.642847, l6: 0.842910\n",
            "\n",
            "[epoch: 117/100000, batch: 712/1000, ite: 14589] train loss: 2.0942, accuracy: 82.2392%, tar: 0.1254 \n",
            "l0: 0.594025, l1: 0.605357, l2: 0.636331, l3: 0.653894, l4: 0.691399, l5: 0.871282, l6: 1.057475\n",
            "\n",
            "[epoch: 117/100000, batch: 720/1000, ite: 14590] train loss: 2.1009, accuracy: 80.9519%, tar: 0.1262 \n",
            "l0: 0.632232, l1: 0.631565, l2: 0.630377, l3: 0.673906, l4: 0.644755, l5: 0.678667, l6: 0.938946\n",
            "\n",
            "[epoch: 117/100000, batch: 728/1000, ite: 14591] train loss: 2.1073, accuracy: 79.4492%, tar: 0.1270 \n",
            "l0: 0.306098, l1: 0.311982, l2: 0.325499, l3: 0.370148, l4: 0.407104, l5: 0.490569, l6: 0.677456\n",
            "\n",
            "[epoch: 117/100000, batch: 736/1000, ite: 14592] train loss: 2.1098, accuracy: 85.3562%, tar: 0.1273 \n",
            "l0: 0.784437, l1: 0.785357, l2: 0.778639, l3: 0.805471, l4: 0.864515, l5: 0.968255, l6: 1.114094\n",
            "\n",
            "[epoch: 117/100000, batch: 744/1000, ite: 14593] train loss: 2.1183, accuracy: 77.7067%, tar: 0.1284 \n",
            "l0: 0.260734, l1: 0.263833, l2: 0.262196, l3: 0.299502, l4: 0.395058, l5: 0.475616, l6: 0.745387\n",
            "\n",
            "[epoch: 117/100000, batch: 752/1000, ite: 14594] train loss: 2.1205, accuracy: 85.7910%, tar: 0.1287 \n",
            "l0: 0.549096, l1: 0.558601, l2: 0.555026, l3: 0.519557, l4: 0.601100, l5: 0.703038, l6: 0.947284\n",
            "\n",
            "[epoch: 117/100000, batch: 760/1000, ite: 14595] train loss: 2.1259, accuracy: 83.9551%, tar: 0.1294 \n",
            "l0: 0.497442, l1: 0.501541, l2: 0.506747, l3: 0.532278, l4: 0.621594, l5: 0.705576, l6: 0.920141\n",
            "\n",
            "[epoch: 117/100000, batch: 768/1000, ite: 14596] train loss: 2.1311, accuracy: 82.2323%, tar: 0.1300 \n",
            "l0: 0.440951, l1: 0.442954, l2: 0.440381, l3: 0.457782, l4: 0.505112, l5: 0.631848, l6: 0.926864\n",
            "\n",
            "[epoch: 117/100000, batch: 776/1000, ite: 14597] train loss: 2.1357, accuracy: 84.2976%, tar: 0.1305 \n",
            "l0: 0.377938, l1: 0.379391, l2: 0.378725, l3: 0.403197, l4: 0.461479, l5: 0.611378, l6: 0.891961\n",
            "\n",
            "[epoch: 117/100000, batch: 784/1000, ite: 14598] train loss: 2.1394, accuracy: 84.4000%, tar: 0.1309 \n",
            "l0: 0.800363, l1: 0.798166, l2: 0.846342, l3: 0.874261, l4: 0.933407, l5: 1.008907, l6: 1.161629\n",
            "\n",
            "[epoch: 117/100000, batch: 792/1000, ite: 14599] train loss: 2.1486, accuracy: 79.5648%, tar: 0.1320 \n",
            "l0: 0.441481, l1: 0.456534, l2: 0.461601, l3: 0.477604, l4: 0.535563, l5: 0.639908, l6: 0.885413\n",
            "\n",
            "[epoch: 117/100000, batch: 800/1000, ite: 14600] train loss: 2.1529, accuracy: 84.9514%, tar: 0.1326 \n",
            "l0: 0.706004, l1: 0.725934, l2: 0.748981, l3: 0.754962, l4: 0.785230, l5: 0.850667, l6: 0.894115\n",
            "\n",
            "[epoch: 117/100000, batch: 808/1000, ite: 14601] train loss: 2.1600, accuracy: 80.6445%, tar: 0.1335 \n",
            "l0: 0.406223, l1: 0.417315, l2: 0.423594, l3: 0.461447, l4: 0.541823, l5: 0.655831, l6: 0.796907\n",
            "\n",
            "[epoch: 117/100000, batch: 816/1000, ite: 14602] train loss: 2.1639, accuracy: 85.1532%, tar: 0.1340 \n",
            "l0: 0.743300, l1: 0.758276, l2: 0.780015, l3: 0.809904, l4: 0.875761, l5: 0.967378, l6: 1.044908\n",
            "\n",
            "[epoch: 117/100000, batch: 824/1000, ite: 14603] train loss: 2.1720, accuracy: 79.2121%, tar: 0.1350 \n",
            "l0: 0.340072, l1: 0.307902, l2: 0.318139, l3: 0.359237, l4: 0.439474, l5: 0.557452, l6: 0.743896\n",
            "\n",
            "[epoch: 117/100000, batch: 832/1000, ite: 14604] train loss: 2.1747, accuracy: 85.8200%, tar: 0.1353 \n",
            "l0: 0.709024, l1: 0.689646, l2: 0.734064, l3: 0.824405, l4: 0.863657, l5: 0.864660, l6: 1.077489\n",
            "\n",
            "[epoch: 117/100000, batch: 840/1000, ite: 14605] train loss: 2.1826, accuracy: 82.1752%, tar: 0.1363 \n",
            "l0: 0.498592, l1: 0.524970, l2: 0.470420, l3: 0.458249, l4: 0.504782, l5: 0.647358, l6: 0.860440\n",
            "\n",
            "[epoch: 117/100000, batch: 848/1000, ite: 14606] train loss: 2.1869, accuracy: 81.9435%, tar: 0.1369 \n",
            "l0: 0.292698, l1: 0.278883, l2: 0.279935, l3: 0.282337, l4: 0.312901, l5: 0.372734, l6: 0.593699\n",
            "\n",
            "[epoch: 117/100000, batch: 856/1000, ite: 14607] train loss: 2.1883, accuracy: 87.6781%, tar: 0.1371 \n",
            "l0: 0.452413, l1: 0.442875, l2: 0.470664, l3: 0.492506, l4: 0.527388, l5: 0.595495, l6: 0.878782\n",
            "\n",
            "[epoch: 117/100000, batch: 864/1000, ite: 14608] train loss: 2.1926, accuracy: 82.3332%, tar: 0.1376 \n",
            "l0: 0.490663, l1: 0.508326, l2: 0.523515, l3: 0.549799, l4: 0.578660, l5: 0.652089, l6: 0.825888\n",
            "\n",
            "[epoch: 117/100000, batch: 872/1000, ite: 14609] train loss: 2.1971, accuracy: 82.2897%, tar: 0.1382 \n",
            "l0: 0.310511, l1: 0.322053, l2: 0.317523, l3: 0.332159, l4: 0.372533, l5: 0.488845, l6: 0.741561\n",
            "\n",
            "[epoch: 117/100000, batch: 880/1000, ite: 14610] train loss: 2.1994, accuracy: 84.2368%, tar: 0.1385 \n",
            "l0: 0.582235, l1: 0.561937, l2: 0.572473, l3: 0.608934, l4: 0.658306, l5: 0.795408, l6: 0.946093\n",
            "\n",
            "[epoch: 117/100000, batch: 888/1000, ite: 14611] train loss: 2.2051, accuracy: 79.7856%, tar: 0.1392 \n",
            "l0: 0.314984, l1: 0.314832, l2: 0.322600, l3: 0.353228, l4: 0.414431, l5: 0.533336, l6: 0.708355\n",
            "\n",
            "[epoch: 117/100000, batch: 896/1000, ite: 14612] train loss: 2.2074, accuracy: 85.6735%, tar: 0.1395 \n",
            "l0: 0.372109, l1: 0.341016, l2: 0.343867, l3: 0.364041, l4: 0.434841, l5: 0.545299, l6: 0.784536\n",
            "\n",
            "[epoch: 117/100000, batch: 904/1000, ite: 14613] train loss: 2.2104, accuracy: 84.7805%, tar: 0.1399 \n",
            "l0: 0.609368, l1: 0.577371, l2: 0.576911, l3: 0.577025, l4: 0.627671, l5: 0.685169, l6: 0.846702\n",
            "\n",
            "[epoch: 117/100000, batch: 912/1000, ite: 14614] train loss: 2.2154, accuracy: 81.5192%, tar: 0.1407 \n",
            "l0: 0.432045, l1: 0.441267, l2: 0.440604, l3: 0.456761, l4: 0.507509, l5: 0.605678, l6: 0.974259\n",
            "\n",
            "[epoch: 117/100000, batch: 920/1000, ite: 14615] train loss: 2.2197, accuracy: 82.0702%, tar: 0.1411 \n",
            "l0: 0.426952, l1: 0.428252, l2: 0.430219, l3: 0.449969, l4: 0.468867, l5: 0.559221, l6: 0.673963\n",
            "\n",
            "[epoch: 117/100000, batch: 928/1000, ite: 14616] train loss: 2.2228, accuracy: 84.8870%, tar: 0.1416 \n",
            "l0: 0.389294, l1: 0.387015, l2: 0.392159, l3: 0.414897, l4: 0.471176, l5: 0.597501, l6: 0.845784\n",
            "\n",
            "[epoch: 117/100000, batch: 936/1000, ite: 14617] train loss: 2.2261, accuracy: 86.1487%, tar: 0.1420 \n",
            "l0: 0.851305, l1: 0.849608, l2: 0.843012, l3: 0.853690, l4: 0.884531, l5: 1.043719, l6: 1.272488\n",
            "\n",
            "[epoch: 117/100000, batch: 944/1000, ite: 14618] train loss: 2.2353, accuracy: 77.3839%, tar: 0.1431 \n",
            "l0: 0.804884, l1: 0.803865, l2: 0.785800, l3: 0.804621, l4: 0.821962, l5: 0.926882, l6: 1.117646\n",
            "\n",
            "[epoch: 117/100000, batch: 952/1000, ite: 14619] train loss: 2.2433, accuracy: 79.2923%, tar: 0.1442 \n",
            "l0: 0.238248, l1: 0.227856, l2: 0.229256, l3: 0.262769, l4: 0.309864, l5: 0.431579, l6: 0.645470\n",
            "\n",
            "[epoch: 117/100000, batch: 960/1000, ite: 14620] train loss: 2.2445, accuracy: 88.1508%, tar: 0.1444 \n",
            "l0: 0.341797, l1: 0.335701, l2: 0.321700, l3: 0.331754, l4: 0.383337, l5: 0.477413, l6: 0.635655\n",
            "\n",
            "[epoch: 117/100000, batch: 968/1000, ite: 14621] train loss: 2.2465, accuracy: 87.9503%, tar: 0.1447 \n",
            "l0: 0.579445, l1: 0.580030, l2: 0.587611, l3: 0.616418, l4: 0.685393, l5: 0.768323, l6: 0.944864\n",
            "\n",
            "[epoch: 117/100000, batch: 976/1000, ite: 14622] train loss: 2.2521, accuracy: 83.0797%, tar: 0.1454 \n",
            "l0: 0.423692, l1: 0.420899, l2: 0.413148, l3: 0.434927, l4: 0.498369, l5: 0.585615, l6: 0.748645\n",
            "\n",
            "[epoch: 117/100000, batch: 984/1000, ite: 14623] train loss: 2.2555, accuracy: 84.0779%, tar: 0.1458 \n",
            "l0: 0.648701, l1: 0.646817, l2: 0.656291, l3: 0.693843, l4: 0.715748, l5: 0.769551, l6: 0.891362\n",
            "\n",
            "[epoch: 117/100000, batch: 992/1000, ite: 14624] train loss: 2.2614, accuracy: 80.8440%, tar: 0.1466 \n",
            "l0: 0.474588, l1: 0.478692, l2: 0.467050, l3: 0.491820, l4: 0.547899, l5: 0.614644, l6: 0.796999\n",
            "\n",
            "[epoch: 117/100000, batch: 1000/1000, ite: 14625] train loss: 2.2654, accuracy: 84.6620%, tar: 0.1472 \n",
            "l0: 0.322755, l1: 0.326156, l2: 0.316227, l3: 0.321925, l4: 0.378668, l5: 0.453870, l6: 0.566731\n",
            "\n",
            "[epoch: 118/100000, batch: 8/1000, ite: 14626] train loss: 2.2670, accuracy: 86.4514%, tar: 0.1474 \n",
            "l0: 0.551207, l1: 0.546863, l2: 0.545081, l3: 0.557310, l4: 0.564540, l5: 0.689903, l6: 0.773586\n",
            "\n",
            "[epoch: 118/100000, batch: 16/1000, ite: 14627] train loss: 2.2713, accuracy: 84.5573%, tar: 0.1481 \n",
            "l0: 0.371694, l1: 0.371643, l2: 0.380242, l3: 0.427864, l4: 0.514007, l5: 0.657217, l6: 0.863920\n",
            "\n",
            "[epoch: 118/100000, batch: 24/1000, ite: 14628] train loss: 2.2747, accuracy: 82.1154%, tar: 0.1484 \n",
            "l0: 0.344072, l1: 0.341385, l2: 0.345807, l3: 0.377301, l4: 0.410811, l5: 0.508742, l6: 0.744839\n",
            "\n",
            "[epoch: 118/100000, batch: 32/1000, ite: 14629] train loss: 2.2772, accuracy: 86.1641%, tar: 0.1487 \n",
            "l0: 0.498646, l1: 0.501988, l2: 0.503796, l3: 0.512165, l4: 0.507703, l5: 0.533585, l6: 0.671128\n",
            "\n",
            "[epoch: 118/100000, batch: 40/1000, ite: 14630] train loss: 2.2806, accuracy: 83.6413%, tar: 0.1493 \n",
            "l0: 0.244260, l1: 0.243268, l2: 0.250255, l3: 0.274613, l4: 0.321788, l5: 0.410670, l6: 0.597407\n",
            "\n",
            "[epoch: 118/100000, batch: 48/1000, ite: 14631] train loss: 2.2816, accuracy: 87.5693%, tar: 0.1495 \n",
            "l0: 0.608121, l1: 0.615907, l2: 0.605526, l3: 0.607831, l4: 0.672954, l5: 0.839463, l6: 0.931457\n",
            "\n",
            "[epoch: 118/100000, batch: 56/1000, ite: 14632] train loss: 2.2873, accuracy: 81.5637%, tar: 0.1502 \n",
            "l0: 0.436466, l1: 0.445862, l2: 0.466868, l3: 0.487424, l4: 0.524108, l5: 0.635111, l6: 0.810507\n",
            "\n",
            "[epoch: 118/100000, batch: 64/1000, ite: 14633] train loss: 2.2909, accuracy: 84.0015%, tar: 0.1506 \n",
            "l0: 0.269785, l1: 0.269449, l2: 0.271960, l3: 0.282625, l4: 0.319492, l5: 0.444243, l6: 0.711232\n",
            "\n",
            "[epoch: 118/100000, batch: 72/1000, ite: 14634] train loss: 2.2925, accuracy: 87.3615%, tar: 0.1508 \n",
            "l0: 0.351574, l1: 0.353414, l2: 0.357493, l3: 0.373924, l4: 0.409683, l5: 0.508074, l6: 0.748782\n",
            "\n",
            "[epoch: 118/100000, batch: 80/1000, ite: 14635] train loss: 2.2949, accuracy: 84.9950%, tar: 0.1511 \n",
            "l0: 0.145925, l1: 0.144122, l2: 0.154271, l3: 0.175655, l4: 0.229203, l5: 0.392139, l6: 0.629365\n",
            "\n",
            "[epoch: 118/100000, batch: 88/1000, ite: 14636] train loss: 2.2952, accuracy: 89.6085%, tar: 0.1511 \n",
            "l0: 0.427409, l1: 0.426116, l2: 0.433701, l3: 0.461263, l4: 0.493988, l5: 0.568205, l6: 0.699677\n",
            "\n",
            "[epoch: 118/100000, batch: 96/1000, ite: 14637] train loss: 2.2982, accuracy: 86.6337%, tar: 0.1516 \n",
            "l0: 0.243688, l1: 0.247211, l2: 0.249610, l3: 0.259594, l4: 0.276404, l5: 0.380430, l6: 0.580940\n",
            "\n",
            "[epoch: 118/100000, batch: 104/1000, ite: 14638] train loss: 2.2990, accuracy: 89.0076%, tar: 0.1517 \n",
            "l0: 0.557212, l1: 0.551835, l2: 0.533515, l3: 0.551691, l4: 0.575243, l5: 0.632562, l6: 0.830802\n",
            "\n",
            "[epoch: 118/100000, batch: 112/1000, ite: 14639] train loss: 2.3033, accuracy: 84.2395%, tar: 0.1523 \n",
            "l0: 0.283750, l1: 0.288661, l2: 0.287770, l3: 0.305607, l4: 0.373462, l5: 0.519216, l6: 0.778556\n",
            "\n",
            "[epoch: 118/100000, batch: 120/1000, ite: 14640] train loss: 2.3053, accuracy: 87.7709%, tar: 0.1525 \n",
            "l0: 0.520008, l1: 0.517748, l2: 0.505338, l3: 0.538721, l4: 0.569434, l5: 0.673428, l6: 0.874551\n",
            "\n",
            "[epoch: 118/100000, batch: 128/1000, ite: 14641] train loss: 2.3096, accuracy: 83.6545%, tar: 0.1531 \n",
            "l0: 0.288865, l1: 0.288098, l2: 0.290341, l3: 0.301231, l4: 0.350286, l5: 0.467791, l6: 0.723190\n",
            "\n",
            "[epoch: 118/100000, batch: 136/1000, ite: 14642] train loss: 2.3113, accuracy: 86.2706%, tar: 0.1533 \n",
            "l0: 0.439946, l1: 0.436965, l2: 0.442159, l3: 0.474661, l4: 0.510461, l5: 0.612609, l6: 0.713645\n",
            "\n",
            "[epoch: 118/100000, batch: 144/1000, ite: 14643] train loss: 2.3144, accuracy: 86.0909%, tar: 0.1538 \n",
            "l0: 0.405938, l1: 0.410572, l2: 0.413075, l3: 0.433289, l4: 0.467994, l5: 0.526345, l6: 0.654832\n",
            "\n",
            "[epoch: 118/100000, batch: 152/1000, ite: 14644] train loss: 2.3169, accuracy: 86.1542%, tar: 0.1542 \n",
            "l0: 0.273786, l1: 0.275249, l2: 0.281236, l3: 0.301828, l4: 0.336053, l5: 0.448668, l6: 0.580154\n",
            "\n",
            "[epoch: 118/100000, batch: 160/1000, ite: 14645] train loss: 2.3181, accuracy: 87.7403%, tar: 0.1544 \n",
            "l0: 0.255374, l1: 0.255435, l2: 0.266807, l3: 0.295663, l4: 0.362253, l5: 0.502654, l6: 0.717110\n",
            "\n",
            "[epoch: 118/100000, batch: 168/1000, ite: 14646] train loss: 2.3198, accuracy: 86.0456%, tar: 0.1545 \n",
            "l0: 0.278392, l1: 0.279311, l2: 0.286620, l3: 0.305181, l4: 0.375330, l5: 0.489153, l6: 0.744198\n",
            "\n",
            "[epoch: 118/100000, batch: 176/1000, ite: 14647] train loss: 2.3216, accuracy: 85.9592%, tar: 0.1547 \n",
            "l0: 0.414847, l1: 0.415222, l2: 0.424626, l3: 0.443195, l4: 0.488068, l5: 0.629552, l6: 0.887296\n",
            "\n",
            "[epoch: 118/100000, batch: 184/1000, ite: 14648] train loss: 2.3251, accuracy: 82.7413%, tar: 0.1551 \n",
            "l0: 0.321791, l1: 0.321099, l2: 0.327149, l3: 0.336501, l4: 0.385656, l5: 0.474586, l6: 0.792895\n",
            "\n",
            "[epoch: 118/100000, batch: 192/1000, ite: 14649] train loss: 2.3275, accuracy: 85.8282%, tar: 0.1554 \n",
            "l0: 0.350896, l1: 0.353624, l2: 0.360052, l3: 0.370401, l4: 0.395724, l5: 0.467631, l6: 0.659872\n",
            "\n",
            "[epoch: 118/100000, batch: 200/1000, ite: 14650] train loss: 2.3295, accuracy: 86.1215%, tar: 0.1557 \n",
            "l0: 0.325202, l1: 0.329242, l2: 0.339872, l3: 0.346615, l4: 0.389224, l5: 0.428197, l6: 0.706850\n",
            "\n",
            "[epoch: 118/100000, batch: 208/1000, ite: 14651] train loss: 2.3315, accuracy: 84.5709%, tar: 0.1559 \n",
            "l0: 0.357142, l1: 0.360358, l2: 0.368457, l3: 0.372612, l4: 0.425642, l5: 0.483879, l6: 0.670063\n",
            "\n",
            "[epoch: 118/100000, batch: 216/1000, ite: 14652] train loss: 2.3336, accuracy: 85.1090%, tar: 0.1562 \n",
            "l0: 0.309155, l1: 0.313823, l2: 0.322850, l3: 0.344553, l4: 0.384311, l5: 0.514048, l6: 0.798836\n",
            "\n",
            "[epoch: 118/100000, batch: 224/1000, ite: 14653] train loss: 2.3357, accuracy: 84.8171%, tar: 0.1565 \n",
            "l0: 0.213011, l1: 0.214093, l2: 0.218151, l3: 0.227717, l4: 0.262988, l5: 0.347361, l6: 0.602050\n",
            "\n",
            "[epoch: 118/100000, batch: 232/1000, ite: 14654] train loss: 2.3362, accuracy: 88.6587%, tar: 0.1565 \n",
            "l0: 0.166827, l1: 0.168125, l2: 0.171004, l3: 0.200026, l4: 0.273821, l5: 0.388180, l6: 0.645979\n",
            "\n",
            "[epoch: 118/100000, batch: 240/1000, ite: 14655] train loss: 2.3368, accuracy: 88.6406%, tar: 0.1566 \n",
            "l0: 0.436023, l1: 0.444301, l2: 0.450809, l3: 0.464438, l4: 0.509244, l5: 0.578411, l6: 0.825584\n",
            "\n",
            "[epoch: 118/100000, batch: 248/1000, ite: 14656] train loss: 2.3402, accuracy: 81.7744%, tar: 0.1570 \n",
            "l0: 0.163557, l1: 0.166348, l2: 0.170504, l3: 0.190611, l4: 0.229154, l5: 0.314526, l6: 0.497417\n",
            "\n",
            "[epoch: 118/100000, batch: 256/1000, ite: 14657] train loss: 2.3401, accuracy: 90.4572%, tar: 0.1570 \n",
            "l0: 0.159291, l1: 0.160321, l2: 0.159977, l3: 0.187321, l4: 0.230872, l5: 0.304205, l6: 0.502448\n",
            "\n",
            "[epoch: 118/100000, batch: 264/1000, ite: 14658] train loss: 2.3399, accuracy: 90.1850%, tar: 0.1570 \n",
            "l0: 0.256521, l1: 0.254964, l2: 0.256202, l3: 0.275730, l4: 0.321385, l5: 0.426882, l6: 0.617903\n",
            "\n",
            "[epoch: 118/100000, batch: 272/1000, ite: 14659] train loss: 2.3410, accuracy: 88.3172%, tar: 0.1572 \n",
            "l0: 0.121219, l1: 0.120598, l2: 0.130927, l3: 0.162527, l4: 0.212401, l5: 0.310712, l6: 0.522659\n",
            "\n",
            "[epoch: 118/100000, batch: 280/1000, ite: 14660] train loss: 2.3406, accuracy: 91.2816%, tar: 0.1571 \n",
            "l0: 0.340982, l1: 0.341791, l2: 0.354139, l3: 0.391051, l4: 0.437779, l5: 0.569064, l6: 0.800187\n",
            "\n",
            "[epoch: 118/100000, batch: 288/1000, ite: 14661] train loss: 2.3432, accuracy: 87.8663%, tar: 0.1574 \n",
            "l0: 0.227546, l1: 0.233664, l2: 0.241284, l3: 0.267620, l4: 0.335042, l5: 0.463710, l6: 0.696440\n",
            "\n",
            "[epoch: 118/100000, batch: 296/1000, ite: 14662] train loss: 2.3443, accuracy: 88.7092%, tar: 0.1575 \n",
            "l0: 0.453164, l1: 0.455434, l2: 0.461027, l3: 0.484586, l4: 0.517573, l5: 0.533699, l6: 0.604917\n",
            "\n",
            "[epoch: 118/100000, batch: 304/1000, ite: 14663] train loss: 2.3470, accuracy: 87.9681%, tar: 0.1579 \n",
            "l0: 0.259524, l1: 0.255699, l2: 0.264625, l3: 0.284089, l4: 0.312779, l5: 0.396195, l6: 0.600732\n",
            "\n",
            "[epoch: 118/100000, batch: 312/1000, ite: 14664] train loss: 2.3480, accuracy: 89.9766%, tar: 0.1581 \n",
            "l0: 0.274150, l1: 0.274816, l2: 0.282244, l3: 0.297309, l4: 0.342766, l5: 0.439239, l6: 0.674778\n",
            "\n",
            "[epoch: 118/100000, batch: 320/1000, ite: 14665] train loss: 2.3494, accuracy: 87.4270%, tar: 0.1583 \n",
            "l0: 0.330250, l1: 0.331978, l2: 0.327881, l3: 0.343948, l4: 0.418762, l5: 0.563324, l6: 0.815546\n",
            "\n",
            "[epoch: 118/100000, batch: 328/1000, ite: 14666] train loss: 2.3518, accuracy: 86.4924%, tar: 0.1585 \n",
            "l0: 0.252630, l1: 0.251957, l2: 0.259147, l3: 0.279116, l4: 0.327060, l5: 0.432169, l6: 0.665260\n",
            "\n",
            "[epoch: 118/100000, batch: 336/1000, ite: 14667] train loss: 2.3530, accuracy: 88.0654%, tar: 0.1587 \n",
            "l0: 0.173233, l1: 0.172666, l2: 0.176732, l3: 0.198389, l4: 0.251844, l5: 0.341131, l6: 0.563195\n",
            "\n",
            "[epoch: 118/100000, batch: 344/1000, ite: 14668] train loss: 2.3532, accuracy: 89.9024%, tar: 0.1587 \n",
            "l0: 0.397359, l1: 0.397936, l2: 0.399526, l3: 0.422171, l4: 0.471904, l5: 0.563812, l6: 0.733651\n",
            "\n",
            "[epoch: 118/100000, batch: 352/1000, ite: 14669] train loss: 2.3558, accuracy: 84.8456%, tar: 0.1590 \n",
            "l0: 0.213665, l1: 0.213350, l2: 0.219769, l3: 0.229968, l4: 0.251690, l5: 0.307540, l6: 0.434526\n",
            "\n",
            "[epoch: 118/100000, batch: 360/1000, ite: 14670] train loss: 2.3558, accuracy: 90.4328%, tar: 0.1591 \n",
            "l0: 0.312853, l1: 0.316148, l2: 0.310968, l3: 0.349092, l4: 0.381029, l5: 0.460242, l6: 0.673904\n",
            "\n",
            "[epoch: 118/100000, batch: 368/1000, ite: 14671] train loss: 2.3575, accuracy: 87.8945%, tar: 0.1593 \n",
            "l0: 0.195361, l1: 0.193959, l2: 0.202175, l3: 0.231846, l4: 0.263597, l5: 0.351166, l6: 0.563561\n",
            "\n",
            "[epoch: 118/100000, batch: 376/1000, ite: 14672] train loss: 2.3578, accuracy: 89.7836%, tar: 0.1594 \n",
            "l0: 0.220976, l1: 0.220228, l2: 0.234001, l3: 0.284578, l4: 0.363934, l5: 0.490032, l6: 0.816369\n",
            "\n",
            "[epoch: 118/100000, batch: 384/1000, ite: 14673] train loss: 2.3594, accuracy: 86.6097%, tar: 0.1595 \n",
            "l0: 0.319035, l1: 0.318301, l2: 0.312597, l3: 0.334656, l4: 0.374870, l5: 0.497137, l6: 0.728898\n",
            "\n",
            "[epoch: 118/100000, batch: 392/1000, ite: 14674] train loss: 2.3613, accuracy: 87.1839%, tar: 0.1597 \n",
            "l0: 0.460549, l1: 0.461792, l2: 0.464247, l3: 0.487565, l4: 0.533949, l5: 0.619172, l6: 0.757722\n",
            "\n",
            "[epoch: 118/100000, batch: 400/1000, ite: 14675] train loss: 2.3645, accuracy: 85.8008%, tar: 0.1602 \n",
            "l0: 0.222082, l1: 0.223003, l2: 0.232811, l3: 0.282159, l4: 0.354408, l5: 0.455754, l6: 0.686265\n",
            "\n",
            "[epoch: 118/100000, batch: 408/1000, ite: 14676] train loss: 2.3657, accuracy: 88.1249%, tar: 0.1603 \n",
            "l0: 0.211223, l1: 0.213323, l2: 0.210895, l3: 0.232405, l4: 0.303270, l5: 0.433253, l6: 0.663916\n",
            "\n",
            "[epoch: 118/100000, batch: 416/1000, ite: 14677] train loss: 2.3665, accuracy: 89.6973%, tar: 0.1603 \n",
            "l0: 0.401296, l1: 0.405318, l2: 0.401990, l3: 0.411938, l4: 0.451440, l5: 0.540394, l6: 0.730793\n",
            "\n",
            "[epoch: 118/100000, batch: 424/1000, ite: 14678] train loss: 2.3690, accuracy: 85.3195%, tar: 0.1607 \n",
            "l0: 0.292138, l1: 0.291980, l2: 0.294490, l3: 0.300826, l4: 0.321674, l5: 0.407982, l6: 0.630189\n",
            "\n",
            "[epoch: 118/100000, batch: 432/1000, ite: 14679] train loss: 2.3701, accuracy: 88.1067%, tar: 0.1609 \n",
            "l0: 0.229033, l1: 0.230147, l2: 0.229668, l3: 0.243981, l4: 0.276742, l5: 0.378090, l6: 0.572560\n",
            "\n",
            "[epoch: 118/100000, batch: 440/1000, ite: 14680] train loss: 2.3707, accuracy: 89.5255%, tar: 0.1610 \n",
            "l0: 0.222999, l1: 0.223754, l2: 0.226952, l3: 0.265768, l4: 0.332844, l5: 0.434838, l6: 0.629970\n",
            "\n",
            "[epoch: 118/100000, batch: 448/1000, ite: 14681] train loss: 2.3716, accuracy: 88.5738%, tar: 0.1611 \n",
            "l0: 0.219783, l1: 0.224312, l2: 0.230623, l3: 0.271721, l4: 0.336292, l5: 0.432920, l6: 0.605062\n",
            "\n",
            "[epoch: 118/100000, batch: 456/1000, ite: 14682] train loss: 2.3724, accuracy: 89.0881%, tar: 0.1612 \n",
            "l0: 0.196783, l1: 0.197624, l2: 0.202424, l3: 0.223561, l4: 0.256813, l5: 0.344328, l6: 0.519174\n",
            "\n",
            "[epoch: 118/100000, batch: 464/1000, ite: 14683] train loss: 2.3725, accuracy: 88.9887%, tar: 0.1612 \n",
            "l0: 0.292216, l1: 0.287582, l2: 0.292010, l3: 0.304503, l4: 0.331721, l5: 0.417636, l6: 0.684491\n",
            "\n",
            "[epoch: 118/100000, batch: 472/1000, ite: 14684] train loss: 2.3739, accuracy: 88.6863%, tar: 0.1614 \n",
            "l0: 0.244784, l1: 0.245329, l2: 0.253812, l3: 0.271755, l4: 0.329113, l5: 0.400315, l6: 0.627680\n",
            "\n",
            "[epoch: 118/100000, batch: 480/1000, ite: 14685] train loss: 2.3749, accuracy: 87.9307%, tar: 0.1615 \n",
            "l0: 0.146982, l1: 0.148495, l2: 0.153359, l3: 0.186675, l4: 0.257079, l5: 0.375014, l6: 0.674840\n",
            "\n",
            "[epoch: 118/100000, batch: 488/1000, ite: 14686] train loss: 2.3753, accuracy: 90.7528%, tar: 0.1615 \n",
            "l0: 0.107593, l1: 0.108463, l2: 0.111346, l3: 0.127567, l4: 0.153940, l5: 0.226772, l6: 0.400082\n",
            "\n",
            "[epoch: 118/100000, batch: 496/1000, ite: 14687] train loss: 2.3742, accuracy: 92.6421%, tar: 0.1614 \n",
            "l0: 0.187291, l1: 0.188385, l2: 0.195582, l3: 0.218153, l4: 0.257625, l5: 0.331484, l6: 0.616718\n",
            "\n",
            "[epoch: 118/100000, batch: 504/1000, ite: 14688] train loss: 2.3746, accuracy: 88.5670%, tar: 0.1615 \n",
            "l0: 0.309186, l1: 0.311821, l2: 0.311965, l3: 0.322140, l4: 0.357500, l5: 0.389402, l6: 0.549226\n",
            "\n",
            "[epoch: 118/100000, batch: 512/1000, ite: 14689] train loss: 2.3757, accuracy: 88.2385%, tar: 0.1617 \n",
            "l0: 0.229858, l1: 0.231207, l2: 0.242658, l3: 0.276711, l4: 0.346544, l5: 0.492802, l6: 0.849575\n",
            "\n",
            "[epoch: 118/100000, batch: 520/1000, ite: 14690] train loss: 2.3774, accuracy: 84.8920%, tar: 0.1618 \n",
            "l0: 0.144204, l1: 0.144937, l2: 0.148654, l3: 0.179586, l4: 0.243489, l5: 0.347594, l6: 0.586035\n",
            "\n",
            "[epoch: 118/100000, batch: 528/1000, ite: 14691] train loss: 2.3774, accuracy: 89.8500%, tar: 0.1618 \n",
            "l0: 0.192113, l1: 0.193990, l2: 0.196297, l3: 0.220953, l4: 0.284880, l5: 0.385907, l6: 0.559747\n",
            "\n",
            "[epoch: 118/100000, batch: 536/1000, ite: 14692] train loss: 2.3778, accuracy: 90.3878%, tar: 0.1618 \n",
            "l0: 0.191982, l1: 0.193044, l2: 0.198617, l3: 0.220747, l4: 0.264049, l5: 0.360183, l6: 0.583915\n",
            "\n",
            "[epoch: 118/100000, batch: 544/1000, ite: 14693] train loss: 2.3781, accuracy: 89.9613%, tar: 0.1618 \n",
            "l0: 0.258878, l1: 0.261660, l2: 0.267670, l3: 0.299670, l4: 0.371255, l5: 0.534788, l6: 0.830467\n",
            "\n",
            "[epoch: 118/100000, batch: 552/1000, ite: 14694] train loss: 2.3800, accuracy: 85.8512%, tar: 0.1620 \n",
            "l0: 0.177172, l1: 0.176969, l2: 0.183678, l3: 0.214321, l4: 0.287085, l5: 0.418262, l6: 0.643989\n",
            "\n",
            "[epoch: 118/100000, batch: 560/1000, ite: 14695] train loss: 2.3805, accuracy: 88.2676%, tar: 0.1620 \n",
            "l0: 0.129359, l1: 0.129883, l2: 0.138219, l3: 0.157424, l4: 0.194712, l5: 0.282408, l6: 0.477795\n",
            "\n",
            "[epoch: 118/100000, batch: 568/1000, ite: 14696] train loss: 2.3799, accuracy: 92.1682%, tar: 0.1620 \n",
            "l0: 0.236758, l1: 0.239301, l2: 0.249285, l3: 0.284961, l4: 0.347676, l5: 0.506905, l6: 0.703110\n",
            "\n",
            "[epoch: 118/100000, batch: 576/1000, ite: 14697] train loss: 2.3812, accuracy: 88.1477%, tar: 0.1621 \n",
            "l0: 0.375993, l1: 0.375196, l2: 0.383969, l3: 0.408575, l4: 0.443661, l5: 0.505865, l6: 0.711648\n",
            "\n",
            "[epoch: 118/100000, batch: 584/1000, ite: 14698] train loss: 2.3834, accuracy: 86.5934%, tar: 0.1624 \n",
            "l0: 0.249949, l1: 0.251348, l2: 0.258293, l3: 0.280696, l4: 0.340579, l5: 0.474104, l6: 0.746658\n",
            "\n",
            "[epoch: 118/100000, batch: 592/1000, ite: 14699] train loss: 2.3848, accuracy: 86.1970%, tar: 0.1625 \n",
            "l0: 0.159313, l1: 0.163833, l2: 0.173180, l3: 0.214487, l4: 0.337420, l5: 0.520795, l6: 0.714084\n",
            "\n",
            "[epoch: 118/100000, batch: 600/1000, ite: 14700] train loss: 2.3857, accuracy: 87.3380%, tar: 0.1625 \n",
            "l0: 0.263576, l1: 0.265147, l2: 0.274685, l3: 0.295710, l4: 0.347289, l5: 0.455107, l6: 0.660141\n",
            "\n",
            "[epoch: 118/100000, batch: 608/1000, ite: 14701] train loss: 2.3869, accuracy: 88.1331%, tar: 0.1626 \n",
            "l0: 0.180245, l1: 0.181989, l2: 0.190573, l3: 0.223159, l4: 0.287672, l5: 0.389025, l6: 0.626679\n",
            "\n",
            "[epoch: 118/100000, batch: 616/1000, ite: 14702] train loss: 2.3874, accuracy: 88.9982%, tar: 0.1627 \n",
            "l0: 0.176873, l1: 0.179268, l2: 0.193459, l3: 0.223322, l4: 0.274350, l5: 0.393532, l6: 0.611785\n",
            "\n",
            "[epoch: 118/100000, batch: 624/1000, ite: 14703] train loss: 2.3878, accuracy: 88.8517%, tar: 0.1627 \n",
            "l0: 0.310105, l1: 0.316033, l2: 0.323173, l3: 0.354698, l4: 0.457044, l5: 0.627652, l6: 0.831791\n",
            "\n",
            "[epoch: 118/100000, batch: 632/1000, ite: 14704] train loss: 2.3901, accuracy: 87.5484%, tar: 0.1629 \n",
            "l0: 0.162529, l1: 0.165000, l2: 0.173669, l3: 0.208173, l4: 0.290786, l5: 0.398513, l6: 0.569160\n",
            "\n",
            "[epoch: 118/100000, batch: 640/1000, ite: 14705] train loss: 2.3903, accuracy: 89.1292%, tar: 0.1629 \n",
            "l0: 0.172510, l1: 0.175268, l2: 0.181591, l3: 0.195150, l4: 0.248747, l5: 0.362770, l6: 0.563572\n",
            "\n",
            "[epoch: 118/100000, batch: 648/1000, ite: 14706] train loss: 2.3904, accuracy: 90.6837%, tar: 0.1629 \n",
            "l0: 0.129887, l1: 0.131189, l2: 0.144202, l3: 0.178023, l4: 0.260716, l5: 0.394254, l6: 0.708100\n",
            "\n",
            "[epoch: 118/100000, batch: 656/1000, ite: 14707] train loss: 2.3908, accuracy: 87.1813%, tar: 0.1629 \n",
            "l0: 0.241674, l1: 0.242832, l2: 0.253346, l3: 0.277360, l4: 0.320683, l5: 0.423605, l6: 0.593098\n",
            "\n",
            "[epoch: 118/100000, batch: 664/1000, ite: 14708] train loss: 2.3916, accuracy: 89.2964%, tar: 0.1630 \n",
            "l0: 0.153684, l1: 0.155156, l2: 0.164133, l3: 0.192981, l4: 0.248131, l5: 0.330001, l6: 0.534573\n",
            "\n",
            "[epoch: 118/100000, batch: 672/1000, ite: 14709] train loss: 2.3915, accuracy: 89.8987%, tar: 0.1630 \n",
            "l0: 0.276491, l1: 0.278905, l2: 0.289700, l3: 0.305514, l4: 0.325409, l5: 0.398405, l6: 0.520204\n",
            "\n",
            "[epoch: 118/100000, batch: 680/1000, ite: 14710] train loss: 2.3923, accuracy: 88.2320%, tar: 0.1631 \n",
            "l0: 0.212416, l1: 0.217271, l2: 0.227562, l3: 0.258893, l4: 0.331080, l5: 0.469562, l6: 0.727233\n",
            "\n",
            "[epoch: 118/100000, batch: 688/1000, ite: 14711] train loss: 2.3934, accuracy: 86.0566%, tar: 0.1632 \n",
            "l0: 0.232754, l1: 0.237799, l2: 0.245919, l3: 0.269603, l4: 0.324604, l5: 0.404872, l6: 0.563214\n",
            "\n",
            "[epoch: 118/100000, batch: 696/1000, ite: 14712] train loss: 2.3941, accuracy: 90.3198%, tar: 0.1633 \n",
            "l0: 0.191638, l1: 0.191766, l2: 0.199332, l3: 0.224018, l4: 0.256608, l5: 0.338941, l6: 0.512982\n",
            "\n",
            "[epoch: 118/100000, batch: 704/1000, ite: 14713] train loss: 2.3941, accuracy: 91.6215%, tar: 0.1633 \n",
            "l0: 0.212357, l1: 0.214607, l2: 0.225979, l3: 0.257229, l4: 0.329437, l5: 0.457869, l6: 0.656009\n",
            "\n",
            "[epoch: 118/100000, batch: 712/1000, ite: 14714] train loss: 2.3950, accuracy: 88.1690%, tar: 0.1634 \n",
            "l0: 0.229152, l1: 0.231024, l2: 0.241758, l3: 0.275065, l4: 0.338742, l5: 0.453435, l6: 0.667366\n",
            "\n",
            "[epoch: 118/100000, batch: 720/1000, ite: 14715] train loss: 2.3960, accuracy: 89.8691%, tar: 0.1635 \n",
            "l0: 0.261104, l1: 0.265668, l2: 0.273208, l3: 0.293164, l4: 0.336615, l5: 0.378031, l6: 0.550916\n",
            "\n",
            "[epoch: 118/100000, batch: 728/1000, ite: 14716] train loss: 2.3967, accuracy: 89.1956%, tar: 0.1636 \n",
            "l0: 0.420456, l1: 0.430596, l2: 0.446086, l3: 0.479850, l4: 0.556446, l5: 0.706432, l6: 0.817699\n",
            "\n",
            "[epoch: 118/100000, batch: 736/1000, ite: 14717] train loss: 2.3999, accuracy: 86.6990%, tar: 0.1640 \n",
            "l0: 0.138727, l1: 0.134278, l2: 0.145381, l3: 0.173870, l4: 0.213949, l5: 0.279249, l6: 0.483881\n",
            "\n",
            "[epoch: 118/100000, batch: 744/1000, ite: 14718] train loss: 2.3994, accuracy: 92.0969%, tar: 0.1639 \n",
            "l0: 0.196589, l1: 0.199987, l2: 0.207319, l3: 0.228776, l4: 0.271621, l5: 0.356206, l6: 0.542656\n",
            "\n",
            "[epoch: 118/100000, batch: 752/1000, ite: 14719] train loss: 2.3996, accuracy: 89.0905%, tar: 0.1640 \n",
            "l0: 0.134216, l1: 0.133556, l2: 0.138673, l3: 0.157045, l4: 0.212702, l5: 0.317561, l6: 0.471269\n",
            "\n",
            "[epoch: 118/100000, batch: 760/1000, ite: 14720] train loss: 2.3992, accuracy: 91.0005%, tar: 0.1640 \n",
            "l0: 0.322161, l1: 0.327887, l2: 0.336905, l3: 0.352606, l4: 0.376403, l5: 0.445440, l6: 0.544002\n",
            "\n",
            "[epoch: 118/100000, batch: 768/1000, ite: 14721] train loss: 2.4004, accuracy: 89.5508%, tar: 0.1642 \n",
            "l0: 0.534575, l1: 0.532565, l2: 0.547409, l3: 0.562873, l4: 0.611878, l5: 0.600618, l6: 0.742164\n",
            "\n",
            "[epoch: 118/100000, batch: 776/1000, ite: 14722] train loss: 2.4039, accuracy: 87.0346%, tar: 0.1647 \n",
            "l0: 0.153484, l1: 0.156077, l2: 0.161199, l3: 0.177140, l4: 0.223755, l5: 0.297026, l6: 0.599756\n",
            "\n",
            "[epoch: 118/100000, batch: 784/1000, ite: 14723] train loss: 2.4038, accuracy: 90.3156%, tar: 0.1647 \n",
            "l0: 0.197140, l1: 0.199816, l2: 0.214176, l3: 0.244656, l4: 0.293915, l5: 0.410314, l6: 0.665159\n",
            "\n",
            "[epoch: 118/100000, batch: 792/1000, ite: 14724] train loss: 2.4045, accuracy: 90.0498%, tar: 0.1647 \n",
            "l0: 0.185753, l1: 0.189202, l2: 0.194909, l3: 0.218851, l4: 0.260192, l5: 0.341342, l6: 0.463007\n",
            "\n",
            "[epoch: 118/100000, batch: 800/1000, ite: 14725] train loss: 2.4044, accuracy: 90.4337%, tar: 0.1647 \n",
            "l0: 0.241592, l1: 0.245971, l2: 0.258653, l3: 0.285627, l4: 0.348028, l5: 0.477216, l6: 0.719929\n",
            "\n",
            "[epoch: 118/100000, batch: 808/1000, ite: 14726] train loss: 2.4057, accuracy: 87.0155%, tar: 0.1648 \n",
            "l0: 0.348620, l1: 0.351007, l2: 0.358167, l3: 0.392729, l4: 0.452481, l5: 0.518223, l6: 0.641569\n",
            "\n",
            "[epoch: 118/100000, batch: 816/1000, ite: 14727] train loss: 2.4075, accuracy: 86.8633%, tar: 0.1651 \n",
            "l0: 0.244824, l1: 0.243258, l2: 0.252504, l3: 0.284766, l4: 0.372001, l5: 0.511421, l6: 0.838444\n",
            "\n",
            "[epoch: 118/100000, batch: 824/1000, ite: 14728] train loss: 2.4091, accuracy: 85.8329%, tar: 0.1652 \n",
            "l0: 0.157657, l1: 0.158560, l2: 0.170135, l3: 0.204780, l4: 0.259726, l5: 0.393541, l6: 0.608413\n",
            "\n",
            "[epoch: 118/100000, batch: 832/1000, ite: 14729] train loss: 2.4093, accuracy: 89.7932%, tar: 0.1652 \n",
            "l0: 0.109610, l1: 0.110985, l2: 0.115606, l3: 0.141995, l4: 0.193775, l5: 0.268797, l6: 0.500519\n",
            "\n",
            "[epoch: 118/100000, batch: 840/1000, ite: 14730] train loss: 2.4087, accuracy: 91.2719%, tar: 0.1651 \n",
            "l0: 0.177404, l1: 0.178718, l2: 0.185211, l3: 0.206823, l4: 0.258950, l5: 0.344853, l6: 0.579333\n",
            "\n",
            "[epoch: 118/100000, batch: 848/1000, ite: 14731] train loss: 2.4088, accuracy: 89.3660%, tar: 0.1651 \n",
            "l0: 0.157031, l1: 0.157434, l2: 0.164513, l3: 0.191613, l4: 0.245398, l5: 0.357559, l6: 0.548939\n",
            "\n",
            "[epoch: 118/100000, batch: 856/1000, ite: 14732] train loss: 2.4088, accuracy: 89.4593%, tar: 0.1651 \n",
            "l0: 0.152285, l1: 0.153056, l2: 0.165032, l3: 0.202659, l4: 0.261842, l5: 0.375536, l6: 0.616788\n",
            "\n",
            "[epoch: 118/100000, batch: 864/1000, ite: 14733] train loss: 2.4090, accuracy: 89.8549%, tar: 0.1651 \n",
            "l0: 0.274562, l1: 0.274238, l2: 0.284797, l3: 0.301253, l4: 0.343495, l5: 0.456847, l6: 0.796655\n",
            "\n",
            "[epoch: 118/100000, batch: 872/1000, ite: 14734] train loss: 2.4106, accuracy: 86.8633%, tar: 0.1653 \n",
            "l0: 0.210405, l1: 0.209802, l2: 0.217181, l3: 0.238783, l4: 0.278606, l5: 0.379453, l6: 0.583156\n",
            "\n",
            "[epoch: 118/100000, batch: 880/1000, ite: 14735] train loss: 2.4110, accuracy: 89.7554%, tar: 0.1653 \n",
            "l0: 0.178103, l1: 0.180089, l2: 0.190774, l3: 0.223117, l4: 0.286577, l5: 0.400546, l6: 0.642271\n",
            "\n",
            "[epoch: 118/100000, batch: 888/1000, ite: 14736] train loss: 2.4114, accuracy: 88.6219%, tar: 0.1653 \n",
            "l0: 0.250314, l1: 0.253613, l2: 0.261100, l3: 0.290244, l4: 0.329597, l5: 0.418071, l6: 0.558679\n",
            "\n",
            "[epoch: 118/100000, batch: 896/1000, ite: 14737] train loss: 2.4122, accuracy: 88.7796%, tar: 0.1655 \n",
            "l0: 0.237881, l1: 0.239472, l2: 0.249696, l3: 0.274254, l4: 0.310200, l5: 0.410986, l6: 0.700899\n",
            "\n",
            "[epoch: 118/100000, batch: 904/1000, ite: 14738] train loss: 2.4132, accuracy: 87.6159%, tar: 0.1656 \n",
            "l0: 0.301956, l1: 0.305777, l2: 0.311987, l3: 0.330530, l4: 0.403331, l5: 0.483981, l6: 0.718774\n",
            "\n",
            "[epoch: 118/100000, batch: 912/1000, ite: 14739] train loss: 2.4148, accuracy: 87.9025%, tar: 0.1657 \n",
            "l0: 0.138088, l1: 0.140812, l2: 0.150279, l3: 0.177761, l4: 0.233990, l5: 0.362504, l6: 0.608266\n",
            "\n",
            "[epoch: 118/100000, batch: 920/1000, ite: 14740] train loss: 2.4147, accuracy: 89.7694%, tar: 0.1657 \n",
            "l0: 0.373473, l1: 0.377185, l2: 0.383463, l3: 0.408095, l4: 0.434981, l5: 0.559948, l6: 0.817206\n",
            "\n",
            "[epoch: 118/100000, batch: 928/1000, ite: 14741] train loss: 2.4172, accuracy: 82.9753%, tar: 0.1660 \n",
            "l0: 0.130278, l1: 0.131415, l2: 0.139402, l3: 0.166600, l4: 0.230217, l5: 0.323086, l6: 0.528790\n",
            "\n",
            "[epoch: 118/100000, batch: 936/1000, ite: 14742] train loss: 2.4168, accuracy: 90.8522%, tar: 0.1659 \n",
            "l0: 0.207578, l1: 0.208702, l2: 0.217856, l3: 0.245888, l4: 0.307252, l5: 0.399692, l6: 0.628878\n",
            "\n",
            "[epoch: 118/100000, batch: 944/1000, ite: 14743] train loss: 2.4174, accuracy: 88.7953%, tar: 0.1660 \n",
            "l0: 0.168046, l1: 0.169029, l2: 0.175597, l3: 0.205557, l4: 0.280445, l5: 0.408610, l6: 0.550385\n",
            "\n",
            "[epoch: 118/100000, batch: 952/1000, ite: 14744] train loss: 2.4175, accuracy: 88.4605%, tar: 0.1660 \n",
            "l0: 0.225792, l1: 0.226479, l2: 0.230663, l3: 0.249759, l4: 0.277151, l5: 0.366711, l6: 0.543436\n",
            "\n",
            "[epoch: 118/100000, batch: 960/1000, ite: 14745] train loss: 2.4179, accuracy: 88.9439%, tar: 0.1661 \n",
            "l0: 0.157615, l1: 0.159619, l2: 0.163282, l3: 0.189365, l4: 0.234931, l5: 0.356889, l6: 0.627319\n",
            "\n",
            "[epoch: 118/100000, batch: 968/1000, ite: 14746] train loss: 2.4181, accuracy: 88.4377%, tar: 0.1661 \n",
            "l0: 0.187351, l1: 0.193882, l2: 0.205280, l3: 0.231266, l4: 0.276630, l5: 0.345371, l6: 0.573729\n",
            "\n",
            "[epoch: 118/100000, batch: 976/1000, ite: 14747] train loss: 2.4183, accuracy: 90.2614%, tar: 0.1661 \n",
            "l0: 0.157262, l1: 0.158525, l2: 0.167256, l3: 0.196851, l4: 0.252140, l5: 0.368630, l6: 0.597168\n",
            "\n",
            "[epoch: 118/100000, batch: 984/1000, ite: 14748] train loss: 2.4184, accuracy: 89.6551%, tar: 0.1661 \n",
            "l0: 0.201926, l1: 0.206325, l2: 0.213487, l3: 0.237579, l4: 0.314612, l5: 0.431098, l6: 0.625887\n",
            "\n",
            "[epoch: 118/100000, batch: 992/1000, ite: 14749] train loss: 2.4190, accuracy: 89.0854%, tar: 0.1661 \n",
            "l0: 0.191921, l1: 0.196581, l2: 0.205095, l3: 0.235957, l4: 0.296431, l5: 0.403493, l6: 0.625156\n",
            "\n",
            "[epoch: 118/100000, batch: 1000/1000, ite: 14750] train loss: 2.4195, accuracy: 87.9898%, tar: 0.1662 \n",
            "l0: 0.312110, l1: 0.314570, l2: 0.324265, l3: 0.365973, l4: 0.452995, l5: 0.649793, l6: 0.891236\n",
            "\n",
            "[epoch: 119/100000, batch: 8/1000, ite: 14751] train loss: 2.4220, accuracy: 83.0530%, tar: 0.1664 \n",
            "l0: 0.140239, l1: 0.142564, l2: 0.150282, l3: 0.167559, l4: 0.194748, l5: 0.272027, l6: 0.456250\n",
            "\n",
            "[epoch: 119/100000, batch: 16/1000, ite: 14752] train loss: 2.4214, accuracy: 92.4310%, tar: 0.1663 \n",
            "l0: 0.148834, l1: 0.150043, l2: 0.162422, l3: 0.202987, l4: 0.288188, l5: 0.453122, l6: 0.741450\n",
            "\n",
            "[epoch: 119/100000, batch: 24/1000, ite: 14753] train loss: 2.4221, accuracy: 88.6079%, tar: 0.1663 \n",
            "l0: 0.135755, l1: 0.139002, l2: 0.146353, l3: 0.177511, l4: 0.238223, l5: 0.339673, l6: 0.539156\n",
            "\n",
            "[epoch: 119/100000, batch: 32/1000, ite: 14754] train loss: 2.4218, accuracy: 89.9432%, tar: 0.1663 \n",
            "l0: 0.167041, l1: 0.169568, l2: 0.176290, l3: 0.207298, l4: 0.256287, l5: 0.366538, l6: 0.531975\n",
            "\n",
            "[epoch: 119/100000, batch: 40/1000, ite: 14755] train loss: 2.4218, accuracy: 90.1034%, tar: 0.1663 \n",
            "l0: 0.118092, l1: 0.119287, l2: 0.128847, l3: 0.144480, l4: 0.183931, l5: 0.289555, l6: 0.481993\n",
            "\n",
            "[epoch: 119/100000, batch: 48/1000, ite: 14756] train loss: 2.4212, accuracy: 90.1573%, tar: 0.1662 \n",
            "l0: 0.256671, l1: 0.258098, l2: 0.267249, l3: 0.303649, l4: 0.384239, l5: 0.542623, l6: 0.813756\n",
            "\n",
            "[epoch: 119/100000, batch: 56/1000, ite: 14757] train loss: 2.4228, accuracy: 86.5454%, tar: 0.1663 \n",
            "l0: 0.171075, l1: 0.179617, l2: 0.186405, l3: 0.205103, l4: 0.262970, l5: 0.354743, l6: 0.603188\n",
            "\n",
            "[epoch: 119/100000, batch: 64/1000, ite: 14758] train loss: 2.4230, accuracy: 90.1502%, tar: 0.1663 \n",
            "l0: 0.177493, l1: 0.184535, l2: 0.192632, l3: 0.212387, l4: 0.266363, l5: 0.329821, l6: 0.493077\n",
            "\n",
            "[epoch: 119/100000, batch: 72/1000, ite: 14759] train loss: 2.4230, accuracy: 89.6144%, tar: 0.1663 \n",
            "l0: 0.113923, l1: 0.115640, l2: 0.121159, l3: 0.136025, l4: 0.179755, l5: 0.256131, l6: 0.422623\n",
            "\n",
            "[epoch: 119/100000, batch: 80/1000, ite: 14760] train loss: 2.4221, accuracy: 91.8628%, tar: 0.1663 \n",
            "l0: 0.117392, l1: 0.118056, l2: 0.127414, l3: 0.155244, l4: 0.214418, l5: 0.289175, l6: 0.477354\n",
            "\n",
            "[epoch: 119/100000, batch: 88/1000, ite: 14761] train loss: 2.4215, accuracy: 90.4336%, tar: 0.1662 \n",
            "l0: 0.149424, l1: 0.151257, l2: 0.161013, l3: 0.199973, l4: 0.283543, l5: 0.446579, l6: 0.777972\n",
            "\n",
            "[epoch: 119/100000, batch: 96/1000, ite: 14762] train loss: 2.4223, accuracy: 89.4901%, tar: 0.1662 \n",
            "l0: 0.157518, l1: 0.160842, l2: 0.169175, l3: 0.196449, l4: 0.261125, l5: 0.396169, l6: 0.714542\n",
            "\n",
            "[epoch: 119/100000, batch: 104/1000, ite: 14763] train loss: 2.4228, accuracy: 88.4653%, tar: 0.1662 \n",
            "l0: 0.173854, l1: 0.176739, l2: 0.185782, l3: 0.214902, l4: 0.285335, l5: 0.432913, l6: 0.689804\n",
            "\n",
            "[epoch: 119/100000, batch: 112/1000, ite: 14764] train loss: 2.4234, accuracy: 88.9017%, tar: 0.1662 \n",
            "l0: 0.121320, l1: 0.120221, l2: 0.128058, l3: 0.162083, l4: 0.215088, l5: 0.316212, l6: 0.510997\n",
            "\n",
            "[epoch: 119/100000, batch: 120/1000, ite: 14765] train loss: 2.4229, accuracy: 92.2095%, tar: 0.1661 \n",
            "l0: 0.135460, l1: 0.135630, l2: 0.147060, l3: 0.183468, l4: 0.259525, l5: 0.412199, l6: 0.677997\n",
            "\n",
            "[epoch: 119/100000, batch: 128/1000, ite: 14766] train loss: 2.4232, accuracy: 89.5345%, tar: 0.1661 \n",
            "l0: 0.140148, l1: 0.142351, l2: 0.152127, l3: 0.177609, l4: 0.221689, l5: 0.319522, l6: 0.497873\n",
            "\n",
            "[epoch: 119/100000, batch: 136/1000, ite: 14767] train loss: 2.4229, accuracy: 90.6990%, tar: 0.1660 \n",
            "l0: 0.158903, l1: 0.160024, l2: 0.171125, l3: 0.191825, l4: 0.259244, l5: 0.365933, l6: 0.558504\n",
            "\n",
            "[epoch: 119/100000, batch: 144/1000, ite: 14768] train loss: 2.4229, accuracy: 89.5747%, tar: 0.1660 \n",
            "l0: 0.135807, l1: 0.136710, l2: 0.145515, l3: 0.178108, l4: 0.255028, l5: 0.393652, l6: 0.623192\n",
            "\n",
            "[epoch: 119/100000, batch: 152/1000, ite: 14769] train loss: 2.4229, accuracy: 88.5072%, tar: 0.1660 \n",
            "l0: 0.133048, l1: 0.135309, l2: 0.146801, l3: 0.168035, l4: 0.230452, l5: 0.346527, l6: 0.562155\n",
            "\n",
            "[epoch: 119/100000, batch: 160/1000, ite: 14770] train loss: 2.4228, accuracy: 91.6557%, tar: 0.1660 \n",
            "l0: 0.212063, l1: 0.212260, l2: 0.220073, l3: 0.249123, l4: 0.281925, l5: 0.388731, l6: 0.622652\n",
            "\n",
            "[epoch: 119/100000, batch: 168/1000, ite: 14771] train loss: 2.4233, accuracy: 90.8155%, tar: 0.1660 \n",
            "l0: 0.128853, l1: 0.129289, l2: 0.137225, l3: 0.160707, l4: 0.214395, l5: 0.330238, l6: 0.594768\n",
            "\n",
            "[epoch: 119/100000, batch: 176/1000, ite: 14772] train loss: 2.4232, accuracy: 90.0528%, tar: 0.1660 \n",
            "l0: 0.194460, l1: 0.200585, l2: 0.213602, l3: 0.252324, l4: 0.312410, l5: 0.454166, l6: 0.706791\n",
            "\n",
            "[epoch: 119/100000, batch: 184/1000, ite: 14773] train loss: 2.4240, accuracy: 87.6569%, tar: 0.1660 \n",
            "l0: 0.112631, l1: 0.118108, l2: 0.128690, l3: 0.156983, l4: 0.222188, l5: 0.323981, l6: 0.542211\n",
            "\n",
            "[epoch: 119/100000, batch: 192/1000, ite: 14774] train loss: 2.4236, accuracy: 90.4349%, tar: 0.1659 \n",
            "l0: 0.131015, l1: 0.130864, l2: 0.143468, l3: 0.163397, l4: 0.214175, l5: 0.318434, l6: 0.548794\n",
            "\n",
            "[epoch: 119/100000, batch: 200/1000, ite: 14775] train loss: 2.4234, accuracy: 89.5496%, tar: 0.1659 \n",
            "l0: 0.169550, l1: 0.170956, l2: 0.183836, l3: 0.208518, l4: 0.283358, l5: 0.438965, l6: 0.650338\n",
            "\n",
            "[epoch: 119/100000, batch: 208/1000, ite: 14776] train loss: 2.4238, accuracy: 89.8829%, tar: 0.1659 \n",
            "l0: 0.128620, l1: 0.133372, l2: 0.141255, l3: 0.163278, l4: 0.209640, l5: 0.304369, l6: 0.533494\n",
            "\n",
            "[epoch: 119/100000, batch: 216/1000, ite: 14777] train loss: 2.4235, accuracy: 89.9078%, tar: 0.1658 \n",
            "l0: 0.085175, l1: 0.084971, l2: 0.097182, l3: 0.123727, l4: 0.183595, l5: 0.295155, l6: 0.497263\n",
            "\n",
            "[epoch: 119/100000, batch: 224/1000, ite: 14778] train loss: 2.4228, accuracy: 90.8518%, tar: 0.1657 \n",
            "l0: 0.199438, l1: 0.207746, l2: 0.212087, l3: 0.240191, l4: 0.288641, l5: 0.378853, l6: 0.550765\n",
            "\n",
            "[epoch: 119/100000, batch: 232/1000, ite: 14779] train loss: 2.4231, accuracy: 88.3725%, tar: 0.1658 \n",
            "l0: 0.135312, l1: 0.134753, l2: 0.146348, l3: 0.168606, l4: 0.219721, l5: 0.360634, l6: 0.641928\n",
            "\n",
            "[epoch: 119/100000, batch: 240/1000, ite: 14780] train loss: 2.4232, accuracy: 90.4602%, tar: 0.1657 \n",
            "l0: 0.195842, l1: 0.205247, l2: 0.210215, l3: 0.229036, l4: 0.292080, l5: 0.418346, l6: 0.633665\n",
            "\n",
            "[epoch: 119/100000, batch: 248/1000, ite: 14781] train loss: 2.4237, accuracy: 88.0825%, tar: 0.1658 \n",
            "l0: 0.151541, l1: 0.150956, l2: 0.160095, l3: 0.167863, l4: 0.208000, l5: 0.301396, l6: 0.491128\n",
            "\n",
            "[epoch: 119/100000, batch: 256/1000, ite: 14782] train loss: 2.4234, accuracy: 90.7019%, tar: 0.1658 \n",
            "l0: 0.179920, l1: 0.180426, l2: 0.193874, l3: 0.225347, l4: 0.310776, l5: 0.457174, l6: 0.686722\n",
            "\n",
            "[epoch: 119/100000, batch: 264/1000, ite: 14783] train loss: 2.4241, accuracy: 88.9537%, tar: 0.1658 \n",
            "l0: 0.190071, l1: 0.194441, l2: 0.206318, l3: 0.216162, l4: 0.256503, l5: 0.373596, l6: 0.520943\n",
            "\n",
            "[epoch: 119/100000, batch: 272/1000, ite: 14784] train loss: 2.4242, accuracy: 90.1799%, tar: 0.1658 \n",
            "l0: 0.202862, l1: 0.209960, l2: 0.215138, l3: 0.242929, l4: 0.299550, l5: 0.405664, l6: 0.636560\n",
            "\n",
            "[epoch: 119/100000, batch: 280/1000, ite: 14785] train loss: 2.4247, accuracy: 90.5309%, tar: 0.1659 \n",
            "l0: 0.288883, l1: 0.282309, l2: 0.296957, l3: 0.331069, l4: 0.382167, l5: 0.513070, l6: 0.765967\n",
            "\n",
            "[epoch: 119/100000, batch: 288/1000, ite: 14786] train loss: 2.4263, accuracy: 87.6032%, tar: 0.1660 \n",
            "l0: 0.215725, l1: 0.218117, l2: 0.228466, l3: 0.245667, l4: 0.282212, l5: 0.401640, l6: 0.631304\n",
            "\n",
            "[epoch: 119/100000, batch: 296/1000, ite: 14787] train loss: 2.4268, accuracy: 89.1204%, tar: 0.1661 \n",
            "l0: 0.240962, l1: 0.243480, l2: 0.249632, l3: 0.270161, l4: 0.307265, l5: 0.366309, l6: 0.551090\n",
            "\n",
            "[epoch: 119/100000, batch: 304/1000, ite: 14788] train loss: 2.4272, accuracy: 89.9744%, tar: 0.1662 \n",
            "l0: 0.109878, l1: 0.114498, l2: 0.127519, l3: 0.157440, l4: 0.213884, l5: 0.275939, l6: 0.533146\n",
            "\n",
            "[epoch: 119/100000, batch: 312/1000, ite: 14789] train loss: 2.4268, accuracy: 92.0500%, tar: 0.1661 \n",
            "l0: 0.190724, l1: 0.190375, l2: 0.199055, l3: 0.227425, l4: 0.293119, l5: 0.419283, l6: 0.615741\n",
            "\n",
            "[epoch: 119/100000, batch: 320/1000, ite: 14790] train loss: 2.4273, accuracy: 87.8521%, tar: 0.1661 \n",
            "l0: 0.223196, l1: 0.223092, l2: 0.233773, l3: 0.261520, l4: 0.305647, l5: 0.401313, l6: 0.681654\n",
            "\n",
            "[epoch: 119/100000, batch: 328/1000, ite: 14791] train loss: 2.4280, accuracy: 89.2763%, tar: 0.1662 \n",
            "l0: 0.114982, l1: 0.117236, l2: 0.121944, l3: 0.139269, l4: 0.173395, l5: 0.259058, l6: 0.455559\n",
            "\n",
            "[epoch: 119/100000, batch: 336/1000, ite: 14792] train loss: 2.4273, accuracy: 92.1335%, tar: 0.1661 \n",
            "l0: 0.109192, l1: 0.109149, l2: 0.115758, l3: 0.134960, l4: 0.170093, l5: 0.263594, l6: 0.455988\n",
            "\n",
            "[epoch: 119/100000, batch: 344/1000, ite: 14793] train loss: 2.4265, accuracy: 91.8183%, tar: 0.1661 \n",
            "l0: 0.166614, l1: 0.165945, l2: 0.172072, l3: 0.197611, l4: 0.261349, l5: 0.395407, l6: 0.611164\n",
            "\n",
            "[epoch: 119/100000, batch: 352/1000, ite: 14794] train loss: 2.4267, accuracy: 89.6544%, tar: 0.1661 \n",
            "l0: 0.226349, l1: 0.227549, l2: 0.241907, l3: 0.266220, l4: 0.333927, l5: 0.424506, l6: 0.587165\n",
            "\n",
            "[epoch: 119/100000, batch: 360/1000, ite: 14795] train loss: 2.4273, accuracy: 89.6781%, tar: 0.1661 \n",
            "l0: 0.120107, l1: 0.122558, l2: 0.135934, l3: 0.156053, l4: 0.213821, l5: 0.301492, l6: 0.496285\n",
            "\n",
            "[epoch: 119/100000, batch: 368/1000, ite: 14796] train loss: 2.4268, accuracy: 91.5748%, tar: 0.1661 \n",
            "l0: 0.123996, l1: 0.126408, l2: 0.135439, l3: 0.151475, l4: 0.202602, l5: 0.305984, l6: 0.538503\n",
            "\n",
            "[epoch: 119/100000, batch: 376/1000, ite: 14797] train loss: 2.4264, accuracy: 91.1882%, tar: 0.1660 \n",
            "l0: 0.125194, l1: 0.126885, l2: 0.139046, l3: 0.170419, l4: 0.221695, l5: 0.304184, l6: 0.495329\n",
            "\n",
            "[epoch: 119/100000, batch: 384/1000, ite: 14798] train loss: 2.4260, accuracy: 92.1414%, tar: 0.1660 \n",
            "l0: 0.140000, l1: 0.140056, l2: 0.150842, l3: 0.180698, l4: 0.214022, l5: 0.315147, l6: 0.542111\n",
            "\n",
            "[epoch: 119/100000, batch: 392/1000, ite: 14799] train loss: 2.4258, accuracy: 90.9353%, tar: 0.1660 \n",
            "l0: 0.082910, l1: 0.084308, l2: 0.090737, l3: 0.110546, l4: 0.141767, l5: 0.233503, l6: 0.478650\n",
            "\n",
            "[epoch: 119/100000, batch: 400/1000, ite: 14800] train loss: 2.4249, accuracy: 92.3092%, tar: 0.1658 \n",
            "l0: 0.292523, l1: 0.293095, l2: 0.306272, l3: 0.347458, l4: 0.422503, l5: 0.574082, l6: 0.876186\n",
            "\n",
            "[epoch: 119/100000, batch: 408/1000, ite: 14801] train loss: 2.4268, accuracy: 86.3893%, tar: 0.1660 \n",
            "l0: 0.157526, l1: 0.158760, l2: 0.168371, l3: 0.205336, l4: 0.289018, l5: 0.432695, l6: 0.706078\n",
            "\n",
            "[epoch: 119/100000, batch: 416/1000, ite: 14802] train loss: 2.4273, accuracy: 89.6502%, tar: 0.1660 \n",
            "l0: 0.226285, l1: 0.228880, l2: 0.238450, l3: 0.265681, l4: 0.337906, l5: 0.452186, l6: 0.623982\n",
            "\n",
            "[epoch: 119/100000, batch: 424/1000, ite: 14803] train loss: 2.4280, accuracy: 88.3899%, tar: 0.1661 \n",
            "l0: 0.128922, l1: 0.130482, l2: 0.138088, l3: 0.155112, l4: 0.206590, l5: 0.257735, l6: 0.408034\n",
            "\n",
            "[epoch: 119/100000, batch: 432/1000, ite: 14804] train loss: 2.4273, accuracy: 91.1822%, tar: 0.1660 \n",
            "l0: 0.246510, l1: 0.247174, l2: 0.256524, l3: 0.284935, l4: 0.333881, l5: 0.406165, l6: 0.580684\n",
            "\n",
            "[epoch: 119/100000, batch: 440/1000, ite: 14805] train loss: 2.4279, accuracy: 87.6502%, tar: 0.1661 \n",
            "l0: 0.168554, l1: 0.171065, l2: 0.174812, l3: 0.189501, l4: 0.238893, l5: 0.342672, l6: 0.589137\n",
            "\n",
            "[epoch: 119/100000, batch: 448/1000, ite: 14806] train loss: 2.4279, accuracy: 90.7246%, tar: 0.1661 \n",
            "l0: 0.264388, l1: 0.266507, l2: 0.272463, l3: 0.303511, l4: 0.394342, l5: 0.515304, l6: 0.670591\n",
            "\n",
            "[epoch: 119/100000, batch: 456/1000, ite: 14807] train loss: 2.4291, accuracy: 89.1057%, tar: 0.1662 \n",
            "l0: 0.162597, l1: 0.168084, l2: 0.174519, l3: 0.199289, l4: 0.256342, l5: 0.388287, l6: 0.645978\n",
            "\n",
            "[epoch: 119/100000, batch: 464/1000, ite: 14808] train loss: 2.4294, accuracy: 89.4483%, tar: 0.1662 \n",
            "l0: 0.151766, l1: 0.152476, l2: 0.163423, l3: 0.194923, l4: 0.258652, l5: 0.391205, l6: 0.619285\n",
            "\n",
            "[epoch: 119/100000, batch: 472/1000, ite: 14809] train loss: 2.4295, accuracy: 89.8831%, tar: 0.1662 \n",
            "l0: 0.146542, l1: 0.148272, l2: 0.159326, l3: 0.185420, l4: 0.220874, l5: 0.273192, l6: 0.481401\n",
            "\n",
            "[epoch: 119/100000, batch: 480/1000, ite: 14810] train loss: 2.4291, accuracy: 92.0567%, tar: 0.1662 \n",
            "l0: 0.153839, l1: 0.163601, l2: 0.163298, l3: 0.179921, l4: 0.247642, l5: 0.330525, l6: 0.510919\n",
            "\n",
            "[epoch: 119/100000, batch: 488/1000, ite: 14811] train loss: 2.4289, accuracy: 91.2025%, tar: 0.1662 \n",
            "l0: 0.111612, l1: 0.114829, l2: 0.123423, l3: 0.152342, l4: 0.222696, l5: 0.383217, l6: 0.587458\n",
            "\n",
            "[epoch: 119/100000, batch: 496/1000, ite: 14812] train loss: 2.4287, accuracy: 90.4810%, tar: 0.1661 \n",
            "l0: 0.110566, l1: 0.112651, l2: 0.120982, l3: 0.140621, l4: 0.188519, l5: 0.277781, l6: 0.489819\n",
            "\n",
            "[epoch: 119/100000, batch: 504/1000, ite: 14813] train loss: 2.4281, accuracy: 91.0970%, tar: 0.1661 \n",
            "l0: 0.124297, l1: 0.125802, l2: 0.137454, l3: 0.164024, l4: 0.232737, l5: 0.394143, l6: 0.683654\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_pHob0P7-kz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPnCoaxA-T-w"
      },
      "source": [
        "a = [1, 2, 3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5s24y6_f0K"
      },
      "source": [
        "print(\"not mining crypto\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXMob_7eI19z"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMyCegKHoroW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}