{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SODtraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "50d7d4c96879406f9636f3ec5ff22622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40815cb981114af5b221995f959cd248",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_47d9711f28e2420cae3a1ed3c6780bc4",
              "IPY_MODEL_9d0ed3a7f556483b9c5bdbf4d3d45993"
            ]
          }
        },
        "40815cb981114af5b221995f959cd248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47d9711f28e2420cae3a1ed3c6780bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ea4cf171b80416887e490251657f12e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87306240,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87306240,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1121fc5fbe4943acb66ac0099d2f7543"
          }
        },
        "9d0ed3a7f556483b9c5bdbf4d3d45993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b33e279973c84240afd1227332be4c65",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 83.3M/83.3M [00:00&lt;00:00, 89.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9645809335cd47cd83363f21a4d513b6"
          }
        },
        "6ea4cf171b80416887e490251657f12e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1121fc5fbe4943acb66ac0099d2f7543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b33e279973c84240afd1227332be4c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9645809335cd47cd83363f21a4d513b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSL2ErH4SvOZ",
        "outputId": "4e6c1cf5-4009-4933-a07b-292764efaa25"
      },
      "source": [
        "!git clone https://github.com/n00bmaster68/ApplyingSODinAutoLabelling\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ApplyingSODinAutoLabelling'...\n",
            "remote: Enumerating objects: 2090, done.\u001b[K\n",
            "remote: Counting objects: 100% (2090/2090), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2070/2070), done.\u001b[K\n",
            "remote: Total 2090 (delta 18), reused 2076 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2090/2090), 75.03 MiB | 47.78 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjqxfTA1XGU3",
        "outputId": "aca379c1-5769-440c-fa46-6d94029d7005"
      },
      "source": [
        "#check whether device has GPU\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-b5a905ab-c5e4-aaf1-1d27-a74832ed8745)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKJksXRPSxvA"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as standard_transforms\n",
        "\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from ApplyingSODinAutoLabelling.data_loader import Rescale\n",
        "from ApplyingSODinAutoLabelling.data_loader import RescaleT\n",
        "from ApplyingSODinAutoLabelling.data_loader import RandomCrop\n",
        "from ApplyingSODinAutoLabelling.data_loader import CenterCrop\n",
        "from ApplyingSODinAutoLabelling.data_loader import ToTensor\n",
        "from ApplyingSODinAutoLabelling.data_loader import ToTensorLab\n",
        "from ApplyingSODinAutoLabelling.data_loader import SalObjDataset\n",
        "\n",
        "from ApplyingSODinAutoLabelling.model import BASNet\n",
        "\n",
        "import ApplyingSODinAutoLabelling.deletable.pytorch_ssim as pytorch_ssim\n",
        "import ApplyingSODinAutoLabelling.deletable.pytorch_iou as pytorch_iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN6sGAEGTvJr",
        "outputId": "396785b8-bf15-4f7d-9d97-4b69f2c9f6e7"
      },
      "source": [
        "# ------- 1. define loss function --------\n",
        "\n",
        "bce_loss = nn.BCELoss(size_average=True)\n",
        "ssim_loss = pytorch_ssim.SSIM(window_size=11,size_average=True)\n",
        "iou_loss = pytorch_iou.IOU(size_average=True)\n",
        "\n",
        "def bce_ssim_loss(pred,target):\n",
        "\n",
        "\tbce_out = bce_loss(pred,target)\n",
        "\tssim_out = 1 - ssim_loss(pred,target)\n",
        "\tiou_out = iou_loss(pred,target)\n",
        "\n",
        "\tloss = bce_out + ssim_out + iou_out\n",
        "\treturn loss, ssim_out\n",
        "\n",
        "def muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, d7, labels_v):\n",
        "  loss0, ssim0 = bce_ssim_loss(d0,labels_v)\n",
        "  loss1, ssim1 = bce_ssim_loss(d1,labels_v)\n",
        "  loss2, ssim2 = bce_ssim_loss(d2,labels_v)\n",
        "  loss3, ssim3 = bce_ssim_loss(d3,labels_v)\n",
        "  loss4, ssim4 = bce_ssim_loss(d4,labels_v)\n",
        "  loss5, ssim5 = bce_ssim_loss(d5,labels_v)\n",
        "  loss6, ssim6 = bce_ssim_loss(d6,labels_v)\n",
        "  loss7, ssim7 = bce_ssim_loss(d7,labels_v)\n",
        "\n",
        "  acc = (ssim0 + ssim1 + ssim2 + ssim3 + ssim4 + ssim5 + ssim6 + ssim7) / 8\n",
        "  \n",
        "  loss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6 + loss7\n",
        "  print(\"l0: %3f, l1: %3f, l2: %3f, l3: %3f, l4: %3f, l5: %3f, l6: %3f\\n\"%(loss0.data,loss1.data,loss2.data,loss3.data,loss4.data,loss5.data,loss6.data))\n",
        "  \n",
        "  return loss0, loss, 1 - acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NH-ofMLTvSX",
        "outputId": "541c0932-3318-41ed-e973-a94edfe3a94e"
      },
      "source": [
        "# ------- 2. set the directory of training dataset --------\n",
        "\n",
        "data_dir = 'ApplyingSODinAutoLabelling/train_data/'\n",
        "tra_image_dir = 'DUTS/DUTS-TR/DUTS-TR/im_aug/'\n",
        "tra_label_dir = 'DUTS/DUTS-TR/DUTS-TR/gt_aug/'\n",
        "\n",
        "image_ext = '.jpg'\n",
        "label_ext = '.png'\n",
        "\n",
        "model_dir = \"ApplyingSODinAutoLabelling/saved_models/basnet_bsi/\"\n",
        "\n",
        "\n",
        "epoch_num = 100000\n",
        "batch_size_train = 8 \n",
        "batch_size_val = 1\n",
        "train_num = 0\n",
        "val_num = 0\n",
        "\n",
        "tra_img_name_list = glob.glob(data_dir + tra_image_dir + '*' + image_ext)\n",
        "\n",
        "tra_lbl_name_list = []\n",
        "for img_path in tra_img_name_list:\n",
        "\timg_name = img_path.split(\"/\")[-1]\n",
        "\n",
        "\taaa = img_name.split(\".\")\n",
        "\tbbb = aaa[0:-1]\n",
        "\timidx = bbb[0]\n",
        "\tfor i in range(1,len(bbb)):\n",
        "\t\timidx = imidx + \".\" + bbb[i]\n",
        "\n",
        "\ttra_lbl_name_list.append(data_dir + tra_label_dir + imidx + label_ext)\n",
        "\n",
        "print(\"---\")\n",
        "print(\"train images: \", len(tra_img_name_list))\n",
        "print(\"train labels: \", len(tra_lbl_name_list))\n",
        "print(\"---\")\n",
        "\n",
        "train_num = len(tra_img_name_list)\n",
        "\n",
        "salobj_dataset = SalObjDataset(\n",
        "    img_name_list=tra_img_name_list,\n",
        "    lbl_name_list=tra_lbl_name_list,\n",
        "    transform=transforms.Compose([\n",
        "        RescaleT(256),\n",
        "        RandomCrop(224),\n",
        "        ToTensorLab(flag=0)]))\n",
        "salobj_dataloader = DataLoader(salobj_dataset, batch_size=batch_size_train, shuffle=True, num_workers=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---\n",
            "train images:  1000\n",
            "train labels:  1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNL4AVnSTvYv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "50d7d4c96879406f9636f3ec5ff22622",
            "40815cb981114af5b221995f959cd248",
            "47d9711f28e2420cae3a1ed3c6780bc4",
            "9d0ed3a7f556483b9c5bdbf4d3d45993",
            "6ea4cf171b80416887e490251657f12e",
            "1121fc5fbe4943acb66ac0099d2f7543",
            "b33e279973c84240afd1227332be4c65",
            "9645809335cd47cd83363f21a4d513b6"
          ]
        },
        "outputId": "f32e710a-c9e4-4b71-e824-c06759efdaa3"
      },
      "source": [
        "# ------- 3. define model --------\n",
        "# define the net\n",
        "net = BASNet(3, 1)\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50d7d4c96879406f9636f3ec5ff22622",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHfoce-xTveR",
        "outputId": "5a3a6ecd-bd67-44bb-e172-dfe8afeeb41a"
      },
      "source": [
        "# ------- 4. define optimizer --------\n",
        "print(\"---define optimizer...\")\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---define optimizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMrCr4J9TvjK",
        "outputId": "17114683-0861-495b-d166-9295ca28d9e8"
      },
      "source": [
        "# ------- 5. training process --------\n",
        "print(\"---start training...\")\n",
        "ite_num = 0\n",
        "running_loss = 0.0\n",
        "running_tar_loss = 0.0\n",
        "ite_num4val = 0\n",
        "\n",
        "for epoch in range(0, epoch_num):\n",
        "    net.train()\n",
        "\n",
        "    for i, data in enumerate(salobj_dataloader):\n",
        "        ite_num = ite_num + 1\n",
        "        ite_num4val = ite_num4val + 1\n",
        "\n",
        "        inputs, labels = data['image'], data['label']\n",
        "\n",
        "        inputs = inputs.type(torch.FloatTensor)\n",
        "        labels = labels.type(torch.FloatTensor)\n",
        "\n",
        "        # wrap them in Variable\n",
        "        if torch.cuda.is_available():\n",
        "            inputs_v, labels_v = Variable(inputs.cuda(), requires_grad=False), Variable(labels.cuda(),\n",
        "                                                                                        requires_grad=False)\n",
        "        else:\n",
        "            inputs_v, labels_v = Variable(inputs, requires_grad=False), Variable(labels, requires_grad=False)\n",
        "\n",
        "        # y zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        d0, d1, d2, d3, d4, d5, d6, d7 = net(inputs_v)\n",
        "        loss2, loss, acc = muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, d7, labels_v)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # # print statistics\n",
        "        running_loss += loss.data\n",
        "        running_tar_loss += loss2.data\n",
        "\n",
        "        # del temporary outputs and loss\n",
        "        del d0, d1, d2, d3, d4, d5, d6, d7, loss2, loss\n",
        "\n",
        "        # print(\"ite_num4val: \", ite_num4val)\n",
        "\n",
        "        print(f\"[epoch: {epoch + 1}/{epoch_num}, batch: {(i + 1) * batch_size_train}/{train_num}, ite: {ite_num}] train loss: {format(running_loss / ite_num4val, '.4f')}, accuracy: {format(acc * 100, '.4f')}%, tar: {format(running_tar_loss / ite_num4val, '.4f')} \")\n",
        "\n",
        "        if ite_num % 2000 == 0:  # save model every 2000 iterations\n",
        "\n",
        "            torch.save(net.state_dict(), model_dir + \"basnet_bsi_itr_%d_train_%3f_tar_%3f.pth\" % (ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val))\n",
        "            running_loss = 0.0\n",
        "            running_tar_loss = 0.0\n",
        "            net.train()  # resume train\n",
        "            ite_num4val = 0\n",
        "\n",
        "print('-------------Congratulations! Training Done!!!-------------')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---start training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "l0: 0.308063, l1: 0.304857, l2: 0.315314, l3: 0.338896, l4: 0.384147, l5: 0.467346, l6: 0.675674\n",
            "\n",
            "[epoch: 100/100000, batch: 88/1000, ite: 12386] train loss: 2.7596, accuracy: 88.1808%, tar: 0.1998 \n",
            "l0: 0.292296, l1: 0.292644, l2: 0.295526, l3: 0.310984, l4: 0.347143, l5: 0.438721, l6: 0.648145\n",
            "\n",
            "[epoch: 100/100000, batch: 96/1000, ite: 12387] train loss: 2.7609, accuracy: 87.9403%, tar: 0.2000 \n",
            "l0: 0.372316, l1: 0.376366, l2: 0.379216, l3: 0.397028, l4: 0.442697, l5: 0.549406, l6: 0.730756\n",
            "\n",
            "[epoch: 100/100000, batch: 104/1000, ite: 12388] train loss: 2.7640, accuracy: 85.7492%, tar: 0.2005 \n",
            "l0: 0.235982, l1: 0.243566, l2: 0.253639, l3: 0.262737, l4: 0.318752, l5: 0.378590, l6: 0.536098\n",
            "\n",
            "[epoch: 100/100000, batch: 112/1000, ite: 12389] train loss: 2.7641, accuracy: 89.0248%, tar: 0.2006 \n",
            "l0: 0.253847, l1: 0.261025, l2: 0.250160, l3: 0.257082, l4: 0.314148, l5: 0.383617, l6: 0.589498\n",
            "\n",
            "[epoch: 100/100000, batch: 120/1000, ite: 12390] train loss: 2.7644, accuracy: 88.6631%, tar: 0.2007 \n",
            "l0: 0.238940, l1: 0.249127, l2: 0.257987, l3: 0.267750, l4: 0.313186, l5: 0.427726, l6: 0.697185\n",
            "\n",
            "[epoch: 100/100000, batch: 128/1000, ite: 12391] train loss: 2.7655, accuracy: 87.5347%, tar: 0.2008 \n",
            "l0: 0.142302, l1: 0.149627, l2: 0.155800, l3: 0.186457, l4: 0.273689, l5: 0.414556, l6: 0.627169\n",
            "\n",
            "[epoch: 100/100000, batch: 136/1000, ite: 12392] train loss: 2.7651, accuracy: 89.0089%, tar: 0.2007 \n",
            "l0: 0.600765, l1: 0.601351, l2: 0.616555, l3: 0.634357, l4: 0.686070, l5: 0.867381, l6: 1.105725\n",
            "\n",
            "[epoch: 100/100000, batch: 144/1000, ite: 12393] train loss: 2.7736, accuracy: 82.1172%, tar: 0.2017 \n",
            "l0: 0.322119, l1: 0.327245, l2: 0.337810, l3: 0.376941, l4: 0.472292, l5: 0.650841, l6: 0.915971\n",
            "\n",
            "[epoch: 100/100000, batch: 152/1000, ite: 12394] train loss: 2.7776, accuracy: 81.6730%, tar: 0.2020 \n",
            "l0: 0.216748, l1: 0.222736, l2: 0.221991, l3: 0.248499, l4: 0.303893, l5: 0.372724, l6: 0.534196\n",
            "\n",
            "[epoch: 100/100000, batch: 160/1000, ite: 12395] train loss: 2.7773, accuracy: 87.8788%, tar: 0.2020 \n",
            "l0: 0.223617, l1: 0.228311, l2: 0.237664, l3: 0.259495, l4: 0.320465, l5: 0.419017, l6: 0.623159\n",
            "\n",
            "[epoch: 100/100000, batch: 168/1000, ite: 12396] train loss: 2.7778, accuracy: 88.6365%, tar: 0.2021 \n",
            "l0: 0.224121, l1: 0.234688, l2: 0.243385, l3: 0.264677, l4: 0.321453, l5: 0.430917, l6: 0.593113\n",
            "\n",
            "[epoch: 100/100000, batch: 176/1000, ite: 12397] train loss: 2.7781, accuracy: 88.9522%, tar: 0.2021 \n",
            "l0: 0.262059, l1: 0.268989, l2: 0.278131, l3: 0.299938, l4: 0.353353, l5: 0.469211, l6: 0.654695\n",
            "\n",
            "[epoch: 100/100000, batch: 184/1000, ite: 12398] train loss: 2.7794, accuracy: 87.3116%, tar: 0.2023 \n",
            "l0: 0.205198, l1: 0.214554, l2: 0.216820, l3: 0.231589, l4: 0.281652, l5: 0.348842, l6: 0.545287\n",
            "\n",
            "[epoch: 100/100000, batch: 192/1000, ite: 12399] train loss: 2.7789, accuracy: 90.2282%, tar: 0.2023 \n",
            "l0: 0.203631, l1: 0.206118, l2: 0.215823, l3: 0.247760, l4: 0.333167, l5: 0.485546, l6: 0.690023\n",
            "\n",
            "[epoch: 100/100000, batch: 200/1000, ite: 12400] train loss: 2.7797, accuracy: 86.7854%, tar: 0.2023 \n",
            "l0: 0.330931, l1: 0.332573, l2: 0.345865, l3: 0.375259, l4: 0.444181, l5: 0.597827, l6: 0.687235\n",
            "\n",
            "[epoch: 100/100000, batch: 208/1000, ite: 12401] train loss: 2.7821, accuracy: 86.3671%, tar: 0.2026 \n",
            "l0: 0.228315, l1: 0.232261, l2: 0.241123, l3: 0.259784, l4: 0.311780, l5: 0.409211, l6: 0.610480\n",
            "\n",
            "[epoch: 100/100000, batch: 216/1000, ite: 12402] train loss: 2.7825, accuracy: 89.1420%, tar: 0.2027 \n",
            "l0: 0.657759, l1: 0.666156, l2: 0.668081, l3: 0.679887, l4: 0.744689, l5: 0.884126, l6: 1.101612\n",
            "\n",
            "[epoch: 100/100000, batch: 224/1000, ite: 12403] train loss: 2.7917, accuracy: 81.7092%, tar: 0.2038 \n",
            "l0: 0.274867, l1: 0.283328, l2: 0.296140, l3: 0.311178, l4: 0.364313, l5: 0.410117, l6: 0.643114\n",
            "\n",
            "[epoch: 100/100000, batch: 232/1000, ite: 12404] train loss: 2.7928, accuracy: 87.8038%, tar: 0.2040 \n",
            "l0: 0.178461, l1: 0.191952, l2: 0.198870, l3: 0.233474, l4: 0.283480, l5: 0.385284, l6: 0.625229\n",
            "\n",
            "[epoch: 100/100000, batch: 240/1000, ite: 12405] train loss: 2.7925, accuracy: 89.6444%, tar: 0.2039 \n",
            "l0: 0.252538, l1: 0.254874, l2: 0.269506, l3: 0.296457, l4: 0.345668, l5: 0.412501, l6: 0.687415\n",
            "\n",
            "[epoch: 100/100000, batch: 248/1000, ite: 12406] train loss: 2.7937, accuracy: 86.3449%, tar: 0.2040 \n",
            "l0: 0.244696, l1: 0.244112, l2: 0.240297, l3: 0.257443, l4: 0.310587, l5: 0.402251, l6: 0.550609\n",
            "\n",
            "[epoch: 100/100000, batch: 256/1000, ite: 12407] train loss: 2.7938, accuracy: 89.1101%, tar: 0.2041 \n",
            "l0: 0.310003, l1: 0.312751, l2: 0.313141, l3: 0.334130, l4: 0.435313, l5: 0.610053, l6: 0.878379\n",
            "\n",
            "[epoch: 100/100000, batch: 264/1000, ite: 12408] train loss: 2.7968, accuracy: 85.3092%, tar: 0.2044 \n",
            "l0: 0.262624, l1: 0.256384, l2: 0.265712, l3: 0.296924, l4: 0.392197, l5: 0.527483, l6: 0.823223\n",
            "\n",
            "[epoch: 100/100000, batch: 272/1000, ite: 12409] train loss: 2.7991, accuracy: 84.8355%, tar: 0.2045 \n",
            "l0: 0.263965, l1: 0.268633, l2: 0.275706, l3: 0.288864, l4: 0.332240, l5: 0.428172, l6: 0.617348\n",
            "\n",
            "[epoch: 100/100000, batch: 280/1000, ite: 12410] train loss: 2.7998, accuracy: 89.2933%, tar: 0.2047 \n",
            "l0: 0.293779, l1: 0.307855, l2: 0.318956, l3: 0.337352, l4: 0.417329, l5: 0.524359, l6: 0.734087\n",
            "\n",
            "[epoch: 100/100000, batch: 288/1000, ite: 12411] train loss: 2.8020, accuracy: 87.5183%, tar: 0.2049 \n",
            "l0: 0.365844, l1: 0.358803, l2: 0.371762, l3: 0.412199, l4: 0.465514, l5: 0.597091, l6: 0.859128\n",
            "\n",
            "[epoch: 100/100000, batch: 296/1000, ite: 12412] train loss: 2.8056, accuracy: 86.3249%, tar: 0.2053 \n",
            "l0: 0.263857, l1: 0.270875, l2: 0.284452, l3: 0.322505, l4: 0.406131, l5: 0.564561, l6: 0.856272\n",
            "\n",
            "[epoch: 100/100000, batch: 304/1000, ite: 12413] train loss: 2.8081, accuracy: 84.5196%, tar: 0.2054 \n",
            "l0: 0.226616, l1: 0.236004, l2: 0.250306, l3: 0.277026, l4: 0.327382, l5: 0.394272, l6: 0.607118\n",
            "\n",
            "[epoch: 100/100000, batch: 312/1000, ite: 12414] train loss: 2.8085, accuracy: 89.1634%, tar: 0.2055 \n",
            "l0: 0.306820, l1: 0.305756, l2: 0.316400, l3: 0.330929, l4: 0.362524, l5: 0.453466, l6: 0.653715\n",
            "\n",
            "[epoch: 100/100000, batch: 320/1000, ite: 12415] train loss: 2.8100, accuracy: 87.3656%, tar: 0.2057 \n",
            "l0: 0.305296, l1: 0.306062, l2: 0.315674, l3: 0.330604, l4: 0.359563, l5: 0.434853, l6: 0.579022\n",
            "\n",
            "[epoch: 100/100000, batch: 328/1000, ite: 12416] train loss: 2.8109, accuracy: 87.1207%, tar: 0.2060 \n",
            "l0: 0.259368, l1: 0.265529, l2: 0.275599, l3: 0.298350, l4: 0.364240, l5: 0.473283, l6: 0.567768\n",
            "\n",
            "[epoch: 100/100000, batch: 336/1000, ite: 12417] train loss: 2.8117, accuracy: 87.4824%, tar: 0.2061 \n",
            "l0: 0.182695, l1: 0.186921, l2: 0.197045, l3: 0.218615, l4: 0.257871, l5: 0.388662, l6: 0.600005\n",
            "\n",
            "[epoch: 100/100000, batch: 344/1000, ite: 12418] train loss: 2.8112, accuracy: 90.1772%, tar: 0.2060 \n",
            "l0: 0.223676, l1: 0.229828, l2: 0.245271, l3: 0.275701, l4: 0.344270, l5: 0.491050, l6: 0.682689\n",
            "\n",
            "[epoch: 100/100000, batch: 352/1000, ite: 12419] train loss: 2.8120, accuracy: 88.2130%, tar: 0.2061 \n",
            "l0: 0.197215, l1: 0.206145, l2: 0.221779, l3: 0.255718, l4: 0.319148, l5: 0.427167, l6: 0.667716\n",
            "\n",
            "[epoch: 100/100000, batch: 360/1000, ite: 12420] train loss: 2.8125, accuracy: 87.9377%, tar: 0.2061 \n",
            "l0: 0.177612, l1: 0.187469, l2: 0.201051, l3: 0.228347, l4: 0.299859, l5: 0.380367, l6: 0.529752\n",
            "\n",
            "[epoch: 100/100000, batch: 368/1000, ite: 12421] train loss: 2.8118, accuracy: 91.2613%, tar: 0.2060 \n",
            "l0: 0.195259, l1: 0.195857, l2: 0.203488, l3: 0.231759, l4: 0.311347, l5: 0.404821, l6: 0.596810\n",
            "\n",
            "[epoch: 100/100000, batch: 376/1000, ite: 12422] train loss: 2.8117, accuracy: 88.9262%, tar: 0.2060 \n",
            "l0: 0.302826, l1: 0.299756, l2: 0.312657, l3: 0.334287, l4: 0.369668, l5: 0.441213, l6: 0.606127\n",
            "\n",
            "[epoch: 100/100000, batch: 384/1000, ite: 12423] train loss: 2.8128, accuracy: 88.5528%, tar: 0.2062 \n",
            "l0: 0.280197, l1: 0.288436, l2: 0.299233, l3: 0.337192, l4: 0.425624, l5: 0.576962, l6: 0.862124\n",
            "\n",
            "[epoch: 100/100000, batch: 392/1000, ite: 12424] train loss: 2.8155, accuracy: 84.4675%, tar: 0.2064 \n",
            "l0: 0.231295, l1: 0.232458, l2: 0.240855, l3: 0.268090, l4: 0.326415, l5: 0.430021, l6: 0.663778\n",
            "\n",
            "[epoch: 100/100000, batch: 400/1000, ite: 12425] train loss: 2.8160, accuracy: 87.6313%, tar: 0.2064 \n",
            "l0: 0.474055, l1: 0.483756, l2: 0.488258, l3: 0.503017, l4: 0.535276, l5: 0.616943, l6: 0.755424\n",
            "\n",
            "[epoch: 100/100000, batch: 408/1000, ite: 12426] train loss: 2.8202, accuracy: 84.2489%, tar: 0.2071 \n",
            "l0: 0.147714, l1: 0.147978, l2: 0.155522, l3: 0.186807, l4: 0.260551, l5: 0.402547, l6: 0.643260\n",
            "\n",
            "[epoch: 100/100000, batch: 416/1000, ite: 12427] train loss: 2.8196, accuracy: 87.4867%, tar: 0.2069 \n",
            "l0: 0.367174, l1: 0.376952, l2: 0.377263, l3: 0.393920, l4: 0.457016, l5: 0.537210, l6: 0.704893\n",
            "\n",
            "[epoch: 100/100000, batch: 424/1000, ite: 12428] train loss: 2.8223, accuracy: 84.9639%, tar: 0.2073 \n",
            "l0: 0.251117, l1: 0.254173, l2: 0.263704, l3: 0.296549, l4: 0.359642, l5: 0.452635, l6: 0.724042\n",
            "\n",
            "[epoch: 100/100000, batch: 432/1000, ite: 12429] train loss: 2.8236, accuracy: 85.9693%, tar: 0.2074 \n",
            "l0: 0.139404, l1: 0.145404, l2: 0.153080, l3: 0.180170, l4: 0.252735, l5: 0.370538, l6: 0.605333\n",
            "\n",
            "[epoch: 100/100000, batch: 440/1000, ite: 12430] train loss: 2.8228, accuracy: 89.8131%, tar: 0.2072 \n",
            "l0: 0.251947, l1: 0.259332, l2: 0.268898, l3: 0.286900, l4: 0.344411, l5: 0.445912, l6: 0.603980\n",
            "\n",
            "[epoch: 100/100000, batch: 448/1000, ite: 12431] train loss: 2.8233, accuracy: 88.3049%, tar: 0.2073 \n",
            "l0: 0.231411, l1: 0.234945, l2: 0.240936, l3: 0.276630, l4: 0.340721, l5: 0.451094, l6: 0.652226\n",
            "\n",
            "[epoch: 100/100000, batch: 456/1000, ite: 12432] train loss: 2.8241, accuracy: 88.7853%, tar: 0.2074 \n",
            "l0: 0.189321, l1: 0.189947, l2: 0.200814, l3: 0.232362, l4: 0.300097, l5: 0.418360, l6: 0.654358\n",
            "\n",
            "[epoch: 100/100000, batch: 464/1000, ite: 12433] train loss: 2.8240, accuracy: 88.1707%, tar: 0.2073 \n",
            "l0: 0.293903, l1: 0.305317, l2: 0.320745, l3: 0.351997, l4: 0.441816, l5: 0.535587, l6: 0.735500\n",
            "\n",
            "[epoch: 100/100000, batch: 472/1000, ite: 12434] train loss: 2.8262, accuracy: 86.8535%, tar: 0.2075 \n",
            "l0: 0.229479, l1: 0.225010, l2: 0.236159, l3: 0.277948, l4: 0.362304, l5: 0.512591, l6: 0.851745\n",
            "\n",
            "[epoch: 100/100000, batch: 480/1000, ite: 12435] train loss: 2.8278, accuracy: 86.2746%, tar: 0.2076 \n",
            "l0: 0.167671, l1: 0.166752, l2: 0.173625, l3: 0.199853, l4: 0.260604, l5: 0.327425, l6: 0.562827\n",
            "\n",
            "[epoch: 100/100000, batch: 488/1000, ite: 12436] train loss: 2.8269, accuracy: 89.5321%, tar: 0.2075 \n",
            "l0: 0.131650, l1: 0.134629, l2: 0.144928, l3: 0.170790, l4: 0.233712, l5: 0.348258, l6: 0.568901\n",
            "\n",
            "[epoch: 100/100000, batch: 496/1000, ite: 12437] train loss: 2.8258, accuracy: 90.5986%, tar: 0.2073 \n",
            "l0: 0.292499, l1: 0.287115, l2: 0.294295, l3: 0.316369, l4: 0.392427, l5: 0.491369, l6: 0.738929\n",
            "\n",
            "[epoch: 100/100000, batch: 504/1000, ite: 12438] train loss: 2.8275, accuracy: 86.8182%, tar: 0.2075 \n",
            "l0: 0.212249, l1: 0.215794, l2: 0.227985, l3: 0.259465, l4: 0.343276, l5: 0.483365, l6: 0.719939\n",
            "\n",
            "[epoch: 100/100000, batch: 512/1000, ite: 12439] train loss: 2.8284, accuracy: 87.2513%, tar: 0.2075 \n",
            "l0: 0.286736, l1: 0.288652, l2: 0.300674, l3: 0.325411, l4: 0.386158, l5: 0.465397, l6: 0.631944\n",
            "\n",
            "[epoch: 100/100000, batch: 520/1000, ite: 12440] train loss: 2.8295, accuracy: 88.1642%, tar: 0.2077 \n",
            "l0: 0.162967, l1: 0.160313, l2: 0.174068, l3: 0.197355, l4: 0.260061, l5: 0.417594, l6: 0.700487\n",
            "\n",
            "[epoch: 100/100000, batch: 528/1000, ite: 12441] train loss: 2.8294, accuracy: 88.8265%, tar: 0.2076 \n",
            "l0: 0.130696, l1: 0.131787, l2: 0.141369, l3: 0.157952, l4: 0.214373, l5: 0.338303, l6: 0.473290\n",
            "\n",
            "[epoch: 100/100000, batch: 536/1000, ite: 12442] train loss: 2.8277, accuracy: 91.1496%, tar: 0.2074 \n",
            "l0: 0.190111, l1: 0.196395, l2: 0.205356, l3: 0.219403, l4: 0.259830, l5: 0.361885, l6: 0.517216\n",
            "\n",
            "[epoch: 100/100000, batch: 544/1000, ite: 12443] train loss: 2.8268, accuracy: 89.8337%, tar: 0.2074 \n",
            "l0: 0.108862, l1: 0.119863, l2: 0.129394, l3: 0.151933, l4: 0.196110, l5: 0.300107, l6: 0.498629\n",
            "\n",
            "[epoch: 100/100000, batch: 552/1000, ite: 12444] train loss: 2.8250, accuracy: 90.6021%, tar: 0.2072 \n",
            "l0: 0.265234, l1: 0.266218, l2: 0.275536, l3: 0.300888, l4: 0.337064, l5: 0.475163, l6: 0.768276\n",
            "\n",
            "[epoch: 100/100000, batch: 560/1000, ite: 12445] train loss: 2.8263, accuracy: 85.9660%, tar: 0.2073 \n",
            "l0: 0.397959, l1: 0.405576, l2: 0.425593, l3: 0.469017, l4: 0.540864, l5: 0.670151, l6: 0.777065\n",
            "\n",
            "[epoch: 100/100000, batch: 568/1000, ite: 12446] train loss: 2.8299, accuracy: 83.8284%, tar: 0.2077 \n",
            "l0: 0.158631, l1: 0.163130, l2: 0.169089, l3: 0.172958, l4: 0.201985, l5: 0.283607, l6: 0.452925\n",
            "\n",
            "[epoch: 100/100000, batch: 576/1000, ite: 12447] train loss: 2.8282, accuracy: 91.2727%, tar: 0.2076 \n",
            "l0: 0.410143, l1: 0.420804, l2: 0.438306, l3: 0.459099, l4: 0.526210, l5: 0.642840, l6: 0.759618\n",
            "\n",
            "[epoch: 100/100000, batch: 584/1000, ite: 12448] train loss: 2.8316, accuracy: 86.7890%, tar: 0.2081 \n",
            "l0: 0.175715, l1: 0.171133, l2: 0.179565, l3: 0.190512, l4: 0.221590, l5: 0.290012, l6: 0.469225\n",
            "\n",
            "[epoch: 100/100000, batch: 592/1000, ite: 12449] train loss: 2.8301, accuracy: 90.9488%, tar: 0.2080 \n",
            "l0: 0.172399, l1: 0.175206, l2: 0.182579, l3: 0.195585, l4: 0.238080, l5: 0.308661, l6: 0.472216\n",
            "\n",
            "[epoch: 100/100000, batch: 600/1000, ite: 12450] train loss: 2.8288, accuracy: 90.9058%, tar: 0.2079 \n",
            "l0: 0.128263, l1: 0.134037, l2: 0.139715, l3: 0.165134, l4: 0.224300, l5: 0.325990, l6: 0.529995\n",
            "\n",
            "[epoch: 100/100000, batch: 608/1000, ite: 12451] train loss: 2.8274, accuracy: 90.4882%, tar: 0.2078 \n",
            "l0: 0.140086, l1: 0.141469, l2: 0.147940, l3: 0.168873, l4: 0.225356, l5: 0.331766, l6: 0.494271\n",
            "\n",
            "[epoch: 100/100000, batch: 616/1000, ite: 12452] train loss: 2.8258, accuracy: 92.2877%, tar: 0.2076 \n",
            "l0: 0.359296, l1: 0.374073, l2: 0.377991, l3: 0.396277, l4: 0.413626, l5: 0.479472, l6: 0.709483\n",
            "\n",
            "[epoch: 100/100000, batch: 624/1000, ite: 12453] train loss: 2.8280, accuracy: 84.2398%, tar: 0.2079 \n",
            "l0: 0.345068, l1: 0.343583, l2: 0.351973, l3: 0.382482, l4: 0.433420, l5: 0.526632, l6: 0.695003\n",
            "\n",
            "[epoch: 100/100000, batch: 632/1000, ite: 12454] train loss: 2.8300, accuracy: 86.4259%, tar: 0.2082 \n",
            "l0: 0.187848, l1: 0.187599, l2: 0.196234, l3: 0.221356, l4: 0.262703, l5: 0.384004, l6: 0.643466\n",
            "\n",
            "[epoch: 100/100000, batch: 640/1000, ite: 12455] train loss: 2.8298, accuracy: 89.2899%, tar: 0.2082 \n",
            "l0: 0.259841, l1: 0.257348, l2: 0.265115, l3: 0.277697, l4: 0.301882, l5: 0.360607, l6: 0.585418\n",
            "\n",
            "[epoch: 100/100000, batch: 648/1000, ite: 12456] train loss: 2.8299, accuracy: 87.5376%, tar: 0.2083 \n",
            "l0: 0.301774, l1: 0.304875, l2: 0.316208, l3: 0.331815, l4: 0.392389, l5: 0.449425, l6: 0.561984\n",
            "\n",
            "[epoch: 100/100000, batch: 656/1000, ite: 12457] train loss: 2.8309, accuracy: 88.8681%, tar: 0.2085 \n",
            "l0: 0.206083, l1: 0.213334, l2: 0.219221, l3: 0.249735, l4: 0.304807, l5: 0.440126, l6: 0.657140\n",
            "\n",
            "[epoch: 100/100000, batch: 664/1000, ite: 12458] train loss: 2.8311, accuracy: 89.0865%, tar: 0.2085 \n",
            "l0: 0.257071, l1: 0.260274, l2: 0.267732, l3: 0.306450, l4: 0.383609, l5: 0.541598, l6: 0.715479\n",
            "\n",
            "[epoch: 100/100000, batch: 672/1000, ite: 12459] train loss: 2.8324, accuracy: 88.0808%, tar: 0.2086 \n",
            "l0: 0.298117, l1: 0.301752, l2: 0.307656, l3: 0.329896, l4: 0.374690, l5: 0.513607, l6: 0.708074\n",
            "\n",
            "[epoch: 100/100000, batch: 680/1000, ite: 12460] train loss: 2.8337, accuracy: 87.1754%, tar: 0.2088 \n",
            "l0: 0.251152, l1: 0.257542, l2: 0.270339, l3: 0.292765, l4: 0.355305, l5: 0.468792, l6: 0.652654\n",
            "\n",
            "[epoch: 100/100000, batch: 688/1000, ite: 12461] train loss: 2.8344, accuracy: 88.9737%, tar: 0.2089 \n",
            "l0: 0.220184, l1: 0.223481, l2: 0.230237, l3: 0.246278, l4: 0.268742, l5: 0.331140, l6: 0.528491\n",
            "\n",
            "[epoch: 100/100000, batch: 696/1000, ite: 12462] train loss: 2.8339, accuracy: 89.4880%, tar: 0.2089 \n",
            "l0: 0.114177, l1: 0.117271, l2: 0.126350, l3: 0.150448, l4: 0.202891, l5: 0.297184, l6: 0.531981\n",
            "\n",
            "[epoch: 100/100000, batch: 704/1000, ite: 12463] train loss: 2.8322, accuracy: 90.2654%, tar: 0.2087 \n",
            "l0: 0.227385, l1: 0.230732, l2: 0.243146, l3: 0.271915, l4: 0.338987, l5: 0.465606, l6: 0.659529\n",
            "\n",
            "[epoch: 100/100000, batch: 712/1000, ite: 12464] train loss: 2.8328, accuracy: 87.8004%, tar: 0.2088 \n",
            "l0: 0.165253, l1: 0.166483, l2: 0.177303, l3: 0.205175, l4: 0.276847, l5: 0.394830, l6: 0.596444\n",
            "\n",
            "[epoch: 100/100000, batch: 720/1000, ite: 12465] train loss: 2.8323, accuracy: 91.0186%, tar: 0.2087 \n",
            "l0: 0.158357, l1: 0.161880, l2: 0.182524, l3: 0.218271, l4: 0.303722, l5: 0.452055, l6: 0.756597\n",
            "\n",
            "[epoch: 100/100000, batch: 728/1000, ite: 12466] train loss: 2.8324, accuracy: 89.6273%, tar: 0.2086 \n",
            "l0: 0.231483, l1: 0.233948, l2: 0.255836, l3: 0.297106, l4: 0.386754, l5: 0.531587, l6: 0.757504\n",
            "\n",
            "[epoch: 100/100000, batch: 736/1000, ite: 12467] train loss: 2.8338, accuracy: 89.0139%, tar: 0.2086 \n",
            "l0: 0.221836, l1: 0.221430, l2: 0.235505, l3: 0.273461, l4: 0.337606, l5: 0.472404, l6: 0.688612\n",
            "\n",
            "[epoch: 100/100000, batch: 744/1000, ite: 12468] train loss: 2.8345, accuracy: 87.1846%, tar: 0.2086 \n",
            "l0: 0.366102, l1: 0.368475, l2: 0.380152, l3: 0.410778, l4: 0.465009, l5: 0.562371, l6: 0.671593\n",
            "\n",
            "[epoch: 100/100000, batch: 752/1000, ite: 12469] train loss: 2.8367, accuracy: 87.8526%, tar: 0.2090 \n",
            "l0: 0.231167, l1: 0.225370, l2: 0.236836, l3: 0.259475, l4: 0.325789, l5: 0.464114, l6: 0.717983\n",
            "\n",
            "[epoch: 100/100000, batch: 760/1000, ite: 12470] train loss: 2.8374, accuracy: 87.2659%, tar: 0.2090 \n",
            "l0: 0.222225, l1: 0.211903, l2: 0.225291, l3: 0.242228, l4: 0.304360, l5: 0.439300, l6: 0.688055\n",
            "\n",
            "[epoch: 100/100000, batch: 768/1000, ite: 12471] train loss: 2.8377, accuracy: 88.3905%, tar: 0.2090 \n",
            "l0: 0.201844, l1: 0.216719, l2: 0.221371, l3: 0.243360, l4: 0.280278, l5: 0.419955, l6: 0.608337\n",
            "\n",
            "[epoch: 100/100000, batch: 776/1000, ite: 12472] train loss: 2.8376, accuracy: 88.2669%, tar: 0.2090 \n",
            "l0: 0.095430, l1: 0.101348, l2: 0.108261, l3: 0.129298, l4: 0.182556, l5: 0.282115, l6: 0.512070\n",
            "\n",
            "[epoch: 100/100000, batch: 784/1000, ite: 12473] train loss: 2.8357, accuracy: 91.4332%, tar: 0.2088 \n",
            "l0: 0.285730, l1: 0.282925, l2: 0.293624, l3: 0.318328, l4: 0.372560, l5: 0.486914, l6: 0.608077\n",
            "\n",
            "[epoch: 100/100000, batch: 792/1000, ite: 12474] train loss: 2.8365, accuracy: 89.3317%, tar: 0.2090 \n",
            "l0: 0.430624, l1: 0.432304, l2: 0.441136, l3: 0.455224, l4: 0.466738, l5: 0.560449, l6: 0.686918\n",
            "\n",
            "[epoch: 100/100000, batch: 800/1000, ite: 12475] train loss: 2.8393, accuracy: 85.8552%, tar: 0.2094 \n",
            "l0: 0.327950, l1: 0.331368, l2: 0.332247, l3: 0.343345, l4: 0.353381, l5: 0.407820, l6: 0.585905\n",
            "\n",
            "[epoch: 100/100000, batch: 808/1000, ite: 12476] train loss: 2.8401, accuracy: 87.5082%, tar: 0.2097 \n",
            "l0: 0.196356, l1: 0.199621, l2: 0.208284, l3: 0.238089, l4: 0.309127, l5: 0.420637, l6: 0.619445\n",
            "\n",
            "[epoch: 100/100000, batch: 816/1000, ite: 12477] train loss: 2.8401, accuracy: 88.1745%, tar: 0.2096 \n",
            "l0: 0.254831, l1: 0.255536, l2: 0.265166, l3: 0.289717, l4: 0.348175, l5: 0.448610, l6: 0.660326\n",
            "\n",
            "[epoch: 100/100000, batch: 824/1000, ite: 12478] train loss: 2.8408, accuracy: 88.9517%, tar: 0.2097 \n",
            "l0: 0.168298, l1: 0.178063, l2: 0.185112, l3: 0.214044, l4: 0.261376, l5: 0.369215, l6: 0.554783\n",
            "\n",
            "[epoch: 100/100000, batch: 832/1000, ite: 12479] train loss: 2.8402, accuracy: 88.2361%, tar: 0.2097 \n",
            "l0: 0.250167, l1: 0.251769, l2: 0.258975, l3: 0.281798, l4: 0.325770, l5: 0.438162, l6: 0.700785\n",
            "\n",
            "[epoch: 100/100000, batch: 840/1000, ite: 12480] train loss: 2.8411, accuracy: 86.6600%, tar: 0.2097 \n",
            "l0: 0.297558, l1: 0.292422, l2: 0.302365, l3: 0.328072, l4: 0.368456, l5: 0.491900, l6: 0.729218\n",
            "\n",
            "[epoch: 100/100000, batch: 848/1000, ite: 12481] train loss: 2.8426, accuracy: 86.7333%, tar: 0.2099 \n",
            "l0: 0.151084, l1: 0.151089, l2: 0.158863, l3: 0.176373, l4: 0.221273, l5: 0.347981, l6: 0.562488\n",
            "\n",
            "[epoch: 100/100000, batch: 856/1000, ite: 12482] train loss: 2.8415, accuracy: 91.0096%, tar: 0.2098 \n",
            "l0: 0.156551, l1: 0.164413, l2: 0.175100, l3: 0.203952, l4: 0.298374, l5: 0.443012, l6: 0.692107\n",
            "\n",
            "[epoch: 100/100000, batch: 864/1000, ite: 12483] train loss: 2.8415, accuracy: 89.7597%, tar: 0.2097 \n",
            "l0: 0.210123, l1: 0.212542, l2: 0.219206, l3: 0.246591, l4: 0.301740, l5: 0.363787, l6: 0.572535\n",
            "\n",
            "[epoch: 100/100000, batch: 872/1000, ite: 12484] train loss: 2.8413, accuracy: 89.3634%, tar: 0.2097 \n",
            "l0: 0.209066, l1: 0.220265, l2: 0.232947, l3: 0.255197, l4: 0.326944, l5: 0.423984, l6: 0.736213\n",
            "\n",
            "[epoch: 100/100000, batch: 880/1000, ite: 12485] train loss: 2.8420, accuracy: 87.7348%, tar: 0.2097 \n",
            "l0: 0.112720, l1: 0.115211, l2: 0.117926, l3: 0.140826, l4: 0.192799, l5: 0.334662, l6: 0.579346\n",
            "\n",
            "[epoch: 100/100000, batch: 888/1000, ite: 12486] train loss: 2.8406, accuracy: 90.0224%, tar: 0.2095 \n",
            "l0: 0.177904, l1: 0.180812, l2: 0.195739, l3: 0.220586, l4: 0.284025, l5: 0.409563, l6: 0.681354\n",
            "\n",
            "[epoch: 100/100000, batch: 896/1000, ite: 12487] train loss: 2.8405, accuracy: 88.7834%, tar: 0.2094 \n",
            "l0: 0.268673, l1: 0.274402, l2: 0.285411, l3: 0.316328, l4: 0.399454, l5: 0.531966, l6: 0.837936\n",
            "\n",
            "[epoch: 100/100000, batch: 904/1000, ite: 12488] train loss: 2.8423, accuracy: 84.2399%, tar: 0.2095 \n",
            "l0: 0.208630, l1: 0.220601, l2: 0.227095, l3: 0.247076, l4: 0.269352, l5: 0.327190, l6: 0.517218\n",
            "\n",
            "[epoch: 100/100000, batch: 912/1000, ite: 12489] train loss: 2.8417, accuracy: 90.7368%, tar: 0.2095 \n",
            "l0: 0.224303, l1: 0.228490, l2: 0.241080, l3: 0.276576, l4: 0.326195, l5: 0.398243, l6: 0.614993\n",
            "\n",
            "[epoch: 100/100000, batch: 920/1000, ite: 12490] train loss: 2.8419, accuracy: 87.9736%, tar: 0.2096 \n",
            "l0: 0.226870, l1: 0.228038, l2: 0.239583, l3: 0.267504, l4: 0.312154, l5: 0.391165, l6: 0.631961\n",
            "\n",
            "[epoch: 100/100000, batch: 928/1000, ite: 12491] train loss: 2.8421, accuracy: 87.9542%, tar: 0.2096 \n",
            "l0: 0.119248, l1: 0.119487, l2: 0.127303, l3: 0.153205, l4: 0.210299, l5: 0.315447, l6: 0.470898\n",
            "\n",
            "[epoch: 100/100000, batch: 936/1000, ite: 12492] train loss: 2.8403, accuracy: 90.9506%, tar: 0.2094 \n",
            "l0: 0.172767, l1: 0.174499, l2: 0.176376, l3: 0.200147, l4: 0.245322, l5: 0.346695, l6: 0.598335\n",
            "\n",
            "[epoch: 100/100000, batch: 944/1000, ite: 12493] train loss: 2.8397, accuracy: 89.7052%, tar: 0.2093 \n",
            "l0: 0.168028, l1: 0.172631, l2: 0.185576, l3: 0.210485, l4: 0.255006, l5: 0.336695, l6: 0.522547\n",
            "\n",
            "[epoch: 100/100000, batch: 952/1000, ite: 12494] train loss: 2.8387, accuracy: 89.7578%, tar: 0.2093 \n",
            "l0: 0.147228, l1: 0.152233, l2: 0.162380, l3: 0.190703, l4: 0.256123, l5: 0.413547, l6: 0.610588\n",
            "\n",
            "[epoch: 100/100000, batch: 960/1000, ite: 12495] train loss: 2.8381, accuracy: 89.9101%, tar: 0.2091 \n",
            "l0: 0.179717, l1: 0.181700, l2: 0.191516, l3: 0.214464, l4: 0.263825, l5: 0.354526, l6: 0.537806\n",
            "\n",
            "[epoch: 100/100000, batch: 968/1000, ite: 12496] train loss: 2.8374, accuracy: 90.7733%, tar: 0.2091 \n",
            "l0: 0.285074, l1: 0.290749, l2: 0.307756, l3: 0.344574, l4: 0.428610, l5: 0.556526, l6: 0.691931\n",
            "\n",
            "[epoch: 100/100000, batch: 976/1000, ite: 12497] train loss: 2.8390, accuracy: 86.2029%, tar: 0.2092 \n",
            "l0: 0.208090, l1: 0.209070, l2: 0.227436, l3: 0.270983, l4: 0.352104, l5: 0.479201, l6: 0.673162\n",
            "\n",
            "[epoch: 100/100000, batch: 984/1000, ite: 12498] train loss: 2.8395, accuracy: 89.3250%, tar: 0.2092 \n",
            "l0: 0.141234, l1: 0.143797, l2: 0.152805, l3: 0.178071, l4: 0.230411, l5: 0.301140, l6: 0.521790\n",
            "\n",
            "[epoch: 100/100000, batch: 992/1000, ite: 12499] train loss: 2.8383, accuracy: 90.8905%, tar: 0.2091 \n",
            "l0: 0.156273, l1: 0.162648, l2: 0.169997, l3: 0.190024, l4: 0.224914, l5: 0.336340, l6: 0.486354\n",
            "\n",
            "[epoch: 100/100000, batch: 1000/1000, ite: 12500] train loss: 2.8370, accuracy: 90.5885%, tar: 0.2090 \n",
            "l0: 0.116648, l1: 0.119043, l2: 0.126610, l3: 0.148153, l4: 0.197178, l5: 0.315767, l6: 0.494788\n",
            "\n",
            "[epoch: 101/100000, batch: 8/1000, ite: 12501] train loss: 2.8355, accuracy: 89.5326%, tar: 0.2088 \n",
            "l0: 0.140950, l1: 0.145069, l2: 0.152064, l3: 0.176792, l4: 0.233290, l5: 0.378111, l6: 0.694623\n",
            "\n",
            "[epoch: 101/100000, batch: 16/1000, ite: 12502] train loss: 2.8350, accuracy: 90.9141%, tar: 0.2087 \n",
            "l0: 0.139649, l1: 0.141001, l2: 0.148288, l3: 0.169816, l4: 0.211138, l5: 0.298250, l6: 0.476339\n",
            "\n",
            "[epoch: 101/100000, batch: 24/1000, ite: 12503] train loss: 2.8334, accuracy: 90.4655%, tar: 0.2085 \n",
            "l0: 0.118156, l1: 0.120773, l2: 0.131797, l3: 0.154457, l4: 0.202717, l5: 0.275651, l6: 0.451184\n",
            "\n",
            "[epoch: 101/100000, batch: 32/1000, ite: 12504] train loss: 2.8316, accuracy: 91.5959%, tar: 0.2084 \n",
            "l0: 0.138526, l1: 0.139357, l2: 0.152663, l3: 0.179444, l4: 0.261963, l5: 0.391811, l6: 0.732111\n",
            "\n",
            "[epoch: 101/100000, batch: 40/1000, ite: 12505] train loss: 2.8314, accuracy: 88.5991%, tar: 0.2082 \n",
            "l0: 0.142879, l1: 0.145785, l2: 0.159793, l3: 0.185417, l4: 0.259729, l5: 0.388044, l6: 0.599119\n",
            "\n",
            "[epoch: 101/100000, batch: 48/1000, ite: 12506] train loss: 2.8308, accuracy: 88.7139%, tar: 0.2081 \n",
            "l0: 0.186652, l1: 0.187159, l2: 0.203315, l3: 0.236987, l4: 0.285619, l5: 0.359651, l6: 0.572059\n",
            "\n",
            "[epoch: 101/100000, batch: 56/1000, ite: 12507] train loss: 2.8303, accuracy: 89.7893%, tar: 0.2080 \n",
            "l0: 0.173687, l1: 0.177335, l2: 0.192240, l3: 0.224765, l4: 0.311108, l5: 0.508267, l6: 0.776741\n",
            "\n",
            "[epoch: 101/100000, batch: 64/1000, ite: 12508] train loss: 2.8310, accuracy: 88.0534%, tar: 0.2080 \n",
            "l0: 0.159272, l1: 0.159318, l2: 0.173267, l3: 0.202268, l4: 0.258936, l5: 0.353959, l6: 0.549371\n",
            "\n",
            "[epoch: 101/100000, batch: 72/1000, ite: 12509] train loss: 2.8301, accuracy: 90.1036%, tar: 0.2079 \n",
            "l0: 0.159704, l1: 0.159821, l2: 0.167487, l3: 0.186822, l4: 0.231500, l5: 0.317587, l6: 0.476870\n",
            "\n",
            "[epoch: 101/100000, batch: 80/1000, ite: 12510] train loss: 2.8289, accuracy: 90.3074%, tar: 0.2078 \n",
            "l0: 0.136909, l1: 0.139034, l2: 0.151427, l3: 0.179324, l4: 0.244065, l5: 0.344192, l6: 0.604487\n",
            "\n",
            "[epoch: 101/100000, batch: 88/1000, ite: 12511] train loss: 2.8280, accuracy: 90.5528%, tar: 0.2076 \n",
            "l0: 0.122562, l1: 0.123378, l2: 0.139420, l3: 0.168291, l4: 0.247567, l5: 0.376413, l6: 0.655072\n",
            "\n",
            "[epoch: 101/100000, batch: 96/1000, ite: 12512] train loss: 2.8273, accuracy: 90.0109%, tar: 0.2075 \n",
            "l0: 0.178655, l1: 0.178980, l2: 0.196072, l3: 0.236845, l4: 0.334524, l5: 0.479558, l6: 0.669309\n",
            "\n",
            "[epoch: 101/100000, batch: 104/1000, ite: 12513] train loss: 2.8276, accuracy: 87.6023%, tar: 0.2074 \n",
            "l0: 0.129752, l1: 0.132143, l2: 0.144652, l3: 0.179485, l4: 0.252892, l5: 0.370573, l6: 0.556600\n",
            "\n",
            "[epoch: 101/100000, batch: 112/1000, ite: 12514] train loss: 2.8266, accuracy: 90.3453%, tar: 0.2073 \n",
            "l0: 0.250749, l1: 0.246275, l2: 0.258988, l3: 0.288473, l4: 0.347404, l5: 0.472430, l6: 0.766088\n",
            "\n",
            "[epoch: 101/100000, batch: 120/1000, ite: 12515] train loss: 2.8277, accuracy: 88.1185%, tar: 0.2074 \n",
            "l0: 0.117439, l1: 0.119816, l2: 0.129826, l3: 0.149878, l4: 0.198369, l5: 0.307947, l6: 0.539706\n",
            "\n",
            "[epoch: 101/100000, batch: 128/1000, ite: 12516] train loss: 2.8263, accuracy: 90.5563%, tar: 0.2072 \n",
            "l0: 0.129224, l1: 0.130910, l2: 0.146897, l3: 0.193327, l4: 0.290572, l5: 0.450239, l6: 0.705152\n",
            "\n",
            "[epoch: 101/100000, batch: 136/1000, ite: 12517] train loss: 2.8261, accuracy: 88.8698%, tar: 0.2070 \n",
            "l0: 0.165266, l1: 0.169136, l2: 0.181057, l3: 0.209720, l4: 0.288489, l5: 0.425193, l6: 0.669630\n",
            "\n",
            "[epoch: 101/100000, batch: 144/1000, ite: 12518] train loss: 2.8260, accuracy: 89.2391%, tar: 0.2070 \n",
            "l0: 0.130025, l1: 0.136624, l2: 0.144579, l3: 0.164571, l4: 0.227793, l5: 0.314854, l6: 0.480346\n",
            "\n",
            "[epoch: 101/100000, batch: 152/1000, ite: 12519] train loss: 2.8246, accuracy: 90.8799%, tar: 0.2068 \n",
            "l0: 0.212103, l1: 0.215519, l2: 0.229064, l3: 0.264996, l4: 0.353217, l5: 0.501780, l6: 0.696923\n",
            "\n",
            "[epoch: 101/100000, batch: 160/1000, ite: 12520] train loss: 2.8253, accuracy: 88.5898%, tar: 0.2068 \n",
            "l0: 0.101686, l1: 0.103977, l2: 0.110698, l3: 0.128678, l4: 0.177151, l5: 0.275300, l6: 0.488826\n",
            "\n",
            "[epoch: 101/100000, batch: 168/1000, ite: 12521] train loss: 2.8234, accuracy: 91.1388%, tar: 0.2066 \n",
            "l0: 0.149183, l1: 0.154151, l2: 0.166571, l3: 0.195245, l4: 0.266301, l5: 0.394801, l6: 0.686932\n",
            "\n",
            "[epoch: 101/100000, batch: 176/1000, ite: 12522] train loss: 2.8232, accuracy: 89.6196%, tar: 0.2065 \n",
            "l0: 0.255715, l1: 0.262023, l2: 0.276495, l3: 0.308961, l4: 0.412037, l5: 0.578422, l6: 0.785920\n",
            "\n",
            "[epoch: 101/100000, batch: 184/1000, ite: 12523] train loss: 2.8247, accuracy: 86.2744%, tar: 0.2066 \n",
            "l0: 0.202957, l1: 0.207944, l2: 0.222481, l3: 0.251477, l4: 0.305982, l5: 0.409573, l6: 0.565901\n",
            "\n",
            "[epoch: 101/100000, batch: 192/1000, ite: 12524] train loss: 2.8245, accuracy: 90.5657%, tar: 0.2066 \n",
            "l0: 0.096440, l1: 0.100246, l2: 0.111580, l3: 0.139139, l4: 0.196912, l5: 0.314949, l6: 0.546320\n",
            "\n",
            "[epoch: 101/100000, batch: 200/1000, ite: 12525] train loss: 2.8230, accuracy: 90.7128%, tar: 0.2064 \n",
            "l0: 0.164370, l1: 0.166759, l2: 0.177636, l3: 0.197017, l4: 0.238949, l5: 0.339583, l6: 0.465341\n",
            "\n",
            "[epoch: 101/100000, batch: 208/1000, ite: 12526] train loss: 2.8218, accuracy: 91.2922%, tar: 0.2063 \n",
            "l0: 0.205909, l1: 0.209976, l2: 0.220685, l3: 0.239342, l4: 0.304616, l5: 0.401987, l6: 0.613285\n",
            "\n",
            "[epoch: 101/100000, batch: 216/1000, ite: 12527] train loss: 2.8218, accuracy: 88.6000%, tar: 0.2063 \n",
            "l0: 0.107416, l1: 0.110358, l2: 0.117155, l3: 0.134832, l4: 0.183985, l5: 0.281888, l6: 0.510144\n",
            "\n",
            "[epoch: 101/100000, batch: 224/1000, ite: 12528] train loss: 2.8202, accuracy: 90.6409%, tar: 0.2061 \n",
            "l0: 0.161804, l1: 0.165926, l2: 0.178088, l3: 0.210493, l4: 0.279484, l5: 0.417980, l6: 0.642816\n",
            "\n",
            "[epoch: 101/100000, batch: 232/1000, ite: 12529] train loss: 2.8200, accuracy: 88.1329%, tar: 0.2060 \n",
            "l0: 0.114601, l1: 0.116303, l2: 0.126624, l3: 0.148047, l4: 0.194192, l5: 0.273974, l6: 0.516849\n",
            "\n",
            "[epoch: 101/100000, batch: 240/1000, ite: 12530] train loss: 2.8185, accuracy: 91.1955%, tar: 0.2059 \n",
            "l0: 0.119305, l1: 0.120344, l2: 0.136729, l3: 0.171210, l4: 0.227442, l5: 0.352563, l6: 0.585330\n",
            "\n",
            "[epoch: 101/100000, batch: 248/1000, ite: 12531] train loss: 2.8175, accuracy: 89.3843%, tar: 0.2057 \n",
            "l0: 0.135049, l1: 0.140742, l2: 0.155874, l3: 0.189202, l4: 0.268295, l5: 0.381847, l6: 0.563218\n",
            "\n",
            "[epoch: 101/100000, batch: 256/1000, ite: 12532] train loss: 2.8167, accuracy: 89.7259%, tar: 0.2056 \n",
            "l0: 0.093949, l1: 0.100579, l2: 0.110519, l3: 0.147302, l4: 0.229360, l5: 0.345128, l6: 0.543356\n",
            "\n",
            "[epoch: 101/100000, batch: 264/1000, ite: 12533] train loss: 2.8155, accuracy: 91.4245%, tar: 0.2053 \n",
            "l0: 0.102896, l1: 0.108456, l2: 0.119121, l3: 0.146080, l4: 0.200825, l5: 0.322382, l6: 0.442236\n",
            "\n",
            "[epoch: 101/100000, batch: 272/1000, ite: 12534] train loss: 2.8137, accuracy: 92.4702%, tar: 0.2052 \n",
            "l0: 0.148925, l1: 0.155536, l2: 0.169675, l3: 0.202468, l4: 0.281218, l5: 0.430504, l6: 0.669758\n",
            "\n",
            "[epoch: 101/100000, batch: 280/1000, ite: 12535] train loss: 2.8136, accuracy: 89.7420%, tar: 0.2051 \n",
            "l0: 0.136351, l1: 0.138427, l2: 0.150535, l3: 0.175252, l4: 0.219811, l5: 0.315566, l6: 0.528354\n",
            "\n",
            "[epoch: 101/100000, batch: 288/1000, ite: 12536] train loss: 2.8124, accuracy: 90.8835%, tar: 0.2049 \n",
            "l0: 0.150501, l1: 0.156263, l2: 0.159556, l3: 0.175429, l4: 0.227337, l5: 0.320227, l6: 0.547746\n",
            "\n",
            "[epoch: 101/100000, batch: 296/1000, ite: 12537] train loss: 2.8114, accuracy: 88.7306%, tar: 0.2048 \n",
            "l0: 0.182981, l1: 0.184221, l2: 0.189517, l3: 0.201864, l4: 0.227780, l5: 0.301977, l6: 0.451117\n",
            "\n",
            "[epoch: 101/100000, batch: 304/1000, ite: 12538] train loss: 2.8103, accuracy: 90.1217%, tar: 0.2048 \n",
            "l0: 0.145860, l1: 0.143831, l2: 0.157726, l3: 0.183233, l4: 0.237352, l5: 0.335442, l6: 0.544291\n",
            "\n",
            "[epoch: 101/100000, batch: 312/1000, ite: 12539] train loss: 2.8094, accuracy: 89.3112%, tar: 0.2047 \n",
            "l0: 0.223019, l1: 0.230851, l2: 0.243962, l3: 0.268440, l4: 0.330879, l5: 0.403499, l6: 0.553417\n",
            "\n",
            "[epoch: 101/100000, batch: 320/1000, ite: 12540] train loss: 2.8094, accuracy: 89.3072%, tar: 0.2047 \n",
            "l0: 0.171928, l1: 0.174511, l2: 0.185711, l3: 0.218754, l4: 0.296628, l5: 0.413752, l6: 0.626485\n",
            "\n",
            "[epoch: 101/100000, batch: 328/1000, ite: 12541] train loss: 2.8093, accuracy: 89.3513%, tar: 0.2046 \n",
            "l0: 0.171191, l1: 0.178978, l2: 0.187176, l3: 0.212578, l4: 0.287560, l5: 0.399883, l6: 0.626591\n",
            "\n",
            "[epoch: 101/100000, batch: 336/1000, ite: 12542] train loss: 2.8091, accuracy: 87.7089%, tar: 0.2046 \n",
            "l0: 0.162203, l1: 0.163821, l2: 0.171383, l3: 0.192369, l4: 0.254792, l5: 0.338186, l6: 0.496339\n",
            "\n",
            "[epoch: 101/100000, batch: 344/1000, ite: 12543] train loss: 2.8081, accuracy: 91.5463%, tar: 0.2045 \n",
            "l0: 0.125795, l1: 0.131666, l2: 0.142604, l3: 0.167900, l4: 0.225983, l5: 0.316107, l6: 0.495191\n",
            "\n",
            "[epoch: 101/100000, batch: 352/1000, ite: 12544] train loss: 2.8068, accuracy: 91.7702%, tar: 0.2044 \n",
            "l0: 0.111917, l1: 0.112665, l2: 0.125942, l3: 0.149002, l4: 0.209624, l5: 0.314011, l6: 0.512823\n",
            "\n",
            "[epoch: 101/100000, batch: 360/1000, ite: 12545] train loss: 2.8054, accuracy: 90.5235%, tar: 0.2042 \n",
            "l0: 0.152097, l1: 0.150321, l2: 0.160509, l3: 0.199619, l4: 0.270698, l5: 0.398605, l6: 0.657961\n",
            "\n",
            "[epoch: 101/100000, batch: 368/1000, ite: 12546] train loss: 2.8051, accuracy: 90.1904%, tar: 0.2041 \n",
            "l0: 0.134365, l1: 0.136142, l2: 0.147975, l3: 0.177372, l4: 0.246584, l5: 0.364821, l6: 0.641279\n",
            "\n",
            "[epoch: 101/100000, batch: 376/1000, ite: 12547] train loss: 2.8045, accuracy: 91.5738%, tar: 0.2040 \n",
            "l0: 0.188197, l1: 0.184008, l2: 0.200263, l3: 0.232821, l4: 0.301474, l5: 0.395586, l6: 0.645040\n",
            "\n",
            "[epoch: 101/100000, batch: 384/1000, ite: 12548] train loss: 2.8045, accuracy: 89.3761%, tar: 0.2039 \n",
            "l0: 0.083884, l1: 0.086374, l2: 0.096404, l3: 0.124571, l4: 0.184161, l5: 0.310758, l6: 0.462434\n",
            "\n",
            "[epoch: 101/100000, batch: 392/1000, ite: 12549] train loss: 2.8027, accuracy: 93.6233%, tar: 0.2037 \n",
            "l0: 0.071247, l1: 0.072993, l2: 0.079637, l3: 0.099436, l4: 0.142080, l5: 0.203035, l6: 0.320099\n",
            "\n",
            "[epoch: 101/100000, batch: 400/1000, ite: 12550] train loss: 2.8000, accuracy: 94.1986%, tar: 0.2035 \n",
            "l0: 0.105969, l1: 0.109623, l2: 0.121316, l3: 0.143475, l4: 0.200949, l5: 0.290971, l6: 0.444187\n",
            "\n",
            "[epoch: 101/100000, batch: 408/1000, ite: 12551] train loss: 2.7983, accuracy: 92.4954%, tar: 0.2033 \n",
            "l0: 0.105861, l1: 0.106843, l2: 0.118777, l3: 0.151009, l4: 0.232834, l5: 0.361754, l6: 0.594360\n",
            "\n",
            "[epoch: 101/100000, batch: 416/1000, ite: 12552] train loss: 2.7973, accuracy: 90.6333%, tar: 0.2031 \n",
            "l0: 0.162906, l1: 0.162542, l2: 0.172225, l3: 0.192331, l4: 0.238223, l5: 0.367760, l6: 0.569381\n",
            "\n",
            "[epoch: 101/100000, batch: 424/1000, ite: 12553] train loss: 2.7966, accuracy: 89.3649%, tar: 0.2031 \n",
            "l0: 0.146837, l1: 0.148533, l2: 0.154802, l3: 0.163945, l4: 0.196823, l5: 0.291012, l6: 0.429266\n",
            "\n",
            "[epoch: 101/100000, batch: 432/1000, ite: 12554] train loss: 2.7951, accuracy: 91.5611%, tar: 0.2030 \n",
            "l0: 0.111532, l1: 0.113103, l2: 0.125863, l3: 0.152511, l4: 0.226386, l5: 0.343522, l6: 0.570895\n",
            "\n",
            "[epoch: 101/100000, batch: 440/1000, ite: 12555] train loss: 2.7941, accuracy: 90.5769%, tar: 0.2028 \n",
            "l0: 0.111603, l1: 0.115073, l2: 0.124500, l3: 0.148756, l4: 0.185853, l5: 0.293552, l6: 0.531026\n",
            "\n",
            "[epoch: 101/100000, batch: 448/1000, ite: 12556] train loss: 2.7926, accuracy: 92.2008%, tar: 0.2026 \n",
            "l0: 0.188817, l1: 0.196174, l2: 0.204863, l3: 0.226948, l4: 0.282303, l5: 0.358622, l6: 0.527669\n",
            "\n",
            "[epoch: 101/100000, batch: 456/1000, ite: 12557] train loss: 2.7922, accuracy: 89.8343%, tar: 0.2026 \n",
            "l0: 0.222607, l1: 0.223576, l2: 0.238452, l3: 0.260920, l4: 0.307875, l5: 0.360862, l6: 0.499377\n",
            "\n",
            "[epoch: 101/100000, batch: 464/1000, ite: 12558] train loss: 2.7919, accuracy: 90.2624%, tar: 0.2026 \n",
            "l0: 0.181323, l1: 0.183174, l2: 0.193344, l3: 0.214304, l4: 0.257625, l5: 0.342637, l6: 0.538540\n",
            "\n",
            "[epoch: 101/100000, batch: 472/1000, ite: 12559] train loss: 2.7913, accuracy: 89.2833%, tar: 0.2026 \n",
            "l0: 0.142248, l1: 0.144529, l2: 0.153359, l3: 0.184814, l4: 0.243769, l5: 0.335882, l6: 0.503154\n",
            "\n",
            "[epoch: 101/100000, batch: 480/1000, ite: 12560] train loss: 2.7902, accuracy: 91.1842%, tar: 0.2025 \n",
            "l0: 0.125037, l1: 0.129147, l2: 0.141960, l3: 0.167043, l4: 0.234192, l5: 0.320954, l6: 0.542715\n",
            "\n",
            "[epoch: 101/100000, batch: 488/1000, ite: 12561] train loss: 2.7891, accuracy: 90.4669%, tar: 0.2024 \n",
            "l0: 0.130074, l1: 0.131032, l2: 0.144113, l3: 0.173403, l4: 0.237245, l5: 0.328968, l6: 0.547518\n",
            "\n",
            "[epoch: 101/100000, batch: 496/1000, ite: 12562] train loss: 2.7881, accuracy: 91.0498%, tar: 0.2022 \n",
            "l0: 0.111627, l1: 0.117320, l2: 0.130122, l3: 0.168438, l4: 0.226914, l5: 0.320954, l6: 0.540228\n",
            "\n",
            "[epoch: 101/100000, batch: 504/1000, ite: 12563] train loss: 2.7869, accuracy: 92.0183%, tar: 0.2021 \n",
            "l0: 0.097884, l1: 0.097019, l2: 0.106007, l3: 0.121068, l4: 0.168478, l5: 0.259144, l6: 0.420862\n",
            "\n",
            "[epoch: 101/100000, batch: 512/1000, ite: 12564] train loss: 2.7850, accuracy: 92.1470%, tar: 0.2019 \n",
            "l0: 0.122280, l1: 0.122831, l2: 0.133452, l3: 0.160289, l4: 0.225002, l5: 0.325753, l6: 0.490559\n",
            "\n",
            "[epoch: 101/100000, batch: 520/1000, ite: 12565] train loss: 2.7838, accuracy: 92.0194%, tar: 0.2017 \n",
            "l0: 0.137104, l1: 0.138246, l2: 0.149422, l3: 0.171627, l4: 0.226183, l5: 0.335513, l6: 0.519335\n",
            "\n",
            "[epoch: 101/100000, batch: 528/1000, ite: 12566] train loss: 2.7827, accuracy: 90.2105%, tar: 0.2016 \n",
            "l0: 0.163212, l1: 0.165850, l2: 0.176003, l3: 0.206100, l4: 0.258854, l5: 0.347551, l6: 0.509270\n",
            "\n",
            "[epoch: 101/100000, batch: 536/1000, ite: 12567] train loss: 2.7820, accuracy: 91.2257%, tar: 0.2016 \n",
            "l0: 0.119324, l1: 0.118592, l2: 0.135285, l3: 0.164114, l4: 0.254508, l5: 0.432183, l6: 0.658914\n",
            "\n",
            "[epoch: 101/100000, batch: 544/1000, ite: 12568] train loss: 2.7816, accuracy: 89.7002%, tar: 0.2014 \n",
            "l0: 0.197360, l1: 0.198621, l2: 0.209454, l3: 0.233142, l4: 0.286171, l5: 0.363851, l6: 0.545969\n",
            "\n",
            "[epoch: 101/100000, batch: 552/1000, ite: 12569] train loss: 2.7812, accuracy: 89.3804%, tar: 0.2014 \n",
            "l0: 0.127918, l1: 0.128648, l2: 0.139778, l3: 0.169550, l4: 0.232977, l5: 0.359289, l6: 0.622906\n",
            "\n",
            "[epoch: 101/100000, batch: 560/1000, ite: 12570] train loss: 2.7806, accuracy: 90.6650%, tar: 0.2013 \n",
            "l0: 0.172815, l1: 0.173284, l2: 0.179582, l3: 0.194121, l4: 0.226796, l5: 0.294589, l6: 0.488751\n",
            "\n",
            "[epoch: 101/100000, batch: 568/1000, ite: 12571] train loss: 2.7796, accuracy: 91.7548%, tar: 0.2012 \n",
            "l0: 0.130422, l1: 0.132512, l2: 0.147175, l3: 0.178164, l4: 0.258399, l5: 0.398954, l6: 0.610017\n",
            "\n",
            "[epoch: 101/100000, batch: 576/1000, ite: 12572] train loss: 2.7790, accuracy: 88.8618%, tar: 0.2011 \n",
            "l0: 0.089157, l1: 0.097276, l2: 0.106147, l3: 0.124596, l4: 0.164339, l5: 0.240026, l6: 0.420513\n",
            "\n",
            "[epoch: 101/100000, batch: 584/1000, ite: 12573] train loss: 2.7771, accuracy: 92.8546%, tar: 0.2009 \n",
            "l0: 0.122454, l1: 0.120505, l2: 0.130792, l3: 0.153448, l4: 0.206842, l5: 0.302001, l6: 0.534217\n",
            "\n",
            "[epoch: 101/100000, batch: 592/1000, ite: 12574] train loss: 2.7759, accuracy: 91.0634%, tar: 0.2008 \n",
            "l0: 0.126969, l1: 0.130435, l2: 0.140104, l3: 0.158177, l4: 0.203258, l5: 0.303414, l6: 0.493253\n",
            "\n",
            "[epoch: 101/100000, batch: 600/1000, ite: 12575] train loss: 2.7746, accuracy: 90.9073%, tar: 0.2006 \n",
            "l0: 0.116232, l1: 0.119047, l2: 0.130093, l3: 0.152526, l4: 0.215663, l5: 0.343949, l6: 0.604740\n",
            "\n",
            "[epoch: 101/100000, batch: 608/1000, ite: 12576] train loss: 2.7737, accuracy: 90.3948%, tar: 0.2005 \n",
            "l0: 0.106716, l1: 0.111410, l2: 0.121958, l3: 0.156416, l4: 0.232523, l5: 0.360461, l6: 0.552482\n",
            "\n",
            "[epoch: 101/100000, batch: 616/1000, ite: 12577] train loss: 2.7727, accuracy: 93.0949%, tar: 0.2003 \n",
            "l0: 0.136809, l1: 0.137919, l2: 0.151051, l3: 0.175324, l4: 0.230959, l5: 0.328550, l6: 0.589142\n",
            "\n",
            "[epoch: 101/100000, batch: 624/1000, ite: 12578] train loss: 2.7719, accuracy: 89.6466%, tar: 0.2002 \n",
            "l0: 0.106268, l1: 0.110529, l2: 0.122517, l3: 0.146697, l4: 0.210858, l5: 0.313179, l6: 0.516193\n",
            "\n",
            "[epoch: 101/100000, batch: 632/1000, ite: 12579] train loss: 2.7706, accuracy: 91.7526%, tar: 0.2001 \n",
            "l0: 0.193951, l1: 0.203558, l2: 0.210838, l3: 0.232810, l4: 0.282874, l5: 0.400728, l6: 0.653302\n",
            "\n",
            "[epoch: 101/100000, batch: 640/1000, ite: 12580] train loss: 2.7707, accuracy: 88.7527%, tar: 0.2000 \n",
            "l0: 0.129684, l1: 0.136436, l2: 0.150401, l3: 0.183087, l4: 0.241723, l5: 0.349697, l6: 0.547580\n",
            "\n",
            "[epoch: 101/100000, batch: 648/1000, ite: 12581] train loss: 2.7699, accuracy: 90.1686%, tar: 0.1999 \n",
            "l0: 0.201544, l1: 0.205352, l2: 0.221885, l3: 0.266071, l4: 0.356015, l5: 0.499855, l6: 0.748301\n",
            "\n",
            "[epoch: 101/100000, batch: 656/1000, ite: 12582] train loss: 2.7708, accuracy: 87.9002%, tar: 0.1999 \n",
            "l0: 0.115575, l1: 0.117713, l2: 0.130895, l3: 0.162956, l4: 0.243777, l5: 0.380724, l6: 0.760054\n",
            "\n",
            "[epoch: 101/100000, batch: 664/1000, ite: 12583] train loss: 2.7706, accuracy: 88.5539%, tar: 0.1998 \n",
            "l0: 0.108954, l1: 0.109689, l2: 0.118224, l3: 0.141886, l4: 0.193387, l5: 0.314611, l6: 0.479545\n",
            "\n",
            "[epoch: 101/100000, batch: 672/1000, ite: 12584] train loss: 2.7692, accuracy: 91.0576%, tar: 0.1996 \n",
            "l0: 0.108373, l1: 0.108279, l2: 0.119290, l3: 0.142788, l4: 0.190523, l5: 0.282802, l6: 0.474115\n",
            "\n",
            "[epoch: 101/100000, batch: 680/1000, ite: 12585] train loss: 2.7677, accuracy: 91.9522%, tar: 0.1995 \n",
            "l0: 0.109113, l1: 0.109467, l2: 0.122366, l3: 0.155857, l4: 0.228246, l5: 0.385318, l6: 0.638808\n",
            "\n",
            "[epoch: 101/100000, batch: 688/1000, ite: 12586] train loss: 2.7670, accuracy: 90.2262%, tar: 0.1993 \n",
            "l0: 0.091537, l1: 0.090535, l2: 0.098164, l3: 0.112532, l4: 0.161999, l5: 0.252985, l6: 0.417564\n",
            "\n",
            "[epoch: 101/100000, batch: 696/1000, ite: 12587] train loss: 2.7651, accuracy: 92.6337%, tar: 0.1991 \n",
            "l0: 0.142662, l1: 0.143552, l2: 0.152103, l3: 0.172260, l4: 0.215330, l5: 0.295077, l6: 0.455855\n",
            "\n",
            "[epoch: 101/100000, batch: 704/1000, ite: 12588] train loss: 2.7638, accuracy: 91.3114%, tar: 0.1990 \n",
            "l0: 0.149576, l1: 0.152083, l2: 0.162093, l3: 0.186923, l4: 0.240577, l5: 0.334721, l6: 0.518353\n",
            "\n",
            "[epoch: 101/100000, batch: 712/1000, ite: 12589] train loss: 2.7630, accuracy: 92.0693%, tar: 0.1990 \n",
            "l0: 0.100245, l1: 0.103641, l2: 0.116451, l3: 0.150656, l4: 0.206274, l5: 0.331207, l6: 0.558563\n",
            "\n",
            "[epoch: 101/100000, batch: 720/1000, ite: 12590] train loss: 2.7619, accuracy: 91.5127%, tar: 0.1988 \n",
            "l0: 0.134991, l1: 0.139873, l2: 0.150781, l3: 0.176073, l4: 0.221423, l5: 0.327883, l6: 0.527595\n",
            "\n",
            "[epoch: 101/100000, batch: 728/1000, ite: 12591] train loss: 2.7609, accuracy: 90.8255%, tar: 0.1987 \n",
            "l0: 0.091613, l1: 0.093860, l2: 0.104656, l3: 0.134325, l4: 0.188734, l5: 0.283142, l6: 0.529476\n",
            "\n",
            "[epoch: 101/100000, batch: 736/1000, ite: 12592] train loss: 2.7596, accuracy: 90.8767%, tar: 0.1985 \n",
            "l0: 0.114939, l1: 0.117050, l2: 0.126351, l3: 0.159591, l4: 0.217840, l5: 0.339039, l6: 0.534421\n",
            "\n",
            "[epoch: 101/100000, batch: 744/1000, ite: 12593] train loss: 2.7586, accuracy: 91.2312%, tar: 0.1984 \n",
            "l0: 0.143721, l1: 0.145457, l2: 0.156947, l3: 0.181225, l4: 0.245829, l5: 0.340217, l6: 0.516958\n",
            "\n",
            "[epoch: 101/100000, batch: 752/1000, ite: 12594] train loss: 2.7577, accuracy: 90.4957%, tar: 0.1983 \n",
            "l0: 0.108094, l1: 0.108318, l2: 0.117994, l3: 0.144913, l4: 0.205025, l5: 0.318286, l6: 0.502437\n",
            "\n",
            "[epoch: 101/100000, batch: 760/1000, ite: 12595] train loss: 2.7564, accuracy: 91.2166%, tar: 0.1981 \n",
            "l0: 0.304450, l1: 0.303769, l2: 0.311200, l3: 0.329999, l4: 0.401387, l5: 0.542420, l6: 0.786241\n",
            "\n",
            "[epoch: 101/100000, batch: 768/1000, ite: 12596] train loss: 2.7582, accuracy: 85.5012%, tar: 0.1983 \n",
            "l0: 0.110307, l1: 0.112961, l2: 0.125574, l3: 0.160267, l4: 0.213331, l5: 0.298894, l6: 0.483085\n",
            "\n",
            "[epoch: 101/100000, batch: 776/1000, ite: 12597] train loss: 2.7569, accuracy: 91.1062%, tar: 0.1981 \n",
            "l0: 0.173195, l1: 0.174113, l2: 0.182657, l3: 0.208239, l4: 0.268922, l5: 0.382415, l6: 0.627897\n",
            "\n",
            "[epoch: 101/100000, batch: 784/1000, ite: 12598] train loss: 2.7567, accuracy: 90.1975%, tar: 0.1981 \n",
            "l0: 0.121993, l1: 0.125022, l2: 0.138546, l3: 0.172072, l4: 0.230679, l5: 0.350456, l6: 0.550345\n",
            "\n",
            "[epoch: 101/100000, batch: 792/1000, ite: 12599] train loss: 2.7558, accuracy: 89.8372%, tar: 0.1980 \n",
            "l0: 0.179694, l1: 0.182141, l2: 0.197809, l3: 0.222190, l4: 0.278459, l5: 0.364363, l6: 0.518781\n",
            "\n",
            "[epoch: 101/100000, batch: 800/1000, ite: 12600] train loss: 2.7553, accuracy: 90.8051%, tar: 0.1979 \n",
            "l0: 0.138541, l1: 0.140566, l2: 0.152165, l3: 0.184168, l4: 0.256347, l5: 0.388550, l6: 0.657645\n",
            "\n",
            "[epoch: 101/100000, batch: 808/1000, ite: 12601] train loss: 2.7550, accuracy: 90.2152%, tar: 0.1978 \n",
            "l0: 0.155700, l1: 0.157010, l2: 0.170486, l3: 0.193723, l4: 0.261356, l5: 0.376712, l6: 0.539988\n",
            "\n",
            "[epoch: 101/100000, batch: 816/1000, ite: 12602] train loss: 2.7544, accuracy: 90.8343%, tar: 0.1978 \n",
            "l0: 0.158776, l1: 0.168344, l2: 0.184230, l3: 0.206488, l4: 0.260021, l5: 0.384995, l6: 0.613005\n",
            "\n",
            "[epoch: 101/100000, batch: 824/1000, ite: 12603] train loss: 2.7543, accuracy: 88.3829%, tar: 0.1977 \n",
            "l0: 0.137781, l1: 0.139700, l2: 0.152795, l3: 0.182037, l4: 0.260260, l5: 0.377291, l6: 0.559783\n",
            "\n",
            "[epoch: 101/100000, batch: 832/1000, ite: 12604] train loss: 2.7536, accuracy: 90.8486%, tar: 0.1976 \n",
            "l0: 0.163599, l1: 0.167194, l2: 0.174529, l3: 0.199044, l4: 0.274525, l5: 0.362479, l6: 0.603676\n",
            "\n",
            "[epoch: 101/100000, batch: 840/1000, ite: 12605] train loss: 2.7533, accuracy: 89.8589%, tar: 0.1976 \n",
            "l0: 0.151203, l1: 0.152949, l2: 0.165365, l3: 0.195897, l4: 0.251558, l5: 0.364301, l6: 0.563254\n",
            "\n",
            "[epoch: 101/100000, batch: 848/1000, ite: 12606] train loss: 2.7528, accuracy: 90.1069%, tar: 0.1975 \n",
            "l0: 0.158210, l1: 0.157340, l2: 0.172337, l3: 0.215565, l4: 0.319131, l5: 0.515886, l6: 0.838660\n",
            "\n",
            "[epoch: 101/100000, batch: 856/1000, ite: 12607] train loss: 2.7535, accuracy: 86.8567%, tar: 0.1974 \n",
            "l0: 0.123931, l1: 0.126326, l2: 0.137292, l3: 0.182271, l4: 0.258629, l5: 0.406138, l6: 0.638345\n",
            "\n",
            "[epoch: 101/100000, batch: 864/1000, ite: 12608] train loss: 2.7531, accuracy: 89.4984%, tar: 0.1973 \n",
            "l0: 0.152287, l1: 0.154589, l2: 0.164848, l3: 0.185224, l4: 0.236677, l5: 0.340189, l6: 0.535678\n",
            "\n",
            "[epoch: 101/100000, batch: 872/1000, ite: 12609] train loss: 2.7524, accuracy: 90.5611%, tar: 0.1972 \n",
            "l0: 0.195760, l1: 0.199568, l2: 0.206499, l3: 0.237459, l4: 0.300420, l5: 0.426001, l6: 0.701237\n",
            "\n",
            "[epoch: 101/100000, batch: 880/1000, ite: 12610] train loss: 2.7527, accuracy: 87.7032%, tar: 0.1972 \n",
            "l0: 0.173645, l1: 0.176787, l2: 0.186443, l3: 0.224930, l4: 0.297358, l5: 0.429112, l6: 0.680401\n",
            "\n",
            "[epoch: 101/100000, batch: 888/1000, ite: 12611] train loss: 2.7529, accuracy: 89.4299%, tar: 0.1972 \n",
            "l0: 0.175957, l1: 0.180805, l2: 0.192844, l3: 0.219178, l4: 0.296353, l5: 0.412489, l6: 0.655252\n",
            "\n",
            "[epoch: 101/100000, batch: 896/1000, ite: 12612] train loss: 2.7530, accuracy: 88.5852%, tar: 0.1971 \n",
            "l0: 0.090395, l1: 0.092634, l2: 0.103139, l3: 0.127431, l4: 0.188387, l5: 0.305577, l6: 0.494489\n",
            "\n",
            "[epoch: 101/100000, batch: 904/1000, ite: 12613] train loss: 2.7516, accuracy: 92.0639%, tar: 0.1970 \n",
            "l0: 0.094204, l1: 0.097960, l2: 0.107064, l3: 0.129867, l4: 0.187823, l5: 0.300833, l6: 0.479491\n",
            "\n",
            "[epoch: 101/100000, batch: 912/1000, ite: 12614] train loss: 2.7501, accuracy: 91.1614%, tar: 0.1968 \n",
            "l0: 0.120537, l1: 0.120059, l2: 0.129273, l3: 0.148017, l4: 0.205127, l5: 0.329479, l6: 0.488330\n",
            "\n",
            "[epoch: 101/100000, batch: 920/1000, ite: 12615] train loss: 2.7489, accuracy: 90.9890%, tar: 0.1967 \n",
            "l0: 0.103536, l1: 0.105247, l2: 0.113354, l3: 0.135207, l4: 0.179755, l5: 0.283279, l6: 0.447487\n",
            "\n",
            "[epoch: 101/100000, batch: 928/1000, ite: 12616] train loss: 2.7475, accuracy: 91.4413%, tar: 0.1965 \n",
            "l0: 0.147122, l1: 0.146063, l2: 0.159772, l3: 0.192923, l4: 0.258496, l5: 0.382108, l6: 0.653572\n",
            "\n",
            "[epoch: 101/100000, batch: 936/1000, ite: 12617] train loss: 2.7472, accuracy: 89.4193%, tar: 0.1964 \n",
            "l0: 0.161615, l1: 0.169298, l2: 0.181943, l3: 0.217561, l4: 0.314309, l5: 0.419336, l6: 0.589158\n",
            "\n",
            "[epoch: 101/100000, batch: 944/1000, ite: 12618] train loss: 2.7471, accuracy: 89.7250%, tar: 0.1964 \n",
            "l0: 0.170587, l1: 0.170587, l2: 0.182143, l3: 0.216946, l4: 0.282499, l5: 0.406491, l6: 0.727007\n",
            "\n",
            "[epoch: 101/100000, batch: 952/1000, ite: 12619] train loss: 2.7473, accuracy: 87.4317%, tar: 0.1964 \n",
            "l0: 0.090570, l1: 0.091563, l2: 0.105125, l3: 0.136616, l4: 0.188657, l5: 0.283905, l6: 0.502893\n",
            "\n",
            "[epoch: 101/100000, batch: 960/1000, ite: 12620] train loss: 2.7460, accuracy: 90.7260%, tar: 0.1962 \n",
            "l0: 0.091631, l1: 0.093568, l2: 0.105529, l3: 0.132082, l4: 0.190875, l5: 0.275125, l6: 0.501723\n",
            "\n",
            "[epoch: 101/100000, batch: 968/1000, ite: 12621] train loss: 2.7446, accuracy: 92.3647%, tar: 0.1960 \n",
            "l0: 0.120853, l1: 0.124673, l2: 0.132724, l3: 0.145781, l4: 0.181976, l5: 0.258802, l6: 0.456721\n",
            "\n",
            "[epoch: 101/100000, batch: 976/1000, ite: 12622] train loss: 2.7432, accuracy: 90.7895%, tar: 0.1959 \n",
            "l0: 0.200336, l1: 0.199418, l2: 0.209126, l3: 0.238079, l4: 0.299968, l5: 0.423036, l6: 0.610655\n",
            "\n",
            "[epoch: 101/100000, batch: 984/1000, ite: 12623] train loss: 2.7434, accuracy: 87.8713%, tar: 0.1959 \n",
            "l0: 0.246955, l1: 0.268183, l2: 0.276163, l3: 0.296663, l4: 0.341442, l5: 0.437224, l6: 0.566531\n",
            "\n",
            "[epoch: 101/100000, batch: 992/1000, ite: 12624] train loss: 2.7438, accuracy: 88.8738%, tar: 0.1960 \n",
            "l0: 0.107541, l1: 0.109309, l2: 0.121168, l3: 0.147973, l4: 0.209482, l5: 0.317909, l6: 0.573016\n",
            "\n",
            "[epoch: 101/100000, batch: 1000/1000, ite: 12625] train loss: 2.7429, accuracy: 90.8594%, tar: 0.1958 \n",
            "l0: 0.231663, l1: 0.231726, l2: 0.248400, l3: 0.294861, l4: 0.381202, l5: 0.521479, l6: 0.798896\n",
            "\n",
            "[epoch: 102/100000, batch: 8/1000, ite: 12626] train loss: 2.7441, accuracy: 85.5281%, tar: 0.1959 \n",
            "l0: 0.112450, l1: 0.114569, l2: 0.126865, l3: 0.151753, l4: 0.218791, l5: 0.285384, l6: 0.484454\n",
            "\n",
            "[epoch: 102/100000, batch: 16/1000, ite: 12627] train loss: 2.7429, accuracy: 91.7680%, tar: 0.1958 \n",
            "l0: 0.097107, l1: 0.101521, l2: 0.109514, l3: 0.140861, l4: 0.191024, l5: 0.294588, l6: 0.511184\n",
            "\n",
            "[epoch: 102/100000, batch: 24/1000, ite: 12628] train loss: 2.7417, accuracy: 91.2208%, tar: 0.1956 \n",
            "l0: 0.072978, l1: 0.073993, l2: 0.086513, l3: 0.108284, l4: 0.157322, l5: 0.236551, l6: 0.457699\n",
            "\n",
            "[epoch: 102/100000, batch: 32/1000, ite: 12629] train loss: 2.7399, accuracy: 92.3206%, tar: 0.1954 \n",
            "l0: 0.131632, l1: 0.136886, l2: 0.148466, l3: 0.180646, l4: 0.249999, l5: 0.385142, l6: 0.561757\n",
            "\n",
            "[epoch: 102/100000, batch: 40/1000, ite: 12630] train loss: 2.7393, accuracy: 89.4884%, tar: 0.1953 \n",
            "l0: 0.108249, l1: 0.110167, l2: 0.120126, l3: 0.150543, l4: 0.207449, l5: 0.331491, l6: 0.579924\n",
            "\n",
            "[epoch: 102/100000, batch: 48/1000, ite: 12631] train loss: 2.7384, accuracy: 92.1458%, tar: 0.1952 \n",
            "l0: 0.191442, l1: 0.193245, l2: 0.205156, l3: 0.242012, l4: 0.307378, l5: 0.436273, l6: 0.619115\n",
            "\n",
            "[epoch: 102/100000, batch: 56/1000, ite: 12632] train loss: 2.7385, accuracy: 90.4644%, tar: 0.1952 \n",
            "l0: 0.185582, l1: 0.189185, l2: 0.200522, l3: 0.219591, l4: 0.277994, l5: 0.362671, l6: 0.593348\n",
            "\n",
            "[epoch: 102/100000, batch: 64/1000, ite: 12633] train loss: 2.7384, accuracy: 88.9139%, tar: 0.1952 \n",
            "l0: 0.113727, l1: 0.117587, l2: 0.126334, l3: 0.148887, l4: 0.207852, l5: 0.309122, l6: 0.474031\n",
            "\n",
            "[epoch: 102/100000, batch: 72/1000, ite: 12634] train loss: 2.7372, accuracy: 91.2630%, tar: 0.1950 \n",
            "l0: 0.153393, l1: 0.157049, l2: 0.169059, l3: 0.196941, l4: 0.264401, l5: 0.384469, l6: 0.610826\n",
            "\n",
            "[epoch: 102/100000, batch: 80/1000, ite: 12635] train loss: 2.7369, accuracy: 89.0257%, tar: 0.1950 \n",
            "l0: 0.164785, l1: 0.170974, l2: 0.179462, l3: 0.210105, l4: 0.268426, l5: 0.360048, l6: 0.564198\n",
            "\n",
            "[epoch: 102/100000, batch: 88/1000, ite: 12636] train loss: 2.7365, accuracy: 89.2616%, tar: 0.1949 \n",
            "l0: 0.133565, l1: 0.136894, l2: 0.148997, l3: 0.172248, l4: 0.237433, l5: 0.364394, l6: 0.594567\n",
            "\n",
            "[epoch: 102/100000, batch: 96/1000, ite: 12637] train loss: 2.7360, accuracy: 89.1375%, tar: 0.1948 \n",
            "l0: 0.133351, l1: 0.135979, l2: 0.149342, l3: 0.178679, l4: 0.230696, l5: 0.354486, l6: 0.537270\n",
            "\n",
            "[epoch: 102/100000, batch: 104/1000, ite: 12638] train loss: 2.7352, accuracy: 90.5366%, tar: 0.1947 \n",
            "l0: 0.124441, l1: 0.127649, l2: 0.136037, l3: 0.154307, l4: 0.206493, l5: 0.288889, l6: 0.450609\n",
            "\n",
            "[epoch: 102/100000, batch: 112/1000, ite: 12639] train loss: 2.7340, accuracy: 91.5870%, tar: 0.1946 \n",
            "l0: 0.127602, l1: 0.128128, l2: 0.143565, l3: 0.175236, l4: 0.240164, l5: 0.357176, l6: 0.582011\n",
            "\n",
            "[epoch: 102/100000, batch: 120/1000, ite: 12640] train loss: 2.7334, accuracy: 90.1262%, tar: 0.1945 \n",
            "l0: 0.155498, l1: 0.156748, l2: 0.169342, l3: 0.194894, l4: 0.261892, l5: 0.379906, l6: 0.569259\n",
            "\n",
            "[epoch: 102/100000, batch: 128/1000, ite: 12641] train loss: 2.7330, accuracy: 90.2583%, tar: 0.1944 \n",
            "l0: 0.139761, l1: 0.143608, l2: 0.158024, l3: 0.196494, l4: 0.286451, l5: 0.387328, l6: 0.572538\n",
            "\n",
            "[epoch: 102/100000, batch: 136/1000, ite: 12642] train loss: 2.7325, accuracy: 91.7513%, tar: 0.1944 \n",
            "l0: 0.105820, l1: 0.110590, l2: 0.127267, l3: 0.165403, l4: 0.237096, l5: 0.369153, l6: 0.576662\n",
            "\n",
            "[epoch: 102/100000, batch: 144/1000, ite: 12643] train loss: 2.7318, accuracy: 91.5024%, tar: 0.1942 \n",
            "l0: 0.163478, l1: 0.164737, l2: 0.180177, l3: 0.201793, l4: 0.262803, l5: 0.390297, l6: 0.624433\n",
            "\n",
            "[epoch: 102/100000, batch: 152/1000, ite: 12644] train loss: 2.7316, accuracy: 89.1093%, tar: 0.1942 \n",
            "l0: 0.089519, l1: 0.090870, l2: 0.104342, l3: 0.132143, l4: 0.209724, l5: 0.303145, l6: 0.503234\n",
            "\n",
            "[epoch: 102/100000, batch: 160/1000, ite: 12645] train loss: 2.7304, accuracy: 92.4256%, tar: 0.1940 \n",
            "l0: 0.169418, l1: 0.168786, l2: 0.177139, l3: 0.194508, l4: 0.239609, l5: 0.356430, l6: 0.523441\n",
            "\n",
            "[epoch: 102/100000, batch: 168/1000, ite: 12646] train loss: 2.7298, accuracy: 90.5969%, tar: 0.1940 \n",
            "l0: 0.074853, l1: 0.076997, l2: 0.087938, l3: 0.116414, l4: 0.174243, l5: 0.278955, l6: 0.487812\n",
            "\n",
            "[epoch: 102/100000, batch: 176/1000, ite: 12647] train loss: 2.7284, accuracy: 91.8290%, tar: 0.1938 \n",
            "l0: 0.081485, l1: 0.083454, l2: 0.091477, l3: 0.114248, l4: 0.174064, l5: 0.260593, l6: 0.494623\n",
            "\n",
            "[epoch: 102/100000, batch: 184/1000, ite: 12648] train loss: 2.7269, accuracy: 92.2267%, tar: 0.1936 \n",
            "l0: 0.200299, l1: 0.196148, l2: 0.206817, l3: 0.233335, l4: 0.290186, l5: 0.435802, l6: 0.558305\n",
            "\n",
            "[epoch: 102/100000, batch: 192/1000, ite: 12649] train loss: 2.7268, accuracy: 89.1135%, tar: 0.1936 \n",
            "l0: 0.123078, l1: 0.124660, l2: 0.134507, l3: 0.157464, l4: 0.208354, l5: 0.287356, l6: 0.470296\n",
            "\n",
            "[epoch: 102/100000, batch: 200/1000, ite: 12650] train loss: 2.7256, accuracy: 91.9959%, tar: 0.1935 \n",
            "l0: 0.116498, l1: 0.121391, l2: 0.134013, l3: 0.163627, l4: 0.222088, l5: 0.323360, l6: 0.544397\n",
            "\n",
            "[epoch: 102/100000, batch: 208/1000, ite: 12651] train loss: 2.7247, accuracy: 91.5140%, tar: 0.1934 \n",
            "l0: 0.109532, l1: 0.113506, l2: 0.125798, l3: 0.158816, l4: 0.206871, l5: 0.300402, l6: 0.523498\n",
            "\n",
            "[epoch: 102/100000, batch: 216/1000, ite: 12652] train loss: 2.7237, accuracy: 90.7787%, tar: 0.1933 \n",
            "l0: 0.174955, l1: 0.183822, l2: 0.188105, l3: 0.206019, l4: 0.241510, l5: 0.322451, l6: 0.469287\n",
            "\n",
            "[epoch: 102/100000, batch: 224/1000, ite: 12653] train loss: 2.7230, accuracy: 89.2455%, tar: 0.1932 \n",
            "l0: 0.166716, l1: 0.179031, l2: 0.198808, l3: 0.244974, l4: 0.339191, l5: 0.471902, l6: 0.708336\n",
            "\n",
            "[epoch: 102/100000, batch: 232/1000, ite: 12654] train loss: 2.7234, accuracy: 87.9668%, tar: 0.1932 \n",
            "l0: 0.160432, l1: 0.164801, l2: 0.184718, l3: 0.226902, l4: 0.321841, l5: 0.494081, l6: 0.742804\n",
            "\n",
            "[epoch: 102/100000, batch: 240/1000, ite: 12655] train loss: 2.7240, accuracy: 88.6102%, tar: 0.1931 \n",
            "l0: 0.142079, l1: 0.147633, l2: 0.157377, l3: 0.185391, l4: 0.248801, l5: 0.385218, l6: 0.614973\n",
            "\n",
            "[epoch: 102/100000, batch: 248/1000, ite: 12656] train loss: 2.7236, accuracy: 90.5082%, tar: 0.1931 \n",
            "l0: 0.096248, l1: 0.096686, l2: 0.106543, l3: 0.134358, l4: 0.207234, l5: 0.309996, l6: 0.485689\n",
            "\n",
            "[epoch: 102/100000, batch: 256/1000, ite: 12657] train loss: 2.7224, accuracy: 91.6214%, tar: 0.1929 \n",
            "l0: 0.095100, l1: 0.096633, l2: 0.107186, l3: 0.130900, l4: 0.196200, l5: 0.294292, l6: 0.496359\n",
            "\n",
            "[epoch: 102/100000, batch: 264/1000, ite: 12658] train loss: 2.7211, accuracy: 91.9441%, tar: 0.1928 \n",
            "l0: 0.092488, l1: 0.100872, l2: 0.107289, l3: 0.138303, l4: 0.184703, l5: 0.263397, l6: 0.515404\n",
            "\n",
            "[epoch: 102/100000, batch: 272/1000, ite: 12659] train loss: 2.7199, accuracy: 91.1646%, tar: 0.1926 \n",
            "l0: 0.100444, l1: 0.099786, l2: 0.110289, l3: 0.139802, l4: 0.200752, l5: 0.311776, l6: 0.542790\n",
            "\n",
            "[epoch: 102/100000, batch: 280/1000, ite: 12660] train loss: 2.7189, accuracy: 90.1423%, tar: 0.1925 \n",
            "l0: 0.112128, l1: 0.121250, l2: 0.132252, l3: 0.167127, l4: 0.219544, l5: 0.266119, l6: 0.462378\n",
            "\n",
            "[epoch: 102/100000, batch: 288/1000, ite: 12661] train loss: 2.7177, accuracy: 91.8967%, tar: 0.1924 \n",
            "l0: 0.169601, l1: 0.171027, l2: 0.183532, l3: 0.213655, l4: 0.300451, l5: 0.400320, l6: 0.583879\n",
            "\n",
            "[epoch: 102/100000, batch: 296/1000, ite: 12662] train loss: 2.7175, accuracy: 90.1460%, tar: 0.1923 \n",
            "l0: 0.122674, l1: 0.124868, l2: 0.137121, l3: 0.162981, l4: 0.219611, l5: 0.332682, l6: 0.550958\n",
            "\n",
            "[epoch: 102/100000, batch: 304/1000, ite: 12663] train loss: 2.7167, accuracy: 90.3555%, tar: 0.1922 \n",
            "l0: 0.176927, l1: 0.178834, l2: 0.189503, l3: 0.214511, l4: 0.283770, l5: 0.371780, l6: 0.594035\n",
            "\n",
            "[epoch: 102/100000, batch: 312/1000, ite: 12664] train loss: 2.7166, accuracy: 90.4470%, tar: 0.1922 \n",
            "l0: 0.100004, l1: 0.104268, l2: 0.114957, l3: 0.146308, l4: 0.229955, l5: 0.370471, l6: 0.671055\n",
            "\n",
            "[epoch: 102/100000, batch: 320/1000, ite: 12665] train loss: 2.7161, accuracy: 90.9977%, tar: 0.1921 \n",
            "l0: 0.101519, l1: 0.105641, l2: 0.117733, l3: 0.144191, l4: 0.214012, l5: 0.326331, l6: 0.540685\n",
            "\n",
            "[epoch: 102/100000, batch: 328/1000, ite: 12666] train loss: 2.7152, accuracy: 90.8049%, tar: 0.1919 \n",
            "l0: 0.087315, l1: 0.088732, l2: 0.101958, l3: 0.128395, l4: 0.189658, l5: 0.300488, l6: 0.527585\n",
            "\n",
            "[epoch: 102/100000, batch: 336/1000, ite: 12667] train loss: 2.7140, accuracy: 91.8986%, tar: 0.1918 \n",
            "l0: 0.094150, l1: 0.096182, l2: 0.106532, l3: 0.127995, l4: 0.179932, l5: 0.292915, l6: 0.542420\n",
            "\n",
            "[epoch: 102/100000, batch: 344/1000, ite: 12668] train loss: 2.7129, accuracy: 91.0142%, tar: 0.1916 \n",
            "l0: 0.181235, l1: 0.181322, l2: 0.190552, l3: 0.210729, l4: 0.258752, l5: 0.344919, l6: 0.604874\n",
            "\n",
            "[epoch: 102/100000, batch: 352/1000, ite: 12669] train loss: 2.7127, accuracy: 89.2541%, tar: 0.1916 \n",
            "l0: 0.130125, l1: 0.134893, l2: 0.153318, l3: 0.197399, l4: 0.280952, l5: 0.467229, l6: 0.688527\n",
            "\n",
            "[epoch: 102/100000, batch: 360/1000, ite: 12670] train loss: 2.7128, accuracy: 89.9450%, tar: 0.1915 \n",
            "l0: 0.126646, l1: 0.126721, l2: 0.141631, l3: 0.175439, l4: 0.243810, l5: 0.338538, l6: 0.561967\n",
            "\n",
            "[epoch: 102/100000, batch: 368/1000, ite: 12671] train loss: 2.7121, accuracy: 91.2090%, tar: 0.1914 \n",
            "l0: 0.108323, l1: 0.111912, l2: 0.123670, l3: 0.145204, l4: 0.198272, l5: 0.297529, l6: 0.488491\n",
            "\n",
            "[epoch: 102/100000, batch: 376/1000, ite: 12672] train loss: 2.7110, accuracy: 92.2798%, tar: 0.1913 \n",
            "l0: 0.115376, l1: 0.119080, l2: 0.126580, l3: 0.153348, l4: 0.212853, l5: 0.333669, l6: 0.574453\n",
            "\n",
            "[epoch: 102/100000, batch: 384/1000, ite: 12673] train loss: 2.7102, accuracy: 89.7014%, tar: 0.1912 \n",
            "l0: 0.111313, l1: 0.115768, l2: 0.120812, l3: 0.141240, l4: 0.182742, l5: 0.290186, l6: 0.522896\n",
            "\n",
            "[epoch: 102/100000, batch: 392/1000, ite: 12674] train loss: 2.7092, accuracy: 90.8238%, tar: 0.1911 \n",
            "l0: 0.101979, l1: 0.102473, l2: 0.109320, l3: 0.130676, l4: 0.187530, l5: 0.278111, l6: 0.473958\n",
            "\n",
            "[epoch: 102/100000, batch: 400/1000, ite: 12675] train loss: 2.7080, accuracy: 92.1831%, tar: 0.1909 \n",
            "l0: 0.131165, l1: 0.135094, l2: 0.146428, l3: 0.173635, l4: 0.228184, l5: 0.340300, l6: 0.554153\n",
            "\n",
            "[epoch: 102/100000, batch: 408/1000, ite: 12676] train loss: 2.7073, accuracy: 89.7423%, tar: 0.1908 \n",
            "l0: 0.094256, l1: 0.099893, l2: 0.113327, l3: 0.149220, l4: 0.217981, l5: 0.314549, l6: 0.530432\n",
            "\n",
            "[epoch: 102/100000, batch: 416/1000, ite: 12677] train loss: 2.7064, accuracy: 91.5039%, tar: 0.1907 \n",
            "l0: 0.133903, l1: 0.136256, l2: 0.146419, l3: 0.167491, l4: 0.225317, l5: 0.340159, l6: 0.607375\n",
            "\n",
            "[epoch: 102/100000, batch: 424/1000, ite: 12678] train loss: 2.7059, accuracy: 90.4274%, tar: 0.1906 \n",
            "l0: 0.139026, l1: 0.141661, l2: 0.155248, l3: 0.195127, l4: 0.285113, l5: 0.387275, l6: 0.620210\n",
            "\n",
            "[epoch: 102/100000, batch: 432/1000, ite: 12679] train loss: 2.7056, accuracy: 89.3013%, tar: 0.1905 \n",
            "l0: 0.117543, l1: 0.120272, l2: 0.130413, l3: 0.157256, l4: 0.222354, l5: 0.334949, l6: 0.514588\n",
            "\n",
            "[epoch: 102/100000, batch: 440/1000, ite: 12680] train loss: 2.7048, accuracy: 91.4127%, tar: 0.1904 \n",
            "l0: 0.137731, l1: 0.144330, l2: 0.152264, l3: 0.169415, l4: 0.219638, l5: 0.297574, l6: 0.485687\n",
            "\n",
            "[epoch: 102/100000, batch: 448/1000, ite: 12681] train loss: 2.7039, accuracy: 89.9703%, tar: 0.1904 \n",
            "l0: 0.096202, l1: 0.098172, l2: 0.107800, l3: 0.130267, l4: 0.189698, l5: 0.296133, l6: 0.507676\n",
            "\n",
            "[epoch: 102/100000, batch: 456/1000, ite: 12682] train loss: 2.7028, accuracy: 90.2599%, tar: 0.1902 \n",
            "l0: 0.108139, l1: 0.110064, l2: 0.121478, l3: 0.149282, l4: 0.220521, l5: 0.341517, l6: 0.522796\n",
            "\n",
            "[epoch: 102/100000, batch: 464/1000, ite: 12683] train loss: 2.7019, accuracy: 91.4416%, tar: 0.1901 \n",
            "l0: 0.094949, l1: 0.096730, l2: 0.107175, l3: 0.131599, l4: 0.190060, l5: 0.326964, l6: 0.573489\n",
            "\n",
            "[epoch: 102/100000, batch: 472/1000, ite: 12684] train loss: 2.7010, accuracy: 91.2598%, tar: 0.1900 \n",
            "l0: 0.120730, l1: 0.122770, l2: 0.129984, l3: 0.152151, l4: 0.203194, l5: 0.266370, l6: 0.432887\n",
            "\n",
            "[epoch: 102/100000, batch: 480/1000, ite: 12685] train loss: 2.6998, accuracy: 92.9445%, tar: 0.1899 \n",
            "l0: 0.108094, l1: 0.106978, l2: 0.120918, l3: 0.150197, l4: 0.209708, l5: 0.301001, l6: 0.499527\n",
            "\n",
            "[epoch: 102/100000, batch: 488/1000, ite: 12686] train loss: 2.6988, accuracy: 91.6497%, tar: 0.1897 \n",
            "l0: 0.136810, l1: 0.134317, l2: 0.146656, l3: 0.178351, l4: 0.253009, l5: 0.383635, l6: 0.655307\n",
            "\n",
            "[epoch: 102/100000, batch: 496/1000, ite: 12687] train loss: 2.6986, accuracy: 89.1194%, tar: 0.1897 \n",
            "l0: 0.154931, l1: 0.152057, l2: 0.161536, l3: 0.181981, l4: 0.236320, l5: 0.298412, l6: 0.496577\n",
            "\n",
            "[epoch: 102/100000, batch: 504/1000, ite: 12688] train loss: 2.6979, accuracy: 91.3077%, tar: 0.1896 \n",
            "l0: 0.111785, l1: 0.111603, l2: 0.117674, l3: 0.142422, l4: 0.184160, l5: 0.264477, l6: 0.436745\n",
            "\n",
            "[epoch: 102/100000, batch: 512/1000, ite: 12689] train loss: 2.6966, accuracy: 91.9051%, tar: 0.1895 \n",
            "l0: 0.145535, l1: 0.150236, l2: 0.158932, l3: 0.179833, l4: 0.239261, l5: 0.331821, l6: 0.504653\n",
            "\n",
            "[epoch: 102/100000, batch: 520/1000, ite: 12690] train loss: 2.6959, accuracy: 91.2363%, tar: 0.1894 \n",
            "l0: 0.154248, l1: 0.154084, l2: 0.169360, l3: 0.197520, l4: 0.262308, l5: 0.363294, l6: 0.535870\n",
            "\n",
            "[epoch: 102/100000, batch: 528/1000, ite: 12691] train loss: 2.6955, accuracy: 89.5379%, tar: 0.1894 \n",
            "l0: 0.134670, l1: 0.135772, l2: 0.147466, l3: 0.162630, l4: 0.216829, l5: 0.332765, l6: 0.539376\n",
            "\n",
            "[epoch: 102/100000, batch: 536/1000, ite: 12692] train loss: 2.6948, accuracy: 90.9088%, tar: 0.1893 \n",
            "l0: 0.076583, l1: 0.078079, l2: 0.088178, l3: 0.114074, l4: 0.175652, l5: 0.289725, l6: 0.528715\n",
            "\n",
            "[epoch: 102/100000, batch: 544/1000, ite: 12693] train loss: 2.6937, accuracy: 91.7073%, tar: 0.1891 \n",
            "l0: 0.113504, l1: 0.114417, l2: 0.123373, l3: 0.146960, l4: 0.202651, l5: 0.307451, l6: 0.479298\n",
            "\n",
            "[epoch: 102/100000, batch: 552/1000, ite: 12694] train loss: 2.6926, accuracy: 91.5839%, tar: 0.1890 \n",
            "l0: 0.084698, l1: 0.086941, l2: 0.102324, l3: 0.127192, l4: 0.188205, l5: 0.312733, l6: 0.529544\n",
            "\n",
            "[epoch: 102/100000, batch: 560/1000, ite: 12695] train loss: 2.6916, accuracy: 92.2262%, tar: 0.1889 \n",
            "l0: 0.095759, l1: 0.098231, l2: 0.109240, l3: 0.133835, l4: 0.188155, l5: 0.292728, l6: 0.495950\n",
            "\n",
            "[epoch: 102/100000, batch: 568/1000, ite: 12696] train loss: 2.6905, accuracy: 90.9608%, tar: 0.1887 \n",
            "l0: 0.117096, l1: 0.121814, l2: 0.132206, l3: 0.148828, l4: 0.186498, l5: 0.259445, l6: 0.406777\n",
            "\n",
            "[epoch: 102/100000, batch: 576/1000, ite: 12697] train loss: 2.6891, accuracy: 92.9697%, tar: 0.1886 \n",
            "l0: 0.087093, l1: 0.088661, l2: 0.095251, l3: 0.110450, l4: 0.151936, l5: 0.234572, l6: 0.427150\n",
            "\n",
            "[epoch: 102/100000, batch: 584/1000, ite: 12698] train loss: 2.6876, accuracy: 92.4296%, tar: 0.1885 \n",
            "l0: 0.116883, l1: 0.119610, l2: 0.134593, l3: 0.168664, l4: 0.227807, l5: 0.351359, l6: 0.656279\n",
            "\n",
            "[epoch: 102/100000, batch: 592/1000, ite: 12699] train loss: 2.6873, accuracy: 89.5594%, tar: 0.1884 \n",
            "l0: 0.082982, l1: 0.086002, l2: 0.097539, l3: 0.130303, l4: 0.196460, l5: 0.311797, l6: 0.522567\n",
            "\n",
            "[epoch: 102/100000, batch: 600/1000, ite: 12700] train loss: 2.6862, accuracy: 92.8181%, tar: 0.1882 \n",
            "l0: 0.107353, l1: 0.109805, l2: 0.127576, l3: 0.162345, l4: 0.229066, l5: 0.371994, l6: 0.581010\n",
            "\n",
            "[epoch: 102/100000, batch: 608/1000, ite: 12701] train loss: 2.6857, accuracy: 91.1286%, tar: 0.1881 \n",
            "l0: 0.153106, l1: 0.160555, l2: 0.172690, l3: 0.194989, l4: 0.257098, l5: 0.378847, l6: 0.547883\n",
            "\n",
            "[epoch: 102/100000, batch: 616/1000, ite: 12702] train loss: 2.6853, accuracy: 90.1948%, tar: 0.1881 \n",
            "l0: 0.110932, l1: 0.117845, l2: 0.129432, l3: 0.155759, l4: 0.220272, l5: 0.329470, l6: 0.591821\n",
            "\n",
            "[epoch: 102/100000, batch: 624/1000, ite: 12703] train loss: 2.6847, accuracy: 91.1950%, tar: 0.1880 \n",
            "l0: 0.099374, l1: 0.102391, l2: 0.112294, l3: 0.136655, l4: 0.218679, l5: 0.308939, l6: 0.503505\n",
            "\n",
            "[epoch: 102/100000, batch: 632/1000, ite: 12704] train loss: 2.6837, accuracy: 91.8239%, tar: 0.1878 \n",
            "l0: 0.152143, l1: 0.151239, l2: 0.166846, l3: 0.211039, l4: 0.308367, l5: 0.483021, l6: 0.759141\n",
            "\n",
            "[epoch: 102/100000, batch: 640/1000, ite: 12705] train loss: 2.6842, accuracy: 88.5371%, tar: 0.1878 \n",
            "l0: 0.060789, l1: 0.062274, l2: 0.075116, l3: 0.106565, l4: 0.183254, l5: 0.289634, l6: 0.440334\n",
            "\n",
            "[epoch: 102/100000, batch: 648/1000, ite: 12706] train loss: 2.6827, accuracy: 93.0365%, tar: 0.1876 \n",
            "l0: 0.093451, l1: 0.096901, l2: 0.103977, l3: 0.126553, l4: 0.192865, l5: 0.287563, l6: 0.448487\n",
            "\n",
            "[epoch: 102/100000, batch: 656/1000, ite: 12707] train loss: 2.6815, accuracy: 92.2936%, tar: 0.1875 \n",
            "l0: 0.177972, l1: 0.177609, l2: 0.192261, l3: 0.219321, l4: 0.306967, l5: 0.420911, l6: 0.656595\n",
            "\n",
            "[epoch: 102/100000, batch: 664/1000, ite: 12708] train loss: 2.6816, accuracy: 90.1130%, tar: 0.1875 \n",
            "l0: 0.152480, l1: 0.161309, l2: 0.173387, l3: 0.201716, l4: 0.240613, l5: 0.320318, l6: 0.505266\n",
            "\n",
            "[epoch: 102/100000, batch: 672/1000, ite: 12709] train loss: 2.6810, accuracy: 91.1485%, tar: 0.1874 \n",
            "l0: 0.066698, l1: 0.070253, l2: 0.080666, l3: 0.104792, l4: 0.147271, l5: 0.196122, l6: 0.311413\n",
            "\n",
            "[epoch: 102/100000, batch: 680/1000, ite: 12710] train loss: 2.6791, accuracy: 94.3326%, tar: 0.1872 \n",
            "l0: 0.082042, l1: 0.085327, l2: 0.095995, l3: 0.116551, l4: 0.167913, l5: 0.299832, l6: 0.491744\n",
            "\n",
            "[epoch: 102/100000, batch: 688/1000, ite: 12711] train loss: 2.6779, accuracy: 91.9168%, tar: 0.1871 \n",
            "l0: 0.100630, l1: 0.099713, l2: 0.107559, l3: 0.122455, l4: 0.164753, l5: 0.232140, l6: 0.451608\n",
            "\n",
            "[epoch: 102/100000, batch: 696/1000, ite: 12712] train loss: 2.6765, accuracy: 92.2632%, tar: 0.1870 \n",
            "l0: 0.115563, l1: 0.115804, l2: 0.126936, l3: 0.156509, l4: 0.196084, l5: 0.303123, l6: 0.489683\n",
            "\n",
            "[epoch: 102/100000, batch: 704/1000, ite: 12713] train loss: 2.6756, accuracy: 91.7039%, tar: 0.1869 \n",
            "l0: 0.129924, l1: 0.128422, l2: 0.141748, l3: 0.175098, l4: 0.260083, l5: 0.392933, l6: 0.576147\n",
            "\n",
            "[epoch: 102/100000, batch: 712/1000, ite: 12714] train loss: 2.6752, accuracy: 89.8998%, tar: 0.1868 \n",
            "l0: 0.140848, l1: 0.143178, l2: 0.158852, l3: 0.193267, l4: 0.269365, l5: 0.400970, l6: 0.600994\n",
            "\n",
            "[epoch: 102/100000, batch: 720/1000, ite: 12715] train loss: 2.6750, accuracy: 90.0391%, tar: 0.1867 \n",
            "l0: 0.160596, l1: 0.166212, l2: 0.179635, l3: 0.214526, l4: 0.292315, l5: 0.426397, l6: 0.658055\n",
            "\n",
            "[epoch: 102/100000, batch: 728/1000, ite: 12716] train loss: 2.6751, accuracy: 90.5594%, tar: 0.1867 \n",
            "l0: 0.090033, l1: 0.090106, l2: 0.099268, l3: 0.122854, l4: 0.172837, l5: 0.260214, l6: 0.514683\n",
            "\n",
            "[epoch: 102/100000, batch: 736/1000, ite: 12717] train loss: 2.6740, accuracy: 91.3575%, tar: 0.1866 \n",
            "l0: 0.102310, l1: 0.103425, l2: 0.113018, l3: 0.137146, l4: 0.164668, l5: 0.239652, l6: 0.462776\n",
            "\n",
            "[epoch: 102/100000, batch: 744/1000, ite: 12718] train loss: 2.6727, accuracy: 91.9312%, tar: 0.1864 \n",
            "l0: 0.084602, l1: 0.089244, l2: 0.101467, l3: 0.132916, l4: 0.198590, l5: 0.307833, l6: 0.530642\n",
            "\n",
            "[epoch: 102/100000, batch: 752/1000, ite: 12719] train loss: 2.6718, accuracy: 90.6698%, tar: 0.1863 \n",
            "l0: 0.111913, l1: 0.112794, l2: 0.127993, l3: 0.170546, l4: 0.263941, l5: 0.415772, l6: 0.642760\n",
            "\n",
            "[epoch: 102/100000, batch: 760/1000, ite: 12720] train loss: 2.6715, accuracy: 88.6771%, tar: 0.1862 \n",
            "l0: 0.134985, l1: 0.137819, l2: 0.149695, l3: 0.179063, l4: 0.221493, l5: 0.328631, l6: 0.510927\n",
            "\n",
            "[epoch: 102/100000, batch: 768/1000, ite: 12721] train loss: 2.6708, accuracy: 90.9313%, tar: 0.1861 \n",
            "l0: 0.133922, l1: 0.136422, l2: 0.147015, l3: 0.168371, l4: 0.224117, l5: 0.303086, l6: 0.498880\n",
            "\n",
            "[epoch: 102/100000, batch: 776/1000, ite: 12722] train loss: 2.6701, accuracy: 90.7121%, tar: 0.1861 \n",
            "l0: 0.177809, l1: 0.180161, l2: 0.198889, l3: 0.236936, l4: 0.338875, l5: 0.495743, l6: 0.724559\n",
            "\n",
            "[epoch: 102/100000, batch: 784/1000, ite: 12723] train loss: 2.6706, accuracy: 87.6501%, tar: 0.1860 \n",
            "l0: 0.109770, l1: 0.110889, l2: 0.124126, l3: 0.147483, l4: 0.212642, l5: 0.282716, l6: 0.443448\n",
            "\n",
            "[epoch: 102/100000, batch: 792/1000, ite: 12724] train loss: 2.6695, accuracy: 91.6803%, tar: 0.1859 \n",
            "l0: 0.109692, l1: 0.114454, l2: 0.123775, l3: 0.149010, l4: 0.190241, l5: 0.277519, l6: 0.489312\n",
            "\n",
            "[epoch: 102/100000, batch: 800/1000, ite: 12725] train loss: 2.6685, accuracy: 90.6692%, tar: 0.1858 \n",
            "l0: 0.105057, l1: 0.107725, l2: 0.120422, l3: 0.143403, l4: 0.204303, l5: 0.295376, l6: 0.486738\n",
            "\n",
            "[epoch: 102/100000, batch: 808/1000, ite: 12726] train loss: 2.6675, accuracy: 90.5363%, tar: 0.1857 \n",
            "l0: 0.145123, l1: 0.150008, l2: 0.158148, l3: 0.181068, l4: 0.225239, l5: 0.340705, l6: 0.530677\n",
            "\n",
            "[epoch: 102/100000, batch: 816/1000, ite: 12727] train loss: 2.6670, accuracy: 89.9945%, tar: 0.1857 \n",
            "l0: 0.152957, l1: 0.155558, l2: 0.168952, l3: 0.189667, l4: 0.238452, l5: 0.358693, l6: 0.578444\n",
            "\n",
            "[epoch: 102/100000, batch: 824/1000, ite: 12728] train loss: 2.6667, accuracy: 90.2078%, tar: 0.1856 \n",
            "l0: 0.091343, l1: 0.096250, l2: 0.106712, l3: 0.137978, l4: 0.187207, l5: 0.252421, l6: 0.449350\n",
            "\n",
            "[epoch: 102/100000, batch: 832/1000, ite: 12729] train loss: 2.6654, accuracy: 91.8824%, tar: 0.1855 \n",
            "l0: 0.107272, l1: 0.110257, l2: 0.120050, l3: 0.142074, l4: 0.190116, l5: 0.276913, l6: 0.489445\n",
            "\n",
            "[epoch: 102/100000, batch: 840/1000, ite: 12730] train loss: 2.6644, accuracy: 90.3220%, tar: 0.1854 \n",
            "l0: 0.129255, l1: 0.130169, l2: 0.144632, l3: 0.172989, l4: 0.221904, l5: 0.321759, l6: 0.533596\n",
            "\n",
            "[epoch: 102/100000, batch: 848/1000, ite: 12731] train loss: 2.6638, accuracy: 90.4366%, tar: 0.1853 \n",
            "l0: 0.115046, l1: 0.119063, l2: 0.133832, l3: 0.175454, l4: 0.249790, l5: 0.350727, l6: 0.602857\n",
            "\n",
            "[epoch: 102/100000, batch: 856/1000, ite: 12732] train loss: 2.6633, accuracy: 90.1929%, tar: 0.1852 \n",
            "l0: 0.113737, l1: 0.116569, l2: 0.131249, l3: 0.166051, l4: 0.228034, l5: 0.356192, l6: 0.564286\n",
            "\n",
            "[epoch: 102/100000, batch: 864/1000, ite: 12733] train loss: 2.6627, accuracy: 90.5371%, tar: 0.1851 \n",
            "l0: 0.110156, l1: 0.110557, l2: 0.126746, l3: 0.154590, l4: 0.230924, l5: 0.364532, l6: 0.557998\n",
            "\n",
            "[epoch: 102/100000, batch: 872/1000, ite: 12734] train loss: 2.6621, accuracy: 90.5939%, tar: 0.1850 \n",
            "l0: 0.111805, l1: 0.115120, l2: 0.126221, l3: 0.157106, l4: 0.205765, l5: 0.325556, l6: 0.531053\n",
            "\n",
            "[epoch: 102/100000, batch: 880/1000, ite: 12735] train loss: 2.6614, accuracy: 90.9103%, tar: 0.1849 \n",
            "l0: 0.133108, l1: 0.138670, l2: 0.147146, l3: 0.171665, l4: 0.229845, l5: 0.389533, l6: 0.598260\n",
            "\n",
            "[epoch: 102/100000, batch: 888/1000, ite: 12736] train loss: 2.6610, accuracy: 88.9218%, tar: 0.1848 \n",
            "l0: 0.122764, l1: 0.130695, l2: 0.140014, l3: 0.175993, l4: 0.248295, l5: 0.374488, l6: 0.659033\n",
            "\n",
            "[epoch: 102/100000, batch: 896/1000, ite: 12737] train loss: 2.6608, accuracy: 89.8184%, tar: 0.1848 \n",
            "l0: 0.087015, l1: 0.088461, l2: 0.098714, l3: 0.124826, l4: 0.189264, l5: 0.326002, l6: 0.526288\n",
            "\n",
            "[epoch: 102/100000, batch: 904/1000, ite: 12738] train loss: 2.6599, accuracy: 90.2964%, tar: 0.1846 \n",
            "l0: 0.160361, l1: 0.164369, l2: 0.171951, l3: 0.186410, l4: 0.250827, l5: 0.341152, l6: 0.513631\n",
            "\n",
            "[epoch: 102/100000, batch: 912/1000, ite: 12739] train loss: 2.6595, accuracy: 90.9878%, tar: 0.1846 \n",
            "l0: 0.099261, l1: 0.101823, l2: 0.112244, l3: 0.139755, l4: 0.208414, l5: 0.319157, l6: 0.480926\n",
            "\n",
            "[epoch: 102/100000, batch: 920/1000, ite: 12740] train loss: 2.6585, accuracy: 91.6223%, tar: 0.1845 \n",
            "l0: 0.113487, l1: 0.119750, l2: 0.134439, l3: 0.154601, l4: 0.206483, l5: 0.276189, l6: 0.454544\n",
            "\n",
            "[epoch: 102/100000, batch: 928/1000, ite: 12741] train loss: 2.6575, accuracy: 91.0183%, tar: 0.1844 \n",
            "l0: 0.081435, l1: 0.084703, l2: 0.097007, l3: 0.122659, l4: 0.193182, l5: 0.314605, l6: 0.568325\n",
            "\n",
            "[epoch: 102/100000, batch: 936/1000, ite: 12742] train loss: 2.6567, accuracy: 91.5809%, tar: 0.1842 \n",
            "l0: 0.140197, l1: 0.139879, l2: 0.155451, l3: 0.190339, l4: 0.282477, l5: 0.473319, l6: 0.744805\n",
            "\n",
            "[epoch: 102/100000, batch: 944/1000, ite: 12743] train loss: 2.6570, accuracy: 87.8040%, tar: 0.1842 \n",
            "l0: 0.134294, l1: 0.136322, l2: 0.146063, l3: 0.173535, l4: 0.236363, l5: 0.351942, l6: 0.493778\n",
            "\n",
            "[epoch: 102/100000, batch: 952/1000, ite: 12744] train loss: 2.6563, accuracy: 91.0166%, tar: 0.1841 \n",
            "l0: 0.112341, l1: 0.112739, l2: 0.122648, l3: 0.147760, l4: 0.206836, l5: 0.326899, l6: 0.466272\n",
            "\n",
            "[epoch: 102/100000, batch: 960/1000, ite: 12745] train loss: 2.6554, accuracy: 92.1109%, tar: 0.1840 \n",
            "l0: 0.096247, l1: 0.098226, l2: 0.109672, l3: 0.129442, l4: 0.170006, l5: 0.261724, l6: 0.466420\n",
            "\n",
            "[epoch: 102/100000, batch: 968/1000, ite: 12746] train loss: 2.6543, accuracy: 91.4904%, tar: 0.1839 \n",
            "l0: 0.096854, l1: 0.098287, l2: 0.106619, l3: 0.130990, l4: 0.170975, l5: 0.254212, l6: 0.441493\n",
            "\n",
            "[epoch: 102/100000, batch: 976/1000, ite: 12747] train loss: 2.6531, accuracy: 92.2227%, tar: 0.1838 \n",
            "l0: 0.103808, l1: 0.105661, l2: 0.111000, l3: 0.121162, l4: 0.152738, l5: 0.216260, l6: 0.406412\n",
            "\n",
            "[epoch: 102/100000, batch: 984/1000, ite: 12748] train loss: 2.6517, accuracy: 92.7415%, tar: 0.1837 \n",
            "l0: 0.087291, l1: 0.091556, l2: 0.102085, l3: 0.128061, l4: 0.181372, l5: 0.284388, l6: 0.487444\n",
            "\n",
            "[epoch: 102/100000, batch: 992/1000, ite: 12749] train loss: 2.6506, accuracy: 92.0820%, tar: 0.1836 \n",
            "l0: 0.100198, l1: 0.103617, l2: 0.115051, l3: 0.142785, l4: 0.197752, l5: 0.284019, l6: 0.501263\n",
            "\n",
            "[epoch: 102/100000, batch: 1000/1000, ite: 12750] train loss: 2.6497, accuracy: 91.7335%, tar: 0.1834 \n",
            "l0: 0.088914, l1: 0.088907, l2: 0.101056, l3: 0.130176, l4: 0.175490, l5: 0.270607, l6: 0.509362\n",
            "\n",
            "[epoch: 103/100000, batch: 8/1000, ite: 12751] train loss: 2.6487, accuracy: 91.4864%, tar: 0.1833 \n",
            "l0: 0.164083, l1: 0.166069, l2: 0.175835, l3: 0.193529, l4: 0.260824, l5: 0.396388, l6: 0.657544\n",
            "\n",
            "[epoch: 103/100000, batch: 16/1000, ite: 12752] train loss: 2.6487, accuracy: 88.8964%, tar: 0.1833 \n",
            "l0: 0.105773, l1: 0.109497, l2: 0.123082, l3: 0.149709, l4: 0.206797, l5: 0.332396, l6: 0.563930\n",
            "\n",
            "[epoch: 103/100000, batch: 24/1000, ite: 12753] train loss: 2.6481, accuracy: 91.9365%, tar: 0.1832 \n",
            "l0: 0.134020, l1: 0.139609, l2: 0.145383, l3: 0.169775, l4: 0.227780, l5: 0.353111, l6: 0.580784\n",
            "\n",
            "[epoch: 103/100000, batch: 32/1000, ite: 12754] train loss: 2.6477, accuracy: 91.3172%, tar: 0.1831 \n",
            "l0: 0.137275, l1: 0.142087, l2: 0.151466, l3: 0.186728, l4: 0.270589, l5: 0.406855, l6: 0.713571\n",
            "\n",
            "[epoch: 103/100000, batch: 40/1000, ite: 12755] train loss: 2.6478, accuracy: 89.6911%, tar: 0.1831 \n",
            "l0: 0.094627, l1: 0.097019, l2: 0.109448, l3: 0.134937, l4: 0.194441, l5: 0.276198, l6: 0.448299\n",
            "\n",
            "[epoch: 103/100000, batch: 48/1000, ite: 12756] train loss: 2.6467, accuracy: 92.2936%, tar: 0.1829 \n",
            "l0: 0.092221, l1: 0.099748, l2: 0.106742, l3: 0.125778, l4: 0.176301, l5: 0.252778, l6: 0.443672\n",
            "\n",
            "[epoch: 103/100000, batch: 56/1000, ite: 12757] train loss: 2.6455, accuracy: 92.0443%, tar: 0.1828 \n",
            "l0: 0.104418, l1: 0.108073, l2: 0.116142, l3: 0.140548, l4: 0.198175, l5: 0.296903, l6: 0.531152\n",
            "\n",
            "[epoch: 103/100000, batch: 64/1000, ite: 12758] train loss: 2.6447, accuracy: 91.0343%, tar: 0.1827 \n",
            "l0: 0.113551, l1: 0.113371, l2: 0.120155, l3: 0.146319, l4: 0.195165, l5: 0.274997, l6: 0.475696\n",
            "\n",
            "[epoch: 103/100000, batch: 72/1000, ite: 12759] train loss: 2.6437, accuracy: 90.9045%, tar: 0.1826 \n",
            "l0: 0.105909, l1: 0.108717, l2: 0.119447, l3: 0.151695, l4: 0.211524, l5: 0.298708, l6: 0.483598\n",
            "\n",
            "[epoch: 103/100000, batch: 80/1000, ite: 12760] train loss: 2.6428, accuracy: 92.6802%, tar: 0.1825 \n",
            "l0: 0.105802, l1: 0.105899, l2: 0.119234, l3: 0.149099, l4: 0.218194, l5: 0.347996, l6: 0.557308\n",
            "\n",
            "[epoch: 103/100000, batch: 88/1000, ite: 12761] train loss: 2.6422, accuracy: 91.3442%, tar: 0.1824 \n",
            "l0: 0.132232, l1: 0.131838, l2: 0.138183, l3: 0.155948, l4: 0.190876, l5: 0.293267, l6: 0.555128\n",
            "\n",
            "[epoch: 103/100000, batch: 96/1000, ite: 12762] train loss: 2.6415, accuracy: 90.5716%, tar: 0.1824 \n",
            "l0: 0.171870, l1: 0.171378, l2: 0.183105, l3: 0.208663, l4: 0.261811, l5: 0.359366, l6: 0.569007\n",
            "\n",
            "[epoch: 103/100000, batch: 104/1000, ite: 12763] train loss: 2.6413, accuracy: 89.4561%, tar: 0.1823 \n",
            "l0: 0.153439, l1: 0.155627, l2: 0.167035, l3: 0.183055, l4: 0.226454, l5: 0.322508, l6: 0.512501\n",
            "\n",
            "[epoch: 103/100000, batch: 112/1000, ite: 12764] train loss: 2.6408, accuracy: 89.8467%, tar: 0.1823 \n",
            "l0: 0.071174, l1: 0.075309, l2: 0.085853, l3: 0.108427, l4: 0.151900, l5: 0.239114, l6: 0.442546\n",
            "\n",
            "[epoch: 103/100000, batch: 120/1000, ite: 12765] train loss: 2.6394, accuracy: 92.3617%, tar: 0.1822 \n",
            "l0: 0.105675, l1: 0.105110, l2: 0.119156, l3: 0.141586, l4: 0.193150, l5: 0.303002, l6: 0.563711\n",
            "\n",
            "[epoch: 103/100000, batch: 128/1000, ite: 12766] train loss: 2.6387, accuracy: 91.3983%, tar: 0.1821 \n",
            "l0: 0.075312, l1: 0.076025, l2: 0.089953, l3: 0.112898, l4: 0.164277, l5: 0.275095, l6: 0.471887\n",
            "\n",
            "[epoch: 103/100000, batch: 136/1000, ite: 12767] train loss: 2.6375, accuracy: 93.4849%, tar: 0.1819 \n",
            "l0: 0.131147, l1: 0.133041, l2: 0.153213, l3: 0.196449, l4: 0.293813, l5: 0.501479, l6: 0.756176\n",
            "\n",
            "[epoch: 103/100000, batch: 144/1000, ite: 12768] train loss: 2.6379, accuracy: 88.4004%, tar: 0.1819 \n",
            "l0: 0.151227, l1: 0.157562, l2: 0.168083, l3: 0.190494, l4: 0.266945, l5: 0.401122, l6: 0.585766\n",
            "\n",
            "[epoch: 103/100000, batch: 152/1000, ite: 12769] train loss: 2.6378, accuracy: 88.9672%, tar: 0.1818 \n",
            "l0: 0.147689, l1: 0.149243, l2: 0.160249, l3: 0.187582, l4: 0.254511, l5: 0.374141, l6: 0.603204\n",
            "\n",
            "[epoch: 103/100000, batch: 160/1000, ite: 12770] train loss: 2.6376, accuracy: 88.4588%, tar: 0.1818 \n",
            "l0: 0.128729, l1: 0.129506, l2: 0.137738, l3: 0.152805, l4: 0.189492, l5: 0.257758, l6: 0.414902\n",
            "\n",
            "[epoch: 103/100000, batch: 168/1000, ite: 12771] train loss: 2.6365, accuracy: 91.9112%, tar: 0.1817 \n",
            "l0: 0.088268, l1: 0.092679, l2: 0.106983, l3: 0.137835, l4: 0.206238, l5: 0.351892, l6: 0.634314\n",
            "\n",
            "[epoch: 103/100000, batch: 176/1000, ite: 12772] train loss: 2.6360, accuracy: 91.1825%, tar: 0.1816 \n",
            "l0: 0.101174, l1: 0.101143, l2: 0.112326, l3: 0.131428, l4: 0.174569, l5: 0.259089, l6: 0.491781\n",
            "\n",
            "[epoch: 103/100000, batch: 184/1000, ite: 12773] train loss: 2.6350, accuracy: 91.6835%, tar: 0.1815 \n",
            "l0: 0.102562, l1: 0.103927, l2: 0.114310, l3: 0.135436, l4: 0.190380, l5: 0.327906, l6: 0.535103\n",
            "\n",
            "[epoch: 103/100000, batch: 192/1000, ite: 12774] train loss: 2.6343, accuracy: 89.7988%, tar: 0.1814 \n",
            "l0: 0.103110, l1: 0.103698, l2: 0.111893, l3: 0.133528, l4: 0.195194, l5: 0.265113, l6: 0.455957\n",
            "\n",
            "[epoch: 103/100000, batch: 200/1000, ite: 12775] train loss: 2.6332, accuracy: 91.6373%, tar: 0.1813 \n",
            "l0: 0.069535, l1: 0.070471, l2: 0.080724, l3: 0.101298, l4: 0.157029, l5: 0.254296, l6: 0.439775\n",
            "\n",
            "[epoch: 103/100000, batch: 208/1000, ite: 12776] train loss: 2.6319, accuracy: 92.4388%, tar: 0.1811 \n",
            "l0: 0.087631, l1: 0.092145, l2: 0.102398, l3: 0.131510, l4: 0.197133, l5: 0.307994, l6: 0.461658\n",
            "\n",
            "[epoch: 103/100000, batch: 216/1000, ite: 12777] train loss: 2.6310, accuracy: 91.4117%, tar: 0.1810 \n",
            "l0: 0.097415, l1: 0.099412, l2: 0.107526, l3: 0.125435, l4: 0.167385, l5: 0.240468, l6: 0.385730\n",
            "\n",
            "[epoch: 103/100000, batch: 224/1000, ite: 12778] train loss: 2.6297, accuracy: 92.4427%, tar: 0.1809 \n",
            "l0: 0.100812, l1: 0.103250, l2: 0.114028, l3: 0.139049, l4: 0.199006, l5: 0.289798, l6: 0.568973\n",
            "\n",
            "[epoch: 103/100000, batch: 232/1000, ite: 12779] train loss: 2.6290, accuracy: 90.8063%, tar: 0.1808 \n",
            "l0: 0.080224, l1: 0.083561, l2: 0.095082, l3: 0.130082, l4: 0.194396, l5: 0.289204, l6: 0.452707\n",
            "\n",
            "[epoch: 103/100000, batch: 240/1000, ite: 12780] train loss: 2.6279, accuracy: 92.2428%, tar: 0.1807 \n",
            "l0: 0.134716, l1: 0.138303, l2: 0.147588, l3: 0.173792, l4: 0.222102, l5: 0.341206, l6: 0.545965\n",
            "\n",
            "[epoch: 103/100000, batch: 248/1000, ite: 12781] train loss: 2.6274, accuracy: 91.4575%, tar: 0.1806 \n",
            "l0: 0.095029, l1: 0.100880, l2: 0.111223, l3: 0.137161, l4: 0.191471, l5: 0.271471, l6: 0.434439\n",
            "\n",
            "[epoch: 103/100000, batch: 256/1000, ite: 12782] train loss: 2.6263, accuracy: 93.2184%, tar: 0.1805 \n",
            "l0: 0.090152, l1: 0.093417, l2: 0.109880, l3: 0.149389, l4: 0.244571, l5: 0.415000, l6: 0.597366\n",
            "\n",
            "[epoch: 103/100000, batch: 264/1000, ite: 12783] train loss: 2.6259, accuracy: 91.5383%, tar: 0.1804 \n",
            "l0: 0.115925, l1: 0.118164, l2: 0.136279, l3: 0.171735, l4: 0.264955, l5: 0.434751, l6: 0.696668\n",
            "\n",
            "[epoch: 103/100000, batch: 272/1000, ite: 12784] train loss: 2.6259, accuracy: 88.2214%, tar: 0.1803 \n",
            "l0: 0.084653, l1: 0.085671, l2: 0.099499, l3: 0.132529, l4: 0.198494, l5: 0.284748, l6: 0.525098\n",
            "\n",
            "[epoch: 103/100000, batch: 280/1000, ite: 12785] train loss: 2.6251, accuracy: 91.3608%, tar: 0.1802 \n",
            "l0: 0.128929, l1: 0.129923, l2: 0.142835, l3: 0.168481, l4: 0.237206, l5: 0.386524, l6: 0.613853\n",
            "\n",
            "[epoch: 103/100000, batch: 288/1000, ite: 12786] train loss: 2.6248, accuracy: 89.1246%, tar: 0.1801 \n",
            "l0: 0.169583, l1: 0.167380, l2: 0.182164, l3: 0.211030, l4: 0.279992, l5: 0.394602, l6: 0.582242\n",
            "\n",
            "[epoch: 103/100000, batch: 296/1000, ite: 12787] train loss: 2.6247, accuracy: 89.4037%, tar: 0.1801 \n",
            "l0: 0.101461, l1: 0.103616, l2: 0.111452, l3: 0.134764, l4: 0.186903, l5: 0.275831, l6: 0.425913\n",
            "\n",
            "[epoch: 103/100000, batch: 304/1000, ite: 12788] train loss: 2.6236, accuracy: 92.4811%, tar: 0.1800 \n",
            "l0: 0.082032, l1: 0.082199, l2: 0.094375, l3: 0.117817, l4: 0.170437, l5: 0.270720, l6: 0.478409\n",
            "\n",
            "[epoch: 103/100000, batch: 312/1000, ite: 12789] train loss: 2.6226, accuracy: 91.9154%, tar: 0.1799 \n",
            "l0: 0.118224, l1: 0.119119, l2: 0.133393, l3: 0.160601, l4: 0.210889, l5: 0.295210, l6: 0.515185\n",
            "\n",
            "[epoch: 103/100000, batch: 320/1000, ite: 12790] train loss: 2.6219, accuracy: 90.5567%, tar: 0.1798 \n",
            "l0: 0.134765, l1: 0.135056, l2: 0.150233, l3: 0.180512, l4: 0.256379, l5: 0.411690, l6: 0.689339\n",
            "\n",
            "[epoch: 103/100000, batch: 328/1000, ite: 12791] train loss: 2.6219, accuracy: 88.1658%, tar: 0.1798 \n",
            "l0: 0.134256, l1: 0.139451, l2: 0.151462, l3: 0.173675, l4: 0.211323, l5: 0.306593, l6: 0.594601\n",
            "\n",
            "[epoch: 103/100000, batch: 336/1000, ite: 12792] train loss: 2.6215, accuracy: 91.5125%, tar: 0.1797 \n",
            "l0: 0.135063, l1: 0.134018, l2: 0.146386, l3: 0.174769, l4: 0.263618, l5: 0.421329, l6: 0.777160\n",
            "\n",
            "[epoch: 103/100000, batch: 344/1000, ite: 12793] train loss: 2.6218, accuracy: 89.5500%, tar: 0.1796 \n",
            "l0: 0.084872, l1: 0.084917, l2: 0.090957, l3: 0.107313, l4: 0.158408, l5: 0.248554, l6: 0.439865\n",
            "\n",
            "[epoch: 103/100000, batch: 352/1000, ite: 12794] train loss: 2.6206, accuracy: 92.4386%, tar: 0.1795 \n",
            "l0: 0.143608, l1: 0.143623, l2: 0.156195, l3: 0.177627, l4: 0.226833, l5: 0.345117, l6: 0.559026\n",
            "\n",
            "[epoch: 103/100000, batch: 360/1000, ite: 12795] train loss: 2.6202, accuracy: 88.8079%, tar: 0.1795 \n",
            "l0: 0.089024, l1: 0.090209, l2: 0.098715, l3: 0.120537, l4: 0.197781, l5: 0.319162, l6: 0.508038\n",
            "\n",
            "[epoch: 103/100000, batch: 368/1000, ite: 12796] train loss: 2.6193, accuracy: 91.3253%, tar: 0.1794 \n",
            "l0: 0.114555, l1: 0.114092, l2: 0.126814, l3: 0.153267, l4: 0.213863, l5: 0.347635, l6: 0.546076\n",
            "\n",
            "[epoch: 103/100000, batch: 376/1000, ite: 12797] train loss: 2.6187, accuracy: 90.6518%, tar: 0.1793 \n",
            "l0: 0.117628, l1: 0.118893, l2: 0.130832, l3: 0.160188, l4: 0.235316, l5: 0.336017, l6: 0.588676\n",
            "\n",
            "[epoch: 103/100000, batch: 384/1000, ite: 12798] train loss: 2.6183, accuracy: 91.0538%, tar: 0.1792 \n",
            "l0: 0.096980, l1: 0.101603, l2: 0.116742, l3: 0.151400, l4: 0.227751, l5: 0.341576, l6: 0.528952\n",
            "\n",
            "[epoch: 103/100000, batch: 392/1000, ite: 12799] train loss: 2.6176, accuracy: 91.7682%, tar: 0.1791 \n",
            "l0: 0.124189, l1: 0.124684, l2: 0.139416, l3: 0.170203, l4: 0.253617, l5: 0.416360, l6: 0.628008\n",
            "\n",
            "[epoch: 103/100000, batch: 400/1000, ite: 12800] train loss: 2.6174, accuracy: 89.4755%, tar: 0.1790 \n",
            "l0: 0.099913, l1: 0.102022, l2: 0.110935, l3: 0.134752, l4: 0.183291, l5: 0.278146, l6: 0.426314\n",
            "\n",
            "[epoch: 103/100000, batch: 408/1000, ite: 12801] train loss: 2.6164, accuracy: 91.7162%, tar: 0.1789 \n",
            "l0: 0.128869, l1: 0.131682, l2: 0.139940, l3: 0.163090, l4: 0.237500, l5: 0.369163, l6: 0.603390\n",
            "\n",
            "[epoch: 103/100000, batch: 416/1000, ite: 12802] train loss: 2.6161, accuracy: 89.7863%, tar: 0.1789 \n",
            "l0: 0.105495, l1: 0.108189, l2: 0.119459, l3: 0.149954, l4: 0.216835, l5: 0.316257, l6: 0.545058\n",
            "\n",
            "[epoch: 103/100000, batch: 424/1000, ite: 12803] train loss: 2.6154, accuracy: 91.8347%, tar: 0.1788 \n",
            "l0: 0.121816, l1: 0.124845, l2: 0.138673, l3: 0.175902, l4: 0.252708, l5: 0.340799, l6: 0.553130\n",
            "\n",
            "[epoch: 103/100000, batch: 432/1000, ite: 12804] train loss: 2.6150, accuracy: 90.4638%, tar: 0.1787 \n",
            "l0: 0.077268, l1: 0.078537, l2: 0.089004, l3: 0.111689, l4: 0.163806, l5: 0.262988, l6: 0.508528\n",
            "\n",
            "[epoch: 103/100000, batch: 440/1000, ite: 12805] train loss: 2.6140, accuracy: 91.6886%, tar: 0.1786 \n",
            "l0: 0.121306, l1: 0.122961, l2: 0.131869, l3: 0.157353, l4: 0.213873, l5: 0.326923, l6: 0.508885\n",
            "\n",
            "[epoch: 103/100000, batch: 448/1000, ite: 12806] train loss: 2.6134, accuracy: 91.1936%, tar: 0.1785 \n",
            "l0: 0.089507, l1: 0.091170, l2: 0.103618, l3: 0.140022, l4: 0.211273, l5: 0.328526, l6: 0.578850\n",
            "\n",
            "[epoch: 103/100000, batch: 456/1000, ite: 12807] train loss: 2.6128, accuracy: 91.4043%, tar: 0.1784 \n",
            "l0: 0.090465, l1: 0.092614, l2: 0.101848, l3: 0.127843, l4: 0.178590, l5: 0.282122, l6: 0.447899\n",
            "\n",
            "[epoch: 103/100000, batch: 464/1000, ite: 12808] train loss: 2.6117, accuracy: 92.5962%, tar: 0.1783 \n",
            "l0: 0.076604, l1: 0.079728, l2: 0.094134, l3: 0.114817, l4: 0.163783, l5: 0.264356, l6: 0.461362\n",
            "\n",
            "[epoch: 103/100000, batch: 472/1000, ite: 12809] train loss: 2.6106, accuracy: 91.9612%, tar: 0.1782 \n",
            "l0: 0.098229, l1: 0.099291, l2: 0.108317, l3: 0.127026, l4: 0.185300, l5: 0.287600, l6: 0.507450\n",
            "\n",
            "[epoch: 103/100000, batch: 480/1000, ite: 12810] train loss: 2.6098, accuracy: 91.0208%, tar: 0.1781 \n",
            "l0: 0.108387, l1: 0.112495, l2: 0.128624, l3: 0.169395, l4: 0.233728, l5: 0.351850, l6: 0.608744\n",
            "\n",
            "[epoch: 103/100000, batch: 488/1000, ite: 12811] train loss: 2.6094, accuracy: 91.6614%, tar: 0.1780 \n",
            "l0: 0.117213, l1: 0.121809, l2: 0.136439, l3: 0.170048, l4: 0.246336, l5: 0.360547, l6: 0.584343\n",
            "\n",
            "[epoch: 103/100000, batch: 496/1000, ite: 12812] train loss: 2.6090, accuracy: 89.9042%, tar: 0.1779 \n",
            "l0: 0.099253, l1: 0.098287, l2: 0.112260, l3: 0.135887, l4: 0.205292, l5: 0.307104, l6: 0.494045\n",
            "\n",
            "[epoch: 103/100000, batch: 504/1000, ite: 12813] train loss: 2.6082, accuracy: 91.7458%, tar: 0.1778 \n",
            "l0: 0.115457, l1: 0.119052, l2: 0.130801, l3: 0.158921, l4: 0.212860, l5: 0.326105, l6: 0.590457\n",
            "\n",
            "[epoch: 103/100000, batch: 512/1000, ite: 12814] train loss: 2.6078, accuracy: 91.7977%, tar: 0.1777 \n",
            "l0: 0.088203, l1: 0.090512, l2: 0.101055, l3: 0.127356, l4: 0.176147, l5: 0.272460, l6: 0.444149\n",
            "\n",
            "[epoch: 103/100000, batch: 520/1000, ite: 12815] train loss: 2.6067, accuracy: 93.1338%, tar: 0.1776 \n",
            "l0: 0.083429, l1: 0.084413, l2: 0.097241, l3: 0.123149, l4: 0.188222, l5: 0.310535, l6: 0.483756\n",
            "\n",
            "[epoch: 103/100000, batch: 528/1000, ite: 12816] train loss: 2.6058, accuracy: 92.6511%, tar: 0.1775 \n",
            "l0: 0.103411, l1: 0.104502, l2: 0.117748, l3: 0.146418, l4: 0.229058, l5: 0.375647, l6: 0.648789\n",
            "\n",
            "[epoch: 103/100000, batch: 536/1000, ite: 12817] train loss: 2.6055, accuracy: 89.4515%, tar: 0.1774 \n",
            "l0: 0.160229, l1: 0.161417, l2: 0.170984, l3: 0.194416, l4: 0.243092, l5: 0.325014, l6: 0.490700\n",
            "\n",
            "[epoch: 103/100000, batch: 544/1000, ite: 12818] train loss: 2.6051, accuracy: 91.4784%, tar: 0.1774 \n",
            "l0: 0.087208, l1: 0.088611, l2: 0.102267, l3: 0.131847, l4: 0.196067, l5: 0.320071, l6: 0.545073\n",
            "\n",
            "[epoch: 103/100000, batch: 552/1000, ite: 12819] train loss: 2.6044, accuracy: 90.3342%, tar: 0.1773 \n",
            "l0: 0.094172, l1: 0.096556, l2: 0.107499, l3: 0.133334, l4: 0.201648, l5: 0.287970, l6: 0.494324\n",
            "\n",
            "[epoch: 103/100000, batch: 560/1000, ite: 12820] train loss: 2.6035, accuracy: 92.4314%, tar: 0.1772 \n",
            "l0: 0.095894, l1: 0.098152, l2: 0.109746, l3: 0.143731, l4: 0.225196, l5: 0.315276, l6: 0.520163\n",
            "\n",
            "[epoch: 103/100000, batch: 568/1000, ite: 12821] train loss: 2.6028, accuracy: 91.2734%, tar: 0.1771 \n",
            "l0: 0.100678, l1: 0.102134, l2: 0.112248, l3: 0.131099, l4: 0.178610, l5: 0.240072, l6: 0.414897\n",
            "\n",
            "[epoch: 103/100000, batch: 576/1000, ite: 12822] train loss: 2.6017, accuracy: 93.3963%, tar: 0.1770 \n",
            "l0: 0.126343, l1: 0.127786, l2: 0.137928, l3: 0.167180, l4: 0.243335, l5: 0.361995, l6: 0.610697\n",
            "\n",
            "[epoch: 103/100000, batch: 584/1000, ite: 12823] train loss: 2.6015, accuracy: 90.4255%, tar: 0.1769 \n",
            "l0: 0.086861, l1: 0.089900, l2: 0.104156, l3: 0.138941, l4: 0.220893, l5: 0.359998, l6: 0.554229\n",
            "\n",
            "[epoch: 103/100000, batch: 592/1000, ite: 12824] train loss: 2.6009, accuracy: 91.2357%, tar: 0.1768 \n",
            "l0: 0.092081, l1: 0.092446, l2: 0.104757, l3: 0.135858, l4: 0.190518, l5: 0.326587, l6: 0.506573\n",
            "\n",
            "[epoch: 103/100000, batch: 600/1000, ite: 12825] train loss: 2.6001, accuracy: 91.3292%, tar: 0.1767 \n",
            "l0: 0.077232, l1: 0.078075, l2: 0.087936, l3: 0.111304, l4: 0.161371, l5: 0.245592, l6: 0.411439\n",
            "\n",
            "[epoch: 103/100000, batch: 608/1000, ite: 12826] train loss: 2.5988, accuracy: 92.7847%, tar: 0.1766 \n",
            "l0: 0.101504, l1: 0.102511, l2: 0.112756, l3: 0.132643, l4: 0.194282, l5: 0.317682, l6: 0.511094\n",
            "\n",
            "[epoch: 103/100000, batch: 616/1000, ite: 12827] train loss: 2.5981, accuracy: 91.8130%, tar: 0.1765 \n",
            "l0: 0.083115, l1: 0.085107, l2: 0.097112, l3: 0.120765, l4: 0.177057, l5: 0.296224, l6: 0.483632\n",
            "\n",
            "[epoch: 103/100000, batch: 624/1000, ite: 12828] train loss: 2.5972, accuracy: 91.8680%, tar: 0.1764 \n",
            "l0: 0.088767, l1: 0.091615, l2: 0.104173, l3: 0.136995, l4: 0.193526, l5: 0.277978, l6: 0.517736\n",
            "\n",
            "[epoch: 103/100000, batch: 632/1000, ite: 12829] train loss: 2.5964, accuracy: 92.0752%, tar: 0.1763 \n",
            "l0: 0.162998, l1: 0.165497, l2: 0.176030, l3: 0.206813, l4: 0.281800, l5: 0.387119, l6: 0.595008\n",
            "\n",
            "[epoch: 103/100000, batch: 640/1000, ite: 12830] train loss: 2.5963, accuracy: 90.4859%, tar: 0.1763 \n",
            "l0: 0.125745, l1: 0.129859, l2: 0.143534, l3: 0.170932, l4: 0.237829, l5: 0.369733, l6: 0.535021\n",
            "\n",
            "[epoch: 103/100000, batch: 648/1000, ite: 12831] train loss: 2.5959, accuracy: 91.1456%, tar: 0.1762 \n",
            "l0: 0.149621, l1: 0.149827, l2: 0.159374, l3: 0.188618, l4: 0.252590, l5: 0.353354, l6: 0.588340\n",
            "\n",
            "[epoch: 103/100000, batch: 656/1000, ite: 12832] train loss: 2.5958, accuracy: 89.7260%, tar: 0.1762 \n",
            "l0: 0.099386, l1: 0.101402, l2: 0.114830, l3: 0.148988, l4: 0.213849, l5: 0.342824, l6: 0.561423\n",
            "\n",
            "[epoch: 103/100000, batch: 664/1000, ite: 12833] train loss: 2.5952, accuracy: 90.5054%, tar: 0.1761 \n",
            "l0: 0.118307, l1: 0.121687, l2: 0.134342, l3: 0.153547, l4: 0.215737, l5: 0.323696, l6: 0.528048\n",
            "\n",
            "[epoch: 103/100000, batch: 672/1000, ite: 12834] train loss: 2.5946, accuracy: 91.7778%, tar: 0.1760 \n",
            "l0: 0.148309, l1: 0.153488, l2: 0.165358, l3: 0.198302, l4: 0.284452, l5: 0.437701, l6: 0.653033\n",
            "\n",
            "[epoch: 103/100000, batch: 680/1000, ite: 12835] train loss: 2.5947, accuracy: 86.9999%, tar: 0.1760 \n",
            "l0: 0.082817, l1: 0.085183, l2: 0.097289, l3: 0.127555, l4: 0.196146, l5: 0.296335, l6: 0.491010\n",
            "\n",
            "[epoch: 103/100000, batch: 688/1000, ite: 12836] train loss: 2.5939, accuracy: 91.2988%, tar: 0.1759 \n",
            "l0: 0.112927, l1: 0.111844, l2: 0.120876, l3: 0.135741, l4: 0.186840, l5: 0.264674, l6: 0.445734\n",
            "\n",
            "[epoch: 103/100000, batch: 696/1000, ite: 12837] train loss: 2.5930, accuracy: 92.3767%, tar: 0.1758 \n",
            "l0: 0.080553, l1: 0.082053, l2: 0.095928, l3: 0.117937, l4: 0.164573, l5: 0.261090, l6: 0.411893\n",
            "\n",
            "[epoch: 103/100000, batch: 704/1000, ite: 12838] train loss: 2.5918, accuracy: 92.8611%, tar: 0.1757 \n",
            "l0: 0.092800, l1: 0.095369, l2: 0.103125, l3: 0.121400, l4: 0.167461, l5: 0.244458, l6: 0.400603\n",
            "\n",
            "[epoch: 103/100000, batch: 712/1000, ite: 12839] train loss: 2.5907, accuracy: 92.4150%, tar: 0.1756 \n",
            "l0: 0.128431, l1: 0.131536, l2: 0.140110, l3: 0.159001, l4: 0.204503, l5: 0.311912, l6: 0.472286\n",
            "\n",
            "[epoch: 103/100000, batch: 720/1000, ite: 12840] train loss: 2.5900, accuracy: 90.7832%, tar: 0.1755 \n",
            "l0: 0.127224, l1: 0.130503, l2: 0.141923, l3: 0.178376, l4: 0.241419, l5: 0.352459, l6: 0.635399\n",
            "\n",
            "[epoch: 103/100000, batch: 728/1000, ite: 12841] train loss: 2.5898, accuracy: 89.5823%, tar: 0.1755 \n",
            "l0: 0.111730, l1: 0.113445, l2: 0.123334, l3: 0.145389, l4: 0.184410, l5: 0.271062, l6: 0.468320\n",
            "\n",
            "[epoch: 103/100000, batch: 736/1000, ite: 12842] train loss: 2.5889, accuracy: 92.5988%, tar: 0.1754 \n",
            "l0: 0.092739, l1: 0.094437, l2: 0.107064, l3: 0.143878, l4: 0.217069, l5: 0.348275, l6: 0.581900\n",
            "\n",
            "[epoch: 103/100000, batch: 744/1000, ite: 12843] train loss: 2.5884, accuracy: 89.9418%, tar: 0.1753 \n",
            "l0: 0.124214, l1: 0.129167, l2: 0.137964, l3: 0.152844, l4: 0.184612, l5: 0.269540, l6: 0.408839\n",
            "\n",
            "[epoch: 103/100000, batch: 752/1000, ite: 12844] train loss: 2.5875, accuracy: 92.7131%, tar: 0.1752 \n",
            "l0: 0.085680, l1: 0.087734, l2: 0.097672, l3: 0.122004, l4: 0.181528, l5: 0.277489, l6: 0.467726\n",
            "\n",
            "[epoch: 103/100000, batch: 760/1000, ite: 12845] train loss: 2.5866, accuracy: 92.7574%, tar: 0.1751 \n",
            "l0: 0.118653, l1: 0.120396, l2: 0.134403, l3: 0.159081, l4: 0.209168, l5: 0.329700, l6: 0.556543\n",
            "\n",
            "[epoch: 103/100000, batch: 768/1000, ite: 12846] train loss: 2.5861, accuracy: 90.7898%, tar: 0.1751 \n",
            "l0: 0.122562, l1: 0.124882, l2: 0.139285, l3: 0.172674, l4: 0.225947, l5: 0.342208, l6: 0.651388\n",
            "\n",
            "[epoch: 103/100000, batch: 776/1000, ite: 12847] train loss: 2.5859, accuracy: 89.1675%, tar: 0.1750 \n",
            "l0: 0.085216, l1: 0.085179, l2: 0.092856, l3: 0.109446, l4: 0.144078, l5: 0.217332, l6: 0.392694\n",
            "\n",
            "[epoch: 103/100000, batch: 784/1000, ite: 12848] train loss: 2.5847, accuracy: 92.2693%, tar: 0.1749 \n",
            "l0: 0.100998, l1: 0.102801, l2: 0.115901, l3: 0.149104, l4: 0.209842, l5: 0.334741, l6: 0.511098\n",
            "\n",
            "[epoch: 103/100000, batch: 792/1000, ite: 12849] train loss: 2.5840, accuracy: 92.3978%, tar: 0.1748 \n",
            "l0: 0.137099, l1: 0.139718, l2: 0.153844, l3: 0.184535, l4: 0.254762, l5: 0.437347, l6: 0.659924\n",
            "\n",
            "[epoch: 103/100000, batch: 800/1000, ite: 12850] train loss: 2.5841, accuracy: 90.7912%, tar: 0.1748 \n",
            "l0: 0.092372, l1: 0.094418, l2: 0.104158, l3: 0.127829, l4: 0.166411, l5: 0.264203, l6: 0.519866\n",
            "\n",
            "[epoch: 103/100000, batch: 808/1000, ite: 12851] train loss: 2.5832, accuracy: 92.4073%, tar: 0.1747 \n",
            "l0: 0.069662, l1: 0.074469, l2: 0.083768, l3: 0.104454, l4: 0.158703, l5: 0.246857, l6: 0.358985\n",
            "\n",
            "[epoch: 103/100000, batch: 816/1000, ite: 12852] train loss: 2.5819, accuracy: 93.2183%, tar: 0.1745 \n",
            "l0: 0.097187, l1: 0.099717, l2: 0.113176, l3: 0.141459, l4: 0.206183, l5: 0.313793, l6: 0.554521\n",
            "\n",
            "[epoch: 103/100000, batch: 824/1000, ite: 12853] train loss: 2.5814, accuracy: 91.1662%, tar: 0.1745 \n",
            "l0: 0.099353, l1: 0.101565, l2: 0.110855, l3: 0.133902, l4: 0.185191, l5: 0.266264, l6: 0.451426\n",
            "\n",
            "[epoch: 103/100000, batch: 832/1000, ite: 12854] train loss: 2.5805, accuracy: 91.4461%, tar: 0.1744 \n",
            "l0: 0.147874, l1: 0.152331, l2: 0.162417, l3: 0.190983, l4: 0.255272, l5: 0.386781, l6: 0.693389\n",
            "\n",
            "[epoch: 103/100000, batch: 840/1000, ite: 12855] train loss: 2.5806, accuracy: 90.3603%, tar: 0.1743 \n",
            "l0: 0.083873, l1: 0.085493, l2: 0.096888, l3: 0.127284, l4: 0.197146, l5: 0.296479, l6: 0.457555\n",
            "\n",
            "[epoch: 103/100000, batch: 848/1000, ite: 12856] train loss: 2.5797, accuracy: 92.2365%, tar: 0.1742 \n",
            "l0: 0.117072, l1: 0.121051, l2: 0.135343, l3: 0.166336, l4: 0.218126, l5: 0.282617, l6: 0.420456\n",
            "\n",
            "[epoch: 103/100000, batch: 856/1000, ite: 12857] train loss: 2.5789, accuracy: 92.9405%, tar: 0.1742 \n",
            "l0: 0.089754, l1: 0.093060, l2: 0.103376, l3: 0.134926, l4: 0.212872, l5: 0.355889, l6: 0.556396\n",
            "\n",
            "[epoch: 103/100000, batch: 864/1000, ite: 12858] train loss: 2.5783, accuracy: 90.5215%, tar: 0.1741 \n",
            "l0: 0.089078, l1: 0.090213, l2: 0.097765, l3: 0.117846, l4: 0.169190, l5: 0.272422, l6: 0.451417\n",
            "\n",
            "[epoch: 103/100000, batch: 872/1000, ite: 12859] train loss: 2.5774, accuracy: 92.0445%, tar: 0.1740 \n",
            "l0: 0.095300, l1: 0.095745, l2: 0.105301, l3: 0.132697, l4: 0.188292, l5: 0.331563, l6: 0.557594\n",
            "\n",
            "[epoch: 103/100000, batch: 880/1000, ite: 12860] train loss: 2.5768, accuracy: 90.9178%, tar: 0.1739 \n",
            "l0: 0.108992, l1: 0.113267, l2: 0.123860, l3: 0.154206, l4: 0.205850, l5: 0.303003, l6: 0.555994\n",
            "\n",
            "[epoch: 103/100000, batch: 888/1000, ite: 12861] train loss: 2.5762, accuracy: 93.3605%, tar: 0.1738 \n",
            "l0: 0.147921, l1: 0.146083, l2: 0.154541, l3: 0.173351, l4: 0.217497, l5: 0.293949, l6: 0.442983\n",
            "\n",
            "[epoch: 103/100000, batch: 896/1000, ite: 12862] train loss: 2.5756, accuracy: 91.9620%, tar: 0.1738 \n",
            "l0: 0.119326, l1: 0.120074, l2: 0.129917, l3: 0.155475, l4: 0.210734, l5: 0.296718, l6: 0.498716\n",
            "\n",
            "[epoch: 103/100000, batch: 904/1000, ite: 12863] train loss: 2.5750, accuracy: 91.0730%, tar: 0.1737 \n",
            "l0: 0.121235, l1: 0.123115, l2: 0.133376, l3: 0.154917, l4: 0.210277, l5: 0.292980, l6: 0.479276\n",
            "\n",
            "[epoch: 103/100000, batch: 912/1000, ite: 12864] train loss: 2.5743, accuracy: 90.9282%, tar: 0.1736 \n",
            "l0: 0.078712, l1: 0.080608, l2: 0.088904, l3: 0.113800, l4: 0.175305, l5: 0.279849, l6: 0.458269\n",
            "\n",
            "[epoch: 103/100000, batch: 920/1000, ite: 12865] train loss: 2.5733, accuracy: 91.5911%, tar: 0.1735 \n",
            "l0: 0.072166, l1: 0.073573, l2: 0.079437, l3: 0.093344, l4: 0.126251, l5: 0.179848, l6: 0.323009\n",
            "\n",
            "[epoch: 103/100000, batch: 928/1000, ite: 12866] train loss: 2.5718, accuracy: 94.1316%, tar: 0.1734 \n",
            "l0: 0.126146, l1: 0.127470, l2: 0.142536, l3: 0.167552, l4: 0.224988, l5: 0.367837, l6: 0.594707\n",
            "\n",
            "[epoch: 103/100000, batch: 936/1000, ite: 12867] train loss: 2.5715, accuracy: 90.5591%, tar: 0.1734 \n",
            "l0: 0.098975, l1: 0.098369, l2: 0.110537, l3: 0.137301, l4: 0.199720, l5: 0.285737, l6: 0.447903\n",
            "\n",
            "[epoch: 103/100000, batch: 944/1000, ite: 12868] train loss: 2.5707, accuracy: 92.1749%, tar: 0.1733 \n",
            "l0: 0.122622, l1: 0.124282, l2: 0.135696, l3: 0.168669, l4: 0.223673, l5: 0.314744, l6: 0.491800\n",
            "\n",
            "[epoch: 103/100000, batch: 952/1000, ite: 12869] train loss: 2.5701, accuracy: 91.2062%, tar: 0.1732 \n",
            "l0: 0.085475, l1: 0.087449, l2: 0.100311, l3: 0.125376, l4: 0.187877, l5: 0.303051, l6: 0.483219\n",
            "\n",
            "[epoch: 103/100000, batch: 960/1000, ite: 12870] train loss: 2.5693, accuracy: 92.9579%, tar: 0.1731 \n",
            "l0: 0.114685, l1: 0.117823, l2: 0.128525, l3: 0.157441, l4: 0.221393, l5: 0.326710, l6: 0.477227\n",
            "\n",
            "[epoch: 103/100000, batch: 968/1000, ite: 12871] train loss: 2.5686, accuracy: 91.9323%, tar: 0.1731 \n",
            "l0: 0.098922, l1: 0.100455, l2: 0.111800, l3: 0.140809, l4: 0.201988, l5: 0.306022, l6: 0.518736\n",
            "\n",
            "[epoch: 103/100000, batch: 976/1000, ite: 12872] train loss: 2.5680, accuracy: 90.5704%, tar: 0.1730 \n",
            "l0: 0.097704, l1: 0.097748, l2: 0.111260, l3: 0.137820, l4: 0.211671, l5: 0.326211, l6: 0.527349\n",
            "\n",
            "[epoch: 103/100000, batch: 984/1000, ite: 12873] train loss: 2.5674, accuracy: 91.0165%, tar: 0.1729 \n",
            "l0: 0.105610, l1: 0.105932, l2: 0.117191, l3: 0.139440, l4: 0.186828, l5: 0.281351, l6: 0.485512\n",
            "\n",
            "[epoch: 103/100000, batch: 992/1000, ite: 12874] train loss: 2.5666, accuracy: 91.9399%, tar: 0.1728 \n",
            "l0: 0.067585, l1: 0.068508, l2: 0.079429, l3: 0.103853, l4: 0.154628, l5: 0.242691, l6: 0.424105\n",
            "\n",
            "[epoch: 103/100000, batch: 1000/1000, ite: 12875] train loss: 2.5655, accuracy: 92.8254%, tar: 0.1727 \n",
            "l0: 0.133709, l1: 0.135035, l2: 0.150963, l3: 0.181828, l4: 0.258146, l5: 0.382664, l6: 0.586171\n",
            "\n",
            "[epoch: 104/100000, batch: 8/1000, ite: 12876] train loss: 2.5653, accuracy: 90.8504%, tar: 0.1726 \n",
            "l0: 0.134368, l1: 0.135314, l2: 0.149985, l3: 0.177588, l4: 0.248144, l5: 0.365563, l6: 0.629249\n",
            "\n",
            "[epoch: 104/100000, batch: 16/1000, ite: 12877] train loss: 2.5652, accuracy: 89.2160%, tar: 0.1726 \n",
            "l0: 0.121928, l1: 0.125059, l2: 0.137251, l3: 0.155841, l4: 0.198112, l5: 0.269959, l6: 0.454024\n",
            "\n",
            "[epoch: 104/100000, batch: 24/1000, ite: 12878] train loss: 2.5645, accuracy: 91.4302%, tar: 0.1725 \n",
            "l0: 0.101320, l1: 0.102591, l2: 0.114110, l3: 0.140771, l4: 0.201445, l5: 0.304363, l6: 0.532902\n",
            "\n",
            "[epoch: 104/100000, batch: 32/1000, ite: 12879] train loss: 2.5639, accuracy: 90.8172%, tar: 0.1725 \n",
            "l0: 0.065088, l1: 0.065619, l2: 0.073255, l3: 0.095566, l4: 0.147408, l5: 0.232266, l6: 0.391547\n",
            "\n",
            "[epoch: 104/100000, batch: 40/1000, ite: 12880] train loss: 2.5626, accuracy: 93.4210%, tar: 0.1723 \n",
            "l0: 0.076641, l1: 0.077685, l2: 0.091997, l3: 0.116589, l4: 0.180344, l5: 0.262924, l6: 0.466225\n",
            "\n",
            "[epoch: 104/100000, batch: 48/1000, ite: 12881] train loss: 2.5617, accuracy: 93.4222%, tar: 0.1722 \n",
            "l0: 0.091374, l1: 0.092496, l2: 0.100740, l3: 0.124141, l4: 0.167646, l5: 0.239592, l6: 0.411201\n",
            "\n",
            "[epoch: 104/100000, batch: 56/1000, ite: 12882] train loss: 2.5606, accuracy: 91.6173%, tar: 0.1721 \n",
            "l0: 0.131474, l1: 0.134015, l2: 0.143048, l3: 0.166185, l4: 0.234629, l5: 0.354910, l6: 0.555535\n",
            "\n",
            "[epoch: 104/100000, batch: 64/1000, ite: 12883] train loss: 2.5603, accuracy: 88.9499%, tar: 0.1721 \n",
            "l0: 0.080391, l1: 0.082763, l2: 0.093429, l3: 0.120131, l4: 0.196661, l5: 0.289866, l6: 0.544085\n",
            "\n",
            "[epoch: 104/100000, batch: 72/1000, ite: 12884] train loss: 2.5596, accuracy: 92.0656%, tar: 0.1720 \n",
            "l0: 0.115972, l1: 0.119616, l2: 0.138877, l3: 0.181057, l4: 0.263687, l5: 0.432653, l6: 0.745246\n",
            "\n",
            "[epoch: 104/100000, batch: 80/1000, ite: 12885] train loss: 2.5598, accuracy: 88.0809%, tar: 0.1719 \n",
            "l0: 0.077750, l1: 0.079325, l2: 0.090295, l3: 0.114027, l4: 0.163576, l5: 0.255745, l6: 0.427043\n",
            "\n",
            "[epoch: 104/100000, batch: 88/1000, ite: 12886] train loss: 2.5588, accuracy: 93.8641%, tar: 0.1718 \n",
            "l0: 0.105343, l1: 0.106111, l2: 0.114972, l3: 0.145803, l4: 0.204420, l5: 0.329078, l6: 0.483197\n",
            "\n",
            "[epoch: 104/100000, batch: 96/1000, ite: 12887] train loss: 2.5581, accuracy: 91.4678%, tar: 0.1717 \n",
            "l0: 0.094016, l1: 0.096828, l2: 0.108717, l3: 0.141520, l4: 0.197696, l5: 0.308662, l6: 0.609541\n",
            "\n",
            "[epoch: 104/100000, batch: 104/1000, ite: 12888] train loss: 2.5577, accuracy: 90.0763%, tar: 0.1717 \n",
            "l0: 0.138800, l1: 0.143106, l2: 0.154705, l3: 0.193869, l4: 0.272946, l5: 0.437477, l6: 0.672077\n",
            "\n",
            "[epoch: 104/100000, batch: 112/1000, ite: 12889] train loss: 2.5579, accuracy: 88.5505%, tar: 0.1716 \n",
            "l0: 0.136137, l1: 0.137812, l2: 0.148207, l3: 0.169688, l4: 0.238209, l5: 0.351873, l6: 0.557124\n",
            "\n",
            "[epoch: 104/100000, batch: 120/1000, ite: 12890] train loss: 2.5576, accuracy: 91.5287%, tar: 0.1716 \n",
            "l0: 0.111804, l1: 0.112248, l2: 0.126044, l3: 0.164366, l4: 0.272221, l5: 0.439982, l6: 0.733641\n",
            "\n",
            "[epoch: 104/100000, batch: 128/1000, ite: 12891] train loss: 2.5577, accuracy: 89.0637%, tar: 0.1715 \n",
            "l0: 0.159810, l1: 0.162437, l2: 0.180830, l3: 0.216665, l4: 0.292262, l5: 0.442706, l6: 0.673763\n",
            "\n",
            "[epoch: 104/100000, batch: 136/1000, ite: 12892] train loss: 2.5579, accuracy: 88.9192%, tar: 0.1715 \n",
            "l0: 0.100917, l1: 0.101795, l2: 0.114002, l3: 0.141493, l4: 0.210679, l5: 0.332148, l6: 0.543833\n",
            "\n",
            "[epoch: 104/100000, batch: 144/1000, ite: 12893] train loss: 2.5574, accuracy: 91.7803%, tar: 0.1714 \n",
            "l0: 0.106104, l1: 0.107589, l2: 0.116231, l3: 0.135664, l4: 0.181547, l5: 0.260075, l6: 0.482130\n",
            "\n",
            "[epoch: 104/100000, batch: 152/1000, ite: 12894] train loss: 2.5566, accuracy: 91.8516%, tar: 0.1713 \n",
            "l0: 0.148095, l1: 0.150914, l2: 0.163087, l3: 0.190409, l4: 0.243928, l5: 0.345253, l6: 0.561412\n",
            "\n",
            "[epoch: 104/100000, batch: 160/1000, ite: 12895] train loss: 2.5564, accuracy: 90.8452%, tar: 0.1713 \n",
            "l0: 0.081570, l1: 0.082237, l2: 0.091505, l3: 0.115143, l4: 0.163928, l5: 0.268943, l6: 0.427115\n",
            "\n",
            "[epoch: 104/100000, batch: 168/1000, ite: 12896] train loss: 2.5554, accuracy: 92.2017%, tar: 0.1712 \n",
            "l0: 0.107393, l1: 0.109083, l2: 0.124031, l3: 0.147718, l4: 0.200211, l5: 0.318808, l6: 0.467967\n",
            "\n",
            "[epoch: 104/100000, batch: 176/1000, ite: 12897] train loss: 2.5548, accuracy: 92.6784%, tar: 0.1711 \n",
            "l0: 0.102356, l1: 0.104374, l2: 0.114154, l3: 0.137708, l4: 0.186600, l5: 0.293197, l6: 0.547806\n",
            "\n",
            "[epoch: 104/100000, batch: 184/1000, ite: 12898] train loss: 2.5542, accuracy: 90.7188%, tar: 0.1711 \n",
            "l0: 0.116092, l1: 0.116810, l2: 0.126242, l3: 0.152545, l4: 0.202553, l5: 0.306441, l6: 0.534559\n",
            "\n",
            "[epoch: 104/100000, batch: 192/1000, ite: 12899] train loss: 2.5537, accuracy: 90.6444%, tar: 0.1710 \n",
            "l0: 0.104842, l1: 0.108207, l2: 0.120947, l3: 0.148057, l4: 0.215986, l5: 0.341408, l6: 0.539829\n",
            "\n",
            "[epoch: 104/100000, batch: 200/1000, ite: 12900] train loss: 2.5531, accuracy: 92.0066%, tar: 0.1709 \n",
            "l0: 0.119947, l1: 0.122388, l2: 0.130530, l3: 0.159771, l4: 0.217383, l5: 0.338626, l6: 0.591362\n",
            "\n",
            "[epoch: 104/100000, batch: 208/1000, ite: 12901] train loss: 2.5528, accuracy: 88.8728%, tar: 0.1709 \n",
            "l0: 0.168634, l1: 0.173752, l2: 0.187452, l3: 0.211576, l4: 0.266689, l5: 0.376400, l6: 0.593056\n",
            "\n",
            "[epoch: 104/100000, batch: 216/1000, ite: 12902] train loss: 2.5528, accuracy: 89.4533%, tar: 0.1709 \n",
            "l0: 0.069392, l1: 0.073757, l2: 0.086230, l3: 0.105665, l4: 0.144955, l5: 0.215421, l6: 0.422158\n",
            "\n",
            "[epoch: 104/100000, batch: 224/1000, ite: 12903] train loss: 2.5517, accuracy: 93.6843%, tar: 0.1708 \n",
            "l0: 0.088591, l1: 0.089890, l2: 0.097251, l3: 0.115002, l4: 0.157010, l5: 0.254943, l6: 0.440321\n",
            "\n",
            "[epoch: 104/100000, batch: 232/1000, ite: 12904] train loss: 2.5507, accuracy: 91.9653%, tar: 0.1707 \n",
            "l0: 0.120350, l1: 0.121947, l2: 0.130309, l3: 0.155529, l4: 0.205564, l5: 0.287537, l6: 0.535105\n",
            "\n",
            "[epoch: 104/100000, batch: 240/1000, ite: 12905] train loss: 2.5502, accuracy: 90.2822%, tar: 0.1706 \n",
            "l0: 0.088160, l1: 0.091506, l2: 0.103802, l3: 0.133122, l4: 0.199370, l5: 0.292731, l6: 0.482088\n",
            "\n",
            "[epoch: 104/100000, batch: 248/1000, ite: 12906] train loss: 2.5495, accuracy: 92.5829%, tar: 0.1705 \n",
            "l0: 0.112732, l1: 0.115035, l2: 0.127920, l3: 0.152641, l4: 0.222458, l5: 0.319348, l6: 0.592294\n",
            "\n",
            "[epoch: 104/100000, batch: 256/1000, ite: 12907] train loss: 2.5491, accuracy: 90.2069%, tar: 0.1705 \n",
            "l0: 0.066448, l1: 0.068859, l2: 0.078012, l3: 0.095953, l4: 0.129247, l5: 0.204854, l6: 0.357725\n",
            "\n",
            "[epoch: 104/100000, batch: 264/1000, ite: 12908] train loss: 2.5478, accuracy: 92.7291%, tar: 0.1703 \n",
            "l0: 0.092725, l1: 0.095627, l2: 0.109100, l3: 0.132492, l4: 0.190738, l5: 0.288784, l6: 0.489282\n",
            "\n",
            "[epoch: 104/100000, batch: 272/1000, ite: 12909] train loss: 2.5471, accuracy: 91.8618%, tar: 0.1703 \n",
            "l0: 0.167876, l1: 0.170763, l2: 0.183632, l3: 0.225156, l4: 0.302100, l5: 0.438239, l6: 0.668446\n",
            "\n",
            "[epoch: 104/100000, batch: 280/1000, ite: 12910] train loss: 2.5474, accuracy: 89.0771%, tar: 0.1703 \n",
            "l0: 0.075302, l1: 0.075491, l2: 0.084615, l3: 0.107541, l4: 0.146626, l5: 0.232186, l6: 0.410059\n",
            "\n",
            "[epoch: 104/100000, batch: 288/1000, ite: 12911] train loss: 2.5463, accuracy: 93.0974%, tar: 0.1702 \n",
            "l0: 0.071998, l1: 0.074568, l2: 0.085800, l3: 0.109183, l4: 0.164815, l5: 0.286146, l6: 0.489627\n",
            "\n",
            "[epoch: 104/100000, batch: 296/1000, ite: 12912] train loss: 2.5454, accuracy: 92.1061%, tar: 0.1700 \n",
            "l0: 0.106356, l1: 0.108223, l2: 0.122542, l3: 0.147934, l4: 0.219172, l5: 0.310605, l6: 0.493801\n",
            "\n",
            "[epoch: 104/100000, batch: 304/1000, ite: 12913] train loss: 2.5448, accuracy: 91.0797%, tar: 0.1700 \n",
            "l0: 0.085123, l1: 0.085270, l2: 0.097019, l3: 0.120846, l4: 0.181151, l5: 0.300896, l6: 0.483663\n",
            "\n",
            "[epoch: 104/100000, batch: 312/1000, ite: 12914] train loss: 2.5441, accuracy: 92.2299%, tar: 0.1699 \n",
            "l0: 0.080673, l1: 0.083131, l2: 0.094925, l3: 0.127942, l4: 0.193498, l5: 0.305539, l6: 0.493572\n",
            "\n",
            "[epoch: 104/100000, batch: 320/1000, ite: 12915] train loss: 2.5434, accuracy: 92.4845%, tar: 0.1698 \n",
            "l0: 0.078366, l1: 0.080001, l2: 0.090582, l3: 0.108497, l4: 0.159534, l5: 0.267059, l6: 0.508819\n",
            "\n",
            "[epoch: 104/100000, batch: 328/1000, ite: 12916] train loss: 2.5426, accuracy: 91.5878%, tar: 0.1697 \n",
            "l0: 0.104199, l1: 0.105342, l2: 0.114354, l3: 0.132726, l4: 0.174285, l5: 0.250261, l6: 0.423295\n",
            "\n",
            "[epoch: 104/100000, batch: 336/1000, ite: 12917] train loss: 2.5417, accuracy: 92.4836%, tar: 0.1696 \n",
            "l0: 0.078728, l1: 0.080802, l2: 0.089818, l3: 0.111426, l4: 0.148039, l5: 0.228858, l6: 0.392187\n",
            "\n",
            "[epoch: 104/100000, batch: 344/1000, ite: 12918] train loss: 2.5406, accuracy: 92.1937%, tar: 0.1695 \n",
            "l0: 0.075677, l1: 0.076344, l2: 0.087568, l3: 0.123417, l4: 0.209441, l5: 0.275278, l6: 0.439682\n",
            "\n",
            "[epoch: 104/100000, batch: 352/1000, ite: 12919] train loss: 2.5397, accuracy: 93.5344%, tar: 0.1694 \n",
            "l0: 0.120546, l1: 0.121875, l2: 0.134835, l3: 0.169571, l4: 0.242471, l5: 0.372734, l6: 0.617320\n",
            "\n",
            "[epoch: 104/100000, batch: 360/1000, ite: 12920] train loss: 2.5395, accuracy: 90.7240%, tar: 0.1694 \n",
            "l0: 0.074833, l1: 0.075929, l2: 0.086011, l3: 0.103902, l4: 0.143668, l5: 0.218602, l6: 0.349597\n",
            "\n",
            "[epoch: 104/100000, batch: 368/1000, ite: 12921] train loss: 2.5383, accuracy: 92.5754%, tar: 0.1693 \n",
            "l0: 0.080202, l1: 0.081615, l2: 0.095633, l3: 0.128523, l4: 0.185634, l5: 0.298421, l6: 0.478138\n",
            "\n",
            "[epoch: 104/100000, batch: 376/1000, ite: 12922] train loss: 2.5375, accuracy: 92.3477%, tar: 0.1692 \n",
            "l0: 0.108780, l1: 0.110620, l2: 0.120899, l3: 0.138960, l4: 0.178575, l5: 0.269278, l6: 0.457036\n",
            "\n",
            "[epoch: 104/100000, batch: 384/1000, ite: 12923] train loss: 2.5367, accuracy: 92.0485%, tar: 0.1691 \n",
            "l0: 0.069296, l1: 0.070710, l2: 0.081632, l3: 0.105654, l4: 0.148770, l5: 0.255014, l6: 0.442658\n",
            "\n",
            "[epoch: 104/100000, batch: 392/1000, ite: 12924] train loss: 2.5357, accuracy: 92.0719%, tar: 0.1690 \n",
            "l0: 0.112809, l1: 0.114693, l2: 0.127989, l3: 0.158936, l4: 0.225932, l5: 0.327629, l6: 0.487446\n",
            "\n",
            "[epoch: 104/100000, batch: 400/1000, ite: 12925] train loss: 2.5352, accuracy: 91.5410%, tar: 0.1689 \n",
            "l0: 0.112014, l1: 0.113455, l2: 0.126282, l3: 0.160542, l4: 0.237042, l5: 0.349164, l6: 0.541111\n",
            "\n",
            "[epoch: 104/100000, batch: 408/1000, ite: 12926] train loss: 2.5348, accuracy: 90.7831%, tar: 0.1689 \n",
            "l0: 0.091952, l1: 0.094826, l2: 0.102880, l3: 0.118668, l4: 0.172205, l5: 0.261632, l6: 0.438704\n",
            "\n",
            "[epoch: 104/100000, batch: 416/1000, ite: 12927] train loss: 2.5339, accuracy: 91.9254%, tar: 0.1688 \n",
            "l0: 0.102054, l1: 0.103980, l2: 0.115880, l3: 0.140172, l4: 0.198011, l5: 0.292879, l6: 0.509930\n",
            "\n",
            "[epoch: 104/100000, batch: 424/1000, ite: 12928] train loss: 2.5333, accuracy: 92.2930%, tar: 0.1687 \n",
            "l0: 0.097556, l1: 0.098783, l2: 0.110931, l3: 0.136706, l4: 0.192146, l5: 0.324496, l6: 0.516851\n",
            "\n",
            "[epoch: 104/100000, batch: 432/1000, ite: 12929] train loss: 2.5327, accuracy: 91.3990%, tar: 0.1686 \n",
            "l0: 0.117369, l1: 0.119022, l2: 0.132133, l3: 0.167693, l4: 0.238188, l5: 0.346102, l6: 0.557175\n",
            "\n",
            "[epoch: 104/100000, batch: 440/1000, ite: 12930] train loss: 2.5324, accuracy: 91.4440%, tar: 0.1686 \n",
            "l0: 0.128843, l1: 0.131407, l2: 0.140829, l3: 0.164224, l4: 0.215908, l5: 0.304949, l6: 0.474040\n",
            "\n",
            "[epoch: 104/100000, batch: 448/1000, ite: 12931] train loss: 2.5319, accuracy: 90.6682%, tar: 0.1685 \n",
            "l0: 0.078925, l1: 0.082812, l2: 0.097024, l3: 0.130205, l4: 0.204026, l5: 0.315833, l6: 0.509087\n",
            "\n",
            "[epoch: 104/100000, batch: 456/1000, ite: 12932] train loss: 2.5313, accuracy: 92.1392%, tar: 0.1684 \n",
            "l0: 0.115501, l1: 0.118809, l2: 0.133007, l3: 0.169238, l4: 0.230802, l5: 0.348177, l6: 0.607765\n",
            "\n",
            "[epoch: 104/100000, batch: 464/1000, ite: 12933] train loss: 2.5310, accuracy: 90.3880%, tar: 0.1684 \n",
            "l0: 0.094897, l1: 0.097483, l2: 0.109467, l3: 0.144579, l4: 0.196221, l5: 0.289455, l6: 0.471905\n",
            "\n",
            "[epoch: 104/100000, batch: 472/1000, ite: 12934] train loss: 2.5303, accuracy: 91.4801%, tar: 0.1683 \n",
            "l0: 0.098728, l1: 0.100852, l2: 0.111780, l3: 0.138141, l4: 0.181946, l5: 0.291760, l6: 0.455627\n",
            "\n",
            "[epoch: 104/100000, batch: 480/1000, ite: 12935] train loss: 2.5296, accuracy: 92.4827%, tar: 0.1682 \n",
            "l0: 0.092024, l1: 0.093380, l2: 0.106404, l3: 0.131049, l4: 0.188898, l5: 0.279637, l6: 0.501810\n",
            "\n",
            "[epoch: 104/100000, batch: 488/1000, ite: 12936] train loss: 2.5289, accuracy: 91.8068%, tar: 0.1682 \n",
            "l0: 0.086495, l1: 0.089108, l2: 0.099938, l3: 0.123946, l4: 0.186015, l5: 0.292206, l6: 0.500028\n",
            "\n",
            "[epoch: 104/100000, batch: 496/1000, ite: 12937] train loss: 2.5282, accuracy: 91.1959%, tar: 0.1681 \n",
            "l0: 0.094774, l1: 0.096116, l2: 0.106246, l3: 0.136619, l4: 0.183785, l5: 0.307917, l6: 0.566493\n",
            "\n",
            "[epoch: 104/100000, batch: 504/1000, ite: 12938] train loss: 2.5277, accuracy: 90.9549%, tar: 0.1680 \n",
            "l0: 0.081934, l1: 0.083547, l2: 0.092244, l3: 0.115695, l4: 0.178319, l5: 0.257597, l6: 0.437806\n",
            "\n",
            "[epoch: 104/100000, batch: 512/1000, ite: 12939] train loss: 2.5268, accuracy: 92.9751%, tar: 0.1679 \n",
            "l0: 0.086513, l1: 0.087088, l2: 0.101198, l3: 0.125405, l4: 0.194515, l5: 0.340726, l6: 0.535039\n",
            "\n",
            "[epoch: 104/100000, batch: 520/1000, ite: 12940] train loss: 2.5263, accuracy: 92.3088%, tar: 0.1678 \n",
            "l0: 0.077772, l1: 0.081282, l2: 0.093871, l3: 0.129943, l4: 0.207185, l5: 0.303483, l6: 0.520045\n",
            "\n",
            "[epoch: 104/100000, batch: 528/1000, ite: 12941] train loss: 2.5256, accuracy: 91.4789%, tar: 0.1677 \n",
            "l0: 0.068763, l1: 0.069995, l2: 0.083405, l3: 0.104842, l4: 0.149581, l5: 0.250412, l6: 0.444232\n",
            "\n",
            "[epoch: 104/100000, batch: 536/1000, ite: 12942] train loss: 2.5247, accuracy: 92.8104%, tar: 0.1676 \n",
            "l0: 0.084524, l1: 0.085661, l2: 0.098483, l3: 0.133642, l4: 0.207109, l5: 0.342750, l6: 0.640049\n",
            "\n",
            "[epoch: 104/100000, batch: 544/1000, ite: 12943] train loss: 2.5243, accuracy: 90.8504%, tar: 0.1675 \n",
            "l0: 0.097795, l1: 0.098313, l2: 0.109546, l3: 0.125385, l4: 0.181839, l5: 0.262311, l6: 0.428407\n",
            "\n",
            "[epoch: 104/100000, batch: 552/1000, ite: 12944] train loss: 2.5235, accuracy: 92.0683%, tar: 0.1674 \n",
            "l0: 0.118456, l1: 0.121454, l2: 0.134304, l3: 0.163116, l4: 0.234842, l5: 0.353803, l6: 0.487571\n",
            "\n",
            "[epoch: 104/100000, batch: 560/1000, ite: 12945] train loss: 2.5231, accuracy: 91.4263%, tar: 0.1674 \n",
            "l0: 0.102307, l1: 0.104560, l2: 0.116765, l3: 0.137297, l4: 0.208435, l5: 0.321267, l6: 0.521143\n",
            "\n",
            "[epoch: 104/100000, batch: 568/1000, ite: 12946] train loss: 2.5226, accuracy: 91.4604%, tar: 0.1673 \n",
            "l0: 0.087768, l1: 0.092445, l2: 0.103107, l3: 0.128946, l4: 0.196000, l5: 0.313763, l6: 0.462065\n",
            "\n",
            "[epoch: 104/100000, batch: 576/1000, ite: 12947] train loss: 2.5219, accuracy: 91.9245%, tar: 0.1672 \n",
            "l0: 0.108906, l1: 0.111234, l2: 0.120278, l3: 0.142854, l4: 0.186416, l5: 0.282874, l6: 0.469630\n",
            "\n",
            "[epoch: 104/100000, batch: 584/1000, ite: 12948] train loss: 2.5212, accuracy: 91.0358%, tar: 0.1672 \n",
            "l0: 0.083570, l1: 0.086056, l2: 0.093426, l3: 0.123328, l4: 0.169321, l5: 0.262418, l6: 0.450927\n",
            "\n",
            "[epoch: 104/100000, batch: 592/1000, ite: 12949] train loss: 2.5204, accuracy: 91.6695%, tar: 0.1671 \n",
            "l0: 0.069620, l1: 0.071461, l2: 0.079679, l3: 0.105053, l4: 0.155472, l5: 0.255470, l6: 0.399560\n",
            "\n",
            "[epoch: 104/100000, batch: 600/1000, ite: 12950] train loss: 2.5193, accuracy: 92.8986%, tar: 0.1670 \n",
            "l0: 0.104098, l1: 0.107123, l2: 0.119178, l3: 0.142416, l4: 0.194678, l5: 0.300001, l6: 0.508879\n",
            "\n",
            "[epoch: 104/100000, batch: 608/1000, ite: 12951] train loss: 2.5188, accuracy: 91.2374%, tar: 0.1669 \n",
            "l0: 0.101057, l1: 0.105814, l2: 0.114733, l3: 0.144689, l4: 0.200553, l5: 0.297302, l6: 0.526689\n",
            "\n",
            "[epoch: 104/100000, batch: 616/1000, ite: 12952] train loss: 2.5182, accuracy: 92.3268%, tar: 0.1669 \n",
            "l0: 0.138661, l1: 0.141941, l2: 0.152707, l3: 0.176657, l4: 0.218852, l5: 0.299034, l6: 0.489584\n",
            "\n",
            "[epoch: 104/100000, batch: 624/1000, ite: 12953] train loss: 2.5178, accuracy: 92.3249%, tar: 0.1668 \n",
            "l0: 0.085702, l1: 0.087264, l2: 0.099359, l3: 0.123741, l4: 0.180966, l5: 0.291966, l6: 0.515865\n",
            "\n",
            "[epoch: 104/100000, batch: 632/1000, ite: 12954] train loss: 2.5172, accuracy: 92.1743%, tar: 0.1667 \n",
            "l0: 0.081073, l1: 0.083092, l2: 0.092047, l3: 0.117407, l4: 0.165259, l5: 0.254565, l6: 0.470006\n",
            "\n",
            "[epoch: 104/100000, batch: 640/1000, ite: 12955] train loss: 2.5163, accuracy: 92.1227%, tar: 0.1666 \n",
            "l0: 0.104866, l1: 0.105934, l2: 0.120658, l3: 0.149813, l4: 0.220912, l5: 0.313169, l6: 0.530843\n",
            "\n",
            "[epoch: 104/100000, batch: 648/1000, ite: 12956] train loss: 2.5159, accuracy: 91.7299%, tar: 0.1666 \n",
            "l0: 0.108256, l1: 0.109880, l2: 0.120217, l3: 0.137686, l4: 0.178730, l5: 0.266638, l6: 0.443510\n",
            "\n",
            "[epoch: 104/100000, batch: 656/1000, ite: 12957] train loss: 2.5151, accuracy: 91.8336%, tar: 0.1665 \n",
            "l0: 0.169639, l1: 0.171195, l2: 0.184734, l3: 0.211229, l4: 0.280290, l5: 0.413060, l6: 0.599642\n",
            "\n",
            "[epoch: 104/100000, batch: 664/1000, ite: 12958] train loss: 2.5152, accuracy: 89.5740%, tar: 0.1665 \n",
            "l0: 0.084706, l1: 0.088262, l2: 0.098892, l3: 0.127815, l4: 0.199138, l5: 0.308542, l6: 0.469427\n",
            "\n",
            "[epoch: 104/100000, batch: 672/1000, ite: 12959] train loss: 2.5145, accuracy: 92.0971%, tar: 0.1664 \n",
            "l0: 0.120853, l1: 0.122954, l2: 0.129457, l3: 0.151827, l4: 0.214602, l5: 0.317589, l6: 0.431939\n",
            "\n",
            "[epoch: 104/100000, batch: 680/1000, ite: 12960] train loss: 2.5139, accuracy: 93.0441%, tar: 0.1664 \n",
            "l0: 0.089647, l1: 0.092028, l2: 0.101559, l3: 0.125869, l4: 0.176939, l5: 0.262473, l6: 0.448156\n",
            "\n",
            "[epoch: 104/100000, batch: 688/1000, ite: 12961] train loss: 2.5131, accuracy: 92.7715%, tar: 0.1663 \n",
            "l0: 0.089674, l1: 0.091624, l2: 0.099928, l3: 0.122183, l4: 0.177077, l5: 0.292862, l6: 0.556817\n",
            "\n",
            "[epoch: 104/100000, batch: 696/1000, ite: 12962] train loss: 2.5126, accuracy: 91.1549%, tar: 0.1662 \n",
            "l0: 0.130115, l1: 0.135067, l2: 0.144616, l3: 0.170307, l4: 0.233978, l5: 0.371351, l6: 0.603278\n",
            "\n",
            "[epoch: 104/100000, batch: 704/1000, ite: 12963] train loss: 2.5124, accuracy: 91.3367%, tar: 0.1662 \n",
            "l0: 0.092264, l1: 0.093432, l2: 0.102516, l3: 0.127447, l4: 0.170634, l5: 0.275177, l6: 0.491751\n",
            "\n",
            "[epoch: 104/100000, batch: 712/1000, ite: 12964] train loss: 2.5118, accuracy: 91.8403%, tar: 0.1661 \n",
            "l0: 0.129570, l1: 0.129728, l2: 0.140327, l3: 0.161704, l4: 0.216437, l5: 0.329366, l6: 0.565596\n",
            "\n",
            "[epoch: 104/100000, batch: 720/1000, ite: 12965] train loss: 2.5115, accuracy: 90.6302%, tar: 0.1661 \n",
            "l0: 0.117572, l1: 0.116924, l2: 0.131545, l3: 0.164975, l4: 0.234567, l5: 0.374995, l6: 0.561126\n",
            "\n",
            "[epoch: 104/100000, batch: 728/1000, ite: 12966] train loss: 2.5112, accuracy: 90.5917%, tar: 0.1660 \n",
            "l0: 0.121767, l1: 0.122585, l2: 0.133285, l3: 0.156170, l4: 0.220137, l5: 0.349301, l6: 0.544730\n",
            "\n",
            "[epoch: 104/100000, batch: 736/1000, ite: 12967] train loss: 2.5109, accuracy: 91.1151%, tar: 0.1660 \n",
            "l0: 0.147300, l1: 0.150295, l2: 0.163933, l3: 0.195441, l4: 0.264640, l5: 0.374611, l6: 0.573537\n",
            "\n",
            "[epoch: 104/100000, batch: 744/1000, ite: 12968] train loss: 2.5108, accuracy: 89.6814%, tar: 0.1660 \n",
            "l0: 0.102935, l1: 0.104769, l2: 0.119030, l3: 0.153813, l4: 0.232414, l5: 0.403810, l6: 0.639169\n",
            "\n",
            "[epoch: 104/100000, batch: 752/1000, ite: 12969] train loss: 2.5107, accuracy: 89.1835%, tar: 0.1659 \n",
            "l0: 0.063667, l1: 0.064499, l2: 0.073634, l3: 0.092088, l4: 0.131821, l5: 0.219485, l6: 0.409306\n",
            "\n",
            "[epoch: 104/100000, batch: 760/1000, ite: 12970] train loss: 2.5096, accuracy: 92.5243%, tar: 0.1658 \n",
            "l0: 0.092186, l1: 0.093544, l2: 0.102315, l3: 0.128763, l4: 0.184859, l5: 0.281639, l6: 0.437346\n",
            "\n",
            "[epoch: 104/100000, batch: 768/1000, ite: 12971] train loss: 2.5088, accuracy: 92.3681%, tar: 0.1657 \n",
            "l0: 0.096345, l1: 0.095044, l2: 0.106240, l3: 0.137178, l4: 0.195287, l5: 0.304685, l6: 0.528010\n",
            "\n",
            "[epoch: 104/100000, batch: 776/1000, ite: 12972] train loss: 2.5083, accuracy: 91.0808%, tar: 0.1656 \n",
            "l0: 0.074947, l1: 0.075500, l2: 0.083614, l3: 0.101640, l4: 0.151287, l5: 0.235654, l6: 0.427072\n",
            "\n",
            "[epoch: 104/100000, batch: 784/1000, ite: 12973] train loss: 2.5073, accuracy: 92.1206%, tar: 0.1656 \n",
            "l0: 0.114776, l1: 0.115932, l2: 0.123062, l3: 0.145995, l4: 0.202791, l5: 0.256923, l6: 0.420242\n",
            "\n",
            "[epoch: 104/100000, batch: 792/1000, ite: 12974] train loss: 2.5066, accuracy: 92.9745%, tar: 0.1655 \n",
            "l0: 0.117828, l1: 0.120131, l2: 0.129426, l3: 0.146600, l4: 0.191554, l5: 0.267520, l6: 0.426778\n",
            "\n",
            "[epoch: 104/100000, batch: 800/1000, ite: 12975] train loss: 2.5059, accuracy: 91.2282%, tar: 0.1655 \n",
            "l0: 0.094699, l1: 0.094159, l2: 0.107255, l3: 0.133548, l4: 0.199757, l5: 0.324053, l6: 0.514354\n",
            "\n",
            "[epoch: 104/100000, batch: 808/1000, ite: 12976] train loss: 2.5054, accuracy: 92.0699%, tar: 0.1654 \n",
            "l0: 0.152035, l1: 0.150826, l2: 0.163355, l3: 0.187999, l4: 0.230230, l5: 0.302324, l6: 0.479754\n",
            "\n",
            "[epoch: 104/100000, batch: 816/1000, ite: 12977] train loss: 2.5050, accuracy: 91.1917%, tar: 0.1654 \n",
            "l0: 0.123015, l1: 0.126699, l2: 0.144022, l3: 0.177300, l4: 0.263295, l5: 0.407345, l6: 0.645257\n",
            "\n",
            "[epoch: 104/100000, batch: 824/1000, ite: 12978] train loss: 2.5051, accuracy: 88.3226%, tar: 0.1653 \n",
            "l0: 0.133656, l1: 0.136680, l2: 0.147741, l3: 0.168703, l4: 0.230680, l5: 0.347741, l6: 0.531857\n",
            "\n",
            "[epoch: 104/100000, batch: 832/1000, ite: 12979] train loss: 2.5048, accuracy: 89.4518%, tar: 0.1653 \n",
            "l0: 0.105601, l1: 0.104986, l2: 0.117912, l3: 0.146035, l4: 0.194342, l5: 0.292111, l6: 0.481645\n",
            "\n",
            "[epoch: 104/100000, batch: 840/1000, ite: 12980] train loss: 2.5042, accuracy: 91.4066%, tar: 0.1652 \n",
            "l0: 0.112295, l1: 0.112843, l2: 0.125166, l3: 0.157857, l4: 0.226348, l5: 0.330763, l6: 0.554462\n",
            "\n",
            "[epoch: 104/100000, batch: 848/1000, ite: 12981] train loss: 2.5039, accuracy: 90.7492%, tar: 0.1652 \n",
            "l0: 0.083778, l1: 0.084446, l2: 0.095593, l3: 0.123792, l4: 0.178711, l5: 0.300903, l6: 0.530668\n",
            "\n",
            "[epoch: 104/100000, batch: 856/1000, ite: 12982] train loss: 2.5033, accuracy: 90.6667%, tar: 0.1651 \n",
            "l0: 0.146181, l1: 0.148921, l2: 0.161398, l3: 0.196201, l4: 0.236691, l5: 0.317708, l6: 0.606258\n",
            "\n",
            "[epoch: 104/100000, batch: 864/1000, ite: 12983] train loss: 2.5032, accuracy: 89.9737%, tar: 0.1651 \n",
            "l0: 0.092611, l1: 0.093924, l2: 0.105290, l3: 0.128110, l4: 0.189143, l5: 0.283352, l6: 0.450325\n",
            "\n",
            "[epoch: 104/100000, batch: 872/1000, ite: 12984] train loss: 2.5025, accuracy: 91.9039%, tar: 0.1650 \n",
            "l0: 0.180394, l1: 0.195859, l2: 0.200897, l3: 0.215456, l4: 0.243799, l5: 0.332353, l6: 0.505983\n",
            "\n",
            "[epoch: 104/100000, batch: 880/1000, ite: 12985] train loss: 2.5023, accuracy: 90.1687%, tar: 0.1650 \n",
            "l0: 0.111354, l1: 0.113141, l2: 0.124135, l3: 0.147147, l4: 0.215194, l5: 0.349082, l6: 0.540929\n",
            "\n",
            "[epoch: 104/100000, batch: 888/1000, ite: 12986] train loss: 2.5020, accuracy: 91.0180%, tar: 0.1650 \n",
            "l0: 0.102584, l1: 0.102780, l2: 0.112315, l3: 0.134842, l4: 0.177339, l5: 0.272972, l6: 0.415618\n",
            "\n",
            "[epoch: 104/100000, batch: 896/1000, ite: 12987] train loss: 2.5012, accuracy: 92.9038%, tar: 0.1649 \n",
            "l0: 0.101210, l1: 0.102929, l2: 0.111952, l3: 0.129154, l4: 0.173297, l5: 0.250471, l6: 0.456400\n",
            "\n",
            "[epoch: 104/100000, batch: 904/1000, ite: 12988] train loss: 2.5005, accuracy: 91.5165%, tar: 0.1648 \n",
            "l0: 0.111499, l1: 0.110884, l2: 0.123008, l3: 0.143637, l4: 0.205252, l5: 0.308377, l6: 0.562483\n",
            "\n",
            "[epoch: 104/100000, batch: 912/1000, ite: 12989] train loss: 2.5001, accuracy: 90.6327%, tar: 0.1648 \n",
            "l0: 0.082710, l1: 0.086582, l2: 0.099348, l3: 0.125853, l4: 0.183545, l5: 0.293919, l6: 0.450949\n",
            "\n",
            "[epoch: 104/100000, batch: 920/1000, ite: 12990] train loss: 2.4994, accuracy: 94.3708%, tar: 0.1647 \n",
            "l0: 0.114955, l1: 0.118334, l2: 0.128838, l3: 0.163765, l4: 0.257942, l5: 0.399699, l6: 0.600589\n",
            "\n",
            "[epoch: 104/100000, batch: 928/1000, ite: 12991] train loss: 2.4993, accuracy: 90.5083%, tar: 0.1646 \n",
            "l0: 0.080694, l1: 0.087085, l2: 0.100685, l3: 0.136207, l4: 0.226134, l5: 0.348328, l6: 0.592206\n",
            "\n",
            "[epoch: 104/100000, batch: 936/1000, ite: 12992] train loss: 2.4989, accuracy: 93.1779%, tar: 0.1646 \n",
            "l0: 0.120571, l1: 0.121521, l2: 0.132998, l3: 0.153770, l4: 0.200193, l5: 0.287375, l6: 0.421950\n",
            "\n",
            "[epoch: 104/100000, batch: 944/1000, ite: 12993] train loss: 2.4983, accuracy: 91.9930%, tar: 0.1645 \n",
            "l0: 0.093381, l1: 0.096262, l2: 0.109205, l3: 0.136894, l4: 0.203176, l5: 0.292250, l6: 0.511093\n",
            "\n",
            "[epoch: 104/100000, batch: 952/1000, ite: 12994] train loss: 2.4978, accuracy: 93.0308%, tar: 0.1644 \n",
            "l0: 0.061741, l1: 0.063882, l2: 0.074023, l3: 0.103377, l4: 0.153214, l5: 0.243245, l6: 0.457038\n",
            "\n",
            "[epoch: 104/100000, batch: 960/1000, ite: 12995] train loss: 2.4969, accuracy: 93.2443%, tar: 0.1643 \n",
            "l0: 0.302037, l1: 0.296620, l2: 0.316599, l3: 0.356166, l4: 0.439689, l5: 0.599738, l6: 0.779887\n",
            "\n",
            "[epoch: 104/100000, batch: 968/1000, ite: 12996] train loss: 2.4982, accuracy: 88.1141%, tar: 0.1645 \n",
            "l0: 0.098858, l1: 0.099548, l2: 0.109187, l3: 0.127202, l4: 0.168624, l5: 0.245806, l6: 0.417986\n",
            "\n",
            "[epoch: 104/100000, batch: 976/1000, ite: 12997] train loss: 2.4974, accuracy: 92.2246%, tar: 0.1644 \n",
            "l0: 0.102427, l1: 0.101396, l2: 0.112985, l3: 0.133698, l4: 0.200747, l5: 0.305786, l6: 0.584360\n",
            "\n",
            "[epoch: 104/100000, batch: 984/1000, ite: 12998] train loss: 2.4971, accuracy: 91.2931%, tar: 0.1644 \n",
            "l0: 0.145879, l1: 0.147245, l2: 0.158125, l3: 0.188843, l4: 0.255070, l5: 0.382947, l6: 0.581955\n",
            "\n",
            "[epoch: 104/100000, batch: 992/1000, ite: 12999] train loss: 2.4971, accuracy: 90.0459%, tar: 0.1643 \n",
            "l0: 0.082359, l1: 0.083472, l2: 0.093295, l3: 0.117767, l4: 0.155655, l5: 0.248308, l6: 0.386889\n",
            "\n",
            "[epoch: 104/100000, batch: 1000/1000, ite: 13000] train loss: 2.4961, accuracy: 92.9968%, tar: 0.1643 \n",
            "l0: 0.103649, l1: 0.106512, l2: 0.115678, l3: 0.141378, l4: 0.193484, l5: 0.265804, l6: 0.438960\n",
            "\n",
            "[epoch: 105/100000, batch: 8/1000, ite: 13001] train loss: 2.4954, accuracy: 92.5504%, tar: 0.1642 \n",
            "l0: 0.091668, l1: 0.095626, l2: 0.112122, l3: 0.133354, l4: 0.175091, l5: 0.252441, l6: 0.367308\n",
            "\n",
            "[epoch: 105/100000, batch: 16/1000, ite: 13002] train loss: 2.4945, accuracy: 92.7279%, tar: 0.1641 \n",
            "l0: 0.110578, l1: 0.112819, l2: 0.120651, l3: 0.141391, l4: 0.199950, l5: 0.271244, l6: 0.455345\n",
            "\n",
            "[epoch: 105/100000, batch: 24/1000, ite: 13003] train loss: 2.4939, accuracy: 92.5116%, tar: 0.1641 \n",
            "l0: 0.087048, l1: 0.089458, l2: 0.097271, l3: 0.113561, l4: 0.159784, l5: 0.240392, l6: 0.430436\n",
            "\n",
            "[epoch: 105/100000, batch: 32/1000, ite: 13004] train loss: 2.4931, accuracy: 92.4740%, tar: 0.1640 \n",
            "l0: 0.152691, l1: 0.155545, l2: 0.169633, l3: 0.195706, l4: 0.282789, l5: 0.368185, l6: 0.519414\n",
            "\n",
            "[epoch: 105/100000, batch: 40/1000, ite: 13005] train loss: 2.4930, accuracy: 91.3198%, tar: 0.1640 \n",
            "l0: 0.093193, l1: 0.095599, l2: 0.111017, l3: 0.134942, l4: 0.203168, l5: 0.327770, l6: 0.529975\n",
            "\n",
            "[epoch: 105/100000, batch: 48/1000, ite: 13006] train loss: 2.4925, accuracy: 91.6764%, tar: 0.1639 \n",
            "l0: 0.103027, l1: 0.103141, l2: 0.117041, l3: 0.153429, l4: 0.239295, l5: 0.358813, l6: 0.580789\n",
            "\n",
            "[epoch: 105/100000, batch: 56/1000, ite: 13007] train loss: 2.4922, accuracy: 91.5825%, tar: 0.1638 \n",
            "l0: 0.069061, l1: 0.071925, l2: 0.079298, l3: 0.100399, l4: 0.144298, l5: 0.208842, l6: 0.369608\n",
            "\n",
            "[epoch: 105/100000, batch: 64/1000, ite: 13008] train loss: 2.4912, accuracy: 94.4587%, tar: 0.1638 \n",
            "l0: 0.079396, l1: 0.080736, l2: 0.091205, l3: 0.117700, l4: 0.187220, l5: 0.303238, l6: 0.479326\n",
            "\n",
            "[epoch: 105/100000, batch: 72/1000, ite: 13009] train loss: 2.4905, accuracy: 92.5670%, tar: 0.1637 \n",
            "l0: 0.110622, l1: 0.113316, l2: 0.129250, l3: 0.164567, l4: 0.222646, l5: 0.365645, l6: 0.536007\n",
            "\n",
            "[epoch: 105/100000, batch: 80/1000, ite: 13010] train loss: 2.4902, accuracy: 90.7978%, tar: 0.1636 \n",
            "l0: 0.078176, l1: 0.080087, l2: 0.090385, l3: 0.115199, l4: 0.170274, l5: 0.277380, l6: 0.468559\n",
            "\n",
            "[epoch: 105/100000, batch: 88/1000, ite: 13011] train loss: 2.4895, accuracy: 91.6268%, tar: 0.1635 \n",
            "l0: 0.084921, l1: 0.086894, l2: 0.100149, l3: 0.131013, l4: 0.182132, l5: 0.280115, l6: 0.438700\n",
            "\n",
            "[epoch: 105/100000, batch: 96/1000, ite: 13012] train loss: 2.4888, accuracy: 92.4875%, tar: 0.1635 \n",
            "l0: 0.102981, l1: 0.107066, l2: 0.120978, l3: 0.152670, l4: 0.216281, l5: 0.317232, l6: 0.520962\n",
            "\n",
            "[epoch: 105/100000, batch: 104/1000, ite: 13013] train loss: 2.4884, accuracy: 92.2133%, tar: 0.1634 \n",
            "l0: 0.083748, l1: 0.085591, l2: 0.097083, l3: 0.124191, l4: 0.170147, l5: 0.270604, l6: 0.431407\n",
            "\n",
            "[epoch: 105/100000, batch: 112/1000, ite: 13014] train loss: 2.4876, accuracy: 92.8498%, tar: 0.1633 \n",
            "l0: 0.103395, l1: 0.106533, l2: 0.117576, l3: 0.142806, l4: 0.188565, l5: 0.251631, l6: 0.460236\n",
            "\n",
            "[epoch: 105/100000, batch: 120/1000, ite: 13015] train loss: 2.4870, accuracy: 91.2480%, tar: 0.1633 \n",
            "l0: 0.135810, l1: 0.139286, l2: 0.151197, l3: 0.176372, l4: 0.245627, l5: 0.375693, l6: 0.545321\n",
            "\n",
            "[epoch: 105/100000, batch: 128/1000, ite: 13016] train loss: 2.4868, accuracy: 91.5924%, tar: 0.1632 \n",
            "l0: 0.084967, l1: 0.087269, l2: 0.097435, l3: 0.115156, l4: 0.149381, l5: 0.225007, l6: 0.344928\n",
            "\n",
            "[epoch: 105/100000, batch: 136/1000, ite: 13017] train loss: 2.4858, accuracy: 93.1110%, tar: 0.1632 \n",
            "l0: 0.126419, l1: 0.128086, l2: 0.137719, l3: 0.159112, l4: 0.205733, l5: 0.301365, l6: 0.475339\n",
            "\n",
            "[epoch: 105/100000, batch: 144/1000, ite: 13018] train loss: 2.4853, accuracy: 91.6204%, tar: 0.1631 \n",
            "l0: 0.094300, l1: 0.095312, l2: 0.105624, l3: 0.132464, l4: 0.174803, l5: 0.295670, l6: 0.518418\n",
            "\n",
            "[epoch: 105/100000, batch: 152/1000, ite: 13019] train loss: 2.4848, accuracy: 91.8718%, tar: 0.1631 \n",
            "l0: 0.144248, l1: 0.145148, l2: 0.158946, l3: 0.188318, l4: 0.254074, l5: 0.346663, l6: 0.584399\n",
            "\n",
            "[epoch: 105/100000, batch: 160/1000, ite: 13020] train loss: 2.4847, accuracy: 89.8290%, tar: 0.1630 \n",
            "l0: 0.070050, l1: 0.069745, l2: 0.078423, l3: 0.097248, l4: 0.142548, l5: 0.220336, l6: 0.382947\n",
            "\n",
            "[epoch: 105/100000, batch: 168/1000, ite: 13021] train loss: 2.4837, accuracy: 93.0787%, tar: 0.1629 \n",
            "l0: 0.090306, l1: 0.091511, l2: 0.104566, l3: 0.132950, l4: 0.197800, l5: 0.290590, l6: 0.532421\n",
            "\n",
            "[epoch: 105/100000, batch: 176/1000, ite: 13022] train loss: 2.4832, accuracy: 91.7995%, tar: 0.1629 \n",
            "l0: 0.118647, l1: 0.120747, l2: 0.129951, l3: 0.151151, l4: 0.207318, l5: 0.328869, l6: 0.550959\n",
            "\n",
            "[epoch: 105/100000, batch: 184/1000, ite: 13023] train loss: 2.4829, accuracy: 89.9371%, tar: 0.1628 \n",
            "l0: 0.099888, l1: 0.101241, l2: 0.108621, l3: 0.130141, l4: 0.181558, l5: 0.272429, l6: 0.442836\n",
            "\n",
            "[epoch: 105/100000, batch: 192/1000, ite: 13024] train loss: 2.4822, accuracy: 91.7609%, tar: 0.1628 \n",
            "l0: 0.085976, l1: 0.087223, l2: 0.097130, l3: 0.115752, l4: 0.151464, l5: 0.223362, l6: 0.368544\n",
            "\n",
            "[epoch: 105/100000, batch: 200/1000, ite: 13025] train loss: 2.4812, accuracy: 91.7959%, tar: 0.1627 \n",
            "l0: 0.086077, l1: 0.085814, l2: 0.094428, l3: 0.119013, l4: 0.176666, l5: 0.274668, l6: 0.521826\n",
            "\n",
            "[epoch: 105/100000, batch: 208/1000, ite: 13026] train loss: 2.4806, accuracy: 92.8287%, tar: 0.1626 \n",
            "l0: 0.092058, l1: 0.094040, l2: 0.105529, l3: 0.140604, l4: 0.210240, l5: 0.294743, l6: 0.453617\n",
            "\n",
            "[epoch: 105/100000, batch: 216/1000, ite: 13027] train loss: 2.4800, accuracy: 93.4454%, tar: 0.1625 \n",
            "l0: 0.053871, l1: 0.056270, l2: 0.068748, l3: 0.092988, l4: 0.146644, l5: 0.257887, l6: 0.419372\n",
            "\n",
            "[epoch: 105/100000, batch: 224/1000, ite: 13028] train loss: 2.4791, accuracy: 94.2319%, tar: 0.1624 \n",
            "l0: 0.105690, l1: 0.107666, l2: 0.118046, l3: 0.143144, l4: 0.210488, l5: 0.326048, l6: 0.531004\n",
            "\n",
            "[epoch: 105/100000, batch: 232/1000, ite: 13029] train loss: 2.4787, accuracy: 90.6412%, tar: 0.1624 \n",
            "l0: 0.100774, l1: 0.102418, l2: 0.115692, l3: 0.147509, l4: 0.222298, l5: 0.358831, l6: 0.577679\n",
            "\n",
            "[epoch: 105/100000, batch: 240/1000, ite: 13030] train loss: 2.4784, accuracy: 90.6734%, tar: 0.1623 \n",
            "l0: 0.104709, l1: 0.107143, l2: 0.125440, l3: 0.169394, l4: 0.283890, l5: 0.372542, l6: 0.581014\n",
            "\n",
            "[epoch: 105/100000, batch: 248/1000, ite: 13031] train loss: 2.4783, accuracy: 91.0121%, tar: 0.1623 \n",
            "l0: 0.084760, l1: 0.087383, l2: 0.096504, l3: 0.122347, l4: 0.197559, l5: 0.280357, l6: 0.482263\n",
            "\n",
            "[epoch: 105/100000, batch: 256/1000, ite: 13032] train loss: 2.4777, accuracy: 91.7167%, tar: 0.1622 \n",
            "l0: 0.125716, l1: 0.125115, l2: 0.133442, l3: 0.155622, l4: 0.205260, l5: 0.304637, l6: 0.482469\n",
            "\n",
            "[epoch: 105/100000, batch: 264/1000, ite: 13033] train loss: 2.4772, accuracy: 92.4614%, tar: 0.1622 \n",
            "l0: 0.074451, l1: 0.076456, l2: 0.085100, l3: 0.098425, l4: 0.138654, l5: 0.207273, l6: 0.360631\n",
            "\n",
            "[epoch: 105/100000, batch: 272/1000, ite: 13034] train loss: 2.4762, accuracy: 93.3019%, tar: 0.1621 \n",
            "l0: 0.086542, l1: 0.087581, l2: 0.099446, l3: 0.128245, l4: 0.206153, l5: 0.300755, l6: 0.488908\n",
            "\n",
            "[epoch: 105/100000, batch: 280/1000, ite: 13035] train loss: 2.4756, accuracy: 92.5529%, tar: 0.1620 \n",
            "l0: 0.080713, l1: 0.082703, l2: 0.101646, l3: 0.152393, l4: 0.259301, l5: 0.395073, l6: 0.594742\n",
            "\n",
            "[epoch: 105/100000, batch: 288/1000, ite: 13036] train loss: 2.4754, accuracy: 90.5053%, tar: 0.1619 \n",
            "l0: 0.062684, l1: 0.065348, l2: 0.077339, l3: 0.104549, l4: 0.153204, l5: 0.271751, l6: 0.460324\n",
            "\n",
            "[epoch: 105/100000, batch: 296/1000, ite: 13037] train loss: 2.4746, accuracy: 92.8245%, tar: 0.1618 \n",
            "l0: 0.121397, l1: 0.125235, l2: 0.135620, l3: 0.149368, l4: 0.187595, l5: 0.260513, l6: 0.409820\n",
            "\n",
            "[epoch: 105/100000, batch: 304/1000, ite: 13038] train loss: 2.4740, accuracy: 92.2074%, tar: 0.1618 \n",
            "l0: 0.105804, l1: 0.107909, l2: 0.121153, l3: 0.148169, l4: 0.224848, l5: 0.389920, l6: 0.612482\n",
            "\n",
            "[epoch: 105/100000, batch: 312/1000, ite: 13039] train loss: 2.4738, accuracy: 89.7087%, tar: 0.1617 \n",
            "l0: 0.128972, l1: 0.131886, l2: 0.141016, l3: 0.168969, l4: 0.236346, l5: 0.354085, l6: 0.547612\n",
            "\n",
            "[epoch: 105/100000, batch: 320/1000, ite: 13040] train loss: 2.4736, accuracy: 90.2400%, tar: 0.1617 \n",
            "l0: 0.106168, l1: 0.106581, l2: 0.113967, l3: 0.137282, l4: 0.185740, l5: 0.271676, l6: 0.454459\n",
            "\n",
            "[epoch: 105/100000, batch: 328/1000, ite: 13041] train loss: 2.4730, accuracy: 91.6063%, tar: 0.1617 \n",
            "l0: 0.125474, l1: 0.126591, l2: 0.140294, l3: 0.170614, l4: 0.248746, l5: 0.373922, l6: 0.603696\n",
            "\n",
            "[epoch: 105/100000, batch: 336/1000, ite: 13042] train loss: 2.4730, accuracy: 90.2636%, tar: 0.1616 \n",
            "l0: 0.094056, l1: 0.094676, l2: 0.106414, l3: 0.130331, l4: 0.182636, l5: 0.294054, l6: 0.480352\n",
            "\n",
            "[epoch: 105/100000, batch: 344/1000, ite: 13043] train loss: 2.4724, accuracy: 92.3244%, tar: 0.1616 \n",
            "l0: 0.104359, l1: 0.105654, l2: 0.118077, l3: 0.141093, l4: 0.185941, l5: 0.262410, l6: 0.460604\n",
            "\n",
            "[epoch: 105/100000, batch: 352/1000, ite: 13044] train loss: 2.4718, accuracy: 91.3013%, tar: 0.1615 \n",
            "l0: 0.119550, l1: 0.120990, l2: 0.130583, l3: 0.161397, l4: 0.232759, l5: 0.345767, l6: 0.552840\n",
            "\n",
            "[epoch: 105/100000, batch: 360/1000, ite: 13045] train loss: 2.4715, accuracy: 91.9050%, tar: 0.1615 \n",
            "l0: 0.069524, l1: 0.069641, l2: 0.079149, l3: 0.100687, l4: 0.148872, l5: 0.241226, l6: 0.401633\n",
            "\n",
            "[epoch: 105/100000, batch: 368/1000, ite: 13046] train loss: 2.4706, accuracy: 93.3990%, tar: 0.1614 \n",
            "l0: 0.103859, l1: 0.105826, l2: 0.117563, l3: 0.140862, l4: 0.187048, l5: 0.248435, l6: 0.388180\n",
            "\n",
            "[epoch: 105/100000, batch: 376/1000, ite: 13047] train loss: 2.4699, accuracy: 92.2043%, tar: 0.1613 \n",
            "l0: 0.155987, l1: 0.157873, l2: 0.168751, l3: 0.196328, l4: 0.269368, l5: 0.372486, l6: 0.573207\n",
            "\n",
            "[epoch: 105/100000, batch: 384/1000, ite: 13048] train loss: 2.4698, accuracy: 89.8221%, tar: 0.1613 \n",
            "l0: 0.088897, l1: 0.089653, l2: 0.098434, l3: 0.119647, l4: 0.183435, l5: 0.273073, l6: 0.498498\n",
            "\n",
            "[epoch: 105/100000, batch: 392/1000, ite: 13049] train loss: 2.4692, accuracy: 91.6555%, tar: 0.1612 \n",
            "l0: 0.088070, l1: 0.091008, l2: 0.103733, l3: 0.133856, l4: 0.206956, l5: 0.303949, l6: 0.539913\n",
            "\n",
            "[epoch: 105/100000, batch: 400/1000, ite: 13050] train loss: 2.4688, accuracy: 91.4873%, tar: 0.1612 \n",
            "l0: 0.103167, l1: 0.104797, l2: 0.114056, l3: 0.133748, l4: 0.188591, l5: 0.281275, l6: 0.463792\n",
            "\n",
            "[epoch: 105/100000, batch: 408/1000, ite: 13051] train loss: 2.4682, accuracy: 92.5519%, tar: 0.1611 \n",
            "l0: 0.082497, l1: 0.085547, l2: 0.098776, l3: 0.139054, l4: 0.187658, l5: 0.255969, l6: 0.379408\n",
            "\n",
            "[epoch: 105/100000, batch: 416/1000, ite: 13052] train loss: 2.4674, accuracy: 92.9436%, tar: 0.1610 \n",
            "l0: 0.075704, l1: 0.077128, l2: 0.089297, l3: 0.112780, l4: 0.161336, l5: 0.250379, l6: 0.393457\n",
            "\n",
            "[epoch: 105/100000, batch: 424/1000, ite: 13053] train loss: 2.4665, accuracy: 92.4062%, tar: 0.1610 \n",
            "l0: 0.082793, l1: 0.085119, l2: 0.095752, l3: 0.114044, l4: 0.138555, l5: 0.195260, l6: 0.354125\n",
            "\n",
            "[epoch: 105/100000, batch: 432/1000, ite: 13054] train loss: 2.4655, accuracy: 94.5058%, tar: 0.1609 \n",
            "l0: 0.061711, l1: 0.062540, l2: 0.072432, l3: 0.100048, l4: 0.144688, l5: 0.250377, l6: 0.385321\n",
            "\n",
            "[epoch: 105/100000, batch: 440/1000, ite: 13055] train loss: 2.4646, accuracy: 94.2197%, tar: 0.1608 \n",
            "l0: 0.164857, l1: 0.172406, l2: 0.182249, l3: 0.215154, l4: 0.271342, l5: 0.357509, l6: 0.567017\n",
            "\n",
            "[epoch: 105/100000, batch: 448/1000, ite: 13056] train loss: 2.4646, accuracy: 90.0233%, tar: 0.1608 \n",
            "l0: 0.101315, l1: 0.101710, l2: 0.114259, l3: 0.139364, l4: 0.202752, l5: 0.350282, l6: 0.562381\n",
            "\n",
            "[epoch: 105/100000, batch: 456/1000, ite: 13057] train loss: 2.4643, accuracy: 90.5017%, tar: 0.1607 \n",
            "l0: 0.063305, l1: 0.064328, l2: 0.073774, l3: 0.088985, l4: 0.122532, l5: 0.185752, l6: 0.356723\n",
            "\n",
            "[epoch: 105/100000, batch: 464/1000, ite: 13058] train loss: 2.4632, accuracy: 94.3015%, tar: 0.1606 \n",
            "l0: 0.102455, l1: 0.105049, l2: 0.117787, l3: 0.146493, l4: 0.210506, l5: 0.344526, l6: 0.642583\n",
            "\n",
            "[epoch: 105/100000, batch: 472/1000, ite: 13059] train loss: 2.4631, accuracy: 88.8326%, tar: 0.1606 \n",
            "l0: 0.206966, l1: 0.208863, l2: 0.221317, l3: 0.244672, l4: 0.310127, l5: 0.388943, l6: 0.650118\n",
            "\n",
            "[epoch: 105/100000, batch: 480/1000, ite: 13060] train loss: 2.4634, accuracy: 89.5266%, tar: 0.1606 \n",
            "l0: 0.090362, l1: 0.090839, l2: 0.100272, l3: 0.118578, l4: 0.162189, l5: 0.254074, l6: 0.444519\n",
            "\n",
            "[epoch: 105/100000, batch: 488/1000, ite: 13061] train loss: 2.4627, accuracy: 92.0246%, tar: 0.1606 \n",
            "l0: 0.112936, l1: 0.115220, l2: 0.131947, l3: 0.167487, l4: 0.254907, l5: 0.376174, l6: 0.582975\n",
            "\n",
            "[epoch: 105/100000, batch: 496/1000, ite: 13062] train loss: 2.4626, accuracy: 90.4088%, tar: 0.1605 \n",
            "l0: 0.090287, l1: 0.093281, l2: 0.102424, l3: 0.122778, l4: 0.170979, l5: 0.235959, l6: 0.412848\n",
            "\n",
            "[epoch: 105/100000, batch: 504/1000, ite: 13063] train loss: 2.4618, accuracy: 92.5628%, tar: 0.1605 \n",
            "l0: 0.106988, l1: 0.108987, l2: 0.116719, l3: 0.143100, l4: 0.195688, l5: 0.287634, l6: 0.470280\n",
            "\n",
            "[epoch: 105/100000, batch: 512/1000, ite: 13064] train loss: 2.4613, accuracy: 91.5451%, tar: 0.1604 \n",
            "l0: 0.113834, l1: 0.116654, l2: 0.132575, l3: 0.167779, l4: 0.243212, l5: 0.360295, l6: 0.628807\n",
            "\n",
            "[epoch: 105/100000, batch: 520/1000, ite: 13065] train loss: 2.4612, accuracy: 89.0059%, tar: 0.1604 \n",
            "l0: 0.109563, l1: 0.114332, l2: 0.127044, l3: 0.161632, l4: 0.233335, l5: 0.356368, l6: 0.568128\n",
            "\n",
            "[epoch: 105/100000, batch: 528/1000, ite: 13066] train loss: 2.4610, accuracy: 91.3617%, tar: 0.1603 \n",
            "l0: 0.150760, l1: 0.153253, l2: 0.164419, l3: 0.186939, l4: 0.243269, l5: 0.340309, l6: 0.617140\n",
            "\n",
            "[epoch: 105/100000, batch: 536/1000, ite: 13067] train loss: 2.4610, accuracy: 89.9096%, tar: 0.1603 \n",
            "l0: 0.109403, l1: 0.111447, l2: 0.122702, l3: 0.147296, l4: 0.199737, l5: 0.304473, l6: 0.566209\n",
            "\n",
            "[epoch: 105/100000, batch: 544/1000, ite: 13068] train loss: 2.4607, accuracy: 90.8998%, tar: 0.1603 \n",
            "l0: 0.107493, l1: 0.110055, l2: 0.117768, l3: 0.139712, l4: 0.191703, l5: 0.273490, l6: 0.478582\n",
            "\n",
            "[epoch: 105/100000, batch: 552/1000, ite: 13069] train loss: 2.4602, accuracy: 92.6398%, tar: 0.1602 \n",
            "l0: 0.112736, l1: 0.112364, l2: 0.121979, l3: 0.136233, l4: 0.182396, l5: 0.264724, l6: 0.429464\n",
            "\n",
            "[epoch: 105/100000, batch: 560/1000, ite: 13070] train loss: 2.4595, accuracy: 92.4805%, tar: 0.1602 \n",
            "l0: 0.131704, l1: 0.133261, l2: 0.147349, l3: 0.180542, l4: 0.246452, l5: 0.314875, l6: 0.460665\n",
            "\n",
            "[epoch: 105/100000, batch: 568/1000, ite: 13071] train loss: 2.4592, accuracy: 92.2206%, tar: 0.1601 \n",
            "l0: 0.108754, l1: 0.111101, l2: 0.123573, l3: 0.148725, l4: 0.211711, l5: 0.330012, l6: 0.497040\n",
            "\n",
            "[epoch: 105/100000, batch: 576/1000, ite: 13072] train loss: 2.4588, accuracy: 91.3156%, tar: 0.1601 \n",
            "l0: 0.108321, l1: 0.111604, l2: 0.122071, l3: 0.148336, l4: 0.206967, l5: 0.288209, l6: 0.454457\n",
            "\n",
            "[epoch: 105/100000, batch: 584/1000, ite: 13073] train loss: 2.4583, accuracy: 91.6600%, tar: 0.1600 \n",
            "l0: 0.141818, l1: 0.144840, l2: 0.159799, l3: 0.191072, l4: 0.260183, l5: 0.373363, l6: 0.575583\n",
            "\n",
            "[epoch: 105/100000, batch: 592/1000, ite: 13074] train loss: 2.4582, accuracy: 89.5178%, tar: 0.1600 \n",
            "l0: 0.147397, l1: 0.153333, l2: 0.163597, l3: 0.188434, l4: 0.239531, l5: 0.378110, l6: 0.598644\n",
            "\n",
            "[epoch: 105/100000, batch: 600/1000, ite: 13075] train loss: 2.4582, accuracy: 89.4894%, tar: 0.1600 \n",
            "l0: 0.118033, l1: 0.123127, l2: 0.133121, l3: 0.161597, l4: 0.242741, l5: 0.354776, l6: 0.546829\n",
            "\n",
            "[epoch: 105/100000, batch: 608/1000, ite: 13076] train loss: 2.4580, accuracy: 92.0191%, tar: 0.1600 \n",
            "l0: 0.094414, l1: 0.091431, l2: 0.106213, l3: 0.144673, l4: 0.219838, l5: 0.364811, l6: 0.625674\n",
            "\n",
            "[epoch: 105/100000, batch: 616/1000, ite: 13077] train loss: 2.4579, accuracy: 90.5767%, tar: 0.1599 \n",
            "l0: 0.099916, l1: 0.103841, l2: 0.116585, l3: 0.152494, l4: 0.234895, l5: 0.343029, l6: 0.567463\n",
            "\n",
            "[epoch: 105/100000, batch: 624/1000, ite: 13078] train loss: 2.4576, accuracy: 90.9090%, tar: 0.1599 \n",
            "l0: 0.151453, l1: 0.148627, l2: 0.158467, l3: 0.188893, l4: 0.255982, l5: 0.403289, l6: 0.673363\n",
            "\n",
            "[epoch: 105/100000, batch: 632/1000, ite: 13079] train loss: 2.4578, accuracy: 89.4060%, tar: 0.1599 \n",
            "l0: 0.130386, l1: 0.130872, l2: 0.143805, l3: 0.173442, l4: 0.243347, l5: 0.362488, l6: 0.545826\n",
            "\n",
            "[epoch: 105/100000, batch: 640/1000, ite: 13080] train loss: 2.4577, accuracy: 90.9447%, tar: 0.1598 \n",
            "l0: 0.109609, l1: 0.108644, l2: 0.122907, l3: 0.159544, l4: 0.248285, l5: 0.399566, l6: 0.570049\n",
            "\n",
            "[epoch: 105/100000, batch: 648/1000, ite: 13081] train loss: 2.4575, accuracy: 91.5854%, tar: 0.1598 \n",
            "l0: 0.101719, l1: 0.103021, l2: 0.117701, l3: 0.146006, l4: 0.207438, l5: 0.323408, l6: 0.534635\n",
            "\n",
            "[epoch: 105/100000, batch: 656/1000, ite: 13082] train loss: 2.4572, accuracy: 91.8230%, tar: 0.1597 \n",
            "l0: 0.118927, l1: 0.120564, l2: 0.132524, l3: 0.158636, l4: 0.198165, l5: 0.287455, l6: 0.452062\n",
            "\n",
            "[epoch: 105/100000, batch: 664/1000, ite: 13083] train loss: 2.4567, accuracy: 90.8858%, tar: 0.1597 \n",
            "l0: 0.097665, l1: 0.099848, l2: 0.111480, l3: 0.142587, l4: 0.195931, l5: 0.322864, l6: 0.521288\n",
            "\n",
            "[epoch: 105/100000, batch: 672/1000, ite: 13084] train loss: 2.4562, accuracy: 90.7329%, tar: 0.1596 \n",
            "l0: 0.116738, l1: 0.118584, l2: 0.131663, l3: 0.165840, l4: 0.235318, l5: 0.393828, l6: 0.703902\n",
            "\n",
            "[epoch: 105/100000, batch: 680/1000, ite: 13085] train loss: 2.4564, accuracy: 89.5855%, tar: 0.1596 \n",
            "l0: 0.149423, l1: 0.155294, l2: 0.165363, l3: 0.193325, l4: 0.258727, l5: 0.402532, l6: 0.608298\n",
            "\n",
            "[epoch: 105/100000, batch: 688/1000, ite: 13086] train loss: 2.4564, accuracy: 89.5549%, tar: 0.1596 \n",
            "l0: 0.143499, l1: 0.145585, l2: 0.157141, l3: 0.190514, l4: 0.274000, l5: 0.407452, l6: 0.754002\n",
            "\n",
            "[epoch: 105/100000, batch: 696/1000, ite: 13087] train loss: 2.4568, accuracy: 86.3618%, tar: 0.1596 \n",
            "l0: 0.120594, l1: 0.123450, l2: 0.136269, l3: 0.172345, l4: 0.238961, l5: 0.383214, l6: 0.586687\n",
            "\n",
            "[epoch: 105/100000, batch: 704/1000, ite: 13088] train loss: 2.4567, accuracy: 91.0959%, tar: 0.1595 \n",
            "l0: 0.106258, l1: 0.107575, l2: 0.116920, l3: 0.140614, l4: 0.196382, l5: 0.330457, l6: 0.555982\n",
            "\n",
            "[epoch: 105/100000, batch: 712/1000, ite: 13089] train loss: 2.4564, accuracy: 91.1606%, tar: 0.1595 \n",
            "l0: 0.105747, l1: 0.107332, l2: 0.120777, l3: 0.143397, l4: 0.195697, l5: 0.291782, l6: 0.497348\n",
            "\n",
            "[epoch: 105/100000, batch: 720/1000, ite: 13090] train loss: 2.4559, accuracy: 91.2758%, tar: 0.1594 \n",
            "l0: 0.140929, l1: 0.144176, l2: 0.155111, l3: 0.183465, l4: 0.255936, l5: 0.390961, l6: 0.676444\n",
            "\n",
            "[epoch: 105/100000, batch: 728/1000, ite: 13091] train loss: 2.4561, accuracy: 87.6353%, tar: 0.1594 \n",
            "l0: 0.125731, l1: 0.125550, l2: 0.132158, l3: 0.157465, l4: 0.217355, l5: 0.297895, l6: 0.446136\n",
            "\n",
            "[epoch: 105/100000, batch: 736/1000, ite: 13092] train loss: 2.4557, accuracy: 91.7689%, tar: 0.1594 \n",
            "l0: 0.104605, l1: 0.105999, l2: 0.119454, l3: 0.138376, l4: 0.177741, l5: 0.283330, l6: 0.485654\n",
            "\n",
            "[epoch: 105/100000, batch: 744/1000, ite: 13093] train loss: 2.4552, accuracy: 90.8676%, tar: 0.1593 \n",
            "l0: 0.110456, l1: 0.110017, l2: 0.116690, l3: 0.141186, l4: 0.200440, l5: 0.299044, l6: 0.491833\n",
            "\n",
            "[epoch: 105/100000, batch: 752/1000, ite: 13094] train loss: 2.4547, accuracy: 93.1123%, tar: 0.1593 \n",
            "l0: 0.113023, l1: 0.114643, l2: 0.125541, l3: 0.157800, l4: 0.235973, l5: 0.392817, l6: 0.549298\n",
            "\n",
            "[epoch: 105/100000, batch: 760/1000, ite: 13095] train loss: 2.4545, accuracy: 91.1606%, tar: 0.1592 \n",
            "l0: 0.073035, l1: 0.076927, l2: 0.087424, l3: 0.108823, l4: 0.148784, l5: 0.246617, l6: 0.422948\n",
            "\n",
            "[epoch: 105/100000, batch: 768/1000, ite: 13096] train loss: 2.4537, accuracy: 93.0381%, tar: 0.1592 \n",
            "l0: 0.086289, l1: 0.086887, l2: 0.095106, l3: 0.128544, l4: 0.192857, l5: 0.320631, l6: 0.524192\n",
            "\n",
            "[epoch: 105/100000, batch: 776/1000, ite: 13097] train loss: 2.4532, accuracy: 91.5194%, tar: 0.1591 \n",
            "l0: 0.097252, l1: 0.100064, l2: 0.108504, l3: 0.126467, l4: 0.173354, l5: 0.293827, l6: 0.486077\n",
            "\n",
            "[epoch: 105/100000, batch: 784/1000, ite: 13098] train loss: 2.4527, accuracy: 91.3144%, tar: 0.1590 \n",
            "l0: 0.097573, l1: 0.098632, l2: 0.112887, l3: 0.140333, l4: 0.226005, l5: 0.374435, l6: 0.621400\n",
            "\n",
            "[epoch: 105/100000, batch: 792/1000, ite: 13099] train loss: 2.4526, accuracy: 91.3960%, tar: 0.1590 \n",
            "l0: 0.072880, l1: 0.074164, l2: 0.089666, l3: 0.111453, l4: 0.147809, l5: 0.218058, l6: 0.377678\n",
            "\n",
            "[epoch: 105/100000, batch: 800/1000, ite: 13100] train loss: 2.4517, accuracy: 93.7674%, tar: 0.1589 \n",
            "l0: 0.094952, l1: 0.096747, l2: 0.111657, l3: 0.147272, l4: 0.196471, l5: 0.289693, l6: 0.491375\n",
            "\n",
            "[epoch: 105/100000, batch: 808/1000, ite: 13101] train loss: 2.4512, accuracy: 92.4358%, tar: 0.1589 \n",
            "l0: 0.092154, l1: 0.094083, l2: 0.110825, l3: 0.145017, l4: 0.215539, l5: 0.352616, l6: 0.571341\n",
            "\n",
            "[epoch: 105/100000, batch: 816/1000, ite: 13102] train loss: 2.4509, accuracy: 90.8641%, tar: 0.1588 \n",
            "l0: 0.102042, l1: 0.104266, l2: 0.116759, l3: 0.147916, l4: 0.223958, l5: 0.374913, l6: 0.612340\n",
            "\n",
            "[epoch: 105/100000, batch: 824/1000, ite: 13103] train loss: 2.4508, accuracy: 89.8366%, tar: 0.1587 \n",
            "l0: 0.081949, l1: 0.083748, l2: 0.094597, l3: 0.116278, l4: 0.175440, l5: 0.276456, l6: 0.451425\n",
            "\n",
            "[epoch: 105/100000, batch: 832/1000, ite: 13104] train loss: 2.4502, accuracy: 91.9829%, tar: 0.1587 \n",
            "l0: 0.088137, l1: 0.089810, l2: 0.099793, l3: 0.124557, l4: 0.183498, l5: 0.316310, l6: 0.551804\n",
            "\n",
            "[epoch: 105/100000, batch: 840/1000, ite: 13105] train loss: 2.4497, accuracy: 90.0600%, tar: 0.1586 \n",
            "l0: 0.089391, l1: 0.092054, l2: 0.102163, l3: 0.123690, l4: 0.169205, l5: 0.246350, l6: 0.407879\n",
            "\n",
            "[epoch: 105/100000, batch: 848/1000, ite: 13106] train loss: 2.4490, accuracy: 93.6803%, tar: 0.1585 \n",
            "l0: 0.089059, l1: 0.089846, l2: 0.100193, l3: 0.124390, l4: 0.185678, l5: 0.287484, l6: 0.500884\n",
            "\n",
            "[epoch: 105/100000, batch: 856/1000, ite: 13107] train loss: 2.4485, accuracy: 93.5515%, tar: 0.1585 \n",
            "l0: 0.091401, l1: 0.091930, l2: 0.100722, l3: 0.120677, l4: 0.172448, l5: 0.282135, l6: 0.512738\n",
            "\n",
            "[epoch: 105/100000, batch: 864/1000, ite: 13108] train loss: 2.4480, accuracy: 91.8030%, tar: 0.1584 \n",
            "l0: 0.090773, l1: 0.092783, l2: 0.100257, l3: 0.119179, l4: 0.167791, l5: 0.252496, l6: 0.404032\n",
            "\n",
            "[epoch: 105/100000, batch: 872/1000, ite: 13109] train loss: 2.4473, accuracy: 92.3606%, tar: 0.1584 \n",
            "l0: 0.097142, l1: 0.099381, l2: 0.114465, l3: 0.154524, l4: 0.246989, l5: 0.409933, l6: 0.635418\n",
            "\n",
            "[epoch: 105/100000, batch: 880/1000, ite: 13110] train loss: 2.4472, accuracy: 89.9928%, tar: 0.1583 \n",
            "l0: 0.102443, l1: 0.104075, l2: 0.111286, l3: 0.119474, l4: 0.150349, l5: 0.217564, l6: 0.347478\n",
            "\n",
            "[epoch: 105/100000, batch: 888/1000, ite: 13111] train loss: 2.4464, accuracy: 92.7551%, tar: 0.1583 \n",
            "l0: 0.077706, l1: 0.079454, l2: 0.088909, l3: 0.114919, l4: 0.166339, l5: 0.268650, l6: 0.482400\n",
            "\n",
            "[epoch: 105/100000, batch: 896/1000, ite: 13112] train loss: 2.4458, accuracy: 91.5467%, tar: 0.1582 \n",
            "l0: 0.097156, l1: 0.100820, l2: 0.110320, l3: 0.135942, l4: 0.185767, l5: 0.277257, l6: 0.432201\n",
            "\n",
            "[epoch: 105/100000, batch: 904/1000, ite: 13113] train loss: 2.4452, accuracy: 91.0305%, tar: 0.1581 \n",
            "l0: 0.063851, l1: 0.064906, l2: 0.077708, l3: 0.100643, l4: 0.145060, l5: 0.243392, l6: 0.471284\n",
            "\n",
            "[epoch: 105/100000, batch: 912/1000, ite: 13114] train loss: 2.4444, accuracy: 92.8887%, tar: 0.1580 \n",
            "l0: 0.077299, l1: 0.078871, l2: 0.090705, l3: 0.116506, l4: 0.178893, l5: 0.285906, l6: 0.487042\n",
            "\n",
            "[epoch: 105/100000, batch: 920/1000, ite: 13115] train loss: 2.4438, accuracy: 92.6200%, tar: 0.1580 \n",
            "l0: 0.120308, l1: 0.121591, l2: 0.131514, l3: 0.154753, l4: 0.225718, l5: 0.340795, l6: 0.572521\n",
            "\n",
            "[epoch: 105/100000, batch: 928/1000, ite: 13116] train loss: 2.4437, accuracy: 90.6789%, tar: 0.1579 \n",
            "l0: 0.097922, l1: 0.099626, l2: 0.111629, l3: 0.136077, l4: 0.191380, l5: 0.286594, l6: 0.511583\n",
            "\n",
            "[epoch: 105/100000, batch: 936/1000, ite: 13117] train loss: 2.4432, accuracy: 92.1921%, tar: 0.1579 \n",
            "l0: 0.086743, l1: 0.088187, l2: 0.099918, l3: 0.124898, l4: 0.173000, l5: 0.267275, l6: 0.415431\n",
            "\n",
            "[epoch: 105/100000, batch: 944/1000, ite: 13118] train loss: 2.4425, accuracy: 93.3711%, tar: 0.1578 \n",
            "l0: 0.091136, l1: 0.092951, l2: 0.106446, l3: 0.139441, l4: 0.214785, l5: 0.360804, l6: 0.563035\n",
            "\n",
            "[epoch: 105/100000, batch: 952/1000, ite: 13119] train loss: 2.4422, accuracy: 92.1556%, tar: 0.1578 \n",
            "l0: 0.099459, l1: 0.101547, l2: 0.111775, l3: 0.140235, l4: 0.210296, l5: 0.320218, l6: 0.518077\n",
            "\n",
            "[epoch: 105/100000, batch: 960/1000, ite: 13120] train loss: 2.4419, accuracy: 90.9908%, tar: 0.1577 \n",
            "l0: 0.096362, l1: 0.097699, l2: 0.108370, l3: 0.139534, l4: 0.211276, l5: 0.330544, l6: 0.521342\n",
            "\n",
            "[epoch: 105/100000, batch: 968/1000, ite: 13121] train loss: 2.4415, accuracy: 91.3525%, tar: 0.1577 \n",
            "l0: 0.105425, l1: 0.107295, l2: 0.118734, l3: 0.146773, l4: 0.214045, l5: 0.360006, l6: 0.694078\n",
            "\n",
            "[epoch: 105/100000, batch: 976/1000, ite: 13122] train loss: 2.4415, accuracy: 88.8576%, tar: 0.1576 \n",
            "l0: 0.100735, l1: 0.101431, l2: 0.113858, l3: 0.141957, l4: 0.221877, l5: 0.361442, l6: 0.622485\n",
            "\n",
            "[epoch: 105/100000, batch: 984/1000, ite: 13123] train loss: 2.4413, accuracy: 89.6040%, tar: 0.1576 \n",
            "l0: 0.095419, l1: 0.096920, l2: 0.109866, l3: 0.140409, l4: 0.212175, l5: 0.328535, l6: 0.537570\n",
            "\n",
            "[epoch: 105/100000, batch: 992/1000, ite: 13124] train loss: 2.4410, accuracy: 90.2672%, tar: 0.1575 \n",
            "l0: 0.089238, l1: 0.091485, l2: 0.102762, l3: 0.129857, l4: 0.188010, l5: 0.304430, l6: 0.552766\n",
            "\n",
            "[epoch: 105/100000, batch: 1000/1000, ite: 13125] train loss: 2.4406, accuracy: 90.0126%, tar: 0.1574 \n",
            "l0: 0.122609, l1: 0.125688, l2: 0.135664, l3: 0.159315, l4: 0.201778, l5: 0.308272, l6: 0.419122\n",
            "\n",
            "[epoch: 106/100000, batch: 8/1000, ite: 13126] train loss: 2.4401, accuracy: 93.4508%, tar: 0.1574 \n",
            "l0: 0.080487, l1: 0.082543, l2: 0.092388, l3: 0.113178, l4: 0.147377, l5: 0.229199, l6: 0.426303\n",
            "\n",
            "[epoch: 106/100000, batch: 16/1000, ite: 13127] train loss: 2.4394, accuracy: 91.9752%, tar: 0.1573 \n",
            "l0: 0.193713, l1: 0.193445, l2: 0.207357, l3: 0.229545, l4: 0.270532, l5: 0.383240, l6: 0.601925\n",
            "\n",
            "[epoch: 106/100000, batch: 24/1000, ite: 13128] train loss: 2.4396, accuracy: 89.4154%, tar: 0.1574 \n",
            "l0: 0.089944, l1: 0.091050, l2: 0.104209, l3: 0.129352, l4: 0.176497, l5: 0.283213, l6: 0.487817\n",
            "\n",
            "[epoch: 106/100000, batch: 32/1000, ite: 13129] train loss: 2.4391, accuracy: 92.3300%, tar: 0.1573 \n",
            "l0: 0.096092, l1: 0.097983, l2: 0.108397, l3: 0.137502, l4: 0.216735, l5: 0.358086, l6: 0.657952\n",
            "\n",
            "[epoch: 106/100000, batch: 40/1000, ite: 13130] train loss: 2.4390, accuracy: 89.6548%, tar: 0.1573 \n",
            "l0: 0.126440, l1: 0.129088, l2: 0.142484, l3: 0.168720, l4: 0.210279, l5: 0.281103, l6: 0.405971\n",
            "\n",
            "[epoch: 106/100000, batch: 48/1000, ite: 13131] train loss: 2.4385, accuracy: 91.5848%, tar: 0.1572 \n",
            "l0: 0.101528, l1: 0.102436, l2: 0.111967, l3: 0.146083, l4: 0.210792, l5: 0.296674, l6: 0.496742\n",
            "\n",
            "[epoch: 106/100000, batch: 56/1000, ite: 13132] train loss: 2.4381, accuracy: 91.4267%, tar: 0.1572 \n",
            "l0: 0.098242, l1: 0.099595, l2: 0.110558, l3: 0.132745, l4: 0.197156, l5: 0.327742, l6: 0.615791\n",
            "\n",
            "[epoch: 106/100000, batch: 64/1000, ite: 13133] train loss: 2.4379, accuracy: 90.1946%, tar: 0.1571 \n",
            "l0: 0.092045, l1: 0.093716, l2: 0.102991, l3: 0.127641, l4: 0.193192, l5: 0.286442, l6: 0.483404\n",
            "\n",
            "[epoch: 106/100000, batch: 72/1000, ite: 13134] train loss: 2.4374, accuracy: 91.8077%, tar: 0.1571 \n",
            "l0: 0.072595, l1: 0.076448, l2: 0.085306, l3: 0.103448, l4: 0.144479, l5: 0.221923, l6: 0.381358\n",
            "\n",
            "[epoch: 106/100000, batch: 80/1000, ite: 13135] train loss: 2.4365, accuracy: 93.2707%, tar: 0.1570 \n",
            "l0: 0.071998, l1: 0.073485, l2: 0.086722, l3: 0.113359, l4: 0.171388, l5: 0.265841, l6: 0.456749\n",
            "\n",
            "[epoch: 106/100000, batch: 88/1000, ite: 13136] train loss: 2.4359, accuracy: 93.6329%, tar: 0.1569 \n",
            "l0: 0.069596, l1: 0.074228, l2: 0.083326, l3: 0.097697, l4: 0.148155, l5: 0.236878, l6: 0.400379\n",
            "\n",
            "[epoch: 106/100000, batch: 96/1000, ite: 13137] train loss: 2.4350, accuracy: 92.9035%, tar: 0.1568 \n",
            "l0: 0.117987, l1: 0.121231, l2: 0.132270, l3: 0.155175, l4: 0.218792, l5: 0.362273, l6: 0.582952\n",
            "\n",
            "[epoch: 106/100000, batch: 104/1000, ite: 13138] train loss: 2.4349, accuracy: 90.1817%, tar: 0.1568 \n",
            "l0: 0.071508, l1: 0.073425, l2: 0.082966, l3: 0.108391, l4: 0.147821, l5: 0.215590, l6: 0.378712\n",
            "\n",
            "[epoch: 106/100000, batch: 112/1000, ite: 13139] train loss: 2.4340, accuracy: 92.8279%, tar: 0.1567 \n",
            "l0: 0.087325, l1: 0.090485, l2: 0.101883, l3: 0.134665, l4: 0.183369, l5: 0.282832, l6: 0.492828\n",
            "\n",
            "[epoch: 106/100000, batch: 120/1000, ite: 13140] train loss: 2.4335, accuracy: 92.7508%, tar: 0.1567 \n",
            "l0: 0.070497, l1: 0.072233, l2: 0.082300, l3: 0.106173, l4: 0.162530, l5: 0.268809, l6: 0.457478\n",
            "\n",
            "[epoch: 106/100000, batch: 128/1000, ite: 13141] train loss: 2.4329, accuracy: 92.6556%, tar: 0.1566 \n",
            "l0: 0.061536, l1: 0.062147, l2: 0.072664, l3: 0.090803, l4: 0.142285, l5: 0.250377, l6: 0.429629\n",
            "\n",
            "[epoch: 106/100000, batch: 136/1000, ite: 13142] train loss: 2.4321, accuracy: 93.4460%, tar: 0.1565 \n",
            "l0: 0.095113, l1: 0.095177, l2: 0.108095, l3: 0.132404, l4: 0.190056, l5: 0.289528, l6: 0.438637\n",
            "\n",
            "[epoch: 106/100000, batch: 144/1000, ite: 13143] train loss: 2.4315, accuracy: 91.4577%, tar: 0.1565 \n",
            "l0: 0.113103, l1: 0.115110, l2: 0.128316, l3: 0.156598, l4: 0.217684, l5: 0.316555, l6: 0.548347\n",
            "\n",
            "[epoch: 106/100000, batch: 152/1000, ite: 13144] train loss: 2.4313, accuracy: 90.5002%, tar: 0.1564 \n",
            "l0: 0.104550, l1: 0.106259, l2: 0.118654, l3: 0.147558, l4: 0.226458, l5: 0.362560, l6: 0.563566\n",
            "\n",
            "[epoch: 106/100000, batch: 160/1000, ite: 13145] train loss: 2.4311, accuracy: 89.4130%, tar: 0.1564 \n",
            "l0: 0.110321, l1: 0.109947, l2: 0.117669, l3: 0.139946, l4: 0.179379, l5: 0.260839, l6: 0.462784\n",
            "\n",
            "[epoch: 106/100000, batch: 168/1000, ite: 13146] train loss: 2.4306, accuracy: 91.8411%, tar: 0.1563 \n",
            "l0: 0.124283, l1: 0.126429, l2: 0.136825, l3: 0.157647, l4: 0.210719, l5: 0.322848, l6: 0.475010\n",
            "\n",
            "[epoch: 106/100000, batch: 176/1000, ite: 13147] train loss: 2.4302, accuracy: 92.3702%, tar: 0.1563 \n",
            "l0: 0.092809, l1: 0.094040, l2: 0.103776, l3: 0.134635, l4: 0.191867, l5: 0.271956, l6: 0.448265\n",
            "\n",
            "[epoch: 106/100000, batch: 184/1000, ite: 13148] train loss: 2.4297, accuracy: 92.0040%, tar: 0.1563 \n",
            "l0: 0.111801, l1: 0.112726, l2: 0.125872, l3: 0.159157, l4: 0.230979, l5: 0.392718, l6: 0.649227\n",
            "\n",
            "[epoch: 106/100000, batch: 192/1000, ite: 13149] train loss: 2.4297, accuracy: 90.7039%, tar: 0.1562 \n",
            "l0: 0.083857, l1: 0.086507, l2: 0.102578, l3: 0.135699, l4: 0.212338, l5: 0.361404, l6: 0.623139\n",
            "\n",
            "[epoch: 106/100000, batch: 200/1000, ite: 13150] train loss: 2.4295, accuracy: 92.6153%, tar: 0.1562 \n",
            "l0: 0.090764, l1: 0.094267, l2: 0.105049, l3: 0.126048, l4: 0.168145, l5: 0.290173, l6: 0.542180\n",
            "\n",
            "[epoch: 106/100000, batch: 208/1000, ite: 13151] train loss: 2.4291, accuracy: 90.6999%, tar: 0.1561 \n",
            "l0: 0.072986, l1: 0.073451, l2: 0.084398, l3: 0.105554, l4: 0.145100, l5: 0.243557, l6: 0.432743\n",
            "\n",
            "[epoch: 106/100000, batch: 216/1000, ite: 13152] train loss: 2.4283, accuracy: 92.4174%, tar: 0.1560 \n",
            "l0: 0.105307, l1: 0.105935, l2: 0.120399, l3: 0.154108, l4: 0.234832, l5: 0.385083, l6: 0.647625\n",
            "\n",
            "[epoch: 106/100000, batch: 224/1000, ite: 13153] train loss: 2.4283, accuracy: 90.9073%, tar: 0.1560 \n",
            "l0: 0.094254, l1: 0.095940, l2: 0.111927, l3: 0.146047, l4: 0.222820, l5: 0.346189, l6: 0.535248\n",
            "\n",
            "[epoch: 106/100000, batch: 232/1000, ite: 13154] train loss: 2.4280, accuracy: 90.2875%, tar: 0.1559 \n",
            "l0: 0.102647, l1: 0.103881, l2: 0.120583, l3: 0.148797, l4: 0.235314, l5: 0.396940, l6: 0.662028\n",
            "\n",
            "[epoch: 106/100000, batch: 240/1000, ite: 13155] train loss: 2.4280, accuracy: 89.2364%, tar: 0.1559 \n",
            "l0: 0.123165, l1: 0.123242, l2: 0.133475, l3: 0.155846, l4: 0.211659, l5: 0.334416, l6: 0.565377\n",
            "\n",
            "[epoch: 106/100000, batch: 248/1000, ite: 13156] train loss: 2.4278, accuracy: 90.2259%, tar: 0.1559 \n",
            "l0: 0.069424, l1: 0.070921, l2: 0.082131, l3: 0.108532, l4: 0.164848, l5: 0.251157, l6: 0.393341\n",
            "\n",
            "[epoch: 106/100000, batch: 256/1000, ite: 13157] train loss: 2.4271, accuracy: 92.5098%, tar: 0.1558 \n",
            "l0: 0.059235, l1: 0.060076, l2: 0.067852, l3: 0.081274, l4: 0.126150, l5: 0.198358, l6: 0.349161\n",
            "\n",
            "[epoch: 106/100000, batch: 264/1000, ite: 13158] train loss: 2.4261, accuracy: 93.9121%, tar: 0.1557 \n",
            "l0: 0.088611, l1: 0.090639, l2: 0.099890, l3: 0.118884, l4: 0.181542, l5: 0.269031, l6: 0.392308\n",
            "\n",
            "[epoch: 106/100000, batch: 272/1000, ite: 13159] train loss: 2.4254, accuracy: 92.1478%, tar: 0.1556 \n",
            "l0: 0.089138, l1: 0.091688, l2: 0.105914, l3: 0.136319, l4: 0.204681, l5: 0.290980, l6: 0.469353\n",
            "\n",
            "[epoch: 106/100000, batch: 280/1000, ite: 13160] train loss: 2.4249, accuracy: 91.9851%, tar: 0.1556 \n",
            "l0: 0.082330, l1: 0.083586, l2: 0.094906, l3: 0.114839, l4: 0.155770, l5: 0.230813, l6: 0.360381\n",
            "\n",
            "[epoch: 106/100000, batch: 288/1000, ite: 13161] train loss: 2.4241, accuracy: 92.9245%, tar: 0.1555 \n",
            "l0: 0.080321, l1: 0.082622, l2: 0.095886, l3: 0.119442, l4: 0.169789, l5: 0.237113, l6: 0.421210\n",
            "\n",
            "[epoch: 106/100000, batch: 296/1000, ite: 13162] train loss: 2.4234, accuracy: 92.3239%, tar: 0.1555 \n",
            "l0: 0.091894, l1: 0.094833, l2: 0.106300, l3: 0.125321, l4: 0.168998, l5: 0.234209, l6: 0.388209\n",
            "\n",
            "[epoch: 106/100000, batch: 304/1000, ite: 13163] train loss: 2.4227, accuracy: 92.2595%, tar: 0.1554 \n",
            "l0: 0.082104, l1: 0.083316, l2: 0.100549, l3: 0.130800, l4: 0.196351, l5: 0.313079, l6: 0.549868\n",
            "\n",
            "[epoch: 106/100000, batch: 312/1000, ite: 13164] train loss: 2.4224, accuracy: 92.5936%, tar: 0.1553 \n",
            "l0: 0.109231, l1: 0.111346, l2: 0.127027, l3: 0.162051, l4: 0.229221, l5: 0.350743, l6: 0.530766\n",
            "\n",
            "[epoch: 106/100000, batch: 320/1000, ite: 13165] train loss: 2.4221, accuracy: 90.8768%, tar: 0.1553 \n",
            "l0: 0.079211, l1: 0.081551, l2: 0.095632, l3: 0.120774, l4: 0.192814, l5: 0.317417, l6: 0.500200\n",
            "\n",
            "[epoch: 106/100000, batch: 328/1000, ite: 13166] train loss: 2.4217, accuracy: 90.7463%, tar: 0.1552 \n",
            "l0: 0.083019, l1: 0.084893, l2: 0.097940, l3: 0.131925, l4: 0.203077, l5: 0.302638, l6: 0.461377\n",
            "\n",
            "[epoch: 106/100000, batch: 336/1000, ite: 13167] train loss: 2.4212, accuracy: 92.1502%, tar: 0.1552 \n",
            "l0: 0.074135, l1: 0.075403, l2: 0.084825, l3: 0.106819, l4: 0.145554, l5: 0.215917, l6: 0.380339\n",
            "\n",
            "[epoch: 106/100000, batch: 344/1000, ite: 13168] train loss: 2.4204, accuracy: 92.7325%, tar: 0.1551 \n",
            "l0: 0.108349, l1: 0.109931, l2: 0.118053, l3: 0.142701, l4: 0.184841, l5: 0.280114, l6: 0.440603\n",
            "\n",
            "[epoch: 106/100000, batch: 352/1000, ite: 13169] train loss: 2.4199, accuracy: 92.2013%, tar: 0.1551 \n",
            "l0: 0.089711, l1: 0.091288, l2: 0.103911, l3: 0.145704, l4: 0.209447, l5: 0.320549, l6: 0.567286\n",
            "\n",
            "[epoch: 106/100000, batch: 360/1000, ite: 13170] train loss: 2.4196, accuracy: 91.1924%, tar: 0.1550 \n",
            "l0: 0.059908, l1: 0.060851, l2: 0.067643, l3: 0.085912, l4: 0.133278, l5: 0.205639, l6: 0.401962\n",
            "\n",
            "[epoch: 106/100000, batch: 368/1000, ite: 13171] train loss: 2.4187, accuracy: 92.9376%, tar: 0.1549 \n",
            "l0: 0.067950, l1: 0.069224, l2: 0.079716, l3: 0.097408, l4: 0.135950, l5: 0.247198, l6: 0.419248\n",
            "\n",
            "[epoch: 106/100000, batch: 376/1000, ite: 13172] train loss: 2.4180, accuracy: 92.8867%, tar: 0.1548 \n",
            "l0: 0.088626, l1: 0.090280, l2: 0.100583, l3: 0.128852, l4: 0.207360, l5: 0.292780, l6: 0.451641\n",
            "\n",
            "[epoch: 106/100000, batch: 384/1000, ite: 13173] train loss: 2.4175, accuracy: 92.8405%, tar: 0.1548 \n",
            "l0: 0.138540, l1: 0.140524, l2: 0.150331, l3: 0.175642, l4: 0.252599, l5: 0.370616, l6: 0.565996\n",
            "\n",
            "[epoch: 106/100000, batch: 392/1000, ite: 13174] train loss: 2.4174, accuracy: 90.8237%, tar: 0.1548 \n",
            "l0: 0.119158, l1: 0.122312, l2: 0.137570, l3: 0.172209, l4: 0.244815, l5: 0.376098, l6: 0.592555\n",
            "\n",
            "[epoch: 106/100000, batch: 400/1000, ite: 13175] train loss: 2.4174, accuracy: 90.3185%, tar: 0.1547 \n",
            "l0: 0.062867, l1: 0.064101, l2: 0.074321, l3: 0.101496, l4: 0.151891, l5: 0.251645, l6: 0.469437\n",
            "\n",
            "[epoch: 106/100000, batch: 408/1000, ite: 13176] train loss: 2.4167, accuracy: 91.9867%, tar: 0.1547 \n",
            "l0: 0.100841, l1: 0.103123, l2: 0.112435, l3: 0.139195, l4: 0.192533, l5: 0.298026, l6: 0.522851\n",
            "\n",
            "[epoch: 106/100000, batch: 416/1000, ite: 13177] train loss: 2.4164, accuracy: 90.6021%, tar: 0.1546 \n",
            "l0: 0.085891, l1: 0.087384, l2: 0.099480, l3: 0.132785, l4: 0.188949, l5: 0.284387, l6: 0.488500\n",
            "\n",
            "[epoch: 106/100000, batch: 424/1000, ite: 13178] train loss: 2.4159, accuracy: 92.9759%, tar: 0.1546 \n",
            "l0: 0.071032, l1: 0.072371, l2: 0.082440, l3: 0.093203, l4: 0.120384, l5: 0.183915, l6: 0.342599\n",
            "\n",
            "[epoch: 106/100000, batch: 432/1000, ite: 13179] train loss: 2.4150, accuracy: 93.5699%, tar: 0.1545 \n",
            "l0: 0.070037, l1: 0.070640, l2: 0.081254, l3: 0.100628, l4: 0.140304, l5: 0.222874, l6: 0.387598\n",
            "\n",
            "[epoch: 106/100000, batch: 440/1000, ite: 13180] train loss: 2.4142, accuracy: 93.0630%, tar: 0.1544 \n",
            "l0: 0.098157, l1: 0.100203, l2: 0.112911, l3: 0.141767, l4: 0.199510, l5: 0.288647, l6: 0.496462\n",
            "\n",
            "[epoch: 106/100000, batch: 448/1000, ite: 13181] train loss: 2.4138, accuracy: 92.0054%, tar: 0.1544 \n",
            "l0: 0.080064, l1: 0.080617, l2: 0.090074, l3: 0.109155, l4: 0.155374, l5: 0.240773, l6: 0.430930\n",
            "\n",
            "[epoch: 106/100000, batch: 456/1000, ite: 13182] train loss: 2.4131, accuracy: 91.5437%, tar: 0.1543 \n",
            "l0: 0.101271, l1: 0.103210, l2: 0.119675, l3: 0.157042, l4: 0.251629, l5: 0.372982, l6: 0.644781\n",
            "\n",
            "[epoch: 106/100000, batch: 464/1000, ite: 13183] train loss: 2.4131, accuracy: 90.2769%, tar: 0.1543 \n",
            "l0: 0.071498, l1: 0.072552, l2: 0.084237, l3: 0.104241, l4: 0.150769, l5: 0.215935, l6: 0.374746\n",
            "\n",
            "[epoch: 106/100000, batch: 472/1000, ite: 13184] train loss: 2.4123, accuracy: 93.3716%, tar: 0.1542 \n",
            "l0: 0.104721, l1: 0.105950, l2: 0.117751, l3: 0.141777, l4: 0.208303, l5: 0.314165, l6: 0.525282\n",
            "\n",
            "[epoch: 106/100000, batch: 480/1000, ite: 13185] train loss: 2.4120, accuracy: 90.7591%, tar: 0.1542 \n",
            "l0: 0.062578, l1: 0.063770, l2: 0.075984, l3: 0.095593, l4: 0.143190, l5: 0.245620, l6: 0.419055\n",
            "\n",
            "[epoch: 106/100000, batch: 488/1000, ite: 13186] train loss: 2.4112, accuracy: 92.7923%, tar: 0.1541 \n",
            "l0: 0.090285, l1: 0.093621, l2: 0.102249, l3: 0.127373, l4: 0.173068, l5: 0.253269, l6: 0.375319\n",
            "\n",
            "[epoch: 106/100000, batch: 496/1000, ite: 13187] train loss: 2.4105, accuracy: 93.4199%, tar: 0.1540 \n",
            "l0: 0.089668, l1: 0.090208, l2: 0.104605, l3: 0.132401, l4: 0.191968, l5: 0.294101, l6: 0.518078\n",
            "\n",
            "[epoch: 106/100000, batch: 504/1000, ite: 13188] train loss: 2.4101, accuracy: 90.8261%, tar: 0.1540 \n",
            "l0: 0.099324, l1: 0.102849, l2: 0.111956, l3: 0.133154, l4: 0.168587, l5: 0.227391, l6: 0.410766\n",
            "\n",
            "[epoch: 106/100000, batch: 512/1000, ite: 13189] train loss: 2.4095, accuracy: 92.6172%, tar: 0.1539 \n",
            "l0: 0.078882, l1: 0.081779, l2: 0.094027, l3: 0.121305, l4: 0.176916, l5: 0.256831, l6: 0.410992\n",
            "\n",
            "[epoch: 106/100000, batch: 520/1000, ite: 13190] train loss: 2.4089, accuracy: 93.9753%, tar: 0.1539 \n",
            "l0: 0.096662, l1: 0.096993, l2: 0.108811, l3: 0.139842, l4: 0.198222, l5: 0.327414, l6: 0.513784\n",
            "\n",
            "[epoch: 106/100000, batch: 528/1000, ite: 13191] train loss: 2.4086, accuracy: 91.7973%, tar: 0.1538 \n",
            "l0: 0.094296, l1: 0.096909, l2: 0.109876, l3: 0.148583, l4: 0.245599, l5: 0.392104, l6: 0.623784\n",
            "\n",
            "[epoch: 106/100000, batch: 536/1000, ite: 13192] train loss: 2.4085, accuracy: 91.0109%, tar: 0.1538 \n",
            "l0: 0.115854, l1: 0.117652, l2: 0.127910, l3: 0.150402, l4: 0.207479, l5: 0.273508, l6: 0.493887\n",
            "\n",
            "[epoch: 106/100000, batch: 544/1000, ite: 13193] train loss: 2.4081, accuracy: 91.3425%, tar: 0.1537 \n",
            "l0: 0.087679, l1: 0.089845, l2: 0.098627, l3: 0.121368, l4: 0.175358, l5: 0.258373, l6: 0.483101\n",
            "\n",
            "[epoch: 106/100000, batch: 552/1000, ite: 13194] train loss: 2.4076, accuracy: 92.1240%, tar: 0.1537 \n",
            "l0: 0.104763, l1: 0.105687, l2: 0.120298, l3: 0.150013, l4: 0.232319, l5: 0.382474, l6: 0.695742\n",
            "\n",
            "[epoch: 106/100000, batch: 560/1000, ite: 13195] train loss: 2.4077, accuracy: 88.8239%, tar: 0.1536 \n",
            "l0: 0.097004, l1: 0.100099, l2: 0.107994, l3: 0.130518, l4: 0.184876, l5: 0.257399, l6: 0.478487\n",
            "\n",
            "[epoch: 106/100000, batch: 568/1000, ite: 13196] train loss: 2.4072, accuracy: 92.6591%, tar: 0.1536 \n",
            "l0: 0.080336, l1: 0.082095, l2: 0.093768, l3: 0.121572, l4: 0.182898, l5: 0.297364, l6: 0.482178\n",
            "\n",
            "[epoch: 106/100000, batch: 576/1000, ite: 13197] train loss: 2.4067, accuracy: 92.1722%, tar: 0.1535 \n",
            "l0: 0.082330, l1: 0.083627, l2: 0.091896, l3: 0.120725, l4: 0.186703, l5: 0.343522, l6: 0.613126\n",
            "\n",
            "[epoch: 106/100000, batch: 584/1000, ite: 13198] train loss: 2.4065, accuracy: 91.9321%, tar: 0.1535 \n",
            "l0: 0.100877, l1: 0.102158, l2: 0.112684, l3: 0.127697, l4: 0.167600, l5: 0.262850, l6: 0.474912\n",
            "\n",
            "[epoch: 106/100000, batch: 592/1000, ite: 13199] train loss: 2.4060, accuracy: 92.3053%, tar: 0.1534 \n",
            "l0: 0.067612, l1: 0.068547, l2: 0.080489, l3: 0.103478, l4: 0.159909, l5: 0.287652, l6: 0.478070\n",
            "\n",
            "[epoch: 106/100000, batch: 600/1000, ite: 13200] train loss: 2.4055, accuracy: 91.5773%, tar: 0.1534 \n",
            "l0: 0.080436, l1: 0.082242, l2: 0.092829, l3: 0.115636, l4: 0.164858, l5: 0.274797, l6: 0.473204\n",
            "\n",
            "[epoch: 106/100000, batch: 608/1000, ite: 13201] train loss: 2.4049, accuracy: 91.8399%, tar: 0.1533 \n",
            "l0: 0.084940, l1: 0.085495, l2: 0.096150, l3: 0.127257, l4: 0.183126, l5: 0.279302, l6: 0.463840\n",
            "\n",
            "[epoch: 106/100000, batch: 616/1000, ite: 13202] train loss: 2.4044, accuracy: 92.6647%, tar: 0.1532 \n",
            "l0: 0.108012, l1: 0.110669, l2: 0.125452, l3: 0.166456, l4: 0.246333, l5: 0.368427, l6: 0.573606\n",
            "\n",
            "[epoch: 106/100000, batch: 624/1000, ite: 13203] train loss: 2.4043, accuracy: 91.0453%, tar: 0.1532 \n",
            "l0: 0.100702, l1: 0.103184, l2: 0.119839, l3: 0.166236, l4: 0.250015, l5: 0.468312, l6: 0.708068\n",
            "\n",
            "[epoch: 106/100000, batch: 632/1000, ite: 13204] train loss: 2.4045, accuracy: 90.7743%, tar: 0.1532 \n",
            "l0: 0.102481, l1: 0.105086, l2: 0.115727, l3: 0.139146, l4: 0.189727, l5: 0.272482, l6: 0.422130\n",
            "\n",
            "[epoch: 106/100000, batch: 640/1000, ite: 13205] train loss: 2.4040, accuracy: 91.7059%, tar: 0.1531 \n",
            "l0: 0.140807, l1: 0.142626, l2: 0.156074, l3: 0.184270, l4: 0.264404, l5: 0.385374, l6: 0.684666\n",
            "\n",
            "[epoch: 106/100000, batch: 648/1000, ite: 13206] train loss: 2.4042, accuracy: 90.1415%, tar: 0.1531 \n",
            "l0: 0.091449, l1: 0.093048, l2: 0.103685, l3: 0.135186, l4: 0.193121, l5: 0.347267, l6: 0.535769\n",
            "\n",
            "[epoch: 106/100000, batch: 656/1000, ite: 13207] train loss: 2.4039, accuracy: 90.8011%, tar: 0.1531 \n",
            "l0: 0.114657, l1: 0.117911, l2: 0.133300, l3: 0.159895, l4: 0.227659, l5: 0.349974, l6: 0.644710\n",
            "\n",
            "[epoch: 106/100000, batch: 664/1000, ite: 13208] train loss: 2.4039, accuracy: 88.9854%, tar: 0.1530 \n",
            "l0: 0.084300, l1: 0.087189, l2: 0.096938, l3: 0.117749, l4: 0.153981, l5: 0.249862, l6: 0.442835\n",
            "\n",
            "[epoch: 106/100000, batch: 672/1000, ite: 13209] train loss: 2.4033, accuracy: 92.0234%, tar: 0.1530 \n",
            "l0: 0.108603, l1: 0.111044, l2: 0.122573, l3: 0.158689, l4: 0.220196, l5: 0.313278, l6: 0.488524\n",
            "\n",
            "[epoch: 106/100000, batch: 680/1000, ite: 13210] train loss: 2.4029, accuracy: 91.3688%, tar: 0.1529 \n",
            "l0: 0.092809, l1: 0.094110, l2: 0.104267, l3: 0.127112, l4: 0.168052, l5: 0.244290, l6: 0.443798\n",
            "\n",
            "[epoch: 106/100000, batch: 688/1000, ite: 13211] train loss: 2.4024, accuracy: 92.1010%, tar: 0.1529 \n",
            "l0: 0.117854, l1: 0.119657, l2: 0.132159, l3: 0.155101, l4: 0.214918, l5: 0.339599, l6: 0.609220\n",
            "\n",
            "[epoch: 106/100000, batch: 696/1000, ite: 13212] train loss: 2.4023, accuracy: 89.1117%, tar: 0.1528 \n",
            "l0: 0.068587, l1: 0.070585, l2: 0.082193, l3: 0.102154, l4: 0.144771, l5: 0.246861, l6: 0.428129\n",
            "\n",
            "[epoch: 106/100000, batch: 704/1000, ite: 13213] train loss: 2.4016, accuracy: 93.5751%, tar: 0.1528 \n",
            "l0: 0.077294, l1: 0.079254, l2: 0.089673, l3: 0.114206, l4: 0.193204, l5: 0.301966, l6: 0.525521\n",
            "\n",
            "[epoch: 106/100000, batch: 712/1000, ite: 13214] train loss: 2.4012, accuracy: 91.5813%, tar: 0.1527 \n",
            "l0: 0.100741, l1: 0.102333, l2: 0.114372, l3: 0.130571, l4: 0.183558, l5: 0.272182, l6: 0.455090\n",
            "\n",
            "[epoch: 106/100000, batch: 720/1000, ite: 13215] train loss: 2.4007, accuracy: 91.1203%, tar: 0.1527 \n",
            "l0: 0.095197, l1: 0.096603, l2: 0.111210, l3: 0.133709, l4: 0.197752, l5: 0.314166, l6: 0.561322\n",
            "\n",
            "[epoch: 106/100000, batch: 728/1000, ite: 13216] train loss: 2.4005, accuracy: 90.2967%, tar: 0.1526 \n",
            "l0: 0.101071, l1: 0.101184, l2: 0.113450, l3: 0.139790, l4: 0.202810, l5: 0.313413, l6: 0.562115\n",
            "\n",
            "[epoch: 106/100000, batch: 736/1000, ite: 13217] train loss: 2.4003, accuracy: 90.7969%, tar: 0.1526 \n",
            "l0: 0.080932, l1: 0.083135, l2: 0.095287, l3: 0.122402, l4: 0.179689, l5: 0.265234, l6: 0.483064\n",
            "\n",
            "[epoch: 106/100000, batch: 744/1000, ite: 13218] train loss: 2.3998, accuracy: 93.0284%, tar: 0.1525 \n",
            "l0: 0.127237, l1: 0.129300, l2: 0.148926, l3: 0.190416, l4: 0.296239, l5: 0.463969, l6: 0.767099\n",
            "\n",
            "[epoch: 106/100000, batch: 752/1000, ite: 13219] train loss: 2.4002, accuracy: 88.1901%, tar: 0.1525 \n",
            "l0: 0.082372, l1: 0.084450, l2: 0.094256, l3: 0.125664, l4: 0.178127, l5: 0.279081, l6: 0.473118\n",
            "\n",
            "[epoch: 106/100000, batch: 760/1000, ite: 13220] train loss: 2.3997, accuracy: 93.2851%, tar: 0.1524 \n",
            "l0: 0.089214, l1: 0.089047, l2: 0.099083, l3: 0.121223, l4: 0.174840, l5: 0.256184, l6: 0.462211\n",
            "\n",
            "[epoch: 106/100000, batch: 768/1000, ite: 13221] train loss: 2.3991, accuracy: 92.6734%, tar: 0.1524 \n",
            "l0: 0.073604, l1: 0.075344, l2: 0.088555, l3: 0.114031, l4: 0.165560, l5: 0.250469, l6: 0.456977\n",
            "\n",
            "[epoch: 106/100000, batch: 776/1000, ite: 13222] train loss: 2.3985, accuracy: 93.2370%, tar: 0.1523 \n",
            "l0: 0.078629, l1: 0.079142, l2: 0.091520, l3: 0.115304, l4: 0.176481, l5: 0.284979, l6: 0.471657\n",
            "\n",
            "[epoch: 106/100000, batch: 784/1000, ite: 13223] train loss: 2.3980, accuracy: 92.3819%, tar: 0.1523 \n",
            "l0: 0.081518, l1: 0.083404, l2: 0.090430, l3: 0.107313, l4: 0.141821, l5: 0.206941, l6: 0.361016\n",
            "\n",
            "[epoch: 106/100000, batch: 792/1000, ite: 13224] train loss: 2.3972, accuracy: 93.6214%, tar: 0.1522 \n",
            "l0: 0.101054, l1: 0.103710, l2: 0.117667, l3: 0.150061, l4: 0.220733, l5: 0.354477, l6: 0.516600\n",
            "\n",
            "[epoch: 106/100000, batch: 800/1000, ite: 13225] train loss: 2.3970, accuracy: 90.4781%, tar: 0.1522 \n",
            "l0: 0.105996, l1: 0.104650, l2: 0.112988, l3: 0.132878, l4: 0.169481, l5: 0.267721, l6: 0.479614\n",
            "\n",
            "[epoch: 106/100000, batch: 808/1000, ite: 13226] train loss: 2.3966, accuracy: 92.5055%, tar: 0.1521 \n",
            "l0: 0.090278, l1: 0.090727, l2: 0.099993, l3: 0.124494, l4: 0.174128, l5: 0.268340, l6: 0.478652\n",
            "\n",
            "[epoch: 106/100000, batch: 816/1000, ite: 13227] train loss: 2.3961, accuracy: 92.1335%, tar: 0.1521 \n",
            "l0: 0.092779, l1: 0.095168, l2: 0.109073, l3: 0.135388, l4: 0.210661, l5: 0.326208, l6: 0.510062\n",
            "\n",
            "[epoch: 106/100000, batch: 824/1000, ite: 13228] train loss: 2.3958, accuracy: 92.5063%, tar: 0.1520 \n",
            "l0: 0.092539, l1: 0.094890, l2: 0.101913, l3: 0.120951, l4: 0.163002, l5: 0.234034, l6: 0.377836\n",
            "\n",
            "[epoch: 106/100000, batch: 832/1000, ite: 13229] train loss: 2.3951, accuracy: 93.6778%, tar: 0.1520 \n",
            "l0: 0.100282, l1: 0.102881, l2: 0.114614, l3: 0.137119, l4: 0.198157, l5: 0.315512, l6: 0.488908\n",
            "\n",
            "[epoch: 106/100000, batch: 840/1000, ite: 13230] train loss: 2.3947, accuracy: 92.5223%, tar: 0.1519 \n",
            "l0: 0.122710, l1: 0.123135, l2: 0.135503, l3: 0.163196, l4: 0.235143, l5: 0.345997, l6: 0.615667\n",
            "\n",
            "[epoch: 106/100000, batch: 848/1000, ite: 13231] train loss: 2.3947, accuracy: 89.6383%, tar: 0.1519 \n",
            "l0: 0.102930, l1: 0.103547, l2: 0.115795, l3: 0.143064, l4: 0.195123, l5: 0.277361, l6: 0.508459\n",
            "\n",
            "[epoch: 106/100000, batch: 856/1000, ite: 13232] train loss: 2.3943, accuracy: 91.7938%, tar: 0.1519 \n",
            "l0: 0.111373, l1: 0.114184, l2: 0.125259, l3: 0.149331, l4: 0.207056, l5: 0.332870, l6: 0.575899\n",
            "\n",
            "[epoch: 106/100000, batch: 864/1000, ite: 13233] train loss: 2.3942, accuracy: 91.4935%, tar: 0.1518 \n",
            "l0: 0.123007, l1: 0.122955, l2: 0.131573, l3: 0.158738, l4: 0.201595, l5: 0.297372, l6: 0.482244\n",
            "\n",
            "[epoch: 106/100000, batch: 872/1000, ite: 13234] train loss: 2.3938, accuracy: 91.5655%, tar: 0.1518 \n",
            "l0: 0.067122, l1: 0.068656, l2: 0.076080, l3: 0.100752, l4: 0.149077, l5: 0.250036, l6: 0.455057\n",
            "\n",
            "[epoch: 106/100000, batch: 880/1000, ite: 13235] train loss: 2.3932, accuracy: 92.6051%, tar: 0.1518 \n",
            "l0: 0.076750, l1: 0.077708, l2: 0.085636, l3: 0.109870, l4: 0.153085, l5: 0.237673, l6: 0.469502\n",
            "\n",
            "[epoch: 106/100000, batch: 888/1000, ite: 13236] train loss: 2.3926, accuracy: 92.7218%, tar: 0.1517 \n",
            "l0: 0.094833, l1: 0.098710, l2: 0.109913, l3: 0.140318, l4: 0.215992, l5: 0.339782, l6: 0.490798\n",
            "\n",
            "[epoch: 106/100000, batch: 896/1000, ite: 13237] train loss: 2.3923, accuracy: 91.8062%, tar: 0.1516 \n",
            "l0: 0.115250, l1: 0.116891, l2: 0.127810, l3: 0.148161, l4: 0.199135, l5: 0.314118, l6: 0.499525\n",
            "\n",
            "[epoch: 106/100000, batch: 904/1000, ite: 13238] train loss: 2.3920, accuracy: 91.1240%, tar: 0.1516 \n",
            "l0: 0.109219, l1: 0.111648, l2: 0.129106, l3: 0.169965, l4: 0.262223, l5: 0.457474, l6: 0.749199\n",
            "\n",
            "[epoch: 106/100000, batch: 912/1000, ite: 13239] train loss: 2.3923, accuracy: 89.4918%, tar: 0.1516 \n",
            "l0: 0.096628, l1: 0.098260, l2: 0.111225, l3: 0.135947, l4: 0.187685, l5: 0.279428, l6: 0.450875\n",
            "\n",
            "[epoch: 106/100000, batch: 920/1000, ite: 13240] train loss: 2.3918, accuracy: 92.1885%, tar: 0.1515 \n",
            "l0: 0.148362, l1: 0.149569, l2: 0.164671, l3: 0.208051, l4: 0.346270, l5: 0.546254, l6: 0.843841\n",
            "\n",
            "[epoch: 106/100000, batch: 928/1000, ite: 13241] train loss: 2.3925, accuracy: 87.1669%, tar: 0.1515 \n",
            "l0: 0.100212, l1: 0.100555, l2: 0.111245, l3: 0.142285, l4: 0.213061, l5: 0.341299, l6: 0.568324\n",
            "\n",
            "[epoch: 106/100000, batch: 936/1000, ite: 13242] train loss: 2.3923, accuracy: 90.5454%, tar: 0.1515 \n",
            "l0: 0.065174, l1: 0.065908, l2: 0.073846, l3: 0.094296, l4: 0.127420, l5: 0.192976, l6: 0.352345\n",
            "\n",
            "[epoch: 106/100000, batch: 944/1000, ite: 13243] train loss: 2.3915, accuracy: 94.3959%, tar: 0.1514 \n",
            "l0: 0.089560, l1: 0.093580, l2: 0.101368, l3: 0.126899, l4: 0.176961, l5: 0.277597, l6: 0.487371\n",
            "\n",
            "[epoch: 106/100000, batch: 952/1000, ite: 13244] train loss: 2.3910, accuracy: 92.2032%, tar: 0.1514 \n",
            "l0: 0.080479, l1: 0.083746, l2: 0.094077, l3: 0.115506, l4: 0.160946, l5: 0.226288, l6: 0.420301\n",
            "\n",
            "[epoch: 106/100000, batch: 960/1000, ite: 13245] train loss: 2.3904, accuracy: 92.5463%, tar: 0.1513 \n",
            "l0: 0.083805, l1: 0.086267, l2: 0.094617, l3: 0.115886, l4: 0.153979, l5: 0.264020, l6: 0.501507\n",
            "\n",
            "[epoch: 106/100000, batch: 968/1000, ite: 13246] train loss: 2.3899, accuracy: 92.5363%, tar: 0.1513 \n",
            "l0: 0.099511, l1: 0.102438, l2: 0.113068, l3: 0.138952, l4: 0.210447, l5: 0.294584, l6: 0.449479\n",
            "\n",
            "[epoch: 106/100000, batch: 976/1000, ite: 13247] train loss: 2.3895, accuracy: 91.7714%, tar: 0.1512 \n",
            "l0: 0.086491, l1: 0.087392, l2: 0.098047, l3: 0.123479, l4: 0.187971, l5: 0.319444, l6: 0.527971\n",
            "\n",
            "[epoch: 106/100000, batch: 984/1000, ite: 13248] train loss: 2.3891, accuracy: 90.6903%, tar: 0.1512 \n",
            "l0: 0.130738, l1: 0.132924, l2: 0.148617, l3: 0.178335, l4: 0.236904, l5: 0.377090, l6: 0.598032\n",
            "\n",
            "[epoch: 106/100000, batch: 992/1000, ite: 13249] train loss: 2.3891, accuracy: 91.5992%, tar: 0.1512 \n",
            "l0: 0.114575, l1: 0.114972, l2: 0.127030, l3: 0.152453, l4: 0.206849, l5: 0.313954, l6: 0.514736\n",
            "\n",
            "[epoch: 106/100000, batch: 1000/1000, ite: 13250] train loss: 2.3889, accuracy: 90.9910%, tar: 0.1511 \n",
            "l0: 0.099729, l1: 0.101559, l2: 0.112358, l3: 0.138418, l4: 0.195358, l5: 0.299917, l6: 0.470993\n",
            "\n",
            "[epoch: 107/100000, batch: 8/1000, ite: 13251] train loss: 2.3885, accuracy: 92.4326%, tar: 0.1511 \n",
            "l0: 0.099731, l1: 0.101786, l2: 0.117362, l3: 0.144829, l4: 0.194206, l5: 0.294362, l6: 0.465102\n",
            "\n",
            "[epoch: 107/100000, batch: 16/1000, ite: 13252] train loss: 2.3881, accuracy: 91.2192%, tar: 0.1510 \n",
            "l0: 0.088633, l1: 0.089698, l2: 0.099424, l3: 0.135339, l4: 0.202044, l5: 0.344262, l6: 0.589442\n",
            "\n",
            "[epoch: 107/100000, batch: 24/1000, ite: 13253] train loss: 2.3878, accuracy: 91.9547%, tar: 0.1510 \n",
            "l0: 0.120717, l1: 0.121969, l2: 0.137965, l3: 0.176318, l4: 0.263860, l5: 0.400319, l6: 0.634814\n",
            "\n",
            "[epoch: 107/100000, batch: 32/1000, ite: 13254] train loss: 2.3879, accuracy: 90.4798%, tar: 0.1510 \n",
            "l0: 0.063170, l1: 0.064456, l2: 0.074679, l3: 0.101248, l4: 0.147392, l5: 0.233534, l6: 0.447636\n",
            "\n",
            "[epoch: 107/100000, batch: 40/1000, ite: 13255] train loss: 2.3873, accuracy: 92.4571%, tar: 0.1509 \n",
            "l0: 0.090630, l1: 0.091077, l2: 0.102240, l3: 0.127108, l4: 0.176167, l5: 0.270155, l6: 0.416950\n",
            "\n",
            "[epoch: 107/100000, batch: 48/1000, ite: 13256] train loss: 2.3867, accuracy: 92.1827%, tar: 0.1509 \n",
            "l0: 0.078195, l1: 0.079082, l2: 0.091050, l3: 0.114609, l4: 0.172440, l5: 0.271783, l6: 0.457447\n",
            "\n",
            "[epoch: 107/100000, batch: 56/1000, ite: 13257] train loss: 2.3862, accuracy: 92.5524%, tar: 0.1508 \n",
            "l0: 0.082481, l1: 0.083317, l2: 0.094069, l3: 0.116078, l4: 0.165220, l5: 0.254828, l6: 0.499028\n",
            "\n",
            "[epoch: 107/100000, batch: 64/1000, ite: 13258] train loss: 2.3857, accuracy: 92.2810%, tar: 0.1507 \n",
            "l0: 0.092910, l1: 0.093818, l2: 0.107951, l3: 0.138511, l4: 0.199043, l5: 0.319039, l6: 0.587068\n",
            "\n",
            "[epoch: 107/100000, batch: 72/1000, ite: 13259] train loss: 2.3855, accuracy: 90.0524%, tar: 0.1507 \n",
            "l0: 0.104909, l1: 0.104908, l2: 0.114612, l3: 0.141127, l4: 0.187135, l5: 0.269899, l6: 0.464943\n",
            "\n",
            "[epoch: 107/100000, batch: 80/1000, ite: 13260] train loss: 2.3851, accuracy: 91.3381%, tar: 0.1507 \n",
            "l0: 0.129837, l1: 0.126888, l2: 0.138244, l3: 0.167295, l4: 0.234486, l5: 0.352882, l6: 0.520048\n",
            "\n",
            "[epoch: 107/100000, batch: 88/1000, ite: 13261] train loss: 2.3849, accuracy: 89.8767%, tar: 0.1506 \n",
            "l0: 0.084393, l1: 0.084224, l2: 0.095258, l3: 0.117999, l4: 0.175316, l5: 0.304501, l6: 0.463824\n",
            "\n",
            "[epoch: 107/100000, batch: 96/1000, ite: 13262] train loss: 2.3845, accuracy: 91.7576%, tar: 0.1506 \n",
            "l0: 0.092438, l1: 0.093447, l2: 0.105830, l3: 0.133882, l4: 0.193528, l5: 0.319632, l6: 0.579127\n",
            "\n",
            "[epoch: 107/100000, batch: 104/1000, ite: 13263] train loss: 2.3842, accuracy: 91.1257%, tar: 0.1505 \n",
            "l0: 0.075010, l1: 0.075551, l2: 0.084443, l3: 0.101934, l4: 0.143099, l5: 0.208842, l6: 0.391828\n",
            "\n",
            "[epoch: 107/100000, batch: 112/1000, ite: 13264] train loss: 2.3835, accuracy: 92.8915%, tar: 0.1505 \n",
            "l0: 0.076665, l1: 0.077570, l2: 0.084594, l3: 0.099681, l4: 0.132902, l5: 0.213466, l6: 0.356744\n",
            "\n",
            "[epoch: 107/100000, batch: 120/1000, ite: 13265] train loss: 2.3827, accuracy: 93.3758%, tar: 0.1504 \n",
            "l0: 0.108763, l1: 0.111723, l2: 0.125332, l3: 0.159424, l4: 0.216655, l5: 0.313080, l6: 0.546891\n",
            "\n",
            "[epoch: 107/100000, batch: 128/1000, ite: 13266] train loss: 2.3825, accuracy: 90.7547%, tar: 0.1504 \n",
            "l0: 0.082861, l1: 0.084442, l2: 0.096818, l3: 0.121348, l4: 0.173376, l5: 0.266438, l6: 0.490603\n",
            "\n",
            "[epoch: 107/100000, batch: 136/1000, ite: 13267] train loss: 2.3821, accuracy: 91.3913%, tar: 0.1503 \n",
            "l0: 0.072309, l1: 0.073241, l2: 0.084130, l3: 0.104115, l4: 0.151054, l5: 0.237917, l6: 0.431416\n",
            "\n",
            "[epoch: 107/100000, batch: 144/1000, ite: 13268] train loss: 2.3814, accuracy: 92.9916%, tar: 0.1503 \n",
            "l0: 0.117241, l1: 0.119158, l2: 0.133279, l3: 0.180121, l4: 0.311731, l5: 0.476880, l6: 0.696710\n",
            "\n",
            "[epoch: 107/100000, batch: 152/1000, ite: 13269] train loss: 2.3817, accuracy: 89.0707%, tar: 0.1503 \n",
            "l0: 0.064139, l1: 0.066072, l2: 0.074947, l3: 0.093394, l4: 0.149446, l5: 0.224165, l6: 0.452454\n",
            "\n",
            "[epoch: 107/100000, batch: 160/1000, ite: 13270] train loss: 2.3811, accuracy: 93.4473%, tar: 0.1502 \n",
            "l0: 0.097550, l1: 0.098549, l2: 0.111776, l3: 0.144486, l4: 0.214504, l5: 0.341057, l6: 0.540163\n",
            "\n",
            "[epoch: 107/100000, batch: 168/1000, ite: 13271] train loss: 2.3809, accuracy: 91.4079%, tar: 0.1501 \n",
            "l0: 0.074815, l1: 0.077941, l2: 0.090576, l3: 0.117048, l4: 0.147546, l5: 0.197989, l6: 0.342249\n",
            "\n",
            "[epoch: 107/100000, batch: 176/1000, ite: 13272] train loss: 2.3801, accuracy: 92.8433%, tar: 0.1501 \n",
            "l0: 0.091286, l1: 0.093495, l2: 0.104986, l3: 0.132809, l4: 0.193003, l5: 0.332278, l6: 0.513086\n",
            "\n",
            "[epoch: 107/100000, batch: 184/1000, ite: 13273] train loss: 2.3798, accuracy: 91.9376%, tar: 0.1500 \n",
            "l0: 0.082100, l1: 0.083285, l2: 0.093783, l3: 0.112633, l4: 0.155342, l5: 0.245767, l6: 0.434321\n",
            "\n",
            "[epoch: 107/100000, batch: 192/1000, ite: 13274] train loss: 2.3792, accuracy: 92.3425%, tar: 0.1500 \n",
            "l0: 0.089361, l1: 0.090873, l2: 0.098824, l3: 0.117032, l4: 0.168390, l5: 0.270573, l6: 0.471075\n",
            "\n",
            "[epoch: 107/100000, batch: 200/1000, ite: 13275] train loss: 2.3787, accuracy: 91.7473%, tar: 0.1499 \n",
            "l0: 0.091264, l1: 0.096048, l2: 0.111531, l3: 0.140950, l4: 0.206280, l5: 0.371032, l6: 0.572183\n",
            "\n",
            "[epoch: 107/100000, batch: 208/1000, ite: 13276] train loss: 2.3785, accuracy: 90.9118%, tar: 0.1499 \n",
            "l0: 0.074962, l1: 0.077475, l2: 0.087465, l3: 0.122048, l4: 0.191677, l5: 0.302201, l6: 0.459239\n",
            "\n",
            "[epoch: 107/100000, batch: 216/1000, ite: 13277] train loss: 2.3780, accuracy: 92.1796%, tar: 0.1498 \n",
            "l0: 0.127137, l1: 0.129979, l2: 0.139581, l3: 0.167233, l4: 0.236939, l5: 0.346219, l6: 0.549151\n",
            "\n",
            "[epoch: 107/100000, batch: 224/1000, ite: 13278] train loss: 2.3779, accuracy: 90.0576%, tar: 0.1498 \n",
            "l0: 0.083663, l1: 0.083732, l2: 0.091102, l3: 0.106528, l4: 0.146966, l5: 0.253278, l6: 0.430539\n",
            "\n",
            "[epoch: 107/100000, batch: 232/1000, ite: 13279] train loss: 2.3774, accuracy: 92.6575%, tar: 0.1498 \n",
            "l0: 0.095386, l1: 0.097054, l2: 0.111773, l3: 0.143063, l4: 0.210368, l5: 0.329398, l6: 0.589162\n",
            "\n",
            "[epoch: 107/100000, batch: 240/1000, ite: 13280] train loss: 2.3772, accuracy: 91.2114%, tar: 0.1497 \n",
            "l0: 0.091278, l1: 0.094352, l2: 0.105955, l3: 0.127361, l4: 0.177487, l5: 0.278855, l6: 0.489463\n",
            "\n",
            "[epoch: 107/100000, batch: 248/1000, ite: 13281] train loss: 2.3768, accuracy: 92.7849%, tar: 0.1497 \n",
            "l0: 0.109380, l1: 0.109805, l2: 0.119420, l3: 0.147927, l4: 0.208007, l5: 0.306110, l6: 0.477489\n",
            "\n",
            "[epoch: 107/100000, batch: 256/1000, ite: 13282] train loss: 2.3764, accuracy: 91.5051%, tar: 0.1496 \n",
            "l0: 0.126314, l1: 0.126603, l2: 0.136590, l3: 0.160106, l4: 0.211960, l5: 0.282850, l6: 0.442081\n",
            "\n",
            "[epoch: 107/100000, batch: 264/1000, ite: 13283] train loss: 2.3761, accuracy: 91.3478%, tar: 0.1496 \n",
            "l0: 0.071443, l1: 0.073526, l2: 0.080777, l3: 0.098056, l4: 0.144300, l5: 0.224590, l6: 0.459768\n",
            "\n",
            "[epoch: 107/100000, batch: 272/1000, ite: 13284] train loss: 2.3755, accuracy: 92.6230%, tar: 0.1496 \n",
            "l0: 0.095899, l1: 0.097966, l2: 0.108141, l3: 0.135174, l4: 0.192517, l5: 0.303795, l6: 0.473366\n",
            "\n",
            "[epoch: 107/100000, batch: 280/1000, ite: 13285] train loss: 2.3751, accuracy: 91.9199%, tar: 0.1495 \n",
            "l0: 0.099447, l1: 0.101074, l2: 0.112041, l3: 0.134935, l4: 0.201478, l5: 0.301091, l6: 0.428554\n",
            "\n",
            "[epoch: 107/100000, batch: 288/1000, ite: 13286] train loss: 2.3747, accuracy: 91.6346%, tar: 0.1495 \n",
            "l0: 0.107899, l1: 0.109555, l2: 0.121985, l3: 0.146759, l4: 0.199176, l5: 0.306941, l6: 0.574447\n",
            "\n",
            "[epoch: 107/100000, batch: 296/1000, ite: 13287] train loss: 2.3745, accuracy: 91.2807%, tar: 0.1495 \n",
            "l0: 0.070760, l1: 0.070260, l2: 0.077844, l3: 0.094312, l4: 0.133092, l5: 0.212859, l6: 0.387381\n",
            "\n",
            "[epoch: 107/100000, batch: 304/1000, ite: 13288] train loss: 2.3738, accuracy: 93.1286%, tar: 0.1494 \n",
            "l0: 0.062052, l1: 0.064699, l2: 0.076898, l3: 0.098827, l4: 0.151224, l5: 0.252631, l6: 0.400748\n",
            "\n",
            "[epoch: 107/100000, batch: 312/1000, ite: 13289] train loss: 2.3731, accuracy: 93.3429%, tar: 0.1493 \n",
            "l0: 0.082958, l1: 0.083294, l2: 0.089786, l3: 0.112184, l4: 0.171106, l5: 0.281631, l6: 0.421889\n",
            "\n",
            "[epoch: 107/100000, batch: 320/1000, ite: 13290] train loss: 2.3726, accuracy: 91.7600%, tar: 0.1493 \n",
            "l0: 0.067796, l1: 0.068288, l2: 0.077400, l3: 0.101652, l4: 0.158412, l5: 0.241750, l6: 0.449569\n",
            "\n",
            "[epoch: 107/100000, batch: 328/1000, ite: 13291] train loss: 2.3720, accuracy: 92.4371%, tar: 0.1492 \n",
            "l0: 0.127136, l1: 0.129496, l2: 0.138718, l3: 0.167580, l4: 0.230518, l5: 0.406237, l6: 0.719156\n",
            "\n",
            "[epoch: 107/100000, batch: 336/1000, ite: 13292] train loss: 2.3722, accuracy: 88.3892%, tar: 0.1492 \n",
            "l0: 0.110918, l1: 0.112791, l2: 0.123840, l3: 0.146490, l4: 0.213541, l5: 0.297777, l6: 0.457230\n",
            "\n",
            "[epoch: 107/100000, batch: 344/1000, ite: 13293] train loss: 2.3718, accuracy: 91.3804%, tar: 0.1492 \n",
            "l0: 0.059208, l1: 0.060267, l2: 0.068472, l3: 0.086790, l4: 0.135331, l5: 0.224266, l6: 0.397127\n",
            "\n",
            "[epoch: 107/100000, batch: 352/1000, ite: 13294] train loss: 2.3711, accuracy: 92.5591%, tar: 0.1491 \n",
            "l0: 0.098742, l1: 0.100547, l2: 0.113305, l3: 0.142282, l4: 0.226178, l5: 0.357672, l6: 0.586578\n",
            "\n",
            "[epoch: 107/100000, batch: 360/1000, ite: 13295] train loss: 2.3710, accuracy: 89.7178%, tar: 0.1491 \n",
            "l0: 0.095521, l1: 0.099127, l2: 0.111017, l3: 0.137071, l4: 0.204414, l5: 0.294860, l6: 0.520330\n",
            "\n",
            "[epoch: 107/100000, batch: 368/1000, ite: 13296] train loss: 2.3707, accuracy: 92.1787%, tar: 0.1490 \n",
            "l0: 0.119835, l1: 0.121775, l2: 0.133386, l3: 0.149795, l4: 0.205013, l5: 0.313456, l6: 0.487558\n",
            "\n",
            "[epoch: 107/100000, batch: 376/1000, ite: 13297] train loss: 2.3704, accuracy: 91.3790%, tar: 0.1490 \n",
            "l0: 0.085106, l1: 0.087468, l2: 0.099030, l3: 0.122280, l4: 0.164838, l5: 0.281594, l6: 0.466363\n",
            "\n",
            "[epoch: 107/100000, batch: 384/1000, ite: 13298] train loss: 2.3700, accuracy: 93.4722%, tar: 0.1489 \n",
            "l0: 0.076781, l1: 0.077759, l2: 0.088309, l3: 0.108463, l4: 0.159759, l5: 0.259436, l6: 0.464655\n",
            "\n",
            "[epoch: 107/100000, batch: 392/1000, ite: 13299] train loss: 2.3694, accuracy: 92.4376%, tar: 0.1489 \n",
            "l0: 0.095216, l1: 0.095282, l2: 0.109051, l3: 0.144517, l4: 0.223108, l5: 0.324617, l6: 0.549703\n",
            "\n",
            "[epoch: 107/100000, batch: 400/1000, ite: 13300] train loss: 2.3692, accuracy: 91.3869%, tar: 0.1488 \n",
            "l0: 0.062521, l1: 0.064991, l2: 0.071575, l3: 0.094723, l4: 0.137535, l5: 0.209637, l6: 0.367356\n",
            "\n",
            "[epoch: 107/100000, batch: 408/1000, ite: 13301] train loss: 2.3685, accuracy: 93.5063%, tar: 0.1488 \n",
            "l0: 0.103243, l1: 0.104589, l2: 0.115491, l3: 0.144831, l4: 0.215995, l5: 0.362836, l6: 0.538705\n",
            "\n",
            "[epoch: 107/100000, batch: 416/1000, ite: 13302] train loss: 2.3683, accuracy: 90.3644%, tar: 0.1487 \n",
            "l0: 0.087308, l1: 0.088773, l2: 0.100089, l3: 0.124484, l4: 0.183336, l5: 0.284847, l6: 0.472869\n",
            "\n",
            "[epoch: 107/100000, batch: 424/1000, ite: 13303] train loss: 2.3679, accuracy: 92.8392%, tar: 0.1487 \n",
            "l0: 0.089504, l1: 0.090641, l2: 0.101021, l3: 0.127517, l4: 0.205964, l5: 0.341729, l6: 0.554398\n",
            "\n",
            "[epoch: 107/100000, batch: 432/1000, ite: 13304] train loss: 2.3676, accuracy: 89.7548%, tar: 0.1486 \n",
            "l0: 0.093594, l1: 0.094189, l2: 0.105922, l3: 0.132474, l4: 0.191750, l5: 0.331711, l6: 0.492220\n",
            "\n",
            "[epoch: 107/100000, batch: 440/1000, ite: 13305] train loss: 2.3673, accuracy: 92.1315%, tar: 0.1486 \n",
            "l0: 0.122923, l1: 0.125652, l2: 0.135053, l3: 0.165052, l4: 0.231560, l5: 0.354214, l6: 0.582351\n",
            "\n",
            "[epoch: 107/100000, batch: 448/1000, ite: 13306] train loss: 2.3673, accuracy: 90.2384%, tar: 0.1486 \n",
            "l0: 0.090942, l1: 0.092729, l2: 0.105742, l3: 0.135966, l4: 0.195355, l5: 0.332087, l6: 0.556914\n",
            "\n",
            "[epoch: 107/100000, batch: 456/1000, ite: 13307] train loss: 2.3670, accuracy: 91.8405%, tar: 0.1485 \n",
            "l0: 0.074974, l1: 0.077466, l2: 0.083522, l3: 0.105751, l4: 0.150763, l5: 0.218633, l6: 0.417726\n",
            "\n",
            "[epoch: 107/100000, batch: 464/1000, ite: 13308] train loss: 2.3664, accuracy: 92.9119%, tar: 0.1485 \n",
            "l0: 0.071648, l1: 0.073180, l2: 0.081524, l3: 0.103347, l4: 0.152362, l5: 0.242722, l6: 0.402355\n",
            "\n",
            "[epoch: 107/100000, batch: 472/1000, ite: 13309] train loss: 2.3658, accuracy: 92.8039%, tar: 0.1484 \n",
            "l0: 0.129953, l1: 0.131546, l2: 0.143918, l3: 0.170780, l4: 0.237394, l5: 0.341819, l6: 0.566833\n",
            "\n",
            "[epoch: 107/100000, batch: 480/1000, ite: 13310] train loss: 2.3657, accuracy: 91.2452%, tar: 0.1484 \n",
            "l0: 0.079095, l1: 0.081765, l2: 0.092808, l3: 0.117435, l4: 0.169114, l5: 0.281750, l6: 0.437821\n",
            "\n",
            "[epoch: 107/100000, batch: 488/1000, ite: 13311] train loss: 2.3652, accuracy: 93.1490%, tar: 0.1484 \n",
            "l0: 0.090380, l1: 0.092236, l2: 0.106820, l3: 0.138760, l4: 0.199924, l5: 0.331888, l6: 0.688869\n",
            "\n",
            "[epoch: 107/100000, batch: 496/1000, ite: 13312] train loss: 2.3652, accuracy: 92.2491%, tar: 0.1483 \n",
            "l0: 0.083156, l1: 0.085590, l2: 0.098413, l3: 0.123648, l4: 0.188354, l5: 0.297237, l6: 0.483344\n",
            "\n",
            "[epoch: 107/100000, batch: 504/1000, ite: 13313] train loss: 2.3648, accuracy: 91.6956%, tar: 0.1483 \n",
            "l0: 0.101111, l1: 0.103549, l2: 0.116074, l3: 0.145711, l4: 0.217141, l5: 0.340953, l6: 0.483125\n",
            "\n",
            "[epoch: 107/100000, batch: 512/1000, ite: 13314] train loss: 2.3645, accuracy: 92.0724%, tar: 0.1482 \n",
            "l0: 0.111112, l1: 0.111083, l2: 0.119056, l3: 0.142955, l4: 0.214469, l5: 0.295108, l6: 0.460454\n",
            "\n",
            "[epoch: 107/100000, batch: 520/1000, ite: 13315] train loss: 2.3642, accuracy: 91.3269%, tar: 0.1482 \n",
            "l0: 0.090887, l1: 0.091830, l2: 0.099825, l3: 0.125125, l4: 0.173001, l5: 0.259678, l6: 0.475548\n",
            "\n",
            "[epoch: 107/100000, batch: 528/1000, ite: 13316] train loss: 2.3638, accuracy: 91.3961%, tar: 0.1482 \n",
            "l0: 0.092993, l1: 0.095004, l2: 0.107262, l3: 0.137088, l4: 0.192824, l5: 0.290297, l6: 0.498388\n",
            "\n",
            "[epoch: 107/100000, batch: 536/1000, ite: 13317] train loss: 2.3634, accuracy: 91.4409%, tar: 0.1481 \n",
            "l0: 0.081233, l1: 0.083111, l2: 0.097145, l3: 0.131941, l4: 0.204839, l5: 0.326090, l6: 0.548993\n",
            "\n",
            "[epoch: 107/100000, batch: 544/1000, ite: 13318] train loss: 2.3632, accuracy: 91.6534%, tar: 0.1481 \n",
            "l0: 0.070610, l1: 0.071841, l2: 0.082725, l3: 0.114868, l4: 0.173668, l5: 0.280717, l6: 0.540073\n",
            "\n",
            "[epoch: 107/100000, batch: 552/1000, ite: 13319] train loss: 2.3628, accuracy: 93.0327%, tar: 0.1480 \n",
            "l0: 0.091922, l1: 0.094037, l2: 0.106345, l3: 0.129814, l4: 0.217560, l5: 0.352833, l6: 0.594191\n",
            "\n",
            "[epoch: 107/100000, batch: 560/1000, ite: 13320] train loss: 2.3627, accuracy: 91.0671%, tar: 0.1480 \n",
            "l0: 0.148378, l1: 0.153624, l2: 0.173378, l3: 0.208026, l4: 0.285170, l5: 0.386142, l6: 0.519929\n",
            "\n",
            "[epoch: 107/100000, batch: 568/1000, ite: 13321] train loss: 2.3627, accuracy: 92.6435%, tar: 0.1480 \n",
            "l0: 0.066002, l1: 0.066913, l2: 0.076154, l3: 0.099987, l4: 0.149779, l5: 0.219211, l6: 0.380840\n",
            "\n",
            "[epoch: 107/100000, batch: 576/1000, ite: 13322] train loss: 2.3620, accuracy: 93.2631%, tar: 0.1479 \n",
            "l0: 0.085836, l1: 0.086814, l2: 0.097759, l3: 0.126636, l4: 0.182511, l5: 0.274021, l6: 0.480977\n",
            "\n",
            "[epoch: 107/100000, batch: 584/1000, ite: 13323] train loss: 2.3616, accuracy: 91.9644%, tar: 0.1479 \n",
            "l0: 0.086159, l1: 0.086120, l2: 0.095997, l3: 0.117266, l4: 0.156021, l5: 0.245644, l6: 0.438746\n",
            "\n",
            "[epoch: 107/100000, batch: 592/1000, ite: 13324] train loss: 2.3611, accuracy: 91.7291%, tar: 0.1478 \n",
            "l0: 0.107076, l1: 0.109399, l2: 0.122335, l3: 0.159199, l4: 0.243661, l5: 0.363950, l6: 0.614212\n",
            "\n",
            "[epoch: 107/100000, batch: 600/1000, ite: 13325] train loss: 2.3611, accuracy: 90.8351%, tar: 0.1478 \n",
            "l0: 0.091749, l1: 0.092126, l2: 0.103344, l3: 0.123925, l4: 0.158996, l5: 0.247080, l6: 0.394884\n",
            "\n",
            "[epoch: 107/100000, batch: 608/1000, ite: 13326] train loss: 2.3605, accuracy: 92.4926%, tar: 0.1477 \n",
            "l0: 0.109992, l1: 0.111244, l2: 0.118403, l3: 0.142229, l4: 0.194832, l5: 0.272327, l6: 0.395894\n",
            "\n",
            "[epoch: 107/100000, batch: 616/1000, ite: 13327] train loss: 2.3600, accuracy: 92.5236%, tar: 0.1477 \n",
            "l0: 0.068553, l1: 0.070011, l2: 0.080337, l3: 0.104306, l4: 0.178386, l5: 0.278992, l6: 0.422157\n",
            "\n",
            "[epoch: 107/100000, batch: 624/1000, ite: 13328] train loss: 2.3594, accuracy: 93.2003%, tar: 0.1476 \n",
            "l0: 0.096114, l1: 0.097721, l2: 0.106188, l3: 0.132548, l4: 0.194902, l5: 0.281650, l6: 0.449417\n",
            "\n",
            "[epoch: 107/100000, batch: 632/1000, ite: 13329] train loss: 2.3590, accuracy: 91.3177%, tar: 0.1476 \n",
            "l0: 0.106317, l1: 0.105454, l2: 0.116863, l3: 0.138597, l4: 0.188871, l5: 0.276369, l6: 0.433655\n",
            "\n",
            "[epoch: 107/100000, batch: 640/1000, ite: 13330] train loss: 2.3586, accuracy: 92.4851%, tar: 0.1476 \n",
            "l0: 0.067909, l1: 0.068802, l2: 0.081347, l3: 0.106605, l4: 0.154304, l5: 0.270523, l6: 0.479243\n",
            "\n",
            "[epoch: 107/100000, batch: 648/1000, ite: 13331] train loss: 2.3581, accuracy: 92.6174%, tar: 0.1475 \n",
            "l0: 0.072332, l1: 0.073654, l2: 0.084847, l3: 0.115828, l4: 0.167088, l5: 0.267771, l6: 0.494396\n",
            "\n",
            "[epoch: 107/100000, batch: 656/1000, ite: 13332] train loss: 2.3577, accuracy: 92.4242%, tar: 0.1475 \n",
            "l0: 0.065166, l1: 0.067637, l2: 0.079231, l3: 0.101734, l4: 0.173058, l5: 0.294754, l6: 0.488819\n",
            "\n",
            "[epoch: 107/100000, batch: 664/1000, ite: 13333] train loss: 2.3573, accuracy: 94.0416%, tar: 0.1474 \n",
            "l0: 0.076627, l1: 0.076766, l2: 0.088799, l3: 0.112295, l4: 0.178044, l5: 0.285313, l6: 0.542503\n",
            "\n",
            "[epoch: 107/100000, batch: 672/1000, ite: 13334] train loss: 2.3569, accuracy: 92.4832%, tar: 0.1473 \n",
            "l0: 0.091911, l1: 0.094372, l2: 0.104183, l3: 0.133421, l4: 0.193890, l5: 0.338385, l6: 0.522690\n",
            "\n",
            "[epoch: 107/100000, batch: 680/1000, ite: 13335] train loss: 2.3566, accuracy: 91.9582%, tar: 0.1473 \n",
            "l0: 0.098270, l1: 0.098240, l2: 0.109437, l3: 0.135473, l4: 0.186500, l5: 0.256867, l6: 0.440307\n",
            "\n",
            "[epoch: 107/100000, batch: 688/1000, ite: 13336] train loss: 2.3562, accuracy: 91.9023%, tar: 0.1473 \n",
            "l0: 0.069012, l1: 0.070247, l2: 0.080114, l3: 0.097316, l4: 0.149812, l5: 0.223932, l6: 0.369717\n",
            "\n",
            "[epoch: 107/100000, batch: 696/1000, ite: 13337] train loss: 2.3555, accuracy: 93.0172%, tar: 0.1472 \n",
            "l0: 0.080097, l1: 0.081138, l2: 0.091866, l3: 0.112830, l4: 0.161996, l5: 0.242010, l6: 0.421024\n",
            "\n",
            "[epoch: 107/100000, batch: 704/1000, ite: 13338] train loss: 2.3549, accuracy: 93.1499%, tar: 0.1472 \n",
            "l0: 0.096672, l1: 0.097317, l2: 0.107969, l3: 0.133878, l4: 0.209146, l5: 0.309393, l6: 0.472735\n",
            "\n",
            "[epoch: 107/100000, batch: 712/1000, ite: 13339] train loss: 2.3546, accuracy: 92.6428%, tar: 0.1471 \n",
            "l0: 0.088267, l1: 0.090685, l2: 0.101527, l3: 0.129482, l4: 0.190616, l5: 0.285066, l6: 0.515561\n",
            "\n",
            "[epoch: 107/100000, batch: 720/1000, ite: 13340] train loss: 2.3543, accuracy: 91.3909%, tar: 0.1471 \n",
            "l0: 0.079920, l1: 0.080669, l2: 0.089872, l3: 0.110214, l4: 0.165018, l5: 0.280015, l6: 0.500600\n",
            "\n",
            "[epoch: 107/100000, batch: 728/1000, ite: 13341] train loss: 2.3538, accuracy: 90.8777%, tar: 0.1470 \n",
            "l0: 0.074985, l1: 0.075370, l2: 0.086104, l3: 0.110566, l4: 0.178865, l5: 0.290744, l6: 0.484931\n",
            "\n",
            "[epoch: 107/100000, batch: 736/1000, ite: 13342] train loss: 2.3534, accuracy: 91.6311%, tar: 0.1470 \n",
            "l0: 0.068256, l1: 0.068657, l2: 0.080535, l3: 0.101037, l4: 0.155192, l5: 0.234420, l6: 0.406248\n",
            "\n",
            "[epoch: 107/100000, batch: 744/1000, ite: 13343] train loss: 2.3528, accuracy: 93.2504%, tar: 0.1469 \n",
            "l0: 0.076023, l1: 0.076776, l2: 0.083555, l3: 0.100173, l4: 0.138662, l5: 0.210371, l6: 0.372884\n",
            "\n",
            "[epoch: 107/100000, batch: 752/1000, ite: 13344] train loss: 2.3521, accuracy: 93.8879%, tar: 0.1469 \n",
            "l0: 0.108310, l1: 0.109898, l2: 0.120027, l3: 0.152226, l4: 0.204361, l5: 0.305262, l6: 0.531518\n",
            "\n",
            "[epoch: 107/100000, batch: 760/1000, ite: 13345] train loss: 2.3519, accuracy: 91.4526%, tar: 0.1468 \n",
            "l0: 0.078367, l1: 0.084053, l2: 0.097333, l3: 0.126744, l4: 0.185129, l5: 0.280454, l6: 0.418135\n",
            "\n",
            "[epoch: 107/100000, batch: 768/1000, ite: 13346] train loss: 2.3514, accuracy: 92.7156%, tar: 0.1468 \n",
            "l0: 0.086609, l1: 0.088035, l2: 0.101100, l3: 0.133218, l4: 0.194570, l5: 0.305357, l6: 0.514531\n",
            "\n",
            "[epoch: 107/100000, batch: 776/1000, ite: 13347] train loss: 2.3511, accuracy: 91.7959%, tar: 0.1467 \n",
            "l0: 0.066628, l1: 0.066875, l2: 0.079900, l3: 0.110428, l4: 0.186519, l5: 0.321294, l6: 0.493334\n",
            "\n",
            "[epoch: 107/100000, batch: 784/1000, ite: 13348] train loss: 2.3507, accuracy: 92.6572%, tar: 0.1467 \n",
            "l0: 0.070022, l1: 0.071809, l2: 0.081632, l3: 0.102588, l4: 0.140314, l5: 0.219945, l6: 0.414305\n",
            "\n",
            "[epoch: 107/100000, batch: 792/1000, ite: 13349] train loss: 2.3501, accuracy: 93.6575%, tar: 0.1466 \n",
            "l0: 0.086650, l1: 0.087708, l2: 0.098404, l3: 0.120609, l4: 0.183565, l5: 0.291985, l6: 0.528796\n",
            "\n",
            "[epoch: 107/100000, batch: 800/1000, ite: 13350] train loss: 2.3498, accuracy: 92.3223%, tar: 0.1466 \n",
            "l0: 0.090103, l1: 0.093051, l2: 0.104972, l3: 0.134940, l4: 0.202028, l5: 0.319927, l6: 0.543991\n",
            "\n",
            "[epoch: 107/100000, batch: 808/1000, ite: 13351] train loss: 2.3496, accuracy: 90.7888%, tar: 0.1465 \n",
            "l0: 0.070104, l1: 0.071014, l2: 0.081091, l3: 0.107834, l4: 0.162110, l5: 0.293629, l6: 0.450475\n",
            "\n",
            "[epoch: 107/100000, batch: 816/1000, ite: 13352] train loss: 2.3491, accuracy: 92.3707%, tar: 0.1465 \n",
            "l0: 0.098288, l1: 0.099933, l2: 0.109038, l3: 0.133652, l4: 0.185456, l5: 0.293753, l6: 0.487307\n",
            "\n",
            "[epoch: 107/100000, batch: 824/1000, ite: 13353] train loss: 2.3487, accuracy: 92.0278%, tar: 0.1464 \n",
            "l0: 0.071937, l1: 0.073589, l2: 0.088191, l3: 0.113565, l4: 0.172220, l5: 0.312121, l6: 0.604424\n",
            "\n",
            "[epoch: 107/100000, batch: 832/1000, ite: 13354] train loss: 2.3485, accuracy: 90.8812%, tar: 0.1464 \n",
            "l0: 0.091238, l1: 0.091650, l2: 0.103402, l3: 0.132756, l4: 0.206934, l5: 0.340206, l6: 0.664204\n",
            "\n",
            "[epoch: 107/100000, batch: 840/1000, ite: 13355] train loss: 2.3485, accuracy: 89.8345%, tar: 0.1464 \n",
            "l0: 0.104819, l1: 0.107371, l2: 0.117514, l3: 0.139199, l4: 0.206210, l5: 0.334521, l6: 0.520173\n",
            "\n",
            "[epoch: 107/100000, batch: 848/1000, ite: 13356] train loss: 2.3483, accuracy: 91.7814%, tar: 0.1463 \n",
            "l0: 0.066692, l1: 0.067770, l2: 0.079927, l3: 0.108120, l4: 0.164775, l5: 0.259981, l6: 0.473227\n",
            "\n",
            "[epoch: 107/100000, batch: 856/1000, ite: 13357] train loss: 2.3478, accuracy: 93.1116%, tar: 0.1463 \n",
            "l0: 0.157488, l1: 0.165896, l2: 0.172350, l3: 0.192005, l4: 0.239727, l5: 0.364955, l6: 0.602264\n",
            "\n",
            "[epoch: 107/100000, batch: 864/1000, ite: 13358] train loss: 2.3479, accuracy: 89.2653%, tar: 0.1463 \n",
            "l0: 0.120851, l1: 0.123204, l2: 0.136924, l3: 0.170005, l4: 0.239695, l5: 0.367072, l6: 0.618857\n",
            "\n",
            "[epoch: 107/100000, batch: 872/1000, ite: 13359] train loss: 2.3480, accuracy: 89.8797%, tar: 0.1463 \n",
            "l0: 0.087421, l1: 0.088416, l2: 0.100510, l3: 0.131547, l4: 0.192959, l5: 0.269693, l6: 0.413691\n",
            "\n",
            "[epoch: 107/100000, batch: 880/1000, ite: 13360] train loss: 2.3475, accuracy: 92.6283%, tar: 0.1462 \n",
            "l0: 0.085163, l1: 0.089447, l2: 0.095936, l3: 0.114880, l4: 0.153086, l5: 0.240761, l6: 0.434909\n",
            "\n",
            "[epoch: 107/100000, batch: 888/1000, ite: 13361] train loss: 2.3470, accuracy: 93.7612%, tar: 0.1462 \n",
            "l0: 0.082413, l1: 0.084509, l2: 0.094456, l3: 0.118227, l4: 0.168235, l5: 0.259372, l6: 0.426469\n",
            "\n",
            "[epoch: 107/100000, batch: 896/1000, ite: 13362] train loss: 2.3465, accuracy: 93.1213%, tar: 0.1461 \n",
            "l0: 0.082056, l1: 0.083850, l2: 0.091795, l3: 0.106376, l4: 0.147075, l5: 0.216109, l6: 0.357216\n",
            "\n",
            "[epoch: 107/100000, batch: 904/1000, ite: 13363] train loss: 2.3458, accuracy: 92.6920%, tar: 0.1461 \n",
            "l0: 0.071525, l1: 0.072749, l2: 0.079291, l3: 0.094610, l4: 0.132073, l5: 0.197793, l6: 0.368371\n",
            "\n",
            "[epoch: 107/100000, batch: 912/1000, ite: 13364] train loss: 2.3451, accuracy: 93.1221%, tar: 0.1460 \n",
            "l0: 0.091137, l1: 0.092969, l2: 0.104617, l3: 0.136312, l4: 0.196210, l5: 0.280230, l6: 0.482668\n",
            "\n",
            "[epoch: 107/100000, batch: 920/1000, ite: 13365] train loss: 2.3447, accuracy: 91.8181%, tar: 0.1460 \n",
            "l0: 0.115588, l1: 0.116682, l2: 0.129785, l3: 0.158355, l4: 0.216649, l5: 0.322542, l6: 0.621959\n",
            "\n",
            "[epoch: 107/100000, batch: 928/1000, ite: 13366] train loss: 2.3447, accuracy: 90.3607%, tar: 0.1460 \n",
            "l0: 0.115434, l1: 0.118749, l2: 0.130086, l3: 0.148753, l4: 0.188734, l5: 0.273200, l6: 0.428276\n",
            "\n",
            "[epoch: 107/100000, batch: 936/1000, ite: 13367] train loss: 2.3443, accuracy: 91.4875%, tar: 0.1459 \n",
            "l0: 0.075216, l1: 0.077682, l2: 0.090707, l3: 0.117334, l4: 0.185702, l5: 0.296957, l6: 0.499972\n",
            "\n",
            "[epoch: 107/100000, batch: 944/1000, ite: 13368] train loss: 2.3440, accuracy: 92.5022%, tar: 0.1459 \n",
            "l0: 0.093666, l1: 0.094653, l2: 0.106823, l3: 0.137492, l4: 0.195123, l5: 0.299165, l6: 0.503910\n",
            "\n",
            "[epoch: 107/100000, batch: 952/1000, ite: 13369] train loss: 2.3437, accuracy: 92.1373%, tar: 0.1458 \n",
            "l0: 0.104139, l1: 0.105621, l2: 0.118069, l3: 0.140595, l4: 0.200840, l5: 0.324643, l6: 0.581151\n",
            "\n",
            "[epoch: 107/100000, batch: 960/1000, ite: 13370] train loss: 2.3435, accuracy: 91.4656%, tar: 0.1458 \n",
            "l0: 0.098242, l1: 0.101186, l2: 0.112568, l3: 0.149799, l4: 0.223054, l5: 0.355206, l6: 0.516059\n",
            "\n",
            "[epoch: 107/100000, batch: 968/1000, ite: 13371] train loss: 2.3433, accuracy: 91.8992%, tar: 0.1458 \n",
            "l0: 0.075174, l1: 0.075829, l2: 0.087951, l3: 0.112903, l4: 0.182375, l5: 0.329107, l6: 0.543527\n",
            "\n",
            "[epoch: 107/100000, batch: 976/1000, ite: 13372] train loss: 2.3431, accuracy: 91.4204%, tar: 0.1457 \n",
            "l0: 0.097632, l1: 0.101130, l2: 0.111858, l3: 0.136129, l4: 0.185277, l5: 0.271893, l6: 0.471414\n",
            "\n",
            "[epoch: 107/100000, batch: 984/1000, ite: 13373] train loss: 2.3427, accuracy: 92.2058%, tar: 0.1457 \n",
            "l0: 0.083210, l1: 0.086082, l2: 0.093130, l3: 0.115239, l4: 0.163994, l5: 0.241070, l6: 0.394463\n",
            "\n",
            "[epoch: 107/100000, batch: 992/1000, ite: 13374] train loss: 2.3421, accuracy: 93.5006%, tar: 0.1456 \n",
            "l0: 0.074738, l1: 0.075185, l2: 0.085645, l3: 0.105837, l4: 0.151647, l5: 0.222450, l6: 0.389257\n",
            "\n",
            "[epoch: 107/100000, batch: 1000/1000, ite: 13375] train loss: 2.3415, accuracy: 92.7926%, tar: 0.1456 \n",
            "l0: 0.097598, l1: 0.097962, l2: 0.109454, l3: 0.136693, l4: 0.189702, l5: 0.300182, l6: 0.531863\n",
            "\n",
            "[epoch: 108/100000, batch: 8/1000, ite: 13376] train loss: 2.3413, accuracy: 90.3338%, tar: 0.1456 \n",
            "l0: 0.084060, l1: 0.084799, l2: 0.098221, l3: 0.120404, l4: 0.180664, l5: 0.290835, l6: 0.497852\n",
            "\n",
            "[epoch: 108/100000, batch: 16/1000, ite: 13377] train loss: 2.3410, accuracy: 91.9892%, tar: 0.1455 \n",
            "l0: 0.091855, l1: 0.091778, l2: 0.101798, l3: 0.120324, l4: 0.160483, l5: 0.270350, l6: 0.525438\n",
            "\n",
            "[epoch: 108/100000, batch: 24/1000, ite: 13378] train loss: 2.3406, accuracy: 90.8309%, tar: 0.1455 \n",
            "l0: 0.088445, l1: 0.089480, l2: 0.101873, l3: 0.126131, l4: 0.195608, l5: 0.303696, l6: 0.461153\n",
            "\n",
            "[epoch: 108/100000, batch: 32/1000, ite: 13379] train loss: 2.3402, accuracy: 93.1566%, tar: 0.1454 \n",
            "l0: 0.066287, l1: 0.067888, l2: 0.074565, l3: 0.091359, l4: 0.133021, l5: 0.205016, l6: 0.390899\n",
            "\n",
            "[epoch: 108/100000, batch: 40/1000, ite: 13380] train loss: 2.3396, accuracy: 93.4717%, tar: 0.1454 \n",
            "l0: 0.107247, l1: 0.111449, l2: 0.122697, l3: 0.143427, l4: 0.198081, l5: 0.321733, l6: 0.553017\n",
            "\n",
            "[epoch: 108/100000, batch: 48/1000, ite: 13381] train loss: 2.3394, accuracy: 89.8429%, tar: 0.1453 \n",
            "l0: 0.095711, l1: 0.100899, l2: 0.117468, l3: 0.155367, l4: 0.230525, l5: 0.340144, l6: 0.538848\n",
            "\n",
            "[epoch: 108/100000, batch: 56/1000, ite: 13382] train loss: 2.3393, accuracy: 91.0749%, tar: 0.1453 \n",
            "l0: 0.095995, l1: 0.099993, l2: 0.109939, l3: 0.134241, l4: 0.187038, l5: 0.283095, l6: 0.453729\n",
            "\n",
            "[epoch: 108/100000, batch: 64/1000, ite: 13383] train loss: 2.3389, accuracy: 91.5240%, tar: 0.1453 \n",
            "l0: 0.104371, l1: 0.106293, l2: 0.118833, l3: 0.154370, l4: 0.228008, l5: 0.373728, l6: 0.562077\n",
            "\n",
            "[epoch: 108/100000, batch: 72/1000, ite: 13384] train loss: 2.3388, accuracy: 91.4186%, tar: 0.1452 \n",
            "l0: 0.092987, l1: 0.093859, l2: 0.104725, l3: 0.132954, l4: 0.190525, l5: 0.290823, l6: 0.465785\n",
            "\n",
            "[epoch: 108/100000, batch: 80/1000, ite: 13385] train loss: 2.3385, accuracy: 92.1423%, tar: 0.1452 \n",
            "l0: 0.087702, l1: 0.090494, l2: 0.101378, l3: 0.129222, l4: 0.202483, l5: 0.293381, l6: 0.457443\n",
            "\n",
            "[epoch: 108/100000, batch: 88/1000, ite: 13386] train loss: 2.3381, accuracy: 93.7039%, tar: 0.1452 \n",
            "l0: 0.074209, l1: 0.074055, l2: 0.081280, l3: 0.104029, l4: 0.163164, l5: 0.270162, l6: 0.461097\n",
            "\n",
            "[epoch: 108/100000, batch: 96/1000, ite: 13387] train loss: 2.3376, accuracy: 93.7253%, tar: 0.1451 \n",
            "l0: 0.069323, l1: 0.070696, l2: 0.084269, l3: 0.111194, l4: 0.158133, l5: 0.269980, l6: 0.455672\n",
            "\n",
            "[epoch: 108/100000, batch: 104/1000, ite: 13388] train loss: 2.3371, accuracy: 93.1381%, tar: 0.1451 \n",
            "l0: 0.088762, l1: 0.090408, l2: 0.102437, l3: 0.128101, l4: 0.180933, l5: 0.316903, l6: 0.585941\n",
            "\n",
            "[epoch: 108/100000, batch: 112/1000, ite: 13389] train loss: 2.3370, accuracy: 90.3812%, tar: 0.1450 \n",
            "l0: 0.082770, l1: 0.085793, l2: 0.091931, l3: 0.116891, l4: 0.176622, l5: 0.260836, l6: 0.433290\n",
            "\n",
            "[epoch: 108/100000, batch: 120/1000, ite: 13390] train loss: 2.3365, accuracy: 92.9645%, tar: 0.1450 \n",
            "l0: 0.070995, l1: 0.072300, l2: 0.084456, l3: 0.108355, l4: 0.164386, l5: 0.277000, l6: 0.450432\n",
            "\n",
            "[epoch: 108/100000, batch: 128/1000, ite: 13391] train loss: 2.3360, accuracy: 93.6340%, tar: 0.1449 \n",
            "l0: 0.092069, l1: 0.092765, l2: 0.108768, l3: 0.143497, l4: 0.196120, l5: 0.288607, l6: 0.497822\n",
            "\n",
            "[epoch: 108/100000, batch: 136/1000, ite: 13392] train loss: 2.3357, accuracy: 92.0126%, tar: 0.1449 \n",
            "l0: 0.087661, l1: 0.088907, l2: 0.100564, l3: 0.124397, l4: 0.171530, l5: 0.287549, l6: 0.465024\n",
            "\n",
            "[epoch: 108/100000, batch: 144/1000, ite: 13393] train loss: 2.3353, accuracy: 92.0254%, tar: 0.1448 \n",
            "l0: 0.067177, l1: 0.067198, l2: 0.078550, l3: 0.101433, l4: 0.144791, l5: 0.218797, l6: 0.391430\n",
            "\n",
            "[epoch: 108/100000, batch: 152/1000, ite: 13394] train loss: 2.3347, accuracy: 93.7683%, tar: 0.1448 \n",
            "l0: 0.159873, l1: 0.176453, l2: 0.187356, l3: 0.210230, l4: 0.268897, l5: 0.337356, l6: 0.484478\n",
            "\n",
            "[epoch: 108/100000, batch: 160/1000, ite: 13395] train loss: 2.3347, accuracy: 90.3402%, tar: 0.1448 \n",
            "l0: 0.117229, l1: 0.118506, l2: 0.128514, l3: 0.151990, l4: 0.206534, l5: 0.288165, l6: 0.502573\n",
            "\n",
            "[epoch: 108/100000, batch: 168/1000, ite: 13396] train loss: 2.3344, accuracy: 92.4995%, tar: 0.1448 \n",
            "l0: 0.109911, l1: 0.104309, l2: 0.115224, l3: 0.146953, l4: 0.194741, l5: 0.296807, l6: 0.499913\n",
            "\n",
            "[epoch: 108/100000, batch: 176/1000, ite: 13397] train loss: 2.3342, accuracy: 91.9147%, tar: 0.1448 \n",
            "l0: 0.077157, l1: 0.076966, l2: 0.083903, l3: 0.097587, l4: 0.130631, l5: 0.219545, l6: 0.388846\n",
            "\n",
            "[epoch: 108/100000, batch: 184/1000, ite: 13398] train loss: 2.3335, accuracy: 92.8043%, tar: 0.1447 \n",
            "l0: 0.077319, l1: 0.079137, l2: 0.092481, l3: 0.120745, l4: 0.198508, l5: 0.330616, l6: 0.541226\n",
            "\n",
            "[epoch: 108/100000, batch: 192/1000, ite: 13399] train loss: 2.3333, accuracy: 91.5315%, tar: 0.1447 \n",
            "l0: 0.083343, l1: 0.084003, l2: 0.094241, l3: 0.121861, l4: 0.173360, l5: 0.262353, l6: 0.489287\n",
            "\n",
            "[epoch: 108/100000, batch: 200/1000, ite: 13400] train loss: 2.3329, accuracy: 91.5340%, tar: 0.1446 \n",
            "l0: 0.098978, l1: 0.101317, l2: 0.117262, l3: 0.149961, l4: 0.231638, l5: 0.404347, l6: 0.617149\n",
            "\n",
            "[epoch: 108/100000, batch: 208/1000, ite: 13401] train loss: 2.3329, accuracy: 90.0951%, tar: 0.1446 \n",
            "l0: 0.085663, l1: 0.086282, l2: 0.093827, l3: 0.115035, l4: 0.158736, l5: 0.238596, l6: 0.410450\n",
            "\n",
            "[epoch: 108/100000, batch: 216/1000, ite: 13402] train loss: 2.3324, accuracy: 92.9227%, tar: 0.1445 \n",
            "l0: 0.072848, l1: 0.074724, l2: 0.085472, l3: 0.115274, l4: 0.189199, l5: 0.293040, l6: 0.495315\n",
            "\n",
            "[epoch: 108/100000, batch: 224/1000, ite: 13403] train loss: 2.3320, accuracy: 92.3025%, tar: 0.1445 \n",
            "l0: 0.079742, l1: 0.081680, l2: 0.091701, l3: 0.115923, l4: 0.180862, l5: 0.314856, l6: 0.585471\n",
            "\n",
            "[epoch: 108/100000, batch: 232/1000, ite: 13404] train loss: 2.3318, accuracy: 91.5798%, tar: 0.1444 \n",
            "l0: 0.087264, l1: 0.088141, l2: 0.104522, l3: 0.143631, l4: 0.223397, l5: 0.382760, l6: 0.586287\n",
            "\n",
            "[epoch: 108/100000, batch: 240/1000, ite: 13405] train loss: 2.3317, accuracy: 91.7069%, tar: 0.1444 \n",
            "l0: 0.088233, l1: 0.089924, l2: 0.100421, l3: 0.122960, l4: 0.160405, l5: 0.238221, l6: 0.416145\n",
            "\n",
            "[epoch: 108/100000, batch: 248/1000, ite: 13406] train loss: 2.3313, accuracy: 92.2198%, tar: 0.1444 \n",
            "l0: 0.144309, l1: 0.148972, l2: 0.163781, l3: 0.181706, l4: 0.218859, l5: 0.300532, l6: 0.490611\n",
            "\n",
            "[epoch: 108/100000, batch: 256/1000, ite: 13407] train loss: 2.3311, accuracy: 90.7111%, tar: 0.1444 \n",
            "l0: 0.124414, l1: 0.124269, l2: 0.140912, l3: 0.174124, l4: 0.268840, l5: 0.452516, l6: 0.758118\n",
            "\n",
            "[epoch: 108/100000, batch: 264/1000, ite: 13408] train loss: 2.3314, accuracy: 87.9979%, tar: 0.1443 \n",
            "l0: 0.075225, l1: 0.077493, l2: 0.086251, l3: 0.115494, l4: 0.187450, l5: 0.279200, l6: 0.440226\n",
            "\n",
            "[epoch: 108/100000, batch: 272/1000, ite: 13409] train loss: 2.3310, accuracy: 92.3473%, tar: 0.1443 \n",
            "l0: 0.139062, l1: 0.138921, l2: 0.154112, l3: 0.186304, l4: 0.265064, l5: 0.391809, l6: 0.653190\n",
            "\n",
            "[epoch: 108/100000, batch: 280/1000, ite: 13410] train loss: 2.3312, accuracy: 89.5643%, tar: 0.1443 \n",
            "l0: 0.088723, l1: 0.090099, l2: 0.102409, l3: 0.127848, l4: 0.210545, l5: 0.310874, l6: 0.469440\n",
            "\n",
            "[epoch: 108/100000, batch: 288/1000, ite: 13411] train loss: 2.3308, accuracy: 92.3853%, tar: 0.1443 \n",
            "l0: 0.070749, l1: 0.073062, l2: 0.086701, l3: 0.113981, l4: 0.178151, l5: 0.288617, l6: 0.460496\n",
            "\n",
            "[epoch: 108/100000, batch: 296/1000, ite: 13412] train loss: 2.3304, accuracy: 93.2612%, tar: 0.1442 \n",
            "l0: 0.169550, l1: 0.167752, l2: 0.179366, l3: 0.214225, l4: 0.298767, l5: 0.411492, l6: 0.716377\n",
            "\n",
            "[epoch: 108/100000, batch: 304/1000, ite: 13413] train loss: 2.3308, accuracy: 89.8084%, tar: 0.1442 \n",
            "l0: 0.097779, l1: 0.097913, l2: 0.108467, l3: 0.138880, l4: 0.195681, l5: 0.296872, l6: 0.571792\n",
            "\n",
            "[epoch: 108/100000, batch: 312/1000, ite: 13414] train loss: 2.3306, accuracy: 92.0082%, tar: 0.1442 \n",
            "l0: 0.095567, l1: 0.097810, l2: 0.104128, l3: 0.124455, l4: 0.193100, l5: 0.296522, l6: 0.475545\n",
            "\n",
            "[epoch: 108/100000, batch: 320/1000, ite: 13415] train loss: 2.3303, accuracy: 91.4430%, tar: 0.1442 \n",
            "l0: 0.079816, l1: 0.082101, l2: 0.091299, l3: 0.116947, l4: 0.184594, l5: 0.300944, l6: 0.618765\n",
            "\n",
            "[epoch: 108/100000, batch: 328/1000, ite: 13416] train loss: 2.3301, accuracy: 89.8650%, tar: 0.1441 \n",
            "l0: 0.152357, l1: 0.147373, l2: 0.159589, l3: 0.185400, l4: 0.213543, l5: 0.264115, l6: 0.403663\n",
            "\n",
            "[epoch: 108/100000, batch: 336/1000, ite: 13417] train loss: 2.3298, accuracy: 91.7665%, tar: 0.1441 \n",
            "l0: 0.110709, l1: 0.113530, l2: 0.127767, l3: 0.170350, l4: 0.259785, l5: 0.415299, l6: 0.679157\n",
            "\n",
            "[epoch: 108/100000, batch: 344/1000, ite: 13418] train loss: 2.3300, accuracy: 91.2475%, tar: 0.1441 \n",
            "l0: 0.089116, l1: 0.091953, l2: 0.100776, l3: 0.123849, l4: 0.189220, l5: 0.275027, l6: 0.453369\n",
            "\n",
            "[epoch: 108/100000, batch: 352/1000, ite: 13419] train loss: 2.3296, accuracy: 93.2144%, tar: 0.1441 \n",
            "l0: 0.080486, l1: 0.081575, l2: 0.089254, l3: 0.117230, l4: 0.177259, l5: 0.280438, l6: 0.521132\n",
            "\n",
            "[epoch: 108/100000, batch: 360/1000, ite: 13420] train loss: 2.3293, accuracy: 91.0294%, tar: 0.1440 \n",
            "l0: 0.149503, l1: 0.152871, l2: 0.164037, l3: 0.188931, l4: 0.237368, l5: 0.364802, l6: 0.607526\n",
            "\n",
            "[epoch: 108/100000, batch: 368/1000, ite: 13421] train loss: 2.3294, accuracy: 89.0192%, tar: 0.1440 \n",
            "l0: 0.071781, l1: 0.072491, l2: 0.083160, l3: 0.107296, l4: 0.152217, l5: 0.249795, l6: 0.462845\n",
            "\n",
            "[epoch: 108/100000, batch: 376/1000, ite: 13422] train loss: 2.3289, accuracy: 91.6703%, tar: 0.1440 \n",
            "l0: 0.126799, l1: 0.127659, l2: 0.135472, l3: 0.162464, l4: 0.182789, l5: 0.247458, l6: 0.427534\n",
            "\n",
            "[epoch: 108/100000, batch: 384/1000, ite: 13423] train loss: 2.3285, accuracy: 90.8453%, tar: 0.1439 \n",
            "l0: 0.099270, l1: 0.105071, l2: 0.119381, l3: 0.149717, l4: 0.217427, l5: 0.333824, l6: 0.512695\n",
            "\n",
            "[epoch: 108/100000, batch: 392/1000, ite: 13424] train loss: 2.3283, accuracy: 92.4078%, tar: 0.1439 \n",
            "l0: 0.083663, l1: 0.085406, l2: 0.090588, l3: 0.115735, l4: 0.178376, l5: 0.298067, l6: 0.483153\n",
            "\n",
            "[epoch: 108/100000, batch: 400/1000, ite: 13425] train loss: 2.3279, accuracy: 92.6393%, tar: 0.1439 \n",
            "l0: 0.079910, l1: 0.080352, l2: 0.091843, l3: 0.119565, l4: 0.168182, l5: 0.280446, l6: 0.493104\n",
            "\n",
            "[epoch: 108/100000, batch: 408/1000, ite: 13426] train loss: 2.3276, accuracy: 91.4588%, tar: 0.1438 \n",
            "l0: 0.072338, l1: 0.073296, l2: 0.082108, l3: 0.106414, l4: 0.160593, l5: 0.247996, l6: 0.428513\n",
            "\n",
            "[epoch: 108/100000, batch: 416/1000, ite: 13427] train loss: 2.3271, accuracy: 93.8676%, tar: 0.1438 \n",
            "l0: 0.079837, l1: 0.081884, l2: 0.088360, l3: 0.108906, l4: 0.154012, l5: 0.246444, l6: 0.429936\n",
            "\n",
            "[epoch: 108/100000, batch: 424/1000, ite: 13428] train loss: 2.3266, accuracy: 92.0049%, tar: 0.1437 \n",
            "l0: 0.069132, l1: 0.070084, l2: 0.078207, l3: 0.102333, l4: 0.141868, l5: 0.202489, l6: 0.388200\n",
            "\n",
            "[epoch: 108/100000, batch: 432/1000, ite: 13429] train loss: 2.3259, accuracy: 93.2672%, tar: 0.1437 \n",
            "l0: 0.099998, l1: 0.101834, l2: 0.113532, l3: 0.147997, l4: 0.212591, l5: 0.365754, l6: 0.530306\n",
            "\n",
            "[epoch: 108/100000, batch: 440/1000, ite: 13430] train loss: 2.3258, accuracy: 91.4802%, tar: 0.1437 \n",
            "l0: 0.089128, l1: 0.089688, l2: 0.099712, l3: 0.120027, l4: 0.177273, l5: 0.281078, l6: 0.521915\n",
            "\n",
            "[epoch: 108/100000, batch: 448/1000, ite: 13431] train loss: 2.3255, accuracy: 91.0269%, tar: 0.1436 \n",
            "l0: 0.077211, l1: 0.077725, l2: 0.086004, l3: 0.110984, l4: 0.157608, l5: 0.240690, l6: 0.381540\n",
            "\n",
            "[epoch: 108/100000, batch: 456/1000, ite: 13432] train loss: 2.3249, accuracy: 93.4140%, tar: 0.1436 \n",
            "l0: 0.106489, l1: 0.106823, l2: 0.117147, l3: 0.149438, l4: 0.211477, l5: 0.326200, l6: 0.636156\n",
            "\n",
            "[epoch: 108/100000, batch: 464/1000, ite: 13433] train loss: 2.3249, accuracy: 89.3938%, tar: 0.1435 \n",
            "l0: 0.088111, l1: 0.087873, l2: 0.097755, l3: 0.122397, l4: 0.198593, l5: 0.327948, l6: 0.524270\n",
            "\n",
            "[epoch: 108/100000, batch: 472/1000, ite: 13434] train loss: 2.3246, accuracy: 90.2428%, tar: 0.1435 \n",
            "l0: 0.095676, l1: 0.099054, l2: 0.104314, l3: 0.121420, l4: 0.160090, l5: 0.244735, l6: 0.424808\n",
            "\n",
            "[epoch: 108/100000, batch: 480/1000, ite: 13435] train loss: 2.3242, accuracy: 93.6418%, tar: 0.1435 \n",
            "l0: 0.107876, l1: 0.109978, l2: 0.123577, l3: 0.155459, l4: 0.216644, l5: 0.332866, l6: 0.547638\n",
            "\n",
            "[epoch: 108/100000, batch: 488/1000, ite: 13436] train loss: 2.3240, accuracy: 90.7841%, tar: 0.1434 \n",
            "l0: 0.071981, l1: 0.073975, l2: 0.084615, l3: 0.114507, l4: 0.195226, l5: 0.322421, l6: 0.617890\n",
            "\n",
            "[epoch: 108/100000, batch: 496/1000, ite: 13437] train loss: 2.3239, accuracy: 91.7825%, tar: 0.1434 \n",
            "l0: 0.097065, l1: 0.100025, l2: 0.111262, l3: 0.140795, l4: 0.197637, l5: 0.315706, l6: 0.567182\n",
            "\n",
            "[epoch: 108/100000, batch: 504/1000, ite: 13438] train loss: 2.3237, accuracy: 90.8329%, tar: 0.1434 \n",
            "l0: 0.083972, l1: 0.086656, l2: 0.095149, l3: 0.117590, l4: 0.168323, l5: 0.262580, l6: 0.415594\n",
            "\n",
            "[epoch: 108/100000, batch: 512/1000, ite: 13439] train loss: 2.3233, accuracy: 92.1389%, tar: 0.1433 \n",
            "l0: 0.076053, l1: 0.077157, l2: 0.086712, l3: 0.105418, l4: 0.147010, l5: 0.210695, l6: 0.313825\n",
            "\n",
            "[epoch: 108/100000, batch: 520/1000, ite: 13440] train loss: 2.3226, accuracy: 94.1010%, tar: 0.1433 \n",
            "l0: 0.117322, l1: 0.118105, l2: 0.133636, l3: 0.165134, l4: 0.236402, l5: 0.361691, l6: 0.592874\n",
            "\n",
            "[epoch: 108/100000, batch: 528/1000, ite: 13441] train loss: 2.3226, accuracy: 89.9282%, tar: 0.1433 \n",
            "l0: 0.114214, l1: 0.116880, l2: 0.129021, l3: 0.168656, l4: 0.261246, l5: 0.413623, l6: 0.636751\n",
            "\n",
            "[epoch: 108/100000, batch: 536/1000, ite: 13442] train loss: 2.3227, accuracy: 90.4644%, tar: 0.1432 \n",
            "l0: 0.091058, l1: 0.090909, l2: 0.104073, l3: 0.130241, l4: 0.183067, l5: 0.277875, l6: 0.422318\n",
            "\n",
            "[epoch: 108/100000, batch: 544/1000, ite: 13443] train loss: 2.3223, accuracy: 92.8541%, tar: 0.1432 \n",
            "l0: 0.086447, l1: 0.087959, l2: 0.098646, l3: 0.127966, l4: 0.190851, l5: 0.320342, l6: 0.502273\n",
            "\n",
            "[epoch: 108/100000, batch: 552/1000, ite: 13444] train loss: 2.3220, accuracy: 91.5071%, tar: 0.1432 \n",
            "l0: 0.078467, l1: 0.080272, l2: 0.090844, l3: 0.117285, l4: 0.175972, l5: 0.272345, l6: 0.431741\n",
            "\n",
            "[epoch: 108/100000, batch: 560/1000, ite: 13445] train loss: 2.3215, accuracy: 92.5201%, tar: 0.1431 \n",
            "l0: 0.097618, l1: 0.099000, l2: 0.113893, l3: 0.134708, l4: 0.200406, l5: 0.310395, l6: 0.481221\n",
            "\n",
            "[epoch: 108/100000, batch: 568/1000, ite: 13446] train loss: 2.3213, accuracy: 91.6615%, tar: 0.1431 \n",
            "l0: 0.144278, l1: 0.147922, l2: 0.164282, l3: 0.201185, l4: 0.264163, l5: 0.378388, l6: 0.641576\n",
            "\n",
            "[epoch: 108/100000, batch: 576/1000, ite: 13447] train loss: 2.3215, accuracy: 89.5273%, tar: 0.1431 \n",
            "l0: 0.078465, l1: 0.078715, l2: 0.090228, l3: 0.118070, l4: 0.157508, l5: 0.243633, l6: 0.433005\n",
            "\n",
            "[epoch: 108/100000, batch: 584/1000, ite: 13448] train loss: 2.3210, accuracy: 93.2505%, tar: 0.1430 \n",
            "l0: 0.083061, l1: 0.084369, l2: 0.097472, l3: 0.123387, l4: 0.184346, l5: 0.291917, l6: 0.523501\n",
            "\n",
            "[epoch: 108/100000, batch: 592/1000, ite: 13449] train loss: 2.3207, accuracy: 91.8893%, tar: 0.1430 \n",
            "l0: 0.169409, l1: 0.171239, l2: 0.183620, l3: 0.199210, l4: 0.232864, l5: 0.338663, l6: 0.517338\n",
            "\n",
            "[epoch: 108/100000, batch: 600/1000, ite: 13450] train loss: 2.3207, accuracy: 88.7918%, tar: 0.1430 \n",
            "l0: 0.100102, l1: 0.100996, l2: 0.117679, l3: 0.154192, l4: 0.235037, l5: 0.364598, l6: 0.585866\n",
            "\n",
            "[epoch: 108/100000, batch: 608/1000, ite: 13451] train loss: 2.3206, accuracy: 91.5365%, tar: 0.1430 \n",
            "l0: 0.122603, l1: 0.127927, l2: 0.141226, l3: 0.177987, l4: 0.262558, l5: 0.405626, l6: 0.582281\n",
            "\n",
            "[epoch: 108/100000, batch: 616/1000, ite: 13452] train loss: 2.3207, accuracy: 92.2008%, tar: 0.1430 \n",
            "l0: 0.119464, l1: 0.121491, l2: 0.132669, l3: 0.152267, l4: 0.218704, l5: 0.330150, l6: 0.494736\n",
            "\n",
            "[epoch: 108/100000, batch: 624/1000, ite: 13453] train loss: 2.3205, accuracy: 90.8060%, tar: 0.1430 \n",
            "l0: 0.106425, l1: 0.107871, l2: 0.116950, l3: 0.137931, l4: 0.213063, l5: 0.341712, l6: 0.517545\n",
            "\n",
            "[epoch: 108/100000, batch: 632/1000, ite: 13454] train loss: 2.3203, accuracy: 91.4707%, tar: 0.1429 \n",
            "l0: 0.137219, l1: 0.138176, l2: 0.151252, l3: 0.185290, l4: 0.241058, l5: 0.340105, l6: 0.583057\n",
            "\n",
            "[epoch: 108/100000, batch: 640/1000, ite: 13455] train loss: 2.3203, accuracy: 89.7987%, tar: 0.1429 \n",
            "l0: 0.089728, l1: 0.092901, l2: 0.106408, l3: 0.145194, l4: 0.205953, l5: 0.340494, l6: 0.599653\n",
            "\n",
            "[epoch: 108/100000, batch: 648/1000, ite: 13456] train loss: 2.3203, accuracy: 90.4919%, tar: 0.1429 \n",
            "l0: 0.087825, l1: 0.090399, l2: 0.103909, l3: 0.130718, l4: 0.211839, l5: 0.321035, l6: 0.531036\n",
            "\n",
            "[epoch: 108/100000, batch: 656/1000, ite: 13457] train loss: 2.3200, accuracy: 91.6242%, tar: 0.1429 \n",
            "l0: 0.102192, l1: 0.102641, l2: 0.112057, l3: 0.130183, l4: 0.180305, l5: 0.268698, l6: 0.427564\n",
            "\n",
            "[epoch: 108/100000, batch: 664/1000, ite: 13458] train loss: 2.3196, accuracy: 91.7450%, tar: 0.1428 \n",
            "l0: 0.114000, l1: 0.116899, l2: 0.129407, l3: 0.162845, l4: 0.227284, l5: 0.352796, l6: 0.598169\n",
            "\n",
            "[epoch: 108/100000, batch: 672/1000, ite: 13459] train loss: 2.3196, accuracy: 90.3254%, tar: 0.1428 \n",
            "l0: 0.090595, l1: 0.092437, l2: 0.102457, l3: 0.125367, l4: 0.181455, l5: 0.300232, l6: 0.516848\n",
            "\n",
            "[epoch: 108/100000, batch: 680/1000, ite: 13460] train loss: 2.3194, accuracy: 91.5719%, tar: 0.1428 \n",
            "l0: 0.141788, l1: 0.145776, l2: 0.156787, l3: 0.188407, l4: 0.252634, l5: 0.369032, l6: 0.662443\n",
            "\n",
            "[epoch: 108/100000, batch: 688/1000, ite: 13461] train loss: 2.3195, accuracy: 89.8040%, tar: 0.1428 \n",
            "l0: 0.104695, l1: 0.104512, l2: 0.112631, l3: 0.130676, l4: 0.180907, l5: 0.262548, l6: 0.449842\n",
            "\n",
            "[epoch: 108/100000, batch: 696/1000, ite: 13462] train loss: 2.3192, accuracy: 91.7107%, tar: 0.1427 \n",
            "l0: 0.061459, l1: 0.063423, l2: 0.074730, l3: 0.097432, l4: 0.147117, l5: 0.227411, l6: 0.399027\n",
            "\n",
            "[epoch: 108/100000, batch: 704/1000, ite: 13463] train loss: 2.3186, accuracy: 92.9260%, tar: 0.1427 \n",
            "l0: 0.081810, l1: 0.082628, l2: 0.096893, l3: 0.120303, l4: 0.187197, l5: 0.288372, l6: 0.523901\n",
            "\n",
            "[epoch: 108/100000, batch: 712/1000, ite: 13464] train loss: 2.3183, accuracy: 92.2307%, tar: 0.1426 \n",
            "l0: 0.116179, l1: 0.117112, l2: 0.130836, l3: 0.152546, l4: 0.203895, l5: 0.324688, l6: 0.510167\n",
            "\n",
            "[epoch: 108/100000, batch: 720/1000, ite: 13465] train loss: 2.3181, accuracy: 91.0089%, tar: 0.1426 \n",
            "l0: 0.072483, l1: 0.073808, l2: 0.086043, l3: 0.110580, l4: 0.165861, l5: 0.257722, l6: 0.442311\n",
            "\n",
            "[epoch: 108/100000, batch: 728/1000, ite: 13466] train loss: 2.3177, accuracy: 92.8008%, tar: 0.1426 \n",
            "l0: 0.090898, l1: 0.091507, l2: 0.104530, l3: 0.132885, l4: 0.195678, l5: 0.320917, l6: 0.541055\n",
            "\n",
            "[epoch: 108/100000, batch: 736/1000, ite: 13467] train loss: 2.3175, accuracy: 91.9864%, tar: 0.1425 \n",
            "l0: 0.102042, l1: 0.103564, l2: 0.117396, l3: 0.145403, l4: 0.232667, l5: 0.364707, l6: 0.567455\n",
            "\n",
            "[epoch: 108/100000, batch: 744/1000, ite: 13468] train loss: 2.3174, accuracy: 90.3697%, tar: 0.1425 \n",
            "l0: 0.103397, l1: 0.106767, l2: 0.117618, l3: 0.138969, l4: 0.199107, l5: 0.317542, l6: 0.482160\n",
            "\n",
            "[epoch: 108/100000, batch: 752/1000, ite: 13469] train loss: 2.3172, accuracy: 91.8099%, tar: 0.1425 \n",
            "l0: 0.087424, l1: 0.087666, l2: 0.095574, l3: 0.115314, l4: 0.164618, l5: 0.248820, l6: 0.412605\n",
            "\n",
            "[epoch: 108/100000, batch: 760/1000, ite: 13470] train loss: 2.3167, accuracy: 92.0605%, tar: 0.1425 \n",
            "l0: 0.082874, l1: 0.082982, l2: 0.092236, l3: 0.117105, l4: 0.164581, l5: 0.276017, l6: 0.524142\n",
            "\n",
            "[epoch: 108/100000, batch: 768/1000, ite: 13471] train loss: 2.3164, accuracy: 92.9777%, tar: 0.1424 \n",
            "l0: 0.085150, l1: 0.086237, l2: 0.096720, l3: 0.124850, l4: 0.183820, l5: 0.270430, l6: 0.465900\n",
            "\n",
            "[epoch: 108/100000, batch: 776/1000, ite: 13472] train loss: 2.3160, accuracy: 92.6846%, tar: 0.1424 \n",
            "l0: 0.104830, l1: 0.106550, l2: 0.117294, l3: 0.143384, l4: 0.199328, l5: 0.279225, l6: 0.417474\n",
            "\n",
            "[epoch: 108/100000, batch: 784/1000, ite: 13473] train loss: 2.3157, accuracy: 92.6044%, tar: 0.1423 \n",
            "l0: 0.087653, l1: 0.091166, l2: 0.101749, l3: 0.121932, l4: 0.185368, l5: 0.278931, l6: 0.473687\n",
            "\n",
            "[epoch: 108/100000, batch: 792/1000, ite: 13474] train loss: 2.3153, accuracy: 93.6719%, tar: 0.1423 \n",
            "l0: 0.102304, l1: 0.105976, l2: 0.114126, l3: 0.138399, l4: 0.207833, l5: 0.297831, l6: 0.476403\n",
            "\n",
            "[epoch: 108/100000, batch: 800/1000, ite: 13475] train loss: 2.3151, accuracy: 93.1828%, tar: 0.1423 \n",
            "l0: 0.097644, l1: 0.098053, l2: 0.106823, l3: 0.125754, l4: 0.187157, l5: 0.272682, l6: 0.522456\n",
            "\n",
            "[epoch: 108/100000, batch: 808/1000, ite: 13476] train loss: 2.3148, accuracy: 91.8583%, tar: 0.1423 \n",
            "l0: 0.095126, l1: 0.094718, l2: 0.100989, l3: 0.115418, l4: 0.167082, l5: 0.272965, l6: 0.403596\n",
            "\n",
            "[epoch: 108/100000, batch: 816/1000, ite: 13477] train loss: 2.3144, accuracy: 93.3344%, tar: 0.1422 \n",
            "l0: 0.102935, l1: 0.104703, l2: 0.113538, l3: 0.130299, l4: 0.180633, l5: 0.261052, l6: 0.427905\n",
            "\n",
            "[epoch: 108/100000, batch: 824/1000, ite: 13478] train loss: 2.3140, accuracy: 92.4059%, tar: 0.1422 \n",
            "l0: 0.109527, l1: 0.110165, l2: 0.122978, l3: 0.154250, l4: 0.215753, l5: 0.343270, l6: 0.524587\n",
            "\n",
            "[epoch: 108/100000, batch: 832/1000, ite: 13479] train loss: 2.3139, accuracy: 90.2756%, tar: 0.1422 \n",
            "l0: 0.082130, l1: 0.082573, l2: 0.092830, l3: 0.121472, l4: 0.174179, l5: 0.258709, l6: 0.430275\n",
            "\n",
            "[epoch: 108/100000, batch: 840/1000, ite: 13480] train loss: 2.3134, accuracy: 92.5144%, tar: 0.1421 \n",
            "l0: 0.085295, l1: 0.087445, l2: 0.096002, l3: 0.113665, l4: 0.153275, l5: 0.212488, l6: 0.396617\n",
            "\n",
            "[epoch: 108/100000, batch: 848/1000, ite: 13481] train loss: 2.3129, accuracy: 93.0557%, tar: 0.1421 \n",
            "l0: 0.104872, l1: 0.107589, l2: 0.116759, l3: 0.140321, l4: 0.184552, l5: 0.291258, l6: 0.479700\n",
            "\n",
            "[epoch: 108/100000, batch: 856/1000, ite: 13482] train loss: 2.3126, accuracy: 91.4572%, tar: 0.1421 \n",
            "l0: 0.095920, l1: 0.097559, l2: 0.104391, l3: 0.123370, l4: 0.169980, l5: 0.261966, l6: 0.504732\n",
            "\n",
            "[epoch: 108/100000, batch: 864/1000, ite: 13483] train loss: 2.3123, accuracy: 91.3285%, tar: 0.1420 \n",
            "l0: 0.119417, l1: 0.113121, l2: 0.121667, l3: 0.138369, l4: 0.176430, l5: 0.251870, l6: 0.434151\n",
            "\n",
            "[epoch: 108/100000, batch: 872/1000, ite: 13484] train loss: 2.3120, accuracy: 91.3284%, tar: 0.1420 \n",
            "l0: 0.124867, l1: 0.122993, l2: 0.134994, l3: 0.155292, l4: 0.217164, l5: 0.329951, l6: 0.516030\n",
            "\n",
            "[epoch: 108/100000, batch: 880/1000, ite: 13485] train loss: 2.3119, accuracy: 89.7061%, tar: 0.1420 \n",
            "l0: 0.094777, l1: 0.094430, l2: 0.102648, l3: 0.130609, l4: 0.188811, l5: 0.329581, l6: 0.475421\n",
            "\n",
            "[epoch: 108/100000, batch: 888/1000, ite: 13486] train loss: 2.3116, accuracy: 91.7712%, tar: 0.1420 \n",
            "l0: 0.076607, l1: 0.079764, l2: 0.090586, l3: 0.124690, l4: 0.201401, l5: 0.347254, l6: 0.554898\n",
            "\n",
            "[epoch: 108/100000, batch: 896/1000, ite: 13487] train loss: 2.3114, accuracy: 92.0961%, tar: 0.1419 \n",
            "l0: 0.081622, l1: 0.082521, l2: 0.094436, l3: 0.128481, l4: 0.218925, l5: 0.362992, l6: 0.632913\n",
            "\n",
            "[epoch: 108/100000, batch: 904/1000, ite: 13488] train loss: 2.3113, accuracy: 91.3010%, tar: 0.1419 \n",
            "l0: 0.092334, l1: 0.094018, l2: 0.109321, l3: 0.142073, l4: 0.191009, l5: 0.291510, l6: 0.472015\n",
            "\n",
            "[epoch: 108/100000, batch: 912/1000, ite: 13489] train loss: 2.3110, accuracy: 91.1387%, tar: 0.1419 \n",
            "l0: 0.082711, l1: 0.084229, l2: 0.092637, l3: 0.112953, l4: 0.164003, l5: 0.270569, l6: 0.552053\n",
            "\n",
            "[epoch: 108/100000, batch: 920/1000, ite: 13490] train loss: 2.3108, accuracy: 91.4968%, tar: 0.1418 \n",
            "l0: 0.102325, l1: 0.103905, l2: 0.115360, l3: 0.140527, l4: 0.203090, l5: 0.296316, l6: 0.502171\n",
            "\n",
            "[epoch: 108/100000, batch: 928/1000, ite: 13491] train loss: 2.3105, accuracy: 91.8719%, tar: 0.1418 \n",
            "l0: 0.113480, l1: 0.113522, l2: 0.123086, l3: 0.143777, l4: 0.176392, l5: 0.260578, l6: 0.442858\n",
            "\n",
            "[epoch: 108/100000, batch: 936/1000, ite: 13492] train loss: 2.3102, accuracy: 91.0454%, tar: 0.1418 \n",
            "l0: 0.052840, l1: 0.054345, l2: 0.062943, l3: 0.083140, l4: 0.116664, l5: 0.176019, l6: 0.305801\n",
            "\n",
            "[epoch: 108/100000, batch: 944/1000, ite: 13493] train loss: 2.3094, accuracy: 95.8337%, tar: 0.1417 \n",
            "l0: 0.096244, l1: 0.096731, l2: 0.108596, l3: 0.125457, l4: 0.182872, l5: 0.294643, l6: 0.464118\n",
            "\n",
            "[epoch: 108/100000, batch: 952/1000, ite: 13494] train loss: 2.3091, accuracy: 91.7355%, tar: 0.1417 \n",
            "l0: 0.084733, l1: 0.086153, l2: 0.097727, l3: 0.126005, l4: 0.189583, l5: 0.276673, l6: 0.504989\n",
            "\n",
            "[epoch: 108/100000, batch: 960/1000, ite: 13495] train loss: 2.3088, accuracy: 91.9744%, tar: 0.1416 \n",
            "l0: 0.107802, l1: 0.109060, l2: 0.119137, l3: 0.147816, l4: 0.208162, l5: 0.317507, l6: 0.528425\n",
            "\n",
            "[epoch: 108/100000, batch: 968/1000, ite: 13496] train loss: 2.3087, accuracy: 91.8347%, tar: 0.1416 \n",
            "l0: 0.093927, l1: 0.096007, l2: 0.105964, l3: 0.125225, l4: 0.168596, l5: 0.260565, l6: 0.441425\n",
            "\n",
            "[epoch: 108/100000, batch: 976/1000, ite: 13497] train loss: 2.3083, accuracy: 93.2345%, tar: 0.1416 \n",
            "l0: 0.068399, l1: 0.069634, l2: 0.080588, l3: 0.108450, l4: 0.164600, l5: 0.286462, l6: 0.489948\n",
            "\n",
            "[epoch: 108/100000, batch: 984/1000, ite: 13498] train loss: 2.3079, accuracy: 92.9713%, tar: 0.1415 \n",
            "l0: 0.067085, l1: 0.068677, l2: 0.078873, l3: 0.106006, l4: 0.166017, l5: 0.257760, l6: 0.441433\n",
            "\n",
            "[epoch: 108/100000, batch: 992/1000, ite: 13499] train loss: 2.3075, accuracy: 92.6664%, tar: 0.1415 \n",
            "l0: 0.062424, l1: 0.064581, l2: 0.071266, l3: 0.090137, l4: 0.133177, l5: 0.219404, l6: 0.394321\n",
            "\n",
            "[epoch: 108/100000, batch: 1000/1000, ite: 13500] train loss: 2.3069, accuracy: 92.4385%, tar: 0.1414 \n",
            "l0: 0.089208, l1: 0.092137, l2: 0.104555, l3: 0.139416, l4: 0.196467, l5: 0.307404, l6: 0.534388\n",
            "\n",
            "[epoch: 109/100000, batch: 8/1000, ite: 13501] train loss: 2.3067, accuracy: 90.9096%, tar: 0.1414 \n",
            "l0: 0.077541, l1: 0.080724, l2: 0.092024, l3: 0.109861, l4: 0.152308, l5: 0.227801, l6: 0.381407\n",
            "\n",
            "[epoch: 109/100000, batch: 16/1000, ite: 13502] train loss: 2.3062, accuracy: 92.3170%, tar: 0.1414 \n",
            "l0: 0.087048, l1: 0.087860, l2: 0.099730, l3: 0.121024, l4: 0.175039, l5: 0.275957, l6: 0.461571\n",
            "\n",
            "[epoch: 109/100000, batch: 24/1000, ite: 13503] train loss: 2.3058, accuracy: 92.2884%, tar: 0.1413 \n",
            "l0: 0.081367, l1: 0.082671, l2: 0.090364, l3: 0.111576, l4: 0.157973, l5: 0.257495, l6: 0.366471\n",
            "\n",
            "[epoch: 109/100000, batch: 32/1000, ite: 13504] train loss: 2.3053, accuracy: 93.2257%, tar: 0.1413 \n",
            "l0: 0.080755, l1: 0.080792, l2: 0.089982, l3: 0.113312, l4: 0.162522, l5: 0.255602, l6: 0.477911\n",
            "\n",
            "[epoch: 109/100000, batch: 40/1000, ite: 13505] train loss: 2.3049, accuracy: 92.6328%, tar: 0.1412 \n",
            "l0: 0.079244, l1: 0.080318, l2: 0.090319, l3: 0.112957, l4: 0.170903, l5: 0.276393, l6: 0.475348\n",
            "\n",
            "[epoch: 109/100000, batch: 48/1000, ite: 13506] train loss: 2.3045, accuracy: 92.9227%, tar: 0.1412 \n",
            "l0: 0.080909, l1: 0.081916, l2: 0.092039, l3: 0.117190, l4: 0.181582, l5: 0.326922, l6: 0.483769\n",
            "\n",
            "[epoch: 109/100000, batch: 56/1000, ite: 13507] train loss: 2.3042, accuracy: 91.7421%, tar: 0.1412 \n",
            "l0: 0.076371, l1: 0.078942, l2: 0.092518, l3: 0.127196, l4: 0.193206, l5: 0.304091, l6: 0.515041\n",
            "\n",
            "[epoch: 109/100000, batch: 64/1000, ite: 13508] train loss: 2.3039, accuracy: 92.0332%, tar: 0.1411 \n",
            "l0: 0.139223, l1: 0.141329, l2: 0.155486, l3: 0.194251, l4: 0.290161, l5: 0.473422, l6: 0.693543\n",
            "\n",
            "[epoch: 109/100000, batch: 72/1000, ite: 13509] train loss: 2.3043, accuracy: 89.6898%, tar: 0.1411 \n",
            "l0: 0.103962, l1: 0.106625, l2: 0.121094, l3: 0.147056, l4: 0.216272, l5: 0.343864, l6: 0.596560\n",
            "\n",
            "[epoch: 109/100000, batch: 80/1000, ite: 13510] train loss: 2.3042, accuracy: 89.6286%, tar: 0.1411 \n",
            "l0: 0.081403, l1: 0.081819, l2: 0.090809, l3: 0.111963, l4: 0.163093, l5: 0.270226, l6: 0.469628\n",
            "\n",
            "[epoch: 109/100000, batch: 88/1000, ite: 13511] train loss: 2.3038, accuracy: 92.1534%, tar: 0.1411 \n",
            "l0: 0.090648, l1: 0.091607, l2: 0.104452, l3: 0.137031, l4: 0.205590, l5: 0.322974, l6: 0.588166\n",
            "\n",
            "[epoch: 109/100000, batch: 96/1000, ite: 13512] train loss: 2.3037, accuracy: 91.8204%, tar: 0.1410 \n",
            "l0: 0.076766, l1: 0.076711, l2: 0.089506, l3: 0.114226, l4: 0.165895, l5: 0.257595, l6: 0.436208\n",
            "\n",
            "[epoch: 109/100000, batch: 104/1000, ite: 13513] train loss: 2.3033, accuracy: 92.8543%, tar: 0.1410 \n",
            "l0: 0.111467, l1: 0.112552, l2: 0.121414, l3: 0.147618, l4: 0.193739, l5: 0.296702, l6: 0.464655\n",
            "\n",
            "[epoch: 109/100000, batch: 112/1000, ite: 13514] train loss: 2.3030, accuracy: 91.8667%, tar: 0.1410 \n",
            "l0: 0.079013, l1: 0.081684, l2: 0.091015, l3: 0.117714, l4: 0.178725, l5: 0.292082, l6: 0.502235\n",
            "\n",
            "[epoch: 109/100000, batch: 120/1000, ite: 13515] train loss: 2.3028, accuracy: 92.3497%, tar: 0.1409 \n",
            "l0: 0.087265, l1: 0.089124, l2: 0.102595, l3: 0.129173, l4: 0.202152, l5: 0.327180, l6: 0.496206\n",
            "\n",
            "[epoch: 109/100000, batch: 128/1000, ite: 13516] train loss: 2.3025, accuracy: 91.2112%, tar: 0.1409 \n",
            "l0: 0.098886, l1: 0.101070, l2: 0.111897, l3: 0.143410, l4: 0.203905, l5: 0.327125, l6: 0.493853\n",
            "\n",
            "[epoch: 109/100000, batch: 136/1000, ite: 13517] train loss: 2.3023, accuracy: 93.0806%, tar: 0.1409 \n",
            "l0: 0.076868, l1: 0.078054, l2: 0.088164, l3: 0.110622, l4: 0.170715, l5: 0.255362, l6: 0.387717\n",
            "\n",
            "[epoch: 109/100000, batch: 144/1000, ite: 13518] train loss: 2.3018, accuracy: 93.0767%, tar: 0.1408 \n",
            "l0: 0.098620, l1: 0.099611, l2: 0.109081, l3: 0.129576, l4: 0.178535, l5: 0.266043, l6: 0.424209\n",
            "\n",
            "[epoch: 109/100000, batch: 152/1000, ite: 13519] train loss: 2.3014, accuracy: 91.8605%, tar: 0.1408 \n",
            "l0: 0.092234, l1: 0.093771, l2: 0.103537, l3: 0.122088, l4: 0.165412, l5: 0.241843, l6: 0.405525\n",
            "\n",
            "[epoch: 109/100000, batch: 160/1000, ite: 13520] train loss: 2.3010, accuracy: 92.2533%, tar: 0.1408 \n",
            "l0: 0.085457, l1: 0.086683, l2: 0.098257, l3: 0.119867, l4: 0.168794, l5: 0.263912, l6: 0.495733\n",
            "\n",
            "[epoch: 109/100000, batch: 168/1000, ite: 13521] train loss: 2.3006, accuracy: 91.5636%, tar: 0.1407 \n",
            "l0: 0.116641, l1: 0.119500, l2: 0.130155, l3: 0.158309, l4: 0.231522, l5: 0.353592, l6: 0.522525\n",
            "\n",
            "[epoch: 109/100000, batch: 176/1000, ite: 13522] train loss: 2.3005, accuracy: 90.0241%, tar: 0.1407 \n",
            "l0: 0.087068, l1: 0.088646, l2: 0.100816, l3: 0.128491, l4: 0.172167, l5: 0.249204, l6: 0.382297\n",
            "\n",
            "[epoch: 109/100000, batch: 184/1000, ite: 13523] train loss: 2.3001, accuracy: 93.6206%, tar: 0.1407 \n",
            "l0: 0.077478, l1: 0.078672, l2: 0.089449, l3: 0.116148, l4: 0.182386, l5: 0.280565, l6: 0.445208\n",
            "\n",
            "[epoch: 109/100000, batch: 192/1000, ite: 13524] train loss: 2.2997, accuracy: 92.9392%, tar: 0.1406 \n",
            "l0: 0.079084, l1: 0.080844, l2: 0.089524, l3: 0.112205, l4: 0.163240, l5: 0.246591, l6: 0.414142\n",
            "\n",
            "[epoch: 109/100000, batch: 200/1000, ite: 13525] train loss: 2.2992, accuracy: 91.5565%, tar: 0.1406 \n",
            "l0: 0.101447, l1: 0.102297, l2: 0.113147, l3: 0.140309, l4: 0.213181, l5: 0.347106, l6: 0.586812\n",
            "\n",
            "[epoch: 109/100000, batch: 208/1000, ite: 13526] train loss: 2.2992, accuracy: 91.0474%, tar: 0.1406 \n",
            "l0: 0.085663, l1: 0.087485, l2: 0.097457, l3: 0.112617, l4: 0.158672, l5: 0.230487, l6: 0.426033\n",
            "\n",
            "[epoch: 109/100000, batch: 216/1000, ite: 13527] train loss: 2.2987, accuracy: 92.4678%, tar: 0.1405 \n",
            "l0: 0.071388, l1: 0.073245, l2: 0.078735, l3: 0.098886, l4: 0.138586, l5: 0.197133, l6: 0.320577\n",
            "\n",
            "[epoch: 109/100000, batch: 224/1000, ite: 13528] train loss: 2.2981, accuracy: 93.6947%, tar: 0.1405 \n",
            "l0: 0.082592, l1: 0.083692, l2: 0.095095, l3: 0.117857, l4: 0.156943, l5: 0.217276, l6: 0.370631\n",
            "\n",
            "[epoch: 109/100000, batch: 232/1000, ite: 13529] train loss: 2.2976, accuracy: 93.5076%, tar: 0.1404 \n",
            "l0: 0.082977, l1: 0.083701, l2: 0.092627, l3: 0.114307, l4: 0.166599, l5: 0.263014, l6: 0.408314\n",
            "\n",
            "[epoch: 109/100000, batch: 240/1000, ite: 13530] train loss: 2.2971, accuracy: 94.1580%, tar: 0.1404 \n",
            "l0: 0.093991, l1: 0.095277, l2: 0.108264, l3: 0.142665, l4: 0.227803, l5: 0.379222, l6: 0.630897\n",
            "\n",
            "[epoch: 109/100000, batch: 248/1000, ite: 13531] train loss: 2.2971, accuracy: 90.4149%, tar: 0.1404 \n",
            "l0: 0.061211, l1: 0.061967, l2: 0.068233, l3: 0.089710, l4: 0.136775, l5: 0.224102, l6: 0.408421\n",
            "\n",
            "[epoch: 109/100000, batch: 256/1000, ite: 13532] train loss: 2.2966, accuracy: 93.0096%, tar: 0.1403 \n",
            "l0: 0.120724, l1: 0.122909, l2: 0.133522, l3: 0.150837, l4: 0.192063, l5: 0.262555, l6: 0.468599\n",
            "\n",
            "[epoch: 109/100000, batch: 264/1000, ite: 13533] train loss: 2.2964, accuracy: 91.6844%, tar: 0.1403 \n",
            "l0: 0.086055, l1: 0.086649, l2: 0.099682, l3: 0.124039, l4: 0.202029, l5: 0.316834, l6: 0.553628\n",
            "\n",
            "[epoch: 109/100000, batch: 272/1000, ite: 13534] train loss: 2.2962, accuracy: 89.9823%, tar: 0.1403 \n",
            "l0: 0.164034, l1: 0.163628, l2: 0.180321, l3: 0.216765, l4: 0.306264, l5: 0.469162, l6: 0.781025\n",
            "\n",
            "[epoch: 109/100000, batch: 280/1000, ite: 13535] train loss: 2.2967, accuracy: 86.7999%, tar: 0.1403 \n",
            "l0: 0.074004, l1: 0.074674, l2: 0.084305, l3: 0.100689, l4: 0.142945, l5: 0.226145, l6: 0.419209\n",
            "\n",
            "[epoch: 109/100000, batch: 288/1000, ite: 13536] train loss: 2.2962, accuracy: 93.1879%, tar: 0.1402 \n",
            "l0: 0.125606, l1: 0.125739, l2: 0.135526, l3: 0.157866, l4: 0.209101, l5: 0.311717, l6: 0.532075\n",
            "\n",
            "[epoch: 109/100000, batch: 296/1000, ite: 13537] train loss: 2.2961, accuracy: 91.1637%, tar: 0.1402 \n",
            "l0: 0.069424, l1: 0.071280, l2: 0.082497, l3: 0.108104, l4: 0.150606, l5: 0.215620, l6: 0.374129\n",
            "\n",
            "[epoch: 109/100000, batch: 304/1000, ite: 13538] train loss: 2.2955, accuracy: 93.6952%, tar: 0.1402 \n",
            "l0: 0.064432, l1: 0.065655, l2: 0.075930, l3: 0.101566, l4: 0.149454, l5: 0.246638, l6: 0.526273\n",
            "\n",
            "[epoch: 109/100000, batch: 312/1000, ite: 13539] train loss: 2.2952, accuracy: 93.7352%, tar: 0.1401 \n",
            "l0: 0.090922, l1: 0.092332, l2: 0.101955, l3: 0.123440, l4: 0.179906, l5: 0.268616, l6: 0.399042\n",
            "\n",
            "[epoch: 109/100000, batch: 320/1000, ite: 13540] train loss: 2.2948, accuracy: 92.7572%, tar: 0.1401 \n",
            "l0: 0.060161, l1: 0.061912, l2: 0.071833, l3: 0.092216, l4: 0.135151, l5: 0.222869, l6: 0.375193\n",
            "\n",
            "[epoch: 109/100000, batch: 328/1000, ite: 13541] train loss: 2.2942, accuracy: 92.8253%, tar: 0.1401 \n",
            "l0: 0.154159, l1: 0.155684, l2: 0.168391, l3: 0.199344, l4: 0.261811, l5: 0.418703, l6: 0.618713\n",
            "\n",
            "[epoch: 109/100000, batch: 336/1000, ite: 13542] train loss: 2.2944, accuracy: 88.5241%, tar: 0.1401 \n",
            "l0: 0.119315, l1: 0.121056, l2: 0.130230, l3: 0.150532, l4: 0.206492, l5: 0.288364, l6: 0.441166\n",
            "\n",
            "[epoch: 109/100000, batch: 344/1000, ite: 13543] train loss: 2.2941, accuracy: 92.1657%, tar: 0.1401 \n",
            "l0: 0.085423, l1: 0.085609, l2: 0.097803, l3: 0.127031, l4: 0.185603, l5: 0.279283, l6: 0.451797\n",
            "\n",
            "[epoch: 109/100000, batch: 352/1000, ite: 13544] train loss: 2.2938, accuracy: 92.2943%, tar: 0.1400 \n",
            "l0: 0.064806, l1: 0.065769, l2: 0.073666, l3: 0.095218, l4: 0.155555, l5: 0.282997, l6: 0.446432\n",
            "\n",
            "[epoch: 109/100000, batch: 360/1000, ite: 13545] train loss: 2.2934, accuracy: 92.4011%, tar: 0.1400 \n",
            "l0: 0.071729, l1: 0.073059, l2: 0.082270, l3: 0.102505, l4: 0.158808, l5: 0.240038, l6: 0.396768\n",
            "\n",
            "[epoch: 109/100000, batch: 368/1000, ite: 13546] train loss: 2.2929, accuracy: 94.1479%, tar: 0.1399 \n",
            "l0: 0.064194, l1: 0.065118, l2: 0.071529, l3: 0.088323, l4: 0.127229, l5: 0.198959, l6: 0.356957\n",
            "\n",
            "[epoch: 109/100000, batch: 376/1000, ite: 13547] train loss: 2.2922, accuracy: 93.6060%, tar: 0.1399 \n",
            "l0: 0.118984, l1: 0.120986, l2: 0.132917, l3: 0.167224, l4: 0.236888, l5: 0.377887, l6: 0.609772\n",
            "\n",
            "[epoch: 109/100000, batch: 384/1000, ite: 13548] train loss: 2.2923, accuracy: 90.4778%, tar: 0.1399 \n",
            "l0: 0.056190, l1: 0.056908, l2: 0.063759, l3: 0.085640, l4: 0.130685, l5: 0.215091, l6: 0.393009\n",
            "\n",
            "[epoch: 109/100000, batch: 392/1000, ite: 13549] train loss: 2.2917, accuracy: 93.6487%, tar: 0.1398 \n",
            "l0: 0.100719, l1: 0.104497, l2: 0.116278, l3: 0.141978, l4: 0.198350, l5: 0.329440, l6: 0.546761\n",
            "\n",
            "[epoch: 109/100000, batch: 400/1000, ite: 13550] train loss: 2.2916, accuracy: 91.7948%, tar: 0.1398 \n",
            "l0: 0.106444, l1: 0.108548, l2: 0.118598, l3: 0.146409, l4: 0.224919, l5: 0.376285, l6: 0.672155\n",
            "\n",
            "[epoch: 109/100000, batch: 408/1000, ite: 13551] train loss: 2.2917, accuracy: 88.9586%, tar: 0.1398 \n",
            "l0: 0.087286, l1: 0.089034, l2: 0.099542, l3: 0.130810, l4: 0.190006, l5: 0.321818, l6: 0.610607\n",
            "\n",
            "[epoch: 109/100000, batch: 416/1000, ite: 13552] train loss: 2.2916, accuracy: 90.5890%, tar: 0.1397 \n",
            "l0: 0.079431, l1: 0.079817, l2: 0.089847, l3: 0.113493, l4: 0.167510, l5: 0.237495, l6: 0.423129\n",
            "\n",
            "[epoch: 109/100000, batch: 424/1000, ite: 13553] train loss: 2.2911, accuracy: 91.9840%, tar: 0.1397 \n",
            "l0: 0.085517, l1: 0.086937, l2: 0.097644, l3: 0.119105, l4: 0.178159, l5: 0.299962, l6: 0.475244\n",
            "\n",
            "[epoch: 109/100000, batch: 432/1000, ite: 13554] train loss: 2.2908, accuracy: 91.2917%, tar: 0.1397 \n",
            "l0: 0.078161, l1: 0.079216, l2: 0.091984, l3: 0.117726, l4: 0.183112, l5: 0.273263, l6: 0.444935\n",
            "\n",
            "[epoch: 109/100000, batch: 440/1000, ite: 13555] train loss: 2.2905, accuracy: 93.2950%, tar: 0.1396 \n",
            "l0: 0.099217, l1: 0.100102, l2: 0.109694, l3: 0.140358, l4: 0.205456, l5: 0.324537, l6: 0.536085\n",
            "\n",
            "[epoch: 109/100000, batch: 448/1000, ite: 13556] train loss: 2.2903, accuracy: 91.0142%, tar: 0.1396 \n",
            "l0: 0.096287, l1: 0.098159, l2: 0.112547, l3: 0.153374, l4: 0.253303, l5: 0.373440, l6: 0.552911\n",
            "\n",
            "[epoch: 109/100000, batch: 456/1000, ite: 13557] train loss: 2.2903, accuracy: 90.5447%, tar: 0.1396 \n",
            "l0: 0.110186, l1: 0.113257, l2: 0.128246, l3: 0.164112, l4: 0.239823, l5: 0.365512, l6: 0.575764\n",
            "\n",
            "[epoch: 109/100000, batch: 464/1000, ite: 13558] train loss: 2.2903, accuracy: 89.5495%, tar: 0.1395 \n",
            "l0: 0.111765, l1: 0.115173, l2: 0.129192, l3: 0.154245, l4: 0.224429, l5: 0.361503, l6: 0.637804\n",
            "\n",
            "[epoch: 109/100000, batch: 472/1000, ite: 13559] train loss: 2.2903, accuracy: 90.8525%, tar: 0.1395 \n",
            "l0: 0.073724, l1: 0.076205, l2: 0.088053, l3: 0.112339, l4: 0.173232, l5: 0.297662, l6: 0.458024\n",
            "\n",
            "[epoch: 109/100000, batch: 480/1000, ite: 13560] train loss: 2.2899, accuracy: 92.1582%, tar: 0.1395 \n",
            "l0: 0.096231, l1: 0.100248, l2: 0.113188, l3: 0.138836, l4: 0.202959, l5: 0.331884, l6: 0.544703\n",
            "\n",
            "[epoch: 109/100000, batch: 488/1000, ite: 13561] train loss: 2.2898, accuracy: 92.4218%, tar: 0.1395 \n",
            "l0: 0.063199, l1: 0.064739, l2: 0.078220, l3: 0.107436, l4: 0.175129, l5: 0.272574, l6: 0.461318\n",
            "\n",
            "[epoch: 109/100000, batch: 496/1000, ite: 13562] train loss: 2.2894, accuracy: 94.0076%, tar: 0.1394 \n",
            "l0: 0.085148, l1: 0.085448, l2: 0.098673, l3: 0.131407, l4: 0.211821, l5: 0.316476, l6: 0.517124\n",
            "\n",
            "[epoch: 109/100000, batch: 504/1000, ite: 13563] train loss: 2.2892, accuracy: 92.5078%, tar: 0.1394 \n",
            "l0: 0.091067, l1: 0.091170, l2: 0.102114, l3: 0.126379, l4: 0.190140, l5: 0.313245, l6: 0.501614\n",
            "\n",
            "[epoch: 109/100000, batch: 512/1000, ite: 13564] train loss: 2.2889, accuracy: 92.0809%, tar: 0.1393 \n",
            "l0: 0.089927, l1: 0.090084, l2: 0.101182, l3: 0.121924, l4: 0.163881, l5: 0.262085, l6: 0.443390\n",
            "\n",
            "[epoch: 109/100000, batch: 520/1000, ite: 13565] train loss: 2.2886, accuracy: 92.0153%, tar: 0.1393 \n",
            "l0: 0.101500, l1: 0.102413, l2: 0.114056, l3: 0.133443, l4: 0.189578, l5: 0.318203, l6: 0.521934\n",
            "\n",
            "[epoch: 109/100000, batch: 528/1000, ite: 13566] train loss: 2.2884, accuracy: 90.4089%, tar: 0.1393 \n",
            "l0: 0.040535, l1: 0.041812, l2: 0.048266, l3: 0.070617, l4: 0.118934, l5: 0.204163, l6: 0.372986\n",
            "\n",
            "[epoch: 109/100000, batch: 536/1000, ite: 13567] train loss: 2.2878, accuracy: 94.0723%, tar: 0.1392 \n",
            "l0: 0.094730, l1: 0.096474, l2: 0.109117, l3: 0.139402, l4: 0.224152, l5: 0.404319, l6: 0.614839\n",
            "\n",
            "[epoch: 109/100000, batch: 544/1000, ite: 13568] train loss: 2.2878, accuracy: 90.7125%, tar: 0.1392 \n",
            "l0: 0.091055, l1: 0.092512, l2: 0.101217, l3: 0.124283, l4: 0.190507, l5: 0.291221, l6: 0.492786\n",
            "\n",
            "[epoch: 109/100000, batch: 552/1000, ite: 13569] train loss: 2.2875, accuracy: 92.5457%, tar: 0.1392 \n",
            "l0: 0.095824, l1: 0.098590, l2: 0.107483, l3: 0.136813, l4: 0.194012, l5: 0.281249, l6: 0.438370\n",
            "\n",
            "[epoch: 109/100000, batch: 560/1000, ite: 13570] train loss: 2.2872, accuracy: 92.1763%, tar: 0.1391 \n",
            "l0: 0.097519, l1: 0.099383, l2: 0.110548, l3: 0.138358, l4: 0.203506, l5: 0.346925, l6: 0.656341\n",
            "\n",
            "[epoch: 109/100000, batch: 568/1000, ite: 13571] train loss: 2.2872, accuracy: 89.7262%, tar: 0.1391 \n",
            "l0: 0.093322, l1: 0.095020, l2: 0.107362, l3: 0.130385, l4: 0.197762, l5: 0.317337, l6: 0.496342\n",
            "\n",
            "[epoch: 109/100000, batch: 576/1000, ite: 13572] train loss: 2.2870, accuracy: 92.5783%, tar: 0.1391 \n",
            "l0: 0.097117, l1: 0.099256, l2: 0.108036, l3: 0.129731, l4: 0.179938, l5: 0.251873, l6: 0.385987\n",
            "\n",
            "[epoch: 109/100000, batch: 584/1000, ite: 13573] train loss: 2.2866, accuracy: 93.5754%, tar: 0.1391 \n",
            "l0: 0.079081, l1: 0.080032, l2: 0.092752, l3: 0.117260, l4: 0.184746, l5: 0.286129, l6: 0.485139\n",
            "\n",
            "[epoch: 109/100000, batch: 592/1000, ite: 13574] train loss: 2.2863, accuracy: 92.1406%, tar: 0.1390 \n",
            "l0: 0.058756, l1: 0.060233, l2: 0.069796, l3: 0.092133, l4: 0.144569, l5: 0.244410, l6: 0.403282\n",
            "\n",
            "[epoch: 109/100000, batch: 600/1000, ite: 13575] train loss: 2.2857, accuracy: 93.2557%, tar: 0.1390 \n",
            "l0: 0.092478, l1: 0.095440, l2: 0.107167, l3: 0.134110, l4: 0.211664, l5: 0.336222, l6: 0.537712\n",
            "\n",
            "[epoch: 109/100000, batch: 608/1000, ite: 13576] train loss: 2.2856, accuracy: 92.3239%, tar: 0.1389 \n",
            "l0: 0.097918, l1: 0.098687, l2: 0.112270, l3: 0.145913, l4: 0.216581, l5: 0.367454, l6: 0.689259\n",
            "\n",
            "[epoch: 109/100000, batch: 616/1000, ite: 13577] train loss: 2.2856, accuracy: 91.3601%, tar: 0.1389 \n",
            "l0: 0.086571, l1: 0.088814, l2: 0.098911, l3: 0.122520, l4: 0.192943, l5: 0.261017, l6: 0.438728\n",
            "\n",
            "[epoch: 109/100000, batch: 624/1000, ite: 13578] train loss: 2.2853, accuracy: 92.1047%, tar: 0.1389 \n",
            "l0: 0.082467, l1: 0.082277, l2: 0.089246, l3: 0.109643, l4: 0.156539, l5: 0.238388, l6: 0.393091\n",
            "\n",
            "[epoch: 109/100000, batch: 632/1000, ite: 13579] train loss: 2.2848, accuracy: 93.7641%, tar: 0.1388 \n",
            "l0: 0.098159, l1: 0.099088, l2: 0.109888, l3: 0.131600, l4: 0.189819, l5: 0.306730, l6: 0.674053\n",
            "\n",
            "[epoch: 109/100000, batch: 640/1000, ite: 13580] train loss: 2.2848, accuracy: 89.8118%, tar: 0.1388 \n",
            "l0: 0.088222, l1: 0.089022, l2: 0.096010, l3: 0.115737, l4: 0.149672, l5: 0.220363, l6: 0.393103\n",
            "\n",
            "[epoch: 109/100000, batch: 648/1000, ite: 13581] train loss: 2.2844, accuracy: 93.1429%, tar: 0.1388 \n",
            "l0: 0.095564, l1: 0.094690, l2: 0.102393, l3: 0.125553, l4: 0.170391, l5: 0.278139, l6: 0.545130\n",
            "\n",
            "[epoch: 109/100000, batch: 656/1000, ite: 13582] train loss: 2.2842, accuracy: 91.7678%, tar: 0.1388 \n",
            "l0: 0.103443, l1: 0.105232, l2: 0.115047, l3: 0.141571, l4: 0.197852, l5: 0.279538, l6: 0.468137\n",
            "\n",
            "[epoch: 109/100000, batch: 664/1000, ite: 13583] train loss: 2.2839, accuracy: 91.8959%, tar: 0.1387 \n",
            "l0: 0.065242, l1: 0.066510, l2: 0.078436, l3: 0.096187, l4: 0.151638, l5: 0.247333, l6: 0.396996\n",
            "\n",
            "[epoch: 109/100000, batch: 672/1000, ite: 13584] train loss: 2.2834, accuracy: 92.7673%, tar: 0.1387 \n",
            "l0: 0.102496, l1: 0.106382, l2: 0.116729, l3: 0.138046, l4: 0.185269, l5: 0.273808, l6: 0.525318\n",
            "\n",
            "[epoch: 109/100000, batch: 680/1000, ite: 13585] train loss: 2.2832, accuracy: 90.7219%, tar: 0.1387 \n",
            "l0: 0.091677, l1: 0.092886, l2: 0.103212, l3: 0.134694, l4: 0.201378, l5: 0.341111, l6: 0.560488\n",
            "\n",
            "[epoch: 109/100000, batch: 688/1000, ite: 13586] train loss: 2.2831, accuracy: 91.3805%, tar: 0.1386 \n",
            "l0: 0.094821, l1: 0.095532, l2: 0.107489, l3: 0.138684, l4: 0.201100, l5: 0.317795, l6: 0.458693\n",
            "\n",
            "[epoch: 109/100000, batch: 696/1000, ite: 13587] train loss: 2.2828, accuracy: 92.0928%, tar: 0.1386 \n",
            "l0: 0.086741, l1: 0.088492, l2: 0.100219, l3: 0.126243, l4: 0.181151, l5: 0.305105, l6: 0.510359\n",
            "\n",
            "[epoch: 109/100000, batch: 704/1000, ite: 13588] train loss: 2.2826, accuracy: 92.3764%, tar: 0.1386 \n",
            "l0: 0.079270, l1: 0.079653, l2: 0.091869, l3: 0.122545, l4: 0.182751, l5: 0.302504, l6: 0.570151\n",
            "\n",
            "[epoch: 109/100000, batch: 712/1000, ite: 13589] train loss: 2.2824, accuracy: 91.2025%, tar: 0.1385 \n",
            "l0: 0.093348, l1: 0.093922, l2: 0.105156, l3: 0.119995, l4: 0.162019, l5: 0.239180, l6: 0.330140\n",
            "\n",
            "[epoch: 109/100000, batch: 720/1000, ite: 13590] train loss: 2.2819, accuracy: 93.3672%, tar: 0.1385 \n",
            "l0: 0.093536, l1: 0.094560, l2: 0.102832, l3: 0.128806, l4: 0.184888, l5: 0.278254, l6: 0.425912\n",
            "\n",
            "[epoch: 109/100000, batch: 728/1000, ite: 13591] train loss: 2.2816, accuracy: 93.5969%, tar: 0.1385 \n",
            "l0: 0.102038, l1: 0.104056, l2: 0.112047, l3: 0.134456, l4: 0.176682, l5: 0.239053, l6: 0.405472\n",
            "\n",
            "[epoch: 109/100000, batch: 736/1000, ite: 13592] train loss: 2.2812, accuracy: 91.7923%, tar: 0.1385 \n",
            "l0: 0.062374, l1: 0.063472, l2: 0.071335, l3: 0.091564, l4: 0.130287, l5: 0.206970, l6: 0.356647\n",
            "\n",
            "[epoch: 109/100000, batch: 744/1000, ite: 13593] train loss: 2.2806, accuracy: 93.5986%, tar: 0.1384 \n",
            "l0: 0.091245, l1: 0.092164, l2: 0.100899, l3: 0.127027, l4: 0.184476, l5: 0.302031, l6: 0.570012\n",
            "\n",
            "[epoch: 109/100000, batch: 752/1000, ite: 13594] train loss: 2.2805, accuracy: 90.1815%, tar: 0.1384 \n",
            "l0: 0.053083, l1: 0.054166, l2: 0.064750, l3: 0.086334, l4: 0.140668, l5: 0.242198, l6: 0.388157\n",
            "\n",
            "[epoch: 109/100000, batch: 760/1000, ite: 13595] train loss: 2.2800, accuracy: 93.2590%, tar: 0.1383 \n",
            "l0: 0.102879, l1: 0.104477, l2: 0.117491, l3: 0.149284, l4: 0.204950, l5: 0.302971, l6: 0.486882\n",
            "\n",
            "[epoch: 109/100000, batch: 768/1000, ite: 13596] train loss: 2.2797, accuracy: 91.6165%, tar: 0.1383 \n",
            "l0: 0.076139, l1: 0.076534, l2: 0.086201, l3: 0.104283, l4: 0.145030, l5: 0.241461, l6: 0.412166\n",
            "\n",
            "[epoch: 109/100000, batch: 776/1000, ite: 13597] train loss: 2.2793, accuracy: 93.5097%, tar: 0.1383 \n",
            "l0: 0.091372, l1: 0.092231, l2: 0.102707, l3: 0.124117, l4: 0.176008, l5: 0.281136, l6: 0.515604\n",
            "\n",
            "[epoch: 109/100000, batch: 784/1000, ite: 13598] train loss: 2.2790, accuracy: 91.2144%, tar: 0.1382 \n",
            "l0: 0.087909, l1: 0.090358, l2: 0.102737, l3: 0.129241, l4: 0.181557, l5: 0.291887, l6: 0.464350\n",
            "\n",
            "[epoch: 109/100000, batch: 792/1000, ite: 13599] train loss: 2.2788, accuracy: 92.1912%, tar: 0.1382 \n",
            "l0: 0.066729, l1: 0.067962, l2: 0.078575, l3: 0.098881, l4: 0.152605, l5: 0.220444, l6: 0.342063\n",
            "\n",
            "[epoch: 109/100000, batch: 800/1000, ite: 13600] train loss: 2.2782, accuracy: 93.6444%, tar: 0.1382 \n",
            "l0: 0.085681, l1: 0.087808, l2: 0.100772, l3: 0.132502, l4: 0.214529, l5: 0.378263, l6: 0.592340\n",
            "\n",
            "[epoch: 109/100000, batch: 808/1000, ite: 13601] train loss: 2.2781, accuracy: 90.5587%, tar: 0.1381 \n",
            "l0: 0.075756, l1: 0.077251, l2: 0.084759, l3: 0.106844, l4: 0.158176, l5: 0.248386, l6: 0.392972\n",
            "\n",
            "[epoch: 109/100000, batch: 816/1000, ite: 13602] train loss: 2.2777, accuracy: 92.5608%, tar: 0.1381 \n",
            "l0: 0.103132, l1: 0.103367, l2: 0.115577, l3: 0.138306, l4: 0.203464, l5: 0.275939, l6: 0.432642\n",
            "\n",
            "[epoch: 109/100000, batch: 824/1000, ite: 13603] train loss: 2.2774, accuracy: 92.3904%, tar: 0.1381 \n",
            "l0: 0.078043, l1: 0.078210, l2: 0.087353, l3: 0.110825, l4: 0.156815, l5: 0.237394, l6: 0.471306\n",
            "\n",
            "[epoch: 109/100000, batch: 832/1000, ite: 13604] train loss: 2.2770, accuracy: 92.2948%, tar: 0.1380 \n",
            "l0: 0.091264, l1: 0.091803, l2: 0.102630, l3: 0.126456, l4: 0.190169, l5: 0.301695, l6: 0.519070\n",
            "\n",
            "[epoch: 109/100000, batch: 840/1000, ite: 13605] train loss: 2.2768, accuracy: 91.6340%, tar: 0.1380 \n",
            "l0: 0.080984, l1: 0.082297, l2: 0.091562, l3: 0.114751, l4: 0.184734, l5: 0.289700, l6: 0.442473\n",
            "\n",
            "[epoch: 109/100000, batch: 848/1000, ite: 13606] train loss: 2.2765, accuracy: 92.8315%, tar: 0.1380 \n",
            "l0: 0.108010, l1: 0.112067, l2: 0.124774, l3: 0.152573, l4: 0.217264, l5: 0.349552, l6: 0.521280\n",
            "\n",
            "[epoch: 109/100000, batch: 856/1000, ite: 13607] train loss: 2.2764, accuracy: 90.9327%, tar: 0.1379 \n",
            "l0: 0.104625, l1: 0.105188, l2: 0.119859, l3: 0.149825, l4: 0.214124, l5: 0.335162, l6: 0.546008\n",
            "\n",
            "[epoch: 109/100000, batch: 864/1000, ite: 13608] train loss: 2.2763, accuracy: 90.8786%, tar: 0.1379 \n",
            "l0: 0.082549, l1: 0.083336, l2: 0.096405, l3: 0.129791, l4: 0.219367, l5: 0.367355, l6: 0.621524\n",
            "\n",
            "[epoch: 109/100000, batch: 872/1000, ite: 13609] train loss: 2.2762, accuracy: 92.7017%, tar: 0.1379 \n",
            "l0: 0.088975, l1: 0.091185, l2: 0.098422, l3: 0.127139, l4: 0.197919, l5: 0.283361, l6: 0.467006\n",
            "\n",
            "[epoch: 109/100000, batch: 880/1000, ite: 13610] train loss: 2.2759, accuracy: 92.8575%, tar: 0.1379 \n",
            "l0: 0.136541, l1: 0.138744, l2: 0.150491, l3: 0.174782, l4: 0.250016, l5: 0.354707, l6: 0.615700\n",
            "\n",
            "[epoch: 109/100000, batch: 888/1000, ite: 13611] train loss: 2.2761, accuracy: 89.0513%, tar: 0.1379 \n",
            "l0: 0.078850, l1: 0.079946, l2: 0.090876, l3: 0.110568, l4: 0.156101, l5: 0.243485, l6: 0.376581\n",
            "\n",
            "[epoch: 109/100000, batch: 896/1000, ite: 13612] train loss: 2.2756, accuracy: 94.0052%, tar: 0.1378 \n",
            "l0: 0.066870, l1: 0.069202, l2: 0.078831, l3: 0.102147, l4: 0.155435, l5: 0.259492, l6: 0.446124\n",
            "\n",
            "[epoch: 109/100000, batch: 904/1000, ite: 13613] train loss: 2.2752, accuracy: 92.5786%, tar: 0.1378 \n",
            "l0: 0.090280, l1: 0.092775, l2: 0.099447, l3: 0.109700, l4: 0.146289, l5: 0.209892, l6: 0.316503\n",
            "\n",
            "[epoch: 109/100000, batch: 912/1000, ite: 13614] train loss: 2.2746, accuracy: 93.5766%, tar: 0.1378 \n",
            "l0: 0.080881, l1: 0.081707, l2: 0.092485, l3: 0.119983, l4: 0.184446, l5: 0.302197, l6: 0.475980\n",
            "\n",
            "[epoch: 109/100000, batch: 920/1000, ite: 13615] train loss: 2.2744, accuracy: 93.1424%, tar: 0.1377 \n",
            "l0: 0.069119, l1: 0.070704, l2: 0.081662, l3: 0.102977, l4: 0.148380, l5: 0.230485, l6: 0.365865\n",
            "\n",
            "[epoch: 109/100000, batch: 928/1000, ite: 13616] train loss: 2.2738, accuracy: 92.8798%, tar: 0.1377 \n",
            "l0: 0.086306, l1: 0.087305, l2: 0.094784, l3: 0.115348, l4: 0.165018, l5: 0.277867, l6: 0.467391\n",
            "\n",
            "[epoch: 109/100000, batch: 936/1000, ite: 13617] train loss: 2.2735, accuracy: 91.6462%, tar: 0.1376 \n",
            "l0: 0.090347, l1: 0.093789, l2: 0.106249, l3: 0.137686, l4: 0.213150, l5: 0.312119, l6: 0.502825\n",
            "\n",
            "[epoch: 109/100000, batch: 944/1000, ite: 13618] train loss: 2.2733, accuracy: 91.4150%, tar: 0.1376 \n",
            "l0: 0.082724, l1: 0.086299, l2: 0.100103, l3: 0.141122, l4: 0.216449, l5: 0.329673, l6: 0.515426\n",
            "\n",
            "[epoch: 109/100000, batch: 952/1000, ite: 13619] train loss: 2.2731, accuracy: 92.6648%, tar: 0.1376 \n",
            "l0: 0.078397, l1: 0.080251, l2: 0.091821, l3: 0.125512, l4: 0.200987, l5: 0.344236, l6: 0.524004\n",
            "\n",
            "[epoch: 109/100000, batch: 960/1000, ite: 13620] train loss: 2.2730, accuracy: 92.6034%, tar: 0.1375 \n",
            "l0: 0.081715, l1: 0.084446, l2: 0.094234, l3: 0.107757, l4: 0.152875, l5: 0.233082, l6: 0.364026\n",
            "\n",
            "[epoch: 109/100000, batch: 968/1000, ite: 13621] train loss: 2.2725, accuracy: 92.6229%, tar: 0.1375 \n",
            "l0: 0.079878, l1: 0.081203, l2: 0.091035, l3: 0.114332, l4: 0.156593, l5: 0.252344, l6: 0.439235\n",
            "\n",
            "[epoch: 109/100000, batch: 976/1000, ite: 13622] train loss: 2.2721, accuracy: 92.5921%, tar: 0.1375 \n",
            "l0: 0.101680, l1: 0.103040, l2: 0.111190, l3: 0.140602, l4: 0.224518, l5: 0.350126, l6: 0.511941\n",
            "\n",
            "[epoch: 109/100000, batch: 984/1000, ite: 13623] train loss: 2.2720, accuracy: 90.2578%, tar: 0.1374 \n",
            "l0: 0.073782, l1: 0.077240, l2: 0.086819, l3: 0.108670, l4: 0.148811, l5: 0.232080, l6: 0.436030\n",
            "\n",
            "[epoch: 109/100000, batch: 992/1000, ite: 13624] train loss: 2.2716, accuracy: 92.3699%, tar: 0.1374 \n",
            "l0: 0.071228, l1: 0.073043, l2: 0.080656, l3: 0.099859, l4: 0.148814, l5: 0.228850, l6: 0.417895\n",
            "\n",
            "[epoch: 109/100000, batch: 1000/1000, ite: 13625] train loss: 2.2711, accuracy: 92.3129%, tar: 0.1374 \n",
            "l0: 0.105377, l1: 0.106608, l2: 0.112996, l3: 0.131785, l4: 0.189898, l5: 0.280583, l6: 0.433635\n",
            "\n",
            "[epoch: 110/100000, batch: 8/1000, ite: 13626] train loss: 2.2708, accuracy: 92.4812%, tar: 0.1373 \n",
            "l0: 0.082185, l1: 0.085476, l2: 0.099990, l3: 0.128816, l4: 0.211798, l5: 0.348076, l6: 0.545408\n",
            "\n",
            "[epoch: 110/100000, batch: 16/1000, ite: 13627] train loss: 2.2707, accuracy: 91.9748%, tar: 0.1373 \n",
            "l0: 0.077683, l1: 0.079633, l2: 0.089793, l3: 0.107819, l4: 0.148001, l5: 0.215728, l6: 0.362018\n",
            "\n",
            "[epoch: 110/100000, batch: 24/1000, ite: 13628] train loss: 2.2702, accuracy: 93.2383%, tar: 0.1373 \n",
            "l0: 0.106370, l1: 0.109413, l2: 0.122747, l3: 0.152653, l4: 0.219758, l5: 0.365750, l6: 0.562146\n",
            "\n",
            "[epoch: 110/100000, batch: 32/1000, ite: 13629] train loss: 2.2701, accuracy: 90.4010%, tar: 0.1373 \n",
            "l0: 0.095940, l1: 0.097110, l2: 0.110017, l3: 0.137738, l4: 0.215057, l5: 0.336218, l6: 0.532530\n",
            "\n",
            "[epoch: 110/100000, batch: 40/1000, ite: 13630] train loss: 2.2700, accuracy: 91.6621%, tar: 0.1372 \n",
            "l0: 0.097206, l1: 0.098826, l2: 0.112063, l3: 0.148849, l4: 0.221620, l5: 0.366490, l6: 0.599195\n",
            "\n",
            "[epoch: 110/100000, batch: 48/1000, ite: 13631] train loss: 2.2700, accuracy: 90.5755%, tar: 0.1372 \n",
            "l0: 0.090743, l1: 0.091775, l2: 0.100526, l3: 0.123392, l4: 0.180126, l5: 0.295196, l6: 0.536053\n",
            "\n",
            "[epoch: 110/100000, batch: 56/1000, ite: 13632] train loss: 2.2698, accuracy: 91.8840%, tar: 0.1372 \n",
            "l0: 0.086651, l1: 0.088565, l2: 0.099713, l3: 0.119214, l4: 0.170421, l5: 0.262438, l6: 0.442539\n",
            "\n",
            "[epoch: 110/100000, batch: 64/1000, ite: 13633] train loss: 2.2694, accuracy: 93.0644%, tar: 0.1372 \n",
            "l0: 0.088692, l1: 0.089042, l2: 0.096760, l3: 0.115924, l4: 0.168749, l5: 0.257979, l6: 0.457094\n",
            "\n",
            "[epoch: 110/100000, batch: 72/1000, ite: 13634] train loss: 2.2691, accuracy: 92.5334%, tar: 0.1371 \n",
            "l0: 0.070930, l1: 0.071632, l2: 0.080188, l3: 0.098796, l4: 0.148365, l5: 0.243745, l6: 0.381644\n",
            "\n",
            "[epoch: 110/100000, batch: 80/1000, ite: 13635] train loss: 2.2686, accuracy: 93.3788%, tar: 0.1371 \n",
            "l0: 0.071805, l1: 0.074247, l2: 0.086198, l3: 0.108449, l4: 0.151003, l5: 0.244714, l6: 0.379839\n",
            "\n",
            "[epoch: 110/100000, batch: 88/1000, ite: 13636] train loss: 2.2681, accuracy: 92.8879%, tar: 0.1370 \n",
            "l0: 0.091076, l1: 0.091097, l2: 0.101693, l3: 0.124782, l4: 0.186892, l5: 0.317248, l6: 0.556026\n",
            "\n",
            "[epoch: 110/100000, batch: 96/1000, ite: 13637] train loss: 2.2680, accuracy: 90.4494%, tar: 0.1370 \n",
            "l0: 0.072604, l1: 0.073360, l2: 0.084651, l3: 0.106628, l4: 0.162653, l5: 0.220804, l6: 0.367134\n",
            "\n",
            "[epoch: 110/100000, batch: 104/1000, ite: 13638] train loss: 2.2675, accuracy: 93.0201%, tar: 0.1370 \n",
            "l0: 0.093541, l1: 0.094809, l2: 0.107072, l3: 0.133270, l4: 0.190939, l5: 0.286902, l6: 0.467120\n",
            "\n",
            "[epoch: 110/100000, batch: 112/1000, ite: 13639] train loss: 2.2672, accuracy: 91.9376%, tar: 0.1369 \n",
            "l0: 0.092200, l1: 0.095179, l2: 0.109069, l3: 0.132197, l4: 0.193286, l5: 0.305397, l6: 0.560726\n",
            "\n",
            "[epoch: 110/100000, batch: 120/1000, ite: 13640] train loss: 2.2671, accuracy: 90.9273%, tar: 0.1369 \n",
            "l0: 0.073923, l1: 0.075211, l2: 0.085189, l3: 0.103346, l4: 0.145215, l5: 0.254188, l6: 0.489792\n",
            "\n",
            "[epoch: 110/100000, batch: 128/1000, ite: 13641] train loss: 2.2668, accuracy: 93.0752%, tar: 0.1369 \n",
            "l0: 0.064341, l1: 0.064709, l2: 0.075389, l3: 0.099443, l4: 0.148931, l5: 0.241056, l6: 0.438622\n",
            "\n",
            "[epoch: 110/100000, batch: 136/1000, ite: 13642] train loss: 2.2663, accuracy: 93.6107%, tar: 0.1368 \n",
            "l0: 0.073817, l1: 0.074018, l2: 0.086300, l3: 0.107247, l4: 0.160432, l5: 0.272781, l6: 0.492362\n",
            "\n",
            "[epoch: 110/100000, batch: 144/1000, ite: 13643] train loss: 2.2660, accuracy: 92.6653%, tar: 0.1368 \n",
            "l0: 0.100437, l1: 0.102819, l2: 0.118043, l3: 0.151575, l4: 0.222873, l5: 0.350242, l6: 0.673898\n",
            "\n",
            "[epoch: 110/100000, batch: 152/1000, ite: 13644] train loss: 2.2661, accuracy: 91.1541%, tar: 0.1368 \n",
            "l0: 0.056593, l1: 0.057658, l2: 0.067664, l3: 0.090386, l4: 0.150801, l5: 0.248436, l6: 0.434520\n",
            "\n",
            "[epoch: 110/100000, batch: 160/1000, ite: 13645] train loss: 2.2657, accuracy: 93.3379%, tar: 0.1367 \n",
            "l0: 0.096024, l1: 0.097865, l2: 0.107606, l3: 0.139921, l4: 0.221445, l5: 0.345254, l6: 0.533883\n",
            "\n",
            "[epoch: 110/100000, batch: 168/1000, ite: 13646] train loss: 2.2655, accuracy: 92.7070%, tar: 0.1367 \n",
            "l0: 0.075241, l1: 0.076043, l2: 0.084073, l3: 0.103081, l4: 0.162932, l5: 0.241402, l6: 0.401220\n",
            "\n",
            "[epoch: 110/100000, batch: 176/1000, ite: 13647] train loss: 2.2651, accuracy: 93.2723%, tar: 0.1367 \n",
            "l0: 0.119689, l1: 0.131860, l2: 0.150619, l3: 0.178173, l4: 0.238693, l5: 0.354879, l6: 0.562275\n",
            "\n",
            "[epoch: 110/100000, batch: 184/1000, ite: 13648] train loss: 2.2651, accuracy: 92.1619%, tar: 0.1367 \n",
            "l0: 0.119782, l1: 0.120638, l2: 0.134833, l3: 0.168201, l4: 0.239134, l5: 0.355432, l6: 0.490765\n",
            "\n",
            "[epoch: 110/100000, batch: 192/1000, ite: 13649] train loss: 2.2650, accuracy: 92.0081%, tar: 0.1366 \n",
            "l0: 0.095738, l1: 0.096528, l2: 0.110408, l3: 0.135938, l4: 0.197833, l5: 0.274894, l6: 0.490813\n",
            "\n",
            "[epoch: 110/100000, batch: 200/1000, ite: 13650] train loss: 2.2648, accuracy: 91.0011%, tar: 0.1366 \n",
            "l0: 0.067840, l1: 0.068896, l2: 0.081045, l3: 0.111362, l4: 0.166519, l5: 0.278829, l6: 0.460596\n",
            "\n",
            "[epoch: 110/100000, batch: 208/1000, ite: 13651] train loss: 2.2644, accuracy: 93.5465%, tar: 0.1366 \n",
            "l0: 0.077572, l1: 0.080372, l2: 0.092264, l3: 0.119376, l4: 0.191991, l5: 0.315248, l6: 0.564117\n",
            "\n",
            "[epoch: 110/100000, batch: 216/1000, ite: 13652] train loss: 2.2643, accuracy: 91.1454%, tar: 0.1365 \n",
            "l0: 0.086508, l1: 0.087354, l2: 0.096333, l3: 0.117127, l4: 0.178334, l5: 0.276244, l6: 0.479230\n",
            "\n",
            "[epoch: 110/100000, batch: 224/1000, ite: 13653] train loss: 2.2640, accuracy: 92.7888%, tar: 0.1365 \n",
            "l0: 0.076974, l1: 0.076761, l2: 0.088954, l3: 0.120444, l4: 0.212567, l5: 0.327399, l6: 0.502115\n",
            "\n",
            "[epoch: 110/100000, batch: 232/1000, ite: 13654] train loss: 2.2638, accuracy: 92.7807%, tar: 0.1365 \n",
            "l0: 0.087541, l1: 0.089980, l2: 0.098203, l3: 0.119942, l4: 0.164994, l5: 0.268916, l6: 0.538850\n",
            "\n",
            "[epoch: 110/100000, batch: 240/1000, ite: 13655] train loss: 2.2636, accuracy: 91.8243%, tar: 0.1364 \n",
            "l0: 0.075573, l1: 0.075932, l2: 0.087098, l3: 0.106861, l4: 0.140976, l5: 0.242504, l6: 0.345546\n",
            "\n",
            "[epoch: 110/100000, batch: 248/1000, ite: 13656] train loss: 2.2631, accuracy: 93.9882%, tar: 0.1364 \n",
            "l0: 0.118631, l1: 0.120862, l2: 0.135715, l3: 0.165209, l4: 0.238401, l5: 0.392094, l6: 0.660624\n",
            "\n",
            "[epoch: 110/100000, batch: 256/1000, ite: 13657] train loss: 2.2632, accuracy: 90.7032%, tar: 0.1364 \n",
            "l0: 0.086852, l1: 0.089057, l2: 0.096013, l3: 0.119053, l4: 0.159583, l5: 0.250550, l6: 0.424550\n",
            "\n",
            "[epoch: 110/100000, batch: 264/1000, ite: 13658] train loss: 2.2628, accuracy: 92.3857%, tar: 0.1364 \n",
            "l0: 0.091515, l1: 0.091664, l2: 0.101256, l3: 0.118907, l4: 0.159606, l5: 0.246374, l6: 0.378021\n",
            "\n",
            "[epoch: 110/100000, batch: 272/1000, ite: 13659] train loss: 2.2624, accuracy: 92.5341%, tar: 0.1363 \n",
            "l0: 0.089777, l1: 0.090385, l2: 0.102785, l3: 0.124456, l4: 0.172579, l5: 0.266263, l6: 0.615514\n",
            "\n",
            "[epoch: 110/100000, batch: 280/1000, ite: 13660] train loss: 2.2623, accuracy: 90.8767%, tar: 0.1363 \n",
            "l0: 0.084086, l1: 0.085443, l2: 0.092587, l3: 0.114228, l4: 0.165019, l5: 0.232711, l6: 0.375566\n",
            "\n",
            "[epoch: 110/100000, batch: 288/1000, ite: 13661] train loss: 2.2619, accuracy: 92.5231%, tar: 0.1363 \n",
            "l0: 0.073529, l1: 0.074869, l2: 0.085745, l3: 0.109838, l4: 0.167598, l5: 0.273715, l6: 0.511997\n",
            "\n",
            "[epoch: 110/100000, batch: 296/1000, ite: 13662] train loss: 2.2616, accuracy: 91.2301%, tar: 0.1362 \n",
            "l0: 0.066596, l1: 0.067912, l2: 0.075421, l3: 0.094089, l4: 0.130550, l5: 0.202757, l6: 0.371514\n",
            "\n",
            "[epoch: 110/100000, batch: 304/1000, ite: 13663] train loss: 2.2611, accuracy: 93.2773%, tar: 0.1362 \n",
            "l0: 0.096692, l1: 0.097377, l2: 0.107032, l3: 0.131706, l4: 0.186377, l5: 0.288604, l6: 0.515345\n",
            "\n",
            "[epoch: 110/100000, batch: 312/1000, ite: 13664] train loss: 2.2609, accuracy: 90.9004%, tar: 0.1362 \n",
            "l0: 0.090550, l1: 0.092027, l2: 0.104285, l3: 0.132990, l4: 0.194998, l5: 0.305534, l6: 0.498794\n",
            "\n",
            "[epoch: 110/100000, batch: 320/1000, ite: 13665] train loss: 2.2607, accuracy: 90.9422%, tar: 0.1362 \n",
            "l0: 0.086929, l1: 0.089281, l2: 0.101976, l3: 0.131834, l4: 0.210939, l5: 0.382669, l6: 0.542379\n",
            "\n",
            "[epoch: 110/100000, batch: 328/1000, ite: 13666] train loss: 2.2606, accuracy: 92.6150%, tar: 0.1361 \n",
            "l0: 0.113547, l1: 0.115660, l2: 0.129441, l3: 0.165973, l4: 0.214203, l5: 0.345792, l6: 0.644685\n",
            "\n",
            "[epoch: 110/100000, batch: 336/1000, ite: 13667] train loss: 2.2606, accuracy: 89.8970%, tar: 0.1361 \n",
            "l0: 0.122153, l1: 0.124944, l2: 0.143736, l3: 0.191673, l4: 0.280375, l5: 0.402892, l6: 0.642330\n",
            "\n",
            "[epoch: 110/100000, batch: 344/1000, ite: 13668] train loss: 2.2608, accuracy: 91.7669%, tar: 0.1361 \n",
            "l0: 0.096973, l1: 0.098583, l2: 0.107701, l3: 0.128594, l4: 0.181058, l5: 0.286159, l6: 0.459389\n",
            "\n",
            "[epoch: 110/100000, batch: 352/1000, ite: 13669] train loss: 2.2605, accuracy: 92.3697%, tar: 0.1361 \n",
            "l0: 0.078676, l1: 0.080031, l2: 0.089299, l3: 0.109981, l4: 0.152977, l5: 0.236669, l6: 0.396211\n",
            "\n",
            "[epoch: 110/100000, batch: 360/1000, ite: 13670] train loss: 2.2601, accuracy: 92.3548%, tar: 0.1360 \n",
            "l0: 0.058391, l1: 0.059388, l2: 0.066008, l3: 0.082886, l4: 0.124506, l5: 0.193219, l6: 0.345401\n",
            "\n",
            "[epoch: 110/100000, batch: 368/1000, ite: 13671] train loss: 2.2595, accuracy: 93.8555%, tar: 0.1360 \n",
            "l0: 0.087826, l1: 0.090164, l2: 0.102962, l3: 0.131214, l4: 0.202628, l5: 0.349104, l6: 0.567099\n",
            "\n",
            "[epoch: 110/100000, batch: 376/1000, ite: 13672] train loss: 2.2594, accuracy: 90.1119%, tar: 0.1360 \n",
            "l0: 0.076355, l1: 0.077350, l2: 0.088159, l3: 0.107987, l4: 0.147027, l5: 0.267686, l6: 0.399382\n",
            "\n",
            "[epoch: 110/100000, batch: 384/1000, ite: 13673] train loss: 2.2590, accuracy: 93.2363%, tar: 0.1359 \n",
            "l0: 0.099283, l1: 0.099897, l2: 0.111639, l3: 0.131973, l4: 0.189034, l5: 0.323616, l6: 0.575815\n",
            "\n",
            "[epoch: 110/100000, batch: 392/1000, ite: 13674] train loss: 2.2589, accuracy: 90.5315%, tar: 0.1359 \n",
            "l0: 0.085092, l1: 0.088658, l2: 0.097723, l3: 0.121010, l4: 0.169339, l5: 0.249189, l6: 0.457316\n",
            "\n",
            "[epoch: 110/100000, batch: 400/1000, ite: 13675] train loss: 2.2586, accuracy: 91.8972%, tar: 0.1359 \n",
            "l0: 0.081658, l1: 0.082020, l2: 0.093936, l3: 0.117331, l4: 0.169865, l5: 0.278029, l6: 0.459542\n",
            "\n",
            "[epoch: 110/100000, batch: 408/1000, ite: 13676] train loss: 2.2583, accuracy: 91.6367%, tar: 0.1358 \n",
            "l0: 0.079011, l1: 0.079294, l2: 0.090260, l3: 0.110063, l4: 0.147335, l5: 0.229379, l6: 0.473973\n",
            "\n",
            "[epoch: 110/100000, batch: 416/1000, ite: 13677] train loss: 2.2580, accuracy: 92.2947%, tar: 0.1358 \n",
            "l0: 0.078300, l1: 0.079193, l2: 0.091758, l3: 0.117716, l4: 0.188281, l5: 0.290408, l6: 0.485021\n",
            "\n",
            "[epoch: 110/100000, batch: 424/1000, ite: 13678] train loss: 2.2577, accuracy: 92.1795%, tar: 0.1358 \n",
            "l0: 0.067525, l1: 0.069206, l2: 0.079177, l3: 0.099867, l4: 0.136850, l5: 0.224937, l6: 0.388509\n",
            "\n",
            "[epoch: 110/100000, batch: 432/1000, ite: 13679] train loss: 2.2572, accuracy: 93.3722%, tar: 0.1357 \n",
            "l0: 0.088155, l1: 0.089718, l2: 0.100925, l3: 0.124226, l4: 0.176095, l5: 0.246151, l6: 0.357771\n",
            "\n",
            "[epoch: 110/100000, batch: 440/1000, ite: 13680] train loss: 2.2568, accuracy: 93.3902%, tar: 0.1357 \n",
            "l0: 0.071810, l1: 0.072068, l2: 0.084887, l3: 0.105264, l4: 0.147317, l5: 0.239508, l6: 0.456473\n",
            "\n",
            "[epoch: 110/100000, batch: 448/1000, ite: 13681] train loss: 2.2564, accuracy: 92.2133%, tar: 0.1357 \n",
            "l0: 0.074524, l1: 0.076032, l2: 0.082869, l3: 0.099886, l4: 0.134676, l5: 0.187872, l6: 0.338765\n",
            "\n",
            "[epoch: 110/100000, batch: 456/1000, ite: 13682] train loss: 2.2559, accuracy: 92.7832%, tar: 0.1356 \n",
            "l0: 0.069166, l1: 0.069655, l2: 0.081931, l3: 0.106382, l4: 0.158942, l5: 0.249765, l6: 0.384136\n",
            "\n",
            "[epoch: 110/100000, batch: 464/1000, ite: 13683] train loss: 2.2554, accuracy: 92.7581%, tar: 0.1356 \n",
            "l0: 0.077607, l1: 0.078552, l2: 0.089189, l3: 0.113411, l4: 0.165064, l5: 0.242847, l6: 0.423682\n",
            "\n",
            "[epoch: 110/100000, batch: 472/1000, ite: 13684] train loss: 2.2551, accuracy: 92.7853%, tar: 0.1356 \n",
            "l0: 0.083127, l1: 0.084144, l2: 0.095162, l3: 0.122451, l4: 0.188487, l5: 0.296154, l6: 0.513942\n",
            "\n",
            "[epoch: 110/100000, batch: 480/1000, ite: 13685] train loss: 2.2548, accuracy: 91.8968%, tar: 0.1355 \n",
            "l0: 0.054387, l1: 0.055570, l2: 0.065509, l3: 0.082427, l4: 0.115684, l5: 0.190556, l6: 0.330928\n",
            "\n",
            "[epoch: 110/100000, batch: 488/1000, ite: 13686] train loss: 2.2542, accuracy: 94.1964%, tar: 0.1355 \n",
            "l0: 0.072756, l1: 0.073970, l2: 0.084937, l3: 0.111528, l4: 0.166679, l5: 0.252474, l6: 0.432442\n",
            "\n",
            "[epoch: 110/100000, batch: 496/1000, ite: 13687] train loss: 2.2539, accuracy: 92.5963%, tar: 0.1354 \n",
            "l0: 0.096762, l1: 0.101290, l2: 0.120972, l3: 0.165860, l4: 0.265295, l5: 0.427741, l6: 0.822046\n",
            "\n",
            "[epoch: 110/100000, batch: 504/1000, ite: 13688] train loss: 2.2542, accuracy: 87.7462%, tar: 0.1354 \n",
            "l0: 0.098112, l1: 0.098455, l2: 0.105968, l3: 0.131816, l4: 0.194974, l5: 0.282302, l6: 0.506207\n",
            "\n",
            "[epoch: 110/100000, batch: 512/1000, ite: 13689] train loss: 2.2540, accuracy: 91.5312%, tar: 0.1354 \n",
            "l0: 0.085685, l1: 0.087599, l2: 0.098070, l3: 0.122816, l4: 0.190033, l5: 0.316484, l6: 0.556295\n",
            "\n",
            "[epoch: 110/100000, batch: 520/1000, ite: 13690] train loss: 2.2539, accuracy: 91.6913%, tar: 0.1354 \n",
            "l0: 0.079539, l1: 0.081565, l2: 0.090218, l3: 0.116305, l4: 0.175713, l5: 0.264622, l6: 0.443238\n",
            "\n",
            "[epoch: 110/100000, batch: 528/1000, ite: 13691] train loss: 2.2536, accuracy: 92.1359%, tar: 0.1353 \n",
            "l0: 0.110379, l1: 0.112875, l2: 0.122223, l3: 0.150341, l4: 0.213580, l5: 0.303749, l6: 0.468195\n",
            "\n",
            "[epoch: 110/100000, batch: 536/1000, ite: 13692] train loss: 2.2534, accuracy: 92.1545%, tar: 0.1353 \n",
            "l0: 0.062073, l1: 0.062666, l2: 0.072259, l3: 0.092436, l4: 0.133696, l5: 0.236199, l6: 0.395375\n",
            "\n",
            "[epoch: 110/100000, batch: 544/1000, ite: 13693] train loss: 2.2529, accuracy: 94.2958%, tar: 0.1353 \n",
            "l0: 0.082848, l1: 0.083595, l2: 0.092068, l3: 0.109919, l4: 0.153618, l5: 0.222585, l6: 0.370045\n",
            "\n",
            "[epoch: 110/100000, batch: 552/1000, ite: 13694] train loss: 2.2525, accuracy: 93.3802%, tar: 0.1352 \n",
            "l0: 0.095510, l1: 0.098858, l2: 0.112481, l3: 0.147983, l4: 0.225548, l5: 0.319893, l6: 0.542930\n",
            "\n",
            "[epoch: 110/100000, batch: 560/1000, ite: 13695] train loss: 2.2524, accuracy: 90.6683%, tar: 0.1352 \n",
            "l0: 0.072181, l1: 0.074788, l2: 0.088805, l3: 0.124580, l4: 0.190632, l5: 0.313056, l6: 0.531306\n",
            "\n",
            "[epoch: 110/100000, batch: 568/1000, ite: 13696] train loss: 2.2522, accuracy: 92.8545%, tar: 0.1352 \n",
            "l0: 0.072842, l1: 0.074771, l2: 0.081469, l3: 0.098140, l4: 0.148792, l5: 0.248221, l6: 0.439383\n",
            "\n",
            "[epoch: 110/100000, batch: 576/1000, ite: 13697] train loss: 2.2518, accuracy: 93.3805%, tar: 0.1352 \n",
            "l0: 0.088227, l1: 0.088727, l2: 0.098224, l3: 0.123199, l4: 0.163741, l5: 0.249298, l6: 0.448908\n",
            "\n",
            "[epoch: 110/100000, batch: 584/1000, ite: 13698] train loss: 2.2515, accuracy: 91.6849%, tar: 0.1351 \n",
            "l0: 0.084146, l1: 0.086167, l2: 0.095696, l3: 0.118390, l4: 0.172467, l5: 0.266514, l6: 0.530548\n",
            "\n",
            "[epoch: 110/100000, batch: 592/1000, ite: 13699] train loss: 2.2513, accuracy: 91.9947%, tar: 0.1351 \n",
            "l0: 0.079207, l1: 0.080293, l2: 0.093030, l3: 0.122718, l4: 0.194329, l5: 0.316069, l6: 0.537532\n",
            "\n",
            "[epoch: 110/100000, batch: 600/1000, ite: 13700] train loss: 2.2511, accuracy: 92.5623%, tar: 0.1351 \n",
            "l0: 0.069939, l1: 0.073261, l2: 0.083489, l3: 0.115696, l4: 0.180826, l5: 0.295904, l6: 0.498673\n",
            "\n",
            "[epoch: 110/100000, batch: 608/1000, ite: 13701] train loss: 2.2508, accuracy: 92.7603%, tar: 0.1350 \n",
            "l0: 0.072664, l1: 0.073940, l2: 0.082361, l3: 0.100303, l4: 0.134655, l5: 0.214116, l6: 0.404570\n",
            "\n",
            "[epoch: 110/100000, batch: 616/1000, ite: 13702] train loss: 2.2504, accuracy: 92.8838%, tar: 0.1350 \n",
            "l0: 0.071470, l1: 0.073569, l2: 0.084667, l3: 0.109627, l4: 0.160063, l5: 0.243500, l6: 0.397496\n",
            "\n",
            "[epoch: 110/100000, batch: 624/1000, ite: 13703] train loss: 2.2499, accuracy: 93.4592%, tar: 0.1349 \n",
            "l0: 0.088704, l1: 0.089544, l2: 0.101489, l3: 0.126717, l4: 0.187726, l5: 0.294739, l6: 0.434084\n",
            "\n",
            "[epoch: 110/100000, batch: 632/1000, ite: 13704] train loss: 2.2497, accuracy: 92.1790%, tar: 0.1349 \n",
            "l0: 0.116047, l1: 0.119185, l2: 0.133432, l3: 0.166070, l4: 0.250866, l5: 0.402086, l6: 0.661363\n",
            "\n",
            "[epoch: 110/100000, batch: 640/1000, ite: 13705] train loss: 2.2498, accuracy: 89.7910%, tar: 0.1349 \n",
            "l0: 0.093749, l1: 0.096917, l2: 0.105951, l3: 0.124215, l4: 0.175057, l5: 0.283443, l6: 0.489470\n",
            "\n",
            "[epoch: 110/100000, batch: 648/1000, ite: 13706] train loss: 2.2496, accuracy: 90.9243%, tar: 0.1349 \n",
            "l0: 0.056668, l1: 0.058265, l2: 0.067615, l3: 0.084442, l4: 0.125671, l5: 0.212312, l6: 0.407738\n",
            "\n",
            "[epoch: 110/100000, batch: 656/1000, ite: 13707] train loss: 2.2491, accuracy: 93.6382%, tar: 0.1348 \n",
            "l0: 0.090387, l1: 0.093785, l2: 0.109894, l3: 0.144836, l4: 0.214271, l5: 0.323131, l6: 0.483152\n",
            "\n",
            "[epoch: 110/100000, batch: 664/1000, ite: 13708] train loss: 2.2489, accuracy: 92.7932%, tar: 0.1348 \n",
            "l0: 0.084521, l1: 0.086570, l2: 0.097128, l3: 0.122900, l4: 0.190214, l5: 0.273999, l6: 0.438401\n",
            "\n",
            "[epoch: 110/100000, batch: 672/1000, ite: 13709] train loss: 2.2486, accuracy: 91.9950%, tar: 0.1348 \n",
            "l0: 0.089779, l1: 0.091791, l2: 0.103624, l3: 0.129500, l4: 0.203474, l5: 0.346945, l6: 0.528405\n",
            "\n",
            "[epoch: 110/100000, batch: 680/1000, ite: 13710] train loss: 2.2485, accuracy: 90.8838%, tar: 0.1348 \n",
            "l0: 0.080692, l1: 0.081826, l2: 0.092528, l3: 0.120471, l4: 0.168532, l5: 0.257223, l6: 0.443427\n",
            "\n",
            "[epoch: 110/100000, batch: 688/1000, ite: 13711] train loss: 2.2481, accuracy: 92.7272%, tar: 0.1347 \n",
            "l0: 0.064010, l1: 0.065417, l2: 0.073812, l3: 0.088696, l4: 0.126230, l5: 0.200228, l6: 0.361905\n",
            "\n",
            "[epoch: 110/100000, batch: 696/1000, ite: 13712] train loss: 2.2476, accuracy: 94.1488%, tar: 0.1347 \n",
            "l0: 0.077538, l1: 0.078639, l2: 0.089330, l3: 0.110288, l4: 0.154139, l5: 0.240189, l6: 0.436624\n",
            "\n",
            "[epoch: 110/100000, batch: 704/1000, ite: 13713] train loss: 2.2473, accuracy: 93.1283%, tar: 0.1347 \n",
            "l0: 0.095880, l1: 0.095204, l2: 0.102354, l3: 0.126714, l4: 0.187400, l5: 0.318681, l6: 0.484936\n",
            "\n",
            "[epoch: 110/100000, batch: 712/1000, ite: 13714] train loss: 2.2470, accuracy: 92.0449%, tar: 0.1346 \n",
            "l0: 0.118379, l1: 0.119603, l2: 0.128757, l3: 0.153161, l4: 0.206212, l5: 0.314145, l6: 0.488684\n",
            "\n",
            "[epoch: 110/100000, batch: 720/1000, ite: 13715] train loss: 2.2469, accuracy: 92.1464%, tar: 0.1346 \n",
            "l0: 0.075855, l1: 0.079011, l2: 0.090913, l3: 0.114549, l4: 0.166367, l5: 0.249515, l6: 0.445675\n",
            "\n",
            "[epoch: 110/100000, batch: 728/1000, ite: 13716] train loss: 2.2466, accuracy: 93.9281%, tar: 0.1346 \n",
            "l0: 0.067544, l1: 0.067953, l2: 0.075934, l3: 0.094600, l4: 0.162225, l5: 0.247326, l6: 0.421478\n",
            "\n",
            "[epoch: 110/100000, batch: 736/1000, ite: 13717] train loss: 2.2462, accuracy: 92.5793%, tar: 0.1345 \n",
            "l0: 0.076766, l1: 0.078568, l2: 0.085913, l3: 0.106305, l4: 0.152407, l5: 0.242114, l6: 0.441289\n",
            "\n",
            "[epoch: 110/100000, batch: 744/1000, ite: 13718] train loss: 2.2458, accuracy: 92.2460%, tar: 0.1345 \n",
            "l0: 0.071751, l1: 0.072115, l2: 0.081738, l3: 0.108088, l4: 0.163240, l5: 0.257411, l6: 0.398299\n",
            "\n",
            "[epoch: 110/100000, batch: 752/1000, ite: 13719] train loss: 2.2454, accuracy: 93.9379%, tar: 0.1345 \n",
            "l0: 0.091526, l1: 0.091749, l2: 0.103692, l3: 0.134872, l4: 0.202580, l5: 0.304761, l6: 0.492719\n",
            "\n",
            "[epoch: 110/100000, batch: 760/1000, ite: 13720] train loss: 2.2452, accuracy: 91.8353%, tar: 0.1345 \n",
            "l0: 0.084037, l1: 0.085901, l2: 0.099132, l3: 0.127644, l4: 0.191171, l5: 0.290155, l6: 0.542059\n",
            "\n",
            "[epoch: 110/100000, batch: 768/1000, ite: 13721] train loss: 2.2450, accuracy: 91.6628%, tar: 0.1344 \n",
            "l0: 0.089515, l1: 0.090325, l2: 0.103581, l3: 0.132803, l4: 0.198338, l5: 0.310006, l6: 0.567769\n",
            "\n",
            "[epoch: 110/100000, batch: 776/1000, ite: 13722] train loss: 2.2449, accuracy: 90.2019%, tar: 0.1344 \n",
            "l0: 0.077639, l1: 0.078408, l2: 0.088726, l3: 0.111692, l4: 0.167744, l5: 0.238157, l6: 0.416648\n",
            "\n",
            "[epoch: 110/100000, batch: 784/1000, ite: 13723] train loss: 2.2446, accuracy: 93.7388%, tar: 0.1344 \n",
            "l0: 0.067898, l1: 0.067118, l2: 0.072975, l3: 0.086421, l4: 0.131820, l5: 0.220519, l6: 0.404498\n",
            "\n",
            "[epoch: 110/100000, batch: 792/1000, ite: 13724] train loss: 2.2441, accuracy: 93.4577%, tar: 0.1343 \n",
            "l0: 0.076331, l1: 0.077099, l2: 0.088974, l3: 0.113104, l4: 0.175200, l5: 0.280940, l6: 0.491406\n",
            "\n",
            "[epoch: 110/100000, batch: 800/1000, ite: 13725] train loss: 2.2439, accuracy: 91.8879%, tar: 0.1343 \n",
            "l0: 0.071480, l1: 0.073005, l2: 0.082796, l3: 0.106711, l4: 0.159207, l5: 0.220151, l6: 0.373220\n",
            "\n",
            "[epoch: 110/100000, batch: 808/1000, ite: 13726] train loss: 2.2434, accuracy: 93.4889%, tar: 0.1343 \n",
            "l0: 0.092484, l1: 0.094784, l2: 0.105634, l3: 0.134134, l4: 0.208405, l5: 0.323093, l6: 0.514935\n",
            "\n",
            "[epoch: 110/100000, batch: 816/1000, ite: 13727] train loss: 2.2433, accuracy: 91.4384%, tar: 0.1342 \n",
            "l0: 0.065373, l1: 0.066294, l2: 0.076445, l3: 0.101391, l4: 0.161721, l5: 0.246336, l6: 0.428735\n",
            "\n",
            "[epoch: 110/100000, batch: 824/1000, ite: 13728] train loss: 2.2429, accuracy: 93.1322%, tar: 0.1342 \n",
            "l0: 0.074556, l1: 0.075114, l2: 0.086098, l3: 0.107512, l4: 0.156705, l5: 0.243050, l6: 0.478249\n",
            "\n",
            "[epoch: 110/100000, batch: 832/1000, ite: 13729] train loss: 2.2426, accuracy: 92.0761%, tar: 0.1342 \n",
            "l0: 0.094458, l1: 0.095361, l2: 0.105434, l3: 0.119574, l4: 0.183560, l5: 0.297677, l6: 0.473991\n",
            "\n",
            "[epoch: 110/100000, batch: 840/1000, ite: 13730] train loss: 2.2423, accuracy: 92.0922%, tar: 0.1341 \n",
            "l0: 0.064178, l1: 0.064966, l2: 0.072612, l3: 0.088719, l4: 0.124455, l5: 0.178998, l6: 0.332222\n",
            "\n",
            "[epoch: 110/100000, batch: 848/1000, ite: 13731] train loss: 2.2417, accuracy: 93.4381%, tar: 0.1341 \n",
            "l0: 0.068289, l1: 0.068651, l2: 0.080432, l3: 0.100395, l4: 0.147779, l5: 0.242997, l6: 0.434406\n",
            "\n",
            "[epoch: 110/100000, batch: 856/1000, ite: 13732] train loss: 2.2414, accuracy: 93.4337%, tar: 0.1341 \n",
            "l0: 0.076540, l1: 0.077061, l2: 0.086296, l3: 0.107311, l4: 0.156013, l5: 0.263028, l6: 0.488863\n",
            "\n",
            "[epoch: 110/100000, batch: 864/1000, ite: 13733] train loss: 2.2411, accuracy: 92.1213%, tar: 0.1340 \n",
            "l0: 0.072657, l1: 0.073833, l2: 0.087214, l3: 0.120905, l4: 0.188646, l5: 0.304631, l6: 0.432687\n",
            "\n",
            "[epoch: 110/100000, batch: 872/1000, ite: 13734] train loss: 2.2408, accuracy: 93.4038%, tar: 0.1340 \n",
            "l0: 0.073628, l1: 0.074574, l2: 0.085572, l3: 0.113881, l4: 0.167747, l5: 0.289610, l6: 0.568176\n",
            "\n",
            "[epoch: 110/100000, batch: 880/1000, ite: 13735] train loss: 2.2406, accuracy: 92.1784%, tar: 0.1340 \n",
            "l0: 0.080678, l1: 0.082117, l2: 0.096303, l3: 0.121749, l4: 0.175242, l5: 0.242656, l6: 0.414283\n",
            "\n",
            "[epoch: 110/100000, batch: 888/1000, ite: 13736] train loss: 2.2403, accuracy: 92.7531%, tar: 0.1339 \n",
            "l0: 0.074590, l1: 0.075384, l2: 0.085984, l3: 0.112806, l4: 0.177595, l5: 0.295617, l6: 0.562997\n",
            "\n",
            "[epoch: 110/100000, batch: 896/1000, ite: 13737] train loss: 2.2401, accuracy: 91.7496%, tar: 0.1339 \n",
            "l0: 0.098497, l1: 0.100281, l2: 0.112663, l3: 0.136072, l4: 0.200212, l5: 0.339557, l6: 0.526715\n",
            "\n",
            "[epoch: 110/100000, batch: 904/1000, ite: 13738] train loss: 2.2400, accuracy: 91.7007%, tar: 0.1339 \n",
            "l0: 0.066117, l1: 0.066905, l2: 0.080639, l3: 0.108555, l4: 0.165386, l5: 0.259477, l6: 0.435657\n",
            "\n",
            "[epoch: 110/100000, batch: 912/1000, ite: 13739] train loss: 2.2396, accuracy: 92.8851%, tar: 0.1338 \n",
            "l0: 0.082556, l1: 0.084119, l2: 0.097531, l3: 0.126125, l4: 0.199604, l5: 0.357318, l6: 0.605804\n",
            "\n",
            "[epoch: 110/100000, batch: 920/1000, ite: 13740] train loss: 2.2396, accuracy: 90.2975%, tar: 0.1338 \n",
            "l0: 0.086892, l1: 0.089107, l2: 0.104017, l3: 0.145669, l4: 0.216462, l5: 0.347176, l6: 0.544188\n",
            "\n",
            "[epoch: 110/100000, batch: 928/1000, ite: 13741] train loss: 2.2395, accuracy: 91.0227%, tar: 0.1338 \n",
            "l0: 0.109433, l1: 0.112777, l2: 0.124191, l3: 0.155689, l4: 0.211665, l5: 0.306508, l6: 0.482735\n",
            "\n",
            "[epoch: 110/100000, batch: 936/1000, ite: 13742] train loss: 2.2393, accuracy: 90.6256%, tar: 0.1338 \n",
            "l0: 0.097809, l1: 0.099874, l2: 0.111834, l3: 0.132557, l4: 0.200232, l5: 0.319234, l6: 0.497474\n",
            "\n",
            "[epoch: 110/100000, batch: 944/1000, ite: 13743] train loss: 2.2392, accuracy: 91.4658%, tar: 0.1337 \n",
            "l0: 0.087462, l1: 0.089849, l2: 0.101212, l3: 0.124829, l4: 0.179114, l5: 0.288936, l6: 0.489708\n",
            "\n",
            "[epoch: 110/100000, batch: 952/1000, ite: 13744] train loss: 2.2389, accuracy: 91.9307%, tar: 0.1337 \n",
            "l0: 0.083529, l1: 0.084960, l2: 0.097203, l3: 0.123384, l4: 0.196800, l5: 0.305839, l6: 0.486956\n",
            "\n",
            "[epoch: 110/100000, batch: 960/1000, ite: 13745] train loss: 2.2387, accuracy: 92.2017%, tar: 0.1337 \n",
            "l0: 0.114304, l1: 0.115274, l2: 0.125088, l3: 0.144720, l4: 0.206258, l5: 0.314679, l6: 0.529665\n",
            "\n",
            "[epoch: 110/100000, batch: 968/1000, ite: 13746] train loss: 2.2386, accuracy: 92.2535%, tar: 0.1337 \n",
            "l0: 0.056084, l1: 0.057163, l2: 0.065959, l3: 0.088916, l4: 0.142106, l5: 0.209264, l6: 0.354896\n",
            "\n",
            "[epoch: 110/100000, batch: 976/1000, ite: 13747] train loss: 2.2381, accuracy: 93.8345%, tar: 0.1336 \n",
            "l0: 0.077531, l1: 0.078401, l2: 0.087692, l3: 0.107702, l4: 0.158469, l5: 0.257794, l6: 0.459627\n",
            "\n",
            "[epoch: 110/100000, batch: 984/1000, ite: 13748] train loss: 2.2378, accuracy: 91.7535%, tar: 0.1336 \n",
            "l0: 0.113777, l1: 0.116307, l2: 0.130099, l3: 0.160438, l4: 0.216571, l5: 0.347842, l6: 0.567412\n",
            "\n",
            "[epoch: 110/100000, batch: 992/1000, ite: 13749] train loss: 2.2378, accuracy: 90.0136%, tar: 0.1336 \n",
            "l0: 0.092389, l1: 0.094969, l2: 0.107584, l3: 0.129325, l4: 0.174253, l5: 0.253362, l6: 0.411254\n",
            "\n",
            "[epoch: 110/100000, batch: 1000/1000, ite: 13750] train loss: 2.2375, accuracy: 92.4382%, tar: 0.1336 \n",
            "l0: 0.073397, l1: 0.074894, l2: 0.085413, l3: 0.114454, l4: 0.179571, l5: 0.288722, l6: 0.496921\n",
            "\n",
            "[epoch: 111/100000, batch: 8/1000, ite: 13751] train loss: 2.2372, accuracy: 92.2523%, tar: 0.1335 \n",
            "l0: 0.103801, l1: 0.106183, l2: 0.117640, l3: 0.148623, l4: 0.240518, l5: 0.403668, l6: 0.663554\n",
            "\n",
            "[epoch: 111/100000, batch: 16/1000, ite: 13752] train loss: 2.2374, accuracy: 89.3917%, tar: 0.1335 \n",
            "l0: 0.060237, l1: 0.060999, l2: 0.069894, l3: 0.093397, l4: 0.134809, l5: 0.222334, l6: 0.448645\n",
            "\n",
            "[epoch: 111/100000, batch: 24/1000, ite: 13753] train loss: 2.2370, accuracy: 92.5133%, tar: 0.1335 \n",
            "l0: 0.073624, l1: 0.076017, l2: 0.084381, l3: 0.107327, l4: 0.160966, l5: 0.260830, l6: 0.442324\n",
            "\n",
            "[epoch: 111/100000, batch: 32/1000, ite: 13754] train loss: 2.2366, accuracy: 92.9942%, tar: 0.1334 \n",
            "l0: 0.074001, l1: 0.075588, l2: 0.087246, l3: 0.116488, l4: 0.170575, l5: 0.258621, l6: 0.399381\n",
            "\n",
            "[epoch: 111/100000, batch: 40/1000, ite: 13755] train loss: 2.2363, accuracy: 92.6409%, tar: 0.1334 \n",
            "l0: 0.089227, l1: 0.089794, l2: 0.102108, l3: 0.129921, l4: 0.185009, l5: 0.317650, l6: 0.513145\n",
            "\n",
            "[epoch: 111/100000, batch: 48/1000, ite: 13756] train loss: 2.2361, accuracy: 91.7483%, tar: 0.1334 \n",
            "l0: 0.057586, l1: 0.058841, l2: 0.065890, l3: 0.087566, l4: 0.128574, l5: 0.189592, l6: 0.330212\n",
            "\n",
            "[epoch: 111/100000, batch: 56/1000, ite: 13757] train loss: 2.2355, accuracy: 93.7166%, tar: 0.1333 \n",
            "l0: 0.096672, l1: 0.097510, l2: 0.110767, l3: 0.153654, l4: 0.253382, l5: 0.425972, l6: 0.711890\n",
            "\n",
            "[epoch: 111/100000, batch: 64/1000, ite: 13758] train loss: 2.2357, accuracy: 89.6105%, tar: 0.1333 \n",
            "l0: 0.085826, l1: 0.087988, l2: 0.100461, l3: 0.128335, l4: 0.184099, l5: 0.350053, l6: 0.536561\n",
            "\n",
            "[epoch: 111/100000, batch: 72/1000, ite: 13759] train loss: 2.2356, accuracy: 91.5445%, tar: 0.1333 \n",
            "l0: 0.067807, l1: 0.069454, l2: 0.080626, l3: 0.106331, l4: 0.158563, l5: 0.271061, l6: 0.461721\n",
            "\n",
            "[epoch: 111/100000, batch: 80/1000, ite: 13760] train loss: 2.2352, accuracy: 92.6762%, tar: 0.1332 \n",
            "l0: 0.088185, l1: 0.090861, l2: 0.101715, l3: 0.130198, l4: 0.177781, l5: 0.259667, l6: 0.441692\n",
            "\n",
            "[epoch: 111/100000, batch: 88/1000, ite: 13761] train loss: 2.2350, accuracy: 91.8560%, tar: 0.1332 \n",
            "l0: 0.061101, l1: 0.062217, l2: 0.071113, l3: 0.090636, l4: 0.129458, l5: 0.219017, l6: 0.382065\n",
            "\n",
            "[epoch: 111/100000, batch: 96/1000, ite: 13762] train loss: 2.2345, accuracy: 93.6776%, tar: 0.1332 \n",
            "l0: 0.102119, l1: 0.104630, l2: 0.117112, l3: 0.143297, l4: 0.193485, l5: 0.277861, l6: 0.492350\n",
            "\n",
            "[epoch: 111/100000, batch: 104/1000, ite: 13763] train loss: 2.2343, accuracy: 91.2385%, tar: 0.1332 \n",
            "l0: 0.128538, l1: 0.129766, l2: 0.142585, l3: 0.174259, l4: 0.235996, l5: 0.365975, l6: 0.562225\n",
            "\n",
            "[epoch: 111/100000, batch: 112/1000, ite: 13764] train loss: 2.2344, accuracy: 89.9909%, tar: 0.1332 \n",
            "l0: 0.079195, l1: 0.081914, l2: 0.093361, l3: 0.123498, l4: 0.190989, l5: 0.293890, l6: 0.518250\n",
            "\n",
            "[epoch: 111/100000, batch: 120/1000, ite: 13765] train loss: 2.2342, accuracy: 91.1289%, tar: 0.1331 \n",
            "l0: 0.077641, l1: 0.078646, l2: 0.092257, l3: 0.119058, l4: 0.169192, l5: 0.296092, l6: 0.515459\n",
            "\n",
            "[epoch: 111/100000, batch: 128/1000, ite: 13766] train loss: 2.2340, accuracy: 90.9320%, tar: 0.1331 \n",
            "l0: 0.108643, l1: 0.108713, l2: 0.120994, l3: 0.148356, l4: 0.209263, l5: 0.335854, l6: 0.553732\n",
            "\n",
            "[epoch: 111/100000, batch: 136/1000, ite: 13767] train loss: 2.2339, accuracy: 92.3381%, tar: 0.1331 \n",
            "l0: 0.090385, l1: 0.091576, l2: 0.104590, l3: 0.132080, l4: 0.198808, l5: 0.297004, l6: 0.512901\n",
            "\n",
            "[epoch: 111/100000, batch: 144/1000, ite: 13768] train loss: 2.2337, accuracy: 91.9817%, tar: 0.1331 \n",
            "l0: 0.069204, l1: 0.071875, l2: 0.081842, l3: 0.101995, l4: 0.158805, l5: 0.244644, l6: 0.373847\n",
            "\n",
            "[epoch: 111/100000, batch: 152/1000, ite: 13769] train loss: 2.2333, accuracy: 93.8328%, tar: 0.1330 \n",
            "l0: 0.069080, l1: 0.071155, l2: 0.086900, l3: 0.116751, l4: 0.178496, l5: 0.261086, l6: 0.432305\n",
            "\n",
            "[epoch: 111/100000, batch: 160/1000, ite: 13770] train loss: 2.2330, accuracy: 93.4024%, tar: 0.1330 \n",
            "l0: 0.087500, l1: 0.090055, l2: 0.100959, l3: 0.124845, l4: 0.184058, l5: 0.279087, l6: 0.511634\n",
            "\n",
            "[epoch: 111/100000, batch: 168/1000, ite: 13771] train loss: 2.2328, accuracy: 91.9292%, tar: 0.1330 \n",
            "l0: 0.093183, l1: 0.098587, l2: 0.109361, l3: 0.140788, l4: 0.195538, l5: 0.252155, l6: 0.353998\n",
            "\n",
            "[epoch: 111/100000, batch: 176/1000, ite: 13772] train loss: 2.2324, accuracy: 92.4816%, tar: 0.1329 \n",
            "l0: 0.071835, l1: 0.072200, l2: 0.085933, l3: 0.116909, l4: 0.176935, l5: 0.301138, l6: 0.537616\n",
            "\n",
            "[epoch: 111/100000, batch: 184/1000, ite: 13773] train loss: 2.2322, accuracy: 91.5823%, tar: 0.1329 \n",
            "l0: 0.069329, l1: 0.071344, l2: 0.083332, l3: 0.113534, l4: 0.184922, l5: 0.280142, l6: 0.488425\n",
            "\n",
            "[epoch: 111/100000, batch: 192/1000, ite: 13774] train loss: 2.2319, accuracy: 92.1863%, tar: 0.1329 \n",
            "l0: 0.097734, l1: 0.098966, l2: 0.113641, l3: 0.141058, l4: 0.208632, l5: 0.369153, l6: 0.604712\n",
            "\n",
            "[epoch: 111/100000, batch: 200/1000, ite: 13775] train loss: 2.2320, accuracy: 89.6163%, tar: 0.1328 \n",
            "l0: 0.078817, l1: 0.079114, l2: 0.089429, l3: 0.109822, l4: 0.169823, l5: 0.264335, l6: 0.518128\n",
            "\n",
            "[epoch: 111/100000, batch: 208/1000, ite: 13776] train loss: 2.2317, accuracy: 91.7525%, tar: 0.1328 \n",
            "l0: 0.077852, l1: 0.079726, l2: 0.092146, l3: 0.118503, l4: 0.173746, l5: 0.275250, l6: 0.480767\n",
            "\n",
            "[epoch: 111/100000, batch: 216/1000, ite: 13777] train loss: 2.2315, accuracy: 91.2517%, tar: 0.1328 \n",
            "l0: 0.074972, l1: 0.074777, l2: 0.082657, l3: 0.105791, l4: 0.158166, l5: 0.257029, l6: 0.429887\n",
            "\n",
            "[epoch: 111/100000, batch: 224/1000, ite: 13778] train loss: 2.2311, accuracy: 92.6741%, tar: 0.1328 \n",
            "l0: 0.109325, l1: 0.110902, l2: 0.119086, l3: 0.137175, l4: 0.180794, l5: 0.278248, l6: 0.460139\n",
            "\n",
            "[epoch: 111/100000, batch: 232/1000, ite: 13779] train loss: 2.2309, accuracy: 92.2708%, tar: 0.1327 \n",
            "l0: 0.107659, l1: 0.117472, l2: 0.129025, l3: 0.157644, l4: 0.203270, l5: 0.276278, l6: 0.453989\n",
            "\n",
            "[epoch: 111/100000, batch: 240/1000, ite: 13780] train loss: 2.2307, accuracy: 91.7999%, tar: 0.1327 \n",
            "l0: 0.095480, l1: 0.096611, l2: 0.105276, l3: 0.124274, l4: 0.165121, l5: 0.240331, l6: 0.401752\n",
            "\n",
            "[epoch: 111/100000, batch: 248/1000, ite: 13781] train loss: 2.2304, accuracy: 91.5877%, tar: 0.1327 \n",
            "l0: 0.078856, l1: 0.079924, l2: 0.091746, l3: 0.113104, l4: 0.156415, l5: 0.237152, l6: 0.372045\n",
            "\n",
            "[epoch: 111/100000, batch: 256/1000, ite: 13782] train loss: 2.2300, accuracy: 93.5979%, tar: 0.1327 \n",
            "l0: 0.070902, l1: 0.072637, l2: 0.080342, l3: 0.101338, l4: 0.147456, l5: 0.209485, l6: 0.383978\n",
            "\n",
            "[epoch: 111/100000, batch: 264/1000, ite: 13783] train loss: 2.2295, accuracy: 93.8341%, tar: 0.1326 \n",
            "l0: 0.085772, l1: 0.088614, l2: 0.097973, l3: 0.115977, l4: 0.164357, l5: 0.243953, l6: 0.426701\n",
            "\n",
            "[epoch: 111/100000, batch: 272/1000, ite: 13784] train loss: 2.2292, accuracy: 93.2642%, tar: 0.1326 \n",
            "l0: 0.126884, l1: 0.126184, l2: 0.135097, l3: 0.151734, l4: 0.205596, l5: 0.301505, l6: 0.498835\n",
            "\n",
            "[epoch: 111/100000, batch: 280/1000, ite: 13785] train loss: 2.2291, accuracy: 91.3469%, tar: 0.1326 \n",
            "l0: 0.113194, l1: 0.115650, l2: 0.125659, l3: 0.147947, l4: 0.191356, l5: 0.236149, l6: 0.389461\n",
            "\n",
            "[epoch: 111/100000, batch: 288/1000, ite: 13786] train loss: 2.2288, accuracy: 92.5379%, tar: 0.1326 \n",
            "l0: 0.073535, l1: 0.076755, l2: 0.093370, l3: 0.125867, l4: 0.213348, l5: 0.334164, l6: 0.693811\n",
            "\n",
            "[epoch: 111/100000, batch: 296/1000, ite: 13787] train loss: 2.2289, accuracy: 90.8676%, tar: 0.1326 \n",
            "l0: 0.131098, l1: 0.131134, l2: 0.142052, l3: 0.172007, l4: 0.217827, l5: 0.348335, l6: 0.543679\n",
            "\n",
            "[epoch: 111/100000, batch: 304/1000, ite: 13788] train loss: 2.2289, accuracy: 91.0875%, tar: 0.1326 \n",
            "l0: 0.084128, l1: 0.086454, l2: 0.099805, l3: 0.126031, l4: 0.194372, l5: 0.340565, l6: 0.542701\n",
            "\n",
            "[epoch: 111/100000, batch: 312/1000, ite: 13789] train loss: 2.2288, accuracy: 91.6155%, tar: 0.1325 \n",
            "l0: 0.069951, l1: 0.071384, l2: 0.081039, l3: 0.105368, l4: 0.156082, l5: 0.225706, l6: 0.397343\n",
            "\n",
            "[epoch: 111/100000, batch: 320/1000, ite: 13790] train loss: 2.2284, accuracy: 92.6163%, tar: 0.1325 \n",
            "l0: 0.108631, l1: 0.110954, l2: 0.126209, l3: 0.154606, l4: 0.240146, l5: 0.375089, l6: 0.521454\n",
            "\n",
            "[epoch: 111/100000, batch: 328/1000, ite: 13791] train loss: 2.2283, accuracy: 91.2673%, tar: 0.1325 \n",
            "l0: 0.092470, l1: 0.094840, l2: 0.111869, l3: 0.137370, l4: 0.203280, l5: 0.304509, l6: 0.466725\n",
            "\n",
            "[epoch: 111/100000, batch: 336/1000, ite: 13792] train loss: 2.2281, accuracy: 92.9151%, tar: 0.1325 \n",
            "l0: 0.067114, l1: 0.068050, l2: 0.082526, l3: 0.113592, l4: 0.203365, l5: 0.304099, l6: 0.506957\n",
            "\n",
            "[epoch: 111/100000, batch: 344/1000, ite: 13793] train loss: 2.2279, accuracy: 92.1447%, tar: 0.1324 \n",
            "l0: 0.111175, l1: 0.113438, l2: 0.125910, l3: 0.144267, l4: 0.190197, l5: 0.282220, l6: 0.404311\n",
            "\n",
            "[epoch: 111/100000, batch: 352/1000, ite: 13794] train loss: 2.2277, accuracy: 92.5947%, tar: 0.1324 \n",
            "l0: 0.079421, l1: 0.080457, l2: 0.089624, l3: 0.114073, l4: 0.162060, l5: 0.266053, l6: 0.463658\n",
            "\n",
            "[epoch: 111/100000, batch: 360/1000, ite: 13795] train loss: 2.2274, accuracy: 91.8611%, tar: 0.1324 \n",
            "l0: 0.108662, l1: 0.109990, l2: 0.121731, l3: 0.144307, l4: 0.195360, l5: 0.291880, l6: 0.453972\n",
            "\n",
            "[epoch: 111/100000, batch: 368/1000, ite: 13796] train loss: 2.2272, accuracy: 92.4250%, tar: 0.1324 \n",
            "l0: 0.084014, l1: 0.085725, l2: 0.093728, l3: 0.117000, l4: 0.186297, l5: 0.302724, l6: 0.474580\n",
            "\n",
            "[epoch: 111/100000, batch: 376/1000, ite: 13797] train loss: 2.2269, accuracy: 92.2694%, tar: 0.1324 \n",
            "l0: 0.091741, l1: 0.092381, l2: 0.105467, l3: 0.129279, l4: 0.185829, l5: 0.309313, l6: 0.523428\n",
            "\n",
            "[epoch: 111/100000, batch: 384/1000, ite: 13798] train loss: 2.2268, accuracy: 90.4985%, tar: 0.1323 \n",
            "l0: 0.066617, l1: 0.068278, l2: 0.076791, l3: 0.102901, l4: 0.160636, l5: 0.247391, l6: 0.436029\n",
            "\n",
            "[epoch: 111/100000, batch: 392/1000, ite: 13799] train loss: 2.2264, accuracy: 92.8535%, tar: 0.1323 \n",
            "l0: 0.071244, l1: 0.074250, l2: 0.086609, l3: 0.116925, l4: 0.176374, l5: 0.269926, l6: 0.437042\n",
            "\n",
            "[epoch: 111/100000, batch: 400/1000, ite: 13800] train loss: 2.2261, accuracy: 94.1767%, tar: 0.1323 \n",
            "l0: 0.117774, l1: 0.118353, l2: 0.126666, l3: 0.155956, l4: 0.206560, l5: 0.257002, l6: 0.370652\n",
            "\n",
            "[epoch: 111/100000, batch: 408/1000, ite: 13801] train loss: 2.2259, accuracy: 92.0887%, tar: 0.1323 \n",
            "l0: 0.083534, l1: 0.085933, l2: 0.097335, l3: 0.131943, l4: 0.204729, l5: 0.306783, l6: 0.457508\n",
            "\n",
            "[epoch: 111/100000, batch: 416/1000, ite: 13802] train loss: 2.2256, accuracy: 92.0869%, tar: 0.1322 \n",
            "l0: 0.074586, l1: 0.075752, l2: 0.086154, l3: 0.106707, l4: 0.164133, l5: 0.250648, l6: 0.465424\n",
            "\n",
            "[epoch: 111/100000, batch: 424/1000, ite: 13803] train loss: 2.2253, accuracy: 91.7180%, tar: 0.1322 \n",
            "l0: 0.105196, l1: 0.107075, l2: 0.118313, l3: 0.137685, l4: 0.197611, l5: 0.304676, l6: 0.535300\n",
            "\n",
            "[epoch: 111/100000, batch: 432/1000, ite: 13804] train loss: 2.2252, accuracy: 92.7510%, tar: 0.1322 \n",
            "l0: 0.088299, l1: 0.089590, l2: 0.098030, l3: 0.117666, l4: 0.146042, l5: 0.234982, l6: 0.376091\n",
            "\n",
            "[epoch: 111/100000, batch: 440/1000, ite: 13805] train loss: 2.2248, accuracy: 93.6774%, tar: 0.1322 \n",
            "l0: 0.071642, l1: 0.071969, l2: 0.081465, l3: 0.104430, l4: 0.147774, l5: 0.208624, l6: 0.348816\n",
            "\n",
            "[epoch: 111/100000, batch: 448/1000, ite: 13806] train loss: 2.2244, accuracy: 93.3656%, tar: 0.1321 \n",
            "l0: 0.082375, l1: 0.080100, l2: 0.088672, l3: 0.109683, l4: 0.160676, l5: 0.275178, l6: 0.432830\n",
            "\n",
            "[epoch: 111/100000, batch: 456/1000, ite: 13807] train loss: 2.2241, accuracy: 92.3972%, tar: 0.1321 \n",
            "l0: 0.116949, l1: 0.117827, l2: 0.129923, l3: 0.150555, l4: 0.207767, l5: 0.290859, l6: 0.429467\n",
            "\n",
            "[epoch: 111/100000, batch: 464/1000, ite: 13808] train loss: 2.2239, accuracy: 91.5797%, tar: 0.1321 \n",
            "l0: 0.072212, l1: 0.074936, l2: 0.081632, l3: 0.104314, l4: 0.152690, l5: 0.225049, l6: 0.319108\n",
            "\n",
            "[epoch: 111/100000, batch: 472/1000, ite: 13809] train loss: 2.2234, accuracy: 94.5290%, tar: 0.1320 \n",
            "l0: 0.098404, l1: 0.099034, l2: 0.109456, l3: 0.138430, l4: 0.224422, l5: 0.372935, l6: 0.607933\n",
            "\n",
            "[epoch: 111/100000, batch: 480/1000, ite: 13810] train loss: 2.2234, accuracy: 91.4992%, tar: 0.1320 \n",
            "l0: 0.072532, l1: 0.073153, l2: 0.086396, l3: 0.109547, l4: 0.169128, l5: 0.273203, l6: 0.454640\n",
            "\n",
            "[epoch: 111/100000, batch: 488/1000, ite: 13811] train loss: 2.2231, accuracy: 92.9883%, tar: 0.1320 \n",
            "l0: 0.129965, l1: 0.130734, l2: 0.146209, l3: 0.183340, l4: 0.272754, l5: 0.376068, l6: 0.584585\n",
            "\n",
            "[epoch: 111/100000, batch: 496/1000, ite: 13812] train loss: 2.2232, accuracy: 90.1802%, tar: 0.1320 \n",
            "l0: 0.060015, l1: 0.061949, l2: 0.072593, l3: 0.100523, l4: 0.160144, l5: 0.298426, l6: 0.497005\n",
            "\n",
            "[epoch: 111/100000, batch: 504/1000, ite: 13813] train loss: 2.2230, accuracy: 92.8717%, tar: 0.1320 \n",
            "l0: 0.111946, l1: 0.114390, l2: 0.125531, l3: 0.146481, l4: 0.189788, l5: 0.252725, l6: 0.391414\n",
            "\n",
            "[epoch: 111/100000, batch: 512/1000, ite: 13814] train loss: 2.2227, accuracy: 92.7774%, tar: 0.1319 \n",
            "l0: 0.102047, l1: 0.103328, l2: 0.116081, l3: 0.143493, l4: 0.206490, l5: 0.297727, l6: 0.456008\n",
            "\n",
            "[epoch: 111/100000, batch: 520/1000, ite: 13815] train loss: 2.2225, accuracy: 91.9815%, tar: 0.1319 \n",
            "l0: 0.059843, l1: 0.063426, l2: 0.073168, l3: 0.097205, l4: 0.138329, l5: 0.230055, l6: 0.366514\n",
            "\n",
            "[epoch: 111/100000, batch: 528/1000, ite: 13816] train loss: 2.2221, accuracy: 93.9359%, tar: 0.1319 \n",
            "l0: 0.104145, l1: 0.104579, l2: 0.113239, l3: 0.133280, l4: 0.184386, l5: 0.318712, l6: 0.522079\n",
            "\n",
            "[epoch: 111/100000, batch: 536/1000, ite: 13817] train loss: 2.2219, accuracy: 91.5890%, tar: 0.1319 \n",
            "l0: 0.104113, l1: 0.105473, l2: 0.111753, l3: 0.131735, l4: 0.186568, l5: 0.260308, l6: 0.417681\n",
            "\n",
            "[epoch: 111/100000, batch: 544/1000, ite: 13818] train loss: 2.2217, accuracy: 92.1105%, tar: 0.1319 \n",
            "l0: 0.109322, l1: 0.115245, l2: 0.126650, l3: 0.161978, l4: 0.247516, l5: 0.366581, l6: 0.578412\n",
            "\n",
            "[epoch: 111/100000, batch: 552/1000, ite: 13819] train loss: 2.2217, accuracy: 91.1771%, tar: 0.1318 \n",
            "l0: 0.065691, l1: 0.065579, l2: 0.075660, l3: 0.097521, l4: 0.153447, l5: 0.273746, l6: 0.481430\n",
            "\n",
            "[epoch: 111/100000, batch: 560/1000, ite: 13820] train loss: 2.2214, accuracy: 91.9254%, tar: 0.1318 \n",
            "l0: 0.069131, l1: 0.070387, l2: 0.080126, l3: 0.102264, l4: 0.152802, l5: 0.241007, l6: 0.472656\n",
            "\n",
            "[epoch: 111/100000, batch: 568/1000, ite: 13821] train loss: 2.2211, accuracy: 91.7752%, tar: 0.1318 \n",
            "l0: 0.081441, l1: 0.081995, l2: 0.092283, l3: 0.112411, l4: 0.161870, l5: 0.287319, l6: 0.453836\n",
            "\n",
            "[epoch: 111/100000, batch: 576/1000, ite: 13822] train loss: 2.2208, accuracy: 92.8940%, tar: 0.1317 \n",
            "l0: 0.077667, l1: 0.078652, l2: 0.092308, l3: 0.123510, l4: 0.190420, l5: 0.317529, l6: 0.600706\n",
            "\n",
            "[epoch: 111/100000, batch: 584/1000, ite: 13823] train loss: 2.2207, accuracy: 90.8365%, tar: 0.1317 \n",
            "l0: 0.083470, l1: 0.084445, l2: 0.094056, l3: 0.117271, l4: 0.161679, l5: 0.286686, l6: 0.469293\n",
            "\n",
            "[epoch: 111/100000, batch: 592/1000, ite: 13824] train loss: 2.2205, accuracy: 92.8185%, tar: 0.1317 \n",
            "l0: 0.093517, l1: 0.095622, l2: 0.105966, l3: 0.132917, l4: 0.201697, l5: 0.311598, l6: 0.529224\n",
            "\n",
            "[epoch: 111/100000, batch: 600/1000, ite: 13825] train loss: 2.2204, accuracy: 92.7679%, tar: 0.1317 \n",
            "l0: 0.115570, l1: 0.117231, l2: 0.131977, l3: 0.162532, l4: 0.238012, l5: 0.380776, l6: 0.588484\n",
            "\n",
            "[epoch: 111/100000, batch: 608/1000, ite: 13826] train loss: 2.2204, accuracy: 89.9501%, tar: 0.1317 \n",
            "l0: 0.085137, l1: 0.087189, l2: 0.097034, l3: 0.125910, l4: 0.177525, l5: 0.266146, l6: 0.458564\n",
            "\n",
            "[epoch: 111/100000, batch: 616/1000, ite: 13827] train loss: 2.2202, accuracy: 92.0403%, tar: 0.1316 \n",
            "l0: 0.113430, l1: 0.114132, l2: 0.126205, l3: 0.158091, l4: 0.232076, l5: 0.340714, l6: 0.580179\n",
            "\n",
            "[epoch: 111/100000, batch: 624/1000, ite: 13828] train loss: 2.2202, accuracy: 91.3291%, tar: 0.1316 \n",
            "l0: 0.070319, l1: 0.072678, l2: 0.084113, l3: 0.114259, l4: 0.168462, l5: 0.263712, l6: 0.476514\n",
            "\n",
            "[epoch: 111/100000, batch: 632/1000, ite: 13829] train loss: 2.2199, accuracy: 92.5459%, tar: 0.1316 \n",
            "l0: 0.086976, l1: 0.087880, l2: 0.097776, l3: 0.120029, l4: 0.165815, l5: 0.284345, l6: 0.507701\n",
            "\n",
            "[epoch: 111/100000, batch: 640/1000, ite: 13830] train loss: 2.2197, accuracy: 91.6574%, tar: 0.1316 \n",
            "l0: 0.076982, l1: 0.077556, l2: 0.089345, l3: 0.112420, l4: 0.162426, l5: 0.248284, l6: 0.430053\n",
            "\n",
            "[epoch: 111/100000, batch: 648/1000, ite: 13831] train loss: 2.2194, accuracy: 92.7825%, tar: 0.1315 \n",
            "l0: 0.074798, l1: 0.075521, l2: 0.085849, l3: 0.109875, l4: 0.156879, l5: 0.270393, l6: 0.489748\n",
            "\n",
            "[epoch: 111/100000, batch: 656/1000, ite: 13832] train loss: 2.2191, accuracy: 91.3949%, tar: 0.1315 \n",
            "l0: 0.090076, l1: 0.093682, l2: 0.104738, l3: 0.130577, l4: 0.187705, l5: 0.288952, l6: 0.503692\n",
            "\n",
            "[epoch: 111/100000, batch: 664/1000, ite: 13833] train loss: 2.2189, accuracy: 91.3295%, tar: 0.1315 \n",
            "l0: 0.075974, l1: 0.077488, l2: 0.089108, l3: 0.123290, l4: 0.194310, l5: 0.298960, l6: 0.436605\n",
            "\n",
            "[epoch: 111/100000, batch: 672/1000, ite: 13834] train loss: 2.2187, accuracy: 93.4745%, tar: 0.1315 \n",
            "l0: 0.062521, l1: 0.064142, l2: 0.075457, l3: 0.092153, l4: 0.136478, l5: 0.197125, l6: 0.338486\n",
            "\n",
            "[epoch: 111/100000, batch: 680/1000, ite: 13835] train loss: 2.2182, accuracy: 93.2714%, tar: 0.1314 \n",
            "l0: 0.104519, l1: 0.104203, l2: 0.111883, l3: 0.131309, l4: 0.191658, l5: 0.286936, l6: 0.384628\n",
            "\n",
            "[epoch: 111/100000, batch: 688/1000, ite: 13836] train loss: 2.2179, accuracy: 93.2138%, tar: 0.1314 \n",
            "l0: 0.089327, l1: 0.090245, l2: 0.100942, l3: 0.129372, l4: 0.193063, l5: 0.314367, l6: 0.502023\n",
            "\n",
            "[epoch: 111/100000, batch: 696/1000, ite: 13837] train loss: 2.2177, accuracy: 91.8493%, tar: 0.1314 \n",
            "l0: 0.071712, l1: 0.072146, l2: 0.080472, l3: 0.100495, l4: 0.150520, l5: 0.246062, l6: 0.394290\n",
            "\n",
            "[epoch: 111/100000, batch: 704/1000, ite: 13838] train loss: 2.2174, accuracy: 93.1417%, tar: 0.1313 \n",
            "l0: 0.071746, l1: 0.072421, l2: 0.081705, l3: 0.103907, l4: 0.157392, l5: 0.256472, l6: 0.416350\n",
            "\n",
            "[epoch: 111/100000, batch: 712/1000, ite: 13839] train loss: 2.2170, accuracy: 93.4787%, tar: 0.1313 \n",
            "l0: 0.093876, l1: 0.096170, l2: 0.110170, l3: 0.135269, l4: 0.194048, l5: 0.304280, l6: 0.567426\n",
            "\n",
            "[epoch: 111/100000, batch: 720/1000, ite: 13840] train loss: 2.2169, accuracy: 91.6496%, tar: 0.1313 \n",
            "l0: 0.066987, l1: 0.068319, l2: 0.073874, l3: 0.088462, l4: 0.130632, l5: 0.208939, l6: 0.362597\n",
            "\n",
            "[epoch: 111/100000, batch: 728/1000, ite: 13841] train loss: 2.2165, accuracy: 94.0095%, tar: 0.1313 \n",
            "l0: 0.067613, l1: 0.068660, l2: 0.078990, l3: 0.102335, l4: 0.151170, l5: 0.246522, l6: 0.450790\n",
            "\n",
            "[epoch: 111/100000, batch: 736/1000, ite: 13842] train loss: 2.2161, accuracy: 92.8798%, tar: 0.1312 \n",
            "l0: 0.093595, l1: 0.099474, l2: 0.121179, l3: 0.165408, l4: 0.265555, l5: 0.409871, l6: 0.694448\n",
            "\n",
            "[epoch: 111/100000, batch: 744/1000, ite: 13843] train loss: 2.2163, accuracy: 91.5206%, tar: 0.1312 \n",
            "l0: 0.063394, l1: 0.063877, l2: 0.074920, l3: 0.101022, l4: 0.168840, l5: 0.306220, l6: 0.564357\n",
            "\n",
            "[epoch: 111/100000, batch: 752/1000, ite: 13844] train loss: 2.2161, accuracy: 92.3827%, tar: 0.1312 \n",
            "l0: 0.076310, l1: 0.077220, l2: 0.088643, l3: 0.110430, l4: 0.147876, l5: 0.277467, l6: 0.515023\n",
            "\n",
            "[epoch: 111/100000, batch: 760/1000, ite: 13845] train loss: 2.2159, accuracy: 92.0706%, tar: 0.1311 \n",
            "l0: 0.065573, l1: 0.067714, l2: 0.077141, l3: 0.101384, l4: 0.161235, l5: 0.263508, l6: 0.474659\n",
            "\n",
            "[epoch: 111/100000, batch: 768/1000, ite: 13846] train loss: 2.2156, accuracy: 92.4238%, tar: 0.1311 \n",
            "l0: 0.101309, l1: 0.103206, l2: 0.113626, l3: 0.135633, l4: 0.203553, l5: 0.301639, l6: 0.495259\n",
            "\n",
            "[epoch: 111/100000, batch: 776/1000, ite: 13847] train loss: 2.2155, accuracy: 92.3134%, tar: 0.1311 \n",
            "l0: 0.104405, l1: 0.105741, l2: 0.120222, l3: 0.146528, l4: 0.206928, l5: 0.309018, l6: 0.479126\n",
            "\n",
            "[epoch: 111/100000, batch: 784/1000, ite: 13848] train loss: 2.2153, accuracy: 91.1731%, tar: 0.1311 \n",
            "l0: 0.064908, l1: 0.065665, l2: 0.076221, l3: 0.098005, l4: 0.139985, l5: 0.233000, l6: 0.408891\n",
            "\n",
            "[epoch: 111/100000, batch: 792/1000, ite: 13849] train loss: 2.2149, accuracy: 92.3857%, tar: 0.1310 \n",
            "l0: 0.102771, l1: 0.105304, l2: 0.119893, l3: 0.156281, l4: 0.235345, l5: 0.349346, l6: 0.548879\n",
            "\n",
            "[epoch: 111/100000, batch: 800/1000, ite: 13850] train loss: 2.2149, accuracy: 91.1100%, tar: 0.1310 \n",
            "l0: 0.102059, l1: 0.102760, l2: 0.111465, l3: 0.133089, l4: 0.201340, l5: 0.308402, l6: 0.510700\n",
            "\n",
            "[epoch: 111/100000, batch: 808/1000, ite: 13851] train loss: 2.2148, accuracy: 90.6280%, tar: 0.1310 \n",
            "l0: 0.110764, l1: 0.112237, l2: 0.127940, l3: 0.160957, l4: 0.252718, l5: 0.384847, l6: 0.599799\n",
            "\n",
            "[epoch: 111/100000, batch: 816/1000, ite: 13852] train loss: 2.2149, accuracy: 90.8540%, tar: 0.1310 \n",
            "l0: 0.081850, l1: 0.083345, l2: 0.095986, l3: 0.113854, l4: 0.161653, l5: 0.232926, l6: 0.399415\n",
            "\n",
            "[epoch: 111/100000, batch: 824/1000, ite: 13853] train loss: 2.2145, accuracy: 93.5522%, tar: 0.1310 \n",
            "l0: 0.080375, l1: 0.081504, l2: 0.096438, l3: 0.127739, l4: 0.199355, l5: 0.327056, l6: 0.607475\n",
            "\n",
            "[epoch: 111/100000, batch: 832/1000, ite: 13854] train loss: 2.2145, accuracy: 90.0568%, tar: 0.1309 \n",
            "l0: 0.085549, l1: 0.087549, l2: 0.096797, l3: 0.115720, l4: 0.165122, l5: 0.271918, l6: 0.434034\n",
            "\n",
            "[epoch: 111/100000, batch: 840/1000, ite: 13855] train loss: 2.2142, accuracy: 91.8631%, tar: 0.1309 \n",
            "l0: 0.081405, l1: 0.082709, l2: 0.093100, l3: 0.109473, l4: 0.149226, l5: 0.236415, l6: 0.426507\n",
            "\n",
            "[epoch: 111/100000, batch: 848/1000, ite: 13856] train loss: 2.2139, accuracy: 92.0593%, tar: 0.1309 \n",
            "l0: 0.071461, l1: 0.072826, l2: 0.080377, l3: 0.094233, l4: 0.135518, l5: 0.194671, l6: 0.352163\n",
            "\n",
            "[epoch: 111/100000, batch: 856/1000, ite: 13857] train loss: 2.2134, accuracy: 93.6512%, tar: 0.1309 \n",
            "l0: 0.097265, l1: 0.099190, l2: 0.109984, l3: 0.137017, l4: 0.213691, l5: 0.331099, l6: 0.556390\n",
            "\n",
            "[epoch: 111/100000, batch: 864/1000, ite: 13858] train loss: 2.2133, accuracy: 90.0258%, tar: 0.1308 \n",
            "l0: 0.082778, l1: 0.082540, l2: 0.096075, l3: 0.128139, l4: 0.201987, l5: 0.322548, l6: 0.502209\n",
            "\n",
            "[epoch: 111/100000, batch: 872/1000, ite: 13859] train loss: 2.2132, accuracy: 92.1420%, tar: 0.1308 \n",
            "l0: 0.062258, l1: 0.063603, l2: 0.074452, l3: 0.093746, l4: 0.137297, l5: 0.230835, l6: 0.489447\n",
            "\n",
            "[epoch: 111/100000, batch: 880/1000, ite: 13860] train loss: 2.2129, accuracy: 92.0804%, tar: 0.1308 \n",
            "l0: 0.073082, l1: 0.074485, l2: 0.086952, l3: 0.108531, l4: 0.161926, l5: 0.254923, l6: 0.395442\n",
            "\n",
            "[epoch: 111/100000, batch: 888/1000, ite: 13861] train loss: 2.2125, accuracy: 93.9217%, tar: 0.1307 \n",
            "l0: 0.103715, l1: 0.105413, l2: 0.121911, l3: 0.149957, l4: 0.231604, l5: 0.351343, l6: 0.572134\n",
            "\n",
            "[epoch: 111/100000, batch: 896/1000, ite: 13862] train loss: 2.2125, accuracy: 91.6508%, tar: 0.1307 \n",
            "l0: 0.071016, l1: 0.073223, l2: 0.086048, l3: 0.111161, l4: 0.152086, l5: 0.260478, l6: 0.457080\n",
            "\n",
            "[epoch: 111/100000, batch: 904/1000, ite: 13863] train loss: 2.2122, accuracy: 93.0578%, tar: 0.1307 \n",
            "l0: 0.079847, l1: 0.081240, l2: 0.092771, l3: 0.117768, l4: 0.175683, l5: 0.279281, l6: 0.444745\n",
            "\n",
            "[epoch: 111/100000, batch: 912/1000, ite: 13864] train loss: 2.2120, accuracy: 92.7234%, tar: 0.1307 \n",
            "l0: 0.057292, l1: 0.058549, l2: 0.065664, l3: 0.078403, l4: 0.108915, l5: 0.143647, l6: 0.254955\n",
            "\n",
            "[epoch: 111/100000, batch: 920/1000, ite: 13865] train loss: 2.2113, accuracy: 95.4674%, tar: 0.1306 \n",
            "l0: 0.072957, l1: 0.074101, l2: 0.085143, l3: 0.107352, l4: 0.159741, l5: 0.268457, l6: 0.431492\n",
            "\n",
            "[epoch: 111/100000, batch: 928/1000, ite: 13866] train loss: 2.2110, accuracy: 92.4866%, tar: 0.1306 \n",
            "l0: 0.078991, l1: 0.080695, l2: 0.090777, l3: 0.113560, l4: 0.166370, l5: 0.265670, l6: 0.428092\n",
            "\n",
            "[epoch: 111/100000, batch: 936/1000, ite: 13867] train loss: 2.2107, accuracy: 93.0616%, tar: 0.1306 \n",
            "l0: 0.088188, l1: 0.088608, l2: 0.097967, l3: 0.122894, l4: 0.187957, l5: 0.289196, l6: 0.429828\n",
            "\n",
            "[epoch: 111/100000, batch: 944/1000, ite: 13868] train loss: 2.2105, accuracy: 91.9804%, tar: 0.1306 \n",
            "l0: 0.079844, l1: 0.080832, l2: 0.091759, l3: 0.120193, l4: 0.186485, l5: 0.300762, l6: 0.524137\n",
            "\n",
            "[epoch: 111/100000, batch: 952/1000, ite: 13869] train loss: 2.2103, accuracy: 91.4635%, tar: 0.1305 \n",
            "l0: 0.079529, l1: 0.081151, l2: 0.089176, l3: 0.106576, l4: 0.139231, l5: 0.219021, l6: 0.346153\n",
            "\n",
            "[epoch: 111/100000, batch: 960/1000, ite: 13870] train loss: 2.2099, accuracy: 93.1466%, tar: 0.1305 \n",
            "l0: 0.069303, l1: 0.069873, l2: 0.077940, l3: 0.103192, l4: 0.168093, l5: 0.256899, l6: 0.442473\n",
            "\n",
            "[epoch: 111/100000, batch: 968/1000, ite: 13871] train loss: 2.2096, accuracy: 92.3215%, tar: 0.1305 \n",
            "l0: 0.106162, l1: 0.108363, l2: 0.120276, l3: 0.147232, l4: 0.221933, l5: 0.342129, l6: 0.590955\n",
            "\n",
            "[epoch: 111/100000, batch: 976/1000, ite: 13872] train loss: 2.2096, accuracy: 91.2703%, tar: 0.1305 \n",
            "l0: 0.088736, l1: 0.089514, l2: 0.103566, l3: 0.131823, l4: 0.208699, l5: 0.366712, l6: 0.666888\n",
            "\n",
            "[epoch: 111/100000, batch: 984/1000, ite: 13873] train loss: 2.2097, accuracy: 89.4133%, tar: 0.1304 \n",
            "l0: 0.122661, l1: 0.124878, l2: 0.136533, l3: 0.162739, l4: 0.217858, l5: 0.311083, l6: 0.508395\n",
            "\n",
            "[epoch: 111/100000, batch: 992/1000, ite: 13874] train loss: 2.2096, accuracy: 92.4347%, tar: 0.1304 \n",
            "l0: 0.086209, l1: 0.086947, l2: 0.096566, l3: 0.122727, l4: 0.178582, l5: 0.299075, l6: 0.505173\n",
            "\n",
            "[epoch: 111/100000, batch: 1000/1000, ite: 13875] train loss: 2.2094, accuracy: 91.6132%, tar: 0.1304 \n",
            "l0: 0.100845, l1: 0.101407, l2: 0.113534, l3: 0.137765, l4: 0.194345, l5: 0.313597, l6: 0.511241\n",
            "\n",
            "[epoch: 112/100000, batch: 8/1000, ite: 13876] train loss: 2.2093, accuracy: 92.0033%, tar: 0.1304 \n",
            "l0: 0.075390, l1: 0.076520, l2: 0.087351, l3: 0.109638, l4: 0.159028, l5: 0.229609, l6: 0.404099\n",
            "\n",
            "[epoch: 112/100000, batch: 16/1000, ite: 13877] train loss: 2.2090, accuracy: 92.3652%, tar: 0.1304 \n",
            "l0: 0.095554, l1: 0.097580, l2: 0.111126, l3: 0.151617, l4: 0.254712, l5: 0.393185, l6: 0.577888\n",
            "\n",
            "[epoch: 112/100000, batch: 24/1000, ite: 13878] train loss: 2.2090, accuracy: 90.7092%, tar: 0.1303 \n",
            "l0: 0.065950, l1: 0.067238, l2: 0.076647, l3: 0.095915, l4: 0.139508, l5: 0.214882, l6: 0.385391\n",
            "\n",
            "[epoch: 112/100000, batch: 32/1000, ite: 13879] train loss: 2.2086, accuracy: 93.8358%, tar: 0.1303 \n",
            "l0: 0.081836, l1: 0.082060, l2: 0.090562, l3: 0.111896, l4: 0.149490, l5: 0.215457, l6: 0.395783\n",
            "\n",
            "[epoch: 112/100000, batch: 40/1000, ite: 13880] train loss: 2.2082, accuracy: 93.4200%, tar: 0.1303 \n",
            "l0: 0.056316, l1: 0.058318, l2: 0.064953, l3: 0.080328, l4: 0.115255, l5: 0.183720, l6: 0.339669\n",
            "\n",
            "[epoch: 112/100000, batch: 48/1000, ite: 13881] train loss: 2.2077, accuracy: 94.2193%, tar: 0.1302 \n",
            "l0: 0.073250, l1: 0.074552, l2: 0.086631, l3: 0.113791, l4: 0.182360, l5: 0.263594, l6: 0.393180\n",
            "\n",
            "[epoch: 112/100000, batch: 56/1000, ite: 13882] train loss: 2.2074, accuracy: 93.3462%, tar: 0.1302 \n",
            "l0: 0.083736, l1: 0.084173, l2: 0.092879, l3: 0.117852, l4: 0.167585, l5: 0.239481, l6: 0.449728\n",
            "\n",
            "[epoch: 112/100000, batch: 64/1000, ite: 13883] train loss: 2.2071, accuracy: 92.3115%, tar: 0.1302 \n",
            "l0: 0.099036, l1: 0.098541, l2: 0.110575, l3: 0.129721, l4: 0.165231, l5: 0.239066, l6: 0.389605\n",
            "\n",
            "[epoch: 112/100000, batch: 72/1000, ite: 13884] train loss: 2.2068, accuracy: 92.5548%, tar: 0.1302 \n",
            "l0: 0.104099, l1: 0.105627, l2: 0.117510, l3: 0.156208, l4: 0.233439, l5: 0.392810, l6: 0.655634\n",
            "\n",
            "[epoch: 112/100000, batch: 80/1000, ite: 13885] train loss: 2.2069, accuracy: 90.8223%, tar: 0.1302 \n",
            "l0: 0.098152, l1: 0.100529, l2: 0.114577, l3: 0.144471, l4: 0.218658, l5: 0.353950, l6: 0.532834\n",
            "\n",
            "[epoch: 112/100000, batch: 88/1000, ite: 13886] train loss: 2.2068, accuracy: 91.7196%, tar: 0.1301 \n",
            "l0: 0.089728, l1: 0.090530, l2: 0.100231, l3: 0.122984, l4: 0.168200, l5: 0.262189, l6: 0.432551\n",
            "\n",
            "[epoch: 112/100000, batch: 96/1000, ite: 13887] train loss: 2.2066, accuracy: 91.5885%, tar: 0.1301 \n",
            "l0: 0.082950, l1: 0.084135, l2: 0.089716, l3: 0.106993, l4: 0.152018, l5: 0.227087, l6: 0.368159\n",
            "\n",
            "[epoch: 112/100000, batch: 104/1000, ite: 13888] train loss: 2.2062, accuracy: 93.5201%, tar: 0.1301 \n",
            "l0: 0.077681, l1: 0.077982, l2: 0.086208, l3: 0.107105, l4: 0.158852, l5: 0.243211, l6: 0.417210\n",
            "\n",
            "[epoch: 112/100000, batch: 112/1000, ite: 13889] train loss: 2.2059, accuracy: 92.5764%, tar: 0.1301 \n",
            "l0: 0.072361, l1: 0.073347, l2: 0.084588, l3: 0.105550, l4: 0.150979, l5: 0.256065, l6: 0.492334\n",
            "\n",
            "[epoch: 112/100000, batch: 120/1000, ite: 13890] train loss: 2.2056, accuracy: 91.1871%, tar: 0.1300 \n",
            "l0: 0.064055, l1: 0.066289, l2: 0.075877, l3: 0.099606, l4: 0.137398, l5: 0.252112, l6: 0.420550\n",
            "\n",
            "[epoch: 112/100000, batch: 128/1000, ite: 13891] train loss: 2.2053, accuracy: 94.1205%, tar: 0.1300 \n",
            "l0: 0.074937, l1: 0.076894, l2: 0.086432, l3: 0.108784, l4: 0.161190, l5: 0.225049, l6: 0.417373\n",
            "\n",
            "[epoch: 112/100000, batch: 136/1000, ite: 13892] train loss: 2.2049, accuracy: 91.7359%, tar: 0.1300 \n",
            "l0: 0.082194, l1: 0.083459, l2: 0.093654, l3: 0.127668, l4: 0.197626, l5: 0.298471, l6: 0.551197\n",
            "\n",
            "[epoch: 112/100000, batch: 144/1000, ite: 13893] train loss: 2.2048, accuracy: 92.1041%, tar: 0.1299 \n",
            "l0: 0.104472, l1: 0.105876, l2: 0.112633, l3: 0.129812, l4: 0.181965, l5: 0.272212, l6: 0.396609\n",
            "\n",
            "[epoch: 112/100000, batch: 152/1000, ite: 13894] train loss: 2.2045, accuracy: 92.5561%, tar: 0.1299 \n",
            "l0: 0.074487, l1: 0.076707, l2: 0.084004, l3: 0.092842, l4: 0.117788, l5: 0.155716, l6: 0.243525\n",
            "\n",
            "[epoch: 112/100000, batch: 160/1000, ite: 13895] train loss: 2.2040, accuracy: 95.1505%, tar: 0.1299 \n",
            "l0: 0.098081, l1: 0.097847, l2: 0.105033, l3: 0.126699, l4: 0.195950, l5: 0.298633, l6: 0.457641\n",
            "\n",
            "[epoch: 112/100000, batch: 168/1000, ite: 13896] train loss: 2.2038, accuracy: 91.2943%, tar: 0.1299 \n",
            "l0: 0.076540, l1: 0.077675, l2: 0.088496, l3: 0.111664, l4: 0.155091, l5: 0.241782, l6: 0.461117\n",
            "\n",
            "[epoch: 112/100000, batch: 176/1000, ite: 13897] train loss: 2.2035, accuracy: 91.1425%, tar: 0.1299 \n",
            "l0: 0.070317, l1: 0.070874, l2: 0.082049, l3: 0.109909, l4: 0.166321, l5: 0.258837, l6: 0.404132\n",
            "\n",
            "[epoch: 112/100000, batch: 184/1000, ite: 13898] train loss: 2.2032, accuracy: 93.2085%, tar: 0.1298 \n",
            "l0: 0.073033, l1: 0.074289, l2: 0.084877, l3: 0.102489, l4: 0.152677, l5: 0.242839, l6: 0.518673\n",
            "\n",
            "[epoch: 112/100000, batch: 192/1000, ite: 13899] train loss: 2.2029, accuracy: 92.3492%, tar: 0.1298 \n",
            "l0: 0.078087, l1: 0.079884, l2: 0.092091, l3: 0.123945, l4: 0.188261, l5: 0.296671, l6: 0.510625\n",
            "\n",
            "[epoch: 112/100000, batch: 200/1000, ite: 13900] train loss: 2.2028, accuracy: 91.8931%, tar: 0.1298 \n",
            "l0: 0.072894, l1: 0.074788, l2: 0.084975, l3: 0.103319, l4: 0.158770, l5: 0.252113, l6: 0.392037\n",
            "\n",
            "[epoch: 112/100000, batch: 208/1000, ite: 13901] train loss: 2.2024, accuracy: 94.0988%, tar: 0.1297 \n",
            "l0: 0.074237, l1: 0.075238, l2: 0.089385, l3: 0.122731, l4: 0.199018, l5: 0.330565, l6: 0.541898\n",
            "\n",
            "[epoch: 112/100000, batch: 216/1000, ite: 13902] train loss: 2.2023, accuracy: 90.9078%, tar: 0.1297 \n",
            "l0: 0.066580, l1: 0.069601, l2: 0.079715, l3: 0.103748, l4: 0.155747, l5: 0.233339, l6: 0.388531\n",
            "\n",
            "[epoch: 112/100000, batch: 224/1000, ite: 13903] train loss: 2.2019, accuracy: 93.6164%, tar: 0.1297 \n",
            "l0: 0.063624, l1: 0.065433, l2: 0.076023, l3: 0.097280, l4: 0.138425, l5: 0.233032, l6: 0.375453\n",
            "\n",
            "[epoch: 112/100000, batch: 232/1000, ite: 13904] train loss: 2.2015, accuracy: 93.1345%, tar: 0.1296 \n",
            "l0: 0.069558, l1: 0.070762, l2: 0.083370, l3: 0.107069, l4: 0.168142, l5: 0.282193, l6: 0.487026\n",
            "\n",
            "[epoch: 112/100000, batch: 240/1000, ite: 13905] train loss: 2.2013, accuracy: 93.0388%, tar: 0.1296 \n",
            "l0: 0.096150, l1: 0.097932, l2: 0.107648, l3: 0.126501, l4: 0.189182, l5: 0.312642, l6: 0.498012\n",
            "\n",
            "[epoch: 112/100000, batch: 248/1000, ite: 13906] train loss: 2.2011, accuracy: 91.5702%, tar: 0.1296 \n",
            "l0: 0.067473, l1: 0.068837, l2: 0.080355, l3: 0.099126, l4: 0.141309, l5: 0.241248, l6: 0.422648\n",
            "\n",
            "[epoch: 112/100000, batch: 256/1000, ite: 13907] train loss: 2.2008, accuracy: 92.9858%, tar: 0.1296 \n",
            "l0: 0.117513, l1: 0.118800, l2: 0.130677, l3: 0.161185, l4: 0.229902, l5: 0.381493, l6: 0.630515\n",
            "\n",
            "[epoch: 112/100000, batch: 264/1000, ite: 13908] train loss: 2.2009, accuracy: 88.3897%, tar: 0.1296 \n",
            "l0: 0.062645, l1: 0.064074, l2: 0.075806, l3: 0.106353, l4: 0.180870, l5: 0.299858, l6: 0.467207\n",
            "\n",
            "[epoch: 112/100000, batch: 272/1000, ite: 13909] train loss: 2.2006, accuracy: 92.0567%, tar: 0.1295 \n",
            "l0: 0.080823, l1: 0.082342, l2: 0.095248, l3: 0.128137, l4: 0.196372, l5: 0.324821, l6: 0.538446\n",
            "\n",
            "[epoch: 112/100000, batch: 280/1000, ite: 13910] train loss: 2.2005, accuracy: 92.9096%, tar: 0.1295 \n",
            "l0: 0.078983, l1: 0.082051, l2: 0.093405, l3: 0.115725, l4: 0.163653, l5: 0.256722, l6: 0.421109\n",
            "\n",
            "[epoch: 112/100000, batch: 288/1000, ite: 13911] train loss: 2.2002, accuracy: 91.9317%, tar: 0.1295 \n",
            "l0: 0.084027, l1: 0.084603, l2: 0.094954, l3: 0.114183, l4: 0.156115, l5: 0.229256, l6: 0.451338\n",
            "\n",
            "[epoch: 112/100000, batch: 296/1000, ite: 13912] train loss: 2.1999, accuracy: 91.1476%, tar: 0.1294 \n",
            "l0: 0.069162, l1: 0.071287, l2: 0.082481, l3: 0.105684, l4: 0.153794, l5: 0.235614, l6: 0.414834\n",
            "\n",
            "[epoch: 112/100000, batch: 304/1000, ite: 13913] train loss: 2.1996, accuracy: 93.3192%, tar: 0.1294 \n",
            "l0: 0.087746, l1: 0.090430, l2: 0.103841, l3: 0.132467, l4: 0.192666, l5: 0.322479, l6: 0.549978\n",
            "\n",
            "[epoch: 112/100000, batch: 312/1000, ite: 13914] train loss: 2.1995, accuracy: 91.0901%, tar: 0.1294 \n",
            "l0: 0.074369, l1: 0.075818, l2: 0.086723, l3: 0.104382, l4: 0.148906, l5: 0.252953, l6: 0.443417\n",
            "\n",
            "[epoch: 112/100000, batch: 320/1000, ite: 13915] train loss: 2.1992, accuracy: 92.8105%, tar: 0.1294 \n",
            "l0: 0.076597, l1: 0.077982, l2: 0.089725, l3: 0.115472, l4: 0.174657, l5: 0.288412, l6: 0.486658\n",
            "\n",
            "[epoch: 112/100000, batch: 328/1000, ite: 13916] train loss: 2.1990, accuracy: 92.0866%, tar: 0.1293 \n",
            "l0: 0.064653, l1: 0.065454, l2: 0.073089, l3: 0.090917, l4: 0.133503, l5: 0.190209, l6: 0.345075\n",
            "\n",
            "[epoch: 112/100000, batch: 336/1000, ite: 13917] train loss: 2.1985, accuracy: 94.3898%, tar: 0.1293 \n",
            "l0: 0.074253, l1: 0.075242, l2: 0.083068, l3: 0.101039, l4: 0.147253, l5: 0.227728, l6: 0.409827\n",
            "\n",
            "[epoch: 112/100000, batch: 344/1000, ite: 13918] train loss: 2.1982, accuracy: 93.7249%, tar: 0.1293 \n",
            "l0: 0.101589, l1: 0.101794, l2: 0.113528, l3: 0.136913, l4: 0.201613, l5: 0.310284, l6: 0.486084\n",
            "\n",
            "[epoch: 112/100000, batch: 352/1000, ite: 13919] train loss: 2.1980, accuracy: 93.3334%, tar: 0.1293 \n",
            "l0: 0.056082, l1: 0.057449, l2: 0.068675, l3: 0.087116, l4: 0.131973, l5: 0.196995, l6: 0.351026\n",
            "\n",
            "[epoch: 112/100000, batch: 360/1000, ite: 13920] train loss: 2.1976, accuracy: 93.6809%, tar: 0.1292 \n",
            "l0: 0.063770, l1: 0.065224, l2: 0.075018, l3: 0.095720, l4: 0.134392, l5: 0.230786, l6: 0.442359\n",
            "\n",
            "[epoch: 112/100000, batch: 368/1000, ite: 13921] train loss: 2.1972, accuracy: 93.1594%, tar: 0.1292 \n",
            "l0: 0.101162, l1: 0.102411, l2: 0.112311, l3: 0.127415, l4: 0.170700, l5: 0.245899, l6: 0.396878\n",
            "\n",
            "[epoch: 112/100000, batch: 376/1000, ite: 13922] train loss: 2.1970, accuracy: 92.3598%, tar: 0.1292 \n",
            "l0: 0.074863, l1: 0.077819, l2: 0.087001, l3: 0.114190, l4: 0.174619, l5: 0.292882, l6: 0.455902\n",
            "\n",
            "[epoch: 112/100000, batch: 384/1000, ite: 13923] train loss: 2.1967, accuracy: 93.2137%, tar: 0.1291 \n",
            "l0: 0.122655, l1: 0.124645, l2: 0.136971, l3: 0.162076, l4: 0.233970, l5: 0.400653, l6: 0.734814\n",
            "\n",
            "[epoch: 112/100000, batch: 392/1000, ite: 13924] train loss: 2.1969, accuracy: 88.8524%, tar: 0.1291 \n",
            "l0: 0.116531, l1: 0.119730, l2: 0.132258, l3: 0.163184, l4: 0.212964, l5: 0.295652, l6: 0.459433\n",
            "\n",
            "[epoch: 112/100000, batch: 400/1000, ite: 13925] train loss: 2.1968, accuracy: 91.8607%, tar: 0.1291 \n",
            "l0: 0.112344, l1: 0.114889, l2: 0.123783, l3: 0.143691, l4: 0.182941, l5: 0.272437, l6: 0.465724\n",
            "\n",
            "[epoch: 112/100000, batch: 408/1000, ite: 13926] train loss: 2.1967, accuracy: 91.8125%, tar: 0.1291 \n",
            "l0: 0.073388, l1: 0.075107, l2: 0.087489, l3: 0.112903, l4: 0.170416, l5: 0.263809, l6: 0.417781\n",
            "\n",
            "[epoch: 112/100000, batch: 416/1000, ite: 13927] train loss: 2.1964, accuracy: 93.0711%, tar: 0.1291 \n",
            "l0: 0.088036, l1: 0.089572, l2: 0.102958, l3: 0.130979, l4: 0.198860, l5: 0.333117, l6: 0.588948\n",
            "\n",
            "[epoch: 112/100000, batch: 424/1000, ite: 13928] train loss: 2.1963, accuracy: 91.4446%, tar: 0.1291 \n",
            "l0: 0.064798, l1: 0.066991, l2: 0.078999, l3: 0.103288, l4: 0.161124, l5: 0.293119, l6: 0.490434\n",
            "\n",
            "[epoch: 112/100000, batch: 432/1000, ite: 13929] train loss: 2.1961, accuracy: 92.5253%, tar: 0.1290 \n",
            "l0: 0.060820, l1: 0.062556, l2: 0.074974, l3: 0.100399, l4: 0.151298, l5: 0.268484, l6: 0.433745\n",
            "\n",
            "[epoch: 112/100000, batch: 440/1000, ite: 13930] train loss: 2.1958, accuracy: 94.1629%, tar: 0.1290 \n",
            "l0: 0.089285, l1: 0.090137, l2: 0.101919, l3: 0.130375, l4: 0.205324, l5: 0.308116, l6: 0.508192\n",
            "\n",
            "[epoch: 112/100000, batch: 448/1000, ite: 13931] train loss: 2.1956, accuracy: 92.2455%, tar: 0.1290 \n",
            "l0: 0.056592, l1: 0.058035, l2: 0.065810, l3: 0.082859, l4: 0.118770, l5: 0.193903, l6: 0.403098\n",
            "\n",
            "[epoch: 112/100000, batch: 456/1000, ite: 13932] train loss: 2.1952, accuracy: 93.7331%, tar: 0.1289 \n",
            "l0: 0.092127, l1: 0.095172, l2: 0.105951, l3: 0.128035, l4: 0.163758, l5: 0.216750, l6: 0.386372\n",
            "\n",
            "[epoch: 112/100000, batch: 464/1000, ite: 13933] train loss: 2.1949, accuracy: 92.9782%, tar: 0.1289 \n",
            "l0: 0.067516, l1: 0.068878, l2: 0.080698, l3: 0.106838, l4: 0.169507, l5: 0.302784, l6: 0.505752\n",
            "\n",
            "[epoch: 112/100000, batch: 472/1000, ite: 13934] train loss: 2.1947, accuracy: 93.5173%, tar: 0.1289 \n",
            "l0: 0.075373, l1: 0.077590, l2: 0.086134, l3: 0.108505, l4: 0.153286, l5: 0.220396, l6: 0.403065\n",
            "\n",
            "[epoch: 112/100000, batch: 480/1000, ite: 13935] train loss: 2.1943, accuracy: 92.6860%, tar: 0.1289 \n",
            "l0: 0.096400, l1: 0.096853, l2: 0.107007, l3: 0.130051, l4: 0.171391, l5: 0.279404, l6: 0.466454\n",
            "\n",
            "[epoch: 112/100000, batch: 488/1000, ite: 13936] train loss: 2.1942, accuracy: 91.8884%, tar: 0.1288 \n",
            "l0: 0.084842, l1: 0.085561, l2: 0.096319, l3: 0.127947, l4: 0.200533, l5: 0.343451, l6: 0.596028\n",
            "\n",
            "[epoch: 112/100000, batch: 496/1000, ite: 13937] train loss: 2.1941, accuracy: 91.2634%, tar: 0.1288 \n",
            "l0: 0.081166, l1: 0.086715, l2: 0.101268, l3: 0.131227, l4: 0.217655, l5: 0.309770, l6: 0.451114\n",
            "\n",
            "[epoch: 112/100000, batch: 504/1000, ite: 13938] train loss: 2.1939, accuracy: 93.4889%, tar: 0.1288 \n",
            "l0: 0.103938, l1: 0.104319, l2: 0.114361, l3: 0.139416, l4: 0.199668, l5: 0.310406, l6: 0.541974\n",
            "\n",
            "[epoch: 112/100000, batch: 512/1000, ite: 13939] train loss: 2.1939, accuracy: 92.4144%, tar: 0.1288 \n",
            "l0: 0.090688, l1: 0.090954, l2: 0.098922, l3: 0.118600, l4: 0.170268, l5: 0.292484, l6: 0.478918\n",
            "\n",
            "[epoch: 112/100000, batch: 520/1000, ite: 13940] train loss: 2.1937, accuracy: 92.9372%, tar: 0.1288 \n",
            "l0: 0.111084, l1: 0.114055, l2: 0.125764, l3: 0.152554, l4: 0.201330, l5: 0.353774, l6: 0.615585\n",
            "\n",
            "[epoch: 112/100000, batch: 528/1000, ite: 13941] train loss: 2.1937, accuracy: 88.7691%, tar: 0.1288 \n",
            "l0: 0.062725, l1: 0.064289, l2: 0.074402, l3: 0.096307, l4: 0.148661, l5: 0.230314, l6: 0.358859\n",
            "\n",
            "[epoch: 112/100000, batch: 536/1000, ite: 13942] train loss: 2.1933, accuracy: 94.1030%, tar: 0.1287 \n",
            "l0: 0.095186, l1: 0.096392, l2: 0.108442, l3: 0.134822, l4: 0.200278, l5: 0.307195, l6: 0.531158\n",
            "\n",
            "[epoch: 112/100000, batch: 544/1000, ite: 13943] train loss: 2.1932, accuracy: 91.0040%, tar: 0.1287 \n",
            "l0: 0.102566, l1: 0.103405, l2: 0.115152, l3: 0.146148, l4: 0.202648, l5: 0.312788, l6: 0.520165\n",
            "\n",
            "[epoch: 112/100000, batch: 552/1000, ite: 13944] train loss: 2.1931, accuracy: 91.4484%, tar: 0.1287 \n",
            "l0: 0.057846, l1: 0.059606, l2: 0.071473, l3: 0.094010, l4: 0.137008, l5: 0.230784, l6: 0.408934\n",
            "\n",
            "[epoch: 112/100000, batch: 560/1000, ite: 13945] train loss: 2.1927, accuracy: 93.7883%, tar: 0.1287 \n",
            "l0: 0.069630, l1: 0.070893, l2: 0.082825, l3: 0.107460, l4: 0.188959, l5: 0.260027, l6: 0.403195\n",
            "\n",
            "[epoch: 112/100000, batch: 568/1000, ite: 13946] train loss: 2.1924, accuracy: 93.1279%, tar: 0.1286 \n",
            "l0: 0.103509, l1: 0.104420, l2: 0.115647, l3: 0.144390, l4: 0.216869, l5: 0.326385, l6: 0.503444\n",
            "\n",
            "[epoch: 112/100000, batch: 576/1000, ite: 13947] train loss: 2.1923, accuracy: 91.6212%, tar: 0.1286 \n",
            "l0: 0.064617, l1: 0.065842, l2: 0.072350, l3: 0.091128, l4: 0.126490, l5: 0.196933, l6: 0.319190\n",
            "\n",
            "[epoch: 112/100000, batch: 584/1000, ite: 13948] train loss: 2.1918, accuracy: 94.0718%, tar: 0.1286 \n",
            "l0: 0.085099, l1: 0.087737, l2: 0.099274, l3: 0.124317, l4: 0.177665, l5: 0.271131, l6: 0.401857\n",
            "\n",
            "[epoch: 112/100000, batch: 592/1000, ite: 13949] train loss: 2.1916, accuracy: 93.8335%, tar: 0.1286 \n",
            "l0: 0.139014, l1: 0.139406, l2: 0.151143, l3: 0.186363, l4: 0.252604, l5: 0.357748, l6: 0.522041\n",
            "\n",
            "[epoch: 112/100000, batch: 600/1000, ite: 13950] train loss: 2.1916, accuracy: 90.8537%, tar: 0.1286 \n",
            "l0: 0.087961, l1: 0.089793, l2: 0.098958, l3: 0.122044, l4: 0.185095, l5: 0.303266, l6: 0.488215\n",
            "\n",
            "[epoch: 112/100000, batch: 608/1000, ite: 13951] train loss: 2.1914, accuracy: 91.9807%, tar: 0.1285 \n",
            "l0: 0.071506, l1: 0.072821, l2: 0.084467, l3: 0.111920, l4: 0.164486, l5: 0.276149, l6: 0.478821\n",
            "\n",
            "[epoch: 112/100000, batch: 616/1000, ite: 13952] train loss: 2.1912, accuracy: 92.6325%, tar: 0.1285 \n",
            "l0: 0.086108, l1: 0.087260, l2: 0.099132, l3: 0.119099, l4: 0.159392, l5: 0.246932, l6: 0.401217\n",
            "\n",
            "[epoch: 112/100000, batch: 624/1000, ite: 13953] train loss: 2.1909, accuracy: 92.7118%, tar: 0.1285 \n",
            "l0: 0.072782, l1: 0.073598, l2: 0.083607, l3: 0.108254, l4: 0.160745, l5: 0.256370, l6: 0.472217\n",
            "\n",
            "[epoch: 112/100000, batch: 632/1000, ite: 13954] train loss: 2.1906, accuracy: 92.4395%, tar: 0.1285 \n",
            "l0: 0.083383, l1: 0.084387, l2: 0.097753, l3: 0.122192, l4: 0.194770, l5: 0.329043, l6: 0.528239\n",
            "\n",
            "[epoch: 112/100000, batch: 640/1000, ite: 13955] train loss: 2.1905, accuracy: 92.1226%, tar: 0.1284 \n",
            "l0: 0.147268, l1: 0.149075, l2: 0.160820, l3: 0.189875, l4: 0.265759, l5: 0.379056, l6: 0.653592\n",
            "\n",
            "[epoch: 112/100000, batch: 648/1000, ite: 13956] train loss: 2.1907, accuracy: 89.0431%, tar: 0.1285 \n",
            "l0: 0.069246, l1: 0.070265, l2: 0.081379, l3: 0.100312, l4: 0.151562, l5: 0.253144, l6: 0.488880\n",
            "\n",
            "[epoch: 112/100000, batch: 656/1000, ite: 13957] train loss: 2.1905, accuracy: 91.9834%, tar: 0.1284 \n",
            "l0: 0.073585, l1: 0.074486, l2: 0.080854, l3: 0.097428, l4: 0.146460, l5: 0.252088, l6: 0.453835\n",
            "\n",
            "[epoch: 112/100000, batch: 664/1000, ite: 13958] train loss: 2.1902, accuracy: 93.2921%, tar: 0.1284 \n",
            "l0: 0.086807, l1: 0.087874, l2: 0.101208, l3: 0.127070, l4: 0.182314, l5: 0.280619, l6: 0.478643\n",
            "\n",
            "[epoch: 112/100000, batch: 672/1000, ite: 13959] train loss: 2.1900, accuracy: 91.2488%, tar: 0.1284 \n",
            "l0: 0.088340, l1: 0.089406, l2: 0.101258, l3: 0.133570, l4: 0.206490, l5: 0.366704, l6: 0.553326\n",
            "\n",
            "[epoch: 112/100000, batch: 680/1000, ite: 13960] train loss: 2.1900, accuracy: 91.6753%, tar: 0.1284 \n",
            "l0: 0.086767, l1: 0.088234, l2: 0.103669, l3: 0.140850, l4: 0.207936, l5: 0.332991, l6: 0.549937\n",
            "\n",
            "[epoch: 112/100000, batch: 688/1000, ite: 13961] train loss: 2.1899, accuracy: 91.5537%, tar: 0.1283 \n",
            "l0: 0.068801, l1: 0.069409, l2: 0.079865, l3: 0.103078, l4: 0.142993, l5: 0.223213, l6: 0.367875\n",
            "\n",
            "[epoch: 112/100000, batch: 696/1000, ite: 13962] train loss: 2.1895, accuracy: 93.8411%, tar: 0.1283 \n",
            "l0: 0.071163, l1: 0.072306, l2: 0.080168, l3: 0.104555, l4: 0.147372, l5: 0.234964, l6: 0.460401\n",
            "\n",
            "[epoch: 112/100000, batch: 704/1000, ite: 13963] train loss: 2.1893, accuracy: 92.0011%, tar: 0.1283 \n",
            "l0: 0.072204, l1: 0.074546, l2: 0.083816, l3: 0.104394, l4: 0.152228, l5: 0.227219, l6: 0.398325\n",
            "\n",
            "[epoch: 112/100000, batch: 712/1000, ite: 13964] train loss: 2.1889, accuracy: 92.1342%, tar: 0.1282 \n",
            "l0: 0.096030, l1: 0.097802, l2: 0.107297, l3: 0.129774, l4: 0.180379, l5: 0.265229, l6: 0.441136\n",
            "\n",
            "[epoch: 112/100000, batch: 720/1000, ite: 13965] train loss: 2.1887, accuracy: 91.7651%, tar: 0.1282 \n",
            "l0: 0.070636, l1: 0.071404, l2: 0.082742, l3: 0.106192, l4: 0.153948, l5: 0.281007, l6: 0.533627\n",
            "\n",
            "[epoch: 112/100000, batch: 728/1000, ite: 13966] train loss: 2.1885, accuracy: 92.3554%, tar: 0.1282 \n",
            "l0: 0.075261, l1: 0.076557, l2: 0.087874, l3: 0.110293, l4: 0.156534, l5: 0.249417, l6: 0.453685\n",
            "\n",
            "[epoch: 112/100000, batch: 736/1000, ite: 13967] train loss: 2.1882, accuracy: 91.9698%, tar: 0.1282 \n",
            "l0: 0.095440, l1: 0.097809, l2: 0.110947, l3: 0.140749, l4: 0.222868, l5: 0.362545, l6: 0.642297\n",
            "\n",
            "[epoch: 112/100000, batch: 744/1000, ite: 13968] train loss: 2.1883, accuracy: 89.7127%, tar: 0.1282 \n",
            "l0: 0.083276, l1: 0.084587, l2: 0.094026, l3: 0.116780, l4: 0.172327, l5: 0.264751, l6: 0.443728\n",
            "\n",
            "[epoch: 112/100000, batch: 752/1000, ite: 13969] train loss: 2.1881, accuracy: 93.1419%, tar: 0.1281 \n",
            "l0: 0.058866, l1: 0.060315, l2: 0.070581, l3: 0.097269, l4: 0.159451, l5: 0.261845, l6: 0.510947\n",
            "\n",
            "[epoch: 112/100000, batch: 760/1000, ite: 13970] train loss: 2.1878, accuracy: 91.6769%, tar: 0.1281 \n",
            "l0: 0.088532, l1: 0.088935, l2: 0.097120, l3: 0.113895, l4: 0.168960, l5: 0.265775, l6: 0.478095\n",
            "\n",
            "[epoch: 112/100000, batch: 768/1000, ite: 13971] train loss: 2.1876, accuracy: 91.5757%, tar: 0.1281 \n",
            "l0: 0.086314, l1: 0.088914, l2: 0.101264, l3: 0.126495, l4: 0.198312, l5: 0.308182, l6: 0.498353\n",
            "\n",
            "[epoch: 112/100000, batch: 776/1000, ite: 13972] train loss: 2.1875, accuracy: 92.9570%, tar: 0.1281 \n",
            "l0: 0.070241, l1: 0.072176, l2: 0.081327, l3: 0.103173, l4: 0.169175, l5: 0.247923, l6: 0.443933\n",
            "\n",
            "[epoch: 112/100000, batch: 784/1000, ite: 13973] train loss: 2.1872, accuracy: 93.1930%, tar: 0.1280 \n",
            "l0: 0.081894, l1: 0.083174, l2: 0.090840, l3: 0.108305, l4: 0.156157, l5: 0.250072, l6: 0.461580\n",
            "\n",
            "[epoch: 112/100000, batch: 792/1000, ite: 13974] train loss: 2.1869, accuracy: 91.8972%, tar: 0.1280 \n",
            "l0: 0.066399, l1: 0.067628, l2: 0.077763, l3: 0.098616, l4: 0.156557, l5: 0.296646, l6: 0.526247\n",
            "\n",
            "[epoch: 112/100000, batch: 800/1000, ite: 13975] train loss: 2.1868, accuracy: 92.0556%, tar: 0.1280 \n",
            "l0: 0.074539, l1: 0.076005, l2: 0.088876, l3: 0.122668, l4: 0.198927, l5: 0.320831, l6: 0.519174\n",
            "\n",
            "[epoch: 112/100000, batch: 808/1000, ite: 13976] train loss: 2.1866, accuracy: 91.4637%, tar: 0.1279 \n",
            "l0: 0.054412, l1: 0.055046, l2: 0.064313, l3: 0.086899, l4: 0.133042, l5: 0.234918, l6: 0.367153\n",
            "\n",
            "[epoch: 112/100000, batch: 816/1000, ite: 13977] train loss: 2.1862, accuracy: 94.2079%, tar: 0.1279 \n",
            "l0: 0.075104, l1: 0.076118, l2: 0.085008, l3: 0.109089, l4: 0.152812, l5: 0.218512, l6: 0.362478\n",
            "\n",
            "[epoch: 112/100000, batch: 824/1000, ite: 13978] train loss: 2.1858, accuracy: 93.6656%, tar: 0.1279 \n",
            "l0: 0.075086, l1: 0.076198, l2: 0.084777, l3: 0.103297, l4: 0.149782, l5: 0.230857, l6: 0.396831\n",
            "\n",
            "[epoch: 112/100000, batch: 832/1000, ite: 13979] train loss: 2.1855, accuracy: 93.0909%, tar: 0.1279 \n",
            "l0: 0.102504, l1: 0.104935, l2: 0.120412, l3: 0.154375, l4: 0.225884, l5: 0.376032, l6: 0.654881\n",
            "\n",
            "[epoch: 112/100000, batch: 840/1000, ite: 13980] train loss: 2.1856, accuracy: 90.1487%, tar: 0.1278 \n",
            "l0: 0.076706, l1: 0.078196, l2: 0.088461, l3: 0.109961, l4: 0.155330, l5: 0.232130, l6: 0.379037\n",
            "\n",
            "[epoch: 112/100000, batch: 848/1000, ite: 13981] train loss: 2.1853, accuracy: 93.1381%, tar: 0.1278 \n",
            "l0: 0.106817, l1: 0.106385, l2: 0.117564, l3: 0.140456, l4: 0.198541, l5: 0.323661, l6: 0.548497\n",
            "\n",
            "[epoch: 112/100000, batch: 856/1000, ite: 13982] train loss: 2.1852, accuracy: 90.5341%, tar: 0.1278 \n",
            "l0: 0.079010, l1: 0.079838, l2: 0.090419, l3: 0.116542, l4: 0.170624, l5: 0.272478, l6: 0.392662\n",
            "\n",
            "[epoch: 112/100000, batch: 864/1000, ite: 13983] train loss: 2.1849, accuracy: 92.5661%, tar: 0.1278 \n",
            "l0: 0.064547, l1: 0.065810, l2: 0.077205, l3: 0.096897, l4: 0.158084, l5: 0.278650, l6: 0.439738\n",
            "\n",
            "[epoch: 112/100000, batch: 872/1000, ite: 13984] train loss: 2.1846, accuracy: 92.8968%, tar: 0.1277 \n",
            "l0: 0.077269, l1: 0.080365, l2: 0.091241, l3: 0.117247, l4: 0.157953, l5: 0.294632, l6: 0.543731\n",
            "\n",
            "[epoch: 112/100000, batch: 880/1000, ite: 13985] train loss: 2.1845, accuracy: 91.2190%, tar: 0.1277 \n",
            "l0: 0.099787, l1: 0.101571, l2: 0.114707, l3: 0.143176, l4: 0.212990, l5: 0.320784, l6: 0.559909\n",
            "\n",
            "[epoch: 112/100000, batch: 888/1000, ite: 13986] train loss: 2.1845, accuracy: 90.2420%, tar: 0.1277 \n",
            "l0: 0.073815, l1: 0.074256, l2: 0.085536, l3: 0.107335, l4: 0.171170, l5: 0.261796, l6: 0.479511\n",
            "\n",
            "[epoch: 112/100000, batch: 896/1000, ite: 13987] train loss: 2.1843, accuracy: 92.2453%, tar: 0.1277 \n",
            "l0: 0.063059, l1: 0.064315, l2: 0.078406, l3: 0.101643, l4: 0.160563, l5: 0.240860, l6: 0.402528\n",
            "\n",
            "[epoch: 112/100000, batch: 904/1000, ite: 13988] train loss: 2.1839, accuracy: 94.1653%, tar: 0.1276 \n",
            "l0: 0.121684, l1: 0.123456, l2: 0.135116, l3: 0.157023, l4: 0.237468, l5: 0.396986, l6: 0.625788\n",
            "\n",
            "[epoch: 112/100000, batch: 912/1000, ite: 13989] train loss: 2.1840, accuracy: 90.7085%, tar: 0.1276 \n",
            "l0: 0.096103, l1: 0.096404, l2: 0.105759, l3: 0.135086, l4: 0.187112, l5: 0.332169, l6: 0.513791\n",
            "\n",
            "[epoch: 112/100000, batch: 920/1000, ite: 13990] train loss: 2.1839, accuracy: 92.1836%, tar: 0.1276 \n",
            "l0: 0.083551, l1: 0.086732, l2: 0.097253, l3: 0.120338, l4: 0.195842, l5: 0.303796, l6: 0.495042\n",
            "\n",
            "[epoch: 112/100000, batch: 928/1000, ite: 13991] train loss: 2.1838, accuracy: 91.8805%, tar: 0.1276 \n",
            "l0: 0.080005, l1: 0.081112, l2: 0.091219, l3: 0.114192, l4: 0.164574, l5: 0.232534, l6: 0.345361\n",
            "\n",
            "[epoch: 112/100000, batch: 936/1000, ite: 13992] train loss: 2.1834, accuracy: 92.8307%, tar: 0.1276 \n",
            "l0: 0.069368, l1: 0.070501, l2: 0.081286, l3: 0.105566, l4: 0.157373, l5: 0.260565, l6: 0.400856\n",
            "\n",
            "[epoch: 112/100000, batch: 944/1000, ite: 13993] train loss: 2.1831, accuracy: 93.2387%, tar: 0.1276 \n",
            "l0: 0.108004, l1: 0.108303, l2: 0.124609, l3: 0.155016, l4: 0.255180, l5: 0.382814, l6: 0.532702\n",
            "\n",
            "[epoch: 112/100000, batch: 952/1000, ite: 13994] train loss: 2.1831, accuracy: 92.1164%, tar: 0.1275 \n",
            "l0: 0.082298, l1: 0.084001, l2: 0.097921, l3: 0.121448, l4: 0.199758, l5: 0.339067, l6: 0.600501\n",
            "\n",
            "[epoch: 112/100000, batch: 960/1000, ite: 13995] train loss: 2.1831, accuracy: 90.7481%, tar: 0.1275 \n",
            "l0: 0.079818, l1: 0.081385, l2: 0.092353, l3: 0.125241, l4: 0.183986, l5: 0.296893, l6: 0.485478\n",
            "\n",
            "[epoch: 112/100000, batch: 968/1000, ite: 13996] train loss: 2.1829, accuracy: 91.6486%, tar: 0.1275 \n",
            "l0: 0.095960, l1: 0.098482, l2: 0.113076, l3: 0.147039, l4: 0.224767, l5: 0.350031, l6: 0.560161\n",
            "\n",
            "[epoch: 112/100000, batch: 976/1000, ite: 13997] train loss: 2.1829, accuracy: 90.6353%, tar: 0.1275 \n",
            "l0: 0.074392, l1: 0.075461, l2: 0.086674, l3: 0.108762, l4: 0.157499, l5: 0.241693, l6: 0.377326\n",
            "\n",
            "[epoch: 112/100000, batch: 984/1000, ite: 13998] train loss: 2.1826, accuracy: 92.3832%, tar: 0.1275 \n",
            "l0: 0.056091, l1: 0.057317, l2: 0.068435, l3: 0.097266, l4: 0.151876, l5: 0.242761, l6: 0.469203\n",
            "\n",
            "[epoch: 112/100000, batch: 992/1000, ite: 13999] train loss: 2.1823, accuracy: 92.8929%, tar: 0.1274 \n",
            "l0: 0.074627, l1: 0.075495, l2: 0.083833, l3: 0.103879, l4: 0.149901, l5: 0.273636, l6: 0.454996\n",
            "\n",
            "[epoch: 112/100000, batch: 1000/1000, ite: 14000] train loss: 2.1820, accuracy: 93.1419%, tar: 0.1274 \n",
            "l0: 0.076365, l1: 0.078431, l2: 0.089116, l3: 0.115321, l4: 0.170622, l5: 0.302635, l6: 0.509620\n",
            "\n",
            "[epoch: 113/100000, batch: 8/1000, ite: 14001] train loss: 1.8521, accuracy: 91.8590%, tar: 0.0764 \n",
            "l0: 0.072686, l1: 0.074600, l2: 0.090957, l3: 0.125531, l4: 0.184005, l5: 0.266312, l6: 0.447052\n",
            "\n",
            "[epoch: 113/100000, batch: 16/1000, ite: 14002] train loss: 1.7762, accuracy: 93.1406%, tar: 0.0745 \n",
            "l0: 0.103355, l1: 0.106531, l2: 0.120038, l3: 0.144648, l4: 0.196275, l5: 0.305174, l6: 0.483317\n",
            "\n",
            "[epoch: 113/100000, batch: 24/1000, ite: 14003] train loss: 1.8309, accuracy: 91.1115%, tar: 0.0841 \n",
            "l0: 0.063966, l1: 0.065395, l2: 0.076531, l3: 0.102307, l4: 0.158824, l5: 0.252788, l6: 0.439660\n",
            "\n",
            "[epoch: 113/100000, batch: 32/1000, ite: 14004] train loss: 1.7770, accuracy: 92.4060%, tar: 0.0791 \n",
            "l0: 0.076734, l1: 0.076495, l2: 0.087440, l3: 0.111841, l4: 0.173331, l5: 0.295029, l6: 0.512017\n",
            "\n",
            "[epoch: 113/100000, batch: 40/1000, ite: 14005] train loss: 1.7940, accuracy: 91.6433%, tar: 0.0786 \n",
            "l0: 0.072012, l1: 0.073319, l2: 0.083824, l3: 0.104922, l4: 0.165526, l5: 0.279713, l6: 0.411422\n",
            "\n",
            "[epoch: 113/100000, batch: 48/1000, ite: 14006] train loss: 1.7632, accuracy: 92.9262%, tar: 0.0775 \n",
            "l0: 0.082166, l1: 0.083003, l2: 0.094402, l3: 0.123325, l4: 0.203990, l5: 0.335486, l6: 0.542342\n",
            "\n",
            "[epoch: 113/100000, batch: 56/1000, ite: 14007] train loss: 1.7967, accuracy: 91.4976%, tar: 0.0782 \n",
            "l0: 0.090323, l1: 0.092169, l2: 0.106013, l3: 0.132282, l4: 0.192818, l5: 0.308281, l6: 0.583327\n",
            "\n",
            "[epoch: 113/100000, batch: 64/1000, ite: 14008] train loss: 1.8342, accuracy: 90.1467%, tar: 0.0797 \n",
            "l0: 0.077825, l1: 0.081109, l2: 0.092138, l3: 0.115305, l4: 0.165438, l5: 0.270196, l6: 0.473370\n",
            "\n",
            "[epoch: 113/100000, batch: 72/1000, ite: 14009] train loss: 1.8250, accuracy: 93.2415%, tar: 0.0795 \n",
            "l0: 0.087397, l1: 0.088493, l2: 0.099059, l3: 0.118179, l4: 0.158171, l5: 0.251073, l6: 0.390947\n",
            "\n",
            "[epoch: 113/100000, batch: 80/1000, ite: 14010] train loss: 1.8018, accuracy: 93.8469%, tar: 0.0803 \n",
            "l0: 0.085292, l1: 0.086292, l2: 0.098392, l3: 0.122401, l4: 0.174454, l5: 0.254449, l6: 0.438983\n",
            "\n",
            "[epoch: 113/100000, batch: 88/1000, ite: 14011] train loss: 1.7933, accuracy: 92.4478%, tar: 0.0807 \n",
            "l0: 0.087789, l1: 0.089996, l2: 0.100360, l3: 0.127664, l4: 0.203586, l5: 0.309503, l6: 0.528960\n",
            "\n",
            "[epoch: 113/100000, batch: 96/1000, ite: 14012] train loss: 1.8084, accuracy: 92.6518%, tar: 0.0813 \n",
            "l0: 0.078888, l1: 0.080422, l2: 0.088998, l3: 0.110036, l4: 0.151028, l5: 0.213476, l6: 0.414567\n",
            "\n",
            "[epoch: 113/100000, batch: 104/1000, ite: 14013] train loss: 1.7885, accuracy: 93.1715%, tar: 0.0811 \n",
            "l0: 0.095913, l1: 0.097963, l2: 0.110235, l3: 0.134582, l4: 0.190875, l5: 0.297465, l6: 0.496356\n",
            "\n",
            "[epoch: 113/100000, batch: 112/1000, ite: 14014] train loss: 1.7979, accuracy: 91.4534%, tar: 0.0822 \n",
            "l0: 0.070947, l1: 0.073157, l2: 0.083997, l3: 0.117089, l4: 0.192250, l5: 0.312214, l6: 0.545279\n",
            "\n",
            "[epoch: 113/100000, batch: 120/1000, ite: 14015] train loss: 1.8082, accuracy: 92.2240%, tar: 0.0814 \n",
            "l0: 0.071228, l1: 0.072778, l2: 0.082832, l3: 0.103420, l4: 0.151786, l5: 0.262798, l6: 0.441865\n",
            "\n",
            "[epoch: 113/100000, batch: 128/1000, ite: 14016] train loss: 1.7976, accuracy: 93.0523%, tar: 0.0808 \n",
            "l0: 0.076435, l1: 0.079047, l2: 0.089171, l3: 0.109288, l4: 0.175202, l5: 0.305106, l6: 0.449306\n",
            "\n",
            "[epoch: 113/100000, batch: 136/1000, ite: 14017] train loss: 1.7933, accuracy: 93.3905%, tar: 0.0805 \n",
            "l0: 0.059564, l1: 0.061045, l2: 0.068628, l3: 0.085870, l4: 0.137361, l5: 0.197365, l6: 0.344796\n",
            "\n",
            "[epoch: 113/100000, batch: 144/1000, ite: 14018] train loss: 1.7659, accuracy: 93.8296%, tar: 0.0794 \n",
            "l0: 0.083867, l1: 0.084506, l2: 0.096762, l3: 0.125034, l4: 0.199945, l5: 0.323120, l6: 0.538454\n",
            "\n",
            "[epoch: 113/100000, batch: 152/1000, ite: 14019] train loss: 1.7776, accuracy: 91.4581%, tar: 0.0796 \n",
            "l0: 0.066908, l1: 0.067498, l2: 0.076269, l3: 0.100775, l4: 0.156821, l5: 0.253382, l6: 0.445269\n",
            "\n",
            "[epoch: 113/100000, batch: 160/1000, ite: 14020] train loss: 1.7695, accuracy: 93.0588%, tar: 0.0790 \n",
            "l0: 0.101284, l1: 0.103539, l2: 0.113974, l3: 0.139543, l4: 0.197005, l5: 0.314179, l6: 0.659051\n",
            "\n",
            "[epoch: 113/100000, batch: 168/1000, ite: 14021] train loss: 1.7951, accuracy: 91.0733%, tar: 0.0800 \n",
            "l0: 0.088428, l1: 0.089731, l2: 0.101829, l3: 0.129978, l4: 0.193070, l5: 0.326923, l6: 0.517201\n",
            "\n",
            "[epoch: 113/100000, batch: 176/1000, ite: 14022] train loss: 1.8026, accuracy: 92.6381%, tar: 0.0804 \n",
            "l0: 0.081110, l1: 0.084421, l2: 0.096911, l3: 0.126319, l4: 0.183413, l5: 0.313401, l6: 0.545370\n",
            "\n",
            "[epoch: 113/100000, batch: 184/1000, ite: 14023] train loss: 1.8099, accuracy: 92.1614%, tar: 0.0805 \n",
            "l0: 0.066631, l1: 0.067151, l2: 0.074570, l3: 0.092837, l4: 0.148822, l5: 0.283082, l6: 0.454053\n",
            "\n",
            "[epoch: 113/100000, batch: 192/1000, ite: 14024] train loss: 1.8032, accuracy: 92.5377%, tar: 0.0799 \n",
            "l0: 0.102527, l1: 0.103156, l2: 0.115007, l3: 0.146379, l4: 0.221365, l5: 0.323861, l6: 0.501593\n",
            "\n",
            "[epoch: 113/100000, batch: 200/1000, ite: 14025] train loss: 1.8116, accuracy: 91.0830%, tar: 0.0808 \n",
            "l0: 0.064131, l1: 0.065323, l2: 0.072469, l3: 0.094352, l4: 0.136040, l5: 0.227351, l6: 0.395694\n",
            "\n",
            "[epoch: 113/100000, batch: 208/1000, ite: 14026] train loss: 1.7982, accuracy: 93.0903%, tar: 0.0801 \n",
            "l0: 0.081318, l1: 0.083698, l2: 0.091602, l3: 0.110982, l4: 0.151503, l5: 0.246204, l6: 0.424721\n",
            "\n",
            "[epoch: 113/100000, batch: 216/1000, ite: 14027] train loss: 1.7912, accuracy: 92.3731%, tar: 0.0802 \n",
            "l0: 0.075679, l1: 0.077208, l2: 0.091980, l3: 0.120050, l4: 0.185398, l5: 0.291237, l6: 0.457755\n",
            "\n",
            "[epoch: 113/100000, batch: 224/1000, ite: 14028] train loss: 1.7896, accuracy: 91.8193%, tar: 0.0800 \n",
            "l0: 0.066381, l1: 0.067673, l2: 0.076291, l3: 0.095591, l4: 0.147189, l5: 0.213320, l6: 0.340942\n",
            "\n",
            "[epoch: 113/100000, batch: 232/1000, ite: 14029] train loss: 1.7746, accuracy: 93.2657%, tar: 0.0796 \n",
            "l0: 0.089875, l1: 0.089526, l2: 0.100167, l3: 0.124001, l4: 0.174978, l5: 0.266888, l6: 0.479639\n",
            "\n",
            "[epoch: 113/100000, batch: 240/1000, ite: 14030] train loss: 1.7756, accuracy: 90.9286%, tar: 0.0799 \n",
            "l0: 0.065209, l1: 0.066375, l2: 0.076741, l3: 0.096262, l4: 0.133012, l5: 0.202050, l6: 0.404947\n",
            "\n",
            "[epoch: 113/100000, batch: 248/1000, ite: 14031] train loss: 1.7650, accuracy: 93.4630%, tar: 0.0794 \n",
            "l0: 0.096493, l1: 0.097010, l2: 0.102858, l3: 0.117834, l4: 0.156978, l5: 0.250236, l6: 0.409449\n",
            "\n",
            "[epoch: 113/100000, batch: 256/1000, ite: 14032] train loss: 1.7612, accuracy: 92.1035%, tar: 0.0800 \n",
            "l0: 0.102466, l1: 0.102507, l2: 0.113875, l3: 0.136519, l4: 0.198799, l5: 0.328188, l6: 0.554612\n",
            "\n",
            "[epoch: 113/100000, batch: 264/1000, ite: 14033] train loss: 1.7714, accuracy: 91.4086%, tar: 0.0806 \n",
            "l0: 0.097718, l1: 0.098909, l2: 0.109847, l3: 0.138840, l4: 0.214867, l5: 0.347252, l6: 0.542828\n",
            "\n",
            "[epoch: 113/100000, batch: 272/1000, ite: 14034] train loss: 1.7808, accuracy: 92.0084%, tar: 0.0811 \n",
            "l0: 0.069167, l1: 0.069438, l2: 0.080339, l3: 0.104600, l4: 0.174213, l5: 0.274045, l6: 0.483173\n",
            "\n",
            "[epoch: 113/100000, batch: 280/1000, ite: 14035] train loss: 1.7797, accuracy: 92.4590%, tar: 0.0808 \n",
            "l0: 0.083066, l1: 0.084119, l2: 0.092877, l3: 0.116448, l4: 0.156713, l5: 0.217581, l6: 0.390139\n",
            "\n",
            "[epoch: 113/100000, batch: 288/1000, ite: 14036] train loss: 1.7733, accuracy: 92.7724%, tar: 0.0809 \n",
            "l0: 0.081091, l1: 0.082563, l2: 0.094979, l3: 0.120120, l4: 0.175179, l5: 0.283701, l6: 0.431520\n",
            "\n",
            "[epoch: 113/100000, batch: 296/1000, ite: 14037] train loss: 1.7715, accuracy: 92.7777%, tar: 0.0809 \n",
            "l0: 0.076090, l1: 0.076836, l2: 0.085632, l3: 0.106167, l4: 0.156585, l5: 0.239600, l6: 0.443820\n",
            "\n",
            "[epoch: 113/100000, batch: 304/1000, ite: 14038] train loss: 1.7680, accuracy: 92.5357%, tar: 0.0807 \n",
            "l0: 0.073460, l1: 0.074767, l2: 0.086172, l3: 0.109977, l4: 0.156567, l5: 0.250591, l6: 0.449715\n",
            "\n",
            "[epoch: 113/100000, batch: 312/1000, ite: 14039] train loss: 1.7652, accuracy: 91.7177%, tar: 0.0806 \n",
            "l0: 0.093003, l1: 0.094225, l2: 0.104474, l3: 0.122518, l4: 0.163357, l5: 0.233770, l6: 0.358726\n",
            "\n",
            "[epoch: 113/100000, batch: 320/1000, ite: 14040] train loss: 1.7595, accuracy: 93.1063%, tar: 0.0809 \n",
            "l0: 0.064466, l1: 0.065346, l2: 0.071451, l3: 0.092822, l4: 0.128409, l5: 0.207485, l6: 0.450083\n",
            "\n",
            "[epoch: 113/100000, batch: 328/1000, ite: 14041] train loss: 1.7541, accuracy: 92.1015%, tar: 0.0805 \n",
            "l0: 0.062219, l1: 0.063350, l2: 0.071625, l3: 0.095413, l4: 0.137665, l5: 0.220672, l6: 0.386565\n",
            "\n",
            "[epoch: 113/100000, batch: 336/1000, ite: 14042] train loss: 1.7464, accuracy: 93.0749%, tar: 0.0800 \n",
            "l0: 0.075209, l1: 0.077330, l2: 0.086856, l3: 0.109955, l4: 0.152732, l5: 0.304658, l6: 0.559503\n",
            "\n",
            "[epoch: 113/100000, batch: 344/1000, ite: 14043] train loss: 1.7510, accuracy: 91.0823%, tar: 0.0799 \n",
            "l0: 0.071124, l1: 0.071266, l2: 0.077654, l3: 0.096840, l4: 0.131114, l5: 0.210618, l6: 0.389741\n",
            "\n",
            "[epoch: 113/100000, batch: 352/1000, ite: 14044] train loss: 1.7440, accuracy: 93.0462%, tar: 0.0797 \n",
            "l0: 0.070626, l1: 0.072076, l2: 0.087376, l3: 0.119328, l4: 0.185895, l5: 0.309991, l6: 0.472455\n",
            "\n",
            "[epoch: 113/100000, batch: 360/1000, ite: 14045] train loss: 1.7451, accuracy: 92.6139%, tar: 0.0795 \n",
            "l0: 0.072032, l1: 0.073246, l2: 0.082837, l3: 0.106171, l4: 0.153967, l5: 0.240630, l6: 0.430037\n",
            "\n",
            "[epoch: 113/100000, batch: 368/1000, ite: 14046] train loss: 1.7416, accuracy: 93.2000%, tar: 0.0794 \n",
            "l0: 0.086734, l1: 0.087432, l2: 0.097590, l3: 0.121032, l4: 0.167415, l5: 0.263495, l6: 0.448652\n",
            "\n",
            "[epoch: 113/100000, batch: 376/1000, ite: 14047] train loss: 1.7413, accuracy: 91.7485%, tar: 0.0795 \n",
            "l0: 0.081325, l1: 0.083189, l2: 0.097296, l3: 0.132655, l4: 0.210720, l5: 0.333804, l6: 0.548282\n",
            "\n",
            "[epoch: 113/100000, batch: 384/1000, ite: 14048] train loss: 1.7475, accuracy: 92.1962%, tar: 0.0796 \n",
            "l0: 0.064821, l1: 0.065741, l2: 0.077922, l3: 0.106172, l4: 0.173307, l5: 0.271090, l6: 0.448546\n",
            "\n",
            "[epoch: 113/100000, batch: 392/1000, ite: 14049] train loss: 1.7457, accuracy: 92.9828%, tar: 0.0793 \n",
            "l0: 0.103666, l1: 0.105661, l2: 0.119618, l3: 0.145130, l4: 0.210734, l5: 0.319915, l6: 0.491095\n",
            "\n",
            "[epoch: 113/100000, batch: 400/1000, ite: 14050] train loss: 1.7506, accuracy: 90.5247%, tar: 0.0797 \n",
            "l0: 0.068819, l1: 0.069986, l2: 0.077629, l3: 0.100239, l4: 0.154237, l5: 0.227568, l6: 0.360651\n",
            "\n",
            "[epoch: 113/100000, batch: 408/1000, ite: 14051] train loss: 1.7441, accuracy: 92.7435%, tar: 0.0795 \n",
            "l0: 0.078873, l1: 0.079881, l2: 0.094528, l3: 0.132093, l4: 0.232628, l5: 0.378858, l6: 0.646131\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_pHob0P7-kz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPnCoaxA-T-w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5s24y6_f0K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}